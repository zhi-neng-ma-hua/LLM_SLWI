{
	"study_id": "10.1177/07356331241307297",
	"no": "135",
	"first_author_year": "Alsofyani 2025",
	"title_short": "NR",
	"year": "2025",
	"country_region": "Saudi Arabia (western region; Jeddah and Madinah)",
	"llm_type_brief": "ChatGPT (GPT-3.5)",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims, Basic Identification.research_gap_or_novelty, and Methodology.theoretical_foundation, the study clearly states the objective of comparing ChatGPT-generated vs teacher-generated feedback and exploring perceptions within constructivist and sociocultural frameworks, explicitly positioning its contribution relative to prior work.",
	"q2_participant_info_score": "2",
	"q2_participant_info_notes": "Participant Information fields specify educational_level (tertiary EFL institute), language_proficiency (intermediate via placement test), learning_context (EFL at a Saudi university), target_language (English), age (18–19), sex (female only), discipline (university EFL program), and mother_tongue (Arabic), providing detailed language background and demographics.",
	"q3_sampling_and_power_score": "2",
	"q3_sampling_and_power_notes": "Methodology.sampling_method and Methodology.sampling_frame_and_representativeness describe convenience sampling of three existing classes at one female campus and note limits to generalizability, while Methodology.sample_size_and_effect and Methodology.power_analysis report N=102 with a priori GPower calculations justifying the sample size.",
	"q4_group_allocation_and_bias_score": "2",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method reports random assignment of 102 students into ChatGPT and teacher feedback groups, and Study Quality and Reporting.baseline_equivalence plus Methodology.sample_size_and_effect acknowledge significant pretest imbalance and describe use of ANCOVA with pretest as covariate to address selection bias, as summarized in Study Quality and Reporting.risk_of_bias_randomization.",
	"q5_longitudinal_design_score": "1",
	"q5_longitudinal_design_notes": "Methodology.research_design and Outcome.assessment_timepoints indicate a pretest in week 1, six weekly feedback cycles, and a posttest in week 8 (short-term pre–post design), while Outcome.followup_length_and_type is coded as NA, indicating no delayed or long-term follow-up.",
	"q6_measurement_reliability_validity_score": "2",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_instrument describes a structured analytic writing rubric and a researcher-developed perception survey, and Methodology.data_collection_validity_reliability plus Methodology.scoring_procedure_and_rater_training report expert review, piloting, high inter-rater reliability (ICC > 0.9) for writing scores, and Cronbach’s alpha=0.86 for the survey, indicating strong reliability and content validity for the L2 writing measures.",
	"q7_intervention_procedure_and_duration_score": "2",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration and Intervention.intervention_implementation provide a detailed 8-week timeline (pretest/training, six weekly sessions, posttest), and fields such as Intervention.writing_stage, Intervention.writing_task_type, Intervention.llm_model_type, Intervention.llm_model_configuration, Intervention.prompting_strategy, Intervention.training_support_llm_literacy, Intervention.role_llm, Intervention.role_instructor, Intervention.llm_access_policy, and Intervention.setting describe tasks, ChatGPT-3.5 use via a fixed rubric-based prompt, training, and teacher/LLM roles sufficiently for replication.",
	"q8_statistical_method_appropriateness_score": "2",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method indicates Shapiro–Wilk and Levene’s tests, an independent samples t-test for pretest comparison, and ANCOVA with pretest scores as covariate for posttest outcomes, which aligns with Outcome.primary_outcome_variables (posttest writing score with pretest covariate), Outcome.independent_variables_and_factors (feedback type), and Methodology.unit_of_analysis (individual student).",
	"q9_assumption_and_effect_size_score": "1",
	"q9_assumption_and_effect_size_notes": "Study Quality and Reporting.assumption_check_and_data_diagnostics reports normality (Shapiro–Wilk) and variance (Levene’s) checks and the use of ANCOVA to adjust for pretest differences, and Outcome.statistical_significance presents key test statistics and p-values; however, Outcome.effect_size_summary states that specific effect size estimates for observed group differences are NR, and Study Quality and Reporting.data_preprocessing_and_transformation notes only basic averaging of rater scores without further diagnostics.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis is NR, indicating no reported procedures for detecting or handling outliers, while Outcome.limitation, Outcome.challenge, Outcome.implication, and Methodology.theoretical_foundation show that results are interpreted in light of constructivist and sociocultural theory and design limitations but without explicit sensitivity analyses or discussion of aberrant data patterns.",
	"total_quality_score": "17",
	"quality_category": "High",
	"key_quality_concerns": "Short-term two-timepoint design with significant baseline imbalance and no reported effect sizes or outlier handling despite reliance on ANCOVA for group comparisons.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "Yes",
	"design_note_llm_specific": "ChatGPT-3.5 was accessed via the free web interface using a single detailed rubric-based prompt and brief initial training, but access dates, model update details, and technical configurations were not reported, which may limit precise reproducibility of the LLM feedback behavior."
}