{
	"study_id": "http://dx.doi.org/10.52380/mojet.2025.13.1.559",
	"no": "118",
	"first_author_year": "Karanjakwut 2025",
	"title_short": "NR",
	"year": "2025",
	"country_region": "Bangkok, Thailand",
	"llm_type_brief": "ChatGPT, Gemini, Bing Chat",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims, Basic Identification.research_gap_or_novelty and Methodology.theoretical_foundation, the study clearly specifies multiple aims regarding AI-driven versus traditional brainstorming, lecturer and student perspectives, and situates these within process writing and AI chatbot use, indicating a concrete pedagogical gap.",
	"q2_participant_info_score": "1",
	"q2_participant_info_notes": "Participant Information.educational_level, language_proficiency, learning_context, target_language and discipline describe third-year B.Ed English majors in an EFL university context with relevant prior coursework, but Participant Information.age, Participant Information.sex and Participant Information.mother_tongue are NR, and no standardized proficiency test is reported.",
	"q3_sampling_and_power_score": "1",
	"q3_sampling_and_power_notes": "Methodology.sampling_method and Methodology.sampling_frame_and_representativeness indicate purposive sampling of two intact course sections (Section D1 and D2) from a single university, and Methodology.sample_size_and_effect reports N = 86 with group means and t-tests, but Methodology.power_analysis is NR and there is no explicit rationale for sample size or detailed discussion of representativeness beyond the specific cohort.",
	"q4_group_allocation_and_bias_score": "1",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method and Study Quality and Reporting.risk_of_bias_randomization state that intact sections D1 (conventional) and D2 (AI-driven) were used without randomization, and Study Quality and Reporting.baseline_equivalence notes that no pretest of writing performance or statistical baseline comparison was conducted, so allocation is clearly described but potential selection and baseline biases are not controlled.",
	"q5_longitudinal_design_score": "1",
	"q5_longitudinal_design_notes": "Methodology.research_design and Intervention.duration describe a six-week sequence with three assignments (People, Places, Things), and Outcome.assessment_timepoints indicates assessments at weeks 2, 4 and 6, but Outcome.limitation notes the absence of both a writing pretest and any delayed posttest, so only short-term outcomes over repeated tasks are captured without formal longitudinal analysis.",
	"q6_measurement_reliability_validity_score": "1",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_instrument and Methodology.data_collection_validity_reliability report that the questionnaire was adapted from prior studies and validated by three experts and that assignments were graded using university criterion-referenced scales with graders blinded to AI vs student brainstorming, but no internal consistency indices (e.g., Cronbach’s alpha) or inter-rater reliability statistics for writing scores are provided in Methodology.scoring_procedure_and_rater_training.",
	"q7_intervention_procedure_and_duration_score": "1",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration and Intervention.intervention_implementation detail a six-week process-writing sequence, specifying topics, stages and how the AI versus traditional brainstorming was incorporated, and Intervention.writing_stage, Intervention.setting, Intervention.llm_model_type, llm_integration_mode, prompting_strategy, role_llm, role_instructor, llm_access_policy and training_support_llm_literacy describe overall use of ChatGPT, Gemini and Bing for brainstorming, but specific LLM versions, concrete example prompts, and systematic AI-literacy training or safety procedures are not reported, limiting full reproducibility.",
	"q8_statistical_method_appropriateness_score": "2",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method indicates use of descriptive statistics and independent samples t-tests to compare AI-driven and traditional groups on assignment scores, which aligns with Outcome.primary_outcome_variables, Outcome.independent_variables_and_factors and Methodology.unit_of_analysis that define individual assignment scores as outcomes and brainstorming type (AI vs conventional) as the main between-group factor.",
	"q9_assumption_and_effect_size_score": "1",
	"q9_assumption_and_effect_size_notes": "Outcome.statistical_significance reports t-values and p-values for group comparisons on each assignment, and Study Quality and Reporting.data_preprocessing_and_transformation notes basic averaging and interpretation of scores, but Study Quality and Reporting.assumption_check_and_data_diagnostics and Outcome.effect_size_summary indicate that normality or homogeneity checks and quantitative effect sizes (e.g., Cohen’s d) were not reported.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis is NR with no mention of outlier handling or robustness checks, while Outcome.limitation, Outcome.challenge and Outcome.implication reflect on sample and design constraints, overreliance and interpretability issues around AI brainstorming, and the need to balance AI affordances with independent thinking within the process-writing and AI integration framework described in Methodology.theoretical_foundation.",
	"total_quality_score": "12",
	"quality_category": "Moderate",
	"key_quality_concerns": "Non-random intact-group design without a writing pretest or demonstrated baseline equivalence, together with absent reliability indices and assumption checks for t-tests, limits causal interpretation and precision of the reported writing gains.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "Yes",
	"design_note_llm_specific": "Students in the intervention group directly used ChatGPT, Gemini and Bing as brainstorming tools with minimal reported AI-literacy training and no details on model versions or safety settings, so both LLM behavior and actual exposure to AI support may vary across learners and be difficult to replicate precisely."
}