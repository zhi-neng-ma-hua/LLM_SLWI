{
	"study_id": "NR",
	"no": "708",
	"first_author_year": "Oktarin 2024",
	"title_short": "NR",
	"year": "2024",
	"country_region": "Indonesia (one private university)",
	"llm_type_brief": "ChatGPT (AI chatbot)",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims, Basic Identification.research_gap_or_novelty, and Methodology.theoretical_foundation, the study clearly formulates aims about ChatGPT effects on writing outcomes, engagement, and feedback literacy, highlights limited prior empirical work, and anchors the study in academic literacies and feedback literacy frameworks.",
	"q2_participant_info_score": "1",
	"q2_participant_info_notes": "Participant Information.educational_level, learning_context, mother_tongue, target_language, discipline, and language_proficiency (comparable writing abilities via pretest) are reported, but key demographic variables such as age and sex are NR, so participant description is incomplete.",
	"q3_sampling_and_power_score": "1",
	"q3_sampling_and_power_notes": "Methodology.sampling_method and Methodology.sampling_frame_and_representativeness describe purposive selection of two intact Economic English classes at one university and acknowledge limited generalizability, and Methodology.sample_size_and_effect reports N=50 and main t-test results, but Methodology.power_analysis is NR and no explicit sample-size rationale is given.",
	"q4_group_allocation_and_bias_score": "1",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method and Study Quality and Reporting.risk_of_bias_randomization indicate non-random assignment of intact classes to experimental and control conditions with the same teacher, and Study Quality and Reporting.baseline_equivalence notes pretest comparability, but potential selection bias and other allocation-related risks are not discussed in depth.",
	"q5_longitudinal_design_score": "0",
	"q5_longitudinal_design_notes": "Although Intervention.duration spans 16 weeks and Outcome.assessment_timepoints notes a pretest used to confirm equivalence, the main outcomes (writing learning outcomes, feedback literacy, engagement) are evaluated only at a single post-test timepoint without analysis of change over time or follow-up (Outcome.followup_length_and_type is NA/NR for main outcomes).",
	"q6_measurement_reliability_validity_score": "1",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_instrument and Methodology.data_collection_validity_reliability report an analytic writing rubric and high internal consistencies for the feedback literacy questionnaire (Cronbach’s alpha=0.91) and engagement scale (alpha=0.92), and interrater reliability for qualitative coding, but specific reliability coefficients for the main writing test and details of rater training in Methodology.scoring_procedure_and_rater_training are not fully reported.",
	"q7_intervention_procedure_and_duration_score": "2",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration and Intervention.intervention_implementation describe a 16-week course with shared textbook and teacher across groups and additional ChatGPT-based feedback for the experimental group, while Intervention.llm_model_type, Intervention.llm_integration_mode, Intervention.llm_access_policy, Intervention.prompting_strategy, Intervention.training_support_llm_literacy, Intervention.role_llm, and Intervention.role_instructor specify how ChatGPT was used, constrained (via Turnitin checks), and supported, providing sufficient detail to broadly replicate the intervention despite missing technical model/version specifics.",
	"q8_statistical_method_appropriateness_score": "2",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method explains that independent samples t-tests (with Levene’s tests) were used in SPSS to compare two groups on continuous outcome measures (writing scores, feedback literacy, engagement) defined in Outcome.primary_outcome_variables, with the individual student as the unit in Methodology.unit_of_analysis, which aligns with the post-test-only control-group design.",
	"q9_assumption_and_effect_size_score": "1",
	"q9_assumption_and_effect_size_notes": "Study Quality and Reporting.assumption_check_and_data_diagnostics notes that normality and homogeneity tests were conducted and Levene’s tests are reported, and Outcome.statistical_significance provides t-values, p-values, and confidence intervals, but Outcome.effect_size_summary indicates that standardized effect sizes (e.g., Cohen’s d, eta squared) were not reported.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis is NR, but Outcome.limitation, Outcome.challenge, Outcome.future_work, and Outcome.implication discuss contextual and methodological limitations and interpret findings in light of the feedback literacy and academic literacies perspectives outlined in Methodology.theoretical_foundation, without explicit treatment of outliers or sensitivity analyses.",
	"total_quality_score": "12",
	"quality_category": "Moderate",
	"key_quality_concerns": "Non-random intact-class post-test-only design with small sample size and no reported standardized effect sizes or detailed writing-score reliability for the main outcome.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "Yes",
	"design_note_llm_specific": "ChatGPT was used only in the experimental group primarily as an out-of-class homework feedback tool with teacher monitoring and Turnitin checks, but the underlying GPT version and technical configuration were not reported, which limits control over and reproducibility of the chatbot-based intervention."
}