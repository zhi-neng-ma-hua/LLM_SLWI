{
	"study_id": "NR",
	"no": "437",
	"first_author_year": "Campos 2025",
	"title_short": "NR",
	"year": "2025",
	"country_region": "Japan",
	"llm_type_brief": "ChatGPT",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims, Basic Identification.research_gap_or_novelty, and Methodology.theoretical_foundation, the study clearly states its aims (perceptions, linguistic gains, and challenges of AI-assisted feedback in CLIL), links them to a specific gap, and frames AI-assisted feedback within CLIL and self-regulated learning.",
	"q2_participant_info_score": "1",
	"q2_participant_info_notes": "Participant Information.educational_level, Participant Information.discipline, Participant Information.learning_context, and Participant Information.target_language describe undergraduates in a Business Administration CLIL course using English (L2), but Participant Information.language_proficiency, Participant Information.age, Participant Information.sex, and Participant Information.mother_tongue are NR.",
	"q3_sampling_and_power_score": "1",
	"q3_sampling_and_power_notes": "Methodology.sampling_method and Methodology.sampling_frame_and_representativeness describe convenience sampling of 205 Business Administration students in one CLIL course and note limited generalizability, and Methodology.sample_size_and_effect reports the numbers of survey respondents and compositions analyzed, but Methodology.power_analysis is NR and no explicit sample size rationale is provided.",
	"q4_group_allocation_and_bias_score": "1",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method is NR and Study Quality and Reporting.risk_of_bias_randomization states that no randomization or control group was used, with all eligible students receiving AI-assisted feedback, so the design acknowledges but does not mitigate potential selection and confounding biases; Study Quality and Reporting.baseline_equivalence is NA for between-group comparisons.",
	"q5_longitudinal_design_score": "1",
	"q5_longitudinal_design_notes": "Methodology.research_design and Intervention.duration describe a 15-week course with repeated weekly writing assignments and AI-reviewed drafts, and Outcome.assessment_timepoints notes multiple draftâ€“final comparisons across six teacher-assessed assignments, but there is no explicit pre/post test of overall writing proficiency or delayed follow-up and no formal analysis of changes over calendar time.",
	"q6_measurement_reliability_validity_score": "1",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_instrument specifies CLIL writing tasks, a bilingual survey, and an error-counting scheme, and Methodology.scoring_procedure_and_rater_training explains that grammar and spelling errors were those identified by ChatGPT and then counted by researchers, but Methodology.data_collection_validity_reliability reports no psychometric validity or reliability indices for the survey or writing measures and no inter-rater reliability for error coding.",
	"q7_intervention_procedure_and_duration_score": "2",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration and Intervention.intervention_implementation describe a 15-week CLIL writing course with weekly assignments, AI-reviewed drafts, and teacher feedback, while Intervention.setting, Intervention.writing_task_type, Intervention.writing_stage, Intervention.llm_model_type, Intervention.llm_integration_mode, Intervention.prompting_strategy, Intervention.training_support_llm_literacy, Intervention.role_llm, Intervention.role_instructor, Intervention.llm_access_policy, and Intervention.llm_safety_guardrails together provide a reasonably detailed picture of how ChatGPT feedback was integrated and used, despite missing technical model configuration.",
	"q8_statistical_method_appropriateness_score": "2",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method reports descriptive statistics for survey items and correction rates for grammar and spelling errors, combined with thematic analysis of open-ended responses, which aligns with the non-experimental design described in Methodology.research_design and the descriptive Outcome.primary_outcome_variables and Outcome.independent_variables_and_factors, with Methodology.unit_of_analysis specifying students, compositions, and errors as analysis units.",
	"q9_assumption_and_effect_size_score": "0",
	"q9_assumption_and_effect_size_notes": "Study Quality and Reporting.assumption_check_and_data_diagnostics indicates that no inferential statistical tests or assumption checks were conducted, Outcome.statistical_significance and Outcome.effect_size_summary are NR, and Study Quality and Reporting.data_preprocessing_and_transformation only describes selection and counting of AI-flagged errors without discussion of distributional assumptions or effect sizes.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis is NR, but Outcome.limitation and Outcome.challenge discuss design constraints (single course, no control group, limited focus on grammar and spelling, possible AI inaccuracies and over-reliance), and Outcome.implication together with Methodology.theoretical_foundation integrates findings with CLIL and self-regulated learning concepts without addressing data outliers or robustness analyses.",
	"total_quality_score": "12",
	"quality_category": "Moderate",
	"key_quality_concerns": "Single-group convenience sample without control group and absence of inferential statistics or psychometric evidence for key measures limit causal inference, generalizability, and robustness of conclusions about AI-assisted feedback effects.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "No",
	"design_note_llm_specific": "ChatGPT was used via fixed teacher-designed prompts as an external feedback tool with no reported model version, configuration, or detailed monitoring of unsupervised use, which constrains reproducibility and precise characterization of AI exposure and feedback quality."
}