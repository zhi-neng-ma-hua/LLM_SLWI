{
	"study_id": "NR",
	"no": "677",
	"first_author_year": "Yan 2024",
	"title_short": "NR",
	"year": "2024",
	"country_region": "China (one Chinese university)",
	"llm_type_brief": "ChatGPT (GPT-3.5, OpenAI)",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims, Basic Identification.research_gap_or_novelty, and Methodology.theoretical_foundation, the study clearly specifies comparative aims for individual versus collaborative ChatGPT feedback processing on task improvement and learning, identifies gaps in classroom-based automated feedback research, and situates the work within ecological and sociocultural feedback frameworks.",
	"q2_participant_info_score": "2",
	"q2_participant_info_notes": "Participant Information.educational_level, Participant Information.language_proficiency, Participant Information.mother_tongue, Participant Information.learning_context, Participant Information.target_language, Participant Information.age, and Participant Information.discipline provide detailed information on study level, L2 proficiency and years of learning, L1, EFL context, target language, age, and course type, although sex distribution (Participant Information.sex) is NR.",
	"q3_sampling_and_power_score": "1",
	"q3_sampling_and_power_notes": "Methodology.sampling_method and Methodology.sampling_frame_and_representativeness describe purposive recruitment of 117 students from one university and random assignment to four groups, and Methodology.sample_size_and_effect reports group sizes and effect sizes from mixed ANOVAs, but Methodology.power_analysis is NR and no a priori sample-size or power rationale is provided, with representativeness explicitly noted as limited.",
	"q4_group_allocation_and_bias_score": "1",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method states that eligible students were randomly assigned to individual processing, teacher-scaffolded, peer-scaffolded, and teacher-plus-peer-scaffolded conditions, and Study Quality and Reporting.risk_of_bias_randomization acknowledges randomization, but Study Quality and Reporting.baseline_equivalence notes that formal baseline equivalence tests (e.g., on initial draft scores or proficiency) were not reported, leaving allocation bias only partially addressed.",
	"q5_longitudinal_design_score": "2",
	"q5_longitudinal_design_notes": "Methodology.research_design, Intervention.duration, Outcome.assessment_timepoints, and Outcome.followup_length_and_type describe three during-intervention tasks (T1–T3) with draft and final scores plus a delayed new-topic draft (NT) written three weeks later, and mixed ANOVAs are used to analyze both short-term task improvements and longer-term learning trajectories.",
	"q6_measurement_reliability_validity_score": "2",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_instrument and Outcome.writing_performance_measure specify CET-6-based writing tasks and the Hedgcock and Lefkowitz 100-point analytic rating scale, while Methodology.data_collection_validity_reliability and Methodology.scoring_procedure_and_rater_training report expert-based prompt selection, double-blind rating by four raters, and high interrater reliability (Fleiss’s kappa≈0.84, 95% CI≈[0.76, 0.93]) for the main L2 writing outcomes.",
	"q7_intervention_procedure_and_duration_score": "2",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration and Intervention.intervention_implementation detail the 7-week sequence with specific sessions for training, drafting, ChatGPT feedback seeking, feedback processing, and revising across T1–T3 plus a delayed NT task, and Intervention.llm_model_type, Intervention.llm_model_configuration, Intervention.llm_integration_mode, Intervention.prompting_strategy, Intervention.training_support_llm_literacy, Intervention.role_llm, Intervention.role_instructor, Intervention.llm_access_policy, Intervention.llm_safety_guardrails, Intervention.writing_stage, and Intervention.setting jointly provide rich information on GPT-3.5 access, standardized prompting, teacher and peer scaffolding roles, and classroom context sufficient for replication.",
	"q8_statistical_method_appropriateness_score": "2",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method reports 4×3 and 4×4 mixed ANOVAs on gain scores (final minus draft for T1–T3) and draft scores (T1–T3 and NT) with group as a between-subjects factor and task as a within-subjects factor, using Mauchly’s test, Greenhouse–Geisser corrections, Bonferroni-adjusted post-hoc tests, and effect sizes (partial eta squared and Cohen’s d), and Outcome.primary_outcome_variables, Outcome.independent_variables_and_factors, and Methodology.unit_of_analysis show that these methods are appropriate for the individual-level repeated-measures design and continuous L2 writing quality measures.",
	"q9_assumption_and_effect_size_score": "2",
	"q9_assumption_and_effect_size_notes": "Outcome.statistical_significance and Outcome.effect_size_summary provide F-values, p-values, partial eta squared, and Cohen’s d for main effects and pairwise comparisons, and Study Quality and Reporting.assumption_check_and_data_diagnostics notes that standard diagnostic tests were conducted with explicit use of Mauchly’s test for sphericity and Greenhouse–Geisser corrections when violated, while Study Quality and Reporting.data_preprocessing_and_transformation describes the construction of gain scores and use of raw draft scores without complex transformations, even though normality and homogeneity checks are not detailed.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis is NR and no explicit outlier checks or sensitivity analyses are reported, but Outcome.limitation, Outcome.challenge, Outcome.implication, and Methodology.theoretical_foundation show a theoretically integrated interpretation of findings within sociocultural and ecological feedback frameworks, including critical discussion of unrealistically large task gains under individual ChatGPT use, academic integrity risks, and the pedagogical value of teacher and peer scaffolding.",
	"total_quality_score": "17",
	"quality_category": "High",
	"key_quality_concerns": "Purposive single-university sample without reported baseline equivalence tests, power analysis, or outlier handling limits generalizability and leaves some uncertainty about residual selection bias and robustness of the mixed-ANOVA findings.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "Yes",
	"design_note_llm_specific": "All groups used ChatGPT (GPT-3.5) accessed via a proxy with a standardized multi-turn prompting pattern as the sole revision feedback source, but the study did not analyze the accuracy or content of individual feedback messages and future updates to ChatGPT may constrain exact reproducibility of the intervention."
}