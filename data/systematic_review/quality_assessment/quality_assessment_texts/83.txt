{
	"study_id": "10.34105/j.kmel.2025.17.009",
	"no": "83",
	"first_author_year": "Al Ghaithi 2025",
	"title_short": "NR",
	"year": "2025",
	"country_region": "Oman (higher education institution, General Foundation Program)",
	"llm_type_brief": "EditGPT (Anthropic)",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims and Basic Identification.research_gap_or_novelty, the study clearly aims to test whether EditGPT improves Omani EFL learners’ writing and to explore learner perceptions while positioning predictive text tools as under-researched, and Methodology.theoretical_foundation links the work to L2 writing, written corrective feedback and AWE literature.",
	"q2_participant_info_score": "2",
	"q2_participant_info_notes": "Participant Information.educational_level, language_proficiency, learning_context, target_language, mother_tongue, age and discipline specify pre-intermediate Arabic L1 General Foundation Program students aged 18–19 in an EFL context, although Participant Information.sex and prior_experience_llm are NR.",
	"q3_sampling_and_power_score": "1",
	"q3_sampling_and_power_notes": "Methodology.sampling_method and Methodology.sample_size_and_effect report random sampling of 60 pre-intermediate students into three groups of 20 with pretest and posttest scores, and Methodology.sampling_frame_and_representativeness notes the single Omani GFP institution and limited representativeness, while Methodology.power_analysis is NR and no explicit sample size or power justification is provided.",
	"q4_group_allocation_and_bias_score": "1",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method and Study Quality and Reporting.risk_of_bias_randomization indicate that students were divided into three groups but do not clarify whether allocation to control, experimental A and experimental B was random, and Study Quality and Reporting.baseline_equivalence reports non-significant pretest ANOVA differences among groups, partially mitigating but not eliminating selection bias.",
	"q5_longitudinal_design_score": "1",
	"q5_longitudinal_design_notes": "Methodology.research_design and Intervention.duration describe a four-week pretest–posttest design with two treatment assignments and a posttest, and Outcome.assessment_timepoints states that assessments were limited to pretest and immediate posttest with no delayed follow-up reported.",
	"q6_measurement_reliability_validity_score": "1",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_instrument describes coursebook-based narrative and compare-and-contrast writing tasks scored with a researcher-made rubric and a 10-item perception questionnaire, and Methodology.data_collection_validity_reliability reports pilot testing and Cronbach’s alpha values for the rubric and questionnaire, but Methodology.scoring_procedure_and_rater_training provides no details on number of raters, rater training or inter-rater reliability for writing scores.",
	"q7_intervention_procedure_and_duration_score": "2",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration and Intervention.intervention_implementation give a week-by-week account of pretest, two genre-specific writing tasks and posttest under three feedback conditions, and fields such as Intervention.llm_model_type, llm_integration_mode, llm_model_configuration, role_llm, role_instructor, writing_stage and writing_task_type describe EditGPT’s role, student interaction and teacher roles in sufficient procedural detail despite limited information on prompting_strategy and llm_safety_guardrails.",
	"q8_statistical_method_appropriateness_score": "1",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method explains that Shapiro–Wilk tests were followed by one-way ANOVAs comparing the three feedback groups’ pretest and posttest writing scores at the individual student level (Methodology.unit_of_analysis), which is broadly consistent with Outcome.primary_outcome_variables and Outcome.independent_variables_and_factors but does not explicitly model within-subject change scores or detail the grammar-focused analysis.",
	"q9_assumption_and_effect_size_score": "1",
	"q9_assumption_and_effect_size_notes": "Study Quality and Reporting.assumption_check_and_data_diagnostics notes Shapiro–Wilk normality checks supporting the use of ANOVA and Outcome.statistical_significance reports F and p values for pretest and posttest group comparisons, while Outcome.effect_size_summary states that no effect sizes were reported and Study Quality and Reporting.data_preprocessing_and_transformation indicates no additional preprocessing or transformations.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis is NR with no described handling of atypical scores or robustness checks, and although Outcome.limitation, Outcome.challenge and Outcome.implication discuss sample, contextual and pedagogical constraints in light of L2 writing and feedback perspectives (Methodology.theoretical_foundation), there is limited integration of findings with potential data anomalies or sensitivity analyses.",
	"total_quality_score": "13",
	"quality_category": "Moderate",
	"key_quality_concerns": "Single Omani institution with unclear allocation to feedback groups and no effect sizes or inter-rater reliability for writing scores, together with limited modeling of pre–post changes and no outlier or sensitivity analyses.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "Yes",
	"design_note_llm_specific": "EditGPT was used as the sole automated feedback source for one experimental group with minimal AI literacy or prompting guidance, and the underlying LLM version and configuration were not reported, which constrains reproducibility and interpretation of the AI-assisted writing gains."
}