{
	"study_id": "NR",
	"no": "136",
	"first_author_year": "Nguyen 2025",
	"title_short": "NR",
	"year": "2025",
	"country_region": "Vietnam (private university, FPT University)",
	"llm_type_brief": "ChatGPT 4.0",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims, Basic Identification.research_gap_or_novelty, and Methodology.theoretical_foundation, the study clearly states multiple aims about ChatGPT-supported pre-writing, situates them in gaps concerning affective engagement and text quality, and anchors them in Sociocultural Theory, process writing, and engagement frameworks.",
	"q2_participant_info_score": "2",
	"q2_participant_info_notes": "Participant Information.educational_level, language_proficiency, learning_context, mother_tongue, age, sex, discipline, prior_experience_llm, and target_language together provide detailed background on first-year Vietnamese EFL students (B1–B2 CEFR) aged 18–21 with Vietnamese as L1 and specified gender distribution.",
	"q3_sampling_and_power_score": "2",
	"q3_sampling_and_power_notes": "Methodology.sampling_method and Methodology.sampling_frame_and_representativeness describe non-random convenience sampling of two intact classes at a single private university, while Methodology.sample_size_and_effect and Methodology.power_analysis report N = 56, an a priori GPower analysis, and note limitations in representativeness.",
	"q4_group_allocation_and_bias_score": "1",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method indicates that learners were in two intact classes with counterbalanced exposure to ChatGPT and non-ChatGPT pre-writing conditions, and Study Quality and Reporting.risk_of_bias_randomization and Study Quality and Reporting.baseline_equivalence acknowledge the absence of random assignment and lack of formal baseline equivalence tests between classes, leaving some selection and order bias concerns.",
	"q5_longitudinal_design_score": "1",
	"q5_longitudinal_design_notes": "Methodology.research_design, Intervention.duration, and Outcome.assessment_timepoints show a short four-week within-subjects design with two writing tasks under different pre-writing conditions but no delayed post-test or long-term follow-up, so temporal analysis is limited to short-term comparisons across the two tasks.",
	"q6_measurement_reliability_validity_score": "2",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_validity_reliability reports good internal consistency for the affective engagement questionnaire (Cronbach’s alpha .879 and .932), expert review for content validity, and high inter-rater agreement percentages for coding logs, note-taking sheets, texts, and interviews; Methodology.scoring_procedure_and_rater_training and Methodology.data_collection_instrument describe standardized rubrics and blinded scoring, though specific reliability coefficients for writing scores are not fully detailed.",
	"q7_intervention_procedure_and_duration_score": "2",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration and Intervention.intervention_implementation provide a detailed week-by-week description of two pre-writing conditions and timed writing procedures, while Intervention.llm_model_type, llm_model_configuration, llm_integration_mode, prompting_strategy, training_support_llm_literacy, role_llm, role_instructor, writing_stage, and llm_access_policy specify how ChatGPT 4.0 was accessed, how students typically prompted it, and how access was controlled, allowing broad replication of the ChatGPT-supported pre-writing set-up.",
	"q8_statistical_method_appropriateness_score": "2",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method and Methodology.unit_of_analysis indicate that outcomes at the learner level were analyzed using a Linear Mixed-Effects Model with participant as random effect for writing scores, Wilcoxon signed-rank tests for non-normal repeated measures, paired-samples t-tests for questionnaire comparisons, and Spearman correlations, which are appropriate for the within-subjects design and the Outcome.primary_outcome_variables and Outcome.independent_variables_and_factors.",
	"q9_assumption_and_effect_size_score": "2",
	"q9_assumption_and_effect_size_notes": "Study Quality and Reporting.assumption_check_and_data_diagnostics notes Shapiro–Wilk tests showing non-normality and the use of non-parametric tests and LMM with VIF checks for multicollinearity, while Outcome.statistical_significance and Outcome.effect_size_summary report p-values, Conditional R², Wilcoxon r, Spearman rs, and Cohen’s d, demonstrating attention to both statistical assumptions and effect sizes.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis is NR, so specific outlier detection or sensitivity analyses are not described, but Outcome.limitation, Outcome.challenge, Outcome.implication, and Methodology.theoretical_foundation provide a theoretically grounded interpretation of results linked to Sociocultural Theory and engagement frameworks and discuss design constraints such as short-term scope and potential overreliance on ChatGPT.",
	"total_quality_score": "17",
	"quality_category": "High",
	"key_quality_concerns": "Single-site convenience sample with non-random intact classes and only short-term within-subject comparison; no explicit outlier detection or treatment reported.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "Yes",
	"design_note_llm_specific": "ChatGPT 4.0 was used only during a 15-minute pre-writing phase with free, unstandardized prompting and limited reporting of technical configuration, constraining control over learners’ AI use and limiting exact reproducibility across settings."
}