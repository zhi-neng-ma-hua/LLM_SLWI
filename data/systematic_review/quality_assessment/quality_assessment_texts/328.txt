{
	"study_id": "10.1016/j.lmot.2025.102158",
	"no": "328",
	"first_author_year": "Zou 2025",
	"title_short": "NR",
	"year": "2025",
	"country_region": "China (Sino-British university context at Xi’an Jiaotong-Liverpool University)",
	"llm_type_brief": "Self-developed LLM IELTS chatbot",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims, Basic Identification.research_gap_or_novelty, and Methodology.theoretical_foundation, the study clearly states aims about visualised vs non-visualised GenAI chatbot feedback on revision, emotions and HCI, identifies a gap in emotional/visual design of GenAI feedback, and anchors the work in CATLM, CLT, CTML and EFL emotion literature.",
	"q2_participant_info_score": "1",
	"q2_participant_info_notes": "Participant Information.educational_level, Participant Information.discipline, Participant Information.language_proficiency, Participant Information.learning_context and Participant Information.target_language specify first-year Chinese EFL undergraduates in an EAP course at CEFR B1+–B2− in an EFL context, but Participant Information.age, Participant Information.sex and Participant Information.mother_tongue are NR, so key demographic details are incomplete.",
	"q3_sampling_and_power_score": "1",
	"q3_sampling_and_power_notes": "Methodology.sampling_method and Methodology.sample_size_and_effect report N=60 EFL undergraduates randomly and equally assigned to two feedback-mode groups with effect sizes, and Methodology.sampling_frame_and_representativeness notes the single-institution, small-sample limitations, but Methodology.power_analysis is NR and no a priori sample-size or power justification is described.",
	"q4_group_allocation_and_bias_score": "2",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method states that participants were randomly and equally assigned to visualised and non-visualised feedback groups, and Study Quality and Reporting.risk_of_bias_randomization plus Study Quality and Reporting.baseline_equivalence indicate random allocation with no significant pre-test differences in key writing scores between groups, while acknowledging that detailed randomisation procedures (e.g., allocation concealment) are not specified.",
	"q5_longitudinal_design_score": "1",
	"q5_longitudinal_design_notes": "Methodology.research_design and Intervention.duration describe a 2 (time: pre vs post) × 2 (feedback mode) design implemented in a single lab session with one revision cycle, and Outcome.assessment_timepoints indicates pre- and post-test within the same session, while Outcome.followup_length_and_type is NA, so only short-term change is examined without longer-term follow-up.",
	"q6_measurement_reliability_validity_score": "1",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_validity_reliability and Methodology.scoring_procedure_and_rater_training report excellent ICCs between two human raters (0.809–0.896) and high ICCs between human averages and AI scores (0.858–0.961) for IELTS-based writing scores, and questionnaires were adapted from established scales, but internal consistency (e.g., Cronbach’s alpha) for the affective and cognitive measures and detailed rater training procedures are not reported.",
	"q7_intervention_procedure_and_duration_score": "2",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration and Intervention.intervention_implementation provide a stepwise account of the single-session procedure (consent, pre-survey, training video, timed essay, Grade pre-score, structured use of chatbot functions, revision, Grade post-score, post-survey), while LLM-related fields (Intervention.llm_model_type, Intervention.llm_model_configuration, Intervention.llm_integration_mode, Intervention.prompting_strategy, Intervention.training_support_llm_literacy, Intervention.role_llm, Intervention.role_instructor, Intervention.setting) detail the chatbot functions, interface, roles and training; however, Intervention.llm_safety_guardrails is NR and exact LLM engine parameters are unspecified, even though the pedagogical procedure is sufficiently described for approximate replication.",
	"q8_statistical_method_appropriateness_score": "2",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method reports mixed ANOVAs with time (pre vs post) and group (visualised vs non-visualised) for writing and emotion outcomes, and independent-samples t-tests for post-only variables, which align with Outcome.independent_variables_and_factors, Outcome.primary_outcome_variables and the repeated-measures structure described in Methodology.unit_of_analysis (individual students’ scores).",
	"q9_assumption_and_effect_size_score": "1",
	"q9_assumption_and_effect_size_notes": "Outcome.statistical_significance and Outcome.effect_size_summary present F-values, t-values, p-values, partial eta squared and Cohen’s d for key effects, while Study Quality and Reporting.assumption_check_and_data_diagnostics notes normality checks via skewness/kurtosis and Q–Q/P–P plots and Study Quality and Reporting.data_preprocessing_and_transformation describes score aggregation; however, homogeneity-of-variance tests, outlier diagnostics or other assumption checks are not reported.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis is NR, with no reported outlier handling or sensitivity analyses, but Outcome.limitation and Outcome.implication, together with Methodology.theoretical_foundation, discuss sample/context constraints, single-round revision, lack of qualitative data and theoretical implications within CATLM and CLT, indicating some integration of findings with theory and methodological limitations.",
	"total_quality_score": "14",
	"quality_category": "Moderate",
	"key_quality_concerns": "Single-session lab study with a small single-site sample and no follow-up, combined with limited reliability reporting for affective scales and lack of detailed LLM specification and outlier handling.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "Yes",
	"design_note_llm_specific": "Both conditions used a self-developed IELTS writing chatbot powered by an unspecified large language model with identical underlying settings but different feedback visualisation, while the exact LLM provider, version, prompt texts and safety guardrails were not reported, which constrains reproducibility and generalisation to other GenAI systems."
}