{
	"study_id": "10.1080/17501229.2025.2503890",
	"no": "198",
	"first_author_year": "Zhang 2025",
	"title_short": "NR",
	"year": "2025",
	"country_region": "China and United States (Chinese EFL students studying at universities in China or the United States, recruited from GRE preparation institutions)",
	"llm_type_brief": "GPT-4 Turbo (ChatGPT-based GenAI)",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims, Basic Identification.research_gap_or_novelty, and Methodology.theoretical_foundation, the study clearly specifies aims comparing GenAI-only and hybrid feedback on multiple L2 academic writing traits and motivation, and situates them within Hattie and Timperley’s feedback model and Self Determination Theory.",
	"q2_participant_info_score": "2",
	"q2_participant_info_notes": "Participant Information fields report educational_level (undergraduate and graduate students), language_proficiency (TOEFL>90, IELTS>7, over ten years of English study), learning_context (Chinese EFL GRE preparation), target_language (English L2), mother_tongue (Chinese), sex (23 males, 37 females), age (mean 23.8), and discipline distribution, providing detailed linguistic and demographic background.",
	"q3_sampling_and_power_score": "1",
	"q3_sampling_and_power_notes": "Methodology.sampling_method and Methodology.sampling_frame_and_representativeness describe purposeful and convenience sampling of motivated Chinese EFL GRE candidates and note limited generalizability, and Methodology.sample_size_and_effect reports N=60 with detailed pre/post means and Hedges g, but Methodology.power_analysis is NR and no a priori sample-size justification is provided.",
	"q4_group_allocation_and_bias_score": "2",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method states that participants were non-randomly divided into two groups based on initial writing performance to ensure similar pre-writing means, Study Quality and Reporting.baseline_equivalence notes nearly identical pre scores (2.88 vs 2.87), and Study Quality and Reporting.risk_of_bias_randomization acknowledges the non-random assignment and associated selection bias.",
	"q5_longitudinal_design_score": "1",
	"q5_longitudinal_design_notes": "Methodology.research_design, Intervention.duration, and Outcome.assessment_timepoints indicate a 12-week course with pre-course and immediate post-course GRE-style writing assessments plus practice essays during the course, but Outcome.followup_length_and_type is NR/absent, indicating no delayed follow-up for longer-term effects.",
	"q6_measurement_reliability_validity_score": "1",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_instrument and Methodology.data_collection_validity_reliability describe GRE-like tasks scored with GRE rubrics and the 6 Traits model and a feedback-motivation questionnaire with very high internal consistency (Cronbach’s alpha=0.97), and Methodology.scoring_procedure_and_rater_training outlines a two-rater plus adjudicator procedure for essay scoring, but no formal inter-rater reliability coefficients or detailed rater training procedures are reported.",
	"q7_intervention_procedure_and_duration_score": "2",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration and Intervention.intervention_implementation specify a 12-week GRE course with ten 90-minute writing sessions, six practice essays, and a final timed assessment, while Intervention.writing_task_type, Intervention.writing_stage, Intervention.setting, and LLM-related fields (Intervention.llm_model_type, Intervention.llm_model_configuration, Intervention.llm_integration_mode, Intervention.prompting_strategy, Intervention.training_support_llm_literacy, Intervention.role_llm, Intervention.role_instructor, Intervention.llm_access_policy, Intervention.llm_safety_guardrails) detail the GPT-4 Turbo Coze-based feedback system and the distinct GenAI-only versus hybrid feedback workflows sufficiently for approximate replication.",
	"q8_statistical_method_appropriateness_score": "2",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method reports using Wilcoxon signed-rank tests for within-group pre–post writing changes and Mann–Whitney U tests for between-group comparisons of post-test writing traits and questionnaire scores due to non-normal distributions, which aligns with Outcome.primary_outcome_variables, Outcome.independent_variables_and_factors, and Methodology.unit_of_analysis focused on individual students’ trait scores and perceptions.",
	"q9_assumption_and_effect_size_score": "2",
	"q9_assumption_and_effect_size_notes": "Study Quality and Reporting.assumption_check_and_data_diagnostics notes the choice of non-parametric tests due to non-normal score distributions, Outcome.statistical_significance reports Wilcoxon and Mann–Whitney results with p-values, and Outcome.effect_size_summary plus Methodology.data_preprocessing_and_transformation state that Cohen’s d/Hedges g effect sizes were calculated for within- and between-group differences, although detailed normality statistics and further diagnostics are not provided.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis is NR, indicating no explicit procedures for identifying or handling outliers or conducting sensitivity analyses, whereas Outcome.limitation, Outcome.challenge, Outcome.implication, and Methodology.theoretical_foundation show that results are interpreted in light of Hattie and Timperley’s Feedback Model and Self Determination Theory with discussion of design constraints and the differential roles of GenAI and hybrid feedback.",
	"total_quality_score": "16",
	"quality_category": "High",
	"key_quality_concerns": "Purposeful non-random sampling with group assignment based on initial performance and no reported power analysis or outlier handling limits internal validity and generalizability despite detailed effect-size reporting.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "Yes",
	"design_note_llm_specific": "A customized GPT-4 Turbo feedback system via the Coze platform with a GRE essay knowledge base is described, but detailed prompt templates, parameter settings, AI-literacy training, and full safety controls are not reported, constraining reproducibility and interpretation of GenAI-only versus hybrid feedback effects."
}