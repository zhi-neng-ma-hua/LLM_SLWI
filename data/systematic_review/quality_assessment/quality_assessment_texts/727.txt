{
	"study_id": "NR",
	"no": "727",
	"first_author_year": "Liu 2024",
	"title_short": "NR",
	"year": "2024",
	"country_region": "China (elementary school summer camp context)",
	"llm_type_brief": "GPT-4 (OpenAI), model GPT-4-0314",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims and Basic Identification.research_gap_or_novelty, the study clearly states that it will develop and test a CALLA-LLM model using GPT-4 to improve composition scores, SRL writing strategies, and writing motivation compared with traditional CALLA instruction. Methodology.theoretical_foundation further anchors the work in CALLA, SRL theory, and process-oriented writing, indicating an explicit theoretical framework and articulated research gap.",
	"q2_participant_info_score": "2",
	"q2_participant_info_notes": "Participant Information.educational_level, Participant Information.age, Participant Information.sex, Participant Information.learning_context, Participant Information.language_proficiency, and Participant Information.target_language together provide detailed information on grade level, age, gender distribution, EFL context, and approximate proficiency, although Participant Information.mother_tongue and Participant Information.prior_experience_llm are NR.",
	"q3_sampling_and_power_score": "2",
	"q3_sampling_and_power_notes": "Methodology.sampling_method and Methodology.sampling_frame_and_representativeness describe recruitment from several sixth-grade classes in a single school during a summer camp and acknowledge limited generalizability. Methodology.sample_size_and_effect reports N=65 with group sizes and model estimates, and Methodology.power_analysis details an a priori G*Power calculation showing that the achieved sample exceeds the required size.",
	"q4_group_allocation_and_bias_score": "2",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method states that students were randomly assigned to LLM and control groups forming two classes, and Study Quality and Reporting.baseline_equivalence reports non-significant baseline differences on composition scores, SRL strategies, and motivation. Study Quality and Reporting.risk_of_bias_randomization notes randomized allocation, although specific details of sequence generation and allocation concealment are not provided.",
	"q5_longitudinal_design_score": "2",
	"q5_longitudinal_design_notes": "Methodology.research_design and Intervention.duration describe a 5-week intervention with measurements at baseline, immediate posttest, and one-month follow-up. Outcome.assessment_timepoints and Outcome.followup_length_and_type confirm analysis of changes over time, including maintenance of effects at follow-up.",
	"q6_measurement_reliability_validity_score": "2",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_instrument identifies Hyland’s analytic writing rubric and adapted SRL and motivation questionnaires from Bai et al. and Pintrich & De Groot as primary instruments for this EFL population. Methodology.data_collection_validity_reliability and Methodology.scoring_procedure_and_rater_training report strong inter-rater reliability for writing scores (Spearman’s rho=0.88) and Cronbach’s alpha values between 0.79 and 0.88 for all questionnaire subscales.",
	"q7_intervention_procedure_and_duration_score": "2",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration, Intervention.intervention_implementation, Intervention.writing_stage, and Intervention.setting provide a detailed 10-lesson, 5-week CALLA curriculum across planning, drafting, and revising phases for both groups. LLM-related fields (Intervention.llm_model_type, Intervention.llm_model_configuration, Intervention.llm_integration_mode, Intervention.prompting_strategy, Intervention.role_llm, Intervention.role_instructor, Intervention.llm_access_policy, Intervention.llm_safety_guardrails, Intervention.training_support_llm_literacy) specify GPT-4-0314 parameters, a modular phase-aligned prompt design, supervised iPad-based access, and teacher roles, supporting practical replication of CALLA-LLM procedures.",
	"q8_statistical_method_appropriateness_score": "2",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method explains that baseline equivalence was checked with independent-samples t-tests and that linear mixed-effects models with fixed effects of group, time, and group×time and random intercepts for participants were fitted separately for composition scores, SRL strategies, and motivation outcomes. Outcome.primary_outcome_variables, Outcome.independent_variables_and_factors, and Methodology.unit_of_analysis indicate that these methods appropriately match the individual-level group×time design and repeated-measures data structure.",
	"q9_assumption_and_effect_size_score": "2",
	"q9_assumption_and_effect_size_notes": "Study Quality and Reporting.assumption_check_and_data_diagnostics reports Shapiro–Wilk tests, QQ-plot inspection, and Levene’s tests to examine normality and homogeneity before modeling. Outcome.statistical_significance and Outcome.effect_size_summary summarize significant group×time effects and present marginal and conditional R² for the mixed-effects models, providing variance-explained effect size indices even though standardized effect sizes such as Cohen’s d are not reported.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis is NR, so no explicit procedures for handling outliers or conducting sensitivity analyses are described. Nevertheless, Outcome.limitation, Outcome.challenge, Outcome.implication, and Methodology.theoretical_foundation link the findings to CALLA, SRL, and 'Humans in the Loop' perspectives and discuss contextual and motivational limitations, indicating some integration of results with theory and methodological constraints.",
	"total_quality_score": "19",
	"quality_category": "High",
	"key_quality_concerns": "Convenience sampling from a single high-proficiency elementary school and the absence of reported outlier or sensitivity analyses may limit generalizability and full assessment of potential bias.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "Yes",
	"design_note_llm_specific": "GPT-4-0314 was implemented via a custom web application with fixed API parameters and modular CALLA-aligned system prompts during supervised in-class use, but no explicit student LLM literacy curriculum or detailed content-filtering and hallucination-control guardrails were reported, so interpretation and reproducibility of AI support rely heavily on teacher mediation and future model stability."
}