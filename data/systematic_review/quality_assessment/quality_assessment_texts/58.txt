{
	"study_id": "10.32038/ltrq.2025.47.07",
	"no": "58",
	"first_author_year": "Yu 2025",
	"title_short": "NR",
	"year": "2025",
	"country_region": "Northwestern China (EFL high school context)",
	"llm_type_brief": "ChatGPT (version NR)",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims and Basic Identification.research_gap_or_novelty, the study clearly aims to compare ChatGPT and teacher written corrective feedback and examine feedback uptake and revision operations in EFL high school argumentative writing, and Methodology.theoretical_foundation anchors this work in L2 WCF and automated feedback literature with concepts such as learners’ trust and ZPD.",
	"q2_participant_info_score": "2",
	"q2_participant_info_notes": "Participant Information.educational_level, language_proficiency, learning_context, target_language, mother_tongue, sex, age and discipline together describe 60 Grade 11 lower-intermediate Chinese EFL learners (31 females, 29 males, aged 16–17) in an EFL high school English course.",
	"q3_sampling_and_power_score": "1",
	"q3_sampling_and_power_notes": "Methodology.sampling_method reports convenience sampling of one public high school and random splitting of 60 students into two groups, Methodology.sample_size_and_effect details group sizes and baseline equivalence, and Methodology.sampling_frame_and_representativeness notes that the single-school, lower-intermediate cohort limits generalizability, but Methodology.power_analysis is NR and no formal sample size or power justification is provided.",
	"q4_group_allocation_and_bias_score": "2",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method states that students were randomly split into Groups A and B and placed in a 2x2 Latin-square design so each group received both teacher and ChatGPT feedback, Study Quality and Reporting.baseline_equivalence reports no significant differences in prior writing scores between groups, and Study Quality and Reporting.risk_of_bias_randomization notes randomization while acknowledging limited procedural detail.",
	"q5_longitudinal_design_score": "1",
	"q5_longitudinal_design_notes": "Methodology.research_design and Intervention.duration describe a four-week counter-balanced design with two writing tasks, each involving an initial draft and a revised draft after feedback, and Outcome.assessment_timepoints confirms only these immediate pre-feedback and post-feedback drafts per task with no delayed follow-up or longer-term tracking.",
	"q6_measurement_reliability_validity_score": "2",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_instrument outlines the two argumentative tasks, multiple feedback sources and detailed coding schemes for feedback categories and revision operations, Methodology.data_collection_validity_reliability reports standardized prompting, parallel teacher instructions and high inter-coder agreement (around 89–96%) with recoding and discrepancy resolution, and Methodology.scoring_procedure_and_rater_training describes collaborative development and training for coders even though no holistic writing scores or rating scales are reported.",
	"q7_intervention_procedure_and_duration_score": "2",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration and Intervention.intervention_implementation give a week-by-week account of Task A and Task B, draft production, allocation of teacher versus ChatGPT feedback and subsequent revisions, Intervention.writing_stage and Intervention.writing_task_type specify the drafting–feedback–revision cycle, and LLM-related fields (Intervention.llm_model_type, llm_integration_mode, llm_model_configuration, prompting_strategy, role_llm, role_instructor, training_support_llm_literacy, llm_access_policy) clearly describe the standardized prompt, teacher-mediated workflow and student role despite llm_safety_guardrails being NR.",
	"q8_statistical_method_appropriateness_score": "1",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method reports using counts, paired t-tests and Pearson correlations to compare feedback counts and rater distributions in line with Outcome.primary_outcome_variables, Outcome.independent_variables_and_factors and Methodology.unit_of_analysis focusing on feedback points and revision operations, but key behavioral outcomes such as uptake rates and revision operation patterns by feedback source are mainly summarized with percentages without corresponding inferential comparisons.",
	"q9_assumption_and_effect_size_score": "1",
	"q9_assumption_and_effect_size_notes": "Outcome.statistical_significance presents p values from paired t-tests and correlations on feedback counts and rater relationships, while Outcome.effect_size_summary explicitly states that effect sizes such as Cohen’s d or partial eta squared were not reported for uptake or revision comparisons, and Study Quality and Reporting.assumption_check_and_data_diagnostics together with Study Quality and Reporting.data_preprocessing_and_transformation indicate that no formal normality, variance or outlier diagnostics beyond basic coding and aggregation were described.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis is NR and there is no specific discussion of outlier handling or sensitivity analyses, but Outcome.limitation and Outcome.challenge outline constraints related to sample, duration, curriculum alignment, variability among teachers and learners’ first-time use of ChatGPT, and Outcome.implication together with Methodology.theoretical_foundation relate findings to WCF theory, automated feedback and ZPD without deeper methodological robustness checks.",
	"total_quality_score": "15",
	"quality_category": "Moderate",
	"key_quality_concerns": "Convenience sampling from a single high school without power analysis, limited inferential testing and effect size reporting for key feedback uptake and revision outcomes, and no reporting of statistical assumption checks or outlier handling.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "Yes",
	"design_note_llm_specific": "ChatGPT provided standardized written corrective feedback via a single fixed prompt in a teacher-mediated workflow with no direct student access, but the specific ChatGPT model version, interface, safety guardrails and parameter settings were not reported, which constrains reproducibility and interpretation of the AI component."
}