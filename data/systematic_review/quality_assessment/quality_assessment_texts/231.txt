{
	"study_id": "https://dx.doi.org/10.24093/awej/AI.13",
	"no": "231",
	"first_author_year": "Elmotri 2025",
	"title_short": "NR",
	"year": "2025",
	"country_region": "Saudi Arabia (Saudi universities in the Kingdom of Saudi Arabia)",
	"llm_type_brief": "ChatGPT",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims, Basic Identification.research_gap_or_novelty, and Methodology.theoretical_foundation, the study clearly specifies multiple aims around ChatGPT-supported ESP writing, identifies a concrete gap in Saudi ESP contexts, and situates the work in socio-constructivist and AI-ethics discussions.",
	"q2_participant_info_score": "1",
	"q2_participant_info_notes": "Participant Information.educational_level, Participant Information.learning_context, Participant Information.language_proficiency, Participant Information.target_language, and Participant Information.discipline indicate higher-education EFL students in Saudi ESP courses with varied proficiency and academic backgrounds, but Participant Information.mother_tongue, Participant Information.age, and Participant Information.sex are NR and proficiency is not quantified with specific test scores.",
	"q3_sampling_and_power_score": "1",
	"q3_sampling_and_power_notes": "Methodology.sampling_method and Methodology.sampling_frame_and_representativeness describe purposive sampling of 150 EFL students and 40 instructors in Saudi universities and acknowledge context-specific representativeness, and Methodology.sample_size_and_effect reports multiple significant pre–post differences, but Methodology.power_analysis is NR and no a priori sample-size or formal effect-size justification is provided.",
	"q4_group_allocation_and_bias_score": "0",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method and Outcome.independent_variables_and_factors indicate a single-group pre–post design with no separate control group, and Study Quality and Reporting.risk_of_bias_randomization notes that no random assignment was used, so there is no experimental versus control allocation or baseline equivalence assessment to mitigate selection and design bias.",
	"q5_longitudinal_design_score": "1",
	"q5_longitudinal_design_notes": "Methodology.research_design and Outcome.assessment_timepoints describe a pre–post intervention design comparing measures before and after ChatGPT integration, but Intervention.duration is NR and Outcome.followup_length_and_type states that no long-term follow-up was conducted, so only short-term effects are examined.",
	"q6_measurement_reliability_validity_score": "1",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_instrument and Methodology.data_collection_validity_reliability report standardized ESP-related writing tests, expert-validated student and educator surveys with Cronbach’s alpha values of 0.89 and 0.92, and inter-rater reliability checks for qualitative coding, yet Methodology.scoring_procedure_and_rater_training notes that details on writing-score raters, training, and inter-rater reliability for the main writing outcomes are not reported.",
	"q7_intervention_procedure_and_duration_score": "1",
	"q7_intervention_procedure_and_duration_notes": "Intervention.intervention_implementation, Intervention.role_llm, Intervention.role_instructor, Intervention.llm_integration_mode, Intervention.llm_access_policy, and Intervention.writing_task_type describe ChatGPT being used across ESP writing tasks to support grammar, vocabulary, brainstorming, feedback, and curriculum design, but Intervention.duration, Intervention.writing_stage, Intervention.prompting_strategy, and Intervention.llm_model_configuration lack concrete details on time structure, writing stages, prompts, and model settings, limiting full procedural replicability.",
	"q8_statistical_method_appropriateness_score": "2",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method indicates use of paired t-tests for pre–post comparisons of writing and perception scores and descriptive statistics for survey data, which matches the single-group pre–post design described in Methodology.research_design and aligns with Outcome.primary_outcome_variables, Outcome.independent_variables_and_factors, and Methodology.unit_of_analysis focusing on individual students’ scores.",
	"q9_assumption_and_effect_size_score": "1",
	"q9_assumption_and_effect_size_notes": "Outcome.statistical_significance reports extensive pre–post improvements with p<0.001 for multiple writing and perception measures and Study Quality and Reporting.data_preprocessing_and_transformation notes standard descriptive and reliability analyses, but Study Quality and Reporting.assumption_check_and_data_diagnostics states that formal checks of t-test assumptions are not described and Outcome.effect_size_summary confirms that effect-size indices such as Cohen’s d are not reported.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis is NR, indicating no explicit handling of outliers or sensitivity analyses, while Outcome.limitation, Outcome.challenge, Outcome.implication, and Methodology.theoretical_foundation show that findings are interpreted within socio-constructivist and ethical frameworks with discussion of design constraints, technical and ethical challenges, and implications for ESP curriculum and assessment.",
	"total_quality_score": "11",
	"quality_category": "Moderate",
	"key_quality_concerns": "Single-group pre–post design with purposive sampling and no non-ChatGPT control group, together with unreported inter-rater reliability for writing scores and lack of effect-size reporting, limits internal validity and the strength of inferences about ChatGPT’s impact.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "Yes",
	"design_note_llm_specific": "ChatGPT was integrated broadly into ESP writing courses without specifying model version, prompting strategies, usage duration or frequency, or technical safety settings, which constrains reproducibility and precise attribution of observed gains to particular LLM configurations or interaction patterns."
}