{
	"study_id": "https://doi.org/10.17507/jltr.1603.29",
	"no": "391",
	"first_author_year": "Alwasidi 2025",
	"title_short": "NR",
	"year": "2025",
	"country_region": "Saudi Arabia",
	"llm_type_brief": "ChatGPT (OpenAI LLM)",
	"q1_research_aims_clarity_score": "1",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims, Basic Identification.research_gap_or_novelty and Methodology.theoretical_foundation, the study clearly states aims and a specific quantitative gap regarding ChatGPT’s impact on EFL writing, but it does not articulate a clear formal theoretical framework beyond general technology-enhanced and AI-assisted learning literature.",
	"q2_participant_info_score": "2",
	"q2_participant_info_notes": "Participant Information.educational_level, Participant Information.language_proficiency, Participant Information.learning_context, Participant Information.target_language, Participant Information.sex and Participant Information.discipline report first-year female Saudi EFL undergraduates in an English Language and Literature department with IELTS 4.0–5.5 in an EFL Saudi university context, while age and mother tongue are NR.",
	"q3_sampling_and_power_score": "1",
	"q3_sampling_and_power_notes": "Methodology.sampling_method and Methodology.sampling_frame_and_representativeness describe convenience sampling of one intact class of 52 female students from a single department and acknowledge limited generalisability, and Methodology.sample_size_and_effect reports N and outcomes, but Methodology.power_analysis is NR and no formal sample-size or power justification is provided.",
	"q4_group_allocation_and_bias_score": "1",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method and Study Quality and Reporting.risk_of_bias_randomization indicate a single-group pretest–posttest design without randomisation or a control group, and Study Quality and Reporting.baseline_equivalence is NA, so potential selection, maturation and confounding biases are recognised but cannot be addressed within the design.",
	"q5_longitudinal_design_score": "1",
	"q5_longitudinal_design_notes": "Methodology.research_design, Intervention.duration and Outcome.assessment_timepoints show a roughly three-month intervention with two main time points (pretest in week 2 and posttest after nine weeks), allowing short-term pre–post change analysis but no delayed or long-term follow-up as Outcome.followup_length_and_type reports none.",
	"q6_measurement_reliability_validity_score": "2",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_instrument and Methodology.data_collection_validity_reliability describe a pre/post definition paragraph task reviewed by experts, use of a validated RCampus definition paragraph rubric, and double marking of 20% of scripts with 92% agreement, and Methodology.scoring_procedure_and_rater_training outlines the use of a common rubric and independent double marking, providing moderate evidence of reliability and content validity for L2 writing assessment.",
	"q7_intervention_procedure_and_duration_score": "2",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration and Intervention.intervention_implementation give a week-by-week timetable (academic writing introduction, pretest, ChatGPT introduction, nine weeks of ChatGPT-supported paragraph writing, and post-test), while LLM-related fields (Intervention.llm_model_type, Intervention.llm_integration_mode, Intervention.prompting_strategy, Intervention.training_support_llm_literacy, Intervention.role_llm, Intervention.role_instructor, Intervention.llm_access_policy, Intervention.setting, Intervention.writing_stage, Intervention.writing_task_type) provide sufficient detail on how, when and for what purposes ChatGPT was used to allow replication of the instructional routine aside from unspecified model configuration and safety settings.",
	"q8_statistical_method_appropriateness_score": "2",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method reports paired-samples t-tests on pre/post rubric scores and word counts, which aligns with the one-group pretest–posttest design described in Methodology.research_design, the primary outcomes (Outcome.primary_outcome_variables) and the individual-student unit of analysis in Methodology.unit_of_analysis.",
	"q9_assumption_and_effect_size_score": "1",
	"q9_assumption_and_effect_size_notes": "Outcome.statistical_significance and Methodology.sample_size_and_effect provide paired t-values, p-values and descriptive statistics for each criterion, but Outcome.effect_size_summary notes that effect sizes such as Cohen’s d or η² were not reported, and Study Quality and Reporting.assumption_check_and_data_diagnostics and Study Quality and Reporting.data_preprocessing_and_transformation indicate no formal checks of normality, outliers or other assumptions.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis is NR, while Outcome.limitation, Outcome.challenge and Outcome.implication discuss the constraints of a one-group design, small homogeneous sample and risks of overreliance on ChatGPT in relation to technology-enhanced EFL writing (Methodology.theoretical_foundation), indicating some interpretive integration with methodological limitations but no explicit treatment of anomalous data or robustness checks.",
	"total_quality_score": "14",
	"quality_category": "Moderate",
	"key_quality_concerns": "One-group pretest–posttest design without a control group, absence of power analysis, and limited reporting of assumption checks, effect sizes and outlier handling restrict causal inference and generalisability of the observed writing gains.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "Yes",
	"design_note_llm_specific": "ChatGPT was used only as a pre-writing assistant for about 30 minutes before in-class handwritten paragraphs, with minimal AI literacy or prompting guidance and no specification of model version or configuration, which may influence how generalisable and reproducible the LLM-related effects are."
}