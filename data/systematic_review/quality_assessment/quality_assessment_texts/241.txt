{
	"study_id": "NR",
	"no": "241",
	"first_author_year": "Zhang 2025",
	"title_short": "NR",
	"year": "2025",
	"country_region": "Hong Kong SAR, China",
	"llm_type_brief": "GPT-4 chatbot (LogicalHamster)",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims and Basic Identification.research_gap_or_novelty, the study clearly targets engagement with GPT responses and learner prompts for argumentative writing logic and identifies a specific gap, while Methodology.theoretical_foundation outlines multiple learning theories underpinning this focus.",
	"q2_participant_info_score": "2",
	"q2_participant_info_notes": "Participant Information.educational_level, language_proficiency, learning_context, mother_tongue, sex, age, discipline and target_language together describe Chinese upper-intermediate to advanced EFL learners in an EMI Hong Kong university with clear demographic and language background information.",
	"q3_sampling_and_power_score": "2",
	"q3_sampling_and_power_notes": "Methodology.sampling_method and Methodology.sampling_frame_and_representativeness specify a voluntary single-institution sample with noted limits to generalisability, while Methodology.sample_size_and_effect and Methodology.power_analysis justify N=42 using heuristic and GPower considerations and report explained variance from the models.",
	"q4_group_allocation_and_bias_score": "1",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method and Study Quality and Reporting.risk_of_bias_randomization indicate a single volunteer group with no randomisation or control condition, and Study Quality and Reporting.baseline_equivalence notes that between-group equivalence is not applicable, so potential selection bias is inherent but only partially discussed.",
	"q5_longitudinal_design_score": "2",
	"q5_longitudinal_design_notes": "Methodology.research_design, Intervention.duration and Outcome.assessment_timepoints describe a pre-test, immediate post-test and one-week delayed post-test structure for logic knowledge plus pre- and post-revision writing tasks, allowing analysis of short-term change and retention over time.",
	"q6_measurement_reliability_validity_score": "2",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_instrument and Methodology.data_collection_validity_reliability report validated logic tests and a logic-focused essay rubric with high inter-rater reliability (Cohen's kappa values) and satisfactory PLS-SEM measurement indices, while Methodology.scoring_procedure_and_rater_training notes blind scoring and consensus procedures even though detailed rater training is not elaborated.",
	"q7_intervention_procedure_and_duration_score": "2",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration and Intervention.intervention_implementation provide a detailed three-week schedule including writing, testing and a 45–75-minute LogicalHamster session, and LLM-related fields (Intervention.llm_model_type, llm_model_configuration, llm_integration_mode, prompting_strategy, training_support_llm_literacy, role_llm, role_instructor, llm_access_policy, llm_safety_guardrails) clearly specify how GPT-4 was used, by whom and under what constraints.",
	"q8_statistical_method_appropriateness_score": "2",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method explains the use of paired t-tests, PLS-SEM and multiple regression at the individual learner level (Methodology.unit_of_analysis) to relate engagement metrics and prior scores to Outcome.primary_outcome_variables such as logic knowledge and writing logic, which is coherent with the single-group design and continuous outcome measures.",
	"q9_assumption_and_effect_size_score": "2",
	"q9_assumption_and_effect_size_notes": "Outcome.statistical_significance and Outcome.effect_size_summary report key significance tests, R-squared values and effect sizes from PLS-SEM and regression, while Study Quality and Reporting.assumption_check_and_data_diagnostics describes checks of normality, linearity, homoscedasticity and collinearity and Study Quality and Reporting.data_preprocessing_and_transformation notes straightforward processing of eye-tracking and score data.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis is NR, but Outcome.limitation, Outcome.challenge and Outcome.implication, together with Methodology.theoretical_foundation, integrate findings with frameworks such as sociocultural theory, input and cognitive load theories, so theoretical interpretation is present though data issues like outliers and robustness checks are not explicitly addressed.",
	"total_quality_score": "18",
	"quality_category": "High",
	"key_quality_concerns": "Single-group voluntary sample from one EMI university without a control condition or randomisation, and no reporting of outlier treatment or sensitivity analyses.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "No",
	"design_note_llm_specific": "Learners completed a single 45–75-minute session with a GPT-4-powered LogicalHamster chatbot in a lab, and although chatbot functions and persona are described in detail, exact system prompts, parameter settings and any out-of-study ChatGPT use are not fully controlled or reported."
}