{
	"study_id": "NR",
	"no": "274",
	"first_author_year": "Schiller 2025",
	"title_short": "NR",
	"year": "2025",
	"country_region": "Germany (federal state of Schleswig-Holstein)",
	"llm_type_brief": "GPT-3.5 Turbo",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims and Basic Identification.research_gap_or_novelty, the study clearly specifies aims to test LLM-generated feedback effects on revision and transfer writing via behavioral and pausing-based engagement measures and to replicate and extend process-oriented findings from traditional AWE. Methodology.theoretical_foundation outlines feedback and engagement theories underpinning the mediation approach, providing an explicit conceptual framework.",
	"q2_participant_info_score": "2",
	"q2_participant_info_notes": "Participant Information.educational_level, language_proficiency, learning_context, age, sex, discipline and target_language indicate Grade 10 EFL learners in German upper secondary schools (mean age 16.11 years, 57% female) in English classes, although Participant Information.mother_tongue is NR.",
	"q3_sampling_and_power_score": "1",
	"q3_sampling_and_power_notes": "Methodology.sampling_method and Methodology.sampling_frame_and_representativeness describe volunteer upper secondary schools in one German federal state with learners participating during regular class time and random assignment within classes to feedback or control conditions, and note limited generalisability. Methodology.sample_size_and_effect reports a final N = 453 with effect sizes, but Methodology.power_analysis is NR and no explicit sample size rationale is provided.",
	"q4_group_allocation_and_bias_score": "2",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method and Study Quality and Reporting.risk_of_bias_randomization state that learners were randomly assigned within classes via the survey tool to LLM feedback versus no-feedback conditions. Study Quality and Reporting.baseline_equivalence reports no significant differences between groups in initial writing performance or sociodemographic covariates, although some exclusions due to technical problems are acknowledged.",
	"q5_longitudinal_design_score": "2",
	"q5_longitudinal_design_notes": "Methodology.research_design, Intervention.duration and Outcome.assessment_timepoints describe an initial writing task, subsequent revision of the same essay with or without feedback, and a later transfer essay in the same session, with analyses relating condition to both revision and transfer performance while controlling for baseline quality. Outcome.followup_length_and_type confirms that there was no longitudinal follow-up beyond this in-session transfer task.",
	"q6_measurement_reliability_validity_score": "2",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_instrument and Methodology.data_collection_validity_reliability report TOEFL-like writing prompts and an automated scoring model trained on expert-rated essays with a quadratically weighted kappa of 0.76, along with keystroke logging scripted into the platform to capture process data. Methodology.scoring_procedure_and_rater_training notes that existing validated automated scoring replaced new human ratings, and while no separate reliability indices are given for process measures, the main performance measure has documented reliability and L2 applicability.",
	"q7_intervention_procedure_and_duration_score": "2",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration, Intervention.intervention_implementation, Intervention.writing_stage, Intervention.writing_task_type and Intervention.setting describe a single up-to-90-minute classroom session with specified phases for initial writing, revision under feedback or control conditions, and a transfer essay on tablets. LLM-related fields (Intervention.llm_model_type, llm_model_configuration, llm_integration_mode, prompting_strategy, role_llm, role_instructor, llm_access_policy, llm_safety_guardrails) explain how GPT 3.5 Turbo was integrated server-side to provide tabular feedback on content, structure and language, giving sufficient detail for approximate replication.",
	"q8_statistical_method_appropriateness_score": "2",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method reports Wilcoxon and t-tests (with Box-Cox transformations for skewed variables), correlations, and structural equation modeling with bootstrapping to test mediation, which align with the between-group experimental design and continuous outcomes. Outcome.primary_outcome_variables, Outcome.independent_variables_and_factors and Methodology.unit_of_analysis show that condition, automated writing scores, and engagement indicators at the individual learner level are appropriately matched to these analyses.",
	"q9_assumption_and_effect_size_score": "2",
	"q9_assumption_and_effect_size_notes": "Outcome.statistical_significance and Outcome.effect_size_summary provide p-values, Cohenâ€™s d, R2 values, and mediated effect estimates for revision and transfer performance. Study Quality and Reporting.assumption_check_and_data_diagnostics and Study Quality and Reporting.data_preprocessing_and_transformation describe inspection of skewness, application of Box-Cox transformations, normalization of engagement variables, and use of bootstrapping for indirect effects, although more detailed residual diagnostics are not reported.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis mentions exclusions for technical problems and transformation of skewed variables but does not detail explicit outlier detection or sensitivity analyses. Outcome.limitation, Outcome.challenge, Outcome.implication and Methodology.theoretical_foundation nonetheless offer a theoretically framed discussion of measurement limitations, potential LLM inaccuracies, interpretive challenges of process measures, and the mediating role of engagement in feedback effectiveness.",
	"total_quality_score": "18",
	"quality_category": "High",
	"key_quality_concerns": "No formal power analysis or systematic outlier/sensitivity checks were reported, and LLM feedback quality was not independently evaluated, which limits inferences about the robustness and generalisability of the observed engagement-mediated effects.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "Yes",
	"design_note_llm_specific": "Automated feedback was generated by GPT 3.5 Turbo via a single pre-defined prompt and displayed once above the revision editor, with no direct evaluation of feedback accuracy and no monitoring of any external LLM use, which may constrain reproducibility and interpretation of feedback quality effects."
}