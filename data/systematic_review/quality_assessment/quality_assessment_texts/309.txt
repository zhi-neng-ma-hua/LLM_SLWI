{
	"study_id": "10.5430/wjel.v16n2p258",
	"no": "309",
	"first_author_year": "Al Mahmud 2026",
	"title_short": "NR",
	"year": "2026",
	"country_region": "Saudi Arabia (University of Jeddah)",
	"llm_type_brief": "ChatGPT (version NR)",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims and Basic Identification.research_gap_or_novelty, the study clearly formulates three comparative aims about ChatGPT versus human written corrective feedback (WCF) and learner perceptions in a Saudi EFL context, and Methodology.theoretical_foundation situates these aims within WCF and automated WCF/ChatGPT literature.",
	"q2_participant_info_score": "1",
	"q2_participant_info_notes": "Participant Information.educational_level, Participant Information.discipline, Participant Information.learning_context, and Participant Information.target_language indicate Saudi undergraduate EFL learners in an academic writing course, but Participant Information.language_proficiency, Participant Information.age, Participant Information.sex, and Participant Information.mother_tongue are NR, so key language background and demographic details are incomplete.",
	"q3_sampling_and_power_score": "1",
	"q3_sampling_and_power_notes": "Methodology.sampling_method and Methodology.sample_size_and_effect describe a convenience sample of 53 Saudi undergraduates divided into ChatGPT and human feedback groups with reported means, SDs, and effect size, and Methodology.sampling_frame_and_representativeness notes limited generalisability, but Methodology.power_analysis is NR and no explicit sample size or power justification is provided.",
	"q4_group_allocation_and_bias_score": "2",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method and Study Quality and Reporting.risk_of_bias_randomization indicate that participants were divided into experimental and control groups without reported randomization, while Study Quality and Reporting.baseline_equivalence reports an independent-samples t-test showing no significant pretest difference in writing skills scores (t=0.549, p=0.586) and acknowledges potential selection bias.",
	"q5_longitudinal_design_score": "1",
	"q5_longitudinal_design_notes": "Methodology.research_design and Intervention.duration describe an 8-week pretest–posttest intervention with repeated writing and feedback sessions, and Outcome.assessment_timepoints notes pretest and week 9 posttest assessments, but Outcome.followup_length_and_type is NaN and no delayed follow-up or extended longitudinal analysis beyond immediate posttest is reported.",
	"q6_measurement_reliability_validity_score": "1",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_instrument and Methodology.data_collection_validity_reliability describe a consistent grammatical accuracy formula, use of established reference grammars, and multiple PhD-level human evaluators, and note an interrater reliability check on 12 essays, but specific reliability coefficients and detailed rater training or calibration procedures are not reported in Methodology.scoring_procedure_and_rater_training.",
	"q7_intervention_procedure_and_duration_score": "1",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration and Intervention.intervention_implementation specify a 9-week schedule with two 1.5-hour sessions per week, repeated short-essay tasks, and feedback cycles, and LLM-related fields (Intervention.llm_model_type, Intervention.llm_integration_mode, Intervention.prompting_strategy, Intervention.role_llm, Intervention.setting) describe ChatGPT as an interactive AWCF tool, but Intervention.llm_model_configuration, Intervention.llm_safety_guardrails, and Intervention.training_support_llm_literacy lack details on model version, exact prompts, and AI literacy training, limiting full procedural reproducibility.",
	"q8_statistical_method_appropriateness_score": "1",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method reports use of independent-samples t-tests on pretest and posttest writing skills scores and descriptive/error analyses in SPSS, which aligns with Outcome.primary_outcome_variables and Methodology.unit_of_analysis at the essay/learner level, but no within-subject (pre–post) tests or models of time × group effects are reported, so the analysis only partially exploits the pretest–posttest design.",
	"q9_assumption_and_effect_size_score": "1",
	"q9_assumption_and_effect_size_notes": "Outcome.statistical_significance provides t-values, p-values, and pre/post group means and SDs, and Outcome.effect_size_summary reports eta squared (η²=0.68) for the posttest comparison, while Study Quality and Reporting.data_preprocessing_and_transformation explains the grammatical accuracy formula; however, Study Quality and Reporting.assumption_check_and_data_diagnostics notes that explicit checks of normality, homogeneity of variance, or other diagnostics are not described.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis is NR and there is no mention of handling extreme scores or conducting sensitivity analyses, although Outcome.limitation and Outcome.implication discuss sample size, feedback modality differences, reliability scope, and the need for training in AWCF use within the WCF and ChatGPT theoretical framing from Methodology.theoretical_foundation.",
	"total_quality_score": "12",
	"quality_category": "Moderate",
	"key_quality_concerns": "Convenience sampling with non-random group assignment and incomplete reporting of measurement reliability and statistical assumption checks for grammatical accuracy scores.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "Yes",
	"design_note_llm_specific": "Students in the experimental group interacted directly with ChatGPT as an automated written corrective feedback tool, but the specific model version, detailed prompt scripts, AI literacy training, and technical guardrails were not reported, limiting reproducibility and making it difficult to disentangle effects of ChatGPT’s immediacy and dialogic feedback from other design factors."
}