{
	"study_id": "NR",
	"no": "675",
	"first_author_year": "Shahsavar 2024",
	"title_short": "NR",
	"year": "2024",
	"country_region": "Shiraz, Iran",
	"llm_type_brief": "ChatGPT (OpenAI; version NR)",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims, Basic Identification.research_gap_or_novelty, and Methodology.theoretical_foundation, the study clearly investigates ChatGPT-assisted versus conventional instruction on overall and component academic writing scores in an EFL medical context, explicitly positioning a longitudinal experimental design within an AI-assisted writing framework.",
	"q2_participant_info_score": "1",
	"q2_participant_info_notes": "Participant Information.educational_level, discipline, learning_context, target_language, and language_proficiency indicate junior medical students in an Iranian EFL academic writing course with intermediate writing proficiency, but Participant Information.mother_tongue, age, and sex are NR, so key demographic and L1 background variables are incomplete.",
	"q3_sampling_and_power_score": "1",
	"q3_sampling_and_power_notes": "Methodology.sampling_method and Methodology.sampling_frame_and_representativeness describe convenience sampling of medical students in a compulsory writing course and random allocation to experimental and control groups, and Methodology.sample_size_and_effect reports N and detailed test results, but Methodology.power_analysis is NR and there is no explicit sample size justification beyond feasibility and accessibility.",
	"q4_group_allocation_and_bias_score": "2",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method and Study Quality and Reporting.risk_of_bias_randomization state that 83 students were randomly separated into experimental and control classes, while Study Quality and Reporting.baseline_equivalence reports non-significant pre-test differences across overall and component scores, supporting baseline equivalence even though randomization procedures and attrition-related bias are only briefly noted.",
	"q5_longitudinal_design_score": "1",
	"q5_longitudinal_design_notes": "Methodology.research_design, Intervention.duration, and Outcome.assessment_timepoints describe a 17-week course with pre-test at the beginning and post-test at the end for both groups, but Outcome.followup_length_and_type is NaN and no delayed or long-term follow-up assessments are reported, so only short-term change is captured.",
	"q6_measurement_reliability_validity_score": "2",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_instrument specifies pre- and post-test essays scored with Jacobs et al. (1981) analytic rubric, Methodology.data_collection_validity_reliability notes the rubric’s established validity and reports inter-rater reliability of 87% after calibration, and Methodology.scoring_procedure_and_rater_training details joint scoring, discussion of discrepancies, and independent double-rating, providing clear evidence of measurement reliability and construct relevance for L2 academic writing.",
	"q7_intervention_procedure_and_duration_score": "2",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration and Intervention.intervention_implementation describe a 17-week process-oriented writing course with weekly drafting and feedback in both groups, while Intervention.llm_model_type, Intervention.llm_integration_mode, Intervention.prompting_strategy, Intervention.training_support_llm_literacy, Intervention.role_llm, Intervention.role_instructor, Intervention.llm_access_policy, Intervention.writing_stage, and Intervention.setting together specify ChatGPT access, the standardized proofreading-and-explanation prompt, student and instructor roles, and exam conditions in enough procedural detail to broadly reproduce the intervention despite the model version being NR.",
	"q8_statistical_method_appropriateness_score": "2",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method reports Kolmogorov–Smirnov normality tests followed by independent samples t-tests on post-test scores, paired t-tests on pre–post scores within groups, and ANCOVA on component scores controlling for pre-test, which aligns with Outcome.primary_outcome_variables, Outcome.independent_variables_and_factors, and Methodology.unit_of_analysis that treat individual student writing scores and group-by-time structure in a coherent quantitative framework.",
	"q9_assumption_and_effect_size_score": "2",
	"q9_assumption_and_effect_size_notes": "Study Quality and Reporting.assumption_check_and_data_diagnostics notes that Kolmogorov–Smirnov tests supported normality for using parametric tests, Outcome.statistical_significance reports detailed t, F, and p-values for overall and component scores, and Outcome.effect_size_summary states eta squared values and interprets them as large or medium, while Study Quality and Reporting.data_preprocessing_and_transformation indicates that rubric scores were directly analyzed without additional transformations, collectively providing both significance tests and effect size information with at least partial assumption checking.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis is NR so outliers and robustness checks are not described, but Outcome.limitation, Outcome.challenge, and Outcome.implication discuss sampling constraints, attrition, limited improvement in language use, risks of plagiarism and over-reliance on AI, and the complementary role of ChatGPT within Elhossiny et al.’s framework, indicating some integration of results with theoretical and methodological considerations but without explicit treatment of anomalous data patterns.",
	"total_quality_score": "16",
	"quality_category": "High",
	"key_quality_concerns": "Convenience sampling from a single medical university with substantial attrition and limited analysis of missing data or outliers may introduce bias and constrain generalizability despite randomized group assignment and baseline equivalence tests.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "Yes",
	"design_note_llm_specific": "ChatGPT was used only for at-home revision with a fixed proofreading-and-explanation prompt while pre- and post-test essays were written without AI, but the underlying ChatGPT model version and configuration are not reported, which limits exact reproducibility of the AI component."
}