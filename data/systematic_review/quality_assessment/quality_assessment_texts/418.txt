{
	"study_id": "NR",
	"no": "418",
	"first_author_year": "Jaashan 2025",
	"title_short": "NR",
	"year": "2025",
	"country_region": "Saudi Arabia (King Khalid University, Abha)",
	"llm_type_brief": "ChatGPT (OpenAI LLM)",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims and Basic Identification.research_gap_or_novelty, the study clearly states its aims (impact of LLM-ChatGPT on spelling and attitudes) and articulates a specific gap on AI-based spelling training, with Methodology.theoretical_foundation referencing AI language models and UTAUT as an underpinning framework.",
	"q2_participant_info_score": "1",
	"q2_participant_info_notes": "Participant Information.educational_level, Participant Information.language_proficiency, Participant Information.learning_context, Participant Information.discipline and Participant Information.target_language are reported, but key demographic and linguistic background variables such as Participant Information.age, Participant Information.sex and Participant Information.mother_tongue are NR.",
	"q3_sampling_and_power_score": "1",
	"q3_sampling_and_power_notes": "Methodology.sampling_method and Methodology.sampling_frame_and_representativeness describe a convenience sample of 60 Writing II students from one Saudi university and acknowledge limited generalisability, and Methodology.sample_size_and_effect reports group sizes and means, but Methodology.power_analysis is NR and no formal sample size justification is provided.",
	"q4_group_allocation_and_bias_score": "2",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method reports random assignment of 60 volunteers to experimental (N=28) and control (N=32) groups, while Study Quality and Reporting.baseline_equivalence and Methodology.sample_size_and_effect indicate similar pre-test means and non-significant Levene’s test results, and Study Quality and Reporting.risk_of_bias_randomization discusses randomisation with remaining context-related bias.",
	"q5_longitudinal_design_score": "1",
	"q5_longitudinal_design_notes": "Methodology.research_design and Outcome.assessment_timepoints describe a pre-test and immediate post-test after three instructional sessions (short-term pre–post design) with no delayed follow-up, and Outcome.followup_length_and_type confirms the absence of longer-term assessments.",
	"q6_measurement_reliability_validity_score": "0",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_instrument specifies a researcher-designed spelling test and a 20-item UTAUT-based questionnaire, but Methodology.data_collection_validity_reliability explicitly notes that no reliability indices or validity evidence for these instruments were reported, and Methodology.scoring_procedure_and_rater_training indicates single-rater manual scoring without rater reliability information.",
	"q7_intervention_procedure_and_duration_score": "2",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration and Intervention.intervention_implementation provide a stepwise description of three sessions (pre-test, nine hours of instruction, post-test) for both experimental and control groups, and LLM-related fields (Intervention.llm_model_type, Intervention.llm_model_configuration, Intervention.llm_integration_mode, Intervention.prompting_strategy, Intervention.training_support_llm_literacy, Intervention.role_llm, Intervention.role_instructor, Intervention.llm_access_policy) specify how ChatGPT was customised, accessed and used during dictated spelling practice, supporting basic reproducibility of the instructional design.",
	"q8_statistical_method_appropriateness_score": "2",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method reports use of Levene’s test to check pre-test homogeneity and independent samples t-tests to compare post-test spelling scores between experimental and control groups, which aligns with the between-subject pre-test–post-test design described in Methodology.research_design and the primary outcome variables in Outcome.primary_outcome_variables, with students as the unit defined in Methodology.unit_of_analysis.",
	"q9_assumption_and_effect_size_score": "1",
	"q9_assumption_and_effect_size_notes": "Study Quality and Reporting.assumption_check_and_data_diagnostics notes that assumption checks were limited to Levene’s test for homogeneity on pre-test scores, while Outcome.effect_size_summary states that no effect sizes (e.g. Cohen’s d) were reported, and Outcome.statistical_significance only presents significance conclusions without detailed diagnostics or effect size metrics.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis is NR, indicating no described handling of outliers or robustness checks, but Outcome.limitation, Outcome.challenge and Outcome.implication discuss contextual and design limitations, potential misuse of ChatGPT and pedagogical implications within the AI and UTAUT framing noted in Methodology.theoretical_foundation.",
	"total_quality_score": "13",
	"quality_category": "Moderate",
	"key_quality_concerns": "Single-institution convenience sample with short three-session intervention and no reliability or validity evidence for the spelling test or UTAUT questionnaire, combined with single-rater scoring and limited statistical diagnostics.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "Yes",
	"design_note_llm_specific": "ChatGPT was customised via free web accounts to drill a fixed list of 50 target words with a trial-and-error feedback loop, but the specific LLM version and any controls on use beyond the configured spelling tasks were not reported."
}