{
	"study_id": "10.70730/PGCQ9242",
	"no": "73",
	"first_author_year": "Khampusaen 2025",
	"title_short": "NR",
	"year": "2025",
	"country_region": "Thailand (Khon Kaen University)",
	"llm_type_brief": "ChatGPT (version not specified)",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims, Basic Identification.research_gap_or_novelty, and Methodology.theoretical_foundation, the study clearly specifies pre–post objectives on argumentative writing quality, perceptions, and usage patterns, identifies longitudinal AI-integration and AI-specific rubric gaps, and situates the work within writing development and AI integration frameworks.",
	"q2_participant_info_score": "1",
	"q2_participant_info_notes": "Participant Information.educational_level, learning_context, target_language, age, sex, and discipline describe third-year EFL English majors aged 20–21 in a university context, but Participant Information.language_proficiency and Participant Information.mother_tongue are NR or only implied rather than explicitly reported.",
	"q3_sampling_and_power_score": "1",
	"q3_sampling_and_power_notes": "Methodology.sampling_method and Methodology.sampling_frame_and_representativeness describe purposive selection of one intact class from four sections at a Thai university and note limited representativeness, and Methodology.sample_size_and_effect reports N=30 and substantial gains, but Methodology.power_analysis is NR and no formal sample size justification is provided.",
	"q4_group_allocation_and_bias_score": "1",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method indicates a single intact class with no random assignment or comparison groups, and Study Quality and Reporting.risk_of_bias_randomization acknowledges high selection bias and absence of a control group, while Study Quality and Reporting.baseline_equivalence is noted as not applicable for this one-group design.",
	"q5_longitudinal_design_score": "1",
	"q5_longitudinal_design_notes": "Methodology.research_design and Intervention.duration describe a 16-week single-group pre–post design using first drafts as pre-test and fifth drafts as post-test, and Outcome.assessment_timepoints and Outcome.followup_length_and_type confirm two within-course timepoints without any longer-term follow-up beyond the semester.",
	"q6_measurement_reliability_validity_score": "1",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_instrument and Methodology.data_collection_validity_reliability report expert review, IOC=0.87, and Cronbach’s alpha=0.89 for the 17-item questionnaire, but Methodology.scoring_procedure_and_rater_training notes use of an AIAS-based rubric by three raters without reporting detailed rater training procedures or inter-rater reliability statistics for the rubric scores.",
	"q7_intervention_procedure_and_duration_score": "1",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration, Intervention.intervention_implementation, Intervention.writing_genre, Intervention.writing_stage, Intervention.writing_task_type, Intervention.setting, Intervention.role_instructor, and Intervention.role_llm outline a 16-week AI-assisted argumentative writing course where students use ChatGPT across planning, drafting, and revising, but Intervention.llm_model_configuration, Intervention.prompting_strategy, Intervention.llm_access_policy, and Intervention.llm_safety_guardrails are NR, limiting detailed replicability of the LLM procedures.",
	"q8_statistical_method_appropriateness_score": "2",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method and Methodology.unit_of_analysis describe ANOVA for pre–post comparisons of rubric scores at the individual-student/essay level and correlations between ChatGPT usage or perceived usefulness and writing outcomes, which aligns with the single-group pre–post design and the continuous Outcome.primary_outcome_variables and Outcome.independent_variables_and_factors.",
	"q9_assumption_and_effect_size_score": "1",
	"q9_assumption_and_effect_size_notes": "Outcome.statistical_significance and Outcome.effect_size_summary report p-values, percentage improvements, score gains, and correlation coefficients, but no standardized effect sizes (e.g., Cohen’s d or partial eta squared) for the main pre–post effects, and Study Quality and Reporting.assumption_check_and_data_diagnostics and Study Quality and Reporting.data_preprocessing_and_transformation do not describe checks of ANOVA assumptions or outlier handling.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis and Outcome.limitation are NR, while Outcome.challenge and Outcome.implication, together with Methodology.theoretical_foundation, discuss AI-related risks, academic integrity, and pedagogical implications, but without explicit treatment of outliers, sensitivity analyses, or a detailed methodological limitations section.",
	"total_quality_score": "12",
	"quality_category": "Moderate",
	"key_quality_concerns": "Single-group pre–post design with purposive intact-class sampling and no control group, and rubric-based writing outcomes without reported inter-rater reliability or documented checks for statistical assumptions and outliers.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "Yes",
	"design_note_llm_specific": "Students directly used ChatGPT across planning, drafting, and revising during a 16-week EFL writing course, but the study does not report the ChatGPT model version, concrete prompt examples, access policy, or safety guardrails, which constrains reproducibility and interpretation of the LLM integration."
}