{
	"study_id": "NR",
	"no": "576",
	"first_author_year": "Sapan 2024",
	"title_short": "NR",
	"year": "2024",
	"country_region": "Türkiye (Anatolian high school in Bahcelievler, Istanbul)",
	"llm_type_brief": "ChatGPT (version NR)",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims, Basic Identification.research_gap_or_novelty, and Methodology.theoretical_foundation, the study clearly states its aims (effects of ChatGPT-integrated teaching on writing and vocabulary and student perceptions), identifies a concrete empirical gap in ChatGPT-based EFL instruction, and situates the work within a pragmatic mixed-methods worldview and AI-in-ELT literature.",
	"q2_participant_info_score": "2",
	"q2_participant_info_notes": "Participant Information.educational_level, Participant Information.age, Participant Information.discipline, Participant Information.learning_context, Participant Information.target_language, Participant Information.mother_tongue, Participant Information.sex, and Participant Information.language_proficiency together provide clear information about 10th grade Turkish EFL learners, including schooling level, L1, L2 context, and basic demographics, although standardized proficiency scores are not reported.",
	"q3_sampling_and_power_score": "1",
	"q3_sampling_and_power_notes": "Methodology.sampling_method and Methodology.sampling_frame_and_representativeness describe cluster random sampling of two intact 10th grade classes (EG and CG) from one Anatolian high school with comments on limited generalisability, and Methodology.sample_size_and_effect reports N=33 per group and main test statistics, but Methodology.power_analysis is NR and there is no explicit sample size justification or power discussion.",
	"q4_group_allocation_and_bias_score": "2",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method and Study Quality and Reporting.risk_of_bias_randomization indicate cluster random assignment of intact classes to experimental and control conditions without individual-level randomisation or allocation concealment, while Study Quality and Reporting.baseline_equivalence reports non-significant Mann–Whitney U tests on pre-writing and pre-vocabulary scores, suggesting baseline similarity despite quasi-experimental constraints.",
	"q5_longitudinal_design_score": "1",
	"q5_longitudinal_design_notes": "Methodology.research_design, Intervention.duration, and Outcome.assessment_timepoints describe a pre–post design with two pre-achievement exams averaged into a single pre-score and one post-achievement exam over a 5-week period, but Outcome.followup_length_and_type is not reported and there is no delayed follow-up to assess longer-term effects.",
	"q6_measurement_reliability_validity_score": "1",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_instrument and Methodology.data_collection_validity_reliability state that achievement exams and the paragraph assessment scale were reviewed and agreed upon by the researcher, two English teachers, and an ELT academic to establish content validity, and interviews used an adapted published protocol, yet Methodology.scoring_procedure_and_rater_training does not report rater training details or inter-rater reliability coefficients for writing scores.",
	"q7_intervention_procedure_and_duration_score": "2",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration and Intervention.intervention_implementation give a clear three-phase timeline with two pre-tests in Week 1, six 40-minute ChatGPT-integrated or traditional lessons over three weeks, and a post-test and interviews in Week 5, while Intervention.writing_genre, Intervention.writing_stage, Intervention.writing_task_type, Intervention.setting, Intervention.llm_model_type, Intervention.llm_integration_mode, Intervention.prompting_strategy, Intervention.training_support_llm_literacy, Intervention.role_instructor, Intervention.role_llm, and Intervention.llm_access_policy together describe LLM use, prompting training, classroom roles, and tasks in sufficient detail for approximate replication despite Intervention.llm_model_configuration and Intervention.llm_safety_guardrails being NR.",
	"q8_statistical_method_appropriateness_score": "2",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method reports use of Wilcoxon Signed Rank tests for within-group pre–post comparisons and Mann–Whitney U tests for between-group comparisons after skewness and kurtosis indicated non-normality, which matches the two-group pre–post structure of Outcome.primary_outcome_variables and Outcome.independent_variables_and_factors at the individual student level as specified in Methodology.unit_of_analysis.",
	"q9_assumption_and_effect_size_score": "1",
	"q9_assumption_and_effect_size_notes": "Study Quality and Reporting.assumption_check_and_data_diagnostics notes that skewness and kurtosis were examined and led to the choice of non-parametric tests, and Study Quality and Reporting.data_preprocessing_and_transformation reports averaging the two pre-achievement scores without further transformation, while Outcome.statistical_significance provides p-values and test statistics but Outcome.effect_size_summary indicates that effect sizes such as Cohen’s d were not reported.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis is NR, so no explicit handling of outliers or sensitivity checks is described, but Outcome.limitation, Outcome.challenge, and Outcome.implication, together with Methodology.theoretical_foundation, discuss short duration, single-site intact-class design, unmeasured learner variables, and the need to position ChatGPT as an assistant rather than replacement, integrating findings with technology-enhanced language learning and AI-in-ELT considerations at a moderate level of theoretical depth.",
	"total_quality_score": "15",
	"quality_category": "Moderate",
	"key_quality_concerns": "Short, small-sample cluster quasi-experiment without delayed follow-up, limited reliability evidence for writing scores, and no reported effect sizes to quantify the impact of ChatGPT-integrated instruction relative to traditional teaching.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "Yes",
	"design_note_llm_specific": "ChatGPT was used as an in-class generative assistant for vocabulary and paragraph-writing tasks with prior prompt training for students, but the specific ChatGPT model version, configuration, safety guardrails, and any control over out-of-class LLM use were not reported, complicating precise replication and interpretation of the null quantitative advantage of the ChatGPT-integrated condition."
}