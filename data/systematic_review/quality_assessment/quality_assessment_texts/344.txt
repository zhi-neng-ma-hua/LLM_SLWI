{
	"study_id": "NR",
	"no": "344",
	"first_author_year": "Yang 2025",
	"title_short": "NR",
	"year": "2025",
	"country_region": "China (Chinese public university)",
	"llm_type_brief": "ChatGPT",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims, Basic Identification.research_gap_or_novelty, and Methodology.theoretical_foundation, the study clearly states its aims (comparing ChatGPT vs teacher feedback on revision productivity, revision types, and self-efficacy), articulates a specific gap in AI-assisted writing research, and is grounded in a multidimensional feedback engagement framework informed by sociocognitive and sociocultural theories.",
	"q2_participant_info_score": "1",
	"q2_participant_info_notes": "Participant Information.educational_level, Participant Information.language_proficiency, Participant Information.learning_context, Participant Information.discipline, and Participant Information.target_language are reported in detail, but key demographic variables such as Participant Information.age, Participant Information.sex, and Participant Information.mother_tongue are marked as NR, so core background is partially but not fully documented.",
	"q3_sampling_and_power_score": "1",
	"q3_sampling_and_power_notes": "Methodology.sampling_method, Methodology.sample_size_and_effect, and Methodology.sampling_frame_and_representativeness describe convenience sampling of two intact classes (N=82), group sizes, baseline comparability, and limited representativeness, but Methodology.power_analysis is NR and no explicit sample size justification is provided.",
	"q4_group_allocation_and_bias_score": "2",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method specifies non-random assignment of two intact classes to ChatGPT-supported vs teacher-feedback conditions, while Study Quality and Reporting.risk_of_bias_randomization and Study Quality and Reporting.baseline_equivalence explicitly discuss selection bias risk and report baseline equivalence in language error load and feedback coverage.",
	"q5_longitudinal_design_score": "2",
	"q5_longitudinal_design_notes": "Methodology.research_design, Intervention.duration, Outcome.assessment_timepoints, and Outcome.followup_length_and_type describe an 11-week pretest–intervention–posttest design with three successive draft–feedback–revision tasks and self-efficacy measured at pre- and posttest, capturing change over multiple timepoints within a course, although no longer-term follow-up is included.",
	"q6_measurement_reliability_validity_score": "2",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_instrument and Methodology.data_collection_validity_reliability report detailed psychometric evidence for the self-efficacy questionnaire (Cronbach’s α=0.946–0.963, good CFA indices, discriminant and criterion validity), and Methodology.scoring_procedure_and_rater_training notes four expert raters with high inter-rater reliability (Cohen’s κ≈0.87 and 0.81) for error and revision coding, though rater training procedures are not elaborated.",
	"q7_intervention_procedure_and_duration_score": "2",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration and Intervention.intervention_implementation outline an 11-week timeline with specific weeks for pretest, three draft–feedback–revision cycles, and posttest; Intervention.writing_stage, Intervention.writing_task_type, and Intervention.setting detail in-class argumentative writing and revision; LLM-related fields (Intervention.llm_model_type, Intervention.llm_integration_mode, Intervention.llm_model_configuration, Intervention.prompting_strategy, Intervention.training_support_llm_literacy, Intervention.llm_access_policy, Intervention.role_llm, Intervention.role_instructor, Intervention.llm_safety_guardrails) describe the standardized ChatGPT prompt, supervised revision-only use, and instructor roles sufficiently to support approximate replication despite unspecified model version.",
	"q8_statistical_method_appropriateness_score": "2",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method describes use of Mann–Whitney U tests for non-normal revision count data and mixed-design ANOVAs (time × group) plus t-tests for self-efficacy scores, which aligns with Outcome.primary_outcome_variables (revision counts/types and self-efficacy subscales), Outcome.independent_variables_and_factors (feedback condition and time), and Methodology.unit_of_analysis (student-level revisions and self-efficacy), indicating good correspondence between design, variables, and analytic methods.",
	"q9_assumption_and_effect_size_score": "1",
	"q9_assumption_and_effect_size_notes": "Study Quality and Reporting.assumption_check_and_data_diagnostics notes that non-normal revision data motivated non-parametric tests and that self-efficacy variables met normality assumptions for ANOVA, and Outcome.statistical_significance with Outcome.effect_size_summary report p-values and multiple effect size indices (Cohen’s d, partial η², r), but there is no detailed discussion of other assumptions (for example homogeneity of variance, residual diagnostics) or additional data diagnostics.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis is NR and does not describe any outlier handling or sensitivity analyses, while Outcome.limitation, Outcome.challenge, Outcome.implication, and Methodology.theoretical_foundation provide a theoretically informed discussion of design limitations, contextual constraints, and how findings relate to feedback engagement and mediated learning frameworks without addressing anomalous data patterns explicitly.",
	"total_quality_score": "16",
	"quality_category": "High",
	"key_quality_concerns": "Non-random assignment of intact classes with limited demographic reporting and no explicit outlier or sensitivity analyses may introduce selection bias and constrain the generalizability and robustness of the findings.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "Yes",
	"design_note_llm_specific": "ChatGPT was used only as a supervised, revision-stage feedback tool with a standardized prompt and unspecified model version or configuration, and interactions were documented via screenshots but not logged systematically, which may limit precise reproducibility and detailed process-level interpretation of the AI component."
}