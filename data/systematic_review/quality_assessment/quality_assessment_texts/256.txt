{
	"study_id": "https://doi.org/10.1016/j.sftr.2025.100809",
	"no": "256",
	"first_author_year": "Yasmin 2025",
	"title_short": "NR",
	"year": "2025",
	"country_region": "Pakistan (urban district of Punjab, Pakistan)",
	"llm_type_brief": "ChatGPT (GPT-3.5)",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims, Basic Identification.research_gap_or_novelty, and Methodology.theoretical_foundation, the study clearly specifies aims regarding ChatGPT’s effects on SSC students’ argumentative writing and error types, identifies a contextual and theoretical gap in Pakistani secondary EFL settings, and anchors the work in sociocultural/constructivist theory plus Toulmin’s and Ellis’s analytic frameworks.",
	"q2_participant_info_score": "1",
	"q2_participant_info_notes": "Participant Information.educational_level, Participant Information.learning_context, Participant Information.discipline, Participant Information.sex, and Participant Information.target_language indicate SSC-level EFL students in Pakistani public-sector schools with a gender-balanced sample, but Participant Information.language_proficiency, Participant Information.age, and Participant Information.mother_tongue are NR, so key language background variables are incomplete.",
	"q3_sampling_and_power_score": "1",
	"q3_sampling_and_power_notes": "Methodology.sampling_method and Methodology.sampling_frame_and_representativeness describe purposive sampling of 30 SSC students from two urban public-sector schools and note limited generalizability, while Methodology.sample_size_and_effect reports detailed pre–post means, SDs, t-statistic, CI, and Cohen’s d; however, Methodology.power_analysis is NR and no a priori sample size rationale beyond feasibility is given.",
	"q4_group_allocation_and_bias_score": "1",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method and Study Quality and Reporting.risk_of_bias_randomization specify a one-group pre-test/post-test quasi-experimental design without randomization or a separate control group, and Outcome.limitation acknowledges threats to internal validity due to this structure, but no additional strategies (e.g., matched comparison group or statistical controls) are reported to address potential bias.",
	"q5_longitudinal_design_score": "1",
	"q5_longitudinal_design_notes": "Methodology.research_design, Intervention.duration, and Outcome.assessment_timepoints describe a within-subject pre-test and post-test separated by approximately three months of ChatGPT use, but Outcome.followup_length_and_type confirms that no delayed follow-up was conducted and time-related effects are limited to this short-term comparison.",
	"q6_measurement_reliability_validity_score": "1",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_instrument and Methodology.data_collection_validity_reliability indicate use of established analytic frameworks (Toulmin’s model and Ellis’s error analysis) and predefined performance categories, but Methodology.scoring_procedure_and_rater_training notes that the number of raters, rater training, and inter-rater reliability statistics are not reported, and no explicit validity evidence for the specific pre/post tasks is provided.",
	"q7_intervention_procedure_and_duration_score": "2",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration and Intervention.intervention_implementation outline an initial pre-test session, a 45-minute lecture on using ChatGPT, and roughly three months of ChatGPT-supported argumentative writing practice; Intervention.writing_stage, Intervention.writing_task_type, Intervention.setting, Intervention.llm_model_type, Intervention.llm_integration_mode, Intervention.prompting_strategy, Intervention.training_support_llm_literacy, Intervention.role_instructor, and Intervention.role_llm together provide concrete information on tasks, prompts, roles, and context, although Intervention.llm_model_configuration and Intervention.llm_safety_guardrails remain only partially specified.",
	"q8_statistical_method_appropriateness_score": "2",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method reports descriptive analyses of Toulmin components and error types plus a paired-samples t-test with confidence intervals and Cohen’s d for total error counts, which matches the one-group pre/post design in Methodology.research_design, the outcome structure in Outcome.primary_outcome_variables, and the individual-level focus in Methodology.unit_of_analysis.",
	"q9_assumption_and_effect_size_score": "1",
	"q9_assumption_and_effect_size_notes": "Outcome.statistical_significance and Methodology.sample_size_and_effect provide t-statistics, p-values, confidence intervals, and a large Cohen’s d for total error reduction, and Study Quality and Reporting.data_preprocessing_and_transformation describes basic scoring and aggregation; however, Study Quality and Reporting.assumption_check_and_data_diagnostics indicates that formal checks of t-test assumptions (e.g., normality of difference scores, outliers) were not reported.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis is NR and there is no mention of robustness checks, while Outcome.limitation, Outcome.challenge, Outcome.implication, and Methodology.theoretical_foundation show that the authors discuss design and sampling limitations, contextual constraints, and the need for hybrid AI–teacher models within a sociocultural and constructivist framework, integrating findings with theory but not with explicit outlier or sensitivity analyses.",
	"total_quality_score": "13",
	"quality_category": "Moderate",
	"key_quality_concerns": "One-group pre–post quasi-experimental design with small purposive sample and no control or randomization, combined with unreported inter-rater reliability, assumption checks, and outlier handling, limits internal validity and the strength of causal claims about ChatGPT’s impact on argumentative writing.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "Yes",
	"design_note_llm_specific": "Students used ChatGPT (GPT-3.5) over approximately three months with only a brief 45-minute orientation and task-focused example prompts, while the specific model settings, access mode, safety guardrails, and detailed usage tracking were not reported, constraining reproducibility and fine-grained interpretation of the LLM-mediated intervention."
}