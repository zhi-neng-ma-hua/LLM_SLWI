{
	"study_id": "https://doi.org/10.24310/ijtei.111.2025.20896",
	"no": "104",
	"first_author_year": "Esfandiari 2025",
	"title_short": "NR",
	"year": "2025",
	"country_region": "Ardabil, Iran",
	"llm_type_brief": "ChatGPT & Microsoft Copilot",
	"q1_research_aims_clarity_score": "2",
	"q1_research_aims_clarity_notes": "Based on Basic Identification.research_aims, Basic Identification.research_gap_or_novelty and Methodology.theoretical_foundation, the study clearly specifies comparative effects of ChatGPT versus Microsoft Copilot on IMMs in argumentative writing and learner attitudes, grounded in feedback theory and Hyland’s interactional metadiscourse model.",
	"q2_participant_info_score": "2",
	"q2_participant_info_notes": "Participant Information.educational_level, language_proficiency, learning_context, mother_tongue, target_language, age, sex and discipline describe advanced adult EFL learners (25–28 years, L1 Turkish, advanced English at an academic center in Ardabil, both males and females), providing detailed educational, linguistic and demographic background.",
	"q3_sampling_and_power_score": "1",
	"q3_sampling_and_power_notes": "Methodology.sampling_method and Methodology.sampling_frame_and_representativeness show convenience sampling from one center followed by random assignment of 90 advanced learners into three groups of 30, and Methodology.sample_size_and_effect reports N and a large partial η², but Methodology.power_analysis is NR and there is only brief comment on limited representativeness without an explicit sample size or power rationale.",
	"q4_group_allocation_and_bias_score": "1",
	"q4_group_allocation_and_bias_notes": "Methodology.group_assignment_method and Study Quality and Reporting.risk_of_bias_randomization indicate individual-level random assignment to ChatGPT, Microsoft Copilot and control groups after MTELP screening, but Study Quality and Reporting.baseline_equivalence notes only that pretest IMMs scores were used as a covariate in ANCOVA rather than reporting detailed baseline group comparisons, and allocation concealment procedures are not described.",
	"q5_longitudinal_design_score": "1",
	"q5_longitudinal_design_notes": "Methodology.research_design and Intervention.duration describe a three-week pretest–posttest design, and Outcome.assessment_timepoints confirms one pre-intervention metadiscourse pretest and one posttest after the nine-session intervention with no delayed follow-up, so only short-term change is examined.",
	"q6_measurement_reliability_validity_score": "2",
	"q6_measurement_reliability_validity_notes": "Methodology.data_collection_instrument and Methodology.data_collection_validity_reliability report MTELP reliability (KR-21 ≈ .81), inter-rater reliability for IMMs scoring (.77 pretest, .81 posttest), expert-validated interview questions, and high intercoder reliability for thematic analysis (α ≈ .91), while Methodology.scoring_procedure_and_rater_training notes double rating of IMMs performance even though detailed rubric descriptors are not fully specified.",
	"q7_intervention_procedure_and_duration_score": "2",
	"q7_intervention_procedure_and_duration_notes": "Intervention.duration and Intervention.intervention_implementation provide a clear nine-session, three-week timeline (training, six IMMs-focused sessions with 10 prompts each, and posttest) for all three groups, and LLM-related fields (Intervention.llm_model_type, llm_model_configuration, llm_integration_mode, prompting_strategy, training_support_llm_literacy, role_llm, role_instructor, llm_access_policy, setting and writing_stage) describe how ChatGPT and Microsoft Copilot were accessed on shared PCs, how IMMs prompts were used, and what roles instructor and tools played, allowing basic replication despite missing low-level model configuration details.",
	"q8_statistical_method_appropriateness_score": "2",
	"q8_statistical_method_appropriateness_notes": "Methodology.data_analysis_method reports using ANCOVA with pretest IMMs scores as covariate to compare posttest IMMs realization across three instructional conditions, with Tukey HSD for pairwise differences, which aligns with Outcome.independent_variables_and_factors, Outcome.primary_outcome_variables and Methodology.unit_of_analysis that define individual learners’ IMMs scores in a three-arm randomized pretest–posttest design.",
	"q9_assumption_and_effect_size_score": "2",
	"q9_assumption_and_effect_size_notes": "Study Quality and Reporting.assumption_check_and_data_diagnostics notes checks of normality (Kolmogorov–Smirnov), homogeneity of variances (Levene’s test), linearity and homogeneity of regression slopes for ANCOVA, Outcome.statistical_significance provides F, p and Tukey results, Outcome.effect_size_summary reports partial η² for the group effect, and Study Quality and Reporting.data_preprocessing_and_transformation explains selection by MTELP threshold and direct use of pretest and posttest scores without additional transformations.",
	"q10_outliers_and_interpretation_score": "1",
	"q10_outliers_and_interpretation_notes": "Study Quality and Reporting.outlier_treatment_and_sensitivity_analysis is NR, with no outlier detection or sensitivity analyses described, while Outcome.limitation, Outcome.challenge and Outcome.implication interpret findings in light of the IMMs framework and feedback theory (Methodology.theoretical_foundation), discussing constraints such as a homogeneous advanced sample, lack of delayed posttest and potential overreliance on AI tools.",
	"total_quality_score": "16",
	"quality_category": "High",
	"key_quality_concerns": "Homogeneous convenience sample of advanced L1 Turkish learners from a single center with no power analysis or delayed follow-up, and baseline IMMs equivalence across randomized groups was not fully documented beyond inclusion of pretest as a covariate.",
	"include_in_main_synthesis": "Yes",
	"include_in_meta_analysis": "Yes",
	"design_note_llm_specific": "ChatGPT and Microsoft Copilot were accessed via standard online interfaces using shared PCs and a fixed set of IMMs-focused prompts, with no detailed reporting of exact model versions or configuration, so results reflect tool-specific behavior during a short intervention window that may be difficult to reproduce exactly as LLMs evolve."
}