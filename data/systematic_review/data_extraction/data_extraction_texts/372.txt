{
	"Basic Identification": {
		"author (作者)": "Widi Andewi, Winia Waziana, Damar Wibisono, Kristian Adi Putra, Tommy Hastomo, Irene Brainnita Oktarin",
		"publication_year (发表年份)": "2025",
		"study_region (研究地区)": "Indonesia",
		"journal_name (期刊名称)": "NR",
		"study_type (研究类型_期刊论文_会议论文等)": "Peer-reviewed journal article",
		"doi_or_identifier (DOI或唯一标识)": "NR",
		"research_aims (研究目的与问题)": "To compare the effectiveness of prompting with ChatGPT versus direct lecturer interaction in enhancing students’ English language proficiency, writing competency, and self-efficacy, and to examine how EFL students formulate and adapt prompting strategies with ChatGPT as well as the challenges associated with using ChatGPT prompting to improve English proficiency.",
		"research_gap_or_novelty (研究创新性与知识空白)": "Few empirical studies have directly compared ChatGPT-based prompting with traditional lecturer support for academic help-seeking in EFL, especially using a mixed-methods design that examines not only proficiency and writing gains but also the development of prompting strategies, AI literacy, self-efficacy, and challenges such as cognitive offloading, accuracy evaluation, and academic integrity concerns."
	},
	"Participant Information": {
		"educational_level (教育阶段)": "Fourth-semester undergraduate students",
		"language_proficiency (语言熟练度水平)": "Beginner, intermediate, and advanced levels based on an institutional English placement test, with 48 students (80.0%) at beginner level, 9 (15.0%) at intermediate level, and 3 (5.0%) at advanced level",
		"mother_tongue (母语)": "Bahasa Indonesia (students’ L1 for interviews and FGD)",
		"sex (性别)": "Male n=11 (18.3%), female n=49 (81.7%); experimental group 5 males and 25 females, control group 6 males and 24 females",
		"age (年龄)": "19–21 years (19: 38.3%, 20: 48.3%, 21: 13.3%; overall mean age 19.75 years, SD≈0.69)",
		"learning_context (学习语境_ESL_EFL_ELL等)": "EFL in a private Indonesian university English course",
		"target_language (目标语言)": "English (L2)",
		"discipline (学科背景)": "Information Systems undergraduates at Bakti Nusantara Institute, a technology and information systems–oriented private university in Indonesia",
		"prior_experience_llm (既有LLM使用经验)": "Students with prior formal training in advanced prompt engineering were excluded; other prior LLM or ChatGPT use was not reported."
	},
	"Methodology": {
		"research_design (研究设计_实验_准实验_纵向等)": "Sequential explanatory mixed-methods design with an eight-week quasi-experimental intervention comparing a ChatGPT-supported experimental group and a lecturer-supported control group, followed by qualitative interviews and a focus group discussion to interpret and elaborate the quantitative findings.",
		"research_method (研究方法_定量_定性_混合)": "Mixed methods, combining quantitative quasi-experimental pretest–posttest comparisons with ANCOVA and paired t-tests, and qualitative thematic and content analyses of interviews, focus group discussion, and chat logs.",
		"sampling_method (抽样方法)": "Purposive sampling of 60 eligible fourth-semester Information Systems students meeting inclusion criteria (active enrollment, participation in the mandatory English course, informed consent, no advanced prompt-engineering training), followed by stratified random sampling based on English proficiency levels (Beginner, Intermediate, Advanced) to assign 30 students each to the experimental (ChatGPT) and control (lecturer) groups.",
		"sample_size_and_effect (样本量及效应量)": "Total N=60; experimental group n=30, control group n=30. Pretest means were nearly identical for both groups on English Proficiency Test scores (≈70.15 vs 70.30), essay scores (≈68.45 vs 68.93), and self-efficacy scores (≈65.40 vs 66.10). ANCOVA controlling for pretest scores showed significant between-group differences favouring the ChatGPT group on English proficiency (F(1,57)=22.14, p<.001, partial η²=0.280), writing performance (F(1,57)=25.81, p<.001, partial η²=0.312), and self-efficacy (F(1,57)=21.33, p<.001, partial η²=0.272). Within-group paired-samples t-tests indicated significant pre–post gains for both groups on all three outcomes (all p<.001), with larger gains in the ChatGPT group.",
		"theoretical_foundation (理论基础_理论框架)": "Grounded in sociocultural theory, particularly Vygotsky’s Zone of Proximal Development and scaffolding, viewing ChatGPT as a simulated conversational partner that provides distributed cognition and scaffolded support, and in constructivist and self-regulated learning perspectives that emphasize active knowledge construction, metacognitive engagement, and self-efficacy as mediating factors in AI-assisted language learning; the study also develops the notion of ‘scaffolding inversion’ to describe how learners take macro-scaffolding control through prompt design while AI provides micro-level support.",
		"data_collection_instrument (数据收集工具)": "English Proficiency Test (50 multiple-choice items covering listening, grammar, and reading, developed and validated by the university Language Center); an in-class argumentative essay writing task scored with a rubric measuring content and argumentation, organization, vocabulary, language use, and mechanics; a 20-item self-efficacy questionnaire on a 5-point Likert scale adapted from Mahande et al. to measure confidence in using English for communicative and academic purposes; semi-structured interview protocols conducted with 15 experimental-group students at mid-point (week 4) and end (week 8); a post-intervention focus group discussion with 15 experimental-group students; and weekly chat logs of the experimental group’s interactions with ChatGPT submitted alongside tasks.",
		"data_collection_validity_reliability (工具信度与效度)": "All instruments underwent expert judgment by two senior TEFL lecturers and were refined through a pilot study. The English Proficiency Test followed institutional validation procedures and had acceptable reliability in prior administrations. The essay rubric was grounded in practical writing assessment principles, and two trained raters independently scored essays with substantial inter-rater reliability (Cohen’s κ=0.81), resolving discrepancies through discussion. The self-efficacy questionnaire showed good internal consistency (Cronbach’s α=0.85). Interview and FGD protocols were developed following established qualitative guidelines, with transcripts produced verbatim in Bahasa Indonesia and translated into English; qualitative coding was reviewed independently by two researchers who discussed discrepancies until agreement to enhance credibility and trustworthiness.",
		"data_analysis_method (数据分析方法)": "Quantitative data were analysed with SPSS 27, using descriptive statistics, paired-samples t-tests for within-group pre–post comparisons, and ANCOVA to compare posttest outcomes between groups while controlling for pretest scores as covariates. Qualitative data from interviews, FGDs, and chat logs were analysed using six-phase thematic analysis following Braun and Clarke (familiarization, coding, theme development, review, naming, reporting) supported by NVivo, and content analysis for categorizing challenges; two researchers independently reviewed coding and resolved disagreements through discussion.",
		"unit_of_analysis (分析单位)": "Individual student test scores, essay scores, and self-efficacy scores for quantitative analyses; individual participants and group-level discourse segments in interview and focus group transcripts, and individual chat sessions in prompting logs for qualitative analyses.",
		"group_assignment_method (组别分配方式_随机_非随机等)": "Stratified random assignment of 60 participants into experimental (ChatGPT) and control (lecturer) groups based on English proficiency categories (Beginner, Intermediate, Advanced) derived from an institutional placement test, with the same lecturer teaching both groups.",
		"power_analysis (功效分析与样本量论证)": "NR",
		"sampling_frame_and_representativeness (抽样框与样本代表性)": "Sampling frame consisted of fourth-semester Information Systems students taking a mandatory English course at a single private Indonesian university, with a predominantly beginner-level and female sample, which limits representativeness and generalizability to similar institutional and disciplinary contexts.",
		"scoring_procedure_and_rater_training (评分流程与评分者培训)": "For the argumentative essays, two trained raters applied a rubric assessing content and argumentation, organization, vocabulary, language use, and mechanics; inter-rater agreement was substantial (Cohen’s κ=0.81), and any scoring differences were resolved through discussion and consensus; the English Proficiency Test followed existing institutional scoring procedures; the self-efficacy questionnaire was scored by summing or averaging Likert responses, though exact scoring details were not elaborated."
	},
	"Intervention": {
		"duration (干预时长与频率)": "Data collection spanned nine weeks, with week 1 devoted to pretests (English Proficiency Test, initial argumentative essay, and self-efficacy questionnaire), followed by an eight-week intervention during which both groups completed weekly English tasks, semi-structured interviews were conducted at weeks 4 and 8, and a focus group discussion took place post-intervention.",
		"llm_model_type (LLM模型类型_如ChatGPT_GPT4_Gemini等)": "ChatGPT (large language model by OpenAI; specific version not reported)",
		"llm_model_configuration (LLM模型配置与版本_API_网页_参数等)": "Students in the experimental group accessed ChatGPT online during and outside class to support weekly English tasks, with unrestricted asynchronous access during the eight-week intervention for preparation, drafting, and revision; they were required to record and submit their chat logs as part of assignments; the exact platform (web UI vs API), model version, and parameter settings were not reported.",
		"llm_integration_mode (LLM整合模式_直接使用_教师中介_系统嵌入)": "Students in the experimental group directly interacted with ChatGPT as a stand-alone tool for help-seeking and task completion, separate from the institutional LMS, while the lecturer only introduced objectives, explained requirements, and monitored ethical use without mediating or editing ChatGPT output.",
		"prompting_strategy (提示策略_提示工程与使用方式)": "Students were encouraged and guided to refine prompts, request revisions, and record interactions with ChatGPT, and over time developed a range of prompting strategies including minimalist prompting and simple commands (for example, ‘Fix this’), keyword replacement, focusing on the core idea, contextual expansion, role-playing (assigning ChatGPT roles such as thesis supervisor), question segmentation, divide and conquer for different text sections, corrective feedback directed at the AI, top-down exploration from broad to narrow questions, guided generation, requesting verification, key point identification, solution-oriented follow-ups, and progressive addition of constraints; prompting evolved from short, often L1-based single-turn prompts to more elaborate, English-medium multi-turn dialogic interactions aligned with academic writing goals.",
		"training_support_llm_literacy (LLM素养与提示培训)": "The experimental group received initial explanation of ChatGPT’s role in the course, guidance on weekly objectives and task requirements, and ongoing instruction to refine prompts, request revisions, and ethically record their interactions, but there was no detailed, stand-alone AI literacy or prompt-engineering curriculum; the authors argue that effective use of generative AI requires explicit instruction in AI literacy and prompt literacy, conceptualized through their scaffolding inversion model.",
		"intervention_implementation (干预实施流程_步骤与任务)": "In week 1 all 60 students completed pretests (English Proficiency Test, an initial argumentative essay under controlled 60-minute conditions, and a self-efficacy questionnaire). During the subsequent eight-week intervention, both groups completed parallel weekly English tasks including essay writing, paragraph revision, and grammar and vocabulary practice. The experimental group used ChatGPT throughout preparation, drafting, and revising to ask questions, refine language, and seek feedback, while the control group completed the same tasks with lecturer guidance and feedback. Interactions in the experimental group were documented through required chat logs, and qualitative data were collected through semi-structured interviews at weeks 4 and 8 and a post-intervention focus group discussion.",
		"experimental_group_intervention (实验组干预内容)": "The experimental group (n=30) completed weekly English tasks with support from ChatGPT, using it to generate ideas, clarify concepts, revise paragraphs, practice grammar and vocabulary, and receive immediate feedback; they were encouraged to refine prompts, engage in multi-turn dialogic interactions, and record their ChatGPT sessions; the lecturer set objectives, explained tasks, and monitored ethical use but did not provide direct language corrections for this group.",
		"control_group_intervention (对照组干预内容)": "The control group (n=30) completed the same weekly English tasks without ChatGPT, relying on direct instruction and feedback from the lecturer during two weekly class meetings (90 minutes total) and on written comments on assignments returned asynchronously within about 48 hours; the lecturer provided formative feedback aligned with course objectives but with less immediacy, frequency, and individualization than ChatGPT.",
		"writing_stage (写作阶段_如生成_修改_反馈_重写等)": "ChatGPT support in the experimental group was available during the preparation, drafting, and revision stages of weekly English tasks, enabling idea generation, drafting assistance, and post-feedback revision, whereas lecturer support in the control group focused on in-class guidance and feedback and subsequent revisions; the pretest and posttest argumentative essays were written under controlled timed conditions without explicit mention of ChatGPT use during the test itself.",
		"writing_genre (写作体裁)": "Argumentative essays used for pretest and posttest assessment, plus weekly essay and paragraph tasks related to academic or topical content.",
		"writing_task_type (写作任务类型)": "Weekly English tasks including essay writing, paragraph revision activities, and grammar and vocabulary practice, along with a formal 60-minute argumentative essay test administered under controlled conditions as the primary writing assessment.",
		"role_llm (LLM角色_如生成文本_给反馈_评分_对话等)": "ChatGPT functioned as an AI conversational partner and on-demand tutor, providing immediate responses to students’ prompts, suggesting language improvements, offering grammar and vocabulary explanations, helping refine thesis statements and paragraphs, generating model paragraphs when requested, summarizing and simplifying content, and acting as a dialogic feedback provider rather than a scorer.",
		"role_instructor (教师角色与介入方式)": "The same lecturer taught both groups, set learning objectives, designed and explained tasks, taught course content, and provided direct language feedback, clarification, and encouragement to the control group through in-class interaction and written comments, while for the experimental group the lecturer limited involvement to introducing tasks, supervising ethical ChatGPT use, and monitoring but not correcting students’ language, thereby allowing ChatGPT to take over most micro-level feedback functions.",
		"setting (教学情境_学校类型_课程类型_线上线下)": "Mandatory English course in the Information Systems program at Bakti Nusantara Institute, a private university in Indonesia; instruction took place primarily in a classroom setting with some asynchronous engagement, ChatGPT accessed online by students, and assessments such as the essay task administered in a controlled, time-limited environment.",
		"ethical_consideration (伦理审查与知情同意)": "Ethical approval was obtained from the Research and Community Service Institute (LPPM) of Bakti Nusantara Institute; all participants gave informed consent, were informed of their right to withdraw without penalty, and had their data anonymized through pseudonyms with identifying details removed; all audio and video recordings were stored on a secure, encrypted drive accessible only to the principal researchers.",
		"llm_access_policy (LLM使用规范_允许与限制)": "Students in the experimental group were allowed to use ChatGPT only as part of the course’s English tasks during the eight-week intervention and were guided to use it for preparation, drafting, and revision while the lecturer monitored ethical use; they were required to submit chat logs alongside weekly assignments; persistent student anxiety about academic integrity and uncertainty about the boundary between legitimate assistance and cheating highlighted the need for clearer institutional policies on ethical AI use.",
		"llm_safety_guardrails (LLM安全与内容过滤设置)": "Safety and integrity were maintained primarily through procedural guardrails, including lecturer monitoring of ChatGPT use, required submission of chat logs, and general guidance on ethical use; no specific technical guardrails such as restricted prompts, content filters, or access limitations beyond standard ChatGPT behaviour were reported.",
		"key_findings (主要研究发现_与LLM写作干预相关)": "Quantitatively, the ChatGPT-supported group achieved significantly greater gains than the lecturer-supported group on English Proficiency Test scores, argumentative essay scores, and self-efficacy measures, with ANCOVA showing large partial η² values (≈0.28–0.31) for condition effects after controlling for pretest scores and both groups improving significantly over time. Qualitatively, students in the experimental group progressed from simple, vague, often L1-based one-shot prompts to more sophisticated English-medium multi-turn prompting strategies such as contextual expansion, role-playing, divide and conquer, solution-oriented follow-ups, and progressive constraint, which supported deeper learning. At the same time, substantial pedagogical, technical, and psychological challenges were identified, including over-reliance on ChatGPT and cognitive offloading, difficulty evaluating the accuracy and bias of AI outputs, generic or shallow feedback when prompts were vague, occasional hallucinated or outdated information, frustration with AI misunderstandings, lack of interpersonal connection compared with human lecturers, and pervasive anxiety about academic integrity."
	},
	"Outcome": {
		"application_effectiveness_overview (应用效果总体评价与测量工具)": "Using ChatGPT for prompting in an EFL course was found to be more effective than traditional lecturer interaction in improving students’ overall English proficiency, writing performance, and self-efficacy, as measured by an institutional English Proficiency Test, rubric-based argumentative essay scores, and a 20-item self-efficacy questionnaire; statistical analyses (paired t-tests and ANCOVA) indicated significantly greater gains in the ChatGPT group on all three quantitative outcomes, and qualitative analyses showed richer prompting strategies and reflective engagement in the experimental group, alongside notable challenges.",
		"writing_performance_measure (写作表现测量工具_量表或评分标准)": "Argumentative essay task scored with a rubric covering content and argumentation, organization, vocabulary, language use, and mechanics, rated independently by two trained raters with substantial inter-rater reliability (Cohen’s κ=0.81); in addition, a 50-item English Proficiency Test assessing listening, grammar, and reading was used as a broader proficiency measure.",
		"writing_performance_focus (写作表现关注维度_流利度_准确性_复杂度_体裁等)": "Primary focus on overall writing quality in argumentative essays, including content and argumentation quality, organization and coherence, lexical range and appropriacy, grammatical accuracy, and mechanics, with general English proficiency (listening, grammar, reading) also assessed but no specific measures of syntactic complexity or fluency reported.",
		"affective_aspect_measure (情感因素测量工具_问卷_量表等)": "A 20-item self-efficacy questionnaire adapted from Mahande et al. on a 5-point Likert scale measuring students’ confidence in using English for communication and academic purposes, administered before and after the intervention and showing good reliability (Cronbach’s α=0.85).",
		"affective_aspect_focus (情感因素维度_动机_态度_焦虑_自效感等)": "English learning self-efficacy, specifically students’ perceived confidence in performing various English tasks and using English for academic communication, as well as qualitative reports of motivation, confidence, and anxiety related to using ChatGPT and concerns over academic integrity.",
		"cognitive_aspect_measure (认知因素测量工具)": "Semi-structured interviews with 15 experimental-group students (conducted at mid-point and at the end of the intervention), a post-intervention focus group discussion with 15 experimental-group students, and collected chat logs of ChatGPT interactions, all analysed via thematic and content analysis to derive categories of prompting strategies and challenges.",
		"cognitive_aspect_focus (认知因素维度_策略使用_元认知监控等)": "Prompt formulation and adaptation, development of AI literacy and prompt literacy, metacognitive engagement in planning and regulating interaction with ChatGPT, evaluation of response accuracy and bias, strategic use of multi-turn dialogic prompting, and the conceptual process of scaffolding inversion in which learners manage macro-level learning structures while AI provides micro-level support.",
		"behavioral_aspect_measure (行为因素测量工具_日志_平台日志等)": "Chat logs documenting students’ weekly interactions with ChatGPT in the experimental group, alongside qualitative accounts from interviews and focus group discussions describing how often and in what ways ChatGPT was used for tasks; behavioural outcomes were also indirectly reflected in pre/post test performance and essay revision practices.",
		"behavioral_aspect_focus (行为因素维度_使用频率_交互模式_坚持度等)": "Patterns and evolution of ChatGPT use, including initial one-shot help-seeking transitioning to sustained multi-turn dialogic interactions, shifts from L1-based to English-based prompting, the degree of reliance on AI for grammar and vocabulary correction and content generation, and tendencies toward cognitive offloading and metacognitive laziness versus strategic, reflective use.",
		"other_outcomes_measure (其他结果测量工具)": "Qualitative thematic and content analyses of interview and focus group transcripts and categorization tables of prompting strategies (Table 4) and prompting challenges (Table 5).",
		"other_outcomes_focus (其他结果维度说明)": "Identification of specific prompting strategy types (for example, contextual expansion, role-playing, question segmentation, divide and conquer, solution-oriented follow-up) and challenge categories (pedagogical, technical, psychological), providing insight into how students learn to work with ChatGPT and where they encounter difficulties such as cognitive offloading, hallucinations, and emotional uncertainty.",
		"assessment_timepoints (评估时间点_前测_后测_延迟测等)": "Pretests (English Proficiency Test, initial argumentative essay, and self-efficacy questionnaire) administered in week 1; posttests (English Proficiency Test, essay, and self-efficacy questionnaire) administered after the eight-week intervention (around week 9); semi-structured interviews conducted in weeks 4 and 8; focus group discussion held after the intervention; no delayed follow-up beyond the immediate post-intervention phase.",
		"primary_outcome_variables (主要结果变量_因变量)": "Posttest English Proficiency Test scores, posttest argumentative essay rubric scores, and post-intervention self-efficacy scores (with pretest scores used as covariates), plus qualitatively derived categories of prompting strategies and prompting-related challenges in the ChatGPT group.",
		"independent_variables_and_factors (自变量与实验因素)": "Main independent variable was feedback and support condition (ChatGPT prompting versus lecturer interaction), with time (pretest vs posttest) as a repeated factor in within-group analyses; pretest scores served as covariates in ANCOVA analyses; proficiency-stratified group assignment was used at sampling but proficiency level was not analysed as an interaction factor in outcome models.",
		"followup_length_and_type (随访时长与类型)": "Immediate post-intervention assessment after eight weeks of ChatGPT or lecturer-supported learning (approximately week 9 overall); no longer-term delayed follow-up assessments were conducted.",
		"statistical_significance (统计显著性结果摘要)": "Descriptive statistics showed comparable baseline means between the experimental and control groups on all three measures. Paired-samples t-tests revealed statistically significant pre–post improvements in both groups for English Proficiency Test scores, essay scores, and self-efficacy scores (all p<.001). ANCOVA analyses controlling for pretest scores demonstrated significant between-group differences in gain scores favouring the ChatGPT group for English proficiency (F(1,57)=22.14, p<.001), writing performance (F(1,57)=25.81, p<.001), and self-efficacy (F(1,57)=21.33, p<.001).",
		"effect_size_summary (效应量摘要)": "Partial η² effect sizes from ANCOVA indicated substantial condition effects favouring the ChatGPT group: approximately 0.280 for English Proficiency Test scores, 0.312 for essay scores, and 0.272 for self-efficacy, representing moderate to large practical significance; paired t-tests also indicated large within-group improvements, although specific Cohen’s d values were not reported numerically.",
		"llm_misuse_or_negative_effects (LLM滥用或负向效应)": "The study documented several negative patterns and risks associated with ChatGPT use, particularly the pedagogical issue of over-reliance and cognitive offloading, where students used the AI as a shortcut for grammar correction and task completion and reported not practising or remembering rules, leading to what the authors describe as metacognitive laziness and potential illusion of competence; learners struggled to evaluate the accuracy and possible bias of AI-generated information and reported cases of hallucinated or outdated content that undermined trust; generic or shallow feedback occurred when prompts were vague; students experienced frustration when ChatGPT misunderstood nuanced questions, reported a lack of emotional support and interpersonal connection compared with human lecturers, and expressed persistent anxiety about academic integrity, being unsure where legitimate assistance ends and cheating begins.",
		"equity_and_subgroup_effects (公平性与亚组差异)": "Participants were stratified by proficiency level (Beginner, Intermediate, Advanced) during random group assignment to ensure balanced proficiency distributions, but no outcome analyses by proficiency, gender, or other subgroups were reported; the authors note that the sample was predominantly beginner-level and suggest that future research should examine whether proficiency level influences preferred prompting language and effective interaction with ChatGPT, but they provide no detailed subgroup statistics beyond stratification and demographic description.",
		"limitation (研究局限)": "Limitations include the single-institution context with a relatively small, predominantly beginner-level sample of Information Systems students, which restricts generalizability; focus on three quantitative outcomes (proficiency, writing, self-efficacy) without direct measurement of higher-order thinking skills such as argument development, critical reasoning, or pragmatic and interpersonal skills that may be affected by AI use; potential confounding due to different levels of availability, responsiveness, and individualization between ChatGPT and lecturer support; reliance on self-report and qualitative data to capture prompting strategies and challenges; and lack of long-term follow-up to assess retention and transfer of skills.",
		"challenge (实施挑战与风险)": "Implementation challenges and risks included managing students’ tendency toward cognitive offloading and over-dependence on ChatGPT for quick fixes, supporting learners in critically evaluating the accuracy and bias of AI outputs, addressing technical issues such as server problems and hallucinated or outdated information that undermine trust, compensating for the lack of emotional connection and relational nuance in AI feedback compared with lecturer interaction, and clarifying ethical boundaries to reduce students’ anxiety about academic integrity when using AI for coursework.",
		"future_work (未来研究方向)": "Future research directions proposed include investigating higher-order outcomes such as argument development, critical reasoning, and pragmatic and interpersonal skills in AI-mediated EFL learning; conducting longitudinal studies to examine long-term skill retention and possible erosion due to cognitive offloading; comparing different pedagogical approaches to teaching AI literacy and prompt literacy as part of EFL curricula; expanding research to more diverse institutions, disciplines, and proficiency profiles to enhance external validity; and examining how proficiency levels and learner backgrounds shape preferred prompting languages and effective use of ChatGPT.",
		"implication (理论与教学实践启示)": "The study implies that effective use of generative AI in EFL is not an automatic outcome of tool access but a learned competence requiring explicit instruction in AI literacy and strategic prompting; ChatGPT can serve as an accessible, responsive, and highly individualized scaffold that enhances proficiency, writing performance, and self-efficacy when students learn to formulate context-rich, iterative prompts and critically evaluate AI feedback, but it should complement rather than replace human lecturers, who remain central for fostering higher-order thinking, interpersonal skills, and ethical awareness; the concept of scaffolding inversion highlights the need to design curricula where students consciously manage macro-level learning goals and AI support while teachers develop policies and classroom practices that reduce cognitive offloading and sustain meaningful, reflective learning."
	},
	"Study Quality and Reporting": {
		"funding_source (经费来源)": "Funded by the Directorate General of Higher Education, Ministry of Education and Culture of the Republic of Indonesia, under Contract Nos. 123/C3/DT.05.00/PL/2025 (May 28, 2025) and 107/LL2/DT.05.00/PL/2025 (June 2, 2025).",
		"conflict_of_interest (利益冲突声明)": "NR",
		"risk_of_bias_randomization (偏倚风险_分配与随机化)": "Risk of selection bias was mitigated by using stratified random sampling based on initial English proficiency levels to allocate students into experimental and control groups and by employing the same lecturer and parallel tasks for both groups, although the study remained limited to one institution and did not involve blinding.",
		"risk_of_bias_blinding (偏倚风险_盲法)": "Participants and the lecturer necessarily knew which condition they were in (ChatGPT vs lecturer), and there is no indication that raters, interviewers, or analysts were blinded to group assignment, so blinding was likely absent.",
		"attrition_and_missing_data (流失与缺失数据处理)": "No participant attrition was reported; all 60 students (30 per group) were included throughout the eight-week intervention and completed pretests and posttests; handling of any item-level missing data on questionnaires was not discussed.",
		"reporting_transparency (报告透明度与可重复性)": "The study clearly reports its research questions, mixed-methods design, sampling and group assignment procedures, participant demographics, instruments, validation and reliability evidence, intervention procedures, and statistical analyses including ANCOVA and t-test results with F values, p values, and partial η²; qualitative methods are described with references to thematic and content analysis, example prompts and quotes, and tables summarizing prompting strategies and challenges, but raw datasets, chat logs, and analysis code are not shared.",
		"preregistration_or_protocol (预注册或研究方案)": "No preregistration or formal pre-published research protocol was mentioned.",
		"llm_version_reproducibility (LLM版本与可复现性)": "The LLM is identified as ChatGPT but no specific version, update date, or configuration parameters are provided, and while chat logs were collected, they are not publicly available, which limits exact reproducibility given that ChatGPT behaviour can change over time.",
		"baseline_equivalence (基线等同性检验)": "Baseline equivalence between groups was supported by nearly identical pretest means on the English Proficiency Test, essay scores, and self-efficacy scores as shown in descriptive statistics, as well as by stratified random assignment based on proficiency; ANCOVA further controlled for minor pre-existing differences by including pretest scores as covariates.",
		"assumption_check_and_data_diagnostics (统计假设检验与数据诊断)": "The authors justify the use of ANCOVA to control for pretest differences and apply standard parametric tests for normally distributed quantitative variables, but they do not report formal checks of ANCOVA assumptions such as homogeneity of regression slopes, normality of residuals, or homoscedasticity, nor do they describe additional diagnostics or robustness checks.",
		"outlier_treatment_and_sensitivity_analysis (异常值处理与稳健性分析)": "NR",
		"data_preprocessing_and_transformation (数据预处理与转换)": "Quantitative data from tests, essays, and questionnaires were scored according to institutional and rubric-based procedures, and pretest scores were used as covariates in ANCOVA; qualitative interview and focus group recordings were transcribed verbatim in Bahasa Indonesia and translated into English for analysis, then coded using NVivo with inductive category development and independent review by two researchers; no additional data transformations or outlier treatments were reported."
	}
}