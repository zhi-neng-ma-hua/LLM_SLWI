{
	"Basic Identification": {
		"author (作者)": "Belén C. Muñoz Muñoz, Hossein Nassaji, Felipe I. Bello Carrillo",
		"publication_year (发表年份)": "2025",
		"study_region (研究地区)": "Chile (Chilean university, EFL context)",
		"journal_name (期刊名称)": "System",
		"study_type (研究类型_期刊论文_会议论文等)": "Journal article; quasi-experimental pre-test–post-test study",
		"doi_or_identifier (DOI或唯一标识)": "10.1016/j.system.2025.103805",
		"research_aims (研究目的与问题)": "To examine and compare the effectiveness of direct written corrective feedback provided by ChatGPT versus a human teacher in improving English Pedagogy students’ L2 essay writing in Chile, focusing on task response, cohesion and coherence, lexical resource, and grammatical range and accuracy; specifically, to determine (1) how ChatGPT-provided direct WCF compares to human-provided direct WCF in improving EFL students’ opinion essays and (2) which aspects of the essays benefit most from ChatGPT versus human feedback.",
		"research_gap_or_novelty (研究创新性与知识空白)": "The study addresses the limited empirical research on ChatGPT as a written corrective feedback source in L2 writing, particularly in non-Asian EFL contexts and in Chile, by directly comparing ChatGPT GPT-4o generated direct WCF with trained teacher direct WCF over multiple IELTS-type writing tasks using the same rubric and instructions."
	},
	"Participant Information": {
		"educational_level (教育阶段)": "First-year or second-year English Pedagogy undergraduates (description inconsistent across abstract and methods) in a pre-service teacher education program at a Chilean university",
		"language_proficiency (语言熟练度水平)": "Between high A2 and low B1 according to the Common European Framework of Reference for Languages (CEFR), based on an annual institutional placement test assessing grammar, vocabulary, reading, and writing",
		"mother_tongue (母语)": "NR",
		"sex (性别)": "26 females, 18 males",
		"age (年龄)": "19–21 years",
		"learning_context (学习语境_ESL_EFL_ELL等)": "EFL context in higher education in Chile where English is learned as a foreign language",
		"target_language (目标语言)": "English (L2)",
		"discipline (学科背景)": "English Pedagogy program (pre-service English language teacher education, mandatory course on English language didactics)",
		"prior_experience_llm (既有LLM使用经验)": "Students are reported as usually using tools such as translators or AI tools to improve their writing outside the classroom, but no formal assessment of prior LLM experience was reported."
	},
	"Methodology": {
		"research_design (研究设计_实验_准实验_纵向等)": "Quasi-experimental pre-test–post-test design with two parallel groups (G1_Chat receiving ChatGPT-generated direct WCF, G2_Teacher receiving teacher-generated direct WCF) over four IELTS Task 2 opinion essays (T1–T4) during two months.",
		"research_method (研究方法_定量_定性_混合)": "Quantitative",
		"sampling_method (抽样方法)": "Convenience sample of intact English Pedagogy course sections at a Chilean university; each section was randomly assigned an experimental condition (ChatGPT feedback or teacher feedback), resulting in two non-randomized groups.",
		"sample_size_and_effect (样本量及效应量)": "Total N=44 English Pedagogy students (G1_Chat n=20, G2_Teacher n=22, aged 19–21, 26 females and 18 males). Wilcoxon Signed-Rank tests comparing pre-test (T1) and post-test (T4) showed a significant improvement for G1_Chat (z=-3.928, p<0.001, eta squared η²=0.772, large effect size) and no significant difference for G2_Teacher (z=-0.898, p=0.369, η²=0.040, small effect size). Mann–Whitney U tests comparing G1_Chat and G2_Teacher showed a significant pre-test difference with G1_Chat having lower ranks (U=30.5, z=-4.77, p<0.001) and a significant post-test difference with G1_Chat outperforming G2_Teacher (U=299, z=1.99, p=0.0468). Friedman tests within groups across four tasks and four criteria showed significant improvement for G1_Chat on all criteria (task response, cohesion and coherence, lexical resource, grammatical range and accuracy; chi-square values approximately 39.175–51.486, df=3, p<0.001), whereas G2_Teacher showed significant change only for task response (chi-square=9.268, p=0.026) and grammatical range and accuracy (chi-square=14.337, p=0.002) but not for cohesion and coherence or lexical resource.",
		"theoretical_foundation (理论基础_理论框架)": "Grounded in written corrective feedback theory distinguishing direct versus indirect and focused versus comprehensive WCF, cognitive views of language learning emphasizing noticing and repeated exposure, and the role of WCF in L2 acquisition and writing development; also informed by emerging literature on AI and Automated Writing Evaluation tools, ChatGPT’s affordances and limitations, and concerns about cognitive engagement, cultural bias, and academic integrity in AI-supported WCF.",
		"data_collection_instrument (数据收集工具)": "Four IELTS Writing Task 2 style opinion essay prompts (T1–T4) on course-related topics such as language acquisition theories, teaching methods, acquisition versus learning, and emotional variables in language learning; each task was pen-and-paper, 40 minutes in class. Essays were assessed using the official IELTS Writing Task 2 rubric with four criteria (task response, cohesion and coherence, lexical resource, grammatical range and accuracy), each rated on a 0–9 scale with the final score as the average of the four criterion ratings. Writing prompts were validated through a Likert-scale evaluation by six academics and piloted with 10 similar students.",
		"data_collection_validity_reliability (工具信度与效度)": "Six academics from different English Pedagogy programs evaluated the quality and equivalence of the writing prompts using a Likert scale; Kendall’s W=0.423, p=0.007 indicated moderate but significant inter-rater agreement and prompts were revised accordingly. The final prompts were piloted with 10 comparable students to identify issues with time, instructions, and genre characteristics. Shapiro–Wilk tests indicated normal distributions for group scores at pre-test and post-test (p>0.05), but Levene’s test indicated lack of homogeneity of variances for the pre-test (p=0.048), leading to the use of non-parametric tests. Inter-rater reliability for writing scores was not reported.",
		"data_analysis_method (数据分析方法)": "Descriptive statistics (means, standard deviations, skewness, kurtosis) and Shapiro–Wilk normality tests were computed for pre-test and post-test scores in each group. Due to violation of homogeneity of variance at pre-test, non-parametric inferential analyses were used: Wilcoxon Signed-Rank tests within each group to compare pre-test and post-test, Mann–Whitney U tests to compare between groups at pre-test and post-test, and Friedman tests within each group to examine changes across tasks (T1–T4) for each rubric criterion. Eta squared (η²) was calculated as an effect size for Wilcoxon tests. Analyses were conducted using Python with SciPy and statsmodels libraries.",
		"unit_of_analysis (分析单位)": "Individual student essays and their IELTS rubric scores (overall band score and criterion-specific scores); change scores within students over time and rank-based comparisons between groups.",
		"group_assignment_method (组别分配方式_随机_非随机等)": "Two intact course sections of English Pedagogy students were each randomly assigned to an experimental condition: G1_Chat (ChatGPT feedback, n=20) and G2_Teacher (teacher feedback, n=22); there was no individual-level randomization within sections.",
		"power_analysis (功效分析与样本量论证)": "NR",
		"sampling_frame_and_representativeness (抽样框与样本代表性)": "Sample drawn from 44 English Pedagogy students enrolled in a mandatory English language didactics course at a single Chilean university; all participants were within the high A2 to low B1 CEFR band. The authors note that learners’ additional exposure to English outside the classroom could not be fully controlled and that the sample reflects typical classroom compositions with within-band individual variation, but broader representativeness and generalisability to other institutions or contexts are limited.",
		"scoring_procedure_and_rater_training (评分流程与评分者培训)": "The IELTS rubric was used to assign band scores (0–9) for task response, cohesion and coherence, lexical resource, and grammatical range and accuracy. For the teacher feedback group, an experienced EFL teacher with eight years of pre-service teaching experience, a master’s degree in English teaching, and expertise as an international examiner was responsible for evaluating texts and providing direct WCF; the teacher was trained to provide targeted feedback following the same instructions given to ChatGPT. Scoring procedures for the ChatGPT group (e.g., whether the same teacher or researchers applied rubric ratings) and any rater training specific to scoring were not specified."
	},
	"Intervention": {
		"duration (干预时长与频率)": "Four class sessions over approximately two months: in each session students wrote one IELTS Task 2 opinion essay in 40 minutes; in sessions 2–4 they first spent about 10 minutes reviewing feedback on the previous task (T1, T2, T3), followed immediately by writing the next task; T1 served as pre-test and T4 as post-test.",
		"llm_model_type (LLM模型类型_如ChatGPT_GPT4_Gemini等)": "ChatGPT (GPT-4o, large language model by OpenAI)",
		"llm_model_configuration (LLM模型配置与版本_API_网页_参数等)": "ChatGPT GPT-4o was used to generate direct written corrective feedback; it was instructed via text prompts and used to create a two-column error and correction table plus general comments aligned with the IELTS rubric. The same prompt, device, and one chat session per essay were used, and a new chat was created for each student text to prevent retention bias and potential variation in responses. The access mode (web UI versus API) and detailed parameter settings were not reported.",
		"llm_integration_mode (LLM整合模式_直接使用_教师中介_系统嵌入)": "Teacher or researcher-mediated integration: researchers interacted directly with ChatGPT (GPT-4o) to obtain feedback on each student essay, then transferred this feedback and the associated rubric scores onto paper forms for students in the G1_Chat group; students did not interact with ChatGPT themselves.",
		"prompting_strategy (提示策略_提示工程与使用方式)": "ChatGPT was assigned the role of an English language teacher and instructed to focus on the four IELTS Task 2 rubric criteria (task response, cohesion and coherence, lexical resource, grammatical range and accuracy). It was asked to assess each essay using these criteria, provide general comments in simple language, and generate a table with two columns (one for the original error and one for the suggested correction) covering areas such as spelling, capitalization, punctuation, singular and plural nouns, verb tense, subject–verb agreement, word form, awkward phrasing, prepositions, articles, and sentence fragments and run-on sentences. This procedure was adapted from Escalante et al. (2023), and prompts for ChatGPT and instructions for the teacher were aligned to ensure comparability of feedback type and explicitness.",
		"training_support_llm_literacy (LLM素养与提示培训)": "Students did not receive explicit LLM literacy or prompt engineering training because they did not directly operate ChatGPT; instead, they were given the IELTS rubric in advance, encouraged to align their writing with the criteria, and during feedback sessions they were given 10 minutes to review the rubric-based feedback (teacher- or ChatGPT-generated) and compare it with their original texts to understand the comments and levels assigned.",
		"intervention_implementation (干预实施流程_步骤与任务)": "The intervention was embedded in the regular course. Session 1: students in both groups completed Writing Task 1 (T1) in 40 minutes on paper, with instructions to reread and make surface-level corrections (spelling, grammar) and to consider the IELTS rubric criteria. After T1, texts were collected and evaluated according to condition: G1_Chat essays were processed through ChatGPT GPT-4o using the standardized prompt, and feedback (error–correction table plus comments) was transferred onto a paper rubric; G2_Teacher essays were evaluated by the trained teacher, who assigned band scores, wrote general comments, and provided direct WCF. Session 2 (two weeks later): students received their T1 feedback on paper, spent 10 minutes reviewing and comparing feedback with their texts, then wrote Task 2 (T2) in 40 minutes under similar conditions; texts were collected and feedback generated as before. Session 3: students reviewed feedback on T2 for 10 minutes and then wrote Task 3 (T3) in 40 minutes; feedback was again provided. Session 4: students reviewed feedback on T3 for 10 minutes and then wrote Task 4 (T4) in 40 minutes; T4 served as the post-test. Rewriting of the same texts was deliberately not included to avoid decontextualized tasks, reflecting the local teaching practice where rewriting is not a common component of writing instruction.",
		"experimental_group_intervention (实验组干预内容)": "G1_Chat (n=20) received direct WCF generated by ChatGPT GPT-4o on Writing Tasks 1, 2, and 3, formatted as an IELTS rubric sheet with band scores for each criterion, simple-language general comments, and a two-column table listing identified errors and their corrections across a wide range of linguistic features. Feedback was presented on paper during class for 10 minutes of review before each subsequent writing task, with the expectation that students would internalize the corrections and improve their performance on subsequent opinion essays.",
		"control_group_intervention (对照组干预内容)": "G2_Teacher (n=22) received direct WCF from an experienced EFL teacher trained in IELTS evaluation and in the study-specific feedback instructions. The teacher assigned band scores for the four IELTS rubric criteria, wrote general comments, and provided direct corrections by marking the correct forms above errors in students’ texts. The teacher followed the same feedback focus and instructions as ChatGPT (task response, cohesion and coherence, lexical resource, grammatical range and accuracy, direct corrections), and feedback was given on paper in class during the same 10-minute review periods before subsequent writing tasks.",
		"writing_stage (写作阶段_如生成_修改_反馈_重写等)": "Writing of initial drafts of timed opinion essays, reception and review of direct written corrective feedback on complete drafts, and subsequent application of feedback to new but similar IELTS Task 2 opinion essays; there was no rewriting of the same texts, so the intervention emphasized iterative feedback and transfer of learning across tasks rather than explicit drafting–revising of a single essay.",
		"writing_genre (写作体裁)": "Opinion essays modelled on IELTS Writing Task 2, addressing course-related academic topics in English language teaching and learning.",
		"writing_task_type (写作任务类型)": "Four timed in-class opinion essays (IELTS Task 2 format) of the standard IELTS length, each written in 40 minutes on paper without outside tools, with T1 and T4 serving as pre-test and post-test.",
		"role_llm (LLM角色_如生成文本_给反馈_评分_对话等)": "ChatGPT acted as an AI feedback provider, generating direct written corrective feedback and brief evaluative comments on students’ essays aligned with the IELTS rubric; it identified language errors and suggested corrections in a structured table and provided criterion-related comments, but did not autonomously score essays for research analysis beyond the rubric-aligned feedback used in class.",
		"role_instructor (教师角色与介入方式)": "The course instructor managed classroom tasks, administered the writing assignments, and collected student texts and feedback sheets. For the teacher feedback group, a hired EFL teacher with extensive IELTS-related experience evaluated the texts, assigned band scores, and provided direct WCF and comments. For the ChatGPT group, the researchers handled interactions with ChatGPT and transferred AI-generated feedback onto paper; the course instructor encouraged students in both groups to review feedback, compare it with their texts, and understand the comments and scores.",
		"setting (教学情境_学校类型_课程类型_线上线下)": "Face-to-face instruction in a mandatory English language didactics course within an English Pedagogy program at a Chilean university; pen-and-paper in-class writing and paper-based feedback in an EFL higher education setting.",
		"ethical_consideration (伦理审查与知情同意)": "Ethical procedures followed the University’s Bioethics and Biosafety Committee guidelines; participation was voluntary and students had the right to withdraw at any time. The study design respected institutional requirements, and data confidentiality and anonymity were maintained in accordance with these ethical guidelines.",
		"llm_access_policy (LLM使用规范_允许与限制)": "During the writing tasks, students were not allowed to use external tools such as translators or AI systems to ensure that texts reflected their own writing; ChatGPT was operated only by the researchers. AI-generated feedback was printed and delivered on paper to avoid medium effects and direct online interaction during class. The study emphasizes the need for students and teachers to critically assess AI feedback, but no explicit institutional ChatGPT policy beyond general ethical compliance is described.",
		"llm_safety_guardrails (LLM安全与内容过滤设置)": "ChatGPT feedback was constrained by carefully designed prompts specifying its role, target criteria, and error types, and a separate chat session was created for each text to prevent retention bias; the same prompt, device, and chat session procedure were used for all texts. The authors discuss broader risks of ChatGPT including cultural bias, misleading information, and academic integrity concerns, but no additional technical safety filters or automated content moderation settings specific to this study are reported.",
		"key_findings (主要研究发现_与LLM写作干预相关)": "Both ChatGPT-generated and teacher-generated direct written corrective feedback supported L2 writing development, but ChatGPT feedback produced a larger and statistically significant improvement in overall writing scores, while teacher feedback did not produce significant pre–post gains. The ChatGPT group began with significantly lower pre-test performance than the teacher group yet significantly outperformed the teacher group in post-test scores. Effect size analysis showed a large effect of ChatGPT feedback (η²=0.772) and a small effect of teacher feedback (η²=0.040). Criterion-level analyses indicated that the ChatGPT group improved significantly across all four IELTS rubric components (task response, cohesion and coherence, lexical resource, grammatical range and accuracy), whereas the teacher group showed significant gains only in task response and grammatical range and accuracy. The authors conclude that ChatGPT-generated direct WCF can be more effective than human teacher direct WCF in this Chilean EFL context and suggest that ChatGPT can be integrated as a complementary tool to support WCF processes and reduce teacher workload, while cautioning that AI feedback should be used critically and not as a full replacement for teacher input."
	},
	"Outcome": {
		"application_effectiveness_overview (应用效果总体评价与测量工具)": "Using the IELTS Writing Task 2 rubric to score pre-test (T1) and post-test (T4) essays, the study found that both feedback conditions enhanced L2 opinion essay writing, but ChatGPT-generated direct WCF led to statistically significant and larger gains in writing performance compared with teacher-generated direct WCF. ChatGPT feedback significantly improved overall IELTS scores and all rubric dimensions, whereas teacher feedback produced smaller and partly non-significant improvements, indicating superior effectiveness of the AI-based feedback in this intervention.",
		"writing_performance_measure (写作表现测量工具_量表或评分标准)": "IELTS Writing Task 2 rubric with four criteria: task response, cohesion and coherence, lexical resource, and grammatical range and accuracy; each criterion rated on a 0–9 scale, with the overall task score being the average of the four criterion scores.",
		"writing_performance_focus (写作表现关注维度_流利度_准确性_复杂度_体裁等)": "Task response (relevance and completeness of addressing the prompt), cohesion and coherence (organization and logical flow), lexical resource (vocabulary range and appropriateness), and grammatical range and accuracy (variety and correctness of grammatical structures).",
		"affective_aspect_measure (情感因素测量工具_问卷_量表等)": "NA",
		"affective_aspect_focus (情感因素维度_动机_态度_焦虑_自效感等)": "NA",
		"cognitive_aspect_measure (认知因素测量工具)": "NA",
		"cognitive_aspect_focus (认知因素维度_策略使用_元认知监控等)": "NA",
		"behavioral_aspect_measure (行为因素测量工具_日志_平台日志等)": "NA",
		"behavioral_aspect_focus (行为因素维度_使用频率_交互模式_坚持度等)": "NA",
		"other_outcomes_measure (其他结果测量工具)": "Friedman tests of rubric component scores across four tasks within each group; no other quantitative instruments or qualitative measures were employed.",
		"other_outcomes_focus (其他结果维度说明)": "Within-group changes over time in each of the four rubric criteria (task response, cohesion and coherence, lexical resource, grammatical range and accuracy) across T1, T2, T3, and T4, revealing that the ChatGPT group significantly improved on all criteria while the teacher group did so only for task response and grammatical range and accuracy.",
		"assessment_timepoints (评估时间点_前测_后测_延迟测等)": "Pre-test at T1, intermediate tasks at T2 and T3 with feedback cycles, and post-test at T4; no delayed follow-up assessments beyond the four tasks.",
		"primary_outcome_variables (主要结果变量_因变量)": "IELTS overall writing score (average of the four rubric criteria) for each essay; band scores for each of the four rubric criteria; pre–post change in overall score and criterion-level scores within each group; rank-based group differences in pre-test and post-test scores.",
		"independent_variables_and_factors (自变量与实验因素)": "Feedback source (ChatGPT direct WCF vs human teacher direct WCF) as the main between-group factor; time or task (T1–T4) as a within-group factor in the Friedman tests; analysis also considered each rubric criterion as a separate outcome within groups.",
		"followup_length_and_type (随访时长与类型)": "NA",
		"statistical_significance (统计显著性结果摘要)": "Within-group Wilcoxon Signed-Rank tests: G1_Chat showed significant improvement from pre-test to post-test (z=-3.928, p<0.001), while G2_Teacher did not show a significant pre–post difference (z=-0.898, p=0.369). Between-group Mann–Whitney U tests: at pre-test the teacher group significantly outperformed the ChatGPT group (U=30.5, z=-4.77, p<0.001), but at post-test the ChatGPT group significantly outperformed the teacher group (U=299, z=1.99, p=0.0468). Friedman tests: in G1_Chat significant differences across tasks were found for all four criteria (task response, cohesion and coherence, lexical resource, grammatical range and accuracy; chi-square values between 39.175 and 51.486, df=3, p<0.001 for all), whereas in G2_Teacher significant differences across tasks were found only for task response (chi-square=9.268, p=0.026) and grammatical range and accuracy (chi-square=14.337, p=0.002), but not for cohesion and coherence or lexical resource.",
		"effect_size_summary (效应量摘要)": "Eta squared for the Wilcoxon tests indicated a large effect of ChatGPT feedback on writing scores (G1_Chat η²=0.772) and a small effect of teacher feedback (G2_Teacher η²=0.040), suggesting that the ChatGPT intervention had a much stronger impact on writing development than the teacher feedback in this study; effect sizes for the Mann–Whitney and Friedman tests were not separately reported but the strong significance of the ChatGPT group’s Friedman results supports a substantial practical effect across all rubric dimensions.",
		"llm_misuse_or_negative_effects (LLM滥用或负向效应)": "While the study did not empirically document misuse of ChatGPT by participants, the literature review and discussion highlight several potential negative effects and risks associated with ChatGPT: the possibility of biased, inappropriate, or discriminatory content due to mono-cultural training data; generation of inaccurate or misleading information; limited ability to grasp subtle cultural nuances and complex concepts; the need for AI literacy and prompt design competencies; and ethical concerns about academic integrity, including plagiarism and cheating. The authors also note that overreliance on AI feedback may hinder the development of independent critical thinking and higher-order skills, and they stress the importance of guiding students to critically evaluate AI-generated feedback rather than accepting it passively.",
		"equity_and_subgroup_effects (公平性与亚组差异)": "No quantitative subgroup analyses by gender, socioeconomic status, or other demographic variables were reported. However, the authors discuss equity-related concerns in terms of ChatGPT’s mono-cultural orientation and the potential for reinforcing stereotypes and discriminatory representations, particularly in underrepresented educational contexts such as Chile. They emphasize that AI training data may not adequately reflect local cultural realities and that educators should help students critically evaluate AI feedback to mitigate possible biases.",
		"limitation (研究局限)": "The authors acknowledge several limitations: the brief period of feedback exposure and the short-term focus on a single pre–post cycle of four tasks; the use of only one genre (IELTS-style opinion essays), limiting generalisability to other writing genres; inability to fully control students’ external exposure to English outside the course; lack of mixed-methods data such as student perceptions or detailed content analysis of teacher versus AI feedback; inherent variability in ChatGPT’s responses even when using the same prompt, device, and session procedure; non-equivalence of groups at pre-test despite similar CEFR bands; and the limited sample drawn from a single institution, which restricts generalization.",
		"challenge (实施挑战与风险)": "Implementation challenges and risks discussed include the difficulty of ensuring consistent and comparable ChatGPT output despite inherent stochastic variability, the need to design clear and effective prompts to align AI feedback with pedagogical goals, managing baseline differences between groups in quasi-experimental classroom settings, controlling for external factors such as additional exposure to English, addressing cultural bias and contextual inaccuracies in AI feedback, and preparing teachers and students to critically use AI feedback so that it supports rather than undermines long-term L2 learning and academic integrity.",
		"future_work (未来研究方向)": "The authors recommend longer-term longitudinal studies to examine the sustained effects of ChatGPT versus teacher feedback across multiple writing cycles, mixed-method research including learners’ perceptions, feedback uptake processes, and content analysis of feedback quality, studies that compare ChatGPT’s effectiveness across a wider range of writing genres and tasks, investigations into the role of task type and context in moderating AI feedback effectiveness, and work on developing AI literacy for both teachers and students, including training in designing purposeful prompts and critically engaging with AI-generated feedback.",
		"implication (理论与教学实践启示)": "The findings suggest that ChatGPT-generated direct written corrective feedback can be a powerful complement to teacher feedback in EFL writing instruction, capable of supporting both lower-order aspects (lexical resource, grammatical range and accuracy) and higher-order aspects (task response, cohesion and coherence) of opinion essay writing. Pedagogically, integrating ChatGPT into WCF practices could alleviate teachers’ workload, allow more frequent and consistent feedback, and enable more writing tasks within existing time constraints, especially in large EFL classes. However, the authors emphasize that AI feedback should complement rather than replace teacher feedback and that educators must frame AI use within a cautious, informed, and ethical approach that fosters AI literacy, critical evaluation of AI output, and attention to long-term L2 learning rather than only short-term writing performance."
	},
	"Study Quality and Reporting": {
		"funding_source (经费来源)": "Funded by the National Agency for Research and Development (ANID) Chile, Fondecyt Iniciacion grant 11230546, and by FDD-UBB, Chile, project FDD2024-24.",
		"conflict_of_interest (利益冲突声明)": "The authors state that they have nothing to declare and do not report any commercial or financial relationships that could be construed as a potential conflict of interest.",
		"risk_of_bias_randomization (偏倚风险_分配与随机化)": "Section-level random assignment of intact classes to ChatGPT and teacher feedback conditions was used, but there was no individual-level randomization; Mann–Whitney tests indicated significant baseline differences in pre-test performance between the groups, with the teacher group initially outperforming the ChatGPT group, indicating potential selection bias and non-equivalent groups at baseline.",
		"risk_of_bias_blinding (偏倚风险_盲法)": "Blinding was not reported. Students knew whether feedback came from ChatGPT or a teacher, the teacher providing WCF knew the condition for the teacher group, and researchers generating AI feedback were aware of the experimental design. It is not specified whether those assigning rubric scores were blinded to group membership, so performance and detection bias cannot be ruled out.",
		"attrition_and_missing_data (流失与缺失数据处理)": "The study reports 44 participants and uses this number in the analyses; no attrition, dropout, or missing data procedures are described, suggesting that all participants completed the study but without explicit confirmation.",
		"reporting_transparency (报告透明度与可重复性)": "The article provides detailed descriptions of participants, proficiency levels, course context, writing tasks, timing, rubric criteria, feedback procedures, and ChatGPT prompting instructions, including sample teacher and ChatGPT feedback in appendices. Statistical methods and key results (test statistics, p-values, eta squared) are reported in tables. Limitations and potential sources of bias are discussed. However, inter-rater reliability for scoring and some implementation details, such as who scored essays in the AI group, are not reported.",
		"preregistration_or_protocol (预注册或研究方案)": "NR",
		"llm_version_reproducibility (LLM版本与可复现性)": "The study explicitly identifies the use of ChatGPT GPT-4o and describes the prompt design, role assignment, targeted rubric criteria, and error types; a separate chat session was used for each essay with the same prompt, device, and procedure. The authors note that some variability in ChatGPT’s output is inherent and beyond researchers’ control, so while the AI configuration is partly documented, exact replication of all AI responses is not guaranteed.",
		"baseline_equivalence (基线等同性检验)": "Baseline equivalence was examined using a Mann–Whitney U test, which showed a statistically significant pre-test difference in favor of the teacher feedback group (U=30.5, z=-4.77, p<0.001), indicating that the ChatGPT group had lower initial writing performance despite all participants being classified within the high A2 to low B1 CEFR band.",
		"assumption_check_and_data_diagnostics (统计假设检验与数据诊断)": "Shapiro–Wilk tests were conducted for pre-test and post-test scores in both groups and indicated normal distributions (p>0.05). Levene’s test for equality of variances showed lack of homogeneity for pre-test scores (p=0.048), leading the authors to adopt non-parametric tests (Wilcoxon Signed-Rank, Mann–Whitney U, and Friedman) for inferential analysis. No additional diagnostics such as residual analyses were reported.",
		"outlier_treatment_and_sensitivity_analysis (异常值处理与稳健性分析)": "NR",
		"data_preprocessing_and_transformation (数据预处理与转换)": "Raw IELTS rubric scores for each essay and criterion were computed and used to calculate overall writing scores; non-parametric analyses were applied to these scores without reported transformations. Descriptive statistics, normality tests, and rank-based statistics were computed in Python using SciPy and statsmodels; no additional data preprocessing or transformations were described."
	}
}