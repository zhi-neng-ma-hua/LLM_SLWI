{
	"Basic Identification": {
		"author (作者)": "Da “Alex” Yan",
		"publication_year (发表年份)": "2024",
		"study_region (研究地区)": "China (one Chinese university)",
		"journal_name (期刊名称)": "Language Learning & Technology",
		"study_type (研究类型_期刊论文_会议论文等)": "Peer-reviewed journal article reporting a 7-week randomized mixed-design classroom experiment",
		"doi_or_identifier (DOI或唯一标识)": "https://hdl.handle.net/10125/73597",
		"research_aims (研究目的与问题)": "To explore the effects of individual versus collaborative processing of ChatGPT-generated automated feedback on L2 English writing; specifically, to compare how teacher-scaffolded, peer-scaffolded, and teacher-plus-peer-scaffolded collaborative processing of ChatGPT feedback affect students’ L2 writing task improvement (gain from draft to final for three during-intervention tasks) and L2 writing learning (development of draft scores across intervention tasks and a delayed new writing task) relative to individual feedback processing.",
		"research_gap_or_novelty (研究创新性与知识空白)": "Addresses the paucity of research on the use of ChatGPT for automated feedback in authentic classroom-based L2 writing settings; connects ecological and learner-centered perspectives on feedback with practice of automated feedback, which has predominantly focused on feedback provision rather than processing; moves beyond prior AWE studies and pretest–posttest designs by examining longitudinal developmental trajectories and the transferability of gains from ChatGPT-generated feedback under different feedback processing modes."
	},
	"Participant Information": {
		"educational_level (教育阶段)": "University undergraduates, second-year (sophomore) EFL students",
		"language_proficiency (语言熟练度水平)": "Relatively high-proficiency EFL learners; only students with L2 proficiency scores higher than 76.4/100 on a CSE-based assessment (approximately CSE level 4–5, around CEFR B1) were recruited; students had learned English for an average of 10.2 years.",
		"mother_tongue (母语)": "Chinese",
		"sex (性别)": "NR",
		"age (年龄)": "Mean age = 19.9 years.",
		"learning_context (学习语境_ESL_EFL_ELL等)": "EFL context in a Chinese university English program",
		"target_language (目标语言)": "English (L2)",
		"discipline (学科背景)": "EFL program; compulsory course Intermediate English Writing",
		"prior_experience_llm (既有LLM使用经验)": "NR (a 10-point survey measured perceived usefulness, curiosity, intention to use GenAI, and joy, but prior ChatGPT/LLM use experience was not reported)."
	},
	"Methodology": {
		"research_design (研究设计_实验_准实验_纵向等)": "Seven-week randomized controlled experiment with a 4 (group: individual processing, teacher-scaffolded, peer-scaffolded, teacher-plus-peer-scaffolded) by 3 or 4 (writing task) mixed design, including three during-intervention writing tasks and one delayed new task.",
		"research_method (研究方法_定量_定性_混合)": "Quantitative experimental study with repeated-measures mixed ANOVA analyses.",
		"sampling_method (抽样方法)": "From a pool of 283 sophomore EFL students in one Chinese university, 117 Chinese L1 learners were purposively recruited based on (a) responses to a 10-point survey (perceived usefulness, curiosity, intention to use GenAI, joy) and (b) scores above 76.4/100 on a CSE-based proficiency assessment; the selected students were then randomly assigned to four groups.",
		"sample_size_and_effect (样本量及效应量)": "Total N=117 sophomore EFL learners; groups: individual processing (IP, n=28), teacher-scaffolded (TS, n=29), peer-scaffolded (PS, n=29), teacher-plus-peer-scaffolded (TPS, n=31). For L2 writing task improvement (gain scores for T1–T3), mixed ANOVA showed a significant main effect of group (F(3,113)=44.61, p<.001, partial eta squared≈0.542, large), a significant main effect of task (F(2,226)=5.79, p=.004, partial eta squared≈0.049, small), and a significant group×task interaction (F(6,226)=2.78, p=.013, partial eta squared≈0.069, small). For L2 writing learning (draft scores across T1–T3 and NT), mixed ANOVA showed a significant main effect of group (F(3,113)=37.75, p<.001, partial eta squared≈0.501, large), a significant main effect of task (F(3,339)=21.25, p<.001, partial eta squared≈0.158, medium), and a significant group×task interaction (F(9,339)=3.91, p<.001, partial eta squared≈0.094, small). Pairwise comparisons indicated that the IP group showed significantly larger task improvement than collaborative groups in each task (e.g., IP vs TS on T3 improvement p<.001, Cohen’s d≈0.71), whereas collaborative groups, especially those with teacher involvement (TS, TPS), significantly outperformed IP on draft scores for all tasks (e.g., TPS vs IP on NT draft p<.001, d≈0.66); TS showed significant draft-score growth from T1 to T3 (p<.001, d≈0.61 in absolute value).",
		"theoretical_foundation (理论基础_理论框架)": "Grounded in research on automated writing evaluation and automated feedback, the New Feedback Paradigm and ecological perspectives that conceptualize feedback as a socioculturally situated process; draws on Vygotskian sociocultural theory including scaffolding by more knowledgeable ones and Zone of Proximal Development; follows Villamil and Guerrero’s framework of feedback as a situated phenomenon shaped by agent interactions; informed by work on automated feedback processing and by arguments that feedback should promote both immediate task performance and long-term learning; situates ChatGPT-based feedback within a human-centered, sociocultural ecology.",
		"data_collection_instrument (数据收集工具)": "Selection instruments: 10-point survey measuring perceived usefulness, curiosity, intention to use GenAI, joy; CSE-based language proficiency assessment. Writing tasks: three during-intervention tasks (T1–T3) and one delayed new-topic task (NT) selected from official College English Test Band 6 (CET-6) writing prompts via expert panel. Writing assessment: Hedgcock and Lefkowitz (1992) 100-point analytic essay rating scale with five dimensions (content, organization, grammar, vocabulary, mechanics).",
		"data_collection_validity_reliability (工具信度与效度)": "Writing prompts were selected through a three-round process by a panel of three veteran teachers and two assessment experts: clustering by topic and familiarity, Delphi ratings of difficulty on a 10-point scale, and collaborative selection of prompts with similar difficulty; CET-6 tasks target core writing competencies of idea expression, discourse organization, language usage, and strategy use. All writing products (drafts and finals for T1–T3, drafts for NT) were rated by four raters using the Hedgcock and Lefkowitz analytic scale under a double-blind mechanism (no participant identity or group information); interrater reliability was acceptable with Fleiss’s kappa≈0.84 (95% CI≈[0.76, 0.93]). Reliability indices for the selection survey and proficiency test were not reported.",
		"data_analysis_method (数据分析方法)": "Analyses conducted in R 4.1; standard diagnostic tests used to verify statistical assumptions. Sphericity was assessed with Mauchly’s test, and Greenhouse–Geisser corrections were applied when violated. For RQ1, a 4×3 mixed ANOVA was conducted on L2 writing task improvements (gain scores, final minus draft) with group as between-subjects factor and task (T1–T3) as within-subjects factor. For RQ2, a 4×4 mixed ANOVA was conducted on L2 writing learning (draft scores) with group as between-subjects factor and task (T1–T3 drafts and NT draft) as within-subjects factor. Bonferroni corrections were used for post-hoc pairwise comparisons; partial eta squared quantified ANOVA effect sizes, and Cohen’s d was used for pairwise comparisons with interpretation guided by thresholds from Plonsky and Oswald and Gignac and Szodorai.",
		"unit_of_analysis (分析单位)": "Individual student",
		"group_assignment_method (组别分配方式_随机_非随机等)": "After eligibility screening, participants were randomly assigned to four conditions: individual processing (IP, control group), teacher-scaffolded (TS), peer-scaffolded (PS), and teacher-plus-peer-scaffolded (TPS).",
		"power_analysis (功效分析与样本量论证)": "NR",
		"sampling_frame_and_representativeness (抽样框与样本代表性)": "Sampling frame comprised sophomore EFL students enrolled in a compulsory Intermediate English Writing course at a single Chinese university; all participants were Chinese-speaking learners with relatively homogeneous L2 competence and prior L2 experiences, which the author notes restricts generalizability but simplifies training and implementation in this early-stage classroom study of ChatGPT.",
		"scoring_procedure_and_rater_training (评分流程与评分者培训)": "Four raters, who were also involved in classroom instruction and scaffolding, rated all essays using the Hedgcock and Lefkowitz analytic scale under a double-blind mechanism where student identity and group assignment were concealed; interrater reliability was acceptable with Fleiss’s kappa≈0.84 (95% CI≈[0.76, 0.93]); specific details of rater training procedures beyond raters’ expertise as L2 instructors and assessment specialists were not reported."
	},
	"Intervention": {
		"duration (干预时长与频率)": "Seven-week experiment with three writing-and-revision cycles (weeks 2, 5, 7) and a delayed new-topic test three weeks after the experiment. In training weeks, students had two 45-minute sessions on ChatGPT usage and two self-paced practice sessions; in writing-and-revision weeks, students used one 45-minute session for draft writing, two sessions for feedback seeking and processing with ChatGPT, and one session for revising and finalizing each task (T1–T3).",
		"llm_model_type (LLM模型类型_如ChatGPT_GPT4_Gemini等)": "ChatGPT (GPT-3.5, OpenAI)",
		"llm_model_configuration (LLM模型配置与版本_API_网页_参数等)": "Official GPT-3.5 version of ChatGPT accessed via a client-side proxy application with whitelist configuration that redirected only traffic to the official ChatGPT service through an overseas proxy server due to access restrictions in mainland China; GPT-3.5 was chosen instead of GPT-4 because benchmark tests showed similar automated corrective feedback capabilities, added GPT-4 features (e.g., multimodal processing) were not needed for writing evaluation, and GPT-3.5 was freely accessible whereas GPT-4 required subscription; access occurred through a browser-like chat interface, not via API, with no additional parameter settings reported.",
		"llm_integration_mode (LLM整合模式_直接使用_教师中介_系统嵌入)": "Students directly interacted with ChatGPT as a standalone online chatbot in computer labs; ChatGPT was not embedded in an LMS or other writing platform. All groups used ChatGPT to obtain automated feedback on their individual drafts for tasks T1–T3, and differences across conditions concerned only how feedback was subsequently processed (individually vs collaboratively with teachers and/or peers).",
		"prompting_strategy (提示策略_提示工程与使用方式)": "All participants were trained and required to use a uniform prompting pattern: each prompt followed a ‘feedback requirement + rating criteria + essay’ structure, with the essay component omitted in continued context-informed turns. Training provided recommendations on designing feedback requirements and rating criteria. Students were encouraged to engage in multi-turn trial-and-error prompting to improve feedback quality, deciding and modifying prompt components based on the ongoing human–ChatGPT dialogue and the quality of obtained automated feedback messages.",
		"training_support_llm_literacy (LLM素养与提示培训)": "All 117 student participants received systematic training on ChatGPT usage and prompting, including two 45-minute training sessions and two self-paced practice sessions per week during learning weeks, where they replicated teacher-modeled examples and learned a standard, replicable workflow for using ChatGPT in L2 writing. Six EFL teachers were also trained in strategies for using ChatGPT for automated feedback and in offering scaffolding, including teaching students to use the standard workflow, preparing and providing modeling of ChatGPT use in L2 writing classrooms, and guiding students in refining prompts and critically processing AI feedback.",
		"intervention_implementation (干预实施流程_步骤与任务)": "All sessions were held in computerized language laboratories with access to ChatGPT and supplementary digital language learning resources (dictionaries, thesaurus, L2 corpus, automated essay grading), which were used only as facilitators for teacher and peer scaffolding, not as alternative feedback sources. For each of three intervention tasks (T1–T3): students individually wrote a draft in English; used ChatGPT with the standardized prompting pattern to obtain automated feedback; processed that feedback according to their assigned processing mode (IP, TS, PS, TPS); and then individually revised their drafts to produce final products. During processing, experimental groups could collaborate with teachers and/or peers, whereas the control group processed feedback alone. Three weeks after the experiment, all students wrote an individual delayed new-topic draft (NT) as a retention measure; collaborative feedback processing for NT was not described.",
		"experimental_group_intervention (实验组干预内容)": "Teacher-scaffolded group (TS): Students used ChatGPT-generated automated feedback and processed it with teacher scaffolding; teachers provided modeling for the whole group, responded to students’ calls for help during writing and revision, and replied to inquiries via real-time communication platforms (e.g., WeChat, Tencent Meeting), focusing on strategies for further prompting ChatGPT to clarify and improve feedback, appreciating and potentially applying automated feedback messages, and validating and rectifying feedback that was ambiguous or incorrect. Peer-scaffolded group (PS): Students used ChatGPT-generated feedback and processed it collaboratively in 4–5 member subgroups, using real-time communication tools and collaborative office suites (e.g., Shimo Docs, Nutstore Docs) to discuss feedback; most peer collaboration occurred via comment threads on collaborative writing sites. Teacher-plus-peer-scaffolded group (TPS): Students combined teacher scaffolding and peer collaboration in processing ChatGPT feedback, with teachers providing the same types of scaffolding as in TS and students working in peer subgroups as in PS; in all experimental groups, final revisions were executed individually after collaborative processing.",
		"control_group_intervention (对照组干预内容)": "Individual processing group (IP): Students used ChatGPT to seek automated feedback on their drafts using the same standardized prompting pattern but were required to process the feedback individually and self-regulate their use of it; peer collaboration during feedback processing was explicitly prohibited. Two in-class teachers were present only to provide technical support and did not scaffold the interpretation or application of ChatGPT feedback. Drafts were revised individually based solely on students’ own processing of the AI feedback.",
		"writing_stage (写作阶段_如生成_修改_反馈_重写等)": "Focus on revision-related stages: initial drafting of essays; seeking and receiving automated feedback from ChatGPT; processing feedback (comprehending, evaluating, integrating) individually or collaboratively; and revising drafts to produce final products. All drafts (T1–T3 and NT) were written individually; collaboration occurred only during feedback processing for T1–T3, not during drafting or finalization.",
		"writing_genre (写作体裁)": "Short EFL examination-style essays (150–200 words) based on CET-6 writing tasks, including opinion essays on general social issues, descriptions of charts or pictures, and expository/discussion-type writing based on outlines or visual aids.",
		"writing_task_type (写作任务类型)": "Timed individual English essay tasks adapted from College English Test Band 6 (CET-6) prompts for T1–T3 and NT, targeting general-topic argumentation and description of graphic information.",
		"role_llm (LLM角色_如生成文本_给反馈_评分_对话等)": "ChatGPT functioned as a generative automated feedback provider, supplying automated feedback on student drafts including grammatical error detection and correction suggestions, metalinguistic hints, and broader comments according to the feedback requirement and rating criteria given in prompts; the interaction was multi-turn, iterative, and dialogic. ChatGPT did not perform scoring; all scoring was done by human raters.",
		"role_instructor (教师角色与介入方式)": "Six EFL teachers were recruited and trained; they served as in-class teachers, coordinators, and raters. In the TS and TPS conditions, teachers provided modeling for using ChatGPT, face-to-face and on-demand scaffolding during writing and revision sessions, guidance on feedback seeking strategies, interpretation and critical appraisal of ChatGPT-generated feedback, suggestions for re-prompting ChatGPT to clarify or improve feedback, and approaches to validate or rectify AI messages; they also responded to students’ questions via real-time online communication platforms. In the PS condition, teachers supported peer collaboration indirectly through initial training; in the IP condition, teachers provided only technical support without engaging in feedback processing. Teachers also rated writing products using the analytic scale under a double-blind procedure.",
		"setting (教学情境_学校类型_课程类型_线上线下)": "Face-to-face instruction in computerized language laboratories at a Chinese university; compulsory Intermediate English Writing course in an EFL program; ChatGPT accessed via proxy from within the university network; collaborative processing conducted in-class and through online communication tools.",
		"ethical_consideration (伦理审查与知情同意)": "Written informed consent was obtained from all student participants, who were informed of the project’s purpose, design, procedures, anonymity policies, and their rights to voluntary participation and unconditional withdrawal. To ensure educational equity, non-participants in the same course received post-project training on the use of ChatGPT for automated feedback and followed the same instructional procedures and assessment tasks but were required to use self/peer assessment or pre-LLM automated feedback providers such as Grammarly for revisions.",
		"llm_access_policy (LLM使用规范_允许与限制)": "Only official ChatGPT (GPT-3.5) accessed via a controlled proxy with whitelist configuration was permitted as the automated feedback source; third-party AI applications were intentionally avoided due to risks of manipulated responses or questionable information sources. For T1–T3, all participants had to use ChatGPT-generated automated feedback to inform revisions, while other tools (e.g., dictionaries, corpora, other AWE tools) served only to support teacher and peer scaffolding. In the IP condition, peer collaboration during feedback processing was prohibited; in experimental conditions, collaboration was structured as teacher-scaffolded, peer-scaffolded, or teacher-plus-peer-scaffolded.",
		"llm_safety_guardrails (LLM安全与内容过滤设置)": "Technical safeguards included using a proxy with a whitelist that redirected only to the official ChatGPT service to avoid unverified or manipulated AI sources. Pedagogical guardrails were provided via teacher training and scaffolding: teachers were instructed to help students critically interpret ChatGPT feedback, prompt for clarification or improvement, and validate and rectify automated messages when ambiguities or false information were detected; the study discusses potential harms such as hallucinated information, blind reliance on AI, and plagiarism but does not describe additional automated content filters or explicit moderation settings.",
		"key_findings (主要研究发现_与LLM写作干预相关)": "For L2 writing task improvement (gain from draft to final for T1–T3), the individual processing group (IP) that processed ChatGPT feedback alone exhibited the largest and steadily increasing task improvements across tasks, significantly outperforming all collaborative processing groups in gain scores. However, for L2 writing learning (development of draft scores across T1–T3 and the delayed NT task), collaborative processing groups (TS, PS, TPS) significantly outperformed the IP group on all drafts, indicating stronger learning trajectories. Teacher-involved groups (TS and TPS) showed particularly notable longitudinal growth in draft scores; the TS group achieved the most significant improvement in learning from T1 to T3, while TPS also surpassed IP on the delayed NT draft. Among collaborative groups, differences in gain scores were not statistically significant, but teacher involvement tended to enhance learning outcomes relative to peer-only scaffolding. Retention of learning from T3 to NT showed no statistically significant group differences, though experimental groups registered slightly larger effect sizes. Overall, collaborative processing of ChatGPT-generated feedback, especially with teacher scaffolding, promoted more realistic and sustainable L2 writing development, whereas purely individual processing yielded very large but potentially unrealistic task improvements."
	},
	"Outcome": {
		"application_effectiveness_overview (应用效果总体评价与测量工具)": "ChatGPT-generated automated feedback was effective in improving L2 writing performance, but the nature of effectiveness differed by feedback processing mode. When students processed ChatGPT feedback individually, they showed the largest task improvements (gain scores from draft to final) across three intervention tasks. When they processed feedback collaboratively, especially with teacher involvement, they demonstrated stronger learning in terms of draft writing quality across tasks and into a delayed new-topic task. Effectiveness was assessed using analytic ratings on the Hedgcock and Lefkowitz 100-point scale and examined via mixed ANOVAs on gain scores (task improvement) and draft scores (learning trajectories).",
		"writing_performance_measure (写作表现测量工具_量表或评分标准)": "Hedgcock and Lefkowitz (1992) 100-point analytic essay rating scale with five dimensions: content, organization, grammar, vocabulary, mechanics; rated by four raters under a double-blind procedure, with acceptable interrater reliability (Fleiss’s kappa≈0.84, 95% CI≈[0.76, 0.93]).",
		"writing_performance_focus (写作表现关注维度_流利度_准确性_复杂度_体裁等)": "Overall L2 writing quality with emphasis on content richness and relevance, discourse organization, grammatical accuracy, lexical choice, and mechanics; outcome measures distinguished between during-intervention task improvement (gain from draft to final products for T1–T3) and longer-term learning (development and retention of draft writing quality from T1 through T3 to the delayed NT task).",
		"affective_aspect_measure (情感因素测量工具_问卷_量表等)": "NA",
		"affective_aspect_focus (情感因素维度_动机_态度_焦虑_自效感等)": "NA",
		"cognitive_aspect_measure (认知因素测量工具)": "Analytic scores on the Hedgcock and Lefkowitz 100-point scale for drafts and final products of T1–T3 and drafts of NT; cognitive outcomes operationalized as gain scores (final minus draft) for each during-intervention task and sequences of draft scores across T1–T3 and NT.",
		"cognitive_aspect_focus (认知因素维度_策略使用_元认知监控等)": "Focus on L2 writing task improvement (extent to which students improved their writing between draft and final after processing ChatGPT feedback) and L2 writing learning (progression of draft writing quality across multiple tasks and retention into a delayed new task); the study discusses but does not directly measure underlying metacognitive and strategic processes during feedback processing.",
		"behavioral_aspect_measure (行为因素测量工具_日志_平台日志等)": "NR",
		"behavioral_aspect_focus (行为因素维度_使用频率_交互模式_坚持度等)": "NR",
		"other_outcomes_measure (其他结果测量工具)": "NA",
		"other_outcomes_focus (其他结果维度说明)": "NA",
		"assessment_timepoints (评估时间点_前测_后测_延迟测等)": "For each during-intervention writing task (T1, T2, T3): draft writing scores and final product scores, with task improvement calculated as final minus draft. For learning: draft scores at four timepoints, namely T1 draft, T2 draft, T3 draft, and a delayed new-topic draft (NT) written three weeks after the experiment.",
		"primary_outcome_variables (主要结果变量_因变量)": "L2 writing task improvement defined as gain scores (final minus draft) for tasks T1–T3; L2 writing learning defined as draft scores for T1–T3 and NT.",
		"independent_variables_and_factors (自变量与实验因素)": "Primary independent variable was feedback processing mode with four levels (individual processing, teacher-scaffolded processing, peer-scaffolded processing, teacher-plus-peer-scaffolded processing). Within-subjects factor was writing task, with three levels (T1, T2, T3) for task improvement analyses and four levels (T1, T2, T3, NT) for learning analyses.",
		"followup_length_and_type (随访时长与类型)": "Three-week delayed post-intervention follow-up; all students completed a new-topic draft (NT) without the described collaborative feedback processing, used to assess retention and transfer of L2 writing learning.",
		"statistical_significance (统计显著性结果摘要)": "Task improvement (gain scores): mixed ANOVA showed a significant main effect of group (F(3,113)=44.61, p<.001) and task (F(2,226)=5.79, p=.004), and a significant group×task interaction (F(6,226)=2.78, p=.013). Post-hoc comparisons indicated that the individual processing group (IP) had significantly larger task improvements than each collaborative group (TS, PS, TPS) for T1 and T2 and also larger improvements for T3, with no significant differences in gain scores among the three collaborative groups and no significant within-group growth in gain scores among collaborative groups over time; the IP group, however, showed significant growth in task improvement from T2 to T3 (p=.01, small d≈0.29). Learning (draft scores): mixed ANOVA showed a significant main effect of group (F(3,113)=37.75, p<.001), task (F(3,339)=21.25, p<.001), and group×task interaction (F(9,339)=3.91, p<.001). Pairwise comparisons showed that all three collaborative groups (TS, PS, TPS) significantly outperformed the IP group on draft scores for all tasks, including NT (e.g., TPS vs IP on NT draft p<.001), while differences among TS, PS, and TPS were mostly non-significant except that TS initially lagged PS and TPS on T1 and TPS significantly surpassed TS on T2 (p=.02). TS and TPS groups showed significant improvements in draft scores from T1 to T3 (e.g., TS T1–T3 p<.001), whereas retention of learning from T3 to NT did not show statistically significant differences for any group.",
		"effect_size_summary (效应量摘要)": "For task improvement, the main effect of group had a large partial eta squared (≈0.542), indicating that feedback processing mode explained a substantial portion of variance in gain scores; the main effect of task had a small partial eta squared (≈0.049), and the group×task interaction had a small partial eta squared (≈0.069). For learning, the main effect of group had a large partial eta squared (≈0.501), the main effect of task had a medium partial eta squared (≈0.158), and the group×task interaction had a small partial eta squared (≈0.094). Pairwise Cohen’s d values indicated that IP’s advantage in task improvement over collaborative groups was medium to large in some cases (e.g., IP vs TS on T3 improvement d≈0.71), whereas collaborative groups’ advantage over IP in learning outcomes was small to medium (e.g., TPS vs IP on NT draft d≈0.66; TS draft-score growth from T1 to T3 d≈0.61 in absolute magnitude).",
		"llm_misuse_or_negative_effects (LLM滥用或负向效应)": "The study notes that individually processed ChatGPT feedback led to dramatic and consistently large gains in writing task improvement, which may be unrealistic relative to students’ independent drafting abilities and raises ethical concerns about blind or excessive reliance on AI-generated feedback and the authenticity of revised work. The discussion links these concerns to broader critiques of ChatGPT in L2 writing, including risks to academic integrity when learners use AI for effortless completion of tasks, potential decreases in creativity and critical thinking, and the danger of undetectable plagiarism. It also emphasizes risks of false or hallucinated information and blind reliance on AI-based automated feedback without sufficient AI literacy, suggesting that collaborative processing with teacher and peer scaffolding may serve as a coping strategy to mitigate such negative effects.",
		"equity_and_subgroup_effects (公平性与亚组差异)": "All participants were Chinese-speaking L2 English learners from a single university, with relatively homogeneous L2 competence and prior experiences; the author notes that this limits generalizability and calls for replication with more diverse samples. Within the course, equity measures included post-project training for non-participants on using ChatGPT for automated feedback and requiring them to complete the same writing tasks with self/peer assessment or pre-LLM tools such as Grammarly. No statistical subgroup analyses by gender, proficiency bands, or other demographic or socioeconomic factors were reported.",
		"limitation (研究局限)": "All participants were Chinese-speaking sophomore EFL learners from a single university with homogenous proficiency and learning backgrounds, limiting the generalizability of findings; the study used GPT-3.5 with a uniform prompting pattern, which may have constrained the quality and diversity of feedback and did not examine effects of newer LLM versions or varied prompting designs; the research relied solely on quantitative methods and did not include qualitative or mixed-method analyses of human–AI and peer interaction patterns during feedback processing; the time frame was relatively short, and only one delayed test was used, which may under-represent longer-term L2 writing development; the study did not analyze the textual content, accuracy, or types of ChatGPT feedback messages themselves, limiting insight into which feedback characteristics impacted outcomes.",
		"challenge (实施挑战与风险)": "Practical challenges included configuring secure and authentic access to the official ChatGPT service from mainland China via an overseas proxy while avoiding unreliable third-party applications; providing sufficient training for both teachers and students to use a standardized yet flexible prompting workflow; coordinating teacher scaffolding and peer collaboration across multiple conditions while keeping all other pedagogical variables constant; ensuring that only ChatGPT-generated automated feedback was used for revision while additional tools remained auxiliary; preserving double-blind rating when raters were also instructors; and managing ethical and pedagogical risks of overly impressive task improvements from individual ChatGPT use, including concerns about academic integrity, hallucinated or inaccurate AI feedback, and blind reliance on automated feedback without sufficient critical evaluation.",
		"future_work (未来研究方向)": "Future studies are encouraged to replicate the experiment with more diverse learner populations in different institutions and contexts to test generalizability; to experiment with multiple prompting patterns and updated versions of ChatGPT or other LLMs to assess how changes in model capabilities and prompt designs affect automated feedback and learning outcomes; to adopt qualitative or mixed-method research approaches to explore interactional patterns in human–AI and peer communication during feedback seeking and processing; and to conduct longer-term longitudinal research to trace L2 writing development and the cumulative effects of ChatGPT-generated automated feedback over extended periods.",
		"implication (理论与教学实践启示)": "The results support a human-centered, sociocultural view of ChatGPT-based automated feedback in L2 writing: the way learners process AI feedback is crucial, and collaborative processing in an ecology involving teachers, peers, and technology appears to promote more sustainable learning than isolated individual use. The study suggests that teachers should integrate ChatGPT-generated feedback into teacher-led and peer-supported classroom activities that foster critical evaluation, knowledge co-construction, and realistic application of AI outputs. Teacher involvement remains essential for supporting students’ inner feedback processes and higher-order thinking, even as AI alleviates some workload in feedback provision. Pedagogically, a more inclusive feedback ecology combining ChatGPT with teacher and peer scaffolding is recommended to harness AI affordances while mitigating risks such as blind reliance, hallucinations, and academic integrity violations."
	},
	"Study Quality and Reporting": {
		"funding_source (经费来源)": "Young Researcher Program of Xinyang Agriculture and Forestry University [QN2022049]; Xinyang Philosophy and Social Sciences Planning Project [2024JY029].",
		"conflict_of_interest (利益冲突声明)": "NR",
		"risk_of_bias_randomization (偏倚风险_分配与随机化)": "Students meeting inclusion criteria were randomly assigned to four feedback processing conditions (IP, TS, PS, TPS), which mitigates selection bias; details on randomization procedures (e.g., method, blocking) and checks for group equivalence at baseline were not reported.",
		"risk_of_bias_blinding (偏倚风险_盲法)": "A double-blind rating mechanism was implemented: raters did not know student identities or group assignments when scoring essays. Participants and instructors necessarily knew their assigned processing modes (individual vs collaborative), so participant and instructor blinding was not possible; the study does not report whether data analysis was blinded to group labels.",
		"attrition_and_missing_data (流失与缺失数据处理)": "The study reports recruiting 117 participants from 283 candidates and describes the seven-week experiment plus delayed test, but does not report any attrition or missing data patterns during the study or any specific procedures for handling missing scores.",
		"reporting_transparency (报告透明度与可重复性)": "The article provides detailed descriptions of participants, setting, ChatGPT version and access method, prompting pattern, training and scaffolding procedures, writing tasks, rating scale, statistical analyses, and effect sizes. However, it does not explicitly state whether data or analysis code are publicly available.",
		"preregistration_or_protocol (预注册或研究方案)": "NR",
		"llm_version_reproducibility (LLM版本与可复现性)": "The study clearly specifies that it used the official GPT-3.5 version of ChatGPT, accessed via a proxy with whitelist configuration, and explains why GPT-3.5 was chosen over GPT-4. It also standardizes prompting through a defined pattern and training, which supports partial reproducibility, although future changes to the ChatGPT service and model updates may limit exact replication of AI feedback content.",
		"baseline_equivalence (基线等同性检验)": "Baseline equivalence tests across groups (e.g., for initial draft scores or proficiency) were not reported; descriptive statistics for T1 drafts by group are presented but no formal comparisons at baseline are described.",
		"assumption_check_and_data_diagnostics (统计假设检验与数据诊断)": "The author states that standard diagnostic tests were conducted to verify assumptions for mixed ANOVAs; Mauchly’s test was used to assess sphericity, and Greenhouse–Geisser corrections were applied when sphericity was violated. Additional details on normality or homogeneity of variance checks are not provided.",
		"outlier_treatment_and_sensitivity_analysis (异常值处理与稳健性分析)": "NR",
		"data_preprocessing_and_transformation (数据预处理与转换)": "L2 writing task improvement was computed as gain scores by subtracting draft scores from final scores for each during-intervention task (T1–T3). L2 writing learning was operationalized as sequences of draft scores across T1–T3 and NT. These raw scores and gain scores were used directly in mixed ANOVAs with Bonferroni-corrected post-hoc tests; no additional data transformations or complex preprocessing procedures are reported."
	}
}