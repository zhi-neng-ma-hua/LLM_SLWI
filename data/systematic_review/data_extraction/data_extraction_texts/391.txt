{
	"Basic Identification": {
		"author (作者)": "Mona A. Alwasidi, Khaloud S. Al-Khalifah",
		"publication_year (发表年份)": "2025",
		"study_region (研究地区)": "Saudi Arabia",
		"journal_name (期刊名称)": "Journal of Language Teaching and Research",
		"study_type (研究类型_期刊论文_会议论文等)": "Peer-reviewed journal article",
		"doi_or_identifier (DOI或唯一标识)": "https://doi.org/10.17507/jltr.1603.29",
		"research_aims (研究目的与问题)": "To investigate whether integrating ChatGPT into an EFL writing course affects Saudi EFL students’ writing productivity and how ChatGPT as an AI-assistant tool can improve their writing proficiency, focusing on topic sentence construction, supporting details/examples, organization, mechanics, and word count.",
		"research_gap_or_novelty (研究创新性与知识空白)": "Addresses a lack of quantitative, pretest–posttest evidence on ChatGPT’s impact on EFL students’ writing productivity and proficiency, as prior work has been largely qualitative or general and has rarely compared writing done with and without ChatGPT using rubric-based scores and word count in a beginner EFL context."
	},
	"Participant Information": {
		"educational_level (教育阶段)": "First-year undergraduate students",
		"language_proficiency (语言熟练度水平)": "IELTS 4.0–5.5, described as independent, limited, and moderate language users",
		"mother_tongue (母语)": "NR",
		"sex (性别)": "All female (N=52)",
		"age (年龄)": "NR",
		"learning_context (学习语境_ESL_EFL_ELL等)": "EFL in a Saudi university academic writing course with three contact hours per week",
		"target_language (目标语言)": "English (L2)",
		"discipline (学科背景)": "English Language and Literature Department at a Saudi university",
		"prior_experience_llm (既有LLM使用经验)": "NR"
	},
	"Methodology": {
		"research_design (研究设计_实验_准实验_纵向等)": "One-group pretest–posttest design tracking changes in writing productivity and proficiency after integrating ChatGPT into an EFL writing course over approximately three months.",
		"research_method (研究方法_定量_定性_混合)": "Quantitative",
		"sampling_method (抽样方法)": "Convenience sampling of one intact class of 52 Saudi female EFL students enrolled in first-year academic writing at a Saudi university.",
		"sample_size_and_effect (样本量及效应量)": "Total N=52; all assigned to a single treatment condition using ChatGPT. Paired-samples t-tests showed significant pre–post improvements for topic sentence scores (pre M=3.00, SD=0.863; post M=3.90, SD=0.975; t(51)=-5.983, p=0.000), details/examples (pre M=2.63, SD=0.715; post M=3.58, SD=1.054; t(51)=-6.945, p=0.000), organization (pre M=2.65, SD=0.764; post M=3.46, SD=0.959; t(51)=-7.125, p=0.000), and mechanics (pre M=2.77, SD=0.731; post M=3.10, SD=0.955; t(51)=-2.615, p=0.012), while word count did not change significantly (pre M=119.27, SD=41.911; post M=110.35, SD=32.301; t(51)=-1.051, p=0.298).",
		"theoretical_foundation (理论基础_理论框架)": "Grounded in literature on technology-enhanced EFL writing and AI-assisted learning, focusing on how AI tools like ChatGPT can support idea generation, feedback, and writing development; no explicit formal learning theory (such as sociocultural theory or self-regulation theory) is articulated as a guiding framework.",
		"data_collection_instrument (数据收集工具)": "Pre/post writing test using a definition paragraph topic (‘A good friend’) as first drafts; definition paragraph rubric from RCampus.com assessing topic sentence, details, organization, and mechanics on a 2–5 scale (unsatisfactory, satisfactory, good, exemplary); word count of each paragraph as a productivity measure.",
		"data_collection_validity_reliability (工具信度与效度)": "The pre/post writing topic was reviewed by two applied linguistics professors to ensure appropriateness and familiarity of ideas, vocabulary, and transitions. The RCampus definition paragraph rubric’s validity and reliability were established through expert review and pilot testing. To ensure scoring consistency, a second internal writing instructor double-marked 20% of pre- and post-test paragraphs using the same rubric, independently of the first marker, with high agreement (92%) on the holistic scores.",
		"data_analysis_method (数据分析方法)": "Descriptive statistics (means, standard deviations) and paired-samples t-tests comparing pre- and post-test scores on topic sentence, details/examples, organization, mechanics, and word count to assess the influence of ChatGPT on writing productivity and proficiency.",
		"unit_of_analysis (分析单位)": "Individual student paragraphs and corresponding rubric scores and word counts.",
		"group_assignment_method (组别分配方式_随机_非随机等)": "NA (single-group design with no comparison or control group).",
		"power_analysis (功效分析与样本量论证)": "NR",
		"sampling_frame_and_representativeness (抽样框与样本代表性)": "Sample drawn from one English Language and Literature department at a Saudi university, including only female first-year EFL students enrolled in academic writing, with relatively small sample size and single-institution, single-gender context noted by the authors as limiting generalizability.",
		"scoring_procedure_and_rater_training (评分流程与评分者培训)": "Writing performance was graded using the definition paragraph rubric; the primary instructor scored all scripts, and a second internal writing instructor independently double-marked 20% of the pre and post paragraphs using the same rubric without seeing the first marks; the second marking process showed 92% agreement in final holistic scores, but detailed rater training procedures beyond rubric use were not reported."
	},
	"Intervention": {
		"duration (干预时长与频率)": "Approximately three months during the second semester of the 2024 academic year; week 1 for general academic writing rules and mechanics, week 2 for definition paragraph instruction and pretest, then around nine weeks of ChatGPT-integrated writing tasks, followed by a post-test after nine weeks had elapsed since the pretest; regular course schedule included three contact hours per week.",
		"llm_model_type (LLM模型类型_如ChatGPT_GPT4_Gemini等)": "ChatGPT (OpenAI, AI-based language model)",
		"llm_model_configuration (LLM模型配置与版本_API_网页_参数等)": "Students were introduced to ChatGPT and required to upload it for use before writing in-class assignments; access was via personal devices (mobiles or computers were later prohibited during tests), but specific platform (web vs app), model version, and parameter settings were not reported.",
		"llm_integration_mode (LLM整合模式_直接使用_教师中介_系统嵌入)": "Students interacted directly with ChatGPT as an external AI assistant prior to in-class handwriting of paragraphs; ChatGPT was not embedded in the LMS and teachers did not mediate or edit ChatGPT’s output for students.",
		"prompting_strategy (提示策略_提示工程与使用方式)": "Students were given about 30 minutes before each in-class writing assignment to seek assistance from ChatGPT to generate ideas, organize their thoughts, or warm up, but the study did not specify systematic prompting strategies or prompt-engineering techniques; prompts were generally used for idea generation, organization, and language support without detailed design guidance.",
		"training_support_llm_literacy (LLM素养与提示培训)": "In the week following the pretest, students were introduced to ChatGPT and required to upload it for use before in-class assignments; beyond this introduction and general instructions to use it for idea generation and organization, no explicit, structured training in AI literacy or prompt literacy was reported.",
		"intervention_implementation (干预实施流程_步骤与任务)": "In week 1 the instructor explained general academic writing format and rules and practiced writing mechanics using model paragraphs and LMS activities. In week 2 the elements, structure, and purpose of definition paragraphs were explained, model samples were analysed, and students completed the pretest definition paragraph (‘A good friend’) under supervised, no-technology conditions. In the following week students were introduced to ChatGPT and required to upload it; before each in-class writing assignment they used ChatGPT for about 30 minutes to generate ideas, organize thoughts, or warm up, followed by one hour to handwrite their paragraphs without devices. During the nine-week intervention, students wrote three definition paragraphs, two opinion paragraphs, and two procedure paragraphs using this routine. After nine weeks from the pretest, the same definition paragraph topic was administered again as the post-test under pen-and-paper, no-device conditions.",
		"experimental_group_intervention (实验组干预内容)": "Single-group intervention in which 52 female EFL students used ChatGPT prior to writing multiple paragraphs; for each assignment they consulted ChatGPT for approximately 30 minutes to assist with idea generation, thought organization, and preparation, then wrote their paragraphs by hand in class for one hour without access to ChatGPT or other devices.",
		"control_group_intervention (对照组干预内容)": "NA",
		"writing_stage (写作阶段_如生成_修改_反馈_重写等)": "ChatGPT was used at the pre-writing and planning stage before in-class drafting of paragraphs, mainly for brainstorming, organizing ideas, and warming up, and also for grammar and spelling exposure prior to writing; pre- and post-test paragraphs themselves were drafted without ChatGPT access under examination-like conditions.",
		"writing_genre (写作体裁)": "Definition paragraphs (including the pre/post topic ‘A good friend’), opinion paragraphs, and procedure paragraphs.",
		"writing_task_type (写作任务类型)": "Short paragraph writing tasks requiring a title, a topic sentence, three supporting sentences linked to the controlling idea, elaborating details for each supporting point, and a concluding sentence, written by hand under time limits; pre/post tests used a definition paragraph and weekly tasks included definition, opinion, and procedure paragraphs.",
		"role_llm (LLM角色_如生成文本_给反馈_评分_对话等)": "ChatGPT acted as an AI assistant to help students generate ideas, clarify and organize their thoughts, prepare outlines, warm up for writing, and expose them to grammar and spelling models before they wrote; it provided text generation and instant feedback for planning and language support but did not perform automated scoring.",
		"role_instructor (教师角色与介入方式)": "The instructor delivered traditional academic writing instruction three hours per week, explaining the general format and rules of academic writing, modelling definition paragraphs, and guiding students through mechanics exercises and LMS activities; the instructor also set and supervised pre/post tests and in-class writing, but direct details of feedback on intermediate assignments beyond rubric scoring were not elaborated.",
		"setting (教学情境_学校类型_课程类型_线上线下)": "Face-to-face academic writing classes in the English Language and Literature Department at a Saudi university, supported by a Learning Management System for activities; paragraphs were handwritten in the classroom, with ChatGPT used before writing tasks and not during pre/post tests.",
		"ethical_consideration (伦理审查与知情同意)": "Institutional Review Board (IRB) approval was obtained from the deanship of scientific research at the university prior to the study; all participants were informed of the study’s purpose, the voluntary nature of participation, and their right to withdraw at any time without penalty; written consent forms were collected, privacy and confidentiality were rigorously maintained, and the authors state that the study was conducted honestly and findings were reported truthfully without fabricating or falsifying data.",
		"llm_access_policy (LLM使用规范_允许与限制)": "Students were required to upload and use ChatGPT before in-class writing assignments for about 30 minutes, but during both pre- and post-tests they used pen and paper only and mobiles and computers were not allowed, ensuring that test paragraphs were produced without ChatGPT; access to other writing aids such as dictionaries, style guides, and spell-checkers was also restricted during drafts to isolate the impact of prior ChatGPT exposure.",
		"llm_safety_guardrails (LLM安全与内容过滤设置)": "No specific technical safety or content-filter settings for ChatGPT were reported; the study emphasizes the pedagogical need to avoid heavy reliance on AI tools and to ensure that beginners develop essential writing skills independently, but it does not describe explicit safety guardrails beyond exam conditions and restricted use during in-class writing.",
		"key_findings (主要研究发现_与LLM写作干预相关)": "Integrating ChatGPT into an EFL writing course was associated with significant improvements in students’ writing proficiency on rubric-based measures of topic sentence, details/examples, organization, and mechanics, with paired t-tests showing statistically significant gains across these criteria, particularly for students whose initial writing quality was lower; word count did not differ significantly between pre- and post-tests, but qualitative interpretation suggests that post-test paragraphs were more concise with fewer filler words and redundancies, indicating improved productivity quality rather than quantity; ChatGPT appeared to support idea generation, clarity, and elaboration, especially in topic sentences and supporting details, while gains in organization and mechanics were smaller; the authors highlight ChatGPT’s potential as a helpful tool for beginning EFL learners but stress that its use should be judicious to prevent overreliance and ensure that learners still develop fundamental writing skills independently."
	},
	"Outcome": {
		"application_effectiveness_overview (应用效果总体评价与测量工具)": "Using ChatGPT as a pre-writing assistant in an EFL academic writing course led to measurable improvements in writing proficiency, as assessed by rubric scores for topic sentence, supporting details/examples, organization, and mechanics on pre/post definition paragraphs and by descriptive analyses of performance level shifts; writing productivity, operationalized as word count, did not change significantly, but the authors report better quality of production (reduced redundancy and filler words) in the post-test.",
		"writing_performance_measure (写作表现测量工具_量表或评分标准)": "Definition paragraph rubric from RCampus.com assessing four criteria—topic sentence, details/examples, organization, and mechanics—each rated from 2 (unsatisfactory) to 5 (exemplary), applied to pre- and post-test paragraphs; word count recorded for each paragraph as an additional performance indicator.",
		"writing_performance_focus (写作表现关注维度_流利度_准确性_复杂度_体裁等)": "Focus on quality of topic sentence construction (clarity, definition, reader interest), quality and relevance of details/examples (specificity, elaboration, lack of tangential information), organization (logical order, transitions, coherence, paragraph unity), mechanics (spelling, capitalization, punctuation, grammar, sentence variety), and writing productivity via word count.",
		"affective_aspect_measure (情感因素测量工具_问卷_量表等)": "NA",
		"affective_aspect_focus (情感因素维度_动机_态度_焦虑_自效感等)": "NA",
		"cognitive_aspect_measure (认知因素测量工具)": "NA",
		"cognitive_aspect_focus (认知因素维度_策略使用_元认知监控等)": "NA",
		"behavioral_aspect_measure (行为因素测量工具_日志_平台日志等)": "Word count of pre- and post-test paragraphs as an index of writing productivity, along with descriptive analyses of students’ use of filler words, redundancy, and paragraph length trends.",
		"behavioral_aspect_focus (行为因素维度_使用频率_交互模式_坚持度等)": "Amount of text produced within a fixed time limit, tendencies to overuse filler words or redundant phrases, and shifts toward more concise and focused paragraphs after repeated use of ChatGPT for pre-writing support.",
		"other_outcomes_measure (其他结果测量工具)": "Descriptive distribution of rubric performance levels (unsatisfactory, satisfactory, good, exemplary) for each criterion before and after the intervention, including percentages of students moving up or down levels across topic sentence, details/examples, organization, and mechanics.",
		"other_outcomes_focus (其他结果维度说明)": "Patterns of movement between rubric levels showing that many students improved one or more levels on topic sentences and supporting details, with somewhat smaller but still notable improvements in organization and mechanics, and that improvements were more substantial among students with lower initial writing quality.",
		"assessment_timepoints (评估时间点_前测_后测_延迟测等)": "Pre-test definition paragraph during week 2 of the semester, before ChatGPT integration; post-test using the same definition paragraph topic after about nine weeks of ChatGPT-supported writing practice; no delayed follow-up test beyond the end-of-semester post-test.",
		"primary_outcome_variables (主要结果变量_因变量)": "Rubric scores for topic sentence, details/examples, organization, and mechanics on pre- and post-test paragraphs, and word count of each paragraph.",
		"independent_variables_and_factors (自变量与实验因素)": "Primary independent factor was time (pretest versus posttest) within a single group exposed to ChatGPT integration between measurements; there was no control group or between-group factor.",
		"followup_length_and_type (随访时长与类型)": "No follow-up beyond the immediate post-test at the end of the roughly three-month intervention; long-term retention and transfer were not assessed.",
		"statistical_significance (统计显著性结果摘要)": "Paired-samples t-tests showed statistically significant pre–post differences in favour of the post-test for topic sentence scores (t(51)=-5.983, p=0.000), details/examples scores (t(51)=-6.945, p=0.000), organization scores (t(51)=-7.125, p=0.000), and mechanics scores (t(51)=-2.615, p=0.012), while word count differences were not significant (t(51)=-1.051, p=0.298).",
		"effect_size_summary (效应量摘要)": "Effect sizes such as Cohen’s d or η² were not reported; the authors interpret the statistically significant t-test results as evidence of noticeable improvements in writing proficiency, particularly for students with lower initial performance, and no meaningful change in overall word count.",
		"llm_misuse_or_negative_effects (LLM滥用或负向效应)": "The discussion explicitly warns about heavy reliance on ChatGPT and other AI tools, especially for beginners who need to learn and practice basic skills rather than using the app as a central medium of information and feedback; the authors note risks that students may focus on tool use instead of developing independent writing abilities and that variability in how much students engaged with ChatGPT could influence outcomes; concerns from prior literature about reliability, authenticity of AI-provided information, and limitations in detecting complex writing errors are cited to justify the need for judicious use.",
		"equity_and_subgroup_effects (公平性与亚组差异)": "All participants were female Saudi EFL students, and subgroup analyses by proficiency or other characteristics were not conducted; however, the authors qualitatively note that the lower the writing quality in the pretest, the more notable the improvement in the post-test, suggesting stronger gains among weaker writers, but no detailed subgroup statistics or equity analyses are provided.",
		"limitation (研究局限)": "The authors acknowledge that the study used a one-group pretest–posttest design without a control group, which limits causal inference; the sample size was relatively small (N=52), all participants were female from a single department and institution, and the intervention period was relatively short, which may restrict generalizability and may not capture long-term effects; they also note variability in how much each participant engaged with ChatGPT, which could affect individual outcomes and the consistency and reliability of results.",
		"challenge (实施挑战与风险)": "Challenges include the absence of a control group for more rigorous comparison, a relatively small and homogeneous sample, short intervention duration, and variability in students’ engagement with ChatGPT; pedagogically, there is the risk of learners using ChatGPT as a shortcut rather than as a learning tool, potential overreliance on AI feedback, and the need to balance AI assistance with opportunities for students to practice and internalize writing skills without technological support.",
		"future_work (未来研究方向)": "The authors recommend future quasi-experimental research with control groups to better manipulate the independent variable and strengthen generalizability, studies with larger and more diverse samples to improve external validity, longer-term investigations to capture sustained effects and language proficiency development, and further examination of how differing levels of engagement with ChatGPT influence outcomes in EFL writing.",
		"implication (理论与教学实践启示)": "Findings suggest that ChatGPT, when used in appropriate contexts, can serve as a useful support for EFL students’ writing performance by assisting with idea generation, outlines, organization of thoughts, and grammar and spelling checks, acting as a timesaving tool and contributing to clarity and reduced redundancy; at the same time, the study underscores that AI tools should complement, not replace, foundational writing instruction, and that EFL teachers and curriculum planners should develop guidelines on appropriate use contexts, balancing benefits with the need to prevent overreliance and to help beginners build essential writing skills in alignment with broader educational goals such as Saudi Vision 2030."
	},
	"Study Quality and Reporting": {
		"funding_source (经费来源)": "Supported and funded by the Deanship of Scientific Research at Imam Mohammad Ibn Saud Islamic University (IMSIU) under grant number IMSIU-DDRSP2502.",
		"conflict_of_interest (利益冲突声明)": "NR",
		"risk_of_bias_randomization (偏倚风险_分配与随机化)": "No randomization or control group was used; all 52 participants received the ChatGPT-integrated intervention, so there is an inherent risk of selection and confounding bias typical of one-group pretest–posttest designs.",
		"risk_of_bias_blinding (偏倚风险_盲法)": "Blinding of participants, instructors, or raters to the intervention or time point was not mentioned and is unlikely given the design and explicit introduction of ChatGPT.",
		"attrition_and_missing_data (流失与缺失数据处理)": "The text does not report participant attrition or how missing data, if any, were handled; results are presented for N=52 at both pre- and post-test, suggesting all participants completed both measurements but without explicit confirmation.",
		"reporting_transparency (报告透明度与可重复性)": "The study clearly reports its design, participants, context, instruments, scoring rubric, pre/post procedures, and statistical analyses, including means, standard deviations, t values, and p values for each writing criterion and word count; it qualitatively describes how ChatGPT was integrated into weekly tasks and acknowledges methodological limitations, but raw data and analysis code are not shared.",
		"preregistration_or_protocol (预注册或研究方案)": "NR",
		"llm_version_reproducibility (LLM版本与可复现性)": "The study names ChatGPT as the AI tool and notes that students were required to upload and use it, but it does not specify the ChatGPT version, access mode (web vs app) in detail, or any configuration parameters, which limits exact reproducibility given potential evolution of the model over time.",
		"baseline_equivalence (基线等同性检验)": "NA (only one group was studied, so no baseline equivalence between groups was assessed).",
		"assumption_check_and_data_diagnostics (统计假设检验与数据诊断)": "Apart from applying paired-samples t-tests, the authors do not report formal checks of statistical assumptions (such as normality of difference scores or presence of outliers) or additional diagnostic analyses.",
		"outlier_treatment_and_sensitivity_analysis (异常值处理与稳健性分析)": "NR",
		"data_preprocessing_and_transformation (数据预处理与转换)": "Pre/post paragraphs were handwritten under controlled conditions and scored using a rubric; 20% were double-marked for reliability; word count was computed for each script; no additional data transformations or complex preprocessing procedures were described."
	}
}