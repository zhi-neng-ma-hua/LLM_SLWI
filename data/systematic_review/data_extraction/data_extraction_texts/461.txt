{
	"Basic Identification": {
		"author (作者)": "Ruofei Zhang; Di Zou; Gary Cheng",
		"publication_year (发表年份)": "2025",
		"study_region (研究地区)": "Hong Kong, China",
		"journal_name (期刊名称)": "Education and Information Technologies",
		"study_type (研究类型_期刊论文_会议论文等)": "Journal article; concurrent triangulation mixed-method single-group pre-test–immediate post-test–delayed post-test experimental study",
		"doi_or_identifier (DOI或唯一标识)": "10.1007/s10639-025-13776-2",
		"research_aims (研究目的与问题)": "To explore the extent and nature of non-academic learner socialisation with ChatGPT (behavioural and emotional) among EFL university students in GPT-4-assisted learning of English argumentative writing logic, and to examine whether and how such socialisation influences learning outcomes in logical knowledge, logical quality, and self-efficacy in English argumentative writing.",
		"research_gap_or_novelty (研究创新性与知识空白)": "The study addresses the lack of empirical research on non-academic learner socialisation with ChatGPT in educational settings and the absence of work on ChatGPT-assisted learning of English argumentative writing logic; it proposes and tests a conceptual framework linking behavioural and emotional non-academic socialisation with ChatGPT to logical knowledge, logical quality, and self-efficacy outcomes, using a GPT-4-powered bot specifically designed for logic learning."
	},
	"Participant Information": {
		"educational_level (教育阶段)": "University students (tertiary level) in Hong Kong",
		"language_proficiency (语言熟练度水平)": "Chinese EFL learners who needed to enhance English argumentative writing for university assessments and had some experience with technology-enhanced learning; no standardised English proficiency scores reported",
		"mother_tongue (母语)": "Chinese",
		"sex (性别)": "Total N=40; 32 female, 8 male",
		"age (年龄)": "Age range 18–27 years, M=22.85, SD=3.05",
		"learning_context (学习语境_ESL_EFL_ELL等)": "EFL context at a Hong Kong university; ChatGPT-assisted learning of English argumentative writing logic",
		"target_language (目标语言)": "English (L2)",
		"discipline (学科背景)": "Students from a single Hong Kong university who frequently needed to complete English argumentative writing for coursework; specific majors or disciplines not reported",
		"prior_experience_llm (既有LLM使用经验)": "Participants had experience with technology-enhanced learning but no prior experience with logic learning, ChatGPT-assisted learning, or prompt engineering training; prior informal LLM use was not reported"
	},
	"Methodology": {
		"research_design (研究设计_实验_准实验_纵向等)": "Concurrent triangulation mixed-method design with a single cohort completing pre-test, immediate post-test, and one-week delayed post-test of logical knowledge, pre-learning argumentative essay writing and post-learning logic-focused revision, plus post-treatment questionnaires and semi-structured interviews; no control group",
		"research_method (研究方法_定量_定性_混合)": "Mixed methods combining quantitative (tests, questionnaires, writing scores, prompt counts, PLS-SEM, regression) and qualitative (thematic analysis of interviews and prompt content) approaches",
		"sampling_method (抽样方法)": "Voluntary convenience sampling of Chinese EFL university students in Hong Kong incentivised by gift cards, followed by eligibility screening via an online pre-treatment survey to exclude students without urgent need to improve EFL argumentative writing and those with prior logic learning experience",
		"sample_size_and_effect (样本量及效应量)": "Initial volunteers N=52; after excluding 9 without urgent need for EFL argumentative writing improvement and 3 with prior logic learning, final N=40 (32 female, 8 male, age 18–27, M=22.85, SD=3.05). Paired-samples t-tests showed large gains in logical knowledge (immediate post-test vs pre-test mean difference=10.16, SD=3.65, t(39)=17.82, p<.001, Cohen’s d=2.78; delayed post-test vs pre-test mean difference=9.32, SD=3.77, t(39)=15.83, p<.001, d=2.47), logical quality (revised vs initial writing mean increase=6.63, SD=5.79, t(39)=7.237, p<.001, d=1.144), and self-efficacy (post vs pre questionnaire mean increase≈0.42, SD=0.50, t(39)=5.325, p<.001, d=0.842). PLS-SEM showed a significant path from non-academic socialisation with ChatGPT to logical-knowledge outcomes (β=0.34, 95% BCCI=[0.07, 0.59], f2=0.14). Hierarchical regressions indicated that, controlling for pre-test scores, each additional non-academic socialisation prompt predicted about 0.94–0.96 points higher immediate and delayed post-test logical-knowledge scores (b≈0.94–0.96, p<.05).",
		"theoretical_foundation (理论基础_理论框架)": "Conceptual framework grounded in self-regulated learning theory, attachment theory, self-determination theory, constructivist learning theory, cognitive load theory, social presence theory, anthropomorphisation, homophily theory, and flow theory, combined with prior work on logical knowledge and quality in English argumentative writing, non-academic learner socialisation with teachers, peers and chatbots, and the affordances of ChatGPT-assisted learning.",
		"data_collection_instrument (数据收集工具)": "Online pre-treatment survey on demographics, EFL writing needs, and prior experiences with technology-enhanced learning, logic learning, ChatGPT-assisted learning, and prompt engineering; GPT-4-Turbo-powered POE bot LogicalHamster for learning English argumentative writing logic and logging learner prompts; three parallel 30-min paper-based tests of logical knowledge (identify, explain, and label seven logical fallacies); timed 250-word English argumentative essay writing task and 30-min logic-focused revision task; pre- and post-questionnaires on English argumentative writing self-efficacy (7-item 5-point Likert scale adapted from Rahimi and Fathi, 2022); post-questionnaire on learners’ sense of relatedness to ChatGPT (5-point Likert scale adapted from Croes and Antheunis, 2021); semi-structured interviews in L1 Chinese; screen recordings of the ChatGPT-assisted learning session.",
		"data_collection_validity_reliability (工具信度与效度)": "LogicalHamster was piloted with five similar students who used it for over 45 minutes and were interviewed; its instructional content on logical fallacies was checked against Bassham et al. (2010), Murray (2012), and Texas State University’s fallacy definitions, and no bias or inaccuracy was found. Logical-knowledge tests were adapted from Zhang et al. (2023a) and blind-scored by two authors using a three-point rubric per fallacy, with high inter-rater reliability (Cohen’s κ=0.96) and discrepancies resolved by discussion. Initial and revised essays were blind-scored by two authors and a colleague using an analytic rubric adapted from the Illinois Critical Thinking Essay Scoring Rubric and IELTS criteria, with inter-rater reliability κ=0.87 for initial writing and κ=0.85 for revisions. The self-efficacy questionnaire showed Cronbach’s α=0.80 and the relatedness questionnaire α=0.86. Coding of non-academic socialisation prompts achieved Cohen’s κ=0.89. PLS-SEM measurement models showed acceptable indicator loadings (>0.708), composite reliability (rhoC>.700), convergent validity (AVE>0.50), discriminant validity (HTMT<0.85), and VIF<3.",
		"data_analysis_method (数据分析方法)": "Thematic analysis of interview transcripts with inductive coding of perceived extent, relationship type, and impacts of non-academic socialisation; content coding of 1,460 learner prompts into four social-purpose categories and calculation of per-learner frequencies; descriptive statistics (means, SDs) for socialisation measures, test scores, writing scores, and questionnaire responses; paired-samples t-tests in SPSS to compare pre- and post-/delayed scores; PLS-SEM using SEMinR in R with bootstrapping of 10,000 subsamples to estimate paths from non-academic socialisation and prior learner factors to logical-knowledge, logical-quality, and self-efficacy outcomes; hierarchical multiple linear regressions in SPSS to further examine the predictive effects of non-academic prompt counts and relatedness scores on logical-knowledge outcomes; assumption checks for linearity, homoscedasticity, normality, and multicollinearity.",
		"unit_of_analysis (分析单位)": "Individual learner for tests, questionnaires, essay scores, PLS-SEM constructs, and regression analyses; individual learner’s set of prompts aggregated to counts per social-purpose category; individual interviewee for qualitative themes.",
		"group_assignment_method (组别分配方式_随机_非随机等)": "No assignment to experimental and control groups; all 40 participants received the ChatGPT-assisted intervention; 20 interviewees were randomly selected from the 40 participants using an online random picker.",
		"power_analysis (功效分析与样本量论证)": "No formal a priori power analysis was reported; the authors argued that N=40 met common rules of thumb for paired t-tests (≥30), multiple regression (≥10 observations per predictor), and PLS-SEM (≥10 times the maximum number of indicators for a construct) and reported strong statistical power (>0.80 and >0.99) for key regression parameter estimates.",
		"sampling_frame_and_representativeness (抽样框与样本代表性)": "Sampling frame consisted of Chinese EFL university students at a single Hong Kong institution who needed to improve English argumentative writing, had some technology-enhanced learning experience, and had no prior logic learning, ChatGPT-assisted learning, or prompt engineering training; the final sample was predominantly female and from one cultural and institutional context, and the authors noted that situational, developmental, and cultural factors likely affect non-academic socialisation, limiting generalisability.",
		"scoring_procedure_and_rater_training (评分流程与评分者培训)": "Logical-knowledge tests from three timepoints were independently and blindly scored by two authors using a predefined three-point rubric for each fallacy (0–2 points for meaning/structure plus 0–1 point for correct term matching) to yield total scores 0–21; discrepancies were resolved through discussion. Initial and revised essays were independently and blindly scored by two authors and a colleague with expertise in teaching and assessing English argumentative writing, using an analytic rubric with four logic-related dimensions each scored 0–25; inter-rater indices were calculated and disagreements discussed until consensus. Interview transcripts and prompt datasets were jointly used to develop coding schemes, after which coders independently applied them, compared results, and discussed differences until agreement."
	},
	"Intervention": {
		"duration (干预时长与频率)": "Three-week procedure: Week 1 pre-treatment survey, participant selection, 20-min orientation and pre self-efficacy questionnaire; Week 2 40-min initial essay writing, 30-min pre-test of logical knowledge, 45–75-min ChatGPT-assisted learning session, 30-min logic-focused revision, 30-min immediate post-test, 5-min post self-efficacy questionnaire, 5-min relatedness questionnaire, and ~25-min semi-structured interviews for a subsample; Week 3 30-min delayed post-test of logical knowledge.",
		"llm_model_type (LLM模型类型_如ChatGPT_GPT4_Gemini等)": "ChatGPT (GPT-4-Turbo) via POE, instantiated as the custom educational chatbot 'LogicalHamster'.",
		"llm_model_configuration (LLM模型配置与版本_API_网页_参数等)": "LogicalHamster was implemented on the POE platform using GPT-4-Turbo and configured via natural-language system instructions specifying its role ('a hamster and a teacher on logical knowledge in English argumentative writing'), teaching methods (providing examples and exercises of logical fallacies in English argumentative writing that increase in difficulty), interactive style (praise, encouragement, jokes, emojis, empathetic and non-judgmental language, name-calling), and target knowledge (seven logical fallacies). Students accessed the bot through the POE web interface on desktop computers; no API key, parameter settings (e.g., temperature), or precise version dates were reported.",
		"llm_integration_mode (LLM整合模式_直接使用_教师中介_系统嵌入)": "Students interacted directly with the GPT-4-Turbo LogicalHamster bot via the POE web user interface on desktop computers in a supervised computer lab; the LLM was not embedded in an LMS, and instructors did not mediate content beyond initial configuration and technical support.",
		"prompting_strategy (提示策略_提示工程与使用方式)": "At the system level, LogicalHamster was prompt-engineered with role prompting and behavioural instructions to teach seven logical fallacies through explanations, examples, and increasingly complex exercises, to ask and answer questions, to analyse students’ English argumentative writing from a logical perspective, and to provide immediate feedback while addressing learners by name, using humour and emojis, and expressing empathy and encouragement to foster non-academic socialisation. Learners used spontaneous natural-language prompts in Chinese and English to request explanations, ask follow-up questions, ask for and complete exercises, submit parts of their essays for logical analysis, and engage in casual social talk (greetings, gratitude, small talk, self-disclosure); no explicit instruction in advanced prompt engineering techniques such as few-shot prompting, chain-of-thought, or rubric-based prompting was provided.",
		"training_support_llm_literacy (LLM素养与提示培训)": "All participants attended a 20-min orientation session covering logical knowledge, logical quality, and self-efficacy in English argumentative writing and the idea of ChatGPT-assisted learning to familiarise them with the research objectives and procedures and to reduce novelty effects. During interviews, the concept of non-academic learner socialisation with ChatGPT was explained. There was no systematic training in prompt engineering, critical evaluation of AI outputs, plagiarism avoidance, or wider AI literacy.",
		"intervention_implementation (干预实施流程_步骤与任务)": "In Week 1, 52 volunteers completed an online pre-treatment survey; 12 were excluded based on criteria, 40 provided signed consent, and all attended a 20-min orientation and a 5-min pre-questionnaire on English argumentative writing self-efficacy. In Week 2, participants first composed a 250-word English argumentative essay in 40 minutes on an IELTS-style topic without reference materials, followed by a 30-min paper-based pre-test of logical knowledge. They then engaged in 45–75 minutes of ChatGPT-assisted learning with LogicalHamster in a computer lab, where they interacted in Chinese and English to receive instruction and exercises on seven logical fallacies, ask and answer questions, have their own essays analysed from a logical perspective, and receive immediate feedback; their screens were recorded, and the first author remained in the room only to provide technical help. After the learning session, they revised the essays they had written earlier in a 30-min logic-focused revision task without external resources, completed an immediate 30-min logical-knowledge post-test, and filled in post questionnaires on self-efficacy (5 min) and relatedness to LogicalHamster (5 min). Twenty randomly selected participants then took part in ~25-min semi-structured interviews in L1 Chinese. In Week 3, all participants completed a 30-min delayed post-test of logical knowledge.",
		"experimental_group_intervention (实验组干预内容)": "All 40 participants formed a single experimental cohort receiving ChatGPT-assisted learning of English argumentative writing logic using the GPT-4 LogicalHamster, involving individual natural-language interaction with the bot to study seven logical fallacies through explanations, examples, Q&A, exercises with feedback, analysis of their own essays, and supportive social conversation, followed by logic-focused essay revision and immediate and delayed assessments.",
		"control_group_intervention (对照组干预内容)": "NA",
		"writing_stage (写作阶段_如生成_修改_反馈_重写等)": "Initial generation of a timed argumentative essay before ChatGPT-assisted learning and a subsequent logic-focused revision of the same essay after the ChatGPT-assisted session; during learning, the LLM analysed drafts and provided feedback, but the timed writing and revision tasks themselves were completed without direct access to ChatGPT.",
		"writing_genre (写作体裁)": "English argumentative essay of approximately 250 words on an IELTS-style topic about whether young people who commit crimes should be treated the same as adults.",
		"writing_task_type (写作任务类型)": "Individual timed argumentative essay writing task (40 min) followed by a timed revision task focusing on logical quality (30 min), both performed in MS Word without external references or tools.",
		"role_llm (LLM角色_如生成文本_给反馈_评分_对话等)": "GPT-4 LogicalHamster functioned as a logic tutor and conversational companion: it generated explanations and examples of seven logical fallacies, created and adapted exercises with immediate feedback, asked and answered open-ended questions, analysed students’ English argumentative writing from a logical perspective, and provided personalised feedback and motivational, humorous, and empathetic responses to support both academic learning and non-academic socialisation; it did not formally grade the tests or essays used as outcome measures.",
		"role_instructor (教师角色与介入方式)": "Researchers designed and configured the GPT-4 LogicalHamster bot, piloted and validated its content, recruited and screened participants, delivered the orientation, monitored the lab session for technical help without instructional intervention, administered writing tasks, tests, and questionnaires, selected and conducted interviews, coded prompts and qualitative data, and scored tests and essays using defined rubrics.",
		"setting (教学情境_学校类型_课程类型_线上线下)": "Face-to-face higher education setting at a Hong Kong university; ChatGPT-assisted learning occurred in an on-campus computer lab with desktop computers and internet access to the POE web interface; essay writing and revision tasks and paper-based tests were completed in person under supervision.",
		"ethical_consideration (伦理审查与知情同意)": "All participants signed consent forms stating that their personal data would remain confidential, their participation would not affect academic standing, and they could withdraw at any time; the authors state that the research met ethical guidelines and legal requirements of the study country; data cannot be shared publicly because participants did not provide consent for public data sharing.",
		"llm_access_policy (LLM使用规范_允许与限制)": "Participants were allowed to interact freely with the GPT-4 LogicalHamster in Chinese and English during the 45–75-min learning session but were not instructed or required to engage in non-academic socialisation; pre- and post-tests, revision tasks, and questionnaires were conducted without access to ChatGPT or other external tools; participants reported no prior ChatGPT-assisted learning or prompt engineering training.",
		"llm_safety_guardrails (LLM安全与内容过滤设置)": "LogicalHamster’s instructional content and examples were manually checked against standard logic references in a pilot, and five students tested the bot and reported it was easy to use and effective; the bot was configured to be supportive, non-judgmental, and empathetic to avoid discouraging learners. No additional automated safety mechanisms, content filters, academic integrity checks, or technical guardrails were described beyond this piloting and configuration.",
		"key_findings (主要研究发现_与LLM写作干预相关)": "Learners exhibited upper-intermediate levels of non-academic socialisation with ChatGPT: 50% produced non-academic prompts (greetings, name-calling, gratitude, admiration, casual talk, self-disclosure) and mean relatedness scores to LogicalHamster were high (M=4.33/5); many interviewees described the bot as a friend rather than just a tool or teacher. ChatGPT-assisted learning led to very large improvements in logical-knowledge test scores, significant enhancements in logical quality of argumentative writing, and increased self-efficacy. PLS-SEM and regression analyses showed that non-academic learner socialisation with ChatGPT, operationalised as prompt frequency and relatedness, significantly and positively predicted logical-knowledge outcomes after controlling for prior knowledge, while direct paths to logical quality and self-efficacy were not significant, suggesting that socialisation primarily benefits knowledge gains. Interview data indicated that non-academic socialisation improved feedback acceptance, motivation to apply learning strategies, and flow during learning but was perceived by some students as distracting or unnecessary, highlighting both benefits and potential drawbacks of such socialisation in ChatGPT-assisted writing logic education."
	},
	"Outcome": {
		"application_effectiveness_overview (应用效果总体评价与测量工具)": "Effectiveness of the GPT-4-assisted intervention was evaluated using pre-, immediate post-, and one-week delayed paper-based tests of logical knowledge, analytic scoring of initial and revised argumentative essays for logical quality, pre- and post-questionnaires on English argumentative writing self-efficacy, a post-questionnaire on learners’ sense of relatedness to ChatGPT, and coded frequencies of non-academic socialisation prompts; results demonstrated large, statistically significant gains in logical knowledge and logical quality and moderate-to-large gains in self-efficacy, with non-academic socialisation significantly associated with logical-knowledge outcomes.",
		"writing_performance_measure (写作表现测量工具_量表或评分标准)": "Analytic rubric for logical quality in English argumentative writing adapted from Finken and Ennis’s Illinois Critical Thinking Essay Scoring Rubric and the IELTS academic writing criteria, comprising four dimensions (supporting reasons, reasoning, commitment of logical fallacies, coherence) each scored 0–25, summed to a total logic-quality score from 0 to 100.",
		"writing_performance_focus (写作表现关注维度_流利度_准确性_复杂度_体裁等)": "Logical quality of English argumentative writing, focusing on accuracy, relevance, and sufficiency of supporting reasons, clarity and convincingness of reasoning, frequency and severity of logical fallacies, and logical coherence and sequencing across the essay.",
		"affective_aspect_measure (情感因素测量工具_问卷_量表等)": "Pre- and post-questionnaires on English argumentative writing self-efficacy using a 7-item 5-point Likert scale adapted from Rahimi and Fathi (2022), and a post-treatment questionnaire on learners’ sense of relatedness to ChatGPT using a 5-point Likert scale adapted from Croes and Antheunis (2021).",
		"affective_aspect_focus (情感因素维度_动机_态度_焦虑_自效感等)": "Learners’ self-efficacy regarding their ability to perform English argumentative writing tasks (confidence, perceived capability, expectation of success) and their emotional sense of relatedness, friendship, and intention to continue interacting with LogicalHamster as a companion in future.",
		"cognitive_aspect_measure (认知因素测量工具)": "Three 30-min paper-based logical-knowledge tests administered pre-treatment, immediately after treatment, and one week later, requiring participants to identify reasoning errors in seven English argumentative sentences, explain the meaning and structure of each fallacy, and match it to one of seven fallacy terms.",
		"cognitive_aspect_focus (认知因素维度_策略使用_元认知监控等)": "Logical knowledge in English argumentative writing, specifically understanding, identifying, explaining, and accurately labelling seven common logical fallacies (Begging the Question, Red Herring, False Alternatives, Post hoc fallacy, Hasty Generalization, Slippery Slope, Faulty Analogy) in argument sentences.",
		"behavioral_aspect_measure (行为因素测量工具_日志_平台日志等)": "Log data of 1,460 prompts sent by 40 learners to the GPT-4 LogicalHamster collected from the POE platform, coded into four categories of non-academic socialisation (greeting and name-calling; expressing gratitude and admiration; sharing personal issues and vulnerability; casual talk) and counted per learner; interview reports of frequency and nature of non-academic socialisation complemented these data.",
		"behavioral_aspect_focus (行为因素维度_使用频率_交互模式_坚持度等)": "Behavioural engagement in non-academic socialisation with ChatGPT, including whether learners greeted LogicalHamster and addressed it by name, expressed gratitude or admiration, engaged in casual conversations or joking, and disclosed personal difficulties, along with how often such prompts occurred per learner and how these patterns related to learning outcomes.",
		"other_outcomes_measure (其他结果测量工具)": "PLS-SEM with a latent construct for non-academic learner socialisation (non-academic prompt counts and relatedness scores), latent outcome constructs for logical knowledge (immediate and delayed test scores), logical quality (revised essay scores), and self-efficacy (post self-efficacy scores), and latent constructs for prior learner factors (pre-test, initial essay score, pre self-efficacy); hierarchical multiple linear regressions predicting immediate and delayed logical-knowledge scores; thematic analysis of semi-structured interviews probing perceived relationships, extent and impacts of non-academic socialisation, and reasons.",
		"other_outcomes_focus (其他结果维度说明)": "Structural relationships between behavioural and emotional non-academic socialisation and ChatGPT-assisted learning outcomes, the positive predictive role of non-academic prompt frequency on logical-knowledge gains, the mediating role of logical knowledge in effects on logical quality and self-efficacy, and qualitative themes on social presence, homophily, motivation, feedback acceptance, flow, cognitive load, and learner beliefs about the utility and risks of socialising with ChatGPT.",
		"assessment_timepoints (评估时间点_前测_后测_延迟测等)": "Pre-treatment online survey and pre self-efficacy questionnaire (Week 1); initial argumentative essay and pre-test of logical knowledge before ChatGPT-assisted learning (Week 2); immediate post-test of logical knowledge, post self-efficacy questionnaire, and relatedness questionnaire directly after the ChatGPT-assisted learning session and revision task (Week 2); semi-structured interviews shortly after learning for 20 participants (Week 2); one-week delayed post-test of logical knowledge (Week 3).",
		"primary_outcome_variables (主要结果变量_因变量)": "Logical-knowledge test scores at pre-test, immediate post-test, and delayed post-test; logical-quality scores for initial and revised argumentative essays; English argumentative writing self-efficacy questionnaire scores before and after the intervention; latent logical-knowledge, logical-quality, and self-efficacy outcome constructs in the PLS-SEM model.",
		"independent_variables_and_factors (自变量与实验因素)": "Composite indicator of non-academic learner socialisation with ChatGPT (number of non-academic socialisation prompts and relatedness scores), prior logical knowledge (pre-test scores), prior logical quality (initial essay logic scores), prior English argumentative writing self-efficacy (pre-questionnaire scores), and in regression analyses the separate behavioural (prompt counts) and emotional (relatedness questionnaire scores) socialisation measures.",
		"followup_length_and_type (随访时长与类型)": "One-week delayed post-test of logical knowledge after the ChatGPT-assisted learning session; no longer-term follow-up tests of writing performance or self-efficacy were conducted.",
		"statistical_significance (统计显著性结果摘要)": "Paired-samples t-tests showed that immediate and delayed logical-knowledge test scores were significantly higher than pre-test scores (mean differences ≈10.16 and 9.32 points, t(39)=17.824 and 15.833, both p<.001), revised essay logical-quality scores were significantly higher than initial scores (mean difference=6.63, t(39)=7.237, p<.001), and post self-efficacy scores were significantly higher than pre self-efficacy scores (mean difference≈0.42, t(39)=5.325, p<.001). PLS-SEM indicated a significant positive effect of non-academic learner socialisation with ChatGPT on logical-knowledge outcomes (β=0.34, 95% BCCI [0.07, 0.59], f2=0.14) after controlling for prior logical knowledge, but non-significant direct paths from non-academic socialisation to logical quality and self-efficacy. Hierarchical multiple regressions showed that adding non-academic prompt counts and relatedness scores increased explained variance in immediate logical-knowledge outcomes (R2 change=0.134, Fchange(2,36)=3.652, p=.036) and delayed logical-knowledge outcomes (R2 change=0.165, Fchange(2,36)=4.306, p=.021), with non-academic prompt counts significantly predicting both immediate (b=0.936, t=2.694, p=.011) and delayed (b=0.964, t=2.839, p=.007) post-test scores, while relatedness scores were not significant.",
		"effect_size_summary (效应量摘要)": "Logical-knowledge gains were very large (Cohen’s d≈2.78 for immediate post-test vs pre-test and d≈2.47 for delayed post-test vs pre-test); improvements in logical quality were large (d≈1.14) and gains in self-efficacy were moderate to large (d≈0.84). In the PLS-SEM model, the effect of non-academic socialisation on logical-knowledge outcomes had a small-to-medium effect size (f2≈0.14). Regression coefficients indicated that, for learners scoring zero on the pre-test, each additional non-academic socialisation prompt was associated with increases of about 0.94 points on the immediate post-test and 0.96 points on the delayed post-test.",
		"llm_misuse_or_negative_effects (LLM滥用或负向效应)": "The study did not report plagiarism, cheating, or explicit misuse of ChatGPT; however, some interviewees perceived non-academic socialisation with LogicalHamster as a waste of time or a distraction from learning and reported deliberately avoiding such interactions to preserve learning efficiency. The authors linked this to potential extraneous cognitive load and, in the discussion of long-term use, warned that frequent non-academic socialisation could lead to over-anthropomorphisation and excessive dependence on ChatGPT, potentially causing cognitive disorientation and negatively affecting academic development.",
		"equity_and_subgroup_effects (公平性与亚组差异)": "No subgroup analyses by gender, age, proficiency, discipline, or socio-economic status were conducted. The authors noted that the sample, predominantly female Chinese EFL university students from a single institution, limited exploration of how situational, developmental, and cultural factors such as age and cultural norms of politeness might affect non-academic socialisation with ChatGPT; these equity-related issues were discussed conceptually but not tested empirically.",
		"limitation (研究局限)": "Limitations include the homogeneous and relatively small sample of mainly female Chinese EFL university students from one institution, constraining generalisability and preventing analysis of gender, cultural, or educational-background effects; the short, single 45–75-min ChatGPT-assisted session that may be influenced by novelty effects and may not suffice to change complex outcomes like logical quality and self-efficacy, which are rooted in longer-term experience; the use of three logical-knowledge tests with identical content but varied item order, leaving some potential for test–retest and expectancy effects; the focus on learner prompts, questionnaires, and interviews without systematic coding and analysis of the full learner–ChatGPT dialogues or GPT responses; the structural model did not incorporate all plausible interactions or explicitly model mediation by logical knowledge; and absence of a non-ChatGPT control group, which limits causal attribution of effects solely to non-academic socialisation with ChatGPT.",
		"challenge (实施挑战与风险)": "Implementation challenges and risks highlighted include that some learners, due to long-standing beliefs and habits, view non-academic socialisation with ChatGPT as inappropriate or distracting and therefore suppress such behaviour even when they feel related to the bot; ChatGPT’s non-human, emotionless nature and the unidirectional emotional investment may limit the depth and sustainability of socialisation; non-academic socialisation can add extraneous cognitive load in a cognitively demanding domain like logical reasoning in argument writing; a brief intervention may be insufficient to affect deep-seated self-efficacy beliefs; and over time, frequent socialisation risks over-anthropomorphisation and overdependence on ChatGPT, necessitating careful orientation and monitoring.",
		"future_work (未来研究方向)": "The authors call for future studies with more diverse and larger samples varying in age, gender, digital literacy, educational level, and cultural background to explore how these factors shape non-academic socialisation with ChatGPT; long-term ChatGPT-assisted learning interventions to examine how non-academic socialisation evolves over time and its sustained effects on logical quality and self-efficacy while managing novelty and dependence; use of alternative logical-knowledge tests with varied content to reduce test–retest effects; systematic coding of complete learner–ChatGPT dialogues to identify GPT cues that trigger non-academic socialisation and to clarify underlying mechanisms; refinement of the conceptual model to incorporate interactions between behavioural and emotional socialisation and mediation by logical knowledge; implementation of designs with control groups to isolate the effects of non-academic socialisation; and extension of research to ChatGPT-assisted collaborative learning and educational games.",
		"implication (理论与教学实践启示)": "The study suggests that ChatGPT, when configured as a GPT-4-powered bot with a distinct engaging persona such as LogicalHamster, can serve simultaneously as an instructional agent for logical fallacies in English argumentative writing and as a social companion, and that learners’ spontaneous non-academic socialisation with the bot positively contributes to logical-knowledge gains. For practice, educators are advised to provide orientations that inform students about both benefits and limitations of non-academic socialisation with ChatGPT, to encourage spontaneous but not mandatory casual interaction, and to clarify the bot’s non-human nature to mitigate over-anthropomorphisation and overdependence. Instructional designers are encouraged to create vivid, humorous, patient GPT personas that enhance social presence and motivation while ensuring that cognitive load remains manageable and that the primary goals—developing logical knowledge, logical quality, and self-efficacy in English argumentative writing—remain central."
	},
	"Study Quality and Reporting": {
		"funding_source (经费来源)": "Start-up Fund for New Recruits of The Hong Kong Polytechnic University (Project No. P0056518); open access funding provided by The Hong Kong Polytechnic University.",
		"conflict_of_interest (利益冲突声明)": "Authors declared no conflict of interest.",
		"risk_of_bias_randomization (偏倚风险_分配与随机化)": "There was no randomisation to different instructional conditions because all participants received the ChatGPT-assisted intervention in a single-group pre-test–post-test design; participants were recruited via voluntary sampling with exclusion criteria based on pre-treatment survey responses, which may introduce selection bias, though baseline measures (pre-test, initial writing, pre self-efficacy) were controlled for in the analyses.",
		"risk_of_bias_blinding (偏倚风险_盲法)": "Blinding was not possible for exposure to the ChatGPT-assisted intervention, as participants knew they were using LogicalHamster; however, logical-knowledge tests and essays were scored independently and blindly by multiple raters using predefined rubrics, and coding of prompts and interviews used anonymised data; coders were not reported to be blinded to the study aims.",
		"attrition_and_missing_data (流失与缺失数据处理)": "Of the 52 initial volunteers, 12 were excluded prior to the intervention based on pre-treatment criteria; among the 40 included participants, the study reported no attrition across the three-week period and did not describe any specific missing-data handling procedures, implying that analyses were based on complete cases.",
		"reporting_transparency (报告透明度与可重复性)": "The article provides detailed descriptions of the participant recruitment and exclusion process, sample characteristics, the configuration and piloting of the GPT-4 LogicalHamster bot, instruments and rubrics for tests, writing, and questionnaires, coding schemes for prompts and interviews, analytical methods including PLS-SEM specification and diagnostics, and key descriptive and inferential statistics; ethical compliance, funding sources, and the use of Grammarly for language polishing are disclosed; raw data are not publicly available because participants did not consent to data sharing.",
		"preregistration_or_protocol (预注册或研究方案)": "NR",
		"llm_version_reproducibility (LLM版本与可复现性)": "The study states that LogicalHamster is a GPT-4-Turbo-powered bot implemented on the POE platform and documents its role, instructional scope (seven logical fallacies), and interaction style with illustrative screenshots, but it does not report exact OpenAI model identifiers, parameter settings (e.g., temperature, max tokens), or access dates; as a result, while the instructional design can be replicated, exact replication of ChatGPT outputs may be limited by future changes in the underlying GPT-4 models.",
		"baseline_equivalence (基线等同性检验)": "NA",
		"assumption_check_and_data_diagnostics (统计假设检验与数据诊断)": "The authors report that scatterplots and P–P plots indicated linearity and homoscedasticity, and that skewness values between −2 and +2 and kurtosis between −7 and +7 supported approximate normality, justifying the use of paired t-tests and multiple regressions; multicollinearity was not a concern, with Pearson correlation coefficients below 0.90 for predictors. For PLS-SEM, they report high indicator reliability (loadings>.708), composite reliabilities (rhoC>.700), AVE>0.50, HTMT ratios<0.85, and VIF<3, supporting reliability, convergent and discriminant validity, and absence of problematic collinearity.",
		"outlier_treatment_and_sensitivity_analysis (异常值处理与稳健性分析)": "NR",
		"data_preprocessing_and_transformation (数据预处理与转换)": "Logical-knowledge test responses were scored with a three-point rubric per fallacy and summed to total scores (0–21); initial and revised essays were scored on four logic-related dimensions (0–25 each) and summed to total logical-quality scores (0–100); self-efficacy and relatedness questionnaires were scored on 5-point Likert items to yield mean or total scores; learner prompts were coded into predefined non-academic socialisation categories and counted per learner; interview recordings were transcribed into text for thematic coding; no additional data transformations such as scaling or normalisation were reported beyond these scoring, aggregation, and coding steps."
	}
}