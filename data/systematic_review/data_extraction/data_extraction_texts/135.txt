{
	"Basic Identification": {
		"author (作者)": "Abrar H. Alsofyani, Amal M. Barzanji",
		"publication_year (发表年份)": "2025",
		"study_region (研究地区)": "Saudi Arabia (western region; Jeddah and Madinah)",
		"journal_name (期刊名称)": "Journal of Educational Computing Research",
		"study_type (研究类型_期刊论文_会议论文等)": "Journal article; explanatory sequential mixed-methods experimental study",
		"doi_or_identifier (DOI或唯一标识)": "10.1177/07356331241307297",
		"research_aims (研究目的与问题)": "To examine the effects of ChatGPT-generated written corrective feedback compared to teacher-generated feedback on Saudi EFL university students’ writing skills, and to explore students’ perceptions of the effectiveness of ChatGPT feedback for improving their writing.",
		"research_gap_or_novelty (研究创新性与知识空白)": "Addresses the lack of studies that directly compare ChatGPT-generated feedback with teacher feedback on actual improvements in students’ writing quality using pretest–posttest data and a shared analytic rubric; uses a detailed rubric-aligned prompt for ChatGPT and a perception survey tailored to the same writing components (content, structure, grammar, punctuation), rather than general acceptability of ChatGPT."
	},
	"Participant Information": {
		"educational_level (教育阶段)": "Tertiary level (university; English Language Institute, female campus)",
		"language_proficiency (语言熟练度水平)": "Intermediate EFL students as determined by a standardized institutional placement test",
		"mother_tongue (母语)": "Arabic (all participants were native Arabic speakers)",
		"sex (性别)": "Female only (102 Saudi female students)",
		"age (年龄)": "18–19 years old",
		"learning_context (学习语境_ESL_EFL_ELL等)": "EFL context at a Saudi university English Language Institute",
		"target_language (目标语言)": "English (L2)",
		"discipline (学科背景)": "University-level English language program (EFL writing course at an English Language Institute)",
		"prior_experience_llm (既有LLM使用经验)": "NR"
	},
	"Methodology": {
		"research_design (研究设计_实验_准实验_纵向等)": "Explanatory sequential mixed-methods design with a pretest–posttest control group experimental design; participants randomly assigned to an experimental group receiving ChatGPT-generated feedback and a control group receiving teacher-generated feedback over an 8-week period.",
		"research_method (研究方法_定量_定性_混合)": "Mixed methods (quantitative pretest–posttest with ANCOVA plus survey statistics, followed by qualitative content analysis of open-ended perception data).",
		"sampling_method (抽样方法)": "Convenience sampling of three existing EFL classes at a female campus of an English Language Institute; within this pool, 102 students were randomly assigned to two groups (ChatGPT feedback vs teacher feedback) based on GPower-specified minimum sample sizes.",
		"sample_size_and_effect (样本量及效应量)": "Total N=102 Saudi female EFL students, randomly assigned to an experimental ChatGPT-generated feedback group (CGF, n=51) and a teacher-generated feedback group (TGF, n=51). Pretest overall writing scores: CGF M=10.83, SD=3.00; TGF M=13.27, SD=1.70; independent samples t-test showed a statistically significant difference with unequal variances (p<.0001). Posttest overall writing scores: CGF M=16.39, SD=2.42; TGF M=17.55, SD=1.01; simple comparison of posttest means showed a difference of 2.45 points (p<.0001). ANCOVA with pretest as covariate indicated no statistically significant difference between groups on posttest scores (F(1,99)=3.874, p=0.052). Effect sizes for group differences were said to be calculated using GPower but specific effect size values were not reported.",
		"theoretical_foundation (理论基础_理论框架)": "Constructivism (learners actively construct knowledge through iterative revision and reflection on feedback) and sociocultural theory with Vygotsky’s Zone of Proximal Development (teacher and ChatGPT feedback as scaffolding tools providing mediated learning and dynamic assessment within learners’ ZPD).",
		"data_collection_instrument (数据收集工具)": "Standardized pretest and posttest paragraph-writing tasks selected from the institution’s assigned textbook; an analytic writing rubric (maximum 20 points) assessing structure (topic sentence, supporting details, concluding sentence), content (relevance, reasons and examples, linking words), grammar (word order, personal pronouns, tenses, comparative and superlative), and punctuation (full stops, capital letters, run-on sentences, fragments, spelling); a detailed ChatGPT prompt aligned with this rubric; a structured Likert-scale perception survey about ChatGPT’s impact on specific writing components plus overall ease of use and experience; and open-ended survey questions about advantages and disadvantages of using ChatGPT feedback.",
		"data_collection_validity_reliability (工具信度与效度)": "Two expert EFL writing raters independently scored pretest and posttest essays using the institutional rubric; the mean of the two scores was used. Inter-rater reliability was examined via Intraclass Correlation Coefficient (ICC), with all ICCs above 0.9 (ChatGPT group pretest ICC=0.993, teacher group pretest ICC=0.988, ChatGPT group posttest ICC=0.984, teacher group posttest ICC=0.943), indicating strong agreement. The ChatGPT perception survey was designed by the researchers, reviewed and validated by three EFL experts, translated into Arabic, and piloted; Cronbach’s alpha was 0.86, indicating high internal consistency. The ChatGPT prompt was iteratively refined by the researchers and evaluated by an ESL expert.",
		"data_analysis_method (数据分析方法)": "Assumption checks via Shapiro–Wilk tests for normality and Levene’s test for homogeneity of variances; independent samples t-test to compare pretest scores between groups; ANCOVA with pretest scores as covariate to compare posttest writing scores between ChatGPT and teacher feedback groups; descriptive statistics (means, weighted mean scores) for survey responses; Cronbach’s alpha for survey reliability; ICC for rater reliability; GPower used to compute required sample size and to assess effect size and power; qualitative content analysis of open-ended survey responses to identify recurring themes about ChatGPT’s advantages and disadvantages.",
		"unit_of_analysis (分析单位)": "Individual student (each student’s writing score on pretest and posttest, and each student’s survey and open-ended responses).",
		"group_assignment_method (组别分配方式_随机_非随机等)": "Random assignment of 102 students into two groups of equal size (n=51 ChatGPT feedback, n=51 teacher feedback) after determining sample size with GPower; participants were originally from three classes but group membership was not strictly by intact class.",
		"power_analysis (功效分析与样本量论证)": "GPower was used prior to data collection to estimate a minimum sample size for two groups at alpha=0.05, power=0.8, and expected effect size=0.6, yielding required n1=45, n2=45 (total 90); the actual sample used was n1=51, n2=51 (total 102). The authors state that GPower was also used to calculate effect size and statistical power for posttest comparisons, but specific effect size values are not reported.",
		"sampling_frame_and_representativeness (抽样框与样本代表性)": "Sampling frame consisted of Saudi female EFL students aged 18–19 at the female campus of an English Language Institute in the western region of Saudi Arabia, all with at least six years of prior English instruction; authors note that this context (single institution, single gender, intermediate proficiency) limits generalizability to other populations.",
		"scoring_procedure_and_rater_training (评分流程与评分者培训)": "Two raters who are experts in EFL writing graded all pretest and posttest paragraphs independently using the institution’s analytic writing rubric (total score 20 points). Their scores were averaged for each script, and ICC values were computed to confirm strong inter-rater reliability (all ICC>0.9). Specific details about formal rater training sessions are not reported, but rubric use and reliability checks are described."
	},
	"Intervention": {
		"duration (干预时长与频率)": "Eight weeks total: week 1 pretest plus ChatGPT training for the experimental group; weeks 2–7 six weekly writing sessions with feedback for both groups; week 8 posttest and ChatGPT perception survey for the experimental group.",
		"llm_model_type (LLM模型类型_如ChatGPT_GPT4_Gemini等)": "ChatGPT (GPT-3.5; generative AI large language model).",
		"llm_model_configuration (LLM模型配置与版本_API_网页_参数等)": "ChatGPT-3.5 accessed as a generative AI chatbot (free version) via its standard web interface; students used a single, detailed instructor-designed prompt specifying level A2 on the CEFR and aligning feedback with the institutional writing rubric; no API access, parameter settings, or access dates were reported.",
		"llm_integration_mode (LLM整合模式_直接使用_教师中介_系统嵌入)": "Students in the experimental group interacted directly with ChatGPT-3.5 using the provided prompt to obtain feedback on drafts; the teacher introduced ChatGPT, provided the prompt, and supervised its use but did not mediate each AI response; the control group did not use ChatGPT and relied solely on teacher feedback.",
		"prompting_strategy (提示策略_提示工程与使用方式)": "A single, highly structured rubric-based prompt instructed ChatGPT to act as an English language instructor, edit the student’s paragraph at A2 level, check structure (topic sentence, at least three supporting sentences, concluding sentence, use of linking words), and grammar (capital letters, full stops, spelling, verb tenses, basic word order, run-on sentences, fragments, personal pronouns). It required ChatGPT to highlight errors, provide a corrected version of the paragraph, and present structural and grammatical errors in separate tables with explanations, examples from the student’s writing, and corrections. The prompt emphasized editing only when there were errors and preserving the student’s text where possible.",
		"training_support_llm_literacy (LLM素养与提示培训)": "In week 1 the experimental group received a structured training session on using ChatGPT-3.5 for writing feedback, including explanation of the technology, demonstration of how to input the detailed prompt and paragraph, and guidance on interpreting ChatGPT’s corrections; this training was justified with reference to recommendations to train students before using new classroom technologies. The perception survey also included an item on awareness of ethical issues such as plagiarism, indicating that academic integrity related to ChatGPT use was at least discussed, though specific training content on ethical use is not fully detailed.",
		"intervention_implementation (干预实施流程_步骤与任务)": "All participants took a standardized pretest (descriptive paragraph) under exam conditions (70 minutes). The experimental group was then trained to use ChatGPT-3.5 with a rubric-aligned prompt. Over six weekly writing sessions, all students wrote paragraphs on different topics; the experimental group submitted their drafts to ChatGPT using the provided prompt, received structured feedback including tables of errors and a revised paragraph, and then revised their writing accordingly; the control group received up to 30 minutes of individualized teacher feedback per week on the same rubric components in one-on-one written and verbal sessions and then revised their paragraphs. By the end of week 7 all students had written and revised six paragraphs. In week 8 both groups completed a standardized posttest (comparison paragraph) under exam conditions, and the experimental group completed a ChatGPT perception survey including Likert-scale items and open-ended questions.",
		"experimental_group_intervention (实验组干预内容)": "Experimental group (ChatGPT-generated feedback, CGF, n=51): after the pretest and ChatGPT training, students wrote one paragraph per week during six sessions, then used ChatGPT-3.5 with the detailed prompt to obtain feedback on structure, content, grammar, and punctuation; ChatGPT produced highlighted errors, explanatory tables for both structural and grammatical issues, and a corrected version of the paragraph; students revised their paragraphs based on this feedback and submitted both original and revised versions; no regular teacher corrective feedback on errors was provided beyond general classroom instruction.",
		"control_group_intervention (对照组干预内容)": "Control group (teacher-generated feedback, TGF, n=51): wrote the same weekly paragraphs as the experimental group but did not use ChatGPT; instead, they received traditional, individualized teacher feedback for up to 30 minutes each week in one-on-one sessions that combined written annotations and verbal guidance aligned with the same rubric components (structure, content, grammar, punctuation); the teacher’s feedback was tailored to each student’s needs and guided subsequent revisions.",
		"writing_stage (写作阶段_如生成_修改_反馈_重写等)": "Post-draft feedback and revision stage: students first drafted paragraphs, then received feedback (from ChatGPT or the teacher) and revised their texts; ChatGPT was not used for initial topic generation but for editing and corrective feedback on existing paragraphs.",
		"writing_genre (写作体裁)": "Single-paragraph academic writing tasks including descriptive paragraphs (pretest and some weekly tasks) and comparative paragraphs (posttest describing and comparing two buildings).",
		"writing_task_type (写作任务类型)": "Standardized exam-type paragraph writing tasks (70-minute descriptive and comparative paragraphs from the course textbook) and six in-class or instructional writing sessions focused on writing and revising comprehensive paragraphs at intermediate EFL level.",
		"role_llm (LLM角色_如生成文本_给反馈_评分_对话等)": "ChatGPT-3.5 acted as an automated writing tutor providing written corrective feedback and editing: identifying and categorizing structural and grammatical errors in tables, explaining errors, suggesting corrections, and generating a corrected version of the student’s paragraph; it did not formally score or grade essays but functioned as a feedback generator and reviser.",
		"role_instructor (教师角色与介入方式)": "A single teacher taught all three original classes and supervised both groups; for the control group the teacher provided individualized corrective feedback each week aligned with the rubric; for the experimental group the teacher introduced and trained students to use ChatGPT and provided general instruction but did not routinely supply parallel corrective feedback on drafts; the teacher also administered pretests, posttests, and surveys and ensured alignment of tasks and criteria across groups.",
		"setting (教学情境_学校类型_课程类型_线上线下)": "Female campus of an English Language Institute in the western region of Saudi Arabia; university-level EFL writing classes conducted face-to-face during a regular academic semester, supplemented with technology-mediated feedback (ChatGPT via web interface for the experimental group; traditional teacher feedback sessions for the control group).",
		"ethical_consideration (伦理审查与知情同意)": "Ethical approval was obtained from the institution’s review board; informed consent was obtained from all participants after explaining the objectives and procedures; participants were informed of their right to withdraw at any time; anonymity and confidentiality were ensured by using pseudonyms and altering personally identifying information, and results were reported in aggregate form.",
		"llm_access_policy (LLM使用规范_允许与限制)": "ChatGPT-3.5 use was permitted only for the experimental group within the context of the writing course and for the purpose of receiving rubric-based feedback on their own paragraphs; students were given a fixed prompt to standardize ChatGPT’s responses; the perception survey included an item on awareness of ethical issues such as plagiarism, indicating that use was framed within academic integrity considerations, though no detailed institutional AI policy or explicit restrictions beyond this study’s design were reported.",
		"llm_safety_guardrails (LLM安全与内容过滤设置)": "No technical safety or content-filter settings for ChatGPT-3.5 were described; educational guardrails consisted of prior explanation of ethical issues (such as plagiarism) and teacher supervision of ChatGPT use; the discussion acknowledges risks such as inaccurate or unrealistic feedback and academic integrity concerns, and it recommends that teachers train students to critically evaluate ChatGPT output rather than rely on it uncritically.",
		"key_findings (主要研究发现_与LLM写作干预相关)": "Both ChatGPT-generated feedback and teacher-generated feedback led to improvements in students’ writing scores from pretest to posttest. Although raw posttest means favored the teacher feedback group (CGF M=16.39 vs TGF M=17.55; difference 2.45, p<.0001), ANCOVA controlling for pretest differences showed no statistically significant difference between the two groups (F(1,99)=3.874, p=0.052), indicating that ChatGPT-generated feedback was overall as effective as teacher-generated feedback in improving writing scores over the 8-week period. Survey data from the ChatGPT group showed high perceived benefits of ChatGPT for improving topic sentences, supporting and concluding sentences, grammar, spelling, fragments and run-ons, capitalization and full stops, and overall writing skills (most item means around 4.0–4.6 on a 5-point scale), and very high ratings for ease of use (mean 4.6), positive feedback experience (mean 4.4) and recommendation to others (mean 4.5). However, participants rated the accuracy of ChatGPT feedback somewhat lower (mean 3.8) and expressed only moderate preference for ChatGPT over their instructor (mean 3.4). Qualitative content analysis of open-ended responses revealed that students appreciated ChatGPT’s immediacy, availability, detailed explanations, support for autonomous learning, and help with structural and grammatical issues, but also reported disadvantages such as unrealistic or unnecessary corrections, added sentences and altered meanings, overly long and complex feedback, and occasional inaccuracies, leading to the conclusion that ChatGPT is a valuable supplementary feedback tool but should not fully replace teacher feedback."
	},
	"Outcome": {
		"application_effectiveness_overview (应用效果总体评价与测量工具)": "Writing improvement was evaluated using standardized pretest and posttest paragraph-writing tasks scored with a 20-point analytic rubric focusing on structure, content, grammar, and punctuation. Both groups improved from pretest to posttest; ANCOVA results indicated no statistically significant difference between ChatGPT-generated feedback and teacher-generated feedback once initial pretest differences were controlled, suggesting comparable effectiveness of ChatGPT and teacher feedback in enhancing Saudi EFL learners’ paragraph writing skills over eight weeks.",
		"writing_performance_measure (写作表现测量工具_量表或评分标准)": "Institutional analytic writing rubric (maximum 20 points) with four main criteria: structure (topic sentence, supporting details, concluding sentence; 5 points), content (on topic, reasons/opinions and examples, linking words; 5 points), grammar (word order, personal pronouns, tenses, comparative and superlative; 5 points), and punctuation (full stops, capital letters, run-on sentences, fragments, spelling; 5 points).",
		"writing_performance_focus (写作表现关注维度_流利度_准确性_复杂度_体裁等)": "Accuracy and quality of paragraph structure (presence and clarity of topic and concluding sentences, development of supporting details), content relevance and coherence (on-topic information, reasons and examples, use of linking words), grammatical accuracy (word order, correct pronoun and tense use, comparative/superlative forms), and mechanical accuracy (punctuation, capitalization, avoidance of fragments and run-on sentences, spelling).",
		"affective_aspect_measure (情感因素测量工具_问卷_量表等)": "Structured perception survey administered to the ChatGPT group after the intervention, using 5-point Likert-scale items (strongly disagree to strongly agree) on perceived improvements in specific writing components, ease of use, overall satisfaction, preference compared to teacher feedback, perceived accuracy, and awareness of ethical issues; plus open-ended survey questions prompting students to express their opinions about using ChatGPT for developing writing skills, including perceived advantages and disadvantages.",
		"affective_aspect_focus (情感因素维度_动机_态度_焦虑_自效感等)": "Students’ attitudes toward ChatGPT as a feedback tool (enjoyable, amazing, useful), satisfaction with the feedback process, perceived support for autonomous learning and confidence, preference for ChatGPT versus teacher feedback, perceived accuracy and trustworthiness of feedback, and awareness of ethical concerns such as plagiarism.",
		"cognitive_aspect_measure (认知因素测量工具)": "Qualitative content analysis of open-ended responses in the ChatGPT perception survey focusing on reflections about how ChatGPT feedback affected their understanding of writing elements (structure, grammar, punctuation) and their learning processes.",
		"cognitive_aspect_focus (认知因素维度_策略使用_元认知监控等)": "Learners’ perceived development of self-directed learning strategies (using ChatGPT to independently identify and correct errors), increased noticing of structural and grammatical problems through detailed tables and explanations, greater awareness of appropriate tense use and sentence structure, and reflective evaluation of ChatGPT’s suggestions (including recognizing when corrections are inaccurate or over-elaborate).",
		"behavioral_aspect_measure (行为因素测量工具_日志_平台日志等)": "No automated usage logs were reported; behavioral insights were derived from survey items and open-ended responses regarding how and when students used ChatGPT and how it influenced their writing and revision practices.",
		"behavioral_aspect_focus (行为因素维度_使用频率_交互模式_坚持度等)": "Described patterns include weekly use of ChatGPT for feedback on six writing tasks, immediate iterative revisions after receiving ChatGPT feedback, recommendations for other students to use ChatGPT especially those reluctant to show errors to teachers, and some reports that the length and complexity of ChatGPT feedback sometimes hindered effective use.",
		"other_outcomes_measure (其他结果测量工具)": "Open-ended survey questions asking students to describe their overall experience with ChatGPT, perceived usefulness, and perceived advantages and disadvantages; content analysis used to summarize recurring themes.",
		"other_outcomes_focus (其他结果维度说明)": "Qualitative themes about ChatGPT as an enjoyable and motivating tool, a support for independent learning, a helpful resource for multiple courses, a form of low-anxiety feedback for reluctant learners, as well as concerns about unrealistic corrections, added or altered content, over-complex wording, limited improvement for some students, and the need to avoid complete dependence on ChatGPT.",
		"assessment_timepoints (评估时间点_前测_后测_延迟测等)": "Pretest at week 1 (diagnostic descriptive paragraph); six weekly feedback cycles during weeks 2–7 (paragraph writing, feedback, revision); posttest at week 8 (comparative paragraph); no delayed posttest or long-term follow-up reported.",
		"primary_outcome_variables (主要结果变量_因变量)": "Posttest overall writing scores (0–20) for each student, with pretest writing scores used as covariates in ANCOVA; subscores by rubric criterion were conceptually important but not reported as separate statistical outcomes.",
		"independent_variables_and_factors (自变量与实验因素)": "Type of feedback with two levels (ChatGPT-generated feedback vs teacher-generated feedback) as the main independent variable; pretest writing score as a covariate; no additional between-subject factors such as proficiency band or age were modeled.",
		"followup_length_and_type (随访时长与类型)": "NA (no delayed follow-up assessment beyond the immediate posttest at the end of the 8-week intervention).",
		"statistical_significance (统计显著性结果摘要)": "Shapiro–Wilk tests indicated data were reasonably normal (reported statistics for CGF and TGF), while Levene’s test showed unequal variances for some comparisons (p<.0001 for pretest scores). Pretest independent samples t-test revealed a significant baseline difference favoring the teacher feedback group (TGF M=13.27 vs CGF M=10.83, p<.0001). Posttest descriptive statistics showed CGF M=16.39, SD=2.42 and TGF M=17.55, SD=1.01; the initial comparison of posttest means indicated a significant difference (mean difference 2.45, t≈5.08, p<.0001). However, ANCOVA with pretest as covariate indicated that the treatment effect on posttest scores was not statistically significant (Treatment F=3.874, p=0.052; Pretest covariate F=3.811, p=0.054), leading to the conclusion that ChatGPT and teacher feedback were comparably effective when accounting for baseline differences.",
		"effect_size_summary (效应量摘要)": "The authors report using GPower to compute effect size and power, and they designed the study assuming an effect size of 0.6, but specific effect size estimates (such as Cohen’s d or partial eta squared) for the observed group differences are not reported; thus exact effect sizes for the ChatGPT vs teacher feedback comparison are NR.",
		"llm_misuse_or_negative_effects (LLM滥用或负向效应)": "Students and authors noted several negative aspects of ChatGPT feedback: instances of inaccurate or unrealistic corrections (e.g., misidentification of correct structures as errors, inappropriate preposition changes), insertion of additional sentences not in the original text, over-elaborate rephrasing that adds unnecessary information or alters the original meaning, and occasional misclassification of errors (such as labeling a complete sentence as a fragment). Some students reported that their writing had not improved substantially or that ChatGPT’s lengthy and complex feedback was confusing, especially for lower proficiency learners. The discussion also highlights broader risks such as AI hallucinations, potential bias, and academic integrity concerns, including plagiarism, emphasizing that ChatGPT cannot fully replace teacher feedback and should be used critically and with guidance.",
		"equity_and_subgroup_effects (公平性与亚组差异)": "NR (no subgroup analyses by proficiency band, age, or other demographic factors were conducted; the sample consisted solely of Saudi female students aged 18–19 at one institution).",
		"limitation (研究局限)": "Limitations noted include: single-institution and single-gender sample of Saudi female intermediate EFL learners, restricting generalizability; use of only ChatGPT-3.5 and a single detailed prompt, making results context- and design-specific; relatively short intervention duration (8 weeks) with no delayed posttest, so long-term retention of writing gains was not assessed; baseline differences in pretest writing scores between groups requiring ANCOVA adjustment; moderate sample size that, although adequate per GPower, could be expanded in future studies; no detailed analysis of differences in feedback characteristics (length, clarity, or complexity) between ChatGPT and teacher feedback.",
		"challenge (实施挑战与风险)": "Implementation challenges include the time and effort required for traditional individualized teacher feedback in large classes, the need to train students to effectively use ChatGPT, the occurrence of inaccurate, off-target, or over-long ChatGPT feedback that can confuse students, particularly those with lower proficiency, and the risk that students may rely too heavily on ChatGPT and reduce their own independent thinking and creativity; managing academic integrity and preventing misuse of ChatGPT-generated content is also identified as a concern.",
		"future_work (未来研究方向)": "The authors recommend future research that varies prompt design and context of ChatGPT use to examine how these factors influence feedback effectiveness; compares different proficiency levels, including advanced learners, and includes more extended interactions with ChatGPT; incorporates delayed posttests to assess long-term retention of writing improvements; analyzes detailed characteristics of ChatGPT vs teacher feedback (such as length, complexity, clarity) and their impact on student uptake; increases sample size and broadens contexts beyond one female campus; compares multiple AI feedback tools rather than focusing solely on ChatGPT; and explores newer ChatGPT versions (e.g., GPT-4 or GPT-4o) with enhanced capabilities.",
		"implication (理论与教学实践启示)": "The study suggests that ChatGPT-generated feedback can achieve writing improvements comparable to traditional teacher feedback for intermediate Saudi EFL learners, supporting its use as a supplementary tool to provide immediate, individualized corrective feedback and to scaffold autonomous learning within constructivist and sociocultural frameworks. Practically, the authors advocate integrating ChatGPT into writing instruction to alleviate teacher workload in large classes while providing rubric-aligned feedback on structure, content, grammar, and punctuation, but emphasize that teachers must oversee use, provide training in critical evaluation of AI output and ethical usage, and continue to offer human feedback, especially for nuanced and complex issues. The findings underscore the need for teacher professional development in AI-assisted feedback, careful design of prompts and rubrics, and balanced use of AI and human feedback to optimize writing instruction and maintain academic integrity."
	},
	"Study Quality and Reporting": {
		"funding_source (经费来源)": "The authors reported that they received no financial support for the research, authorship, or publication of the article.",
		"conflict_of_interest (利益冲突声明)": "The authors declared no potential conflicts of interest with respect to the research, authorship, or publication of the article.",
		"risk_of_bias_randomization (偏倚风险_分配与随机化)": "Participants were randomly assigned to the ChatGPT feedback and teacher feedback groups, and sample size was determined a priori using G*Power; however, a significant baseline difference in pretest writing scores between groups remained, suggesting imperfect randomization at the outcome level, which was handled analytically via ANCOVA with pretest as covariate.",
		"risk_of_bias_blinding (偏倚风险_盲法)": "Students and the teacher necessarily knew their assigned feedback condition; the paper does not explicitly state whether raters of the pretest and posttest paragraphs were blind to group and time point when scoring, so blinding of outcome assessment is NR.",
		"attrition_and_missing_data (流失与缺失数据处理)": "No information is provided on participant attrition, dropouts, or missing data during the 8-week study; analyses appear to be based on the full sample of 102 students, but explicit handling of missing data is NR.",
		"reporting_transparency (报告透明度与可重复性)": "The study reports detailed information about context, participants, design, instruments, procedures, analytic methods, reliability estimates (ICC, Cronbach’s alpha), and key statistical results (means, variances, test statistics, p-values). The writing rubric structure and the full ChatGPT prompt are described, and survey items are included in an appendix, supporting a relatively transparent and replicable report.",
		"preregistration_or_protocol (预注册或研究方案)": "NR (no mention of preregistration or a publicly available study protocol).",
		"llm_version_reproducibility (LLM版本与可复现性)": "The study identifies the AI tool as ChatGPT-3.5 and provides the exact feedback prompt used, which supports some reproducibility; however, it does not specify the exact time frame of ChatGPT access or model updates, and given that LLM behavior may change over time, replicating the exact conditions may be challenging.",
		"baseline_equivalence (基线等同性检验)": "Baseline equivalence on writing performance was tested and not achieved: pretest scores for the teacher feedback group were significantly higher than for the ChatGPT group (p<.0001). This imbalance was addressed by using ANCOVA with pretest as a covariate to compare posttest outcomes.",
		"assumption_check_and_data_diagnostics (统计假设检验与数据诊断)": "Shapiro–Wilk tests were used to assess normality and indicated that the data were reasonably normal; Levene’s test showed unequal variances for pretest scores; ANCOVA was used to adjust for baseline differences. No further details are given on checks of other ANCOVA assumptions such as homogeneity of regression slopes or additional diagnostics of residuals.",
		"outlier_treatment_and_sensitivity_analysis (异常值处理与稳健性分析)": "NR (no specific procedures for identifying or handling outliers, nor sensitivity analyses, are reported).",
		"data_preprocessing_and_transformation (数据预处理与转换)": "Pretest and posttest writing scores from two raters were averaged after verifying high ICC values; survey responses were digitized via Google Forms and analyzed using descriptive statistics and Cronbach’s alpha; open-ended responses were subjected to qualitative content analysis. No statistical data transformations or scaling beyond the use of rubric scores and Likert scaling are reported."
	}
}