{
	"Basic Identification": {
		"author (作者)": "Ruofei Zhang; Di Zou; Gary Cheng",
		"publication_year (发表年份)": "2025",
		"study_region (研究地区)": "Hong Kong Special Administrative Region, China",
		"journal_name (期刊名称)": "System",
		"study_type (研究类型_期刊论文_会议论文等)": "Journal article; concurrent triangulation mixed-method one-group pre-test immediate post-test delayed post-test experimental study",
		"doi_or_identifier (DOI或唯一标识)": "https://doi.org/10.1016/j.system.2024.103561",
		"research_aims (研究目的与问题)": "To develop a GPT-4 based logic learning chatbot LogicalHamster and engage Chinese EFL university students in ChatGPT based logic learning in order to explore ChatGPT affordances for logic learning strategies and examine the usefulness of ChatGPT based logic learning strategies for developing knowledge of logic and quality of logic in English argumentative writing, guided by two research questions on the extent and mechanisms of such support and its influence on outcomes.",
		"research_gap_or_novelty (研究创新性与知识空白)": "Addresses the lack of empirical research on ChatGPT based logic learning and on learning strategies in ChatGPT based environments, goes beyond conventional rule based chatbots with limited autonomy to a GPT-4 based bot, proposes and tests a conceptual framework of five logic learning strategies and 12 sub strategies in ChatGPT based logic learning, and empirically links frequencies of strategy use with gains in logical knowledge and logical quality in English argumentative writing."
	},
	"Participant Information": {
		"educational_level (教育阶段)": "Chinese EFL university students including undergraduates and postgraduates at a Hong Kong university",
		"language_proficiency (语言熟练度水平)": "EFL learners enrolled in English as a medium of instruction courses who frequently needed to complete EFL argumentative writings; no standardised proficiency scores reported",
		"mother_tongue (母语)": "Chinese",
		"sex (性别)": "Total N=40; 32 female and 8 male",
		"age (年龄)": "Age range 18–27 years, mean 22.85, SD 3.05",
		"learning_context (学习语境_ESL_EFL_ELL等)": "EFL learners studying in English as a medium of instruction university courses in Hong Kong",
		"target_language (目标语言)": "English (L2)",
		"discipline (学科背景)": "Students from a Hong Kong university taking English as a medium courses; specific majors or disciplines not reported",
		"prior_experience_llm (既有LLM使用经验)": "Participants had experience with technology enhanced learning and no technophobia and were selected to have no prior experience in logic learning, no prior experience in ChatGPT based learning, and no prior prompt engineering training; prior casual use of ChatGPT outside learning was not reported"
	},
	"Methodology": {
		"research_design (研究设计_实验_准实验_纵向等)": "Concurrent triangulation mixed method design with a single group of EFL learners completing pre test, immediate post test, and one week delayed post test of knowledge of logic plus pre learning argumentative essay writing and post learning logic focused revision, combined with analysis of learner bot conversation logs and semi structured interviews",
		"research_method (研究方法_定量_定性_混合)": "Mixed methods combining quantitative analyses of test and writing scores and prompt frequencies with qualitative content analysis of semi structured interviews and chat interactions",
		"sampling_method (抽样方法)": "Voluntary response sampling from a Hong Kong university followed by screening via an online pre treatment report to exclude students who did not frequently need to write EFL argumentative essays and those with prior logic learning; incentives in the form of gift cards were provided to reduce voluntary response bias",
		"sample_size_and_effect (样本量及效应量)": "Fifty two students initially signed up and completed a pre treatment report; 9 who did not frequently need to complete EFL argumentative writings and 3 with prior logic learning were excluded, yielding N=40 participants (32 female, 8 male, age 18–27, M=22.85, SD=3.05). Knowledge of logic test scores (0–21) increased from pre test M=6.32, SD=2.84 to immediate post test M=16.48, SD=3.91 and delayed post test M=15.63, SD=3.78. Quality of logic in argumentative writing scored from 0–100 increased from initial writing M=71.38, SD=8.43 to post learning revision M=78.00, SD=8.20. Welch ANOVA on prompt frequencies across 12 sub strategies showed significant differences with F(11, 182.90)=22.22, p<.001 and omega squared about 0.41. PLS SEM showed significant paths including Exercising strategies to writing logic outcomes with beta about 0.31 and f squared about 0.148 and a near significant path from Gathering strategies to knowledge outcomes with f squared about 0.187; other effect size indices for pre post changes were not reported.",
		"theoretical_foundation (理论基础_理论框架)": "Builds on literature on logic in English argumentative writing and reasoning errors, logic learning strategies for EFL learners, models of learning strategies such as Bloom revised taxonomy, Kolb experiential learning theory, and Merrill principles of instruction, research on chatbot based learning and AI and generative AI for writing, and research on ChatGPT based learning; develops a conceptual framework in which ChatGPT affords five main logic learning strategies Gathering, Understanding, Exercising, Analysing, and Crafting, which in turn influence knowledge of logic and quality of logic in English argumentative writing while being moderated by learner prior knowledge and prior writing quality.",
		"data_collection_instrument (数据收集工具)": "Pre treatment online report via Wenjuanxing to collect biographical data, needs for EFL argumentative writing, technophobia, and prior experience with technology enhanced learning, logic learning, ChatGPT based learning, and prompt engineering; GPT-4 based POE bot LogicalHamster for ChatGPT based logic learning and capture of learner prompts; paper based knowledge of logic test lasting 30 minutes administered at pre test, immediate post test, and one week delayed post test, adapted from earlier work and requiring identification and explanation of seven common reasoning errors and matching them to terms; English argumentative essay writing task before learning using an IELTS style prompt of about 250 words in 40 minutes; post learning logic focused revision of the same essay in 30 minutes without reference materials; scoring rubrics for knowledge test and for logic quality in writing adapted from prior instruments including Illinois Critical Thinking Essay Scoring Rubric and IELTS academic writing criteria; prompt coding scheme for 12 sub strategies; semi structured interview protocol with questions on frequency and perceived impact of each learning strategy type.",
		"data_collection_validity_reliability (工具信度与效度)": "LogicalHamster was piloted with five similar students who used it for over 45 minutes and were interviewed; its conversations were examined by two authors who confirmed consistently friendly, positive, unbiased style and checked instructional content on logic against standard sources, finding no bias or inaccuracy. Knowledge tests were blind scored by the research team using a three point scoring system per fallacy with total scores 0–21; scorer agreement had Pearson r of 0.96 and discrepancies were resolved through discussion. Logic quality in initial and revised essays was blind scored by two authors and a colleague on a 0–100 scale using an analytic rubric; scorer correlations were r=0.87 for initial writing and r=0.85 for revisions. Prompt coding into 12 sub strategies had Cohen kappa of 0.83, and interview coding had Cohen kappa of 0.84. For the PLS SEM measurement model, indicator loadings, composite reliabilities, AVE, HTMT, and VIF values indicated acceptable reliability and convergent and discriminant validity after removing the Crafting construct with low internal consistency.",
		"data_analysis_method (数据分析方法)": "Prompt logs from LogicalHamster were repeatedly read and coded into five main strategy categories and 12 sub strategies, with frequencies per participant computed; descriptive statistics were used to summarise average total prompts and per strategy prompts. Welch one way ANOVA with omega squared effect size and Tukey HSD post hoc tests were conducted in SPSS to compare frequencies of different sub strategies. Interview transcripts in Chinese were subjected to qualitative content analysis following Mayring with inductive coding into categories relating to frequency of strategy use and perceived impacts; codes were compared for inter coder reliability and representative quotations were selected and translated into English. Quantitative analysis used SPSS and R, including descriptive statistics of knowledge test and writing scores, tests of linearity, homoscedasticity, and normality, one way ANOVA, multiple linear regressions for predictive power of strategies on outcomes while controlling for learner factors, and Partial Least Squares Structural Equation Modelling using the SEMinR package in R with bootstrapping of 10,000 subsamples to estimate path coefficients, f squared, and confidence intervals.",
		"unit_of_analysis (分析单位)": "Individual learner for test scores, writing scores, and interview perceptions; individual learner prompt counts by strategy type for behavioural analysis; individual essay for logic quality scoring",
		"group_assignment_method (组别分配方式_随机_非随机等)": "Single group design; participants were volunteers who met inclusion criteria and were not randomly allocated to different experimental or control conditions",
		"power_analysis (功效分析与样本量论证)": "No a priori power analysis was reported; the authors noted that the final sample size of N=40 met general rules of thumb for ANOVA, multiple regression, and PLS SEM and used G Power post hoc to indicate high power for some R squared tests",
		"sampling_frame_and_representativeness (抽样框与样本代表性)": "Sampling frame consisted of Chinese EFL university students at a single university in Hong Kong who were enrolled in English as a medium courses and frequently completed EFL argumentative writing; only those without technophobia and without prior logic learning or ChatGPT based learning were included; the sample was gender imbalanced with 32 females and 8 males and limited to tertiary students, which restricts representativeness beyond similar EFL EMI university contexts.",
		"scoring_procedure_and_rater_training (评分流程与评分者培训)": "Knowledge tests from the three time points were blind scored by members of the research team using a predefined rubric that awarded up to two points for correct explanation of each fallacy and one point for correct term matching; high inter rater agreement was obtained and disagreements were resolved through discussion. Initial and revised essays were blind scored by two authors and an experienced colleague using an analytic rubric with four logic related dimensions each scored from 0 to 25; again high inter rater correlations were achieved and differences were settled through discussion. No formal rater training session is described beyond these procedures."
	},
	"Intervention": {
		"duration (干预时长与频率)": "The study lasted three weeks: Week 1 involved pre treatment survey, participant selection, consent, a 20 minute orientation to logic in English argumentative writing and ChatGPT based logic learning, and collection of prior essays; Week 2 included a pre learning argumentative essay writing task, a 30 minute pre test of knowledge of logic, and a single self paced ChatGPT based logic learning session with LogicalHamster constrained to 45–75 minutes followed immediately by a 30 minute logic focused revision of the essay and a 30 minute immediate post test; Week 3 comprised a 30 minute delayed post test one week after learning.",
		"llm_model_type (LLM模型类型_如ChatGPT_GPT4_Gemini等)": "ChatGPT GPT-4 based bot LogicalHamster deployed on the POE platform",
		"llm_model_configuration (LLM模型配置与版本_API_网页_参数等)": "LogicalHamster was implemented as a POE bot powered by GPT-4 and configured to teach seven common reasoning errors relevant to English argumentative writing Begging the Question, Red Herrings, Hasty Generalisation, Faulty Analogy, Post Hoc, False Alternatives, and Slippery Slope; it was programmed to support five categories of logic learning strategies by generating personalised instructions at varying difficulty levels, asking and answering exploratory questions, creating and adjusting diverse exercise formats with immediate feedback, suggesting ways to analyse logic in authentic texts, and providing references and comments to help learners craft logical links; it used a humorous and supportive tone, offered praise and encouragement, and provided strategy related guiding questions based on learner progress; exact model parameters such as temperature and detailed system prompts were not reported.",
		"llm_integration_mode (LLM整合模式_直接使用_教师中介_系统嵌入)": "Students interacted directly with the GPT-4 based LogicalHamster bot via the POE web interface on desktop computers in a computer lab, typing prompts and receiving responses in real time in a self paced single session; the bot acted as an external tutor and learning partner rather than being embedded in an LMS or mediated through the teacher.",
		"prompting_strategy (提示策略_提示工程与使用方式)": "Learners generated their own natural language prompts to LogicalHamster to request instructions, ask for examples, pose and answer exploratory questions, request and modify exercises, submit their essays for analysis, and seek references and feedback on logical links, thus enacting Gathering, Understanding, Exercising, Analysing, and Crafting strategies; LogicalHamster complemented this with guiding questions and suggestions about which strategies to use based on learner histories and progress and responded in a supportive conversational style; there was no explicit training in advanced prompt engineering techniques beyond encouraging learners to clearly state their desired formats and tasks such as asking for a paragraph containing a reasoning error to identify.",
		"training_support_llm_literacy (LLM素养与提示培训)": "Before the main learning session, participants received a 20 minute orientation introducing knowledge and quality of logic in English argumentative writing, ChatGPT, and ChatGPT based logic learning; for interview purposes the concepts of the five logic learning strategies were later explained and checked for understanding; no extensive training in broader AI literacy, academic integrity, or systematic prompt engineering was reported, and learners were largely expected to learn to interact with the bot through hands on experience and the bot’s guiding suggestions.",
		"intervention_implementation (干预实施流程_步骤与任务)": "In Week 1, after completing an online pre treatment report and being screened for eligibility, 40 students provided consent and attended a short orientation covering logic in English argumentative writing and ChatGPT based logic learning, and each submitted a digital copy of a prior English argumentative essay to be used later. In Week 2, participants first wrote a 250 word English argumentative essay in 40 minutes on an IELTS style topic without reference materials and then completed a 30 minute paper based pre test of knowledge of logic, with the ordering chosen so that the test would not influence the writing. Next, they engaged in ChatGPT based logic learning for 45–75 minutes using LogicalHamster in a computer lab, with the first author present only to offer technical support if requested and otherwise not intervening; learners used LogicalHamster to receive explanations of seven reasoning errors, ask exploratory questions, request and complete exercises with feedback, analyse the logic of their own prior essays, and craft or modify logical links with the bot’s suggestions. Immediately after this learning session, participants revised the logic of the essays they had just written in a 30 minute revision task without access to references and then completed an immediate post test of knowledge of logic in 30 minutes. In Week 3, they took an identical delayed post test one week later to assess retention; a random subset of 20 learners participated in semi structured interviews immediately after the learning and revision session while reviewing their chat histories with LogicalHamster.",
		"experimental_group_intervention (实验组干预内容)": "All 40 participants formed a single experimental cohort that experienced ChatGPT based logic learning with LogicalHamster, involving self paced interaction with the GPT-4 bot to gather logic instructions, deepen understanding through questioning and examples, undertake personalised exercises with feedback, analyse logic in their own argumentative essays, and craft or revise logical links under guidance, followed by immediate and delayed assessment of knowledge and writing logic; there was no separate control group receiving a different intervention.",
		"control_group_intervention (对照组干预内容)": "NA",
		"writing_stage (写作阶段_如生成_修改_反馈_重写等)": "Both initial drafting and subsequent revision with a focus on logical reasoning and coherence in English argumentative writing, particularly revising and creating logical links in response to newly acquired logical knowledge from the ChatGPT based learning session",
		"writing_genre (写作体裁)": "Individual English argumentative essays of about 250 words on a standardised topic similar to IELTS academic writing task 2",
		"writing_task_type (写作任务类型)": "Timed individual argumentative writing task followed by a timed logic focused revision of the same essay without reference materials or external tools",
		"role_llm (LLM角色_如生成文本_给反馈_评分_对话等)": "The GPT-4 based LogicalHamster acted as a logic tutor, instructional content generator, exercise generator and evaluator, analyser of logic in authentic argumentative texts including learners essays, and a conversational partner offering personalised suggestions and comments to help learners understand and apply logical concepts and revise logical links; it did not formally score the main pre and post tests or serve as an automated grader for the outcome measures.",
		"role_instructor (教师角色与介入方式)": "Researchers designed the LogicalHamster bot, piloted and refined its behaviour, developed and adapted the knowledge tests and writing tasks, recruited and screened participants, delivered a brief orientation session, monitored the computer lab during ChatGPT based learning to provide technical support on request while avoiding instructional intervention, administered tests and tasks, conducted and analysed interviews, coded prompts, and scored the tests and essays using established rubrics.",
		"setting (教学情境_学校类型_课程类型_线上线下)": "University setting at a Hong Kong institution where students were taking English as a medium of instruction courses; ChatGPT based learning took place in a campus computer lab with each student using a desktop computer and the POE interface to access LogicalHamster; writing tasks were completed in Microsoft Word offline under timed conditions; overall context is a higher education EFL logic and writing development setting.",
		"ethical_consideration (伦理审查与知情同意)": "Participants completed consent forms before the intervention; anonymity of data was ensured and performance in the study had no academic consequences; students were explicitly informed of their right to withdraw at any time; the authors stated that the research met ethical guidelines and legal requirements of the study country and that data could not be shared publicly due to sensitivity and lack of consent for public sharing.",
		"llm_access_policy (LLM使用规范_允许与限制)": "During the logic learning session participants used only the GPT-4 based LogicalHamster via POE for learning and were not described as using other AI tools; the writing and revision tasks and knowledge tests were completed without reference materials or external assistance; participants had had no prior ChatGPT based learning or prompt engineering training by design; no broader institutional AI usage policy was reported.",
		"llm_safety_guardrails (LLM安全与内容过滤设置)": "The researchers manually examined LogicalHamster outputs in the pilot to ensure a friendly, positive, and unbiased tone and cross checked logical instruction against standard references, finding no bias or inaccuracy; beyond this content validation and tone adjustment, no specific mention was made of additional safety filters, content moderation features, or technical guardrails built into the bot or platform.",
		"key_findings (主要研究发现_与LLM写作干预相关)": "Learners produced on average about 36 learning related prompts each, with substantial use of all five strategy categories and 12 sub strategies, indicating that ChatGPT via LogicalHamster afforded diverse logic learning strategies; Exercising and Gathering strategies were most frequently enacted, especially prompts for Doing exercises, Asking for instructions, and Asking for exercises, whereas prompts for Crafting and some Analysing sub strategies were less frequent. Interviews confirmed that students often used Gathering, Understanding, and Exercising strategies and that they valued LogicalHamster’s friend like emotional support, high autonomy, and guiding suggestions, but found Analysing and Crafting cognitively demanding and occasionally hindered by shallow or general responses. Knowledge of logic scores increased substantially from pre test to immediate post test and remained high at delayed post test, indicating that ChatGPT based logic learning effectively developed learners knowledge of logic. Quality of logic in argumentative writing improved from initial essays to post learning revisions. PLS SEM and regression analyses showed that Gathering strategies, particularly asking for further elaboration of instructions, significantly predicted gains in knowledge of logic, and that Exercising strategies significantly influenced improvements in quality of logic in writing, after controlling for prior knowledge and prior writing quality. Understanding, Analysing, and Crafting strategies were perceived as useful but did not show statistically significant paths in the structural model, possibly due to lower usage and limitations in depth and complexity of GPT generated materials. Overall, ChatGPT based logic learning supported logic knowledge and logical quality in English argumentative writing through a combination of personalised input, practice, and strategy rich interaction."
	},
	"Outcome": {
		"application_effectiveness_overview (应用效果总体评价与测量工具)": "Effectiveness of the ChatGPT based logic learning was evaluated using a paper based knowledge of logic test at three time points, analytic scoring of pre learning and post learning revision argumentative essays for quality of logic, coded frequencies of learner prompts representing different logic learning strategies, and semi structured interviews on perceptions; results showed large gains in knowledge of logic that were sustained at one week and significant improvements in logical quality of writing, with specific logic learning strategies, particularly Gathering and Exercising, associated with these gains.",
		"writing_performance_measure (写作表现测量工具_量表或评分标准)": "Analytic rubric adapted from Illinois Critical Thinking Essay Scoring Rubric and IELTS academic writing criteria scoring quality of logic on four dimensions supporting reasons, reasoning, commitment of logical fallacies, and coherence each from 0 to 25, summed to a total logic quality score from 0 to 100 for both initial essays and post learning revisions.",
		"writing_performance_focus (写作表现关注维度_流利度_准确性_复杂度_体裁等)": "Quality of logic in English argumentative writing focusing on accuracy, relevance, and sufficiency of evidence supporting arguments, clarity and convincingness of reasoning, frequency and seriousness of logical fallacies such as reasoning errors, and logical coherence and sequencing of ideas throughout the essay.",
		"affective_aspect_measure (情感因素测量工具_问卷_量表等)": "Semi structured interviews with 20 randomly selected participants conducted immediately after ChatGPT based learning and revision, using concept checked explanations of the five logic learning strategies and eliciting reported frequency of strategy use and perceived positive, neutral, negative, or mixed impacts on their learning; pre treatment survey also measured technophobia and prior experience with technology enhanced learning.",
		"affective_aspect_focus (情感因素维度_动机_态度_焦虑_自效感等)": "Learners perceptions of ChatGPT based logic learning and logic learning strategies, including motivation to engage in strategy use, feelings of autonomy and control, perceived emotional support from LogicalHamster, stress or exhaustion associated with cognitively demanding strategies such as Analysing and Crafting, enjoyment of humorous and vivid examples, and judgments about usefulness or limitations of ChatGPT responses.",
		"cognitive_aspect_measure (认知因素测量工具)": "Paper based knowledge of logic test of 21 points administered at pre test, immediate post test, and one week delayed post test, adapted from prior work, requiring students to identify reasoning errors in argument sentences, explain how and why each sentence commits a reasoning error, and match each error to one of seven named fallacies; tests were identical across time points to ensure internal validity and were blind scored with high inter rater agreement.",
		"cognitive_aspect_focus (认知因素维度_策略使用_元认知监控等)": "Knowledge of logic in English argumentative writing including understanding of seven reasoning errors such as Begging the Question, Red Herrings, Hasty Generalisation, Faulty Analogy, Post Hoc, False Alternatives, and Slippery Slope, and the ability to recognise, explain, and label these fallacies in English arguments.",
		"behavioral_aspect_measure (行为因素测量工具_日志_平台日志等)": "Systematic coding and counting of learner prompts sent to LogicalHamster retrieved from the POE system, categorised into five strategy types and 12 sub strategies such as Asking for instructions, Asking for further elaboration of instructions, Paraphrasing logical concepts, Asking exploratory questions, Asking for exercises, Doing exercises, Adjusting exercise format, Asking for advice for analysing logic, and Asking for references or comments on logical links; descriptive statistics, ANOVA, and PLS SEM used these prompt counts as behavioural indicators of strategy use.",
		"behavioral_aspect_focus (行为因素维度_使用频率_交互模式_坚持度等)": "Frequency and distribution of different logic learning strategies during ChatGPT based learning, patterns of interaction with LogicalHamster including how often learners requested instruction versus exercises versus analysis and crafting support, responsiveness to guiding suggestions, and variation in engagement with more cognitively demanding strategies.",
		"other_outcomes_measure (其他结果测量工具)": "PLS SEM model using latent constructs for Gathering, Understanding, Exercising, and Analysing strategies, learner prior knowledge and prior writing quality, and outcomes for knowledge of logic and quality of logic in writing; multiple linear regression models predicting immediate and delayed test scores and post learning writing logic scores; Welch ANOVA and Tukey HSD tests on prompt frequencies; qualitative content analysis of interview transcripts.",
		"other_outcomes_focus (其他结果维度说明)": "Relationships between frequencies of specific ChatGPT based logic learning strategies and changes in knowledge of logic and writing logic, the moderating roles of prior knowledge and prior quality of logic in writing, learners perspectives on ChatGPT affordances and limitations, and identification of ChatGPT features such as personalisation, emotional support, and response depth that influence both frequency and effectiveness of strategy use.",
		"assessment_timepoints (评估时间点_前测_后测_延迟测等)": "Pre treatment online survey; Week 2 initial argumentative essay writing task; Week 2 pre test of knowledge of logic; Week 2 ChatGPT based logic learning session; Week 2 post learning logic focused revision of the essay; Week 2 immediate post test of knowledge of logic; Week 2 immediate post learning semi structured interviews with a subsample; Week 3 delayed post test of knowledge of logic one week after learning.",
		"primary_outcome_variables (主要结果变量_因变量)": "Knowledge of logic test scores at pre test, immediate post test, and delayed post test; quality of logic scores for initial argumentative essays and post learning revisions; latent composite scores for knowledge outcomes and writing logic outcomes in PLS SEM; learner perceived effectiveness of learning strategies from interviews.",
		"independent_variables_and_factors (自变量与实验因素)": "Frequency counts of learner prompts representing Gathering, Understanding, Exercising, Analysing, and Crafting strategies and their 12 sub strategies; learner prior knowledge of logic operationalised as pre test scores; learner prior quality of logic in argumentative writing operationalised as initial writing logic scores; learner level factors such as age and gender were described but not used as predictors in the main models.",
		"followup_length_and_type (随访时长与类型)": "One week delayed post test of knowledge of logic administered after the ChatGPT based logic learning and revision session to assess short term retention; no longer term follow up for writing performance was conducted.",
		"statistical_significance (统计显著性结果摘要)": "Descriptive statistics showed substantial increases in knowledge of logic from pre test M about 6.3 to immediate post test M about 16.5 and delayed post test M about 15.6 out of 21; quality of logic in writing increased from initial essays M about 71.4 to revisions M about 78.0 out of 100. Welch ANOVA on prompt frequencies across 12 sub strategies was significant with F approximately 22.22 and p<.001, indicating different levels of use by strategy. PLS SEM results indicated a significant path from Exercising strategies to ChatGPT based learning outcomes in quality of logic in writing with beta around 0.31 and f squared around 0.148, and a near significant path from Gathering strategies to knowledge outcomes with f squared around 0.187; multiple regression showed that after controlling for pre test scores, the number of prompts asking for further elaboration of instructions significantly predicted higher immediate post test scores with a regression coefficient of about 0.71 and p about .04 and that prior knowledge and prior writing quality were significant predictors of respective outcomes; other paths such as from Understanding, Analysing, and Crafting strategies were not statistically significant at the 5 percent level.",
		"effect_size_summary (效应量摘要)": "For the ANOVA on prompt use, omega squared and mu squared values of about 0.41 indicated a large effect of strategy type on prompt frequency; PLS SEM reported f squared of about 0.148 for the path from Exercising strategies to writing logic outcomes and about 0.187 for the path from Gathering strategies to knowledge outcomes, suggesting small to medium effects; effect sizes for pre to post changes in test and writing scores such as Cohen d were not reported.",
		"llm_misuse_or_negative_effects (LLM滥用或负向效应)": "The study did not report academic dishonesty or overt misuse of ChatGPT by participants but identified limitations and potential negative effects of ChatGPT within this learning context, including that some learners perceived ChatGPT responses for deeper discussion and exploration as general, superficial, or over easy, which discouraged continued use of more advanced Understanding, Analysing, and Crafting strategies; some students experienced cognitive overload and felt that performing all five strategy types in a single session was too demanding, leading them to avoid the most challenging strategies; the authors also referenced broader concerns in the literature about ChatGPT’s limited effectiveness in teaching nuanced domain specific knowledge and skills due to training data constraints.",
		"equity_and_subgroup_effects (公平性与亚组差异)": "No statistical analyses by gender, age, educational level, or other subgroups were reported, although the sample was predominantly female and contained both undergraduate and graduate students; equity related issues were not explicitly discussed.",
		"limitation (研究局限)": "The authors noted several limitations: the sample was gender imbalanced and restricted to tertiary level students in a single Hong Kong university without prior chatbot based learning or prompt engineering experience, limiting generalisability; the study examined only individual ChatGPT based learning rather than collaborative use; the intervention consisted of a single main learning session, which may be insufficient for learners to fully apply cognitively demanding Analysing and Crafting strategies and to internalise knowledge of logic for authentic writing; the focus was on overall quality of logic rather than detailed micro level logical elements in essays; and the study did not explore variations in effects across different types of logical elements in writing.",
		"challenge (实施挑战与风险)": "Implementation challenges included the cognitive complexity and perceived difficulty of applying Analysing and Crafting strategies in a single short session, which reduced learner motivation to use them; the need for careful calibration of session length and target number of logical concepts so that learning is effective but not overwhelming; limitations in the depth, subtlety, and complexity of ChatGPT generated learning materials and feedback, which may restrict the effectiveness of advanced strategies and result in shallow understanding; the risk that learners may rely mainly on easier Gathering and Exercising and underuse higher level strategies; and practical requirements for piloting and validating the ChatGPT tool to ensure accuracy and unbiased instruction.",
		"future_work (未来研究方向)": "The authors recommended future studies with longer term implementations involving multiple ChatGPT based learning sessions so that students can progressively move from Gathering, Understanding, and Exercising to more frequent Analysing and Crafting and thereby produce larger gains in logical quality; research with more diverse and gender balanced samples and varied educational backgrounds; investigations of ChatGPT based collaborative learning and ChatGPT based educational games; studies that enhance and examine ChatGPT’s capacity to generate deeper and more complex domain specific materials and explanations; analyses of the micro level logical elements in pre and post revision essays to clarify how specific fallacies and logical features are affected by the learning; and work to better understand and strengthen the effects of Understanding, Analysing, and Crafting strategies when used more frequently.",
		"implication (理论与教学实践启示)": "The study provides a systematic framework of ChatGPT based logic learning strategies for English argumentative writing and suggests that GPT-4 powered tools can function as high quality educational chatbots that support a wide range of strategies, including those that require analysis and evaluation of learner output; it indicates that personalised Gathering and intensive Exercising supported by ChatGPT can substantially develop knowledge of logic and improve logical quality of writing while emotional support and autonomy affordances encourage sustained strategy use; at the same time it cautions that instructional designers and teachers should be aware of ChatGPT’s limitations in producing deep, nuanced content and of the cognitive demands of Analysing and Crafting strategies, and should therefore design multi session, scaffolded programmes that gradually build learners capacity for higher level strategies; more broadly, it suggests that AI driven platforms like ChatGPT can bridge the gap between theory and practice in logic and writing education by providing dynamic, supportive, and tailored learning experiences that complement but do not replace human instruction."
	},
	"Study Quality and Reporting": {
		"funding_source (经费来源)": "Interdisciplinary Research Scheme of the Dean’s Research Fund 2021 slash 22 at The Education University of Hong Kong, project code FLASS slash DRF slash IDS dash 3 2022",
		"conflict_of_interest (利益冲突声明)": "NR",
		"risk_of_bias_randomization (偏倚风险_分配与随机化)": "No random assignment to different conditions was used as the design included only a single group receiving the ChatGPT based logic learning intervention; participants self selected into the study via voluntary response sampling and were then screened for eligibility, which introduces potential selection bias; however, baseline measures of knowledge of logic and writing logic were collected to serve as covariates in analyses.",
		"risk_of_bias_blinding (偏倚风险_盲法)": "Participants and researchers were aware that ChatGPT based learning was being implemented since there was only one condition; however, scoring of knowledge tests and writing samples was conducted blind with respect to time point and participant identity by multiple raters; no blinding was applicable for the behavioural prompt data or interviews.",
		"attrition_and_missing_data (流失与缺失数据处理)": "From 52 initial volunteers, 12 were excluded based on pre treatment criteria before the intervention; there is no report of attrition among the 40 selected participants across the three week procedure, and no procedures for handling missing data were described.",
		"reporting_transparency (报告透明度与可重复性)": "The article provides detailed descriptions of participant characteristics, sampling and inclusion criteria, the design and configuration of LogicalHamster, pilot procedures, instruments and rubrics for knowledge tests and writing assessments, coding schemes for prompts and interviews, analytic methods and software used, descriptive statistics, key inferential results, reliability indices, and limitations; ethical declarations, funding, and an explicit statement on use of Grammarly for language polishing are also included; raw data are not publicly available due to lack of consent for data sharing.",
		"preregistration_or_protocol (预注册或研究方案)": "NR",
		"llm_version_reproducibility (LLM版本与可复现性)": "The study clearly states that LogicalHamster is based on GPT-4 and accessible via POE and documents its target domain of seven reasoning errors and the five supported strategy categories; screenshots of representative interactions are provided in appendices; however, specific version dates, parameter settings, and full system prompts are not reported, and the underlying GPT-4 model may change over time, which limits exact reproducibility of AI behaviour even if the general instructional logic can be replicated.",
		"baseline_equivalence (基线等同性检验)": "NA",
		"assumption_check_and_data_diagnostics (统计假设检验与数据诊断)": "The authors report that data met assumptions for ANOVA and regression with checks indicating linearity and homoscedasticity through scatterplots, approximate normality of distributions with skewness between minus two and plus two and kurtosis between minus seven and plus seven, and acceptable levels of multicollinearity with correlation coefficients below 0.90; for PLS SEM they note that there is no strict distributional requirement.",
		"outlier_treatment_and_sensitivity_analysis (异常值处理与稳健性分析)": "No specific procedures for identifying or handling outliers or conducting sensitivity analyses were described.",
		"data_preprocessing_and_transformation (数据预处理与转换)": "Knowledge test responses were scored according to a predefined rubric to yield total scores on a 0–21 scale; writing samples were scored using an analytic rubric to yield 0–100 logic quality scores; learner prompts were coded into categorical strategy types and sub types and counted; interview transcripts were transcribed, coded, and translated; there is no mention of additional data transformations such as normalisation or scaling beyond these scoring and coding steps."
	}
}