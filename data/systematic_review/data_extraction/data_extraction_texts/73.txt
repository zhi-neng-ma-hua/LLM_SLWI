{
	"Basic Identification": {
		"author (作者)": "Dararat Khampusaen",
		"publication_year (发表年份)": "2025",
		"study_region (研究地区)": "Thailand (Khon Kaen University)",
		"journal_name (期刊名称)": "LEARN Journal: Language Education and Acquisition Research Network",
		"study_type (研究类型_期刊论文_会议论文等)": "Journal article (empirical mixed-methods study)",
		"doi_or_identifier (DOI或唯一标识)": "10.70730/PGCQ9242",
		"research_aims (研究目的与问题)": "To investigate the impact of ChatGPT integration on EFL third-year English majors argumentative essay writing by examining changes in writing quality between first and fifth drafts over a 16-week period, students perceptions and attitudes toward ChatGPT in academic writing, and patterns of ChatGPT usage in the essay writing process.",
		"research_gap_or_novelty (研究创新性与知识空白)": "The study addresses gaps concerning the longitudinal impact of systematic ChatGPT integration on argumentative writing development, critical thinking, and independent writing competencies in EFL contexts, using a pre–post comparison of multiple drafts and an AI-specific rubric based on the AIAS framework that explicitly evaluates AI integration and academic integrity alongside traditional writing dimensions."
	},
	"Participant Information": {
		"educational_level (教育阶段)": "Third-year undergraduate students (English majors)",
		"language_proficiency (语言熟练度水平)": "NR (participants were third-year English majors who had completed fundamental writing courses and were considered able to engage in complex argumentative writing tasks)",
		"mother_tongue (母语)": "NR (participants were Thai EFL students at a Thai university; mother tongue not explicitly stated but implied to be Thai)",
		"sex (性别)": "23 female, 7 male",
		"age (年龄)": "20–21 years",
		"learning_context (学习语境_ESL_EFL_ELL等)": "EFL university context",
		"target_language (目标语言)": "English (L2)",
		"discipline (学科背景)": "English major; academic argumentative writing within an English language program",
		"prior_experience_llm (既有LLM使用经验)": "Participants reported minimal prior exposure to AI writing tools based on a preliminary survey."
	},
	"Methodology": {
		"research_design (研究设计_实验_准实验_纵向等)": "Single-group pre–post intervention design over 16 weeks using comparison of first drafts as pre-test and fifth drafts as post-test in AI-assisted writing classes, combined with cross-sectional questionnaire data and qualitative thematic analysis of essays (longitudinal within-subject design without a control group).",
		"research_method (研究方法_定量_定性_混合)": "Mixed-methods (quantitative analysis of writing scores and questionnaire responses; qualitative thematic analysis of essays with coding in NVivo and integration via convergent parallel design).",
		"sampling_method (抽样方法)": "Purposive sampling; one intact class out of four sections of third-year English Language majors was selected based on language proficiency, completion of fundamental writing courses, and minimal prior exposure to AI writing tools.",
		"sample_size_and_effect (样本量及效应量)": "Total N=30 third-year English majors (23 females, 7 males, aged 20–21); each student produced multiple argumentative essay drafts, with draft 1 and draft 5 used as pre-test and post-test for writing development; substantial pre–post improvements were reported, such as overall average rubric score increasing from 2.04/5 to 4.22/5 (gain of 2.18 points), academic integrity increasing by 3.0 points (from 1.5/5 to 4.5/5), organization and critical thinking increasing by 2.2 and 2.1 points respectively, and language use improving by 1.7 points; additional quantitative results included content quality improvement of 63.2% and significant gains in organization, coherence, and language use (all p<0.001); standardized effect sizes such as Cohen’s d or partial eta squared were not reported.",
		"theoretical_foundation (理论基础_理论框架)": "The design is grounded in pre–post intervention methodology for writing development (Cohen et al., 2017; Ferris, 2010; Graham and Perin, 2007) and technology integration frameworks for writing assessment (Steiss et al., 2024), combined with the Artificial Intelligence Assessment Scale (AIAS) framework (Perkins et al., 2024) for evaluating content, organization, language use, critical thinking, AI integration, and academic integrity; the conceptual framework specifies AI integration, prior writing experience, and English proficiency level as independent variables influencing writing quality, argument structure, writing fluency, and metacognitive awareness in EFL academic writing.",
		"data_collection_instrument (数据收集工具)": "Pre- and post-intervention argumentative essays (first and fifth drafts); an adapted rubric based on the AIAS framework evaluating six components content and ideas, organization and structure, language use and style, critical thinking, AI tool integration, and academic integrity on a five-point scale; a systematically developed 17-item questionnaire on ChatGPT-assisted writing using a 5-point Likert scale and open-ended questions, drawing on the Technology Acceptance Model and writing self-efficacy measures; NVivo 14 for thematic analysis and coding of essays; IBM SPSS Statistics 29 for quantitative analysis.",
		"data_collection_validity_reliability (工具信度与效度)": "The 17-item questionnaire underwent expert review (n=3) and pilot testing (n=15); content validity was established using Item-Objective Congruence with IOC=0.87 and reliability testing yielded Cronbach’s alpha=0.89, indicating high internal consistency; the AIAS-based rubric was aligned with contemporary AI integration and academic integrity needs and was applied collaboratively by the researcher and two other raters to provide a comprehensive assessment of writing development, though specific inter-rater reliability coefficients for rubric scoring were not reported.",
		"data_analysis_method (数据分析方法)": "Essays were imported into NVivo 14 and analyzed via thematic analysis following Braun and Clarke’s six-phase framework, with codes and themes later transformed into quantitative data; quantitative data were analyzed using IBM SPSS Statistics 29, including ANOVA to examine differences in writing performance across time and dimensions, descriptive statistics for questionnaire dimensions, and correlation analysis (e.g., r=0.67 between ChatGPT usage frequency and writing confidence, r=0.72 between perceived usefulness and writing quality improvement, both p<0.01); the overall mixed-methods approach followed a convergent parallel design integrating qualitative and quantitative findings.",
		"unit_of_analysis (分析单位)": "Individual student for questionnaire responses and pre–post comparisons; individual argumentative essays/drafts (first and fifth drafts) per student for writing quality and rubric dimension scores.",
		"group_assignment_method (组别分配方式_随机_非随机等)": "Not applicable; a single intact class of 30 students was studied as one group without random assignment to different conditions.",
		"power_analysis (功效分析与样本量论证)": "NR",
		"sampling_frame_and_representativeness (抽样框与样本代表性)": "Sampling frame consisted of four available sections of third-year English majors at one Thai university; one section meeting criteria of adequate proficiency, prior completion of writing courses, and minimal AI exposure was purposively selected; the sample is representative of that particular class but not claimed to be statistically representative of all EFL university learners.",
		"scoring_procedure_and_rater_training (评分流程与评分者培训)": "The adapted AIAS-based rubric was developed by the researcher and used by the researcher and two additional raters to evaluate essays on content and ideas, organization and structure, language use and style, critical thinking, AI tool integration, and academic integrity on a five-point scale; the rubric facilitated objective and consistent evaluation and reflective feedback on strengths and areas for improvement, but specific details on rater training procedures, calibration sessions, and inter-rater reliability statistics for rubric scoring were not reported."
	},
	"Intervention": {
		"duration (干预时长与频率)": "Sixteen-week semester-long intervention in AI-assisted writing classes, with multiple argumentative essay drafts produced and development tracked by comparing first and fifth drafts as pre-test and post-test.",
		"llm_model_type (LLM模型类型_如ChatGPT_GPT4_Gemini等)": "ChatGPT (transformer-based large language model; specific version not reported).",
		"llm_model_configuration (LLM模型配置与版本_API_网页_参数等)": "NR (the study identifies use of ChatGPT in AI-assisted writing classes but does not specify whether students accessed it via web UI or app, nor the model version or parameter settings).",
		"llm_integration_mode (LLM整合模式_直接使用_教师中介_系统嵌入)": "Students directly used ChatGPT as an external AI tool during their argumentative essay writing process within an EFL course, integrating it into planning, drafting, and revising their essays; ChatGPT was not embedded in a dedicated platform but used as an AI assistant alongside traditional instruction.",
		"prompting_strategy (提示策略_提示工程与使用方式)": "NR (the study describes ChatGPT integration broadly for brainstorming, argument construction, evidence integration, and academic writing support but does not provide specific example prompts or systematic prompting strategies beyond general references to AI assistance in idea generation, structure, language, and academic voice).",
		"training_support_llm_literacy (LLM素养与提示培训)": "Participants had minimal prior exposure to AI writing tools, and the course included AI-assisted writing classes, but the article does not specify detailed training in prompt design, critical evaluation of AI output, or explicit instruction on how to use ChatGPT responsibly beyond general emphasis on academic integrity in the rubric and questionnaire; no dedicated LLM literacy curriculum is reported.",
		"intervention_implementation (干预实施流程_步骤与任务)": "During a 16-week course, students engaged in AI-assisted argumentative essay writing with ChatGPT integrated into their writing workflow; writing development was tracked through comparison of first and fifth drafts produced within AI-assisted classes; ChatGPT was used to support idea generation, argument construction, organization, language use, and integration of evidence and citations; essays were evaluated using an AIAS-based rubric focusing on content and ideas, organization and structure, language use and style, critical thinking, AI integration, and academic integrity, and student perceptions of ChatGPT were collected using a 17-item questionnaire; data analysis combined thematic coding of essays with statistical analyses of pre–post changes and questionnaire results.",
		"experimental_group_intervention (实验组干预内容)": "All 30 third-year English majors experienced ChatGPT-integrated argumentative writing instruction, where ChatGPT served as an AI assistant for generating ideas, refining language, enhancing organization, supporting critical thinking, and integrating evidence in argumentative essays; students produced multiple drafts over 16 weeks, with first and fifth drafts used as pre-test and post-test samples to measure writing development under sustained AI-assisted instruction.",
		"control_group_intervention (对照组干预内容)": "NA (no separate control group without ChatGPT or with alternative interventions was included; the design used within-group pre–post comparisons only).",
		"writing_stage (写作阶段_如生成_修改_反馈_重写等)": "ChatGPT was integrated across multiple stages of the argumentative writing process including idea generation and planning, drafting, revising, and refining academic language, argument structure, and evidence integration in students essays.",
		"writing_genre (写作体裁)": "Academic argumentative essays.",
		"writing_task_type (写作任务类型)": "Argumentative essay writing on contemporary and academic topics requiring thesis development, support with evidence, counterargument consideration, and use of academic voice, as reflected in examples such as global warming, online versus traditional education, artificial intelligence, homeschooling, gender-neutral bathrooms, and physical education grading.",
		"role_llm (LLM角色_如生成文本_给反馈_评分_对话等)": "ChatGPT functioned as an AI-assisted writing tool that generated ideas and examples, provided suggestions on structure and organization, supported development of more sophisticated language and academic voice, assisted with integrating and synthesizing supporting evidence, and helped students revise content, organization, and language at the sentence and discourse level; it did not provide scores but indirectly influenced evaluation by shaping the quality of student writing assessed with the AIAS-based rubric.",
		"role_instructor (教师角色与介入方式)": "The instructor designed and implemented the AI-assisted writing course, selected the class and topics, introduced ChatGPT and the expectations for its use, guided students through AI-integrated argumentative writing tasks, and, together with two other raters, evaluated students essays using the AIAS-based rubric, providing feedback and shaping pedagogical approaches to balance AI support with the development of independent writing competencies.",
		"setting (教学情境_学校类型_课程类型_线上线下)": "Tertiary EFL academic writing context in the Department of English, Faculty of Humanities and Social Sciences at Khon Kaen University, Thailand; face-to-face university course within which students engaged in AI-assisted argumentative writing using ChatGPT over a 16-week semester.",
		"ethical_consideration (伦理审查与知情同意)": "All participants provided informed consent, and the study received approval from the institution's Ethics Review Board to ensure compliance with research ethics guidelines.",
		"llm_access_policy (LLM使用规范_允许与限制)": "NR (the study discusses academic integrity as a rubric dimension and as a central concern in perceptions of ChatGPT and recommends institutional guidelines for AI usage, but does not detail specific classroom-level rules or access policies enforced during the intervention).",
		"llm_safety_guardrails (LLM安全与内容过滤设置)": "NR",
		"key_findings (主要研究发现_与LLM写作干预相关)": "Systematic ChatGPT integration over a 16-week period led to substantial improvements in argumentative writing quality across all rubric dimensions, with overall average scores increasing from 2.04/5 to 4.22/5; the largest gain was in academic integrity (from 1.5/5 to 4.5/5, +3.0 points), followed by notable improvements in organization (+2.2 points to 4.3/5), critical thinking (+2.1 points to 4.0/5), and language use (+1.7 points to 4.1/5). Quantitatively, content quality improved by 63.2% (p<0.001), with significant enhancements in organization (43.5%, p<0.001), coherence (41.5%, p<0.001), and language use (38.9%, p<0.001). Thematic analysis of essays showed marked progression in thesis construction, evidence integration, and academic voice, and illustrative draft comparisons revealed how AI-supported revisions moved from vague, informal, or weakly reasoned texts to data-rich, structured, and critical arguments supported by credible sources. Questionnaire data indicated that students perceived ChatGPT as particularly beneficial for time management (mean 4.1) and idea generation (mean 3.8), with more moderate but positive views on writing skills enhancement and essay quality; academic integrity (mean 3.2) emerged as a contentious area reflecting ongoing concerns about appropriate AI use. Significant positive correlations were found between ChatGPT usage frequency and writing confidence (r=0.67, p<0.01) and between perceived usefulness and writing quality improvement (r=0.72, p<0.01), suggesting that regular AI use was associated with greater confidence and perceived gains. Overall, the study concludes that ChatGPT, when systematically integrated and combined with structured assessment rubrics, can substantially enhance EFL argumentative writing while necessitating careful attention to academic integrity and independent thinking."
	},
	"Outcome": {
		"application_effectiveness_overview (应用效果总体评价与测量工具)": "Using an AIAS-based analytic rubric applied to first and fifth drafts and a validated 17-item questionnaire on ChatGPT-assisted writing, the study found significant pre–post improvements in argumentative writing quality across content, organization, language use, critical thinking, AI integration, and academic integrity, as well as positive student perceptions of ChatGPT in terms of time management, idea generation, and writing confidence, with some reservations about academic integrity and appropriate AI use.",
		"writing_performance_measure (写作表现测量工具_量表或评分标准)": "Adapted rubric based on the Artificial Intelligence Assessment Scale (AIAS) framework evaluating six components content and ideas, organization and structure, language use and style, critical thinking, AI tool integration, and academic integrity on a 5-point scale.",
		"writing_performance_focus (写作表现关注维度_流利度_准确性_复杂度_体裁等)": "Writing performance focused on argumentative essay quality including content richness and evidence use, organization and coherence, accuracy and appropriateness of language use and style, depth of critical thinking, effective and transparent integration of AI support, and adherence to academic integrity standards; overall progression from basic, informal, or opinion-based writing toward more structured, data-driven, and critical academic discourse was emphasized.",
		"affective_aspect_measure (情感因素测量工具_问卷_量表等)": "A 17-item questionnaire developed following survey design principles by Dörnyei and Taguchi, incorporating elements from the Technology Acceptance Model and writing self-efficacy measures, using a 5-point Likert scale plus open-ended responses to assess perceptions of ChatGPT in terms of idea generation, writing skills enhancement, essay quality, time management, academic integrity, and writing confidence and usage.",
		"affective_aspect_focus (情感因素维度_动机_态度_焦虑_自效感等)": "Students perceptions and attitudes toward ChatGPT in academic writing, including perceived usefulness for brainstorming and structural support, perceived impact on essay quality and writing process efficiency, confidence in their writing abilities when using ChatGPT, overall writing confidence and sense of competence, and concerns about academic integrity and appropriate use of AI tools.",
		"cognitive_aspect_measure (认知因素测量工具)": "AIAS-based rubric dimension for critical thinking assessing the sophistication of argumentation, use of evidence, handling of counterarguments, and depth of analysis in essays; qualitative thematic analysis of essays in NVivo focusing on development of argumentative structures and cognitive processes such as argument construction, evidence integration, and analytical reasoning.",
		"cognitive_aspect_focus (认知因素维度_策略使用_元认知监控等)": "Critical thinking and argumentation skills including construction of clear and defensible thesis statements, integration and synthesis of empirical evidence, engagement with opposing viewpoints, development of more sophisticated academic voice and reasoning, and evolution from surface-level, emotion-based arguments to evidence-based and analytically grounded positions; metacognitive awareness was indirectly addressed through analysis of students ability to critically evaluate AI-supported content, but no direct metacognitive scale was used.",
		"behavioral_aspect_measure (行为因素测量工具_日志_平台日志等)": "Self-report questionnaire items on ChatGPT usage patterns in writing assignments, including the percentage of assignments involving ChatGPT use, perceived impact on time management and process efficiency, and frequency of use; there were no system log files, but usage was captured through structured questionnaire responses.",
		"behavioral_aspect_focus (行为因素维度_使用频率_交互模式_坚持度等)": "Patterns of ChatGPT usage in essay writing such as how often students used ChatGPT across assignments (e.g., majority reporting use in 21–60% of their assignments), reliance on ChatGPT for idea generation and time management, perceived integration of ChatGPT into their regular writing process, and the relationship between frequency of AI use and writing confidence or perceived writing quality improvement.",
		"other_outcomes_measure (其他结果测量工具)": "Thematic analysis and NVivo coding of essay drafts to identify qualitative patterns in writing development; conversion of qualitative themes into quantitative indicators; ANOVA to test differences in argument quality and rubric dimensions across drafts; correlation analysis linking ChatGPT usage and perception variables to writing outcomes.",
		"other_outcomes_focus (其他结果维度说明)": "Detailed progression across rubric dimensions including AI integration and academic integrity, qualitative examples of before-and-after drafts showing enhanced data use, organization, technical vocabulary, and critical stance; quantifiable effects of AI-assisted instruction on independent writing competence, and description of how AI-enabled revisions supported argument structure, evidence integration, and academic voice; student beliefs about AI’s role in their learning processes and ethical concerns.",
		"assessment_timepoints (评估时间点_前测_后测_延迟测等)": "Writing performance was assessed at two main timepoints using first drafts as pre-test and fifth drafts as post-test over a 16-week AI-assisted writing period; the questionnaire was administered to capture students perceptions and usage patterns after sustained exposure to ChatGPT in academic writing; no delayed post-test beyond the course duration was reported.",
		"primary_outcome_variables (主要结果变量_因变量)": "Rubric scores on content and ideas, organization and structure, language use and style, critical thinking, AI integration, and academic integrity for first and fifth drafts; overall average rubric score; questionnaire dimension scores for idea generation, writing skills enhancement, essay quality, time management, academic integrity, and writing confidence and usage; correlations between ChatGPT usage frequency, perceived usefulness, writing confidence, and perceived writing quality improvement.",
		"independent_variables_and_factors (自变量与实验因素)": "Time/condition factor comparing pre-test (first draft) and post-test (fifth draft) writing performance under ongoing ChatGPT integration; self-reported ChatGPT usage frequency and perceived usefulness acted as predictor variables in correlation analyses; prior writing experience and English proficiency level were conceptualized as independent variables in the research framework but not experimentally manipulated.",
		"followup_length_and_type (随访时长与类型)": "Sixteen-week instructional period with pre-test (draft 1) and post-test (draft 5) assessment during the same semester; no additional long-term follow-up after course completion.",
		"statistical_significance (统计显著性结果摘要)": "Quantitative analyses revealed substantial and statistically significant improvements across all assessed writing criteria, including content quality improvement of 63.2% (p<0.001), organization improvement of 43.5% (p<0.001), coherence improvement of 41.5% (p<0.001), and language use improvement of 38.9% (p<0.001), with pre–post comparisons showing large increases in rubric scores for academic integrity (+3.0 points), organization (+2.2), critical thinking (+2.1), and language use (+1.7); student perception data showed high means for time management (4.1, SD=0.68) and idea generation (3.8, SD=0.72), moderate means for writing skills enhancement (3.4, SD=0.85), essay quality (3.6, SD=0.91), and academic integrity (3.2, SD=1.02); significant positive correlations were reported between ChatGPT usage frequency and writing confidence (r=0.67, p<0.01) and between perceived usefulness of ChatGPT and writing quality improvement (r=0.72, p<0.01).",
		"effect_size_summary (效应量摘要)": "Effect sizes were primarily expressed as percentage improvements and score gains, for example content quality improved by 63.2%, organization by 43.5%, coherence by 41.5%, and language use by 38.9%, while overall rubric scores rose by 2.18 points on a 5-point scale and academic integrity increased by 3.0 points; correlation coefficients of r=0.67 and r=0.72 indicated strong positive associations between ChatGPT usage and writing confidence and between perceived usefulness and writing quality improvement; formal standardized effect size metrics such as Cohen’s d or partial eta squared were not reported.",
		"llm_misuse_or_negative_effects (LLM滥用或负向效应)": "Academic integrity emerged as the most contentious questionnaire dimension (mean 3.2, SD=1.02), reflecting students concerns about appropriate use of ChatGPT and potential risks such as overreliance on AI and blurring of boundaries between AI assistance and original work; the discussion emphasizes challenges identified in the literature about originality, learning loss, and maintaining rigorous scholarly standards when using AI for content generation and revision, and stresses the need to balance AI-enhanced scaffolding with autonomous learning and to implement clear guidelines, assessment criteria, and monitoring mechanisms to prevent inappropriate AI use.",
		"equity_and_subgroup_effects (公平性与亚组差异)": "NR (no subgroup analyses by gender, proficiency level, or other demographic or equity-related variables were reported, and fairness or differential impact across subgroups was not quantitatively examined).",
		"limitation (研究局限)": "NR (the article does not include a dedicated limitations section and does not explicitly discuss constraints such as sample size, single institutional context, or absence of a non-AI control group, though these can be inferred by readers).",
		"challenge (实施挑战与风险)": "The study highlights several implementation challenges and risks, including the need to maintain academic integrity and originality when integrating ChatGPT, the danger of overreliance on AI for argument construction and language formulation, the difficulty of striking an optimal balance between AI-enhanced scaffolding and autonomous learning, the necessity of clear institutional guidelines and monitoring systems to regulate AI use in writing assignments, and the requirement for professional development to equip educators to integrate ChatGPT responsibly while preserving critical thinking and independent writing skills.",
		"future_work (未来研究方向)": "The author recommends that future research explore the long-term effects of AI-assisted writing instruction on students independent writing capabilities beyond the immediate pre–post period, investigate cognitive mechanisms and metacognitive processes by which AI tools influence argument construction and critical thinking, examine how to optimize the balance between AI support and autonomous learning in EFL contexts, and evaluate comprehensive pedagogical frameworks and ethical guidelines that promote responsible AI usage while maintaining high standards of academic integrity and student agency.",
		"implication (理论与教学实践启示)": "The findings imply that integrating ChatGPT systematically into EFL argumentative writing courses can significantly enhance content quality, organization, coherence, language use, critical thinking, and academic integrity measures when combined with structured assessment rubrics such as the AIAS-based framework; however, successful implementation requires comprehensive institutional guidelines, updated assessment criteria that account for AI use, ongoing professional development for teachers, monitoring systems to prevent overreliance and misuse, and pedagogical frameworks that promote reflective practice, self-directed learning, and critical evaluation of AI outputs so that learners benefit from AI assistance while developing independent, ethical, and sophisticated academic writing competencies."
	},
	"Study Quality and Reporting": {
		"funding_source (经费来源)": "Research grant from the English Department, Faculty of Humanities and Social Sciences, Khon Kaen University, Thailand.",
		"conflict_of_interest (利益冲突声明)": "NR (the acknowledgments state that the views expressed are those of the author and do not necessarily reflect the official policy or position of the funding institution, but no explicit conflict of interest statement is provided).",
		"risk_of_bias_randomization (偏倚风险_分配与随机化)": "High risk of selection bias due to purposive sampling of a single intact class without random assignment; there was no control group and no randomization to different conditions, so pre–post changes cannot be unequivocally attributed to ChatGPT alone.",
		"risk_of_bias_blinding (偏倚风险_盲法)": "Blinding procedures were not described; participants knew they were using ChatGPT in AI-assisted writing classes, and it is not specified whether raters were blind to the timepoint (first vs fifth draft) or the AI involvement when scoring essays, which may introduce measurement bias.",
		"attrition_and_missing_data (流失与缺失数据处理)": "NR (the study reports 30 participants and analysis of pre- and post-intervention drafts but does not discuss attrition, missing data, or handling procedures).",
		"reporting_transparency (报告透明度与可重复性)": "The study transparently reports participant characteristics, sampling rationale, course duration, use of ChatGPT in AI-assisted writing classes, theoretical and conceptual framework, instrument development and validation (IOC and Cronbach’s alpha), analytic procedures (NVivo thematic analysis and SPSS-based ANOVA and correlation analyses), and illustrative before-and-after writing samples; however, detailed procedural steps for ChatGPT interaction, complete rubrics, full questionnaire items, and raw data are not fully presented, limiting complete reproducibility.",
		"preregistration_or_protocol (预注册或研究方案)": "NR",
		"llm_version_reproducibility (LLM版本与可复现性)": "The study identifies ChatGPT as the AI tool used but does not specify the model version, access mode, or configuration, which may limit exact replication as ChatGPT and its behavior can change over time with updates and new model releases.",
		"baseline_equivalence (基线等同性检验)": "Not applicable in the sense of comparing multiple groups, as a single intact class was studied; baseline performance was established via first drafts as pre-test measures, but no equivalence tests between different groups were required or reported.",
		"assumption_check_and_data_diagnostics (统计假设检验与数据诊断)": "NR (the study reports the use of ANOVA, p-values, and correlation coefficients but does not describe checks for normality, homogeneity of variance, or other diagnostic tests, nor any adjustments such as nonparametric alternatives).",
		"outlier_treatment_and_sensitivity_analysis (异常值处理与稳健性分析)": "NR",
		"data_preprocessing_and_transformation (数据预处理与转换)": "Essays were imported into NVivo 14 and coded using Braun and Clarke’s thematic analysis framework; qualitative themes and coding outcomes were transformed into quantitative data following established qualitative data transformation guidelines for subsequent statistical analysis; questionnaire responses were scored on 5-point Likert scales and aggregated into dimension means; no additional data transformations such as normalization or scaling were described."
	}
}