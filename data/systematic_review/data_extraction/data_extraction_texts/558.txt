{
	"Basic Identification": {
		"author (作者)": "Santosh Mahapatra",
		"publication_year (发表年份)": "2024",
		"study_region (研究地区)": "India (elite private-run university)",
		"journal_name (期刊名称)": "Smart Learning Environments",
		"study_type (研究类型_期刊论文_会议论文等)": "Journal article",
		"doi_or_identifier (DOI或唯一标识)": "10.1186/s40561-024-00295-9",
		"research_aims (研究目的与问题)": "To investigate the impact of ChatGPT, used as a formative feedback tool, on the academic writing skills of undergraduate ESL students in an intensive writing course and to explore experimental group students’ perceptions of ChatGPT as a feedback tool.",
		"research_gap_or_novelty (研究创新性与知识空白)": "Addresses the lack of empirical evidence on the impact of ChatGPT on ESL/EFL students’ academic writing skills, especially in relatively crowded large writing classes in the Global South; demonstrates the use of ChatGPT as a dialogic formative feedback tool within a mixed methods intervention design and links it explicitly to theories of dialogic feedback and ChatGPT as a reliable writing tool."
	},
	"Participant Information": {
		"educational_level (教育阶段)": "Undergraduate first-year students in science and engineering",
		"language_proficiency (语言熟练度水平)": "Undergraduate ESL students who had studied in English-medium schools and passed a challenging institutional English test before admission; exact proficiency scores are not reported.",
		"mother_tongue (母语)": "NR",
		"sex (性别)": "NR",
		"age (年龄)": "18–19 years",
		"learning_context (学习语境_ESL_EFL_ELL等)": "ESL context in higher education; intensive academic writing course in an English-medium university in India with relatively large writing classes.",
		"target_language (目标语言)": "English (L2)",
		"discipline (学科背景)": "First-year science and engineering students at an elite private-run university.",
		"prior_experience_llm (既有LLM使用经验)": "None of the participants had used ChatGPT to improve their writing skills before the intervention; many had prior experience with mobile phones, laptops, the Internet, and AI tools such as Grammarly."
	},
	"Methodology": {
		"research_design (研究设计_实验_准实验_纵向等)": "Mixed methods intervention design with a quasi-experimental structure (experimental group using ChatGPT vs comparison group without ChatGPT) and three time points (pre-test, post-test, delayed post-test) plus qualitative focus group discussions.",
		"research_method (研究方法_定量_定性_混合)": "Mixed methods (quantitative quasi-experimental intervention combined with qualitative focus group discussions).",
		"sampling_method (抽样方法)": "An intact class of first-year science and engineering students was randomly assigned to two sections (experimental group and comparison group) following principles for quasi-experimental studies; participation was voluntary with inclusion criteria based on attendance and completion of all tests.",
		"sample_size_and_effect (样本量及效应量)": "Initially 78 students in the experimental group (EG) and 56 in the comparison group (CG) consented; only students who attended all six intervention hours and took the pre-, post-, and delayed post-tests were included in analyses, resulting in CG N=35 and EG N=37 (total N=72). For the EG, mean scores increased from 12.581 (SD=0.833) at pre-test to 19.216 (SD=2.485) at post-test and 20.419 (SD=2.575) at delayed post-test. One-way repeated measures ANOVA on EG scores yielded F(2,72)=330.704, p≈5.15×10⁻³⁷, η²=0.902. Bonferroni post-hoc comparisons showed significant differences between pre-test and post-test (p<0.001, Cohen’s d≈3.300), pre-test and delayed post-test (p<0.001, d≈3.898), and post-test and delayed post-test (p<0.01, d≈0.598). Independent-samples t-tests indicated significantly higher scores for the EG than the CG at post-test (t(70)=−5.643, p≈3.30×10⁻⁷; EG M=19.216, SD=2.485; CG M=16.371, SD=1.695) and at delayed post-test (t(70)=−9.371, p≈5.54×10⁻¹⁴; EG M=20.419, SD=2.575; CG M=15.400, SD=1.897).",
		"theoretical_foundation (理论基础_理论框架)": "Grounded in the theory of feedback as a dialogic process (Winstone & Carless, 2020), where feedback involves interactive exchanges that support clarification and progress, and in Barrot’s (2023) theory of ChatGPT as a reliable writing tool providing immediate, tailored feedback across writing stages; also informed by literature on formative feedback, self-assessment (SA), peer assessment (PA), and automated writing evaluation (AWE) in large writing classes.",
		"data_collection_instrument (数据收集工具)": "Three writing tests (pre-test, post-test, delayed post-test), each with three 150-word paragraph tasks representing process, comparison, and cause-effect genres within familiar scientific and general topics; analytic rubrics for each task type focusing on content, organization, grammar, and vocabulary, created by the researcher and a colleague and validated by two applied linguistics experts; writing performance rated by the researcher and another teacher. Qualitative data were collected via three focus group discussions (FGDs) with five experimental-group students using semi-structured prompts about experiences and perceived impact of ChatGPT for self- and peer feedback.",
		"data_collection_validity_reliability (工具信度与效度)": "Rubrics were validated by two experts in applied linguistics; all write-ups were double-rated by the researcher and a colleague, with Cohen’s Kappa exceeding 0.8 for all scripts, indicating strong inter-rater reliability; inclusion and exclusion criteria ensured consistent participation across all phases of the intervention; FGD prompts were aligned with the study’s research questions and theoretical framework.",
		"data_analysis_method (数据分析方法)": "Quantitative data (pre-, post-, and delayed post-test scores) for EG and CG were analyzed using one-way repeated measures ANOVA on the EG’s three test scores, Bonferroni post-hoc tests for pairwise comparisons, and one-tailed independent-samples t-tests comparing EG and CG post-test and delayed post-test scores. Levene’s test assessed homogeneity of variance, Shapiro–Wilk tests checked normality, and Grubb’s test was used to detect outliers. Qualitative FGD data were transcribed and coded using a phronetic iterative approach, combining inductive coding with themes informed by prior literature to identify patterns in students’ perceptions of ChatGPT’s impact on content, organization, grammar, autonomy, collaboration, and dependence.",
		"unit_of_analysis (分析单位)": "Individual student (writing test scores per student across time; FGD contributions from individual experimental-group students).",
		"group_assignment_method (组别分配方式_随机_非随机等)": "Intact class randomly assigned to two sections (experimental group with ChatGPT and comparison group without ChatGPT); no individual-level randomization within sections, consistent with quasi-experimental educational designs.",
		"power_analysis (功效分析与样本量论证)": "NR",
		"sampling_frame_and_representativeness (抽样框与样本代表性)": "Sampling frame consisted of first-year science and engineering students at one elite private-run university in India; participants were generally from financially well-off backgrounds with good access to technology and media; the author notes that findings can be generalized primarily to similar ESL/EFL settings with relatively large classes and comparable institutional contexts.",
		"scoring_procedure_and_rater_training (评分流程与评分者培训)": "The researcher and another teacher, who also taught the course, jointly developed analytic rubrics, had them validated by two experts, and then scored all student writings using these rubrics; Cohen’s Kappa values above 0.8 for all texts indicate consistent scoring, though specific details of rater training sessions are not further described."
	},
	"Intervention": {
		"duration (干预时长与频率)": "The intervention took place over approximately one month within an academic semester and consisted of a one-hour training session on using ChatGPT for self- and peer assessment followed by six hours of instruction in which the experimental group was taught process, comparison, and cause-effect writing with ChatGPT integrated as a formative feedback tool; pre-test occurred before training, post-test immediately after the intervention, and a delayed post-test about two months later.",
		"llm_model_type (LLM模型类型_如ChatGPT_GPT4_Gemini等)": "ChatGPT (large generative language model from OpenAI; specific version not reported).",
		"llm_model_configuration (LLM模型配置与版本_API_网页_参数等)": "NR",
		"llm_integration_mode (LLM整合模式_直接使用_教师中介_系统嵌入)": "Students in the experimental group interacted directly with ChatGPT as an external tool during classroom writing tasks to obtain formative feedback for self-assessment and peer assessment; ChatGPT was not embedded in a learning management system, and the instructor orchestrated but did not mediate or rewrite ChatGPT’s responses.",
		"prompting_strategy (提示策略_提示工程与使用方式)": "Students used functional prompts to ask ChatGPT for help with brainstorming ideas, verifying topic sentences, checking the relevance of supporting details and conclusions, assessing adherence to controlling ideas, reviewing use of signposts, and correcting grammar, vocabulary, and sentence structure; prompts focused on genre-specific features and accuracy (e.g., querying sentence correctness, requesting explanations of tense or voice shifts) rather than formalized prompt-engineering techniques.",
		"training_support_llm_literacy (LLM素养与提示培训)": "Experimental-group students received a one-hour training session on how to use ChatGPT for self-assessment and peer assessment, including how to ask questions, request feedback on specific components (topic sentence, supporting details, concluding sentence, signposts, grammar, vocabulary), and interpret and apply ChatGPT’s feedback; the study emphasizes the importance of such student training before using digital tools like ChatGPT in the classroom.",
		"intervention_implementation (干预实施流程_步骤与任务)": "After a common pre-test for both groups, the experimental group received a short training on using ChatGPT for SA and PA. During the intervention phase, EG students were taught process, comparison, and cause-effect writing over six hours. They analyzed genre features through tasks, completed text production tasks focusing on components of each genre, wrote full paragraphs, and repeatedly used ChatGPT to verify whether their texts exhibited the required genre features, content appropriateness, organization, vocabulary use, and grammatical accuracy. Brainstorming and idea generation were supported by ChatGPT, followed by student-led SA and PA informed by ChatGPT’s feedback. Two FGDs were conducted during this phase to capture students’ experiences. The comparison group received the same instructional hours and tasks without ChatGPT. Both groups then took an immediate post-test, and approximately two months later, both groups took a delayed post-test and the experimental group participated in a further FGD.",
		"experimental_group_intervention (实验组干预内容)": "Experimental-group students received an intensive academic writing course in process, comparison, and cause-effect paragraph writing with ChatGPT integrated as a formative feedback tool: they were trained to use ChatGPT for self- and peer assessment, used it for brainstorming and idea generation, checked genre features, topic sentences, supporting details, signposts, and conclusions, and obtained metalinguistic feedback and explanations on grammar and vocabulary to revise their texts.",
		"control_group_intervention (对照组干预内容)": "The comparison group was taught the same writing genres (process, comparison, and cause-effect) with equivalent instructional hours and tasks but without access to ChatGPT as a feedback tool; they received conventional instruction and feedback as part of the intensive academic writing course.",
		"writing_stage (写作阶段_如生成_修改_反馈_重写等)": "ChatGPT was used across multiple stages of the writing process: brainstorming and idea generation, outlining and planning, drafting paragraphs, revising content and organization, and editing for grammatical accuracy and vocabulary choice; self- and peer assessment activities with ChatGPT feedback occurred during drafting and revising.",
		"writing_genre (写作体裁)": "Short academic paragraphs in three genres: process writing (describing experimental procedures), comparison writing (comparing entities such as operating systems or material properties), and cause-effect writing (describing impacts of exercise, climate change, or technology addiction).",
		"writing_task_type (写作任务类型)": "Multiple 150-word paragraph-writing tasks for process, comparison, and cause-effect genres; three tasks per test (pre-test, post-test, delayed post-test) on content related to science experiments, technological comparisons, and everyday cause-effect topics.",
		"role_llm (LLM角色_如生成文本_给反馈_评分_对话等)": "ChatGPT functioned as a formative feedback provider and writing support tool: it generated ideas and focused information on topics, suggested organization and connections between main ideas and supporting details, helped craft strong topic and concluding sentences, indicated inappropriate or off-topic details, supplied and explained grammatical corrections and vocabulary choices, and responded dialogically to students’ questions; it did not grade or score student writing.",
		"role_instructor (教师角色与介入方式)": "The instructor designed and delivered the academic writing course, created and validated rubrics, administered tests, organized and supervised the ChatGPT-based self- and peer assessment activities, and facilitated focus group discussions; the instructor served as a facilitator and guide, leaving ChatGPT to supply immediate feedback while monitoring student engagement and adherence to tasks.",
		"setting (教学情境_学校类型_课程类型_线上线下)": "Intensive academic writing course in an elite private-run university in India, within an ESL higher-education context; relatively large writing classes; instruction took place in a regular classroom environment over an academic semester (face-to-face instruction with students using personal devices to access ChatGPT).",
		"ethical_consideration (伦理审查与知情同意)": "Written informed consent was obtained from all participants, participation was voluntary with the option to withdraw at any point, and students were informed about the nature of the study and their expected tasks; the institution did not require formal ethics committee approval because participants were adults with full freedom to decide on participation.",
		"llm_access_policy (LLM使用规范_允许与限制)": "Students in the experimental group were explicitly instructed to use ChatGPT for self-assessment and peer assessment of their writing during the intervention; the study emphasizes training and purposeful use of ChatGPT for feedback but does not detail additional institutional policies or explicit prohibitions regarding other uses or copying of ChatGPT-generated text beyond its role as a feedback tool.",
		"llm_safety_guardrails (LLM安全与内容过滤设置)": "NR",
		"key_findings (主要研究发现_与LLM写作干预相关)": "ChatGPT, used as a formative feedback tool in an intensive ESL academic writing course, had a significant positive impact on students’ academic writing skills. Experimental-group students showed large and statistically significant gains between pre-test and post-test and between pre-test and delayed post-test, with sustained improvement over approximately two months and significantly higher scores than the comparison group at both post-intervention time points. Students perceived ChatGPT as a helpful 'writing buddy' that supported content generation, focus on topic, organization of ideas, use of signposts and conclusions, grammatical accuracy, metalinguistic understanding, and vocabulary choices, while also fostering learner autonomy and peer collaboration. At the same time, some students expressed concerns about reduced motivation to think independently, increased machine dependence, and possible constraints on creativity in organizing content."
	},
	"Outcome": {
		"application_effectiveness_overview (应用效果总体评价与测量工具)": "Effectiveness of the ChatGPT-based formative feedback intervention was evaluated using three writing tests (pre-test, post-test, delayed post-test) scored with validated analytic rubrics (content, organization, grammar, vocabulary) for both experimental and comparison groups, combined with qualitative evidence from three focus group discussions; results showed significant and sustained improvements in experimental-group writing performance and overwhelmingly positive student perceptions of ChatGPT’s impact, indicating that ChatGPT can effectively support academic writing development in large ESL classes when used as a feedback tool.",
		"writing_performance_measure (写作表现测量工具_量表或评分标准)": "Researcher-developed analytic rubrics for each of the three paragraph genres (process, comparison, cause-effect) with evaluation criteria including content, organization, grammar, and vocabulary, validated by two applied linguistics experts and applied by two raters with strong inter-rater reliability (Cohen’s Kappa > 0.8).",
		"writing_performance_focus (写作表现关注维度_流利度_准确性_复杂度_体裁等)": "Academic writing performance in three paragraph genres with focus on generation of focused ideas, relevance and sufficiency of supporting details, organization and coherence (including topic sentences, supporting details, signposts, conclusions), and language use (grammatical accuracy and appropriate vocabulary).",
		"affective_aspect_measure (情感因素测量工具_问卷_量表等)": "Three semi-structured focus group discussions with experimental-group students, guided by prompts about their experiences using ChatGPT for self- and peer feedback, perceived benefits and drawbacks, and suggestions for improving its use; students also shared screenshots of interactions with ChatGPT as artefacts during discussions.",
		"affective_aspect_focus (情感因素维度_动机_态度_焦虑_自效感等)": "Students’ attitudes toward ChatGPT as a feedback tool, enjoyment and enthusiasm in using it as a 'writing buddy', perceived motivation and autonomy, perceived reduction of anxiety when asking questions about writing, sense of empowerment in collaborative use, and concerns about possible over-reliance and decreased motivation to think and write independently.",
		"cognitive_aspect_measure (认知因素测量工具)": "Qualitative analysis of FGD transcripts using a phronetic iterative approach to identify how students understood and used ChatGPT feedback for self- and peer assessment, including references to metalinguistic explanations, awareness of genre features, and reflections on organizing ideas and maintaining topic focus.",
		"cognitive_aspect_focus (认知因素维度_策略使用_元认知监控等)": "Use of self-assessment and peer-assessment strategies supported by ChatGPT, metacognitive monitoring of content relevance and organization, recognition of patterns in their own errors, increased explicit knowledge of grammar through ChatGPT’s explanations, and reflection on balancing ChatGPT’s guidance with their own creativity and judgment.",
		"behavioral_aspect_measure (行为因素测量工具_日志_平台日志等)": "Observed and self-reported behaviors captured through FGDs, including coded references to how frequently and in what ways students used ChatGPT during classroom tasks (e.g., for brainstorming, checking topic sentences, verifying signposts, seeking grammar explanations) and how they collaborated with peers around ChatGPT-based feedback; no digital log data were collected.",
		"behavioral_aspect_focus (行为因素维度_使用频率_交互模式_坚持度等)": "Students’ use of ChatGPT to generate focused ideas and information, to maintain attention on the topic, to verify alignment between topic sentences and supporting details, to improve signpost usage and conclusions, to correct sentence structures and vocabulary, to engage in peer collaboration around shared prompts and feedback, and, in some cases, emerging patterns of dependence and reduced manual checking of accuracy.",
		"other_outcomes_measure (其他结果测量工具)": "NR",
		"other_outcomes_focus (其他结果维度说明)": "NR",
		"assessment_timepoints (评估时间点_前测_后测_延迟测等)": "Pre-test administered to both experimental and comparison groups before the intervention; immediate post-test conducted for both groups at the end of the six-hour intervention period; delayed post-test for both groups and a further FGD with five experimental-group students conducted approximately two months after the post-test.",
		"primary_outcome_variables (主要结果变量_因变量)": "Students’ total writing test scores (and underlying rubric-based performance on content, organization, grammar, and vocabulary) on pre-test, post-test, and delayed post-test; qualitatively, students’ reported perceptions of ChatGPT’s impact on their writing skills.",
		"independent_variables_and_factors (自变量与实验因素)": "Group membership (experimental group with ChatGPT-based formative feedback vs comparison group without ChatGPT) and time (pre-test, post-test, delayed post-test); within the experimental group, exposure to ChatGPT-mediated self- and peer assessment activities and training on using ChatGPT as a feedback tool.",
		"followup_length_and_type (随访时长与类型)": "Short-term follow-up via a delayed post-test and FGD administered approximately two months after the immediate post-test to assess the sustainability of intervention effects.",
		"statistical_significance (统计显著性结果摘要)": "For the experimental group, repeated measures ANOVA across pre-test, post-test, and delayed post-test yielded F(2,72)=330.704, p≈5.15×10⁻³⁷, indicating highly significant differences over time. Bonferroni-adjusted post-hoc tests showed statistically significant improvements from pre-test to post-test (p<0.001) and from pre-test to delayed post-test (p<0.001), as well as a smaller but still significant gain from post-test to delayed post-test (p<0.01). Between-group comparisons revealed that the experimental group significantly outperformed the comparison group at post-test (t(70)=−5.643, p≈3.30×10⁻⁷) and at delayed post-test (t(70)=−9.371, p≈5.54×10⁻¹⁴). Normality and homogeneity assumptions were met according to Shapiro–Wilk and Levene’s tests, and no outliers were detected via Grubb’s test.",
		"effect_size_summary (效应量摘要)": "The repeated measures ANOVA for the experimental group produced a large effect size (η²=0.902). Bonferroni post-hoc comparisons indicated very large standardized mean differences between pre-test and post-test (Cohen’s d≈3.300) and between pre-test and delayed post-test (d≈3.898), and a moderate effect between post-test and delayed post-test (d≈0.598). Specific effect sizes for between-group t-tests are not reported, but the very small p-values and large mean differences suggest substantial group-level effects attributable to the ChatGPT-mediated intervention.",
		"llm_misuse_or_negative_effects (LLM滥用或负向效应)": "Students noted several potential negative effects: reduced motivation to think independently and risk of doing less cognitive work because ChatGPT supplies ideas quickly, increased machine dependence and worry about not wanting to write on their own, perception that ChatGPT can impose a fixed pattern on writing and hinder creative organization of content, and occasional reduction in attention to grammatical accuracy due to reliance on ChatGPT corrections. In the broader discussion, the author also references concerns in the literature about threats to academic honesty, ethicality, and creativity associated with ChatGPT use, although these were not empirically measured in this study.",
		"equity_and_subgroup_effects (公平性与亚组差异)": "Participants came from financially well-off backgrounds and an elite private-run institution, and the study discusses implications for similar large-class ESL/EFL settings in the Global South, but no statistical subgroup analyses by gender, socioeconomic status, proficiency band, or other equity-related characteristics are reported.",
		"limitation (研究局限)": "Limitations include focus on only three paragraph genres (process, comparison, cause-effect) with exclusion of other genres such as argumentative essays; a relatively short intervention duration of six hours; absence of student artefact analysis due to privacy and copyright concerns, which limits triangulation of test and perception data; use of an intact classroom and prescribed syllabus that constrained extension of intervention hours and coverage of additional components; and the need for careful wording of generalizations because findings may apply primarily to the genres studied and similar institutional contexts.",
		"challenge (实施挑战与风险)": "Challenges and risks highlighted include dependence on teacher awareness of ChatGPT’s affordances and ability to guide students constructively in large classes, potential loss of creativity and over-structuring of content organization due to following ChatGPT’s suggestions too closely, concerns about academic honesty and ethical use of generative AI in writing, students’ varying ability to formulate appropriate questions and prompts to obtain useful feedback, and the need to move beyond traditional feedback strategies and teacher-centered approaches to fully realize the benefits of dialogic, AI-mediated feedback.",
		"future_work (未来研究方向)": "Future research directions proposed include extending the intervention to cover more writing genres and components (including argumentative writing), lengthening the intervention period to examine longer-term effects, investigating the impact of ChatGPT on specific micro-features of writing (e.g., particular grammatical structures, cohesion devices), examining the role of students’ language proficiency as a moderating variable, and exploring the impact of corrective metalinguistic written feedback delivered through ChatGPT on students’ writing skills over time.",
		"implication (理论与教学实践启示)": "The study supports and extends theories of feedback as a dialogic process and ChatGPT as a formative writing tool by showing that interactions with ChatGPT during writing can positively influence how students seek, interpret, and use feedback in academic writing. Pedagogically, it suggests that with appropriate student training and teacher facilitation, ChatGPT can serve as a scalable feedback mechanism in large ESL writing classes, enhancing formative assessment through self- and peer assessment, reducing feedback-related anxiety, and allowing teachers to focus on higher-level facilitation. It also underscores the need for reflective teacher education and institutional planning to integrate ChatGPT ethically and effectively into writing instruction, balancing AI support with the development of independent writing and critical thinking skills."
	},
	"Study Quality and Reporting": {
		"funding_source (经费来源)": "No external funding was used to conduct the study.",
		"conflict_of_interest (利益冲突声明)": "The author reports no financial or non-financial competing interests.",
		"risk_of_bias_randomization (偏倚风险_分配与随机化)": "The study used an intact class randomly assigned to two sections (experimental vs comparison), but there was no individual-level randomization, and groups may differ on unmeasured characteristics; allocation was not concealed, consistent with a quasi-experimental educational design.",
		"risk_of_bias_blinding (偏倚风险_盲法)": "Blinding procedures are not reported; students obviously knew whether they were using ChatGPT, and while writings were double-rated with high inter-rater reliability, it is not stated whether raters were blinded to group assignment or test time point, leaving potential for detection bias.",
		"attrition_and_missing_data (流失与缺失数据处理)": "Of the 78 experimental-group and 56 comparison-group students who initially consented, only those attending all six intervention hours and completing all three tests were included in the final analysis (EG N=37, CG N=35); the study specifies inclusion and exclusion criteria but does not provide detailed attrition rates or describe statistical treatment of partial data beyond exclusion.",
		"reporting_transparency (报告透明度与可重复性)": "The article provides detailed descriptions of participants, inclusion/exclusion criteria, intervention procedures, test tasks (appendix), rubrics, statistical tests and results (including F, t, p, η², Cohen’s d, and assumption checks), and qualitative coding themes, enhancing transparency; however, raw data and full rubrics are not reproduced, and some numerical inconsistencies in reported group Ns appear between narrative and tables.",
		"preregistration_or_protocol (预注册或研究方案)": "NR",
		"llm_version_reproducibility (LLM版本与可复现性)": "The study identifies ChatGPT as the AI tool but does not specify the underlying version or model (e.g., GPT-3.5 vs GPT-4), access date, or configuration, which may limit exact reproducibility given ongoing updates to the system.",
		"baseline_equivalence (基线等同性检验)": "Although both groups completed a pre-test and normality and homogeneity of variance were assessed, explicit statistical comparisons of baseline writing scores between the experimental and comparison groups are not reported, so baseline equivalence is not fully documented.",
		"assumption_check_and_data_diagnostics (统计假设检验与数据诊断)": "The study reports Levene’s test for equality of variances (f≈0.1608, p≈0.6897), Shapiro–Wilk tests for normality for both groups (no significant departures from normality), and Grubb’s test for outliers (no outliers detected), indicating that key parametric test assumptions were examined and met.",
		"outlier_treatment_and_sensitivity_analysis (异常值处理与稳健性分析)": "Grubb’s test was used to check for outliers and none were found; no additional sensitivity analyses or robustness checks are reported.",
		"data_preprocessing_and_transformation (数据预处理与转换)": "Writing scores from the three tests were analyzed directly using standard parametric procedures (repeated measures ANOVA and t-tests); apart from tests for normality, homogeneity of variance, and outliers, no additional data transformations or preprocessing steps are described."
	}
}