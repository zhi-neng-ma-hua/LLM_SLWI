{
	"Basic Identification": {
		"author (作者)": "Myunghwan Hwang; Robert Jeens; Hee-Kyung Lee",
		"publication_year (发表年份)": "2025",
		"study_region (研究地区)": "South Korea (Korean university with multinational EFL learners)",
		"journal_name (期刊名称)": "The Asia-Pacific Education Researcher",
		"study_type (研究类型_期刊论文_会议论文等)": "Journal article; regular article; one-group pretest–posttest experiment with mixed methods",
		"doi_or_identifier (DOI或唯一标识)": "https://doi.org/10.1007/s40299-024-00930-6",
		"research_aims (研究目的与问题)": "To identify EFL learners prompting behaviors during ChatGPT-assisted English writing revision and to examine how these behaviors affect the quality of their revised writings, specifically by investigating learners objectives for using ChatGPT during revision, their prompt-writing approaches, the alignment between objectives and approaches, and whether these prompting behaviors influence writing outcomes.",
		"research_gap_or_novelty (研究创新性与知识空白)": "Addresses the lack of research on how learners formulate prompts and how prompt-driven learner–ChatGPT interactions impact writing outcomes; prior work largely examined overall ChatGPT impact, learner responses to feedback, and attitudes, but not prompt literacy or objective–approach alignment; introduces a 2-mode network analysis of objectives and prompt approaches together with pre–post writing scores to link prompting behavior with surface-level and higher-order writing outcomes."
	},
	"Participant Information": {
		"educational_level (教育阶段)": "First-year undergraduate students in an advanced English writing course at a Korean university",
		"language_proficiency (语言熟练度水平)": "At least CEFR B2 level based on admission requirements including official English test scores and interview; 7 to 15 years of English learning experience with an average of about 10 years",
		"mother_tongue (母语)": "Multiple L1 backgrounds with participants originating from China, Uzbekistan, Russia, Austria, Mongolia, and Taiwan; specific mother tongues not explicitly reported",
		"sex (性别)": "Total N=11; 2 males (18.2%) and 9 females (81.8%)",
		"age (年龄)": "First-year undergraduates aged between 19 and 21 years",
		"learning_context (学习语境_ESL_EFL_ELL等)": "EFL context in an international program at a Korean university where all coursework is conducted in English",
		"target_language (目标语言)": "English (L2)",
		"discipline (学科背景)": "Various majors within an international program: humanities (n=2), social sciences (n=3), business (n=4), interdisciplinary studies (n=2)",
		"prior_experience_llm (既有LLM使用经验)": "All participants reported having used ChatGPT before the experiment for tasks such as school assignments, information searches, and programming assistance"
	},
	"Methodology": {
		"research_design (研究设计_实验_准实验_纵向等)": "One-group pretest–posttest design over three weeks, with all participants receiving a ChatGPT-assisted revision intervention and their pre- and post-revision essays compared to assess changes in writing quality",
		"research_method (研究方法_定量_定性_混合)": "Mixed methods integrating qualitative thematic and network analysis of prompting behaviors with quantitative nonparametric analysis of pre- and post-writing scores",
		"sampling_method (抽样方法)": "Volunteer convenience sampling of 11 multinational students enrolled in an advanced English writing course in a Korean university international program",
		"sample_size_and_effect (样本量及效应量)": "Total N=11 EFL undergraduates. Writing scores were rated on seven TEEP attributes (content, organization, cohesion, vocabulary, grammar, punctuation, spelling, each 0–3). Wilcoxon signed-rank tests showed significant improvements for grammar and spelling but not for higher-order attributes. Grammar: pre Md=2.00, M=2.04, SD=0.72; post Md=2.83, M=2.77, SD=0.41; z=−2.21, p<0.05, matched pairs rank biserial correlation r=0.92. Spelling: pre Md=2.17, M=2.23, SD=0.41; post Md=2.83, M=2.77, SD=0.41; z=−2.46, p<0.05, r=0.90. Content, organization, cohesion, vocabulary, and punctuation showed positive but non-significant pre–post changes (p>0.05).",
		"theoretical_foundation (理论基础_理论框架)": "Assemblage framework for learner–ChatGPT interactions conceptualising learners and ChatGPT as co-participants in a dynamic system; concept of prompt literacy as the ability to engineer prompts aligned with user objectives and critically evaluate AI feedback; prompt-engineering literature on crafting and refining prompts for LLMs; underlying transformer and attention mechanisms of LLMs such as ChatGPT; use of the TEEP attribute writing scale framework for writing assessment.",
		"data_collection_instrument (数据收集工具)": "Pre- and post-writing samples scored with the Test in English for Educational Purposes (TEEP) attribute writing scale measuring content, organization, cohesion, vocabulary, grammar, punctuation, and spelling, each on a 0–3 scale; reflection logs with questions about difficulties during revision, reasons for using ChatGPT, and the specific prompts used; ChatGPT log history consisting of actual learner–ChatGPT interaction records shared by participants via email or an online board.",
		"data_collection_validity_reliability (工具信度与效度)": "Two independent raters scored pre- and post-writing samples using the TEEP scale. Inter-rater reliability was evaluated using Cohen s Kappa. Pre-writing Kappa values: content 0.62, organization 0.86, cohesion 0.86, vocabulary 0.85, grammar 0.85, punctuation 0.81, spelling 0.74, total score 0.95. Post-writing Kappa values: content 0.82, organization 0.65, cohesion 0.81, vocabulary 0.79, grammar 0.74, punctuation 1.00, spelling 0.74, total score 0.92. These were interpreted as substantial to almost perfect agreement based on Landis and Koch. For thematic coding of objectives and prompt approaches, test–retest reliability of frequency coding using the developed coding scheme yielded Kappa=1.0.",
		"data_analysis_method (数据分析方法)": "Thematic analysis of reflection logs to identify and categorise learners objectives for using ChatGPT (15 categories) and prompt approaches (10 categories); frequency counts of objectives and approaches; construction of a 2-mode objective–approach network and computation of degree centrality using Ucinet and visualisation with Netdraw to examine alignment and imbalance between objectives and approaches; descriptive statistics (means, medians, standard deviations) for pre- and post-writing scores; Wilcoxon signed-rank tests to compare pre- and post-writing scores for each TEEP attribute due to small sample size; calculation of matched pairs rank biserial correlation as effect size; all statistical tests conducted in SPSS.",
		"unit_of_analysis (分析单位)": "Individual learner essays for writing scores; individual learners for pre–post comparisons; individual objectives and prompt approaches for thematic and network analysis of prompting behaviors.",
		"group_assignment_method (组别分配方式_随机_非随机等)": "Single cohort one-group pretest–posttest design in which all 11 students received the ChatGPT-assisted revision intervention; no random assignment to different groups and no separate control group.",
		"power_analysis (功效分析与样本量论证)": "NR",
		"sampling_frame_and_representativeness (抽样框与样本代表性)": "Sampling frame comprised first-year students in an advanced English writing course within an international program at a Korean university; small sample size (N=11) and single-institution context with relatively homogeneous high-proficiency EFL learners limit representativeness and generalisability to other EFL populations and settings.",
		"scoring_procedure_and_rater_training (评分流程与评分者培训)": "Pre- and post-writing samples were rated independently by two trained raters: one research team member with a PhD in English education and extensive teaching and research experience, and one external Filipino rater with English as a first language, a master s degree, and more than 12 years of high school English teaching experience; both used the TEEP attribute writing scale; inter-rater reliability was quantified via Cohen s Kappa for each attribute and total scores; specific rater training procedures beyond description of rater backgrounds and reliability assessment were not detailed."
	},
	"Intervention": {
		"duration (干预时长与频率)": "Three-week intervention: week 1 ChatGPT workshop and discussion, week 2 30-minute pretest essay without AI or external aids, week 3 ChatGPT-assisted revision of the pretest essay in two revision sessions (one outside class with no time limit and one in class for 30 minutes) with an average of 3.5 and 3 learner–ChatGPT turns per session respectively.",
		"llm_model_type (LLM模型类型_如ChatGPT_GPT4_Gemini等)": "ChatGPT (OpenAI large language model, transformer-based LLM)",
		"llm_model_configuration (LLM模型配置与版本_API_网页_参数等)": "NR",
		"llm_integration_mode (LLM整合模式_直接使用_教师中介_系统嵌入)": "Students interacted directly with ChatGPT during the revision stage of their essays, using the chatbot to request ideas, corrections, rewrites, and feedback; interactions occurred both outside class and in class, and logs of these direct learner–ChatGPT conversations were collected.",
		"prompting_strategy (提示策略_提示工程与使用方式)": "No explicit prompt-writing instruction was provided as part of the intervention; the week 1 workshop introduced ChatGPT s architecture, features, role in improving writing quality, and some prompt examples but intentionally excluded direct guidance on how to formulate prompts to maintain authenticity; learners spontaneously employed prompt approaches such as rewriting the entire essay, requesting ideas, general grammar checks, simplification, requesting general feedback, general error checks, partial rewrites, synonym searches, checking organization, and requesting samples; analysis revealed frequent use of general one-size-fits-all prompts, limited variety of approaches, and often misalignment between specific objectives and chosen prompt approaches.",
		"training_support_llm_literacy (LLM素养与提示培训)": "In week 1 a workshop provided learners with their first formal learning experience with ChatGPT, introducing its architecture, features, and its potential role in improving writing quality using prompt examples; participants discussed prior experiences with ChatGPT and shared views on incorporating the tool into their learning; however, direct instruction on prompt-engineering strategies was deliberately omitted to observe natural prompting behaviors; beyond this introductory workshop, no further structured LLM literacy or prompt training is reported.",
		"intervention_implementation (干预实施流程_步骤与任务)": "A member of the research team led the class. Week 1: workshop introducing ChatGPT s architecture, features, and role in writing, with example prompts and group discussions about experiences and views on using ChatGPT; explicit prompt-writing guidance was excluded. Week 2: learners completed a 30-minute pretest essay comparing and contrasting urban and rural lifestyles without dictionaries, ChatGPT, internet access, peer discussions, or prior formal instruction on comparison essays. Week 3: learners revised their initial drafts using ChatGPT in two stages. In session 1 outside class, with no time limit, they interacted with ChatGPT to revise their essays. In session 2 in class, they had 30 minutes to continue ChatGPT-assisted revision, with an average of 3.5 and 3 ChatGPT turns for the two sessions respectively. After each revision, participants completed reflection logs describing their difficulties, reasons for using ChatGPT, and specific prompts. They also submitted their ChatGPT interaction logs via email or an online board. Pre- and post-writing samples were then scored using the TEEP scale.",
		"experimental_group_intervention (实验组干预内容)": "All 11 advanced EFL learners formed a single intervention group: they first wrote an in-class comparison essay without tools and subsequently revised the same essay using ChatGPT in two revision sessions, during which they crafted prompts aligned to their perceived needs, received ChatGPT feedback, and edited their essays accordingly while documenting objectives, prompt approaches, and experiences in reflection logs.",
		"control_group_intervention (对照组干预内容)": "NA",
		"writing_stage (写作阶段_如生成_修改_反馈_重写等)": "ChatGPT was used only during the revision stage of writing; the initial essay drafts were produced without AI or other external aids, and ChatGPT-assisted interactions focused on revising and improving these drafts.",
		"writing_genre (写作体裁)": "Comparison and contrast essay on urban and rural lifestyles",
		"writing_task_type (写作任务类型)": "Timed in-class expository comparison essay as pretest, followed by out-of-class and in-class revision tasks supported by ChatGPT; no formal instruction on comparison essays was provided before the pretest",
		"role_llm (LLM角色_如生成文本_给反馈_评分_对话等)": "ChatGPT functioned as an interactive writing assistant during revision, used to generate ideas, correct grammar, enhance vocabulary and sentence naturalness, suggest alternative word choices and synonyms, provide general feedback, check tone and organization, and rewrite sentences or entire essays; it did not act as an official scorer of writing quality.",
		"role_instructor (教师角色与介入方式)": "A research team member taught the advanced writing course, designed and led the ChatGPT workshop, set the essay tasks and conditions, explained procedures, collected reflection logs and ChatGPT logs, and coordinated data collection; two independent raters (one researcher and one external rater) scored the pre- and post-writing samples; instructors did not provide direct feedback on the intervention essays during the revision stage, allowing ChatGPT to be the primary feedback source.",
		"setting (教学情境_学校类型_课程类型_线上线下)": "International program at a Korean university where all coursework is in English; advanced English writing course; pretest essay written in a face-to-face classroom without external tools; ChatGPT-assisted revision conducted partly outside class and partly in class; data shared via email and online course board.",
		"ethical_consideration (伦理审查与知情同意)": "The study underwent review by the Institutional Review Board of Yonsei University and obtained approval; participants volunteered to join the experiment; explicit statements about written informed consent procedures are not reported.",
		"llm_access_policy (LLM使用规范_允许与限制)": "During the pretest writing, participants were explicitly prohibited from using dictionaries, ChatGPT, the internet, or peer discussion; ChatGPT use was restricted to the revision stage of the prewritten essay and was not allowed during initial draft composition; no broader institutional AI use policies are detailed.",
		"llm_safety_guardrails (LLM安全与内容过滤设置)": "NR",
		"key_findings (主要研究发现_与LLM写作干预相关)": "Learners displayed a wide range of objectives for using ChatGPT during revision, but relied on a relatively small set of prompt approaches, frequently using general prompts and heavily depending on rewriting the entire essay as a one-size-fits-all solution; network analysis showed imbalances and misalignments between specific objectives and approaches, indicating limited prompt literacy and difficulties in crafting precise, goal-aligned prompts. Quantitatively, significant improvements were observed in surface-level writing features, specifically grammar and spelling, while higher-order aspects such as content, organization, and cohesion showed only modest, statistically non-significant gains. These patterns suggest that ChatGPT-assisted revision, as used by learners without explicit prompt training, primarily enhanced lower-level linguistic accuracy, and that ineffective prompting behaviors limited potential improvements in higher-order writing quality, highlighting the need for explicit instruction in prompt-writing and prompt literacy."
	},
	"Outcome": {
		"application_effectiveness_overview (应用效果总体评价与测量工具)": "Using ChatGPT as a revision assistant led to significant improvements in surface-level writing features but only limited enhancement in higher-order writing quality. Effectiveness was assessed through pre- and post-writing scores on the TEEP attribute writing scale (content, organization, cohesion, vocabulary, grammar, punctuation, spelling), scored by two independent raters, and analysed via Wilcoxon signed-rank tests and matched pairs rank biserial correlations. Thematic and network analyses of reflection logs and ChatGPT logs further showed that learners prompting behaviors strongly influenced the extent and nature of improvements, with a focus on grammar and spelling and less attention to content and organisation.",
		"writing_performance_measure (写作表现测量工具_量表或评分标准)": "Test in English for Educational Purposes (TEEP) attribute writing scale (Weir 1990) rating seven attributes: content, organization, cohesion, vocabulary, grammar, punctuation, and spelling, each on a 0–3 scale",
		"writing_performance_focus (写作表现关注维度_流利度_准确性_复杂度_体裁等)": "Surface-level accuracy and mechanics (grammar, punctuation, spelling, vocabulary) and higher-order writing dimensions (content, organization, cohesion) as separate scored attributes, allowing the study to differentiate improvements in lower-level linguistic features versus higher-order rhetorical and structural aspects.",
		"affective_aspect_measure (情感因素测量工具_问卷_量表等)": "Reflection logs in which learners described difficulties, reasons for using ChatGPT during revision, and experiences with using the tool; no standardised affective questionnaire or scale was used.",
		"affective_aspect_focus (情感因素维度_动机_态度_焦虑_自效感等)": "Learners subjective perceptions of ChatGPT s usefulness in addressing writing difficulties, feelings of uncertainty about how to ask questions or what to request, and perceived challenges or satisfaction with AI-provided feedback; affective dimensions such as motivation, anxiety, or self-efficacy were mentioned implicitly but not systematically measured as separate constructs.",
		"cognitive_aspect_measure (认知因素测量工具)": "TEEP scale scores on content, organization, and cohesion as indicators of higher-order cognitive aspects of writing; thematic analysis of reflection logs capturing learners stated objectives, perceived difficulties, and reasoning; 2-mode network analysis of objectives and prompt approaches as a representation of learners cognitive strategies in translating revision goals into prompts.",
		"cognitive_aspect_focus (认知因素维度_策略使用_元认知监控等)": "Prompt literacy and prompt-engineering skills (ability to translate objectives into effective prompts), awareness of different writing dimensions (surface-level versus higher-order aspects), and meta-knowledge of how to target specific problems through interactions with ChatGPT; the study discusses learners lack of meta-knowledge about which aspects to focus on, how to construct queries with appropriate keywords, and how to align prompt approaches with writing goals.",
		"behavioral_aspect_measure (行为因素测量工具_日志_平台日志等)": "Authentic ChatGPT log histories containing learners prompts and ChatGPT responses; reflection logs documenting how and why learners used ChatGPT; counts and coding of objectives for using ChatGPT (15 categories) and prompt approaches (10 categories); network analysis metrics such as degree centrality in the 2-mode objective–approach network.",
		"behavioral_aspect_focus (行为因素维度_使用频率_交互模式_坚持度等)": "Prompting behaviors including objectives for using ChatGPT (e.g. improving grammar accuracy, generating ideas, finding words, making sentences natural, checking organization and tone, seeking feedback), prompt approaches (e.g. rewriting entire essay, requesting ideas, general grammar check, simplification, requesting general feedback, general error check, partial rewriting, synonym search, organization check, requesting samples), alignment or misalignment between objectives and approaches, over-reliance on general one-size-fits-all approaches such as rewriting essays, and the average number of ChatGPT turns per revision session (about 3.5 and 3 turns in the two sessions).",
		"other_outcomes_measure (其他结果测量工具)": "2-mode network analysis with degree centrality to map relationships between objective categories and prompt approaches; Cohen s Kappa statistics for inter-rater reliability on TEEP scores; Kappa for test–retest reliability in coding objectives and prompt approaches; descriptive statistics for all writing attributes pre and post intervention.",
		"other_outcomes_focus (其他结果维度说明)": "Balance and imbalance in the objective–approach network, indicating whether learners used a diverse set of prompt strategies for different objectives or relied on a few approaches across many objectives; identification of central objectives and approaches with high degree centrality; evidence of prompt misalignment and complete discrepancies between learners intentions and prompts; confirmation of substantial and almost perfect inter-rater reliability for writing scores and stability of the coding scheme for objectives and prompt approaches.",
		"assessment_timepoints (评估时间点_前测_后测_延迟测等)": "Pretest writing assessment in week 2 using a 30-minute comparison essay written without AI or external aids; posttest writing assessment in week 3 on the revised version of the same essay after two ChatGPT-assisted revision sessions; no delayed follow-up assessment beyond the three-week period.",
		"primary_outcome_variables (主要结果变量_因变量)": "Scores on TEEP writing attributes (content, organization, cohesion, vocabulary, grammar, punctuation, spelling) for pre- and post-writing samples; changes in these scores, particularly grammar and spelling where significant improvements were found.",
		"independent_variables_and_factors (自变量与实验因素)": "Presence of the ChatGPT-assisted revision intervention, treated as a within-subject factor via pre- versus post-writing comparisons; variation in learners prompting behaviors (objectives and prompt approaches) conceptually linked to writing outcomes though not modelled through inferential statistics beyond descriptive and network analysis.",
		"followup_length_and_type (随访时长与类型)": "Three-week short-term intervention with immediate post-revision assessment; no long-term or delayed follow-up conducted.",
		"statistical_significance (统计显著性结果摘要)": "Wilcoxon signed-rank tests showed statistically significant improvements for grammar (z=−2.21, p<0.05, r=0.92) and spelling (z=−2.46, p<0.05, r=0.90) between pre- and post-writing; content (z=−1.63, p=0.102), organization (z=−0.76, p=0.450), cohesion (z=−1.86, p=0.063), vocabulary (z=−1.71, p=0.088), and punctuation (z=−1.89, p=0.059) showed positive but non-significant changes; thus significant gains were confined to surface-level features of grammar and spelling.",
		"effect_size_summary (效应量摘要)": "Matched pairs rank biserial correlation effect sizes indicated very large effects for grammar (r=0.92) and spelling (r=0.90), with similarly large r values reported for other attributes despite their non-significant p-values, likely reflecting the small sample size and distribution of scores; no additional effect size indices such as Cohen s d or partial eta squared were reported.",
		"llm_misuse_or_negative_effects (LLM滥用或负向效应)": "The study did not report explicit misuse such as plagiarism but identified several risks associated with limited prompt literacy, including receiving inaccurate or irrelevant responses that do not match learners objectives, unproductive feedback when prompts are too general or unspecific, and overly verbose ChatGPT responses that impose high cognitive load and may hinder effective revision; learners over-relied on general prompts and complete essay rewrites, which the authors argue can limit engagement with higher-order writing aspects and reduce the educational value of AI-assisted revision.",
		"equity_and_subgroup_effects (公平性与亚组差异)": "No subgroup analyses by gender, country of origin, major, or proficiency band were reported, and equity-related issues were not specifically analysed; NR.",
		"limitation (研究局限)": "Limitations noted include the small sample size (N=11) from a single advanced writing class, limiting generalisability; use of a one-group pretest–posttest design with no control group, making it difficult to rule out alternative explanations for observed changes; the study did not consider learners subsequent responses to ChatGPT feedback such as acceptance, rejection, or detailed incorporation into revisions; it did not systematically investigate the root causes that make it difficult for learners to create effective prompts; and it did not analyse the influence of potential learner factors such as AI literacy, English proficiency differences, or task types on prompting behaviors and prompt literacy development.",
		"challenge (实施挑战与风险)": "Challenges include learners difficulty in translating revision objectives into effective, specific prompts; a tendency to rely on general or one-size-fits-all prompt approaches such as rewriting entire essays; potential cognitive overload from verbose AI responses; the need to guide learners in managing expectations about ChatGPT s capabilities and understanding that AI does not interpret prompts like humans; and the practical constraint of providing adequate prompt-writing instruction within existing writing curricula.",
		"future_work (未来研究方向)": "Future research should integrate analysis of learners objectives, prompt approaches, and their actual responses to ChatGPT feedback to gain a more holistic understanding of the prompting process and its impact on writing quality; investigate the underlying factors that contribute to difficulties in prompt-writing, including AI literacy, meta-knowledge of writing, and task characteristics; examine how different learner factors such as English proficiency and other background variables affect prompt literacy growth; and design and test prompt-writing instruction or prompt literacy interventions to determine how targeted training can improve both prompting behaviors and higher-order writing outcomes.",
		"implication (理论与教学实践启示)": "The study highlights prompt literacy as a critical component of effective learner–ChatGPT interaction, suggesting that writing pedagogy should explicitly include instruction on crafting specific, goal-aligned prompts to leverage ChatGPT s capabilities for both surface-level and higher-order writing improvement; it shows that without such training, learners may primarily obtain benefits in grammar and spelling but not in deeper aspects of content and organization; theoretically, the assemblage perspective underscores the co-constructed nature of learner–LLM interactions, with prompts serving as key mediators; practically, instructors are encouraged to integrate ChatGPT into revision stages while teaching students how to formulate targeted prompts for content, coherence, and organisation, to critically evaluate AI feedback, and to balance AI support with learners own critical thinking and revision skills."
	},
	"Study Quality and Reporting": {
		"funding_source (经费来源)": "Supported by the Ministry of Education of the Republic of Korea and the National Research Foundation of Korea, grant number NRF-2023S1A5B5A16079327.",
		"conflict_of_interest (利益冲突声明)": "NR",
		"risk_of_bias_randomization (偏倚风险_分配与随机化)": "Risk of bias from lack of randomization and absence of a control group is present since a one-group pretest–posttest design was used and all participants received the ChatGPT-assisted revision intervention; individual differences and maturation effects cannot be fully ruled out as alternative explanations for observed changes.",
		"risk_of_bias_blinding (偏倚风险_盲法)": "Two independent raters scored the writing samples, but the article does not specify whether they were blinded to pretest or posttest status; participants and instructors were aware of ChatGPT use, so blinding at the participant and teacher level was not possible; blinding of analysts conducting statistical and network analyses is not reported.",
		"attrition_and_missing_data (流失与缺失数据处理)": "The study consistently reports N=11 participants for analyses and does not describe attrition or missing data; handling of any potential missing values is not discussed.",
		"reporting_transparency (报告透明度与可重复性)": "The article provides detailed information on participants, setting, research design, timelines, tasks, instruments, scoring scale, rater characteristics, coding schemes for objectives and prompt approaches, analytical methods including network analysis and Wilcoxon tests, and main numerical results including Kappa, z, p, and effect sizes; IRB approval and funding are reported; however, specific ChatGPT configuration details, raw datasets, and analysis code are not shared, and there is no preregistered protocol referenced.",
		"preregistration_or_protocol (预注册或研究方案)": "NR",
		"llm_version_reproducibility (LLM版本与可复现性)": "The study identifies ChatGPT as the generative AI tool but does not report the underlying model version, access method, or parameter settings, which limits precise reproducibility of the AI component; only the general interaction pattern and analysis of prompting behaviors are fully reproducible from the description.",
		"baseline_equivalence (基线等同性检验)": "NA",
		"assumption_check_and_data_diagnostics (统计假设检验与数据诊断)": "The authors justified use of the nonparametric Wilcoxon signed-rank test due to small sample size but did not report additional diagnostics such as distribution checks, outlier detection, or other assumption tests; no diagnostics for network analysis are discussed.",
		"outlier_treatment_and_sensitivity_analysis (异常值处理与稳健性分析)": "No explicit outlier detection, exclusion criteria, or sensitivity analyses are described.",
		"data_preprocessing_and_transformation (数据预处理与转换)": "Writing samples were scored on the TEEP scale by two raters and aggregated into attribute scores and total scores; Cohen s Kappa was computed for reliability; reflection logs were coded into objective and prompt-approach categories using a developed coding scheme; frequencies were calculated and then entered into network analysis software to construct 2-mode networks and compute degree centrality; no additional data transformations such as scaling or normalisation are reported."
	}
}