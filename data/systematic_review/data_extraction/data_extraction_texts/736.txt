{
	"Basic Identification": {
		"author (作者)": "Mohammad Ghafouri; Jaleh Hassaskhah; Amir Mahdavi-Zafarghandi",
		"publication_year (发表年份)": "2024",
		"study_region (研究地区)": "Iran (Iranian EFL teachers and learners)",
		"journal_name (期刊名称)": "Language Teaching Research",
		"study_type (研究类型_期刊论文_会议论文等)": "Peer-reviewed journal article; experimental, longitudinal, mixed-methods with ANCOVA and t-test analyses",
		"doi_or_identifier (DOI或唯一标识)": "10.1177/13621688241239764",
		"research_aims (研究目的与问题)": "To investigate the impact of a ChatGPT-based writing instruction protocol (CGWIP) on EFL teachers’ self-efficacy and learners’ L2 writing skills and retention; specifically, to examine how ChatGPT-based writing instruction influences (1) EFL teachers’ self-efficacy, (2) EFL learners’ writing skills, and (3) the retention of EFL learners’ writing skills.",
		"research_gap_or_novelty (研究创新性与知识空白)": "Addresses the lack of empirical studies connecting AI tools, especially ChatGPT, with psycho-emotional aspects of L2 teachers (self-efficacy, well-being) and learners’ writing skills; provides a structured three-phased ChatGPT-based Writing Instruction Protocol (CGWIP) for L2 writing instruction, filling the gap of integrated, operationalized AI-based writing instruction modules and examining both teacher and learner outcomes including retention."
	},
	"Participant Information": {
		"educational_level (教育阶段)": "Tertiary-level EFL learners (adult learners aged 20–27) in online classes; in-service EFL teachers (ages 24–32) with 5–8 years of teaching experience.",
		"language_proficiency (语言熟练度水平)": "Learners classified as intermediate level (B1 CEFR) based on the Oxford Placement Test (OPT; Allan, 2004); teachers’ language proficiency not explicitly reported.",
		"mother_tongue (母语)": "Persian (Iranian participants; specific mother tongue not explicitly stated but implied as Persian).",
		"sex (性别)": "Teachers: 6 male, 6 female; Learners: 19 male, 29 female.",
		"age (年龄)": "Teachers: 24–32 years; Learners: 20–27 years.",
		"learning_context (学习语境_ESL_EFL_ELL等)": "EFL context (Iranian learners of English as a foreign language in online classes).",
		"target_language (目标语言)": "English (L2)",
		"discipline (学科背景)": "General EFL writing instruction with focus on IELTS general writing tasks; learners from various backgrounds in private EFL classes (specific academic majors NR).",
		"prior_experience_llm (既有LLM使用经验)": "NR"
	},
	"Methodology": {
		"research_design (研究设计_实验_准实验_纵向等)": "Experimental, longitudinal design with random assignment of teachers and learners to experimental and control groups; 10-week CGWIP intervention with pre-test, post-test, and 1-week delayed post-test for learners’ writing; pre-test and post-test for teachers’ self-efficacy.",
		"research_method (研究方法_定量_定性_混合)": "Primarily quantitative (t-tests, ANCOVA) with descriptive discussion; no separate qualitative interview component reported for this study.",
		"sampling_method (抽样方法)": "Teachers: convenience sampling via Telegram contact, then random assignment of 12 teachers to experimental and control groups (6 each). Learners: each teacher selected and grouped four intermediate-level students willing to participate in 10-week online writing classes; 48 learners (intermediate by OPT) were then assigned based on their teacher’s group membership to experimental learners’ group (n=24) or control group (n=24).",
		"sample_size_and_effect (样本量及效应量)": "Teachers: N=12 (experimental n=6, control n=6). Learners: N=48 (experimental n=24, control n=24), all intermediate by OPT. OPT homogeneity: t(46)=0.335, p>.05, r=0.049 (no significant initial proficiency difference). Teacher self-efficacy pre-test homogeneity: t(10)=0.127, p>.05, r=0.040. Teacher self-efficacy post-test: experimental group significantly higher than control, t(10)=5.714, p<.001, r=0.88 (large effect), mean difference=9.833, 95% CI [5.999, 13.667]. Learner writing post-test ANCOVA (controlling pre-test): F(1,45)=44.055, p<.001, partial η²≈.495 (reported as .50, large effect). Covariate pre-test effect: F(1,45)=83.407, p<.001, partial η²=.650 (large). Delayed post-test writing: t(46)=6.149, p<.001, mean difference=1.396 bands, 95% CI [0.939, 1.853].",
		"theoretical_foundation (理论基础_理论框架)": "Grounded in Positive Psychology (Seligman & Csikszentmihalyi, 2000; Csikszentmihalyi, 2014) and Social-Cognitive Theory (Bandura, 1997, 2011) with a focus on teacher self-efficacy as a key component of teacher well-being; draws on L2 writing research and process writing approach (e.g., Badger & White, 2000; Ferris, 2014; Hyland, 2003) and AI-in-education literature regarding ChatGPT and AI-based tools as instructional supports.",
		"data_collection_instrument (数据收集工具)": "Oxford Placement Test (OPT; Allan, 2004) to determine learners’ general English proficiency and ensure intermediate level and group homogeneity; IELTS writing tasks from the Complete IELTS series (Brook-Hart & Jakeman, 2012a, 2012b) used for pre-test, 10-week instruction, post-test, and a new set of latest IELTS writing tasks for 1-week delayed post-test; IELTS Writing Task checklist based on the official 9-band descriptors assessing task achievement, cohesion and coherence, lexical resource, and grammatical range and accuracy; Teachers’ Self-Efficacy Scale (TSES) by Schwarzer et al. (1999), 10 items on a 4-point Likert scale assessing job accomplishment, skill development, social interaction with students, and coping with stress.",
		"data_collection_validity_reliability (工具信度与效度)": "OPT reliability confirmed via KR-21, r=.71. Normality assumption met (estimated ratios < ±1.96). Inter-rater reliability for learners’ writing scores showed significant agreement between ChatGPT and a human IELTS expert: pre-test r(46)=.697, post-test r(46)=.658, delayed post-test r(46)=.648, all p<.05 (large effect size). Cronbach’s alpha for teachers’ self-efficacy: pre-test (n=10 items) α=.785, post-test α=.858, indicating acceptable internal consistency.",
		"data_analysis_method (数据分析方法)": "SPSS 26 used. Normality, reliability (KR-21, Cronbach’s alpha), and inter-rater reliability (correlations, Cohen’s Kappa for writing scoring reportedly 94% agreement) were examined. Independent-samples t-tests used for: (1) OPT scores to confirm learner homogeneity; (2) teacher TSE pre-test homogeneity; (3) teacher TSE post-test comparison between groups; (4) delayed post-test writing comparison between groups. One-way ANCOVA used to test CGWIP effects on learners’ writing post-test (and delayed post-test) using pre-test writing scores as covariate; assumptions of homogeneity of variances, linearity, and homogeneity of regression slopes were checked.",
		"unit_of_analysis (分析单位)": "Individual teacher for TSE analyses; individual learner for writing proficiency analyses.",
		"group_assignment_method (组别分配方式_随机_非随机等)": "Random assignment of 12 teachers into experimental and control groups (6 per group); each teacher then selected four intermediate learners, with learners grouped according to their teacher’s assignment (clustered randomization at the teacher/class level).",
		"power_analysis (功效分析与样本量论证)": "Teacher sample size justified by reference to Cohen (1992) recommendations for ANCOVA (minimum six participants per group to reach power 0.80 with alpha 0.05 for a medium effect size); no separate power analysis for learner sample reported.",
		"sampling_frame_and_representativeness (抽样框与样本代表性)": "Teacher sampling frame: Iranian EFL teachers reachable via Telegram with online classes; learner sampling frame: intermediate-level students (OPT-confirmed) in these teachers’ classes willing to attend 10 consecutive weeks of online writing-focused sessions; participants limited to one national and sociocultural context, which restricts representativeness beyond similar Iranian EFL settings.",
		"scoring_procedure_and_rater_training (评分流程与评分者培训)": "Learners’ pre-test, post-test, and delayed post-test writing were rated according to the IELTS 9-band writing descriptors (task achievement, cohesion and coherence, lexical resource, grammatical range and accuracy). ChatGPT was used as a rater to analyse and rate each script, and an IELTS-examiner expert independently reviewed scores and provided feedback; Cohen’s Kappa indicated 94% agreement between raters. Final score aggregation method (e.g., average vs consensus) not explicitly specified. Teacher self-efficacy scored using TSES (4-point Likert) with standard scoring; rater training for TSES not required."
	},
	"Intervention": {
		"duration (干预时长与频率)": "10-week writing instruction program with two 90-minute online sessions per week (total 20 sessions) for both experimental and control groups; learners’ writing pre-test administered one week before intervention, post-test immediately after, and delayed post-test one week later.",
		"llm_model_type (LLM模型类型_如ChatGPT_GPT4_Gemini等)": "ChatGPT (GPT-3.5)",
		"llm_model_configuration (LLM模型配置与版本_API_网页_参数等)": "ChatGPT-3.5 accessed via the official ChatGPT platform (https://openai.com/chatgpt);premium accounts were provided to experimental - group teachers and learners to access the chatbot before, during, and after classes;no API usage, temperature settings, or additional parameters reported.",
		"llm_integration_mode (LLM整合模式_直接使用_教师中介_系统嵌入)": "Teachers in the experimental group directly interacted with ChatGPT for planning, instruction, and assessment phases; learners in the experimental group also directly interacted with ChatGPT through their own premium accounts during allocated portions of each session and for homework. ChatGPT was not embedded in an LMS but used as an external conversational assistant integrated into the writing instruction protocol (CGWIP).",
		"prompting_strategy (提示策略_提示工程与使用方式)": "Teachers prompted ChatGPT by providing information about lesson topics, learners’ proficiency levels, and session objectives to obtain lesson plans, topic lists, specific learning outcomes, suggested materials, and writing task designs. During instruction, teachers used ChatGPT to generate writing prompts, sample texts, and detailed sample analyses, and to request diagnostic and general corrective feedback on learners’ written output. ChatGPT was also prompted to generate IELTS-like writing tasks and detailed expected-output descriptions for exam simulation. No explicit use of advanced prompting techniques (e.g., chain-of-thought, few-shot examples) was reported beyond these structured instructional prompts.",
		"training_support_llm_literacy (LLM素养与提示培训)": "Before the intervention, experimental-group teachers attended a one-hour online training session on ChatGPT and the CGWIP, including how to use ChatGPT for lesson planning, generating prompts, analysing writing, and providing feedback. During instruction, teachers introduced ChatGPT to learners, explained strategy-based learning with the chatbot, and allocated time for supervised student–ChatGPT interaction, aiming to develop learners’ digital literacy, autonomy, and self-confidence in using ChatGPT for self-regulated writing improvement.",
		"intervention_implementation (干预实施流程_步骤与任务)": "After pre-testing and randomization, control-group teachers implemented a task-based process writing model with pre-task (purpose introduction, topic discussion, brainstorming), while-task (teacher modeling, analysis, and revision of student outputs), and post-task phases (evaluation and task assignment). Experimental-group teachers implemented the three-phased ChatGPT-based Writing Instruction Protocol (CGWIP): Planning phase: teachers used ChatGPT to brainstorm ideas, determine course and session objectives, identify topics, set learning outcomes, select materials, and design writing tasks aligned with IELTS general writing. Instruction phase: teachers used ChatGPT to generate writing prompts and sample texts, provide detailed sample analyses and strategy introduction, guide learners in strategy-based use of ChatGPT, allocate time for student–chatbot interaction on writing homework and tasks, and obtain diagnostic and general corrective feedback from ChatGPT on learners’ writings, which teachers then discussed with students. Assessment phase: teachers used ChatGPT to assign additional writing tasks, analyse written output, monitor learners’ progress, set up exam simulations with ChatGPT-generated IELTS tasks, and guide learners to produce responses within time limits considering IELTS criteria (task achievement, cohesion and coherence, lexical resource, grammatical range and accuracy). Pre-test, post-test, and delayed post-test writing tasks were rated using IELTS descriptors with ChatGPT and human examiner scoring.",
		"experimental_group_intervention (实验组干预内容)": "Experimental teachers (n=6) and their learners (n=24) followed CGWIP. Teachers used ChatGPT-3.5 for session planning (objectives, topics, materials, tasks), in-class instruction (prompt generation, sample analysis, strategy instruction), and assessment (additional tasks, monitoring, exam simulation). Learners used premium ChatGPT accounts under teacher guidance during dedicated segments in each session and for homework to brainstorm, draft, revise, and refine their IELTS-style writing, receiving detailed automated feedback which was then interpreted and supplemented by teachers.",
		"control_group_intervention (对照组干预内容)": "Control teachers (n=6) and their learners (n=24) followed a task-based process writing model without ChatGPT or other AI tools. Teachers introduced session purposes, discussed topics, brainstormed ideas, modeled writing tasks, analysed and revised learners’ outputs, and conducted evaluation and task assignment using traditional teacher-led methods; no AI-based planning, instruction, or assessment was involved.",
		"writing_stage (写作阶段_如生成_修改_反馈_重写等)": "ChatGPT was involved across multiple writing stages: pre-writing/planning (idea generation, outline and lesson plan design), drafting and composing (prompt generation and sample analysis to guide learners’ drafting), revising and editing (diagnostic and general corrective feedback on learners’ drafts supporting revision), and assessment/exam simulation (generation of IELTS-like tasks, analysis of written outputs, and formative assessment of progress).",
		"writing_genre (写作体裁)": "IELTS general writing tasks (combination of general-module IELTS writing tasks from the Complete IELTS series and additional latest IELTS writing tasks for delayed post-test), including letter and essay-type writing oriented toward general writing proficiency.",
		"writing_task_type (写作任务类型)": "Standardized IELTS general writing tasks simulating IELTS exam conditions; tasks required meeting criteria for task achievement, cohesion and coherence, lexical resource, and grammatical range and accuracy; tasks were used for pre-test, instructional practice, post-test, and delayed post-test.",
		"role_llm (LLM角色_如生成文本_给反馈_评分_对话等)": "ChatGPT acted as a virtual assistant and writing mentor: generating ideas, lesson plans, and writing prompts; producing sample texts and analyses; providing diagnostic and general corrective feedback on learners’ writing; suggesting strategies to improve coherence, lexical resource, and grammatical range; simulating IELTS writing exam tasks; analysing written outputs; and providing formative assessment and recommendations. ChatGPT also functioned as an interactive conversational partner for learners to practice strategy-based, self-regulated writing improvement.",
		"role_instructor (教师角色与介入方式)": "Teachers in the experimental group orchestrated CGWIP by designing instruction around ChatGPT outputs, interpreting and filtering AI-generated suggestions, modeling writing processes and feedback use, and supervising student–ChatGPT interactions to support digital literacy, autonomy, and self-confidence. They also used ChatGPT feedback as a basis for class discussion and additional teacher feedback. Control-group teachers fulfilled traditional roles of planning, modeling, giving feedback, and assessing writing without AI support. Across both groups, teachers remained central to instruction, classroom management, and assessment.",
		"setting (教学情境_学校类型_课程类型_线上线下)": "Online EFL writing-focused classes taught by Iranian EFL teachers to intermediate-level adult learners; each teacher typically had online classes of about 25–40 students weekly, but for the study selected four intermediate learners per teacher; sessions were delivered online (exact platform for instruction NR, teacher recruitment via Telegram).",
		"ethical_consideration (伦理审查与知情同意)": "All respondents were briefed about the study; ethical considerations followed the British Educational Research Association (2011) guidelines; participants were informed about the research objectives and procedures and ethical principles were applied throughout the study.",
		"llm_access_policy (LLM使用规范_允许与限制)": "Premium ChatGPT-3.5 accounts were provided only to experimental-group teachers and learners for use during the study; ChatGPT was used as an instructional aid for planning, feedback, and assessment, not to replace human teachers; learners used ChatGPT under teacher guidance during specified class time and for homework; control-group participants did not use ChatGPT as part of the intervention.",
		"llm_safety_guardrails (LLM安全与内容过滤设置)": "Use of ChatGPT was embedded within a teacher-supervised protocol (CGWIP) emphasizing structured, controlled integration rather than unrestricted use; ethical, social, and pedagogical concerns such as plagiarism, cheating, privacy, quality, validity, and reliability of ChatGPT outputs, and the risk of overreliance on AI were discussed conceptually; no specific technical content filters or automatic plagiarism detection tools were reported in this study.",
		"key_findings (主要研究发现_与LLM写作干预相关)": "ChatGPT-based writing instruction via CGWIP significantly enhanced EFL teachers’ self-efficacy compared to process writing without ChatGPT (post-test TSES t(10)=5.714, p<.001, r=.88), indicating a large positive impact on teachers’ sense of job accomplishment, skill development, social interaction with students, and coping with stress. Learners in the experimental group showed significantly higher writing post-test scores than control learners when controlling for pre-test writing, with ANCOVA results F(1,45)=44.055, p<.001, partial η²≈.50, indicating a large effect of CGWIP on writing performance. Delayed post-test results one week later (using new IELTS tasks) also showed significantly higher scores for the experimental group (t(46)=6.149, p<.001, mean difference≈1.40 bands), suggesting retention of improved writing skills over time. The study concludes that CGWIP helps teachers by reducing cognitive load in planning and assessment, supporting brainstorming, feedback, and exam simulation, and simultaneously improves learners’ L2 writing skills in a sustained way."
	},
	"Outcome": {
		"application_effectiveness_overview (应用效果总体评价与测量工具)": "The ChatGPT-based Writing Instruction Protocol (CGWIP) was effective in enhancing both teacher-level and learner-level outcomes. Teachers’ self-efficacy increased significantly more in the experimental group than in the control group, measured by the Teachers’ Self-Efficacy Scale (Schwarzer et al., 1999). Learners’ writing skills improved substantially and durably in the experimental group, as shown by higher post-test and delayed post-test scores on IELTS-style writing tasks rated with the IELTS 9-band descriptors, analysed via ANCOVA controlling pre-test writing scores and follow-up t-tests. The intervention thus demonstrated positive effects across psycho-emotional (teacher self-efficacy) and linguistic (writing performance) domains.",
		"writing_performance_measure (写作表现测量工具_量表或评分标准)": "IELTS writing tasks from the Complete IELTS series and additional latest IELTS exam writing tasks, scored with the official IELTS 9-band writing descriptors checklist assessing task achievement, cohesion and coherence, lexical resource, and grammatical range and accuracy; writing band scores from 1 to 9 were assigned, with ChatGPT and a human IELTS expert serving as raters.",
		"writing_performance_focus (写作表现关注维度_流利度_准确性_复杂度_体裁等)": "Overall L2 writing proficiency in the IELTS general writing genre, focusing on task achievement, cohesion and coherence (organization and flow), lexical resource (range and appropriateness of vocabulary), and grammatical range and accuracy.",
		"affective_aspect_measure (情感因素测量工具_问卷_量表等)": "Teachers’ Self-Efficacy Scale (TSES) by Schwarzer et al. (1999), a 10-item questionnaire on a 4-point Likert scale (1=not at all to 4=exactly true) administered to teachers before and after the 10-week intervention to assess self-efficacy-related affective and cognitive beliefs.",
		"affective_aspect_focus (情感因素维度_动机_态度_焦虑_自效感等)": "Teacher self-efficacy as an affective-cognitive construct, including job accomplishment, skill development, social interaction with students, and coping with stress as subcomponents; broader links to teacher well-being, motivation, and resilience are discussed conceptually but not directly measured beyond TSES.",
		"cognitive_aspect_measure (认知因素测量工具)": "No separate learner cognitive or metacognitive questionnaire was administered; cognitive aspects are inferred from changes in writing performance and teacher self-efficacy but not directly measured with dedicated cognitive instruments.",
		"cognitive_aspect_focus (认知因素维度_策略使用_元认知监控等)": "NR",
		"behavioral_aspect_measure (行为因素测量工具_日志_平台日志等)": "NR",
		"behavioral_aspect_focus (行为因素维度_使用频率_交互模式_坚持度等)": "NR",
		"other_outcomes_measure (其他结果测量工具)": "Oxford Placement Test (OPT; Allan, 2004) to confirm learners’ proficiency level and group homogeneity before intervention; normality and reliability diagnostics; inter-rater reliability indices between ChatGPT and human examiner ratings for writing; no additional distinct outcome instruments beyond those for proficiency, writing performance, and teacher self-efficacy.",
		"other_outcomes_focus (其他结果维度说明)": "Learners’ general English proficiency (intermediate level, B1) ensured via OPT; reliability and normality of measures; these served as supporting variables rather than primary outcomes.",
		"assessment_timepoints (评估时间点_前测_后测_延迟测等)": "Teachers: self-efficacy measured at pre-test (before the 10-week CGWIP or control instruction) and post-test (after the 10-week program). Learners: writing pre-test one week before intervention, writing post-test immediately after the 10-week program, and a delayed post-test (new IELTS tasks) one week after the program. OPT administered prior to intervention for proficiency and homogeneity checks.",
		"primary_outcome_variables (主要结果变量_因变量)": "Teachers’ self-efficacy total scores on TSES; learners’ IELTS writing band scores at post-test and 1-week delayed post-test (with pre-test writing scores as covariate in ANCOVA).",
		"independent_variables_and_factors (自变量与实验因素)": "Instructional condition (CGWIP with ChatGPT-based writing instruction vs process writing without ChatGPT) as the main between-group independent variable; pre-test writing scores used as covariate in ANCOVA; teacher group (experimental vs control) as grouping factor for self-efficacy analyses.",
		"followup_length_and_type (随访时长与类型)": "1-week delayed post-test of learners’ writing skills using a new set of latest IELTS writing exam tasks, administered after the completion of the 10-week intervention to assess retention.",
		"statistical_significance (统计显著性结果摘要)": "OPT scores indicated no significant difference between groups before intervention (t(46)=0.335, p>.05), confirming proficiency homogeneity. Teacher self-efficacy pre-test showed no significant group differences (t(10)=0.127, p>.05). Teacher self-efficacy post-test: experimental group significantly higher than control (t(10)=5.714, p<.001, mean difference=9.833, 95% CI [5.999, 13.667]). Learners’ writing post-test (with pre-test as covariate): ANCOVA showed a significant group effect, F(1,45)=44.055, p<.001, partial η²≈.495; pre-test covariate also significant, F(1,45)=83.407, p<.001, partial η²=.650. Delayed post-test writing: experimental group significantly outperformed control, t(46)=6.149, p<.001, mean difference=1.396 bands, 95% CI [0.939, 1.853].",
		"effect_size_summary (效应量摘要)": "Teacher self-efficacy post-test: effect size r=0.88, indicating a very large effect of CGWIP on teacher self-efficacy. Learners’ writing post-test: partial eta squared η²≈.495–.50, indicating a large effect of the intervention on writing skill after controlling pre-test performance. Pre-test covariate for writing: partial eta squared η²=.650, large effect. Delayed post-test t-test for writing (t(46)=6.149) implies a large standardized mean difference, though Cohen’s d was not explicitly reported.",
		"llm_misuse_or_negative_effects (LLM滥用或负向效应)": "The study does not report empirical incidents of ChatGPT misuse but discusses potential negative aspects conceptually, including the risks of overreliance on AI, lack of digital literacy, possible confusion in learners’ language learning process, demoralizing human learning by replacing human interactions, ethical issues such as plagiarism and cheating, and threats to teacher role and identity; the authors stress that ChatGPT cannot be considered a substitute for teachers and must be used under careful teacher supervision within a structured protocol.",
		"equity_and_subgroup_effects (公平性与亚组差异)": "No statistical subgroup analyses (e.g., by gender, age, or proficiency within intermediate level) were reported for either teachers or learners; the authors discuss at a conceptual level ethical and social issues such as protecting teachers’ and learners’ rights and privacy and the impact of AI on teacher–student relationships, but no empirical equity or subgroup effect data were provided.",
		"limitation (研究局限)": "The study is based on a relatively small sample (12 teachers, 48 learners) from one national context (Iran) and online EFL classes, which limits generalizability. Data are primarily quantitative; no qualitative data were collected to explore in-depth experiences. The CGWIP protocol was only tested in one sociocultural and instructional context. ChatGPT version 3.5 was used; results may differ with newer versions (e.g., GPT-4). Quality, validity, and reliability of ChatGPT outputs, as well as ethical, social, and pedagogical issues, require further examination. The study acknowledges that its claims rest on limited empirical evidence and calls for more cautious interpretation and further research.",
		"challenge (实施挑战与风险)": "Challenges include the need for teachers to develop sufficient digital literacy and confidence to use ChatGPT effectively; potential overreliance on AI for instructional decisions; possible confusion for learners if AI outputs are not properly mediated; ethical issues related to plagiarism, cheating, privacy, and critical evaluation of AI-generated text; ensuring that ChatGPT supports rather than undermines teacher roles, human relationships, and learner creativity; aligning AI use with curriculum goals and assessment standards; and addressing variability in quality, validity, and reliability of ChatGPT outputs.",
		"future_work (未来研究方向)": "Future research should provide in-depth analyses and further tests of CGWIP in different sociocultural contexts and educational settings, consider using ChatGPT-4 and other advanced AI tools, triangulate quantitative findings with qualitative data to capture the complexity of AI–human interactions, investigate the impact of ChatGPT on additional variables such as motivation, engagement, attitudes, and various aspects of well-being, and develop and evaluate standards and guidelines for ethical and effective AI integration in L2 writing instruction. Mixed-methods and longitudinal designs with larger and more diverse samples are recommended.",
		"implication (理论与教学实践启示)": "The study suggests that a structured ChatGPT-based writing instruction protocol can simultaneously enhance EFL teachers’ self-efficacy and learners’ writing skills and retention, highlighting the potential of AI tools to support positive psychology goals in language education. Practically, ChatGPT can serve as a versatile and flexible assistant for planning, feedback, assessment, and self-regulated learning, helping teachers save time and reduce stress while providing richer, more personalized support to learners. Teacher education and professional development programs should include training on integrating ChatGPT and similar AI tools ethically and effectively. At the policy level, standards and guidelines are needed to ensure quality, validity, reliability, and protection of teachers’ and learners’ rights and privacy when using AI in L2 education. Theoretically, the findings contribute to understanding how AI-driven protocols like CGWIP can foster teacher well-being and learner achievement within Positive Psychology and Social-Cognitive Theory frameworks."
	},
	"Study Quality and Reporting": {
		"funding_source (经费来源)": "The authors reported that they received no financial support for the research, authorship, and/or publication of this article.",
		"conflict_of_interest (利益冲突声明)": "NR",
		"risk_of_bias_randomization (偏倚风险_分配与随机化)": "Teachers were randomly assigned to experimental and control groups (6 per group), and learners were then assigned based on their teacher’s group membership, constituting clustered randomization at teacher/class level; this reduces but does not eliminate selection bias. The study reports baseline homogeneity for learners (OPT) and teachers (TSE pre-test), supporting balanced groups at baseline.",
		"risk_of_bias_blinding (偏倚风险_盲法)": "A double-blind experimental approach is described in which learners (participants) and researchers (experimenters) were unaware of assigned experimental conditions to minimize experiment-induced effects; however, teachers necessarily knew whether they were using ChatGPT or not, so blinding was incomplete. Raters of writing included ChatGPT and a human IELTS examiner; whether the human examiner was blinded to group assignment is not explicitly stated.",
		"attrition_and_missing_data (流失与缺失数据处理)": "The study reports final sample sizes of 12 teachers and 48 learners (24 per group) at all main timepoints; no attrition, dropout rates, or missing data handling procedures are described.",
		"reporting_transparency (报告透明度与可重复性)": "The article provides clear descriptions of participants, instruments (OPT, IELTS tasks, IELTS descriptors, TSES), the CGWIP and control procedures, statistical tests, and effect size estimates; reliability and assumption checks are reported. The exact ChatGPT prompts, full CGWIP materials, and raw data are not made publicly available, though the authors state that data are sharable on reasonable request. No explicit data-sharing repository is indicated.",
		"preregistration_or_protocol (预注册或研究方案)": "NR",
		"llm_version_reproducibility (LLM版本与可复现性)": "The study explicitly states that ChatGPT-3.5 was used and that premium accounts on the official ChatGPT platform were provided, specifying the general LLM version; however, no further details about model updates over time or session-level settings are given, and the authors note that future research could consider ChatGPT-4 and its features, implying that results may not fully generalize across versions.",
		"baseline_equivalence (基线等同性检验)": "Learners’ general proficiency homogeneity established via OPT with no significant group differences (t(46)=0.335, p>.05). Teachers’ self-efficacy pre-test scores also showed no significant differences between experimental and control groups (t(10)=0.127, p>.05). Writing pre-test scores were used as covariate in ANCOVA, and assumptions of homogeneity of regression slopes were checked, supporting baseline comparability.",
		"assumption_check_and_data_diagnostics (统计假设检验与数据诊断)": "Normality was checked and confirmed (ratios lower than ±1.96). For ANCOVA and t-tests, assumptions including homogeneity of variances (Levene’s test), linearity, and homogeneity of regression slopes were tested and reported as being met. Reliability analyses for OPT, writing scores, and TSES provided additional support for data quality.",
		"outlier_treatment_and_sensitivity_analysis (异常值处理与稳健性分析)": "NR",
		"data_preprocessing_and_transformation (数据预处理与转换)": "OPT scores were used to confirm intermediate proficiency and group homogeneity without further transformation. Writing scores from ChatGPT and the human examiner were analysed for inter-rater reliability (correlations and Cohen’s Kappa) and then used in subsequent statistical analyses; the exact method of combining rater scores is not specified. Teacher self-efficacy responses were summed or averaged according to TSES scoring conventions; no additional data transformations or sensitivity analyses were reported."
	}
}