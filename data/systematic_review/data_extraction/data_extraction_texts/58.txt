{
	"Basic Identification": {
		"author (作者)": "Hetian Yu; Qin Xie",
		"publication_year (发表年份)": "2025",
		"study_region (研究地区)": "Northwestern China (EFL high school context)",
		"journal_name (期刊名称)": "Language Teaching Research Quarterly",
		"study_type (研究类型_期刊论文_会议论文等)": "Peer-reviewed journal article; classroom-based counter-balanced experimental study",
		"doi_or_identifier (DOI或唯一标识)": "10.32038/ltrq.2025.47.07",
		"research_aims (研究目的与问题)": "To systematically compare written corrective feedback (WCF) generated by ChatGPT with teacher WCF in EFL high school argumentative writing, and to examine differences in students’ uptake of feedback and revision operations when responding to feedback from teachers versus ChatGPT.",
		"research_gap_or_novelty (研究创新性与知识空白)": "Addresses the lack of empirical research on generative AI (ChatGPT) feedback in L2 writing, especially in K-12 EFL contexts; goes beyond earlier automated writing evaluation studies by directly comparing ChatGPT and teacher feedback on the same essays, focusing on feedback quality, uptake, and revision behavior with a counter-balanced design and two writing tasks."
	},
	"Participant Information": {
		"educational_level (教育阶段)": "Secondary education; Grade 11 high school students",
		"language_proficiency (语言熟练度水平)": "Lower-intermediate (China’s Standards of English Language Ability CSE level 4)",
		"mother_tongue (母语)": "Chinese",
		"sex (性别)": "Total N=60; 31 females, 29 males",
		"age (年龄)": "16–17 years (mean age approximately 16.93)",
		"learning_context (学习语境_ESL_EFL_ELL等)": "EFL in China",
		"target_language (目标语言)": "English (L2)",
		"discipline (学科背景)": "General high school students enrolled in a general English course; non-tertiary, non-specialized majors",
		"prior_experience_llm (既有LLM使用经验)": "None of the student participants had prior experience with ChatGPT."
	},
	"Methodology": {
		"research_design (研究设计_实验_准实验_纵向等)": "2x2 Latin-square (counter-balanced) experimental design over four weeks in which two groups of EFL high school students wrote two argumentative essays, received feedback either from the class teacher or from ChatGPT in alternating order, and submitted revised drafts; all drafts were also annotated by three additional teachers and ChatGPT for comparative analysis of feedback.",
		"research_method (研究方法_定量_定性_混合)": "Primarily quantitative textual analysis with descriptive and inferential statistics (paired t-tests, correlations, percentages) on feedback quantity, uptake, and revision operations, supplemented by qualitative illustration of feedback examples.",
		"sampling_method (抽样方法)": "Convenience sampling of one high school in northwestern China; within that school, 60 Grade 11 students from one cohort were selected and then randomly split into Groups A and B (30 students each).",
		"sample_size_and_effect (样本量及效应量)": "Student participants: N=60 (Group A N=30, Group B N=30). Teachers: 4 high school English teachers (including the class teacher). Writing tasks: each student wrote two essays (Task A and Task B), yielding 120 original drafts that were each marked by four teachers and ChatGPT (total feedback records reported as 1200). Baseline equivalence: prior semester English writing scores did not differ significantly between groups (Group A M=71.63, SD=4.04; Group B M=71.77, SD=4.70; p=0.907). Paired t-tests comparing feedback counts across raters showed no significant difference between ChatGPT and the class teacher (e.g., paired difference mean approximately 0.14, t=0.84, p=0.402) but significant differences between ChatGPT and other teachers and among teachers themselves (all p<.001). Correlation analysis showed the highest correlation between ChatGPT and the class teacher (r=.483, p<.001); effect sizes for uptake and revision outcomes were not reported.",
		"theoretical_foundation (理论基础_理论框架)": "Grounded in L2 written corrective feedback and automated feedback literature, with interpretation of findings drawing on concepts such as learners’ trust in feedback sources, feedback focus (surface versus meaning level), and learners’ zone of proximal development (ZPD) in relation to feedback quantity and cognitive demands.",
		"data_collection_instrument (数据收集工具)": "Two argumentative writing tasks (Task A: 150–200 word essay on high school students’ Internet usage; Task B: 150–200 word essay on after-school tutorials); written feedback produced by the class teacher, three additional teachers, and ChatGPT in response to each draft; coding schemes for feedback categories (surface-level subcategories such as spelling, singular versus plural, verb tense, subject-verb agreement, articles, pronouns, collocation, punctuation, and meaning-level categories such as ideas and elaboration, organization, logic) and for revision operations (no correction, correction, addition, deletion, substitution, reorganization).",
		"data_collection_validity_reliability (工具信度与效度)": "To standardize ChatGPT output, the same prompt was used for all 120 student essays. The four teachers received instructions parallel to the ChatGPT prompt regarding feedback focus and form. Coding reliability was established through double coding: researchers and teachers jointly developed and refined the coding scheme, then coded feedback and revisions initially together and later independently; initial inter-coder agreement for revision operations was 89.3%, and after discussion final inter-coder agreement was 94.1% for feedback focus and 96.4% for revision operations. A research assistant was also trained to recode all written feedback, and discrepancies were resolved through discussion and re-examination of the data.",
		"data_analysis_method (数据分析方法)": "Counts of feedback points by type and level were computed for the class teacher, three additional teachers, and ChatGPT. Paired t-tests were used to compare numbers of feedback points across raters, and Pearson correlations were used to examine relationships among raters’ feedback distributions. Feedback uptake was calculated as the number and percentage of feedback items addressed in students’ revised drafts relative to total feedback items. Revision operations were coded and analyzed using frequency counts and percentages for each type of operation by feedback source and level, with illustrative examples to contextualize the quantitative findings.",
		"unit_of_analysis (分析单位)": "Individual feedback points and individual revision operations on each student essay; analyses aggregated at the level of essays, raters, feedback categories, and feedback sources (teacher vs ChatGPT).",
		"group_assignment_method (组别分配方式_随机_非随机等)": "Students were randomly split into Groups A and B (30 per group) after confirmation of comparable prior English writing scores; a 2x2 Latin-square design was then used so that each group received both teacher feedback and ChatGPT feedback across the two tasks in alternating order.",
		"power_analysis (功效分析与样本量论证)": "NR",
		"sampling_frame_and_representativeness (抽样框与样本代表性)": "Single public high school in northwestern China, Grade 11 classes; participants were lower-intermediate Chinese EFL learners in an exam-oriented educational context; authors explicitly note that the specific learner population and setting limit generalizability.",
		"scoring_procedure_and_rater_training (评分流程与评分者培训)": "Teachers were instructed to provide unfocused direct surface-level feedback (e.g., grammar, spelling, mechanics) and indirect unfocused meaning-level feedback (e.g., content, logic, coherence) consistent with Ferris’s taxonomy. ChatGPT was prompted with a standardized instruction to act as a high school English teacher and provide surface- and meaning-level feedback. For research coding, the researchers elaborated the feedback and revision coding scheme with teachers, practiced coding together, then coded data independently; a research assistant was trained to recode all written feedback to support reliability checks. No holistic writing scores or analytic rating scales for overall writing quality were reported."
	},
	"Intervention": {
		"duration (干预时长与频率)": "Four-week experiment; two writing tasks (Task A and Task B); for each task students wrote a draft, received feedback (teacher or ChatGPT), and submitted a revised version; overall one writing cycle per two weeks.",
		"llm_model_type (LLM模型类型_如ChatGPT_GPT4_Gemini等)": "ChatGPT (generative AI large language model; specific engine or version not specified for the experiment)",
		"llm_model_configuration (LLM模型配置与版本_API_网页_参数等)": "ChatGPT was used via a single standardized textual prompt instructing it to act as a high school English teacher and to provide surface-level (spelling, grammar, word use, mechanics, sentence structure) and meaning-level (organization, logic, ideas and elaboration, writing style) feedback; the same prompt was applied to all 120 essays. The article mentions GPT-4o in the background but does not specify which model version or interface was used in the experiment, nor does it report parameter settings.",
		"llm_integration_mode (LLM整合模式_直接使用_教师中介_系统嵌入)": "Teacher and researcher mediated: students did not log into or prompt ChatGPT themselves; instead, students submitted handwritten or typed drafts to the teacher, the drafts were digitized and input into ChatGPT by the researchers, ChatGPT generated WCF per the fixed prompt, and this feedback was then given to students for revision.",
		"prompting_strategy (提示策略_提示工程与使用方式)": "A single explicit prompt was used for all student essays, asking ChatGPT to act as a high school English teacher and provide both surface- and meaning-level feedback; surface-level feedback required selecting errors and giving correct forms, while meaning-level feedback required comments on ideas and elaboration, organization, logic, and style, along with revision suggestions; no additional prompt engineering techniques such as few-shot examples, chain-of-thought, or rubric-based prompting were reported.",
		"training_support_llm_literacy (LLM素养与提示培训)": "At the beginning of the study, students were introduced to ChatGPT and briefed on its functionality; the class teacher and the researcher demonstrated ChatGPT’s application in English writing in class. Students had no prior ChatGPT experience and did not receive further systematic training in prompt writing, critical evaluation of AI output, or AI literacy beyond this introductory demonstration.",
		"intervention_implementation (干预实施流程_步骤与任务)": "In Week 1, both groups were assigned Task A, a 150–200 word argumentative essay on high school students’ Internet usage, with one day allotted to write the first draft and submit it to the teacher. The drafts of Group A were marked by the class teacher, while Group B’s drafts were digitized and submitted to ChatGPT for feedback. In Week 2, both groups revised and resubmitted their essays based on the received feedback. In Week 3, both groups were assigned Task B, a 150–200 word argumentative essay on after-school tutorials, again with one day to write the first draft. This time, Group A’s drafts were submitted to ChatGPT for feedback, and Group B’s drafts were marked by the teacher. In Week 4, both groups revised Task B based on the corresponding feedback and submitted their final drafts. Throughout, for research purposes, all 240 drafts were also annotated by three additional teachers and ChatGPT, but only the class teacher’s feedback and ChatGPT feedback were actually given to students.",
		"experimental_group_intervention (实验组干预内容)": "ChatGPT feedback condition (in Latin-square design): for each task in which a group was assigned to ChatGPT, students wrote the argumentative essay draft, the draft was digitized and input into ChatGPT using the standardized prompt, ChatGPT generated comprehensive surface- and meaning-level feedback including explicit corrections, explanations, and revision suggestions, and students then revised their essays based on this generative AI feedback.",
		"control_group_intervention (对照组干预内容)": "Teacher feedback condition: for each task in which a group was assigned to teacher feedback, the class teacher provided written WCF on the student drafts, giving direct and comprehensive feedback on surface-level issues (such as grammar, vocabulary, spelling, verb tense, and punctuation) and indirect, unfocused comments on meaning-level issues (such as content, logic, coherence, and organization); students then revised their essays according to this teacher feedback. Due to the counter-balanced design, all students served under both conditions across the two tasks.",
		"writing_stage (写作阶段_如生成_修改_反馈_重写等)": "Initial drafting, then feedback, then revision; ChatGPT and teacher WCF were provided on first drafts, and students revised their essays for the second submission based on this feedback.",
		"writing_genre (写作体裁)": "Argumentative essays on school-related topics (Internet usage among high school students; after-school tutorials).",
		"writing_task_type (写作任务类型)": "Short argumentative topic writing (150–200 word essays) completed within one day per task as course writing assignments.",
		"role_llm (LLM角色_如生成文本_给反馈_评分_对话等)": "ChatGPT functioned as an automated written corrective feedback provider, detecting surface-level errors (spelling, grammar, word use, mechanics, sentence structure) and meaning-level issues (ideas and elaboration, organization, logic, writing style), providing corrections, explanations, and concrete suggestions for revision; it did not assign scores and did not directly converse with students in the study design.",
		"role_instructor (教师角色与介入方式)": "The class teacher served as both a feedback provider and classroom instructor: introducing ChatGPT and demonstrating its use, giving WCF in the teacher-feedback condition, and continuing regular teaching; three additional teachers provided WCF for research comparison but their feedback was not given to students. The teacher’s class-based feedback resembled his normal practice, informed by his knowledge of students’ proficiency and the local curriculum.",
		"setting (教学情境_学校类型_课程类型_线上线下)": "General English course in a high school in northwestern China, exam-oriented context; students had eight English classes per week, and the writing tasks were integrated into regular course work; feedback was generated partly offline (teacher marking on scripts) and partly via online generative AI (ChatGPT) and then delivered back to students.",
		"ethical_consideration (伦理审查与知情同意)": "All participants (teachers and students) were informed of study procedures and their right to withdraw; student and teacher participants signed consent forms; no further details of formal institutional ethics review procedures were reported.",
		"llm_access_policy (LLM使用规范_允许与限制)": "Students had no direct access to ChatGPT within the study and only received printed or otherwise mediated ChatGPT feedback generated through a fixed prompt by the researchers; use of ChatGPT was confined to producing WCF on the specified writing tasks within the experiment; no other AI tools were used.",
		"llm_safety_guardrails (LLM安全与内容过滤设置)": "NR",
		"key_findings (主要研究发现_与LLM写作干预相关)": "ChatGPT’s surface-level feedback was comprehensive and similar in quantity to that of the class teacher, though teachers as a group provided more surface-level feedback overall. ChatGPT provided substantially more meaning-level feedback on ideas, organization, and logic than the class teacher and some other teachers, often with detailed explanations and examples, and qualitatively outperformed the class teacher in providing content-level guidance. However, some ChatGPT feedback used advanced vocabulary and academic terms beyond students’ proficiency, which reduced comprehensibility and uptake. Teacher feedback tended to be more concise, directly embedded in student scripts, and better aligned with students’ language ability and local curriculum, although some meaning-level comments were vague and generic. Overall, teacher feedback received a slightly higher total uptake rate (78.10 percent) than ChatGPT feedback (70.41 percent), with both showing very high uptake for surface-level feedback and low uptake for meaning-level feedback. Students adopted a similar range of revision strategies (correction, addition, deletion, substitution, reorganization, or no correction) in response to both teacher and ChatGPT feedback. The results suggest that ChatGPT feedback can be used as a valuable supplementary source of WCF alongside teacher feedback to support EFL high school students’ writing, especially for meaning-level issues, provided that the amount and complexity of feedback are calibrated to learners’ zone of proximal development and curricular expectations."
	},
	"Outcome": {
		"application_effectiveness_overview (应用效果总体评价与测量工具)": "Effectiveness was assessed by comparing the quantity and distribution of feedback across raters, the proportion of feedback taken up by learners (uptake rates), and the types of revision operations applied to teacher versus ChatGPT feedback. Teacher feedback achieved a slightly higher overall uptake (78.10 percent) than ChatGPT feedback (70.41 percent), with both sources eliciting high uptake at the surface level and low uptake at the meaning level, indicating that ChatGPT can generate usable feedback comparable to teacher WCF in many respects but with some differences in how students act on it.",
		"writing_performance_measure (写作表现测量工具_量表或评分标准)": "NR",
		"writing_performance_focus (写作表现关注维度_流利度_准确性_复杂度_体裁等)": "Rather than overall writing scores, the study focused on accuracy and quality at two levels: surface-level linguistic accuracy (spelling, singular versus plural, verb tense, subject-verb agreement, articles, pronouns, collocation, punctuation) and meaning-level qualities (ideas and elaboration, organization, logic), operationalized via feedback categories, uptake, and revision operations.",
		"affective_aspect_measure (情感因素测量工具_问卷_量表等)": "NA",
		"affective_aspect_focus (情感因素维度_动机_态度_焦虑_自效感等)": "NA",
		"cognitive_aspect_measure (认知因素测量工具)": "NA",
		"cognitive_aspect_focus (认知因素维度_策略使用_元认知监控等)": "NA",
		"behavioral_aspect_measure (行为因素测量工具_日志_平台日志等)": "Textual coding of feedback uptake and revision operations in students’ revised essays, including counts of feedback items addressed and frequencies of revision strategies such as correction, no correction, addition, deletion, substitution, and reorganization.",
		"behavioral_aspect_focus (行为因素维度_使用频率_交互模式_坚持度等)": "Learners’ behavioral responses to teacher and ChatGPT feedback, including how often they implemented feedback from each source, the extent to which they revised surface versus meaning-level aspects of their writing, and the distribution of revision operations applied to different feedback types.",
		"other_outcomes_measure (其他结果测量工具)": "Coding of feedback focus and distribution (surface versus meaning level, subcategories within each level) for the class teacher, three additional teachers, and ChatGPT; paired t-tests and correlation analyses on feedback counts across raters.",
		"other_outcomes_focus (其他结果维度说明)": "Features and distribution of teacher versus ChatGPT feedback (quantity, coverage, balance between surface and meaning levels); similarity and differences between ChatGPT and the class teacher and among human teachers; alignment of feedback with students’ proficiency and curriculum demands.",
		"assessment_timepoints (评估时间点_前测_后测_延迟测等)": "For each of the two writing tasks, an initial draft (pre-feedback) and a revised draft (post-feedback) were collected; there was no delayed follow-up assessment beyond the two draft versions for each task.",
		"primary_outcome_variables (主要结果变量_因变量)": "Number and type of feedback points generated by ChatGPT and teachers; feedback uptake rates (percentage of feedback items acted upon) by level and source; frequencies and percentages of revision operations (correction, no correction, addition, deletion, substitution, reorganization) in response to teacher versus ChatGPT feedback at surface and meaning levels.",
		"independent_variables_and_factors (自变量与实验因素)": "Feedback source (class teacher WCF versus ChatGPT WCF) as the main factor; writing task (Task A versus Task B) and rater (class teacher, three other teachers, ChatGPT) considered in comparisons of feedback features; group assignment (Group A versus Group B) counter-balanced across tasks to control for order effects of teacher versus ChatGPT feedback.",
		"followup_length_and_type (随访时长与类型)": "NA",
		"statistical_significance (统计显著性结果摘要)": "Paired t-tests on feedback counts across raters showed that the differences in total feedback points between ChatGPT and the class teacher were not statistically significant (paired differences around 0.14, t approximately 0.84, p=0.402), whereas differences between ChatGPT and the other three teachers, and among human teachers, were significant (all p<.001). Correlation analysis revealed a significant positive correlation between ChatGPT and the class teacher’s feedback counts (r=.483, p<.001), higher than correlations among the human teachers (maximum r=.404). No inferential statistics were reported for differences in feedback uptake rates or revision operations between feedback sources.",
		"effect_size_summary (效应量摘要)": "Effect sizes such as Cohen’s d or partial eta squared for group comparisons of feedback uptake and revision operations were not reported.",
		"llm_misuse_or_negative_effects (LLM滥用或负向效应)": "The study did not report misuse of ChatGPT by learners because students did not access the system directly, but it did identify several limitations and potential negative aspects of ChatGPT feedback: some feedback contained advanced vocabulary and academic terminology (for example, words like ubiquitous and terms like thesis statement) beyond students’ proficiency, which made feedback harder to understand and less likely to be taken up; ChatGPT also produced long, dense meaning-level comments that could overwhelm low-proficiency learners; and because students lacked prior experience with AI, they initially placed less trust in ChatGPT feedback than in teacher feedback, sometimes ignoring AI suggestions.",
		"equity_and_subgroup_effects (公平性与亚组差异)": "All student participants were lower-intermediate Chinese EFL high school learners in one school; no subgroup analyses by gender, proficiency bands, or other demographic characteristics were reported, and equity-related outcomes were not examined explicitly.",
		"limitation (研究局限)": "The study involved only 60 low-proficiency Grade 11 EFL students from a single high school in northwestern China, which limits generalizability to other age groups, proficiency levels, and contexts; the experiment lasted only four weeks and involved only two writing tasks, so longitudinal and cumulative effects of ChatGPT feedback were not examined; only four teachers participated and their feedback styles varied considerably, sometimes more than the difference between ChatGPT and an individual teacher, which constrains comparison between generative AI and teachers as broader categories; this was students’ first experience with ChatGPT, so their trust and familiarity with AI feedback may not reflect long-term usage; and the study did not measure changes in overall writing quality or long-term learning outcomes, focusing instead on feedback features, uptake, and revision behavior.",
		"challenge (实施挑战与风险)": "Implementation challenges include aligning ChatGPT feedback with students’ language ability and the local exam-oriented curriculum, avoiding overwhelming learners with overly long or dense AI-generated comments, balancing surface and meaning-level feedback so that learners’ zone of proximal development is respected, building learners’ trust in AI feedback when they have no prior experience with such tools, and managing the potentially large quantity of feedback that ChatGPT can produce so that it remains pedagogically manageable.",
		"future_work (未来研究方向)": "Future research is recommended with learner populations of different ages, cognitive maturity, and proficiency levels to see whether the observed patterns of feedback uptake and revision generalize; with longer-term and more tasks to examine longitudinal and cumulative effects of ChatGPT feedback on writing development; with more teachers to better characterize differences between teacher groups and generative AI; and with refined prompts and locally contextualized examples so that ChatGPT feedback better matches local curricula and learners’ proficiency, possibly staged over multiple drafts to optimize the sequencing of meaning-level and surface-level feedback.",
		"implication (理论与教学实践启示)": "Findings suggest that ChatGPT can be used as a supplementary WCF source alongside teachers in EFL writing instruction, particularly for providing rich meaning-level feedback on content, organization, and logic that teachers may not have time to supply in large classes; teacher feedback remains crucial because it tends to be better aligned with learners’ proficiency, curriculum goals, and trust relationships and is often easier for students to understand and act upon; effective integration of generative AI into L2 writing pedagogy requires designing prompts and feedback workflows that limit the amount and complexity of AI feedback, sequence meaning-level and surface-level feedback in line with writing pedagogy and learners’ ZPD, and support learners in developing the skills and confidence needed to interpret and use AI-generated feedback productively."
	},
	"Study Quality and Reporting": {
		"funding_source (经费来源)": "Partially supported by a research grant from the Research Grants Council of the Hong Kong SAR Government, China (Project 18600121) awarded to the second author.",
		"conflict_of_interest (利益冲突声明)": "Authors state that there are no conflicting interests.",
		"risk_of_bias_randomization (偏倚风险_分配与随机化)": "Students were randomly split into two groups (A and B) after showing no significant difference in prior English writing scores, but detailed procedures for randomization (for example, random number generation or stratification) were not described; all students received both teacher and ChatGPT feedback across different tasks, which helped control for order effects through the Latin-square design.",
		"risk_of_bias_blinding (偏倚风险_盲法)": "No blinding was reported; students knew whether feedback came from their teacher or ChatGPT, and coders of feedback and revision operations likely knew the feedback source; ChatGPT obviously operated without knowledge of teacher identities, but there was no blinding of human raters to experimental conditions.",
		"attrition_and_missing_data (流失与缺失数据处理)": "NR; the article reports N=60 students throughout and does not discuss attrition or handling of missing data.",
		"reporting_transparency (报告透明度与可重复性)": "The study reports participant demographics, group assignment, tasks, counter-balanced design, the exact ChatGPT prompt used, feedback coding categories, revision coding scheme, reliability statistics, and key statistical analyses (paired t-tests, correlations, uptake percentages) with tables; however, it does not provide raw data, full prompts beyond the main one, or codebooks in appendices, and no pre-registration is mentioned.",
		"preregistration_or_protocol (预注册或研究方案)": "NR",
		"llm_version_reproducibility (LLM版本与可复现性)": "The article specifies that ChatGPT was used with a single standardized prompt and notes GPT-4o as the latest iteration in the background, but it does not explicitly state which ChatGPT model version, interface, or access date was used in the study, nor does it document parameter settings; this limits strict reproducibility of the AI behavior over time as the underlying model evolves.",
		"baseline_equivalence (基线等同性检验)": "Baseline equivalence between Group A and Group B was examined using prior English examination writing scores, which showed no significant difference (Group A M=71.63, SD=4.04; Group B M=71.77, SD=4.70; p=0.907); this supports comparability of groups before the counter-balanced intervention.",
		"assumption_check_and_data_diagnostics (统计假设检验与数据诊断)": "The study used paired t-tests and Pearson correlations but did not report specific assumption checks such as normality tests, homogeneity of variance tests, or diagnostics for outliers associated with these analyses.",
		"outlier_treatment_and_sensitivity_analysis (异常值处理与稳健性分析)": "NR",
		"data_preprocessing_and_transformation (数据预处理与转换)": "Student essays were collected as written drafts, digitized for input into ChatGPT, and then coded for feedback categories and revision operations according to predefined schemes; counts of feedback and revisions were aggregated across tasks and raters for analysis; no additional data transformations (such as standardization or scaling) were reported."
	}
}