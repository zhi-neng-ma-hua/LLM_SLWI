{
	"Basic Identification": {
		"author (作者)": "Musarat Yasmin, Walees Fatima, Isra Irshad",
		"publication_year (发表年份)": "2025",
		"study_region (研究地区)": "Pakistan (urban district of Punjab, Pakistan)",
		"journal_name (期刊名称)": "Sustainable Futures",
		"study_type (研究类型_期刊论文_会议论文等)": "Journal article; quasi-experimental one-group pre-test/post-test study",
		"doi_or_identifier (DOI或唯一标识)": "https://doi.org/10.1016/j.sftr.2025.100809",
		"research_aims (研究目的与问题)": "To assess the effectiveness of ChatGPT in improving the argumentative writing skills of Pakistani Secondary School Certificate (SSC) students in an EFL environment; specifically, to examine the impact of ChatGPT on key components of argumentative writing (claim, reason, evidence, counterclaim) through pre-test and post-test, and to identify the specific types of errors committed by learners in Pakistani SSC context before and after a ChatGPT-based intervention.",
		"research_gap_or_novelty (研究创新性与知识空白)": "The study addresses the limited research on the efficacy of AI tools such as ChatGPT for enhancing English writing skills among EFL learners in secondary school contexts in Pakistan; it focuses on argumentative writing at SSC level, combines Toulmin’s model of argumentative components with Ellis’s error analysis framework, and empirically examines how ChatGPT use influences both the quality of argument structure and the frequency and types of writing errors in a low-resource EFL setting."
	},
	"Participant Information": {
		"educational_level (教育阶段)": "Secondary School Certificate (SSC) students in secondary education",
		"language_proficiency (语言熟练度水平)": "NR (students are described as mainstream EFL learners in SSC context; no specific proficiency level or standardized test scores reported)",
		"mother_tongue (母语)": "NR",
		"sex (性别)": "Gender-balanced sample; 30 SSC students equally drawn from a boys’ and a girls’ public-sector school (15 boys and 15 girls)",
		"age (年龄)": "NR",
		"learning_context (学习语境_ESL_EFL_ELL等)": "EFL context in Pakistan (English as a Foreign Language classroom in public-sector secondary schools)",
		"target_language (目标语言)": "English (L2)",
		"discipline (学科背景)": "General secondary education English subject (SSC-level English in public-sector schools, national curriculum, middle-socioeconomic background students)",
		"prior_experience_llm (既有LLM使用经验)": "NR"
	},
	"Methodology": {
		"research_design (研究设计_实验_准实验_纵向等)": "Quasi-experimental one-group pre-test/post-test design (within-subject repeated measures) over approximately three months of ChatGPT use; no parallel control group due to administrative constraints.",
		"research_method (研究方法_定量_定性_混合)": "Quantitative quasi-experimental study with pre- and post-intervention argumentative writing tests and statistical analysis of changes; supplemented by qualitative exemplars of improved claims, reasons, evidence, and counterclaims.",
		"sampling_method (抽样方法)": "Purposive sampling of 30 SSC-level students equally drawn from a boys’ and a girls’ public-sector school in an urban district of Punjab, Pakistan; stratification by prior proficiency was not feasible due to institutional assessment limitations.",
		"sample_size_and_effect (样本量及效应量)": "Total N=30 SSC students; all participants received the ChatGPT-based intervention and completed both pre-test and post-test. Error counts decreased from pre-test mean 10.03 (SD=2.74) to post-test mean 4.73 (SD=1.80), mean difference 5.30 errors, paired-samples t(29)=9.44, p<.001, 95% CI [4.15, 6.45], with a large effect size Cohen’s d=1.72; improvements in key components of argumentative writing (claim, reason, evidence, counterclaim) are described descriptively as showing substantial shifts from low to average and high achievers, with reported improvements of approximately 15–20%, but inferential statistics for these component scores were not reported.",
		"theoretical_foundation (理论基础_理论框架)": "Vygotsky’s sociocultural theory, particularly the Zone of Proximal Development (ZPD) and the role of more expert entities, is used to conceptualize ChatGPT as a digital scaffold that provides immediate feedback, models structured argumentation, and supports learner autonomy in writing; the study is also situated within constructivist language-learning methodologies that emphasize active student participation, reflective practice, and iterative refinement; Toulmin’s model of argument structure and Ellis’s error analysis framework (building on Pit Corder’s work) provide analytic lenses for argumentative components and learner errors.",
		"data_collection_instrument (数据收集工具)": "Pre-test and post-test argumentative essay writing tasks for SSC students; analysis of key components of argumentative essays (claim, reason, evidence, counterclaim) using Toulmin’s model; error analysis of student essays using Ellis’s error analysis framework (identification, description, explanation, evaluation of errors such as omissions, misinformation, grammatical flaws, inappropriate word usage, literal translations, punctuation errors, disordered sentence structure, inaccurate use of numbers, abbreviations, prepositional misuse, differentiation, spelling mistakes, spacing issues, and improper use of articles).",
		"data_collection_validity_reliability (工具信度与效度)": "The study uses established frameworks (Toulmin’s model and Ellis’s error analysis) and categorizes student performance into high, average, and low achievers aligned with standard educational benchmarks (high 80%+, average 51–79%, low below 50%), but specific reliability indices for scoring (such as inter-rater reliability) or explicit validity evidence for the pre/post writing tasks are not reported.",
		"data_analysis_method (数据分析方法)": "Descriptive analysis of student performance in argumentative components (claim, reason, evidence, counterclaim) with distributions of high, average, and low achievers before and after the intervention; descriptive and graphical analysis of error frequencies and types pre- and post-intervention; paired-samples t-test to assess statistical significance of the difference in total error counts between pre-test and post-test; calculation of 95% confidence intervals and effect size (Cohen’s d); statistical analyses conducted using SPSS v.26.",
		"unit_of_analysis (分析单位)": "Individual student argumentative essay (pre-test and post-test) and associated error counts and ratings of argumentative components.",
		"group_assignment_method (组别分配方式_随机_非随机等)": "NA (one-group design; all 30 SSC students received the ChatGPT intervention; no random assignment to separate experimental and control groups).",
		"power_analysis (功效分析与样本量论证)": "NR",
		"sampling_frame_and_representativeness (抽样框与样本代表性)": "The sampling frame comprised SSC-level EFL students from two urban public-sector schools in Punjab, Pakistan, serving middle-socioeconomic background students and following the national curriculum; the authors note that, despite the limited sample size, its composition reflects typical mainstream SSC EFL learners in many urban public schools in Pakistan, while acknowledging broader regional, linguistic, and socioeconomic differences and limited generalizability.",
		"scoring_procedure_and_rater_training (评分流程与评分者培训)": "Student essays were analyzed for key components of Toulmin’s argumentative model and for error types following Ellis’s framework; students were categorized into high, average, and low achievers based on percentage scores using predefined benchmarks; the number of raters, details of rater training, and inter-rater reliability statistics are not reported."
	},
	"Intervention": {
		"duration (干预时长与频率)": "Approximately three months of ChatGPT-supported writing practice between pre-test and post-test; an initial session introduced argumentative essays and administered the pre-test, followed by a 45-minute lecture on using ChatGPT for writing assignments, and continued use of ChatGPT over a three-month period before the post-test assessment.",
		"llm_model_type (LLM模型类型_如ChatGPT_GPT4_Gemini等)": "ChatGPT (GPT-3.5, OpenAI large language model)",
		"llm_model_configuration (LLM模型配置与版本_API_网页_参数等)": "OpenAI’s ChatGPT (GPT-3.5) was employed by the students to generate and revise argumentative paragraphs using text prompts such as generating counterclaims or improving thesis statements; the specific access mode (web interface vs API), access dates, and parameter settings (e.g., temperature) were not reported.",
		"llm_integration_mode (LLM整合模式_直接使用_教师中介_系统嵌入)": "Students directly interacted with ChatGPT during their writing assignments; after a 45-minute instructional lecture on how to use ChatGPT for composition, they used ChatGPT outside or alongside classroom instruction over three months to generate, refine, and revise argumentative paragraphs, with ChatGPT functioning as an external GenAI writing tool rather than being embedded in a dedicated learning management system.",
		"prompting_strategy (提示策略_提示工程与使用方式)": "Task-specific prompts focused on generating and revising argumentative paragraphs; examples of prompts include asking ChatGPT to generate counterclaims for given arguments and to suggest improvements for thesis statements; prompts emphasized constructing claims, counterclaims, and refining argument structure, but no systematic prompt engineering approach (such as few-shot prompting or rubric-based prompting) beyond these functional examples was described.",
		"training_support_llm_literacy (LLM素养与提示培训)": "Students received a short introduction to argumentative essays in the first session, followed by a 45-minute lecture in which participants were instructed to use ChatGPT for their writing assignments; they were also taught about the function of artificial intelligence in composition and informed about ethical and institutional guidelines for AI use, but a detailed, structured LLM literacy curriculum (e.g., training in critical evaluation of AI output or advanced prompting strategies) was not reported.",
		"intervention_implementation (干预实施流程_步骤与任务)": "In the first session, SSC students received a brief introduction to argumentative essays and took a pre-test argumentative writing task. Subsequently, a 45-minute lecture was delivered, instructing participants on how to utilize ChatGPT for their writing assignments. Over the following three months, students regularly used ChatGPT (GPT-3.5) to generate, revise, and refine argumentative paragraphs as part of their writing practice, using prompts focused on claims, reasons, evidence, and counterclaims. Throughout this period, regular classroom instruction and content remained constant, with ChatGPT as the primary innovation in the learning environment. At the end of the three-month intervention, a post-test argumentative essay was administered under similar conditions to the pre-test. Pre- and post-test essays were then analyzed using Toulmin’s model to rate key argumentative components and Ellis’s error analysis framework to categorize and count errors, followed by descriptive and inferential statistical analysis.",
		"experimental_group_intervention (实验组干预内容)": "All 30 SSC students received the intervention consisting of explicit instruction on argumentative writing and three months of guided use of ChatGPT (GPT-3.5) as a writing assistant to generate, revise, and refine argumentative paragraphs, with emphasis on improving claims, reasons, evidence, counterclaims, and reducing linguistic and structural errors through ChatGPT’s feedback and suggestions.",
		"control_group_intervention (对照组干预内容)": "NA (no separate control group; the design used a single group assessed before and after ChatGPT-based instruction).",
		"writing_stage (写作阶段_如生成_修改_反馈_重写等)": "Generation and revision of argumentative paragraphs, including drafting claims, providing reasons and evidence, constructing counterclaims, and editing and refining essays based on ChatGPT feedback.",
		"writing_genre (写作体裁)": "Argumentative essays written by SSC-level EFL students.",
		"writing_task_type (写作任务类型)": "SSC-level argumentative essay tasks used as pre-test and post-test, focusing on constructing claims, reasons, evidence, and counterclaims; specific essay topics are not reported.",
		"role_llm (LLM角色_如生成文本_给反馈_评分_对话等)": "ChatGPT served as a generative writing assistant and feedback provider, helping students generate argumentative content (claims and counterclaims), improve thesis statements and reasoning, and revise linguistic and structural features (grammar, punctuation, prepositions, ordering, articles, spelling); it functioned as a learning scaffold in Vygotsky’s sense, offering immediate, structured suggestions rather than being used solely for scoring.",
		"role_instructor (教师角色与介入方式)": "The teacher introduced argumentative essays, administered the pre-test and post-test, delivered the 45-minute lecture on the use of ChatGPT for writing assignments, guided students in integrating AI assistance into their compositions, and ensured that instruction on AI use followed institutional and ethical guidelines; the teacher maintained the same instructional content and environment aside from the introduction of ChatGPT and did not serve as a contrasting treatment as there was no separate control class.",
		"setting (教学情境_学校类型_课程类型_线上线下)": "Two public-sector secondary schools (one boys’ and one girls’ school) in an urban district of Punjab, Pakistan, following the national SSC curriculum for English as a Foreign Language; the mode of instruction is classroom-based secondary education, with ChatGPT use for writing tasks; the exact balance of in-class versus out-of-class technology use is not specified.",
		"ethical_consideration (伦理审查与知情同意)": "Informed consent was obtained from all students and school authorities prior to the study; no personally identifiable information was collected; students received instruction on the function of artificial intelligence in composition in accordance with institutional and ethical guidelines; the study did not involve sensitive data and complied with local AI-use policies and research ethics guidelines.",
		"llm_access_policy (LLM使用规范_允许与限制)": "Students were instructed on appropriate use of artificial intelligence in writing in line with institutional and local AI-use policies; the study emphasizes that AI served as a support tool rather than a replacement for learning and notes concerns in the literature about over-reliance on AI and the need for critical thinking; explicit details of access restrictions, rate limits, or monitoring policies are not provided.",
		"llm_safety_guardrails (LLM安全与内容过滤设置)": "NR (no specific technical safety mechanisms, content filters, or guardrail settings for ChatGPT are described beyond general ethical and policy compliance).",
		"key_findings (主要研究发现_与LLM写作干预相关)": "The integration of ChatGPT led to substantial improvements in SSC students’ argumentative writing. Analysis of key components showed marked gains in claim, reason, evidence, and counterclaim quality, with large shifts from low to average and high achievers in each component after the intervention; for example, in claim construction, pre-test performance was dominated by average and low scores, while post-test results showed 43.30% high achievers and no low scorers. Evidence use improved from almost all students scoring low (96.60%) with no high achievers in the pre-test to 13.40% high achievers and a large increase in moderate performers in the post-test. Counterclaim handling, though still the weakest area, showed a reduction in low scorers from 93.30% to 76.60% and emergence of both moderate and high scorers. Error analysis revealed a substantial reduction in overall error frequency: mean total errors fell from 10.03 to 4.73 per student, with a highly significant paired t-test t(29)=9.44, p<.001 and a very large effect size Cohen’s d=1.72; the proportion of students with low error rates rose from 7% to 43%, and high-error performers dropped from 30% to 20%. Specific error types such as grammar, punctuation, preposition use, word order (disordering), articles, and spelling decreased markedly (spelling errors dropped from 49 to 3 occurrences), though some categories (literal translation, word usage, abbreviation, misinformation) showed little change, indicating that ChatGPT support strongly improved mechanical and structural aspects but less so content accuracy and culture-specific language use."
	},
	"Outcome": {
		"application_effectiveness_overview (应用效果总体评价与测量工具)": "Using Toulmin’s model to assess key components of argumentative writing (claim, reason, evidence, counterclaim) and Ellis’s error analysis framework to categorize and count errors, combined with descriptive statistics and paired-samples t-tests, the study concludes that ChatGPT is highly effective in enhancing SSC students’ argumentative writing skills in an EFL context, leading to improved argument structure and a large, statistically significant reduction in overall error frequency.",
		"writing_performance_measure (写作表现测量工具_量表或评分标准)": "Argumentative essay pre-test and post-test scored using key components of Toulmin’s model (claim, reason, evidence, counterclaim) and categorized into performance levels (high achievers 80%+, average 51–79%, low achievers below 50%) for each component.",
		"writing_performance_focus (写作表现关注维度_流利度_准确性_复杂度_体裁等)": "Argumentative writing quality, including clarity and strength of claim, quality and depth of reasons, appropriate and credible use of evidence, and ability to acknowledge and refute counterclaims; overall coherence and organization of argumentative essays are discussed through examples, though not separately quantified.",
		"affective_aspect_measure (情感因素测量工具_问卷_量表等)": "NA (no affective measures such as motivation, attitudes, or anxiety scales were administered).",
		"affective_aspect_focus (情感因素维度_动机_态度_焦虑_自效感等)": "NA",
		"cognitive_aspect_measure (认知因素测量工具)": "NA (no separate cognitive instruments such as strategy or metacognitive awareness scales were used beyond what is reflected in writing performance and error patterns).",
		"cognitive_aspect_focus (认知因素维度_策略使用_元认知监控等)": "NA",
		"behavioral_aspect_measure (行为因素测量工具_日志_平台日志等)": "NA (no behavioral logs or usage-tracking tools were reported; error frequency and distribution were used as outcome variables rather than behavioral engagement measures).",
		"behavioral_aspect_focus (行为因素维度_使用频率_交互模式_坚持度等)": "NA",
		"other_outcomes_measure (其他结果测量工具)": "Error analysis based on Ellis’s framework, quantifying various error types including omissions, misinformation, grammatical errors, inappropriate word usage, literal translations, punctuation errors, disordered sentence structure, inaccurate use of numbers, abbreviations, prepositional misuse, differentiation errors, spelling mistakes, spacing issues, and improper use of articles; classification of overall error frequency into low, average, and high categories; paired-samples t-test of total error counts with confidence intervals and effect size.",
		"other_outcomes_focus (其他结果维度说明)": "Changes in overall error frequency and distribution (increases in low-error writers and decreases in high-error writers); specific reductions in error types such as grammar, punctuation, prepositions, word order, articles, and spelling; persistence of certain error types (literal translation, word usage, abbreviation, misinformation) where ChatGPT had limited impact; the study interprets these patterns as indicating that ChatGPT supports mechanical and structural accuracy effectively but does not fully address content accuracy or culturally embedded language issues.",
		"assessment_timepoints (评估时间点_前测_后测_延迟测等)": "One pre-test administered before ChatGPT introduction and a post-test administered after three months of ChatGPT-assisted writing practice; no delayed follow-up test beyond the immediate post-test.",
		"primary_outcome_variables (主要结果变量_因变量)": "Quality of argumentative writing as operationalized by performance on Toulmin key components (claim, reason, evidence, counterclaim) at pre-test and post-test; total number of writing errors per student; frequencies of specific error types as defined in Ellis’s framework.",
		"independent_variables_and_factors (自变量与实验因素)": "Time (pre-test vs post-test) within the same group of SSC students, with the introduction and sustained use of ChatGPT (GPT-3.5) as the primary intervention factor; no between-group factors (such as a control group) were included in the design.",
		"followup_length_and_type (随访时长与类型)": "No follow-up beyond the immediate post-test after three months of ChatGPT use; the study does not track longer-term retention or delayed effects.",
		"statistical_significance (统计显著性结果摘要)": "Paired-samples t-test showed a statistically highly significant reduction in total writing errors from pre-test (M=10.03, SD=2.74) to post-test (M=4.73, SD=1.80), with a mean difference of 5.30 errors, t(29)=9.44, p<.001, 95% confidence interval [4.15, 6.45]; descriptive analyses indicated notable improvements in the distribution of high, average, and low achievers on Toulmin components (e.g., claims, reasons, evidence, counterclaims), but inferential statistics for these component scores were not reported.",
		"effect_size_summary (效应量摘要)": "A very large effect size was reported for the reduction in total error counts following ChatGPT intervention, with Cohen’s d=1.72 based on the paired pre-test and post-test comparison; effect sizes for improvements in individual argumentative components (claim, reason, evidence, counterclaim) were not provided.",
		"llm_misuse_or_negative_effects (LLM滥用或负向效应)": "The study notes that while ChatGPT substantially reduced mechanical and structural errors and improved argumentative components, some error types (literal translation, word usage, abbreviation, misinformation) remained unchanged, suggesting that AI tools may not adequately handle culture-specific language use, deeper content comprehension, or factual accuracy; it emphasizes that ChatGPT may not foster independent critical thinking on its own and echoes prior research warning that over-reliance on AI could hinder the development of learners’ critical thinking skills; the authors call for a hybrid instructional model that combines AI feedback with teacher-led development of argumentation and critical thinking and highlight the need for explicit instruction in fact-checking and contextual understanding.",
		"equity_and_subgroup_effects (公平性与亚组差异)": "The authors describe the sample as reflecting middle-socioeconomic background students in urban public-sector SSC schools in Pakistan and acknowledge broader regional, linguistic, and socioeconomic differences, suggesting that future research with more diverse samples is needed to improve generalizability; however, no statistical subgroup analyses by gender, socioeconomic status, prior proficiency, or other equity-related characteristics are reported, and no differential effects by subgroup are examined.",
		"limitation (研究局限)": "Limitations include the quasi-experimental one-group pre-test/post-test design without randomization or a parallel control group, which restricts strong causal attribution despite maintaining the same teacher and instructional content; a small sample size of 30 students from only two urban public-sector schools, limiting generalizability to other regions, school types, or socioeconomic contexts; inability to stratify participants by prior proficiency due to institutional assessment constraints; reliance on quantitative pre/post comparisons without qualitative data such as interviews or think-aloud protocols; and limited impact of ChatGPT on certain error types and content accuracy, indicating that AI alone cannot address all aspects of writing development.",
		"challenge (实施挑战与风险)": "Implementation challenges and risks discussed or implied include administrative constraints that prevented the use of parallel classes and randomized controlled designs; potential over-dependence on AI tools which may undermine the development of independent critical thinking and argumentation skills if not combined with teacher guidance; limited effectiveness of ChatGPT for culture-specific language use, literal translation issues, and factual accuracy, highlighting the need for supplementary instruction in critical thinking and fact-checking; and broader contextual challenges in Pakistani EFL education such as traditional teacher-centered pedagogy and resource limitations which the authors frame as part of the rationale for adopting AI tools but which may also complicate their integration.",
		"future_work (未来研究方向)": "The authors recommend future studies employing randomized control groups and parallel classes to strengthen causal claims; using larger and more diverse samples across different regions, school types, and socioeconomic backgrounds to enhance generalizability; investigating hybrid instructional models that combine AI-generated feedback with explicit teacher-led instruction in argumentation and critical thinking; examining how AI tools can be better leveraged to address content accuracy, critical thinking, and culture-specific usage rather than primarily mechanical accuracy; and extending research on AI-assisted language learning to different educational levels and language learning contexts.",
		"implication (理论与教学实践启示)": "The study provides theoretical implications by integrating Toulmin’s model and Ellis’s error analysis within a sociocultural and constructivist framework, illustrating how ChatGPT can act as a digital scaffold to support EFL learners’ development of argumentative writing; it suggests that AI tools like ChatGPT can complement traditional teaching by offering interactive, student-centered learning experiences, enhancing structural aspects of writing, and reducing mechanical errors; for pedagogy, it encourages teachers in Pakistan and comparable contexts to incorporate AI tools into English curricula to move beyond rote memorization towards more analytical, argument-focused writing instruction, using AI to support material preparation, feedback, and student engagement; it calls for teacher training programs to include modules on effective technology integration and AI literacy so that educators can guide students to use ChatGPT productively while cultivating critical thinking and avoiding over-reliance on AI."
	},
	"Study Quality and Reporting": {
		"funding_source (经费来源)": "NR (authorship contribution statements note that one author was responsible for funding acquisition, but specific funding agencies or grant numbers are not reported).",
		"conflict_of_interest (利益冲突声明)": "The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.",
		"risk_of_bias_randomization (偏倚风险_分配与随机化)": "No randomization or control group was used; the study employed a one-group pre-test/post-test quasi-experimental design, and internal validity was addressed by keeping the same instructional content, teacher, and classroom environment, with the introduction of ChatGPT as the only systematic change; however, the lack of randomization and control group leaves the study vulnerable to threats such as maturation, history, and testing effects.",
		"risk_of_bias_blinding (偏倚风险_盲法)": "Blinding procedures are not reported; there is no indication that teachers, students, or potential raters of the essays were blinded to the intervention phase (pre vs post) or the use of ChatGPT, which may introduce performance and detection bias.",
		"attrition_and_missing_data (流失与缺失数据处理)": "Attrition and missing data are not discussed; analyses are reported for 30 students, but procedures for handling any missing data or dropouts are not described.",
		"reporting_transparency (报告透明度与可重复性)": "The article clearly describes the quasi-experimental design, sample characteristics, intervention timeline, analytic frameworks (Toulmin and Ellis), and statistical methods (paired-samples t-test, SPSS v.26), and provides pre- and post-test means, standard deviations, t-value, p-value, confidence interval, and effect size for total error counts; it also reports detailed qualitative descriptions and percentage distributions of performance levels for key argumentative components and error types; however, raw data, full scoring rubrics, and reliability statistics are not provided, and the data availability statement notes that no data were used for the research, which does not reflect the reported empirical work.",
		"preregistration_or_protocol (预注册或研究方案)": "NR",
		"llm_version_reproducibility (LLM版本与可复现性)": "The LLM is identified as OpenAI’s ChatGPT (GPT-3.5), which supports partial reproducibility regarding the AI model; example prompts used for generating and revising argumentative paragraphs are provided, but comprehensive prompt sets, interaction logs, and details of access mode or parameter settings are not reported, limiting exact replication of the AI-mediated interactions.",
		"baseline_equivalence (基线等同性检验)": "NA (baseline equivalence between groups is not applicable because the design used a single group with the pre-test serving as baseline; no comparison with a separate control group is available).",
		"assumption_check_and_data_diagnostics (统计假设检验与数据诊断)": "The study applies a paired-samples t-test and reports key statistics and effect size, but does not report diagnostic checks for statistical assumptions such as normality of difference scores or presence of outliers; no additional SEM or model fit diagnostics are relevant here as LGCM was not used.",
		"outlier_treatment_and_sensitivity_analysis (异常值处理与稳健性分析)": "NR (there is no discussion of identifying or handling outliers in error counts or writing scores, and no sensitivity analyses are reported to test the robustness of the findings).",
		"data_preprocessing_and_transformation (数据预处理与转换)": "Pre- and post-test argumentative essays were scored using Toulmin’s key components, with student scores converted into percentage-based categories (high, average, low achievers) aligned with standard benchmarks; error counts were tallied for each essay according to Ellis’s error categories and then aggregated for analysis; total error counts were used as continuous variables in paired-samples t-tests; no additional data transformations (such as normalization or log transformation) are reported."
	}
}