{
	"Basic Identification": {
		"author (作者)": "Xue Yin, Kun Dou",
		"publication_year (发表年份)": "2025",
		"study_region (研究地区)": "Hebei Province, China (three public universities)",
		"journal_name (期刊名称)": "Studies in Educational Evaluation",
		"study_type (研究类型_期刊论文_会议论文等)": "Journal research article; single-group quasi-experimental pretest–posttest study with mixed methods",
		"doi_or_identifier (DOI或唯一标识)": "https://doi.org/10.1016/j.stueduc.2025.101480",
		"research_aims (研究目的与问题)": "To investigate how an AI-assisted critical-thinking-oriented writing intervention supported by ChatGPT affects undergraduate EFL learners’ writing performance, and to examine changes in EFL learners’ acceptance of ChatGPT in CT-oriented writing practices.",
		"research_gap_or_novelty (研究创新性与知识空白)": "Addresses the lack of studies using advanced GPT-based tools to support critical-thinking-oriented EFL writing; goes beyond earlier work with traditional Web 2.0 tools or simple chatbots by embedding ChatGPT into an infused CT-oriented framework via AI-assisted brainstorming worksheets and peer-review checklists, and concurrently measuring both CT-reflected writing proficiency and ChatGPT acceptance using the UTAUT2 model."
	},
	"Participant Information": {
		"educational_level (教育阶段)": "First-year undergraduate students",
		"language_proficiency (语言熟练度水平)": "Intermediate B2 level on the CEFR; able to communicate in a clear and detailed manner in most situations",
		"mother_tongue (母语)": "NR",
		"sex (性别)": "135 male students (54%), 115 female students (46%)",
		"age (年龄)": "NR",
		"learning_context (学习语境_ESL_EFL_ELL等)": "EFL context in Chinese higher education",
		"target_language (目标语言)": "English (L2)",
		"discipline (学科背景)": "Mixed majors including law, finance, marketing, insurance, economics and others; English is a compulsory subject",
		"prior_experience_llm (既有LLM使用经验)": "A questionnaire item asked whether students had used ChatGPT for CT-oriented EFL writing before, but descriptive results on prior experience were not reported."
	},
	"Methodology": {
		"research_design (研究设计_实验_准实验_纵向等)": "Single-group quasi-experimental pretest–posttest design implemented over one semester, with an 8-week AI-assisted CT-oriented writing intervention; all participants received the ChatGPT-supported intervention.",
		"research_method (研究方法_定量_定性_混合)": "Mixed methods: quantitative (pre- and post-writing tests and pre- and post-ChatGPT acceptance questionnaire analyzed with descriptive statistics, paired t-tests, and effect sizes) and qualitative (semi-structured interviews analyzed inductively).",
		"sampling_method (抽样方法)": "Convenience and purposive sampling of 250 first-year undergraduates from three public universities in Hebei Province, China; participants were recruited online to meet recommended item-to-respondent ratios for the questionnaire.",
		"sample_size_and_effect (样本量及效应量)": "Total N = 250 first-year undergraduate EFL learners. Writing performance: mean CT-oriented writing score increased from 26.13 (SD = 3.08) at pre-test to 29.58 (SD = 3.16) at post-test, with a significant paired t-test result (t = -1.452, p = .003). ChatGPT acceptance constructs (all N = 250) also increased from pre-test to post-test: performance expectancy mean increased from 8.63 (SD = 3.77) to 10.59 (SD = 4.38), t = -6.75, p < .001, Cohen’s d ≈ 0.43; effort expectancy from 9.23 (SD = 4.19) to 11.62 (SD = 4.52), t = -7.65, p < .001, d ≈ 0.48; trust from 8.19 (SD = 3.31) to 10.32 (SD = 3.57), t = -8.18, p < .001, d ≈ 0.52; behavioral intention from 8.54 (SD = 3.69) to 11.24 (SD = 4.33), t = -9.14, p < .001, d ≈ 0.58; hedonic motivation and habit showed smaller increases (hedonic motivation t = -1.80, p = .073, d ≈ 0.11; habit t = -4.29, p < .001, d ≈ 0.27).",
		"theoretical_foundation (理论基础_理论框架)": "Grounded in critical thinking instruction and CT-oriented pedagogy (Abrami et al., Ennis, Paul and Elder), especially the infusion type of CT instruction in EFL writing (Dong and colleagues); CT-oriented writing is conceptualized as process-based with explicit CT instruction and context-based activities. The intervention uses Paul and Elder’s elements of thought and intellectual standards (clarity, accuracy, precision, relevance, depth, breadth, logic, significance, fairness) as the CT framework. Technology acceptance is framed by the UTAUT2 model (Venkatesh et al., 2012), focusing on performance expectancy, effort expectancy, hedonic motivation, habit, trust, and behavioral intention as key constructs of ChatGPT acceptance.",
		"data_collection_instrument (数据收集工具)": "Pre- and post-argumentative English writing tests (IELTS-style argumentative essays) scored using a CT-oriented writing rubric developed by Dong (2017b), evaluating nine CT dimensions (clarity, accuracy, precision, relevance, depth, breadth, logic, significance, fairness); a self-administered ChatGPT acceptance questionnaire with 24 items (4 per construct: performance expectancy, effort expectancy, hedonic motivation, habit, trust, behavioral intention) on a 5-point Likert scale, plus demographic items (gender, major, prior ChatGPT use), translated into Chinese and back-translated; a semi-structured interview protocol with seven open-ended questions exploring acceptance factors, perceptions of AI-assisted brainstorming and peer review, perceived AI interaction, and attitudes toward CT-oriented writing.",
		"data_collection_validity_reliability (工具信度与效度)": "For the questionnaire, Cronbach’s alpha was 0.913 (pre-test) and 0.909 (post-test) overall, with all constructs having alpha values above 0.70; KMO measures were 0.900 (pre-test) and 0.898 (post-test), and Bartlett’s test of sphericity was significant (p < .001), indicating good sampling adequacy and construct validity. Items were adapted from prior IS/IT and AI acceptance research and translated into Chinese with a back-translation procedure; a pretest with 25 students was conducted to refine item wording and ensure clarity. The CT-oriented writing rubric was developed previously (Dong 2017b) specifically to assess CT reflected in EFL writing, but inter-rater reliability statistics for rubric scoring are not reported.",
		"data_analysis_method (数据分析方法)": "Quantitative data from writing tests and ChatGPT acceptance questionnaires were analyzed using SPSS 25, computing descriptive statistics (means, standard deviations) and paired t-tests to compare pre- and post-intervention scores; Cohen’s d effect sizes were reported for acceptance constructs. Reliability (Cronbach’s alpha) and validity (KMO, Bartlett’s test) of the questionnaire were examined before further analysis. Qualitative interview data were transcribed (in Chinese), translated into English, and analyzed inductively following an approach similar to Thomas (2006), involving summarizing, categorizing, and grouping responses into themes that aligned with questionnaire topics (e.g., CT understanding, AI interaction, perceived roles of ChatGPT).",
		"unit_of_analysis (分析单位)": "Individual student for writing proficiency scores, questionnaire responses, and interview data.",
		"group_assignment_method (组别分配方式_随机_非随机等)": "Single intervention group with no separate control group; all 250 participants received the AI-assisted CT-oriented writing intervention with ChatGPT.",
		"power_analysis (功效分析与样本量论证)": "Sample size justification was based on recommended item-to-respondent ratios for questionnaire measurement (1:5 as minimum, 1:10 as ideal), leading to the target of at least 120 participants and ideally 240; actual sample size was 250. No formal statistical power analysis beyond these guidelines was reported.",
		"sampling_frame_and_representativeness (抽样框与样本代表性)": "Sampling frame consisted of first-year undergraduate students from three public universities in Hebei Province, China, across various majors, all taking compulsory English courses. Convenience and purposive sampling, and the focus on one province and three institutions, limit the representativeness to similar EFL higher education contexts; authors note the need for broader multi-site and international replications.",
		"scoring_procedure_and_rater_training (评分流程与评分者培训)": "Two lecturers independently assessed pre- and post-writing samples using Dong’s CT-oriented writing rubric to evaluate nine CT dimensions in EFL writing. The study mentions independent assessment to mitigate bias but does not report details about rater training procedures, calibration sessions, or inter-rater reliability coefficients."
	},
	"Intervention": {
		"duration (干预时长与频率)": "Eight-week intervention within one semester: week 1 pre-test writing and acceptance survey; weeks 2–7 six two-hour AI-assisted CT-oriented writing lessons (once per week); week 8 post-test writing and post-intervention acceptance survey.",
		"llm_model_type (LLM模型类型_如ChatGPT_GPT4_Gemini等)": "ChatGPT (OpenAI GPT-series large language model; specific version not reported)",
		"llm_model_configuration (LLM模型配置与版本_API_网页_参数等)": "Each student was provided with a free ChatGPT account; ChatGPT was used as an online AI tool during classroom-based writing activities via individual accounts; access was through standard ChatGPT interface, but specific model version, API usage, and parameter settings (e.g., temperature) were not reported.",
		"llm_integration_mode (LLM整合模式_直接使用_教师中介_系统嵌入)": "Students directly interacted with ChatGPT as a virtual knowledgeable peer during CT-oriented brainstorming and peer-review stages, guided by AI-assisted CT-oriented worksheets and checklists; ChatGPT was integrated into the writing process as a scaffolding tool rather than embedded in a separate LMS or used only by the teacher.",
		"prompting_strategy (提示策略_提示工程与使用方式)": "Prompting was structured through an AI-assisted CT-oriented brainstorming worksheet and an AI-assisted CT-oriented peer-review checklist, both grounded in Paul and Elder’s elements of thought and intellectual standards. The worksheets provided explicit prompt stems for students to input into ChatGPT during three brainstorming phases (shaping and generating, expanding and supporting, verifying and finishing) and during peer review to ask ChatGPT to evaluate clarity, accuracy, precision, relevance, depth, breadth, logic, significance, and fairness of their theses and essays, request examples and explanations, and generate model discourse embedded with CT elements. Prompts targeted tasks such as eliciting multiple viewpoints, identifying assumptions, generating supporting information, evaluating relevance, and diagnosing CT-related weaknesses.",
		"training_support_llm_literacy (LLM素养与提示培训)": "Before and during the intervention, the instructor introduced and demonstrated how to use the AI-assisted CT-oriented brainstorming worksheet and peer-review checklist with ChatGPT, explaining the objectives of the intervention and guiding students to formulate meaningful prompts aligned with CT elements and CT standards. The instructor also emphasized ethical and appropriate use of ChatGPT, clarifying rules for using the tool during training and raising awareness of potential issues (such as overreliance and cheating). The worksheets’ notes columns encouraged students to verify the accuracy and reliability of ChatGPT’s information, fostering critical engagement rather than blind acceptance.",
		"intervention_implementation (干预实施流程_步骤与任务)": "The intervention took place in extra English writing classes conducted in multimedia classrooms with internet-connected computers. All participants first completed a pre-test IELTS argumentative essay using the original CT-oriented approach (CT worksheets and peer review with human peers, no AI). From week 2 to week 7, students attended six two-hour lessons in which they practiced CT-oriented writing with ChatGPT support. Each lesson followed a four-stage CT-infused process: (1) CT-oriented brainstorming with ChatGPT using the AI-assisted brainstorming worksheet, where students used CT-based prompts to generate, expand, and verify ideas; (2) drafting a CT-oriented argumentative essay based on the generated ideas and notes; (3) AI-assisted CT-oriented peer review using the AI-assisted peer-review checklist, where students engaged ChatGPT with prompts corresponding to nine CT intellectual standards to diagnose issues in their drafts; and (4) revising essays based on insights from ChatGPT’s feedback and CT standards. A trained CT and writing instructor delivered the same lesson design at all three universities, while a pre-service English teacher helped students technically and procedurally with ChatGPT use. In week 8, students produced a post-test IELTS argumentative essay without AI support to evaluate the impact of the ChatGPT-supported CT-oriented training, and they completed the same ChatGPT acceptance questionnaire again.",
		"experimental_group_intervention (实验组干预内容)": "All 250 participants formed a single intervention group receiving AI-assisted CT-oriented instruction. They practiced CT-oriented writing through a structured infusion approach that combined teacher instruction, collaborative discussion with ChatGPT, note-taking using the AI-assisted brainstorming worksheet, drafting, AI-assisted peer review with the CT-oriented checklist, and revision. ChatGPT served as a knowledgeable peer to help students understand CT concepts, generate and organize ideas in line with CT elements, and diagnose weaknesses against CT intellectual standards in their own writing.",
		"control_group_intervention (对照组干预内容)": "NA",
		"writing_stage (写作阶段_如生成_修改_反馈_重写等)": "ChatGPT was integrated into CT-oriented brainstorming (idea generation and planning) and CT-oriented peer review (feedback and evaluation) stages of the process-oriented writing cycle. Drafting and revising were informed by CT-based ideas and feedback obtained via ChatGPT, while pretest and posttest writing tasks were completed without AI assistance.",
		"writing_genre (写作体裁)": "Argumentative essays (IELTS-style argumentative writing tasks)",
		"writing_task_type (写作任务类型)": "CT-oriented argumentative English writing tests similar to IELTS argumentative essays, focusing on applying CT elements and intellectual standards in written arguments; example prompts involve positions on topics such as language death and language diversity.",
		"role_llm (LLM角色_如生成文本_给反馈_评分_对话等)": "ChatGPT acted as a knowledgeable peer and scaffolding tool: generating ideas and viewpoints, illustrating how CT is reflected in model discourse, helping students link CT elements to writing, providing explanations and supporting information, identifying issues in students’ drafts related to CT standards (e.g., lack of clarity, weak logic, insufficient breadth), and giving detailed feedback and examples in response to CT-based prompts. ChatGPT was not used for automated grading of writing tests.",
		"role_instructor (教师角色与介入方式)": "A proficient English writing and CT instructor served as the trainer, delivering the same CT-oriented writing lessons at all three universities, explaining CT concepts, introducing and modeling the AI-assisted worksheets and checklists, and ensuring consistent implementation. Another lecturer (a pre-service English teacher) supported students’ use of ChatGPT during the classroom intervention. The instructor explicitly outlined the objectives of the intervention, provided guidelines for ethical and effective ChatGPT use, and addressed potential misuse or overreliance, while facilitating CT-oriented writing activities and overseeing the pre- and post-test assessments.",
		"setting (教学情境_学校类型_课程类型_线上线下)": "Extra English writing classes within compulsory English courses at three public universities in Hebei Province, China; EFL higher education context; face-to-face lessons conducted in multimedia classrooms with computer terminals and internet access; ChatGPT accessed online by each student.",
		"ethical_consideration (伦理审查与知情同意)": "The questionnaire included an informed consent statement specifying that data would be used for academic research only and kept confidential; participants indicated consent by selecting an agreement option and were told they were at least 18 years old. Questionnaire items did not collect identifiable information such as names. The authors mention ethical considerations and guidelines for responsible ChatGPT use, including informing students about rules of using ChatGPT during training and raising awareness about ethical issues such as potential cheating and misuse.",
		"llm_access_policy (LLM使用规范_允许与限制)": "All participants were given access to free ChatGPT accounts for classroom intervention sessions; ChatGPT use was limited to specific stages of CT-oriented writing (brainstorming and peer review) and was not allowed during pretest and posttest writing tasks. The instructor outlined rules for the ethical and effective use of ChatGPT, emphasizing its role as a supplementary CT scaffold, not as a substitute for genuine writing ability; participants were also instructed not to engage in other CT-related interventions during the study period to avoid confounds. Details of institutional-level AI policies were not reported.",
		"llm_safety_guardrails (LLM安全与内容过滤设置)": "NR (the article does not describe technical safety configurations, content filters, or system-level guardrails for ChatGPT beyond pedagogical guidelines for responsible and critical use).",
		"key_findings (主要研究发现_与LLM写作干预相关)": "The AI-assisted CT-oriented writing intervention using ChatGPT significantly enhanced students’ CT-reflected writing performance: mean CT-oriented writing scores increased from 26.13 (SD = 3.08) at pretest to 29.58 (SD = 3.16) at posttest, with a significant paired t-test (p < .05). Quantitative results showed significant improvements in multiple ChatGPT acceptance constructs (performance expectancy, effort expectancy, trust, behavioral intention) with medium effect sizes, indicating that students increasingly perceived ChatGPT as useful, easy to use, trustworthy, and something they intended to continue using as a scaffolding tool for CT-oriented EFL writing; hedonic motivation and habit showed only marginal or modest increases. Qualitatively, most interviewees reported that ChatGPT deepened their understanding of CT concepts by demonstrating how CT is reflected in model discourse, provided effective information and feedback superior to real peers during brainstorming and peer review, and helped them become more logical in writing. Students valued ChatGPT for supplying model discourse embedded with CT elements and for its ability to clarify and elaborate CT-based criteria, though some noted that the multi-stage, prompt-heavy process could be boring and required patience. Overall, ChatGPT functioned as an effective intellectual partner and scaffold within an infused CT-oriented writing framework, enhancing both CT-oriented writing performance and acceptance of AI tools in EFL writing."
	},
	"Outcome": {
		"application_effectiveness_overview (应用效果总体评价与测量工具)": "Effectiveness of the AI-assisted CT-oriented intervention was gauged primarily through pre- and post-intervention CT-oriented writing tests (IELTS-style argumentative essays) scored by two lecturers using Dong’s CT writing rubric and through changes in students’ ChatGPT acceptance scores across six UTAUT2 constructs. Additional qualitative evidence from semi-structured interviews enriched understanding of how ChatGPT influenced CT-oriented writing, CT understanding, and AI acceptance.",
		"writing_performance_measure (写作表现测量工具_量表或评分标准)": "CT-oriented EFL writing performance was measured by pre- and post-test IELTS argumentative essays assessed with a rubric developed by Dong (2017b) to evaluate nine CT dimensions in writing: clarity, accuracy, precision, relevance, depth, breadth, logic, significance, and fairness.",
		"writing_performance_focus (写作表现关注维度_流利度_准确性_复杂度_体裁等)": "The focus was on critical thinking as reflected in writing quality, particularly the logical organization and evidentiary robustness of argumentative essays, including clarity and accuracy of expression, precision and relevance of arguments, depth and breadth of analysis, logical coherence, significance of content, and fairness in perspective; syntactic and lexical aspects were embedded within these CT-oriented dimensions rather than assessed separately.",
		"affective_aspect_measure (情感因素测量工具_问卷_量表等)": "A self-administered ChatGPT acceptance questionnaire grounded in the UTAUT2 model, with 24 items on a 5-point Likert scale (strongly disagree to strongly agree) measuring six constructs (performance expectancy, effort expectancy, hedonic motivation, habit, trust, behavioral intention), plus demographic questions (gender, major, prior ChatGPT use).",
		"affective_aspect_focus (情感因素维度_动机_态度_焦虑_自效感等)": "Students’ acceptance of ChatGPT as a CT-oriented EFL writing tool, including perceived usefulness and performance benefits (performance expectancy), perceived ease of use (effort expectancy), enjoyment and fun in using ChatGPT (hedonic motivation), habit and perceived addiction or regular use (habit), trust in ChatGPT and its content (trust), and behavioral intention to continue using and recommending ChatGPT as a scaffolding tool in future CT-oriented writing activities.",
		"cognitive_aspect_measure (认知因素测量工具)": "CT-specific writing tests (pre- and post- essays scored on nine CT dimensions) and qualitative interview questions that probed students’ understanding of CT elements and CT intellectual standards, perceived changes in their thinking processes during AI-supported brainstorming and peer review, and their reflections on CT-oriented writing practices with ChatGPT.",
		"cognitive_aspect_focus (认知因素维度_策略使用_元认知监控等)": "Students’ critical thinking skills as operationalized in writing (clarity, accuracy, precision, relevance, depth, breadth, logic, significance, fairness), their conceptual understanding of CT and how CT elements and intellectual standards manifest in argumentative writing, their ability to apply CT-based strategies in brainstorming and peer review, and their metacognitive awareness of thinking processes when interacting with ChatGPT and self-evaluating their essays.",
		"behavioral_aspect_measure (行为因素测量工具_日志_平台日志等)": "Self-report items in the ChatGPT acceptance questionnaire measuring habit and behavioral intention constructs related to ChatGPT use in CT-oriented writing; a background item on previous experience with ChatGPT; and interview questions focusing on actual AI interaction patterns (e.g., how students used ChatGPT for brainstorming and peer review). No system log data or objective usage metrics were reported.",
		"behavioral_aspect_focus (行为因素维度_使用频率_交互模式_坚持度等)": "Habitual use tendencies (e.g., whether ChatGPT had become a habit, feelings of addiction, frequency of use, preference for consulting ChatGPT first when CT is needed in EFL writing) and behavioral intentions (e.g., intentions to continue using ChatGPT in future CT-oriented writing, to use it to develop CT-oriented writing skills, to regularly use it for practice, and to recommend it to classmates); qualitative data also highlighted interaction styles such as viewing ChatGPT as an intellectual partner rather than an information browser.",
		"other_outcomes_measure (其他结果测量工具)": "Semi-structured interviews with 25 participants from the three universities, analyzed inductively to extract themes; descriptive analysis of theme frequencies (e.g., percentages of interviewees mentioning CT concepts understanding, model discourse, information and feedback, logic, AI interaction).",
		"other_outcomes_focus (其他结果维度说明)": "Interview themes indicated that ChatGPT positively influenced CT-oriented writing in several ways: deepening CT concepts understanding by showing how CT elements are embedded in writing rather than just giving definitions (mentioned by 72% of interviewees); providing model discourse that systematically demonstrates CT elements, especially helpful for students less confident in writing (68%); offering effective and knowledgeable feedback and information, often more helpful than real peers during brainstorming and peer review (64%); and enhancing logic in writing, which most interviewees (84%) highlighted as a key perceived benefit. Some students (36%) also described the AI-assisted CT-oriented process as efficient but somewhat boring and demanding in terms of patience due to multiple stages and prompts.",
		"assessment_timepoints (评估时间点_前测_后测_延迟测等)": "Pre-test writing and pre-intervention ChatGPT acceptance questionnaire administered one week before the start of the intervention; eight-week CT-oriented writing intervention with ChatGPT during weeks 2–7; post-test writing and post-intervention acceptance questionnaire administered immediately after the intervention (week 8); semi-structured interviews conducted after the intervention. No delayed or follow-up assessment was conducted.",
		"primary_outcome_variables (主要结果变量_因变量)": "Primary outcomes were CT-oriented writing proficiency scores (total scores based on nine CT dimensions) on pre- and post-test argumentative essays and construct scores on the ChatGPT acceptance questionnaire (performance expectancy, effort expectancy, hedonic motivation, habit, trust, behavioral intention) before and after the intervention.",
		"independent_variables_and_factors (自变量与实验因素)": "The main independent factor was time (pre-intervention vs post-intervention) under a single-group design, reflecting exposure to the AI-assisted CT-oriented writing intervention using ChatGPT. Within the acceptance model, the six constructs were examined as dependent measures of ChatGPT acceptance; moderating variables such as major or English level were discussed conceptually but not analyzed statistically in this study.",
		"followup_length_and_type (随访时长与类型)": "NA",
		"statistical_significance (统计显著性结果摘要)": "CT-oriented writing proficiency improved significantly from pre-test (M = 26.13, SD = 3.08) to post-test (M = 29.58, SD = 3.16), with a paired t-test indicating a statistically significant difference (t = -1.452, p = .003, p < .05). For ChatGPT acceptance, all constructs showed higher mean scores at post-test: performance expectancy, effort expectancy, habit, trust, and behavioral intention increased significantly with p-values below .001 (e.g., performance expectancy t = -6.750, p < .001; effort expectancy t = -7.649, p < .001; habit t = -4.289, p < .001; trust t = -8.182, p < .001; behavioral intention t = -9.136, p < .001). Hedonic motivation also increased slightly but did not reach conventional significance (t = -1.801, p = .073).",
		"effect_size_summary (效应量摘要)": "Cohen’s d effect sizes reported for acceptance constructs indicated small-to-moderate effects: performance expectancy d ≈ 0.43, effort expectancy d ≈ 0.48, habit d ≈ 0.27, trust d ≈ 0.52, behavioral intention d ≈ 0.58, and hedonic motivation d ≈ 0.11. Effect sizes for CT-oriented writing proficiency gains were not reported.",
		"llm_misuse_or_negative_effects (LLM滥用或负向效应)": "The study acknowledges potential risks such as overreliance on ChatGPT, skill degradation, cheating, and limitations of ChatGPT (e.g., misinformation), but reports that only a few interviewees explicitly voiced concerns about these issues. The relatively low number of negative reports is attributed to the instructor’s proactive guidance and clearly communicated ethical rules for ChatGPT use. The authors warn that using ChatGPT to revise essays may obscure true writing competence, raising fairness concerns in assessment. They emphasize that ChatGPT should be used as a supplementary tool within a structured CT framework rather than for direct generation of complete essays, and they highlight the need for students to develop regulation skills to critically assess AI-generated content and mitigate risks of misuse and overreliance.",
		"equity_and_subgroup_effects (公平性与亚组差异)": "No quantitative subgroup analyses (e.g., by gender, major, or institution) or equity-focused comparisons were conducted. The authors note that participants came from different majors and that future research should examine moderating variables such as field of study and English level, and potentially use multilevel modeling when more institutions are involved, but no subgroup statistics are provided in this study.",
		"limitation (研究局限)": "Key limitations include the single-group pretest–posttest design without a control group, which restricts causal inference and makes it difficult to rule out alternative explanations such as effects of other courses or general development; lack of a delayed follow-up assessment to determine the persistence of intervention effects; reliance on self-reported questionnaire data, which may be subject to self-report bias; sample restricted to three universities in one Chinese province, limiting external validity; inability to link individual students’ ChatGPT acceptance levels to their specific writing scores due to the anonymous design of questionnaires; small number of institutional clusters (three universities), which precludes multilevel modeling; and the possibility that process-oriented writing practice over the six-week intervention period contributed to gradual improvement independent of ChatGPT. The authors recommend future studies that incorporate control groups, delayed assessments, broader and more diverse samples, identifiable yet ethically managed data, and more advanced statistical modeling.",
		"challenge (实施挑战与风险)": "Implementation challenges and risks identified include the complexity and length of the AI-assisted CT-oriented writing process, which some students found boring and requiring considerable patience due to multiple stages and detailed prompts; the need to carefully manage ethical issues such as potential cheating and unfair advantages when ChatGPT is used for writing tasks; concerns about possible overreliance on ChatGPT, which could undermine autonomous cognitive development and the accurate evaluation of students’ writing competence; and the practical demands of training instructors and students in CT frameworks, prompt design, and responsible AI use while ensuring that students do not participate in other overlapping CT interventions during the study period.",
		"future_work (未来研究方向)": "Future research should adopt multi-group designs with appropriate control or comparison groups (e.g., traditional CT-oriented writing without AI vs AI-supported CT-oriented writing) and conduct delayed follow-up assessments (e.g., one month after intervention) to examine the durability of effects; expand to multi-site, multi-country contexts with larger and more diverse samples to enhance external validity and allow multilevel modeling; incorporate behavioral measures such as actual usage logs and identifiable but ethically managed linkage between acceptance levels and writing performance; explore moderating variables such as field of study, English proficiency level, and institutional context; and further refine structured AI-assisted CT instructional models, possibly comparing different AI scaffolding strategies or alternative LLMs. The authors also recommend examining how ChatGPT can be optimally integrated into CT-oriented curricula as a cognitive partner while minimizing risks of misuse.",
		"implication (理论与教学实践启示)": "The study implies that ChatGPT, when systematically integrated into a CT-oriented writing framework via AI-assisted brainstorming and peer-review tools grounded in Paul and Elder’s CT elements and standards, can function as an intellectual partner that enhances CT-reflected writing performance and increases students’ acceptance of AI in EFL writing. Pedagogically, educators should explicitly teach students how to formulate CT-based prompts, use CT-oriented rubrics and checklists (e.g., clarity, logic, fairness) during AI-assisted peer evaluation, and critically compare AI-generated feedback with peer and teacher feedback to cultivate evaluative metacognition. ChatGPT should be positioned as a collaborative cognitive tool rather than an authoritative source, with students required to justify their decisions to adopt or reject AI-suggested revisions. Teacher training should cover CT frameworks, prompt engineering, ethical guidelines, and adaptive scaffolding strategies for learners of different proficiency levels. Theoretically, the findings contribute to the understanding of how LLMs can be embedded into CT-infused second language writing pedagogy and demonstrate the value of viewing generative AI as a structured scaffolding mechanism for higher-order thinking rather than as a mere information browser."
	},
	"Study Quality and Reporting": {
		"funding_source (经费来源)": "NR",
		"conflict_of_interest (利益冲突声明)": "No potential conflict of interest was reported by the authors.",
		"risk_of_bias_randomization (偏倚风险_分配与随机化)": "No randomization was used; all participants formed a single intervention group receiving the AI-assisted CT-oriented writing treatment. The authors attempted to control potential confounding variables through standardized instructional delivery by the same instructor across universities, control of baseline characteristics, protocol to restrict participation in other CT-related programs, and design features to reduce testing and history threats, but the absence of a control group and random assignment remains a source of potential bias.",
		"risk_of_bias_blinding (偏倚风险_盲法)": "The study does not report any blinding of participants, instructors, or raters to intervention stage or study aims. Students and instructors clearly knew ChatGPT was being used as part of the intervention; two lecturers independently rated pre- and post-test writing, but there is no indication that they were blinded to time point (pre vs post) or to any other identifying information.",
		"attrition_and_missing_data (流失与缺失数据处理)": "The authors state that all enrolled students remained in the study due to integration into regular semester schedules and the provision of extra credit, resulting in no attrition; students who might have left the course would have been omitted, but this did not occur. No discussion of missing data handling for questionnaire items or writing scores is provided, suggesting that analyses were conducted on complete cases.",
		"reporting_transparency (报告透明度与可重复性)": "The article clearly reports participants’ number, gender distribution, proficiency level, institutions, and majors; describes the intervention design, duration, and stages; specifies measurement instruments (writing rubric, acceptance questionnaire, interview protocol) and their reliability and validity indices; outlines data collection procedures, timing, and steps taken to minimize validity threats; and presents main descriptive statistics, t-test results, and effect sizes. Limitations and potential confounds are explicitly discussed. However, some implementation details, such as exact writing prompts used for pre- and post-tests and inter-rater reliability statistics for writing scores, are not reported.",
		"preregistration_or_protocol (预注册或研究方案)": "NR",
		"llm_version_reproducibility (LLM版本与可复现性)": "The study specifies that all students used a free version of ChatGPT as a GPT-based large language model but does not report the specific model version, exact time frame of model access beyond the academic schedule, or parameter settings, which limits precise reproducibility given the evolving nature of LLMs.",
		"baseline_equivalence (基线等同性检验)": "Baseline CT-oriented writing performance was measured by the pre-test essay, and ChatGPT acceptance was measured by the pre-intervention questionnaire. Since there was only one group, baseline equivalence between groups was not applicable; there were no statistical tests of equivalence across subgroups (e.g., majors or universities).",
		"assumption_check_and_data_diagnostics (统计假设检验与数据诊断)": "The study reports paired t-test results for writing performance and acceptance constructs but does not describe checks of statistical assumptions (e.g., normality of differences, absence of outliers) or other diagnostics such as inspection of residuals.",
		"outlier_treatment_and_sensitivity_analysis (异常值处理与稳健性分析)": "NR (no specific procedures for outlier detection, removal, or sensitivity analysis are reported).",
		"data_preprocessing_and_transformation (数据预处理与转换)": "Questionnaire data were screened for reliability (Cronbach’s alpha) and validity (KMO, Bartlett’s test) and then analyzed using descriptive statistics and paired t-tests; factor analysis suitability was established. Writing scores were obtained from rubric-based assessments and analyzed directly without reported transformation. Qualitative interview data were transcribed, translated, and condensed by omitting redundant information and grouping relevant segments into thematic categories aligned with questionnaire constructs."
	}
}