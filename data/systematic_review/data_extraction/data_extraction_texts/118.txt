{
	"Basic Identification": {
		"author (作者)": "Chalermsup Karanjakwut, Kamonwan Charunsri",
		"publication_year (发表年份)": "2025",
		"study_region (研究地区)": "Bangkok, Thailand",
		"journal_name (期刊名称)": "Malaysian Online Journal of Educational Technology",
		"study_type (研究类型_期刊论文_会议论文等)": "Journal research article; mixed-methods quasi-experimental study with non-equivalent groups",
		"doi_or_identifier (DOI或唯一标识)": "http://dx.doi.org/10.52380/mojet.2025.13.1.559",
		"research_aims (研究目的与问题)": "To investigate whether AI-driven brainstorming tools in process writing instruction improve third-year Thai university students' writing outcomes compared to traditional brainstorming techniques; to explore foreign English lecturers' preferences and comments on AI-generated versus student-generated brainstorming results; to identify which AI chatbots students use as brainstorming tools in process writing; and to examine perceived challenges and facilitative factors experienced when using AI chatbots for brainstorming.",
		"research_gap_or_novelty (研究创新性与知识空白)": "Addresses limitations of traditional brainstorming in process writing (limited idea diversity, time constraints, inefficiency) by integrating AI-driven brainstorming tools (ChatGPT, Gemini, Microsoft Bing) in an EFL university context; provides empirical mixed-methods evidence on AI chatbots as brainstorming tools within process writing, including learning outcomes, teacher preference, student chatbot choice, and perceived challenges and facilitative factors in a Thai higher education setting."
	},
	"Participant Information": {
		"educational_level (教育阶段)": "Third-year university students in a Bachelor of Education (English major) program",
		"language_proficiency (语言熟练度水平)": "Had completed four major English courses (Fundamental Grammar for English Language Teaching, Advanced Grammar for Teachers of English, Critical Reading for English Language Teaching, English Materials and Learning Innovations Development) and were described as possessing requisite background in English grammar, reading skills, and technological skills; no standardized English proficiency test reported.",
		"mother_tongue (母语)": "NR (participants were third-year Thai university students at an EFL public university in Bangkok, Thailand; L1 not explicitly stated)",
		"sex (性别)": "NR",
		"age (年龄)": "NR",
		"learning_context (学习语境_ESL_EFL_ELL等)": "EFL university context at a public university in Bangkok, Thailand",
		"target_language (目标语言)": "English (L2)",
		"discipline (学科背景)": "Bachelor of Education majoring in English; student teachers enrolled in the course Academic Writing for English Language Teaching",
		"prior_experience_llm (既有LLM使用经验)": "NR"
	},
	"Methodology": {
		"research_design (研究设计_实验_准实验_纵向等)": "Mixed-methods quasi-experimental design with two intact course sections (AI-driven brainstorming group vs conventional brainstorming group) and concurrent qualitative components (lecturers' feedback notes, student questionnaire including open-ended responses).",
		"research_method (研究方法_定量_定性_混合)": "Mixed methods: quantitative (comparison of writing assignment scores via descriptive statistics and independent samples t-tests) and qualitative (content analysis and thematic analysis of lecturers’ feedback and open-ended questionnaire responses).",
		"sampling_method (抽样方法)": "Purposive sampling of third-year students enrolled in the Academic Writing for English Language Teaching course in the 2023 academic year; two intact sections were used as conventional and AI-driven groups.",
		"sample_size_and_effect (样本量及效应量)": "Total N = 86; intervention (AI-driven brainstorming) group n = 44 (Section D2), conventional (traditional brainstorming) group n = 42 (Section D1). Over three assignments, AI group had higher mean scores: People (AI 82.5, conventional 77.2, t(84) = 3.21, p = .002), Places (AI 79.8, conventional 77.6, t(84) = 1.62, p = .11, not significant), Things (AI 85.3, conventional 80.1, t(84) = 3.78, p = .001); overall mean scores: AI 82.5 (Excellent), conventional 78.3 (Very good); effect sizes not reported.",
		"theoretical_foundation (理论基础_理论框架)": "Grounded in process writing pedagogy (brainstorming, outlining, drafting, revising, editing) and brainstorming theory, with AI-driven brainstorming positioned as a means to enhance idea diversity and creativity; draws on literature about AI chatbots (ChatGPT, Gemini, Microsoft Bing) as generative AI tools for writing assistance, and on prior studies about challenges and facilitative factors of AI use in writing.",
		"data_collection_instrument (数据收集工具)": "Three writing assignments (descriptive, opinion-based, comparative essays about people, places, and things) graded by foreign English lecturers using university criterion-referenced scales (0–100 marks with categories from Excellent to Very poor); a questionnaire adapted from Sasikumar and Sunil (2023) and Chan and Hu (2023), validated by three experts in English language teaching and writing instruction, including sections on respondent background, preference for AI chatbots as brainstorming tools, Likert-scale items on challenges and facilitative factors, and open-ended questions; foreign English lecturers' feedback notes on AI-generated and student-generated brainstorming results.",
		"data_collection_validity_reliability (工具信度与效度)": "The questionnaire was adapted from prior studies and validated by three experts in English language teaching and writing instruction; Likert scales were interpreted using published criteria (Likert, 1932); assignments were graded by foreign English lecturers using standardized university criterion-referenced scales, and graders were not informed whether brainstorming results were AI-generated or student-generated to reduce potential bias; internal consistency indices (e.g., Cronbach’s alpha) and inter-rater reliability for assignment scores were not reported.",
		"data_analysis_method (数据分析方法)": "For RQ1, descriptive statistics (mean, standard deviation) and independent samples t-tests were used to compare AI-driven and traditional groups across three assignments, and assignment means were interpreted using university criterion-referenced levels; for RQ2, content analysis and thematic content analysis following Braun and Clarke (2006) and Miles et al. (2014) were applied to lecturers’ feedback notes to derive themes (Novelty and Creativity, Depth and Development, Language Use, Feedback Potential); for RQ3, frequencies and percentages were calculated for AI chatbot usage preferences, and thematic analysis was applied to open-ended responses on reasons for chatbot choice; for RQ4, means and standard deviations of Likert items on challenges and facilitative factors were computed and interpreted using Likert (1932) levels, and open-ended responses were analyzed via thematic analysis to enrich interpretation.",
		"unit_of_analysis (分析单位)": "Individual student for assignment scores, questionnaire responses, and chatbot usage; individual lecturer for feedback note comments; group-level comparisons between intervention and conventional groups for quantitative analyses.",
		"group_assignment_method (组别分配方式_随机_非随机等)": "Non-random assignment based on intact course sections: Section D1 (42 students) served as the conventional/traditional brainstorming group, and Section D2 (44 students) served as the interventional/AI-driven brainstorming group.",
		"power_analysis (功效分析与样本量论证)": "NR",
		"sampling_frame_and_representativeness (抽样框与样本代表性)": "Sampling frame consisted of third-year student teachers majoring in English and enrolled in Academic Writing for English Language Teaching at a single EFL public university in Bangkok, Thailand; purposive selection of course sections limits representativeness to similar cohorts and contexts.",
		"scoring_procedure_and_rater_training (评分流程与评分者培训)": "Foreign English lecturers graded the three assignments over a six-week period using the university’s criterion-referenced scales (0–100 marks with categorical interpretations) and provided feedback on each assignment; graders were not informed whether brainstorming results were AI-generated or student-generated; specific details on rater training procedures, number of raters per script, and inter-rater reliability statistics were not reported."
	},
	"Intervention": {
		"duration (干预时长与频率)": "Six-week intervention during a semester-long Academic Writing for English Language Teaching course, with three key assignments: People (week 2), Places (week 4), and Things (week 6); AI-driven or traditional brainstorming applied for each assignment cycle, followed by drafting, revising, and editing.",
		"llm_model_type (LLM模型类型_如ChatGPT_GPT4_Gemini等)": "ChatGPT (OpenAI), Gemini (Google, also referred to as Bard), Microsoft Bing Chat (Microsoft)",
		"llm_model_configuration (LLM模型配置与版本_API_网页_参数等)": "AI chatbots were used as online AI-driven brainstorming tools (ChatGPT, Gemini, Microsoft Bing) by students in the intervention group; specific access modes (e.g., web UI versus app), model versions, API usage, dates of access, and parameter settings were not reported.",
		"llm_integration_mode (LLM整合模式_直接使用_教师中介_系统嵌入)": "Students in the interventional group interacted directly with AI chatbots (ChatGPT, Gemini, Microsoft Bing) as brainstorming tools when preparing each writing assignment; AI tools were not embedded in a separate LMS or automated assessment system, and the teacher did not mediate the AI outputs beyond giving instructions to use them for brainstorming.",
		"prompting_strategy (提示策略_提示工程与使用方式)": "Students were instructed to use AI-driven tools to brainstorm ideas, generate keywords, and develop initial thoughts by asking the AI for examples, receiving prompts, exploring different perspectives, and refining their topic focus based on AI responses; no explicit advanced prompt engineering strategies (e.g., few-shot prompting, chain-of-thought prompting) were described.",
		"training_support_llm_literacy (LLM素养与提示培训)": "Students in the interventional group were instructed to interact with AI chatbots for brainstorming and were guided to ask AI for examples, prompts, and alternative perspectives; however, the article does not report systematic training on AI literacy, critical evaluation of AI outputs, plagiarism awareness related to AI-generated text, or detailed instruction on prompt design.",
		"intervention_implementation (干预实施流程_步骤与任务)": "Both groups received identical essay topics (descriptive, opinion-based, comparative essays about people, places, and things) within a process writing framework. In the interventional group, each assignment began with AI-driven brainstorming: students used AI chatbots to generate ideas, keywords, and initial thoughts, asked AI for examples and prompts, and refined their topic focus based on AI responses; then they organized ideas into structured outlines, drafted full essays, revisited AI tools during drafting for additional examples, transitions, or vocabulary, received self-assessment, peer feedback, and feedback from foreign English lecturers, and finally edited their essays before submission. In the conventional group, students used traditional brainstorming techniques—including mind-mapping, listing, double list, and freewriting—to generate ideas, then followed similar outlining, drafting, revising (self and peer), teacher feedback, and editing stages, but without AI tools. Over six weeks, foreign English lecturers provided feedback and graded assignments, blinded to whether brainstorming results were AI- or student-generated in the interventional group.",
		"experimental_group_intervention (实验组干预内容)": "Interventional (AI) group (Section D2, n = 44) used AI-driven brainstorming tools (ChatGPT, Gemini, Microsoft Bing) at the brainstorming stage of each assignment to generate ideas, keywords, and perspectives, asked AI for examples and prompts, refined topic focus using AI output, could revisit AI during drafting for further examples, transitions, or vocabulary, and then proceeded with outlining, drafting, revising (self and peer), receiving feedback from foreign English lecturers, and editing before submitting essays for grading.",
		"control_group_intervention (对照组干预内容)": "Conventional group (Section D1, n = 42) used traditional brainstorming techniques such as mind-mapping, listing, double list, and freewriting to generate ideas for the same topics (People, Places, Things); they then organized ideas into outlines, drafted essays, engaged in self-assessment and peer feedback, received feedback from foreign English lecturers, and edited their work prior to submission, without any use of AI chatbots.",
		"writing_stage (写作阶段_如生成_修改_反馈_重写等)": "AI-driven brainstorming was applied primarily at the idea generation and planning stages of process writing (brainstorming and outlining), with the option for students in the AI group to revisit AI tools during drafting for additional prompts, examples, transitions, or vocabulary; subsequent revising, feedback, and editing stages involved self-assessment, peer feedback, and lecturer feedback.",
		"writing_genre (写作体裁)": "Descriptive essays, opinion-based essays, and comparative essays about people, places, and things.",
		"writing_task_type (写作任务类型)": "Three course writing assignments: People (brainstorming and essay about people), Places (brainstorming and essay about places), and Things (brainstorming and essay about things), each graded on a 0–100 scale with performance categories.",
		"role_llm (LLM角色_如生成文本_给反馈_评分_对话等)": "LLMs (ChatGPT, Gemini, Microsoft Bing) served as brainstorming assistants and idea generators, helping students generate diverse ideas, keywords, examples, prompts, perspectives, vocabulary options, and potential angles for essays; they were not used for automated scoring or high-stakes assessment.",
		"role_instructor (教师角色与介入方式)": "The course instructor taught process writing and brainstorming techniques, assigned topics, guided conventional brainstorming in the control group, instructed the AI group to use AI chatbots for brainstorming, and oversaw the writing process; foreign English lecturers provided feedback on language use, coherence, and idea development, and graded assignments using the university criterion-referenced scales while being blinded to whether brainstorming results were AI-generated or student-generated.",
		"setting (教学情境_学校类型_课程类型_线上线下)": "EFL public university in Bangkok, Thailand; on-campus Academic Writing for English Language Teaching course for third-year Bachelor of Education (English major) students; AI tools accessed as part of classroom-based or course-based writing assignments.",
		"ethical_consideration (伦理审查与知情同意)": "All participants were fully informed about the study’s purpose, procedures, potential risks, and benefits, could ask questions for clarification, and provided voluntary informed consent; participant data were kept confidential with secure data storage and restricted access to authorized personnel; researchers adhered to academic integrity by avoiding plagiarism, data fabrication, and falsification; participants were treated with respect and cultural sensitivity without discrimination; potential benefits (enhanced writing skills and creativity) were weighed against risks (possible frustration or anxiety when using AI-driven brainstorming tools).",
		"llm_access_policy (LLM使用规范_允许与限制)": "AI chatbots were allowed as brainstorming tools for the interventional group and were integrated into the process writing assignments; the conventional group did not use AI chatbots; formal institutional or course-level policies on extent of AI use, restrictions on copying AI-generated text, or citation of AI output were not detailed.",
		"llm_safety_guardrails (LLM安全与内容过滤设置)": "NR (no specific description of technical safety guardrails, content moderation settings, or AI safety configurations for ChatGPT, Gemini, or Microsoft Bing was provided).",
		"key_findings (主要研究发现_与LLM写作干预相关)": "Quantitatively, the AI-driven brainstorming group achieved higher mean scores on all three assignments, with statistically significant advantages on two of them: People (AI 82.5 vs conventional 77.2, t(84) = 3.21, p = .002) and Things (AI 85.3 vs conventional 80.1, t(84) = 3.78, p = .001), while Places showed no significant difference (AI 79.8 vs conventional 77.6, t(84) = 1.62, p = .11); overall, the AI group’s average performance across assignments was rated as Excellent, while the conventional group’s performance was Very Good. Qualitatively, foreign English lecturers perceived AI-generated brainstorming as highly novel and creative, with polished language and strong vocabulary, but preferred student-generated brainstorming for greater depth, nuance, coherence, and development potential; they viewed AI outputs as valuable supplementary resources for feedback, modeling, and discussion rather than replacements for student creativity. Students overwhelmingly reported using ChatGPT (78.8%, 68 of 86), followed by Gemini (31.4%, 27 students) and Bing (19.8%, 17 students), valuing ChatGPT for easy access, natural and fluent responses, and creativity, Gemini for integration with Google accounts and up-to-date information, and Bing for control over tone and style and a user-friendly interface. Perceived challenges included overreliance on AI for idea generation as the most challenging issue (M = 4.62, SD = 0.44), difficulty interpreting AI-generated ideas (M = 3.75), concerns about plagiarism/ethical issues (M = 3.28), lack of control over output (M = 3.15), and difficulty integrating AI ideas into writing (M = 2.96). Facilitative factors rated highest were enhanced creativity (M = 4.53, SD = 0.79) and increased idea generation (M = 4.51, SD = 0.93), with additional benefits in overcoming writer’s obstacles, exposure to diverse perspectives, and collaborative brainstorming opportunities."
	},
	"Outcome": {
		"application_effectiveness_overview (应用效果总体评价与测量工具)": "Effectiveness of AI-driven brainstorming tools was primarily evaluated using the scores of three course writing assignments (People, Places, Things) graded on 0–100 marks by foreign English lecturers using university criterion-referenced scales, comparing AI-driven and traditional groups; additional outcomes included lecturer thematic feedback about AI vs student brainstorming results and student questionnaire responses (Likert-scale items and open-ended questions) on AI chatbot use, challenges, and facilitative factors.",
		"writing_performance_measure (写作表现测量工具_量表或评分标准)": "Three course writing assignments assessed by foreign English lecturers according to the university criterion-referenced scales (0–100 marks, with categories such as Excellent, Very good, Good, Average, Below average, Marginal, Poor, Very poor) and informed by checks of accuracy, appropriacy, and creativity in students’ writing.",
		"writing_performance_focus (写作表现关注维度_流利度_准确性_复杂度_体裁等)": "Overall writing outcomes and assignment scores in descriptive, opinion-based, and comparative essays about people, places, and things, with emphasis on idea generation quality, accuracy, appropriacy, creativity, and language use across process writing stages.",
		"affective_aspect_measure (情感因素测量工具_问卷_量表等)": "Questionnaire including Likert-scale items (5-point scale) on perceived challenges and facilitative factors when using AI chatbots as brainstorming tools, frequency and preference items on AI chatbot use, and open-ended questions about reasons for chatbot preferences and experiences; qualitative insights from open-ended questionnaire responses and lecturers’ feedback notes.",
		"affective_aspect_focus (情感因素维度_动机_态度_焦虑_自效感等)": "Students’ attitudes and preferences toward AI chatbots (ChatGPT, Gemini, Bing) as brainstorming tools; perceived usefulness, creativity, and user-friendliness; perceived challenges such as difficulty interpreting AI ideas, concerns about plagiarism/ethical issues, lack of control over output, overreliance on AI, and difficulty integrating AI ideas into writing; perceived facilitative factors such as increased idea generation, enhanced creativity, overcoming writer’s block, exposure to diverse perspectives, and collaborative brainstorming experiences; lecturers’ attitudes toward AI brainstorming as supplementary versus primary tool.",
		"cognitive_aspect_measure (认知因素测量工具)": "Likert-scale questionnaire items and open-ended responses related to difficulty interpreting AI-generated ideas, difficulty integrating AI ideas into writing, and reflections on how AI output influenced idea development and critical thinking; thematic analysis of students’ and lecturers’ comments about depth, coherence, and development potential of ideas.",
		"cognitive_aspect_focus (认知因素维度_策略使用_元认知监控等)": "Learners’ perceived cognitive challenges and benefits in using AI brainstorming tools, including difficulty interpreting and evaluating AI-generated ideas, integrating AI content into coherent written texts, and concerns that overreliance on AI might hinder independent critical thinking and creativity; perceived support for considering new angles, thinking outside the box, and expanding idea diversity in the brainstorming phase.",
		"behavioral_aspect_measure (行为因素测量工具_日志_平台日志等)": "Self-reported questionnaire data on which AI chatbots were used (ChatGPT, Gemini, Bing) and percentages of users for each; open-ended responses describing usage patterns and interaction experiences; no system log data were reported.",
		"behavioral_aspect_focus (行为因素维度_使用频率_交互模式_坚持度等)": "Self-reported use and preference patterns for specific AI chatbots (ChatGPT most used, followed by Gemini and Bing); reported interaction styles when brainstorming (asking AI for examples, generating ideas, exploring perspectives, bouncing ideas back and forth like a conversation); no explicit measures of frequency, duration, or persistence over time beyond assignment-related use.",
		"other_outcomes_measure (其他结果测量工具)": "Foreign English lecturers’ written feedback notes on AI-generated versus student-generated brainstorming results analyzed via content/thematic analysis; thematic summaries of perceived novelty, creativity, depth and development, language use, and feedback potential.",
		"other_outcomes_focus (其他结果维度说明)": "Lecturers’ perceptions that AI brainstorming provided highly novel, imaginative, and unconventional ideas and polished language but sometimes lacked coherence or relevance; preference for students’ brainstorming for deeper, more nuanced, and more development-ready ideas; recognition of AI outputs as valuable for modeling, comparison, and feedback discussions; perceived potential of AI brainstorming to enhance classroom dialogue about writing and ideas.",
		"assessment_timepoints (评估时间点_前测_后测_延迟测等)": "Three course assignments assessed during the six-week intervention (People: week 2; Places: week 4; Things: week 6); a questionnaire administered at the end of the study; no separate pretest of writing performance and no delayed posttest or follow-up assessment reported.",
		"primary_outcome_variables (主要结果变量_因变量)": "Assignment scores (0–100) for three writing tasks (People, Places, Things) and their classification according to university criterion-referenced categories; group differences (AI vs conventional) in these scores; mean Likert ratings of perceived challenges (e.g., overreliance on AI, difficulty interpreting AI ideas) and facilitative factors (e.g., enhanced creativity, increased idea generation); proportions of students using each AI chatbot.",
		"independent_variables_and_factors (自变量与实验因素)": "Type of brainstorming instruction (AI-driven brainstorming tools vs traditional brainstorming techniques) as the main independent variable; assignment topic type (People, Places, Things) as repeated tasks; AI chatbot choice (ChatGPT, Gemini, Bing) as a descriptive variable in student preferences; no other experimental factors reported.",
		"followup_length_and_type (随访时长与类型)": "NA",
		"statistical_significance (统计显著性结果摘要)": "For the People assignment, the AI-driven group significantly outperformed the conventional group (M = 82.5, SD = 6.7 vs M = 77.2, SD = 7.4), t(84) = 3.21, p = .002; for the Places assignment, there was no statistically significant difference between AI-driven (M = 79.8, SD = 5.9) and traditional (M = 77.6, SD = 6.2) groups, t(84) = 1.62, p = .11; for the Things assignment, the AI-driven group again significantly outperformed the conventional group (M = 85.3, SD = 5.1 vs M = 80.1, SD = 6.8), t(84) = 3.78, p = .001. Means for perceived challenges and facilitative factors were interpreted using Likert (1932) criteria, with overreliance on AI for idea generation rated as the most challenging (M = 4.62, SD = 0.44), difficulty interpreting AI-generated ideas as very challenging (M = 3.75, SD = 0.71), and enhanced creativity (M = 4.53, SD = 0.79) and increased idea generation (M = 4.51, SD = 0.93) rated as the highest facilitative factors.",
		"effect_size_summary (效应量摘要)": "Effect sizes (e.g., Cohen’s d) for group differences on assignment scores and for questionnaire items were not reported.",
		"llm_misuse_or_negative_effects (LLM滥用或负向效应)": "Students reported several concerns related to AI chatbot use, notably overreliance on AI for idea generation (M = 4.62, SD = 0.44), which they feared could hinder the development of their own critical thinking and creativity skills; difficulty interpreting AI-generated ideas (M = 3.75) due to content that was off-topic, incoherent, or nonsensical; concerns about plagiarism and ethical issues (M = 3.28), including worries about unintentionally plagiarizing AI-generated content without realizing it; lack of control over AI output (M = 3.15) and difficulty integrating AI ideas into their own writing (M = 2.96). Lecturers also noted that while AI generated novel and polished ideas, some outputs lacked coherence or relevance to prompts. The discussion and conclusion emphasize that AI brainstorming tools should be used as supplementary resources, with explicit guidance to use AI suggestions as inspiration rather than final content and to critically assess AI-generated ideas to avoid plagiarism and overdependence.",
		"equity_and_subgroup_effects (公平性与亚组差异)": "NR (no subgroup analyses by gender, proficiency level, or other demographic variables, and no explicit discussion of equity-related effects were reported).",
		"limitation (研究局限)": "The study was limited to third-year Thai university students (student teachers in a single Bachelor of Education English program) at one EFL public university in Bangkok, with a relatively small sample size (N = 86); the context specificity and sample size limit the generalizability of findings. The design did not include a pretest of writing performance or a delayed posttest, so long-term effects and baseline equivalence in writing ability could not be fully assessed. Findings are tied to one course (Academic Writing for English Language Teaching) and the specific implementation of AI-driven brainstorming tools.",
		"challenge (实施挑战与风险)": "Implementation challenges and risks highlighted include the potential for students to become overreliant on AI chatbots for idea generation, which may undermine independent thinking and creativity; students’ difficulty in interpreting and evaluating AI-generated ideas, especially when content is irrelevant or incoherent; concerns about plagiarism and ethical use of AI-generated text; lack of control over AI output and challenges in integrating AI ideas seamlessly into their own writing; and the pedagogical need for teachers to adjust instructional approaches, manage mixed reactions to AI-assisted writing, and provide guidance for responsible and critical use of AI brainstorming tools.",
		"future_work (未来研究方向)": "Future research should explore the effectiveness of AI-driven brainstorming tools in more diverse educational settings (different institutions, countries, and learner populations) and with larger sample sizes to improve generalizability; examine how AI brainstorming tools perform across different proficiency levels and disciplines; investigate longer-term effects with delayed posttests; and further develop pedagogical strategies to balance AI assistance with the cultivation of students’ independent thinking, creativity, and ethical AI use.",
		"implication (理论与教学实践启示)": "The study suggests that integrating AI-driven brainstorming tools such as ChatGPT, Gemini, and Microsoft Bing into process writing instruction can enhance students’ writing outcomes and creativity, particularly when used as supplementary resources alongside traditional brainstorming techniques. For practice, teachers are encouraged to incorporate AI brainstorming to boost idea generation and engagement, while explicitly guiding students on critical evaluation of AI outputs, preventing plagiarism, and maintaining originality; to facilitate classroom discussions that compare AI-generated and student-generated ideas to deepen understanding and foster idea development; and to consider students’ preferences and needs when selecting AI chatbots for brainstorming activities. Theoretically, the findings contribute to the understanding of AI integration in process writing, highlighting AI chatbots’ role in early-stage idea generation and the need to balance technological affordances with the development of independent thinking and creativity."
	},
	"Study Quality and Reporting": {
		"funding_source (经费来源)": "NR",
		"conflict_of_interest (利益冲突声明)": "NR",
		"risk_of_bias_randomization (偏倚风险_分配与随机化)": "Groups were based on intact course sections (Section D1 as conventional and Section D2 as AI-driven), with purposive selection of participants; no randomization at the individual or class level was reported, which may introduce selection bias and baseline non-equivalence.",
		"risk_of_bias_blinding (偏倚风险_盲法)": "Foreign English lecturers who graded assignments were not informed whether brainstorming results were AI-generated or student-generated, reducing grading bias; however, participants and the instructor were aware of group conditions, and there was no blinding for questionnaire or qualitative data collection.",
		"attrition_and_missing_data (流失与缺失数据处理)": "NR (the article reports 86 participants divided into two groups and does not describe attrition, dropout, or handling of missing data; N appears constant across analyses).",
		"reporting_transparency (报告透明度与可重复性)": "The study clearly reports context, participant numbers, group sizes, course information, intervention description (traditional vs AI-driven brainstorming), assignment structure and topics, questionnaire source and validation process, main statistical analyses (means, SDs, t-tests, p-values), and qualitative analysis procedures and themes; detailed scoring rubrics, reliability indices for questionnaires, and some implementation specifics (e.g., timing of AI use relative to class sessions) are not fully specified.",
		"preregistration_or_protocol (预注册或研究方案)": "NR",
		"llm_version_reproducibility (LLM版本与可复现性)": "The article identifies the AI chatbots used (ChatGPT, Gemini, Microsoft Bing Chat) but does not report specific model versions, configuration parameters, or exact time frames of access, which limits precise reproducibility given evolving LLM behavior.",
		"baseline_equivalence (基线等同性检验)": "No pretest of writing performance is reported and no statistical tests of baseline equivalence between the AI and conventional groups are provided; both groups are described as third-year B.Ed. English majors enrolled in the same academic writing course, but comparability on prior writing ability is not formally assessed.",
		"assumption_check_and_data_diagnostics (统计假设检验与数据诊断)": "The study used independent samples t-tests for group comparisons but does not report checks of normality, homogeneity of variance, or other diagnostic statistics; no mention is made of data transformation or correction for violations of assumptions.",
		"outlier_treatment_and_sensitivity_analysis (异常值处理与稳健性分析)": "NR (no procedures for detecting or handling outliers and no sensitivity or robustness analyses were described).",
		"data_preprocessing_and_transformation (数据预处理与转换)": "Assignment scores (0–100) were summarized as means and standard deviations and interpreted using the university’s criterion-referenced categories; Likert-scale questionnaire responses on challenges and facilitative factors were averaged to obtain mean scores and standard deviations for each item and interpreted using Likert (1932) criteria; no additional preprocessing or data transformation procedures are reported."
	}
}