Title,Year,Decision,Notes
"Ai-driven Language Learning in Higher Education: an Empirical Study on Self-reflection, Creativity, Anxiety, and Emotional Resilience in Efl Learners",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 205 English as a Foreign Language (EFL) undergraduate learners from Chinese universities, clearly fitting an EFL/ESL/ELL context with English as the target language.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers broadly to \u201cAI-powered feedback\u201d (grammar/vocabulary corrections, motivational feedback) but does not specify that these tools are large language model\u2013based (e.g., ChatGPT, GPT-4). They could be traditional NLP/grammar-checking systems. No explicit mention of LLMs or transformer-based generative models is made.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although writing is mentioned (enjoyment in writing and speaking), the primary focus is on self-reflection, creativity, anxiety, and emotional resilience. The study does not frame itself as a writing competence intervention; it examines psychological and affective variables rather than writing performance or writing-related skill development as the main outcome.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported are self-reflection, creativity, anxiety reduction, and emotional resilience. There is no indication of quantifiable writing performance metrics (e.g., writing scores, text quality measures) used to assess the effectiveness of AI-mediated writing intervention.""}}"
From Algorithms to Annotations: Rethinking Feedback Practices in Academic Writing through Ai-human Comparison,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study focuses on Malaysian L2 students in an English for Academic Purposes (EAP) setting, explicitly described as L2 writers of academic introductions in English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is involved, the design is a comparative analysis of feedback characteristics (epistemic strategies and delivery methods) from ChatGPT vs. instructors on existing texts. There is no experimental or quasi-experimental instructional intervention integrating ChatGPT into a writing course or process.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on the nature of feedback (assertiveness, mitigation, monologic vs. dialogic) and AI\u2013human comparison, not on a pedagogical intervention aimed at improving writing competence. It is essentially a discourse/feedback analysis rather than an instructional study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics (e.g., changes in writing quality, scores, accuracy) resulting from ChatGPT-mediated intervention. It only analyzes and compares feedback styles, with no measured impact on learners\u2019 writing performance.""}}"
The Role of Ai Assisted Writing Feedback in Developing Secondary Students Writing Skills,2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as secondary-level EFL students, specifically 60 Turkish high school students. This clearly indicates L2 English learners in an EFL context, with outcomes focused on English writing skills.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The intervention is described as feedback from an 'AI writing assistant' but the abstract does not specify whether this tool is an LLM (e.g., ChatGPT, GPT-4) or a non-LLM AI tool (e.g., rule-based or traditional NLP). Without explicit indication that a transformer-based generative model is used, it is not possible to confirm it meets the LLM criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on developing writing skills: students wrote multiple essays, and the study examines the impact of AI-assisted writing feedback on overall writing performance and subcomponents (grammar, vocabulary, coherence). This is clearly a writing competence intervention, not automated scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses pre-test and post-test writing assessments and reports significant improvement in overall writing performance and specific dimensions (grammar, vocabulary, coherence) for the experimental group. These constitute quantifiable writing outcome metrics.""}}"
Chatgpt-generated Versus Human Direct Corrective Feedback on L2 Writing,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are second-year English Pedagogy students at a Chilean university, i.e., L2 English learners in an EFL/ESL context. The study explicitly concerns L2 essay writing in English.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention compares direct written corrective feedback delivered by ChatGPT (an LLM) versus a human teacher. Students were randomly assigned to ChatGPT or teacher feedback conditions over four sessions, indicating an experimental design integrating an LLM into writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on L2 essay writing and written corrective feedback. Outcomes are writing-related dimensions: task response, cohesion and coherence, lexical resource, and grammatical range and accuracy. This is a pedagogical intervention, not an automated scoring study.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports that both feedback sources significantly enhanced writing development and that ChatGPT was superior across assessed criteria. These criteria (task response, cohesion/coherence, lexical resource, grammatical range/accuracy) are quantifiable writing outcome measures used to evaluate intervention effectiveness.""}}"
Efl Students’ Writing Engagement and Ai Attitude in Genai-assisted Contexts: a Mixed-methods Study Grounded in Sdt and Tam,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL learners in GenAI-assisted writing contexts, clearly indicating L2 English learners in an EFL setting.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines engagement profiles and attitudes toward GenAI and reports that few teachers have actively integrated such tools into their teaching. There is no indication of a structured experimental or quasi-experimental LLM-based writing intervention; GenAI use appears to be contextual/background rather than a designed instructional treatment.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on writing engagement in GenAI-assisted contexts, which is a writing-related variable within EFL learning and teaching.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are engagement profiles and attitudes, not quantifiable writing performance or competence measures. The study does not assess the effectiveness of GenAI on writing quality or other writing outcome metrics.""}}"
Examining Language Learners’ Genai-assisted Writing Self-efficacy Profiles and the Relationship with Their Writing Self-regulated Learning Strategies,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are explicitly described as English-as-a-foreign-language (EFL) learners, i.e., L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the study concerns GenAI-assisted writing, the abstract does not describe an experimental or quasi-experimental instructional intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction. Instead, it analyzes learners\u2019 self-efficacy profiles and SRL strategies related to GenAI use, without indicating a designed treatment or controlled instructional use of an LLM.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on motivational constructs (GenAI-assisted writing self-efficacy profiles and writing self-regulated learning strategies), not on writing competence or writing-related performance variables. The study is about psychological profiles in a GenAI context rather than a pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, text quality measures) are reported. Outcomes are self-efficacy profiles, SRL strategy use, and antecedents such as years of English learning and perceived proficiency, which are not direct writing performance measures.""}}"
"Effects of Three Levels of Ai Integration on Second Language Academic Writing: Evaluating Restricted, Guided, and Free Use of Chatgpt",2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Korean college students in English essay writing courses, explicitly described as L2-English learners. The focus is on English academic writing, fitting ESL/EFL/ELL L2 English contexts.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention manipulates three levels of ChatGPT use (Restricted, Guided, Free) as instructional tools in writing courses. ChatGPT is a large language model, and the design is quasi-experimental with comparison groups.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is academic English essay writing. The study examines how different levels of AI (ChatGPT) integration affect writing instruction and learning outcomes, not just system performance or scoring.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcomes: essay scores and sub-dimensions (content quality, organization, language use) comparing groups. These metrics are used to evaluate the effectiveness of the LLM-mediated writing intervention.""}}"
Exploring Second Language Writers’ Engagement with Chatgpt Feedback: Revision Behaviors and Perceptions,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 25 B1-level English as a Foreign Language (EFL) students at a university in T\u00fcrkiye, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study explicitly investigates EFL writers\u2019 engagement with ChatGPT feedback on their opinion essays. ChatGPT is a large language model integrated into the writing process as a feedback tool.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on L2 writing: revision behaviors in response to ChatGPT feedback on opinion essays, and perceptions of its effectiveness for writing improvement. This is directly tied to writing development rather than automated scoring.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports descriptive and thematic analyses of revision behaviors (acceptance/rejection patterns, types of revision operations) and perceptions from questionnaires and interviews. It does not indicate any quantifiable pre/post or comparative writing outcome measures (e.g., writing scores, quality ratings) assessing effectiveness of the intervention; the focus is on process and perceptions, not measured gains in writing performance.""}}"
Empowering Students' Autonomy in Efl Learning: Ai Innovations in Schools of the Global South,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract focuses on English as a Foreign Language (EFL) learning in schools across the Global South, which fits the target population of L2 English learners in EFL/ELL contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""This is a PRISMA-guided systematic review synthesizing 22 empirical studies on AI in EFL learning. It does not itself implement an experimental or quasi-experimental LLM-based intervention; rather, it is a secondary review article, which is excluded by the protocol.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on student autonomy in EFL learning broadly (speaking, reading, writing, listening, vocabulary) and AI-supported autonomy, not specifically on writing competence or writing-related variables as the central outcome.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a systematic review, it does not report original experimental writing outcome metrics from a specific LLM-mediated intervention; instead, it synthesizes diverse AI uses and focuses on autonomy, context, and implications.""}}"
"Negotiating Understanding, Control, and Authorship: L2 Learners’ Experiences with Ai-assisted Paraphrasing in Academic Writing",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are twelve English-as-a-foreign-language (EFL) students at a Chinese university, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the study involves AI tools for paraphrasing, the abstract does not specify that these are large language model\u2013based tools (e.g., ChatGPT, GPT-4). It generically refers to \u201cAI tools\u201d and focuses on how students use them, not on an experimental or quasi-experimental LLM-based instructional intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on learners\u2019 experiences and interactions with AI-assisted paraphrasing, not on a structured pedagogical intervention targeting writing competence. It is an interview-based qualitative exploration rather than an intervention study of writing instruction or processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is purely qualitative, based on interviews and thematic analysis. No quantifiable writing outcome metrics or experimental measures of writing performance are reported.""}}"
"Exploring L2 Writing Motivation in Ai-mediated Efl Contexts: the Role of Teacher Affective Support, Ai Literacy, and Self-efficacy through the Lens of Self-determination Theory",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 627 Chinese university students in an EFL context, focusing on L2 (English) writing motivation in AI-mediated environments.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is situated in an AI-mediated context but does not specify any particular LLM-based tool (e.g., ChatGPT, GPT-4) nor describe an experimental or quasi-experimental LLM-integrated writing intervention. It is a correlational/structural model study based on questionnaires.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on L2 writing motivation and its predictors (teacher affective support, AI literacy, self-efficacy) rather than on writing competence or writing-related performance variables. It is motivational, not a writing instruction or performance intervention study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are questionnaire-based measures of motivation, AI literacy, self-efficacy, and teacher affective support. No quantifiable writing performance or competence metrics are reported to assess the effectiveness of an LLM-mediated writing intervention.""}}"
The Psychology of Pedagogical Compromise: Written Corrective Feedback in Chinese Efl Writing through an Ecological Systems Lens,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Chinese university EFL (English as a Foreign Language) students and teachers, clearly situated in an EFL context with English as the target language.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention concerns types of written corrective feedback (selective, comprehensive, minimal) delivered by teachers. There is no mention of large language models, ChatGPT, or any transformer-based generative AI being integrated into writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on writing competence, specifically writing accuracy and feedback practices in EFL writing, examined through an ecological systems lens.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Quantitative results are reported (e.g., F = 15.61, p < .001, d = 1.08) showing effects of different feedback types on students\u2019 writing accuracy and satisfaction, indicating measurable writing outcomes.""}}"
Threshold-triggered Dual Effects in Ai-assisted Efl Writing: Self-efficacy Modulates Grammar Learning Pathways,2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study explicitly concerns EFL learners (\u201crevolutionizing EFL grammar instruction,\u201d \u201cEast Asia\u2019s enduring EFL dilemma\u201d), indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cArtificial intelligence writing tools\u201d and \u201cAI-assisted EFL writing,\u201d but does not specify that these tools are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems. They could be other forms of AI grammar tools. Thus, it is unclear whether an LLM is the core intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on grammar instruction and grammatical competence (\u201cEFL grammar instruction,\u201d \u201cgrammatical competence growth/erosion\u201d), not on writing competence or writing-related variables as the main outcome. Writing is mentioned only as a context (\u201cAI-assisted EFL writing\u201d), while the measured construct appears to be grammar learning rather than writing performance.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable outcomes related to grammatical competence (e.g., a self-efficacy threshold T=3.278, 60.32% showing regression), indicating experimental or quasi-experimental measures of learning outcomes, even though these are grammar-focused rather than writing-focused.""}}"
A Student-centered Framework for Understanding Efl Thesis Writing Difficulties in Vietnam,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Vietnamese English as a Foreign Language undergraduate students writing theses in English, clearly fitting an EFL L2 English learner context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although AI tools are mentioned as part of the support systems and in relation to institutional policies on AI integration, there is no indication of an experimental or quasi-experimental design integrating LLMs (e.g., ChatGPT) into writing instruction or processes. The study is qualitative and exploratory, not an LLM-based intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on understanding thesis writing difficulties and support systems broadly (including supervisors, peers, family, institutional services, and AI tools), not on a specific LLM-mediated writing intervention or pedagogy.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses qualitative semi-structured interviews and thematic analysis, with no quantifiable writing outcome metrics or experimental measures of the effectiveness of AI/LLM-mediated writing support.""}}"
Feedback Literacy and Efl Learner Engagement with Chatgpt Feedback: Predicting Feedback Uptake and Perceived Usefulness,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 51 Chinese university students in EFL writing, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses ChatGPT, a large language model, to provide feedback on three ChatGPT-supported writing assignments, integrating it into the writing process.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is EFL writing with a focus on engagement with ChatGPT-generated feedback and feedback uptake in writing assignments, which is directly writing-related.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are feedback uptake (behavioral adoption of feedback) and perceived usefulness, analyzed via regression and mediation. The abstract does not indicate any quantifiable writing performance outcomes (e.g., writing quality scores, accuracy, complexity). The focus is on engagement and perceptions, not measured changes in writing competence.""}}"
Exploring Sentence-level Revision Capabilities of Large Language Models in English for Academic Purposes Writing Assistance,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions challenges for non-native English speakers in English for Academic Purposes, but it does not state that there are human participants, learners, or any educational setting. It appears to be a system-level evaluation of LLMs rather than a learner study.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study \u2018rigorously assess[es] the performance of LLMs in the Sentence-level Revision (SentRev) task\u2019 via three sets of experiments on LLM behavior. There is no indication of an instructional or quasi-experimental pedagogical intervention with learners; it is an NLP evaluation of LLM capabilities.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the context is EAP writing assistance and sentence-level revision, the focus is on benchmarking LLM performance and evaluation methods, not on improving learner writing competence through an instructional intervention. It is a tool/benchmark study rather than a pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The experiments report LLM performance metrics on SentRev and GEC tasks, not quantifiable writing outcomes for L2 learners. No learner writing scores, gains, or writing-related outcome measures from an intervention are described.""}}"
A Multi-stage Interactive Writing Task for the Assessment of English Language Writing Proficiency,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to an assessment of English language writing proficiency but does not specify that participants are L2 English learners (ESL/EFL/ELL). They could be native or mixed populations; the population type is not stated.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""A large language model is used to automatically analyze responses and generate customized follow-up prompts, but this is within a testing/assessment system, not an instructional or pedagogical intervention. There is no experimental or quasi-experimental design integrating LLMs into writing instruction or learning processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on developing and validating an innovative interactive writing assessment task and examining fairness and validity. The LLM is used for theme detection and prompt customization in a high-stakes test context, not for improving writing competence through instruction or feedback.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although scores and response relevance are discussed, they are used to validate an assessment design rather than to evaluate the effectiveness of an LLM-mediated writing intervention. There is no structured pedagogical intervention with pre/post or comparative writing outcome measures aimed at improving learners\u2019 writing.""}}"
Integrating Move Analysis and Sentence Reconstruction in Automated Writing Evaluation for L2 Academic Writers,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cL2 academic writers\u201d and \u201clearners,\u201d implying L2 English users in academic writing, but it does not explicitly specify ESL/EFL/ELL participants or any concrete learner sample; the focus is primarily on system development and evaluation, not on a defined learner population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although GURUS uses transformer-based LLMs and is framed as an AWE system for academic writing, the study described is about system training and performance evaluation (classification, reconstruction) rather than an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction with learners as participants.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on developing and validating an AWE system (classification performance, sentence reconstruction quality). While the paper discusses potential instructional use, the reported study centers on system functionality, not on an implemented writing intervention or measured impact on learners\u2019 writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are system-level metrics (F1-score, Brier score, BERTscore, human assessment of reconstructed sentences), not quantifiable pre/post or comparative writing performance measures for L2 learners following an LLM-mediated intervention.""}}"
Examining the Consistency of Instructor Versus Large Language Model Ratings on Summary Content: Toward Checklist-based Feedback Provision with Second Language Writers,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Japanese undergraduate students producing learner-generated summaries in an L2 writing instruction context in Japan, indicating EFL/L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines consistency between instructor ratings and LLM-estimated ratings under different prompts. The LLM is used as an automated rater, not as part of an experimental or quasi-experimental pedagogical intervention in writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on rating consistency and prompt design for LLM-based assessment of summary content, not on an instructional intervention to improve writing competence. It is essentially an evaluation of LLM functionality as an automated scoring/feedback system.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No experimental or quasi-experimental intervention with pre/post or comparative writing outcome measures is reported. The study analyzes agreement between human and LLM ratings, not the effectiveness of LLM-mediated writing instruction on learners\u2019 writing performance.""}}"
"Evaluating Generative Ai Tools for Improving English Writing Skills: a Preliminary Comparison of Chatgpt-4, Google Gemini, and Microsoft Copilot",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are B+ level English as a Foreign Language (EFL) students at a preparatory school in T\u00fcrkiye, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the study uses LLM-based tools (ChatGPT-4, Gemini, Copilot), the design compares the tools\u2019 performance and student preferences rather than implementing an experimental or quasi-experimental pedagogical intervention that measures changes in learners\u2019 writing performance attributable to LLM use.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on opinion essay writing, with tools used for brainstorming, outlining, and feedback in EFL writing instruction, so the primary context is writing competence and writing-related processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Rubric-based evaluations are applied to the tools\u2019 outputs (idea generation, structuring, feedback actionability), not to students\u2019 own writing development over time. The abstract does not report quantifiable learner writing outcome metrics (e.g., changes in essay scores pre/post intervention), but rather comparative tool performance and perceptions.""}}"
