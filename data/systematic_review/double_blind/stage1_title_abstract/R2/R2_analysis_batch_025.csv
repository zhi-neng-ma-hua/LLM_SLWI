Title,Year,Decision,Notes
Postgraduate Students' Attitude Toward Using Chatgpt in Enhancing Their Master's Thesis: a Mixed Method Study,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as postgraduate EFL learners, indicating they are L2 English learners in an EFL context and the focus is on English thesis writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is central, the study is not an experimental or quasi-experimental intervention. It investigates students\u2019 attitudes and self-reported uses of ChatGPT rather than implementing and testing a structured LLM-mediated instructional intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on enhancing the quality of Master\u2019s thesis writing, including content, structure, grammar, and citation, which are core writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses semi-structured interviews and a questionnaire to explore attitudes and perceived benefits. There is no indication of quantifiable pre/post or comparative writing performance measures assessing the effectiveness of ChatGPT on writing outcomes.""}}"
Enhancing Argumentative Essay Skills: Evaluating the Efficacy of Ai-powered Tools Versus the Traditional Approach among Learners,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly refers to \u201csecond language (L2) learners\u201d and focuses on teaching argumentative essay writing, which is typically in English in such contexts, though the specific language is not named. This is reasonably consistent with an L2 English learner population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses \u201cAI-powered writing tools like Quill Bot, Jeni AI, and others.\u201d QuillBot is not an LLM-based pedagogical tool in the sense required (it is primarily a paraphrasing/rewriting tool and not framed here as an LLM such as ChatGPT, GPT-4, Gemini, etc.). The abstract does not indicate that any large language model is being integrated; it only mentions generic AI tools, which fall outside the specified LLM-focused scope.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study\u2019s primary focus is on teaching and improving argumentative essay writing skills (\u201cmentoring students to write argumentative essays,\u201d \u201cimproved writing competency and the long-term retention of argumentative writing abilities\u201d), which aligns with writing competence as the central outcome.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study is described as a quasi-experimental design with experimental and control groups, and it reports that integration of AI-driven tools with conventional methods \u201csignificantly improved writing competency and the long-term retention of argumentative writing abilities,\u201d implying quantitative outcome measures of writing performance over a semester.""}}"
Leveraging Llm-based Chatbots for Interactional Grammar Feedback in L2 Writing: Opportunities and Challenges,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 89 second-year pre-service teachers at a university of education in South Korea who wrote English essays, indicating an EFL/L2 English context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The title and abstract state the study uses an \u2018LLM-based chatbot\u2019 and references ChatGPT, suggesting an LLM intervention. However, details on whether the chatbot is actually powered by a large language model (vs. rule-based or template-based) are not explicit in the abstract.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on L2 writing instruction and grammar feedback on students\u2019 English essays, framed as \u2018interactional writing feedback for L2 writing instruction\u2019 in classrooms.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports that the chatbot \u2018offers several advantages as a feedback provider\u2019 and could be a complementary resource, but it does not mention any quantitative writing outcome measures (e.g., gains in writing accuracy, scores, or other measurable writing performance). The emphasis appears to be on showcasing practice and perceived advantages rather than experimentally measured writing outcomes.""}}"
Chinese Efl Learners’ Genai Literacy in Digital Multimodal Composing and Self-regulated Writing: Chain Mediation Effects of Needs Satisfaction and Creative Self-concept,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as 634 Chinese EFL learners, i.e., L2 English learners in an EFL context, satisfying the population criterion.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines students\u2019 GenAI literacy in digital multimodal composing via questionnaires and structural equation modeling. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes; it is a correlational/mediation study of literacy, not an LLM-based instructional intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is EFL writing, focusing on digital multimodal composing and self-regulated writing, which are writing-related constructs rather than automated scoring or system evaluation.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are self-report measures (GenAI literacy, needs satisfaction, creative self-concept, self-regulated writing) analyzed via SEM. The abstract does not report quantifiable writing performance outcomes or effectiveness of an LLM-mediated writing intervention; it focuses on psychological/behavioral constructs rather than measured writing quality or competence.""}}"
Artificial Intelligence Vs. Instructor Supported Ai: Teaching Second Language Writing Via “write&improve”,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study investigates second language writing, focusing on students\u2019 English writing success, self-efficacy, and related variables. This implies participants are L2 English learners in an ESL/EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses the Cambridge Write&Improve system. While it is an AI-based automated writing evaluation tool, it is not described as a large language model (e.g., ChatGPT/GPT-4-type transformer-based generative model). The abstract frames it as an AI feedback system, not an LLM-based generative tool integrated into instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on second language writing competence and related constructs (writing success, self-efficacy, achievement emotions, teacher-student interaction) within an instructional context using AI-supported feedback.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses an 8-week pretest-posttest control group design and reports statistically significant increases in English writing success and other quantifiable outcomes, indicating measurable writing-related effects of the intervention.""}}"
"International Conference on Artificial Intelligence and Networks, Icain 2024",2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract is for a conference proceedings volume listing many diverse papers. One title mentions EFL teachers and another mentions Indonesian higher education, but no specific participant details (e.g., L2 English learners) are provided for any individual study.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The proceedings description does not specify any experimental or quasi-experimental integration of large language models (e.g., ChatGPT, GPT-4) into writing instruction. One listed paper is about \u2018AI-Enhanced Writing Instruction\u2019 but the abstract provides no indication that LLMs specifically are used, nor any design details.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""Among the 50 papers, only one title clearly relates to writing (\u2018EFL Teachers\u2019 Inquisitive Agency in AI-Enhanced Writing Instruction\u2019). However, the overall proceedings focus is broad AI and networks, not specifically writing competence, and no information is given about the pedagogical or writing-focused nature of that individual study.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The proceedings abstract does not report any quantifiable writing outcome metrics. It only lists paper titles without methodological or results information, so it is impossible to confirm the presence of experimental writing outcome measures for any included study.""}}"
"Ai-assisted Academic Writing in a Blended Efl Setting: Practices and Perceived Effectiveness at Fpt University, Hanoi",2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are first-year EFL students at FPT University Hanoi, clearly indicating L2 English learners in an EFL context, with outcomes reported in terms of IELTS writing scores (English).""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study involves AI tools including ChatGPT, QuillBot, and DeepSeek for writing support. ChatGPT and DeepSeek are LLMs, but QuillBot may or may not be LLM-based depending on version, and the abstract does not specify which tools were central to the intervention or how systematically LLMs (as opposed to generic AI tools) were integrated in an experimental or quasi-experimental design.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on academic writing in an EFL setting, examining how AI tools are used for idea generation, grammar correction, and content refinement, and discussing AI\u2019s pedagogical potential in EFL writing instruction. This aligns with writing competence and writing-related variables, not automated scoring.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcomes: writing scores improved by an average of 0.94 IELTS band scores, based on 45 paired writing samples. This indicates measurable effects of AI-assisted writing use, alongside qualitative perceptions.""}}"
Large Language Model-driven Dynamic Assessment of Grammatical Accuracy in English Language Learner Writing,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions 'learners of English' and 'English Language Learner writing', suggesting an ELL context, but it does not specify that participants are L2 English learners in ESL/EFL/ELL settings, nor does it clearly describe an actual learner sample versus simulated input.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study develops DynaWrite and tests 21 LLMs (with focus on GPT-4o and neural-chat) for their ability to provide dynamic assessment feedback and identify grammatical errors. The focus is on system performance and model comparison, not on an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction with learners.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on LLM-driven dynamic assessment capabilities (error detection, hint quality, responsiveness, stability), not on improving writing competence or writing-related learner outcomes. It evaluates tool functionality rather than a teaching/learning intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable learner writing outcome metrics are reported. The outcomes concern model accuracy in error identification, quality of hints, and system performance, not changes in learners\u2019 writing performance following an LLM-mediated intervention.""}}"
Prompt Engineering as Mediation: Investigating Ai Chatbot-assisted Writing Process from an Activity Theory Perspective,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as Chinese EFL undergraduates, i.e., L2 English learners in an EFL context, with a focus on English expository writing tasks.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to an \u201cAI chatbot\u201d and \u201cchatbot-supported expository writing tasks,\u201d but does not specify that the chatbot is an LLM (e.g., ChatGPT/GPT-4) or a transformer-based generative model. It could be any AI chatbot, so LLM use cannot be confirmed from the abstract alone.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly EFL expository writing, focusing on how prompt engineering mediates chatbot-assisted writing processes and outcomes, which aligns with writing competence and writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although the abstract mentions that prompt engineering shapes \u201cwriting outcomes,\u201d it does not indicate any experimental or quasi-experimental design, comparison groups, or quantifiable writing outcome metrics. The study appears primarily qualitative (logs, artifacts, interviews) and theoretical, without measured intervention effects.""}}"
The Role of Artificial Intelligence in Writing Assessment: Learner Perceptions and System Effectiveness,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions 'learners of varying educational levels' but does not specify that they are L2 English learners in ESL/EFL/ELL contexts. Their language background and whether English is an L2 is not stated.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study focuses on AI-driven writing tools such as Grammarly and Turnitin, which are not described as large language model (LLM)-based generative systems. There is no mention of ChatGPT, GPT-4, or other LLMs, nor of an experimental or quasi-experimental LLM-based instructional intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on writing assessment, learner perceptions, and system effectiveness (accuracy, fairness, clarity of feedback), not on a pedagogical writing intervention or instructional integration of LLMs. It evaluates an assessment tool rather than a structured teaching/learning intervention in writing.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract reports that regular usage 'significantly enhances writing skills, particularly in grammar,' but does not specify concrete, quantifiable writing outcome measures (e.g., pre/post test scores, rubric-based writing quality metrics). It is unclear whether rigorous experimental outcome data on writing performance were collected.""}}"
The Potential Advantages of Using an Llm-based Chatbot for Automated Writing Evaluation for English Teaching Practitioners,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Korean high school EFL students, i.e., L2 English learners in an EFL context: \u201cnarrative essays written by Korean high school EFL students.\u201d""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study develops an AWE chatbot based on ChatGPT 4.0-turbo and uses it as an automated rater. There is no experimental or quasi-experimental pedagogical intervention integrating the LLM into writing instruction or learners\u2019 writing processes; it is a tool validation study.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on the chatbot\u2019s scoring reliability and alignment with human raters: \u201cthese were then compared with the scores administered by two professional raters using various analytic measures.\u201d This is an automated essay scoring validation study, not a writing competence intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although writing scores are analyzed, they are used only to evaluate the AWE chatbot\u2019s rating performance, not to assess the effectiveness of an LLM-mediated writing intervention. No pre/post or comparative instructional outcomes are reported.""}}"
Development and Validation of a Multidimensional Chatgpt Feedback Engagement Scale in Second Language Writing,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to 'second language (L2) writing' and 'students' but does not specify that the target language is English or that participants are ESL/EFL/ELL learners. The L2 could be any language.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is present, but the study focuses on developing and validating a 'ChatGPT Feedback Engagement Scale.' There is no indication of an experimental or quasi-experimental pedagogical intervention integrating ChatGPT into instruction; instead, it is a psychometric scale development study.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on engagement with ChatGPT feedback (cognitive, behavioral, emotional, ethical) and scale validation, not on improving writing competence or systematically intervening in writing processes for instructional purposes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, text quality measures) are reported. Outcomes are engagement dimensions and psychometric properties of the scale, not changes in writing performance following an LLM-mediated intervention.""}}"
Understanding How Ai Chatbots Influence Efl Learners' Oral English Learning Motivation and Outcomes: Evidence from Chinese Learners,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 351 EFL students in China learning spoken English with an AI chatbot, clearly fitting an EFL/ELL population focused on English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a questionnaire survey of students who already have experience using an AI chatbot; it does not describe an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT, GPT-4) into instruction. The chatbot type/architecture is unspecified and may not be an LLM, and there is no controlled instructional treatment.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on spoken/oral English learning, motivation, human likeness, self-efficacy, and social presence, not on writing competence or writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are modeled via SEM on motivation and related constructs; there is no mention of quantifiable writing outcomes or writing performance measures. The study concerns oral English learning, not writing.""}}"
A Qualitative Descriptive Study of Teachers' Beliefs and Their Design Thinking Practices in Integrating an Ai-based Automated Feedback Tool,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The context is Norwegian 9th-grade students learning English as a second language, taught by ESL teachers. The abstract explicitly mentions L2 writing and English as a second language teachers, indicating L2 English learners in an EFL/ESL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The tool is described as an 'AI-driven automated feedback tool, the Essay Assessment Technology (EAT)'. It is not specified whether EAT is based on a large language model (e.g., transformer-based generative model) or a more traditional automated essay scoring/feedback system. Thus, it is unclear if it qualifies as an LLM-based intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on teachers\u2019 beliefs, perceptions, user experiences, and pedagogical decisions when integrating an AI-based automated feedback tool. Although situated in L2 writing assessment, the study is framed as a qualitative descriptive exploration of teacher practices and design thinking, not as a writing competence intervention study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports a descriptive qualitative study using teacher interviews and focuses on beliefs, experiences, and instructional choices. There is no mention of quantitative writing outcome measures or experimental/quasi-experimental evaluation of students\u2019 writing performance.""}}"
Effects of Ai Chatbots on Efl Students' Critical Thinking Skills and Intrinsic Motivation in Argumentative Writing,2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were 40 Chinese undergraduates in an EFL context (\u201cintegrating AI chatbots into EFL classroom activities\u201d), so they are L2 English learners and the focus is on English argumentative writing.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The intervention uses an \u201cAI chatbot\u201d called Spark Desk in writing activities, but the abstract does not specify whether Spark Desk is an LLM-based, transformer generative model (e.g., similar to ChatGPT/GPT-4) or a different type of AI tool. Without confirmation that Spark Desk is an LLM, it is unclear if this meets the LLM criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is argumentative writing in an EFL classroom. The chatbot is integrated into writing activities, and outcomes include critical thinking skills in argumentative writing and intrinsic motivation related to writing. This aligns with a writing-focused pedagogical intervention rather than automated scoring.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""Quantitative outcomes are reported for critical thinking skills (using the Illinois Critical Thinking Essay Scoring Rubric) and intrinsic motivation. However, it is not explicit whether the rubric scores are treated as writing performance metrics or purely as CTS measures; no direct writing quality scores are clearly mentioned. Thus, it is uncertain whether there are quantifiable writing outcome metrics per se.""}}"
To Disclose or Not to Disclose: Exploring the Risk of Being Transparent about Genai Use in Second Language Writing,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly focuses on second language (L2) writers and L2 writing assessment, which aligns with the target population of L2 English learners in ESL/EFL/ELL-type contexts, though the specific target language is not stated but is implied to be English writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines the impact of disclosing GenAI use on teachers\u2019 grading, not an instructional intervention integrating LLMs into writing instruction or processes. There is no indication of an experimental or quasi-experimental pedagogical design where LLMs (e.g., ChatGPT) are systematically used as part of a writing intervention; GenAI use is only a contextual factor for assessment.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on how disclosure of GenAI use affects L2 writing assessment and teacher bias, not on improving writing competence or writing-related skills through LLM-mediated pedagogy. It is essentially an assessment/perception study rather than a writing intervention study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although the study reports quantitative differences in grades under different disclosure conditions, these are not outcomes of an LLM-based writing intervention aimed at improving writing. The GenAI tools are not manipulated as an instructional treatment; thus, the reported metrics do not assess the effectiveness of an LLM-mediated writing intervention.""}}"
Creating an Internationally Equitable Playing Field for Publishing in English-language Scholarly Journals,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The article discusses non-Anglophone authors in general, not specifically L2 English learners in ESL/EFL/ELL instructional contexts. It focuses on scholars publishing in English-language journals rather than language learners in educational settings.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""AI is mentioned only as a recommendation to facilitate translation. There is no experimental or quasi-experimental design, nor any concrete integration of LLMs (e.g., ChatGPT, GPT-4) into writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on equity in academic publishing and policy recommendations, not on writing competence or pedagogical writing interventions. It is a conceptual/policy piece rather than a study of writing instruction.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics or experimental measures are reported. The article offers recommendations and discussion without empirical assessment of writing outcomes.""}}"
Digital Literacy in the Age of Artificial Intelligence: Exploring Student Engagement with Automated Writing Evaluation (awe) Feedback,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract is situated in the context of L2 writing, but it does not specify the target language (e.g., English) or clearly identify the participants as ESL/EFL/ELL learners. It may be conceptual rather than empirical.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the title mentions AI and automated writing evaluation (AWE), the abstract describes a review and conceptual integration of digital literacy and student engagement, not an experimental or quasi-experimental intervention using an LLM (e.g., ChatGPT, GPT-4) in writing instruction. AWE tools are typically not LLM-based in this context, and no specific LLM is mentioned.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on theorizing digital literacy and student engagement in L2 writing, not on a concrete pedagogical intervention targeting writing competence or writing-related performance variables. It is more conceptual than intervention-focused.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics or experimental results are reported. The article appears to be a review/conceptual piece discussing models and constructs rather than measuring changes in writing performance following an LLM-mediated intervention.""}}"
Secondary School English Teachers' Application of Artificial Intelligence-guided Chatbot in the Provision of Feedback on Student Writing: an Activity Theory Perspective,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""Participants are 13 secondary school English teachers in China. The abstract does not specify the learners\u2019 L1 or explicitly state that the student writers are L2 English learners, though this is likely. However, the data and analysis focus on teachers\u2019 use of AI for feedback, not on learner outcomes.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses Kimi, an AI-guided chatbot, to support teacher feedback on student writing. Kimi may be an LLM-based tool, but the abstract does not explicitly identify it as a large language model (e.g., ChatGPT/GPT-4-type transformer). Thus, it is unclear whether the intervention meets the LLM criterion.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on how teachers incorporate an AI-guided chatbot into their feedback practices, analyzed through Activity Theory. The outcomes reported concern characteristics of AI vs. teacher feedback and components of the activity system, not on changes in students\u2019 writing competence or writing-related performance variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics for students are reported. The study examines features of feedback (amount, length, foci, types) and the facilitative role of AI in teacher feedback, but does not measure or report experimental effects on learners\u2019 writing quality or related performance indicators.""}}"
Efl Students' Writing Engagement and Ai Attitude in Genai-assisted Contexts: a Mixed-methods Study Grounded in Sdt and Tam,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are explicitly described as EFL learners in GenAI-assisted writing contexts, which fits the target population of L2 English learners in EFL settings.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the study concerns GenAI and EFL writing, the abstract does not describe an experimental or quasi-experimental instructional intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction. It focuses on engagement profiles and attitudes, and notes that few teachers have actively integrated such tools into their teaching, suggesting no structured LLM-based intervention was implemented.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on writing engagement and attitudes toward GenAI, not on writing competence or writing-related performance variables. The study examines behavioral, emotional, and cognitive engagement rather than instructional effects on writing ability.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, text quality measures) are reported. Outcomes are engagement profiles and attitudes, plus qualitative teacher perceptions, without measured changes in writing performance.""}}"
