Title,Year,Decision,Notes
Writing Argumentative Essays: Jambi Efl Students' Challenges and Strategies,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL students in the English Education Study Program at a public university in Jambi, Indonesia, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although students report using \u201cAI applications\u201d as a technology utilization strategy, the abstract does not specify large language models (e.g., ChatGPT) nor describe any experimental or quasi-experimental LLM-based instructional intervention. The study is a qualitative case study of challenges and self-reported strategies, not an LLM-mediated intervention design.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on difficulties in writing argumentative essays and strategies to address them, which is directly related to writing competence and writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses qualitative methods (semi-structured interviews, document analysis, thematic analysis) and reports problems and strategies. It does not report quantifiable writing outcome metrics or evaluate the effectiveness of an AI/LLM-mediated intervention.""}}"
L2 Students' Barriers in Engaging with Form and Content-focused Ai-generated Feedback in Revising Their Compositions,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""Participants are described only as \u201cL2 students in a computer science program.\u201d The target L2 is not explicitly stated as English, nor is the context labeled ESL/EFL/ELL. It is plausible but not certain that the L2 is English, so this cannot be confirmed from the abstract alone.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used to provide corrective feedback, the study is observational/analytic: students were tasked with seeking feedback and their revisions and rationales were analyzed. There is no indication of an experimental or quasi-experimental design (e.g., control/comparison groups, pre\u2013post measures, or structured intervention to test effectiveness). The focus is on barriers and uptake, not on testing an LLM-mediated instructional intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly L2 writing: students wrote argumentative essays and sought AI-generated corrective feedback on form (grammar) and content (evidence). The primary focus is on how they engage with feedback in revising their compositions, which is directly related to writing processes and competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports proportions of feedback accepted, argued, or ignored, and examines reasons for rejection using the Technology Acceptance Model. It does not report quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity) to assess the effectiveness of the LLM-mediated intervention. Outcomes are about feedback uptake and perceptions, not measured improvement in writing.""}}"
Balancing Ai and Authenticity: Efl Students' Experiences with Chatgpt in Academic Writing,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are explicitly described as EFL students, indicating they are learners of English as a foreign language and thus L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used by students, the study is a qualitative case study of students\u2019 experiences and strategies. There is no indication of an experimental or quasi-experimental design, structured instructional intervention, or controlled integration of ChatGPT into teaching; it is exploratory and descriptive.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is academic writing, focusing on how EFL students incorporate ChatGPT into their writing process and its impact on essay quality, authenticity, and related writing practices.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract specifies a qualitative case study using semi-structured interviews and self-reported experiences. It notes that future research should include objective measures, implying that this study does not report quantifiable writing outcome metrics or experimental measures of writing performance.""}}"
Investigating Students' Cognitive Processes in Generative Ai-assisted Digital Multimodal Composing and Traditional Writing,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) writers, indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study investigates generative AI-assisted composing processes using ChatGPT and Bing Chat, which are LLM-based tools, integrated into students\u2019 multimodal and traditional writing tasks.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on composing processes in multimodal PPT projects and traditional argumentative essays, both of which are writing-related tasks, with attention to how generative AI supports these processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract describes a qualitative study using screen recordings, think-aloud protocols, final texts, and interviews to analyze cognitive and composing processes. It does not mention any experimental or quasi-experimental design, control/comparison of conditions, or quantifiable writing outcome metrics assessing effectiveness of the AI intervention.""}}"
Ai Chatbot as a Companion in Writing Travel Notes1,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are Russian heritage language speakers and advanced Russian-as-a-foreign-language learners at a German university. The target language is Russian, not English, so the population does not match the review\u2019s focus on L2 English learners in ESL/EFL/ELL contexts.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses a customized chatbot built on the ChatGPT model (an LLM) as an interactive interlocutor and writing assistant in a structured learning scenario, indicating an LLM-based intervention integrated into writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on improving writing competency in the travel note genre, using a genre-based approach and a five-step genre cycle. The chatbot supports learners in crafting travel notes, clearly centering on writing instruction rather than automated scoring.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses potential benefits and observations (e.g., better understanding of genre specifics, development of reading and writing skills) but does not explicitly mention quantitative writing outcome measures or experimental comparisons. It is unclear whether structured, quantifiable writing outcomes were collected.""}}"
English Paraphrasing Strategies and Levels of Proficiency of an Ai-generated Quillbot and Paraphrasing Tool: Case Study of Scientific Research Abstracts,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The study paraphrases 30 abstracts from the Journal of Second Language Writing using QuillBot and Paraphrasing Tool. No human participants or L2 English learners in ESL/EFL/ELL contexts are mentioned; it is a tool-focused text analysis, not learner-focused research.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study analyzes paraphrasing strategies and proficiency levels of QuillBot and Paraphrasing Tool. There is no experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or learner writing processes; it is a comparative evaluation of tools.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on the paraphrasing behavior of AI tools applied to published abstracts, not on developing or assessing learners\u2019 writing competence through an instructional context. Any pedagogical comments are incidental and not part of an intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable learner writing outcomes are reported. The study reports patterns of paraphrasing (e.g., synonym substitution, levels of revision) by the tools themselves, not changes in human learners\u2019 writing performance following an LLM-mediated intervention.""}}"
Eap Teacher Feedback in the Age of Ai: Supporting First-year Students in Efl Disciplinary Writing,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly refers to \u201cEnglish as a foreign language (EFL) disciplinary writing\u201d and \u201cfirst-year EFL undergraduate students in their discipline-specific academic writing within EMI settings,\u201d indicating L2 English learners in an EFL/EMI context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the study discusses \u201cthe emergence of generative artificial intelligence (GenAI) as a feedback tool\u201d and compares students\u2019 perceptions of teacher vs. AI-generated feedback, there is no indication of an experimental or quasi-experimental LLM-based writing intervention. The focus is descriptive/analytical rather than implementing an LLM (e.g., ChatGPT) as an instructional treatment.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly disciplinary academic writing: the study analyzes EAP teacher feedback on EFL disciplinary writing and students\u2019 perceptions of feedback, which is directly related to writing competence and writing support.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract mentions analysis of interview themes and a coding scheme for feedback types, but does not report any quantitative writing outcome measures (e.g., changes in writing scores, quality, accuracy). Outcomes are qualitative (perceptions, nature of feedback), not experimental measures of LLM-mediated writing improvement.""}}"
Reflections on Co-researching Ai Literacy: a Students-as-partners Approach with International Students,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The participants are described as international students in a UK pre-sessional English for Academic Purposes (EAP) course, which likely implies L2 English learners, but the abstract does not explicitly state that they are ESL/EFL/ELL learners or that the data focus specifically on English language learning outcomes.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a Students-as-Partners case study on AI literacy, focusing on learning about AI limitations and prompt writing. It does not describe an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT, GPT-4) into writing instruction or processes; rather, it is about co-researching AI literacy and partnership practices.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on AI literacy, SaP processes, and partnership reflections, not on writing competence or writing-related variables as outcomes. Prompt writing is mentioned as a skill, but the context is AI literacy rather than a structured writing pedagogy intervention targeting writing performance.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics. It discusses perceived benefits (learning about AI limitations, skills for prompt writing) and offers recommendations for SaP projects, but there is no indication of measured writing performance or experimental outcome data.""}}"
Chatgpt-generated Corrective Feedback: Does It Do What It Says on the Tin?,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as students at CEFR B1 level attending an English for Academic Purposes (EAP) course at an international branch campus of a UK university, which fits an ESL/EAP L2 English learner context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study compares ChatGPT-generated corrective feedback with teacher-provided feedback on students\u2019 essays, but the abstract does not indicate an experimental or quasi-experimental pedagogical intervention where L2 learners actually use ChatGPT within a structured writing instruction or process. It appears to be an evaluative comparison of feedback quality, not an LLM-mediated instructional intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on the quantity and quality of corrective feedback produced by ChatGPT versus teachers, and on the adequacy of feedback strategy and polarity. There is no indication that the study examines changes in learners\u2019 writing competence or writing-related performance; rather, it evaluates the feedback tool itself.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics (e.g., pre/post writing scores, improvement measures). Outcomes concern characteristics of feedback, not measurable changes in students\u2019 writing performance following an LLM-mediated intervention.""}}"
"Chatgpt, Plagiarism, and Multilingual Students' Learning to Write",2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions \u201cmultilingual students\u201d and \u201cwriting instructors,\u201d but does not specify that the participants are L2 English learners in ESL/EFL/ELL contexts or that the focus is specifically on English writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The piece is described as a \u201cshort piece\u201d sharing \u201cexploratory interactions with ChatGPT\u201d to discuss plagiarism and academic integrity. There is no indication of an experimental or quasi-experimental design or a structured instructional intervention integrating ChatGPT into writing instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on plagiarism, academic integrity, and ethics in academic writing, not on developing writing competence or writing-related performance. ChatGPT is framed as a tool to teach ethics rather than to improve writing skills.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or assessment of writing performance. It appears to be conceptual/exploratory rather than an empirical study with measurable writing outcomes.""}}"
Chatgpt in Language Writing Education: Reflections and a Research Agenda for a Chatgpt Feedback Engagement Framework,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses ESL writing education in general but does not specify any actual participant group or empirical data collection with L2 English learners. It appears to be a conceptual/personal reflection piece rather than a participant-based study.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is discussed conceptually and ethically, and a future research agenda/framework is proposed. However, there is no indication of an experimental or quasi-experimental intervention actually implemented with learners; it is a reflection and framework paper.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""While the context is ESL writing education and feedback, the paper is theoretical, focusing on ethical considerations and a proposed framework rather than an implemented pedagogical intervention or study of writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not report any quantitative writing outcomes or measures. It is a reflective/conceptual article calling for future research, not an empirical evaluation of LLM-mediated writing outcomes.""}}"
The Reliability of Using Chatgpt in Rating Efl Writings,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study uses 82 compositions from the Written English Corpus of Chinese Learners, clearly indicating EFL learners writing in English as an L2.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is used solely as an automated rater to evaluate existing EFL essays. There is no experimental or quasi-experimental instructional intervention integrating ChatGPT into learners\u2019 writing instruction or writing process.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on the reliability of ChatGPT as an essay scoring tool (intra- and inter-rater reliability), not on pedagogical use for improving writing competence or writing-related learning outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No learner writing outcomes are measured as a result of an LLM-mediated intervention. The only quantitative outcomes are reliability statistics comparing ChatGPT and human ratings, not changes in students\u2019 writing performance.""}}"
"Comparing Peer, Chatgpt, and Teacher Corrective Feedback in Efl Writing: Students' Perceptions and Preferences",2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as EFL students in English as a Foreign Language classrooms, so the population is L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention includes an AI tool (ChatGPT) providing written corrective feedback as one of three feedback modes. ChatGPT is a large language model integrated into the writing process.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on written corrective feedback in EFL writing and subsequent revisions, directly related to writing competence and feedback practices in writing.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is described as using a qualitative approach via survey analysis to explore students\u2019 perceptions and preferences. No quantifiable writing outcome metrics (e.g., scores, rubric-based gains, measurable text quality changes) are reported; revisions are mentioned but not as measured outcomes of effectiveness.""}}"
Enhancing Usability and Learner Engagement: a Heuristic Evaluation of the Ai-enhanced Video Drama Maker App,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The app is designed for learners of English as a Foreign Language (EFL), clearly situating the population as L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the app includes GPT-generated sentences, the study itself is a heuristic evaluation of usability by UI/UX experts, not an experimental or quasi-experimental pedagogical intervention with learners integrating LLMs into writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on usability, user experience, and HCI design (heuristic evaluation using Nielsen\u2019s principles). Writing and speaking are mentioned as intended outcomes, but they are not the focus of the reported study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported. The quantitative data concern usability (e.g., Cronbach\u2019s alpha, descriptive statistics on heuristic evaluation), not writing performance or related writing variables.""}}"
Developing a Thai Grammatical Error Correction Tool for Deaf Students,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are deaf students writing in Thai. The focus is on Thai grammatical error correction, not on L2 English learners in ESL/EFL/ELL contexts or English-language data.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract describes a Thai grammatical error correction (GEC) system and mentions off-the-shelf vs. custom models, but does not specify that these are large language models (e.g., transformer-based generative LLMs like GPT). The nature of the models is not clearly LLM-based.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The study focuses on developing and evaluating an automatic Thai GEC tool and corpus, not on a pedagogical writing intervention or instructional context aimed at improving learners\u2019 writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are model performance metrics (detection and correction accuracy) rather than quantifiable writing outcomes for learners following an LLM-mediated writing intervention.""}}"
Deep Learning Approaches to Predict Student Success in English Language Learning,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to 'English language learning' and 'student-written texts' but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts. They could be L1 or mixed populations; this is not explicit.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""GPT-3 is used to predict student success and assess texts, functioning as an analytic/predictive tool. There is no explicit experimental or quasi-experimental design integrating GPT-3 into writing instruction or the writing process as an intervention; it is primarily a prediction/assessment model.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on predicting student achievement and improving accuracy of success predictions, not on developing writing competence. Writing is used as input data for prediction, and the study centers on evaluation/analytics rather than a pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported concern prediction accuracy of student success and the quality of feedback, not quantifiable changes in learners\u2019 writing performance following an LLM-mediated writing intervention. No pre/post or comparative writing outcome measures are described.""}}"
Xducation of Things (xot): Harnessing Ai and Edge Computing to Educate All Things,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly states that a quasi-experimental study involved 26 EFL learners, indicating that the participants are L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is the smartXoT environment with a Smart Question Answer Forwarding Mechanism (SQA-Forwarding) within an edge-computing/XoT framework. The abstract does not indicate that this system is based on large language models (e.g., ChatGPT, GPT-4, transformer-based generative models); it appears to be a knowledge-base/QA forwarding mechanism rather than an LLM-mediated writing tool.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study reports that interaction between EFL learners and smartthings with SQA-Forwarding significantly improved learners\u2019 writing skills and that revisions enhanced writing quality, indicating a primary focus on writing competence as a learning outcome.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract mentions a quasi-experimental design with experimental and control groups and reports significant improvement in writing skills and writing quality, implying quantifiable writing outcome metrics were used to assess the intervention\u2019s effectiveness.""}}"
Automated English Language Learning Using Bert-lstm Model,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers generally to \u201cautomatic English learning\u201d and \u201cstudents,\u201d but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor does it clearly describe an empirical learner population at all.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses a BERT-LSTM model as an NLP engine for automated English learning. BERT is a transformer-based encoder, but the abstract does not indicate use of a generative large language model (e.g., ChatGPT/GPT-4) integrated into writing instruction. It appears to be an automated system for tasks like comprehension, interpretation, and grammar correction, not an LLM-mediated writing intervention.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions \u201caccuracy of written responses\u201d and \u201cgrammar correction,\u201d but the primary focus seems to be general language learning and multiple linguistic tasks, not specifically writing competence or a writing-focused pedagogical intervention. The instructional context and focus on writing are not clearly described.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""It states that \u201cexperimental findings affirm the usefulness\u201d of the model, but provides no indication that quantifiable writing outcome metrics (e.g., writing scores, text quality measures) were collected as part of a structured writing intervention. The nature of the reported outcomes is not clear from the abstract.""}}"
"The Effects of a Quillbot-based Intervention on English Language Majors' Efl Writing Performance, Apprehension, and Self-efficacy",2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 18 fourth-year English Language majors in an EFL context at Matrouh University. The study explicitly concerns EFL writing performance, indicating L2 English learners in an EFL setting.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is based on QuillBot, described as an AI-powered writing assistant. QuillBot is not clearly identified as an LLM-based, transformer generative model in the abstract, and in this review\u2019s criteria, tools like QuillBot are explicitly listed as examples to exclude when they are not LLM-based writing interventions.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on EFL writing performance and related affective variables (writing apprehension and self-efficacy). The intervention involves drafting, receiving AI-generated feedback, revising, and producing final drafts, which is clearly a writing-focused pedagogical context rather than automated scoring.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses a pre/post test and two scales to measure writing performance, apprehension, and self-efficacy, and reports significant positive effects. These constitute quantifiable outcome measures of writing-related performance and affective variables.""}}"
Revolutionizing Efl Learning through Chatgpt: a Qualitative Study,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL students at the University of Hail in Saudi Arabia, clearly positioning them as L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is the focus, the study is exploratory and qualitative, using interviews to examine perceptions of using ChatGPT. There is no indication of an experimental or quasi-experimental intervention design integrating ChatGPT into writing instruction or processes.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""Writing is mentioned as one of several skills (reading, writing, grammar, spelling, research skills, self-directed learning). The primary focus appears to be general English learning with ChatGPT, not specifically writing competence or writing-related variables as the main context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is explicitly described as qualitative, based on individual and focus group interviews. It reports perceived enhancements but does not mention any quantifiable writing outcome metrics or measured changes in writing performance.""}}"
