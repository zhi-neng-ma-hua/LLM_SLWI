Title,Year,Decision,Notes
Same Assignment-two Different Feedback Contexts: Lower Secondary Students' Experiences with Feedback during a Three Draft Writing Process,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""Participants are described as lower secondary students in English as a foreign language (EFL) classes, which suggests they are L2 English learners. However, the abstract does not explicitly state their L1 or confirm that English is a second/foreign language for all participants, though this is strongly implied by the EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study contrasts AI-generated feedback with peer feedback in an EFL writing process, but the abstract does not specify what AI system is used, nor whether it is a large language model (e.g., ChatGPT, GPT-4). It could be a non-LLM feedback tool. Without explicit mention of an LLM-based system, it is unclear whether the intervention meets the LLM criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is a three-draft writing process in EFL classes, focusing on feedback during writing and students\u2019 engagement with AI-generated vs. peer feedback. The primary focus is clearly on writing processes and feedback in writing, not on automated scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract emphasizes students\u2019 conceptions, experiences, dialogic interactions, and feedback literacy, investigated via observations and interviews with thematic analysis. There is no indication of quantitative or otherwise explicit writing outcome measures (e.g., writing scores, quality ratings, accuracy gains) comparing the two feedback contexts. Outcomes are qualitative and process-oriented rather than quantifiable writing performance metrics.""}}"
Efl Learners' Perceptual Perezhivaniya and Actual Writing Revision Behaviors Mediated by Genai: a Sociocultural Theory Perspective,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are nineteen EFL learners at a university in Southern China, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract states that learners revised L2 continuation writing tasks \""using GenAI\"" but does not specify that the GenAI tool is an LLM (e.g., ChatGPT, GPT-4) or provide its technical nature. It could be any generative AI, not necessarily an LLM-based system.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on L2 writing revision processes (word choice, content, discourse, syntax, errors, alignment, typographic elements) mediated by GenAI, which is central to writing competence and writing-related behaviors.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses interviews, Q-methodology, and Translog screen recordings to explore revision processes and the alignment between perceived experiences and actual revision behaviors. The abstract does not report any quantifiable writing outcome metrics (e.g., writing quality scores, accuracy gains) assessing the effectiveness of the GenAI-mediated intervention; it focuses on process and perceptions rather than outcome measures.""}}"
Students' Perceptions of Generative Artificial Intelligence (genai) Use in Academic Writing in English as a Foreign Language,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 56 undergraduate university students in Ecuador engaged in academic writing in English as a foreign language (EFL), clearly an L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study investigates students\u2019 perceptions of GenAI/ChatGPT use and academic integrity. There is no indication of an experimental or quasi-experimental design integrating LLMs into writing instruction or structured writing processes; it is a perception/survey study.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the context is academic writing, the primary focus is on perceptions of academic integrity, cheating, and AI-giarism, not on a pedagogical writing intervention or instructional use of LLMs to develop writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports attitudinal and perception data (worries about skill development, views on dishonesty, beliefs about detectability). It does not report any quantifiable writing outcome metrics or effectiveness of an LLM-mediated writing intervention.""}}"
Chatbots or Cheatbots? University Students' Uses of Ai Literacy Tools across Four Nations,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""Participants are undergraduate and graduate students in English-medium programs across four nations, but the abstract does not specify that they are L2 English learners; some may be L1 English users (e.g., in the United States). The focus is on English-medium instruction, not explicitly on L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although students use LLMs such as ChatGPT, the study is a cross-case analysis of first-person accounts, not an experimental or quasi-experimental intervention integrating LLMs into writing instruction. There is no structured pedagogical treatment or controlled use of LLMs as an intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on how students use LLMs to support reading, writing, and learning, and on perceived opportunities and challenges, rather than on a designed writing competence intervention. It is more about usage patterns and ethical considerations than a writing-focused instructional context with measured outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports qualitative accounts of uses, opportunities, and challenges. It does not mention any quantifiable writing outcome metrics or experimental measures of writing performance resulting from LLM use.""}}"
"A Comparative Study of the Human, Automated Scoring Model, and Gpt-4 Ratings of Young Efl Students' Writing",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as 'young English as a foreign language learners,' clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""GPT-4 is used as an automated writing evaluation (AWE) scoring model, not as part of an instructional or intervention design to support learners\u2019 writing processes or instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on comparing GPT-4 scoring performance with human raters and an operational AWE model on TOEFL Junior Writing tasks. This is an assessment/measurement study, not a pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics for learners are reported; the outcomes are psychometric/accuracy measures of scoring models relative to human ratings, not changes in learners\u2019 writing performance following an LLM-mediated intervention.""}}"
Efl Learners' Motivation and Acceptance of Using Large Language Models in English Academic Writing: an Extension of the Utaut Model,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL learners engaged in business-related English academic writing, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although participants had completed a semester of training in using LLMs for English academic writing, the study itself does not describe or test an experimental or quasi-experimental LLM-based writing intervention. It focuses on technology acceptance and motivation after prior exposure, not on implementing and evaluating a specific LLM-mediated instructional treatment.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on motivation and acceptance (UTAUT, L2 Motivational Self System) regarding LLM use, not on writing competence or writing-related performance variables. Writing is the context, but not the measured outcome domain.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, quality ratings, accuracy, complexity) are reported. The outcomes are motivational and acceptance constructs, not writing performance, so the effectiveness of LLM-mediated writing intervention is not assessed.""}}"
Edcew-llm: Error Detection and Correction in English Writing: a Large Language Model-based Approach,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cerror profiles of English language learners across CEFR proficiency levels (A, B, and C)\u201d but does not specify whether these are actual L2 learner participants in an instructional context or simply learner corpora used for model training/evaluation. No ESL/EFL/ELL educational setting or participant group is described.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study develops and benchmarks an LLM-based error detection and correction pipeline (fine-tuned LLM plus GPT\u20113.5 explanations) as a WEDC tool. It is a system/methods paper evaluating model performance (F1 scores, benchmarks), not an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction with learners.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on automated error detection/correction performance and generation of explanations, framed as improving GEC tools. There is no described instructional context, classroom implementation, or writing pedagogy intervention; it is essentially an NLP system evaluation rather than a study of writing competence development.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are model-centric (F1 scores on BEA-2019, JFLEG, multilingual datasets; human evaluation of correction quality and explanations). There are no quantifiable learner writing outcomes (e.g., pre/post writing scores, accuracy gains) from an LLM-mediated intervention with L2 writers.""}}"
Investigating Efl Students' Perceptions of Feedback: a Comparative Study of Instructor and Chatgpt-generated Responses in Academic Writing,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Saudi English as a Foreign Language (EFL) learners enrolled in an advanced writing course, clearly fitting the L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study compares instructor feedback with ChatGPT-generated feedback on students\u2019 writing assignments, integrating an LLM (ChatGPT) into the writing feedback process within a course, which qualifies as an LLM-based intervention component.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is academic writing; feedback (from instructor and ChatGPT) is provided on writing assignments with the stated aim of developing writing skills, so the primary focus is on writing competence and writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports only students\u2019 perceptions and preferences via a survey (e.g., instructor feedback perceived as more useful, ChatGPT feedback as immediate and accessible). It does not mention any quantitative writing outcome measures (e.g., changes in writing scores, quality, accuracy) to assess the effectiveness of the LLM-mediated intervention.""}}"
Large Language Models Fall Short in Classifying Learners' Open-ended Responses,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 143 Japanese university students studying English as a foreign language (EFL), which fits the L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""LLMs are used to classify learners\u2019 open-ended survey responses about their essay-writing process, not as part of an instructional or experimental writing intervention. The focus is methodological (classification accuracy), not integrating LLMs into writing instruction or processes for learning.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on LLMs as tools for qualitative data analysis (classifying self-regulated learning processes) rather than on improving writing competence or writing-related pedagogical interventions. It is not a writing instruction or intervention study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes concern agreement (Cohen\u2019s kappa) between LLMs and human coders on classification tasks, not changes in learners\u2019 writing performance or related measurable writing outcomes.""}}"
A Linguistic Comparison between Chatgpt-generated and Nonnative Student-generated Short Story Adaptations: a Stylometric Approach,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as \u201cnonnative ESL students in an Egyptian university,\u201d so the population is L2 English learners in an ESL/EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is used only to generate comparison texts; there is no experimental or quasi-experimental instructional intervention integrating the LLM into students\u2019 writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on stylometric comparison and authorship attribution (distinguishing AI- vs human-generated texts), not on improving writing competence through a pedagogical intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No writing outcome measures assessing the effectiveness of an LLM-mediated writing intervention are reported; the study analyzes existing texts rather than evaluating changes in learners\u2019 writing performance.""}}"
Artificial Intelligence Vs. Instructor Supported Ai: Teaching Second Language Writing Via Write&improve,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study investigates second language writing, English writing success, and English writing self-efficacy. Although the abstract does not explicitly label participants as EFL/ESL/ELL, the focus is clearly on learners of English as an L2 in an instructional context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses the Write&Improve system. Write&Improve is an automated writing evaluation tool based on Cambridge technology, not described here as a large language model (e.g., ChatGPT, GPT-4). The abstract frames it as an AI feedback system, but there is no indication it is an LLM-based, transformer generative model integrated into instruction, which is required by the review criteria.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on second language writing: outcomes include English writing success and related variables (self-efficacy, achievement emotions, teacher-student interaction). The intervention is clearly situated in L2 writing instruction.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses an 8-week pretest-posttest control group design and reports a statistically significant increase in English writing success in the experimental group, indicating quantifiable writing outcome metrics are collected and analyzed.""}}"
Developing L2 Postgraduate Students' Strategic and Responsible Use of Genai through a Purposefully Designed Workshop in Academic Writing,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are explicitly described as L2 postgraduate students facing challenges in academic writing, indicating second language English learners in an academic writing context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The workshop uses \u201cdiverse GenAI tools\u201d and focuses on \u201cstrategic and responsible GenAI use,\u201d but the abstract does not specify that these are large language models (e.g., ChatGPT, GPT-4) as opposed to other generative or AI tools. The exact nature of the GenAI tools is not detailed.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly academic writing: the workshop targets stages of the writing process (brainstorming, literature searching, revising, ethical considerations) and aims to support L2 students\u2019 academic writing practices.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are technology proficiency, critical evaluation skills, ethical competence, and AI agency, measured via pre- and post-workshop questionnaires. No quantifiable writing performance or writing quality metrics are mentioned; the focus is on attitudes/skills related to AI use rather than writing outcomes.""}}"
Linguistic Analyses of Written Corrective Feedback for Chinese as a Second Language: Chatgpt Versus Human Teachers,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are learners of Chinese as a second language (CSL), specifically a Vietnamese CSL writing sample corpus. The focus is not on L2 English learners in ESL/EFL/ELL contexts, and the target language is Chinese, not English.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study analyzes written corrective feedback generated by ChatGPT (an LLM) versus human teachers. Although primarily comparative, it does integrate an LLM into a feedback context relevant to writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is second language writing, focusing on written corrective feedback on CSL learners\u2019 writing, with an analytic framework for language accuracy and content expressivity\u2014both writing-related variables.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract reports linguistic analyses of feedback quality (e.g., word order changes, vocabulary difficulty) but does not indicate any measured learning or writing outcome for students (e.g., post-test writing scores). It appears to evaluate feedback characteristics rather than intervention effectiveness.""}}"
A Translanguaging Perspective on Students' Use of Generative Artificial Intelligence in L2 Writing,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as 'Chinese multilingual undergraduates' engaged in 'L2 writing', which in this context strongly implies English as the target language in an EFL/ESL-type setting.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study investigates students' naturalistic use of 'generative artificial intelligence (GAI)' in L2 writing, using screen recordings, journals, and interviews. It does not describe an experimental or quasi-experimental pedagogical intervention integrating a specific LLM into instruction; rather, it is an observational, qualitative study of existing practices.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on 'GAI-assisted L2 writing' and how students use GAI for creation, translation, evaluation, and revision in their writing processes, aligning with a writing competence/writing-process context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses thematic analysis of qualitative data (screen recordings, reflective journals, interviews) and reports patterns and stances. There is no mention of quantitative writing outcome measures or experimental comparison to assess effectiveness of GAI-mediated writing interventions.""}}"
Saudi Efl Learners' Perceptions of Using Artificial Intelligence and Its Impact on Their Writing Skills,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are female Saudi learners of English as a Foreign Language at the University of Jeddah, clearly an EFL context with English as the target language.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cArtificial Intelligence tools\u201d and explicitly mentions ChatGPT, but does not specify whether all tools are LLM-based or how they are integrated as an instructional intervention beyond general use. However, the main focus is on perceptions rather than a structured experimental or quasi-experimental intervention design.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on learners\u2019 perceptions, attitudes, perceived benefits, and drawbacks of AI tools for writing. There is no description of a designed pedagogical writing intervention being evaluated; instead, it is an attitudinal/perception study about AI use in writing.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although one research question asks about the impact of AI on writing competency, the abstract reports only qualitative perceptions (e.g., students valued AI, appreciated prompt responses, help with grammar and vocabulary) and does not indicate any quantifiable writing outcome measures or experimental comparison of writing performance.""}}"
Enhancing Efl Writing through Ai-driven Video-to-text Recognition in Authentic Learning Contexts,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as EFL learners: \u201c22 first-year university students\u201d in an EFL context, and the focus is on English writing skills (\u201cwriting skills of English as a Foreign Language (EFL) learners\u201d).""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is an \u201cAI-driven video-to-text recognition\u201d (VTR) system that combines AI and cloud-based technologies. There is no indication that it is a large language model or transformer-based generative model (e.g., ChatGPT, GPT-4). It appears to be a recognition/transcription tool rather than an LLM-based writing assistant.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on writing competence: the system is designed \u201cto help learners build vocabulary and write sentences,\u201d and the study evaluates \u201cthe impact of the VTR system on writing proficiency,\u201d clearly centering on writing-related outcomes.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract reports that \u201cThe results showed improvement in writing skills,\u201d implying quantitative assessment of writing proficiency after a two-week experimental study. Thus, quantifiable writing outcome metrics are likely used, even though specific measures are not detailed in the abstract.""}}"
Harnessing Generative Ai for English Curriculum Innovation in Higher Education: a Case Study at Al-zaytoonah University of Jordan,2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""The context is English as a Foreign Language (EFL) at a Jordanian university, so participants are L2 English learners in an EFL setting, with focus on English language instruction.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study integrates GenAI/LLMs (ChatGPT) as a supplementary tool in English language classrooms and discusses curriculum design. However, the abstract does not clearly state that there is an experimental or quasi-experimental design specifically targeting writing instruction or writing processes; it may be broader language curriculum use.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""Writing fluency is mentioned as one of several outcomes (along with linguistic autonomy and critical thinking), but the primary focus appears to be overall curriculum innovation and EFL instruction, not necessarily a writing-focused intervention. It is unclear if writing competence is the central focus.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract notes that a mixed-method approach with qualitative and quantitative data was used and claims improvements in writing fluency, but it does not specify any quantifiable writing outcome metrics or structured writing assessments. It is unclear whether concrete writing measures were collected and analyzed, or if writing fluency is inferred from perceptions.""}}"
Exploring the Use of Generative Ai on Students’ Academic Writing: an Exploratory Study,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) learners, and the context is academic writing in English.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses \u2018generative AI (GenAI)\u2019 to support students\u2019 academic writing, but the abstract does not specify whether the tool is an LLM (e.g., ChatGPT/GPT-based) or another type of generative system. However, even if it were an LLM, the design appears exploratory rather than experimental/quasi-experimental in terms of instructional intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on students\u2019 use of GenAI during an academic writing task, including question categories and adoption of GenAI responses, which is directly related to writing processes and competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study examines questioning behaviors, adoption of GenAI responses, and perceptions of usefulness and ease of use. There is no indication of quantifiable writing outcome measures (e.g., writing quality scores, accuracy, complexity) to assess the effectiveness of the GenAI-mediated intervention.""}}"
Understanding How Ai Chatbots Influence Efl Learners’ Oral English Learning Motivation and Outcomes: Evidence from Chinese Learners,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 351 EFL students in China learning spoken English with an AI chatbot, clearly fitting an EFL/ELL L2 English population.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cartificial intelligence chatbots\u201d but does not specify that they are large language model\u2013based (e.g., ChatGPT, GPT-4). The type of AI chatbot (rule-based vs. LLM) is not identified, so it is unclear whether an LLM is involved.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on spoken/oral English learning, motivation, social presence, and self-efficacy. There is no indication that writing competence or writing-related variables are targeted; the context is oral language learning, not writing.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes concern learning motivation and learning outcomes in spoken English, analyzed via SEM and moderation analysis. No quantifiable writing outcomes or writing performance measures are reported.""}}"
Unveiling the Writing Self-efficacy and Its Relationship with Writing Engagement Based on Generative Ai Feedback,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract does not specify that participants are L2 English learners (ESL/EFL/ELL) or that the target language is English. It only refers to \u201cstudents\u201d and their writing self-efficacy, with no language context provided.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses \u201cgenerative AI feedback,\u201d but the abstract does not indicate whether this is specifically an LLM (e.g., ChatGPT/GPT-4) or another type of generative system. The nature of the AI tool is not described in sufficient detail to confirm it is an LLM-based intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on writing self-efficacy and writing engagement, not on writing competence or performance. The abstract does not mention assessment of writing quality, accuracy, or other competence-related writing outcomes, but rather psychological and behavioral variables around writing.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported concern changes in writing self-efficacy dimensions and their correlation with writing engagement. There is no indication of quantifiable writing performance metrics (e.g., scores, quality ratings) used to evaluate the effectiveness of the AI-mediated writing intervention.""}}"
