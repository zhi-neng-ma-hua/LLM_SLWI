Title,Year,Decision,Notes
Large Language Model-based Artificial Intelligence in the Language Classroom: Practical Ideas for Teaching,2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses language learning and language classrooms in general but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor does it indicate any empirical participant sample at all.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The paper is described as aiming to provide examples of how LLMs can be used for materials development, classroom activities, and feedback. There is no indication of an experimental or quasi-experimental study design or an implemented intervention with participants; it appears to be a conceptual/practical ideas paper.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""While writing-related uses (e.g., feedback, materials) may be included, the abstract frames the paper broadly around language learning and teaching, not specifically around writing competence or writing-related variables as the primary focus.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not mention any quantitative outcome measures or assessment of writing performance. It focuses on providing examples and discussion, with no indication of measured intervention outcomes.""}}"
"Perceptions of High School Students on Ai Chatbots Use in English Learning: Benefits, Concerns, and Ethical Consideration",2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are high school students using AI chatbots in English learning, which fits an EFL/ESL/ELL-type context focused on English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a perception survey about AI chatbot use; there is no experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into instruction as an intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on general English learning and perceptions of benefits, concerns, and ethics, not specifically on writing competence or writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are students\u2019 perceptions (frequency, means, t-test on attitudes). No quantifiable writing performance or writing-related outcome measures are reported.""}}"
Analyzing Composition Complexity in Revised Versions through Artificial Intelligence-based Writing Assistants,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract refers to 'English learners\u2019 writing practice' and 'university-level English essays', indicating L2 English learners in an EFL/ESL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is Grammarly, described as an 'AI-powered essay revision software'. Grammarly is not a large language model-based generative tool in the sense required (e.g., ChatGPT, GPT-4). The study examines automated corrections by Grammarly, not an LLM-based writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on writing complexity (lexical and syntactic) in essays before and after correction, which is directly related to writing competence and writing-related variables.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcome metrics, including three lexical complexity indicators and ten syntactic complexity indicators, and compares these before and after Grammarly correction.""}}"
Work in Progress: Safeguarding Authenticity: Strategies for Combating Ai-generated Plagiarism in Academia,2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions students in STEM and use of common English language sentence patterns, but does not clearly state that participants are L2 English learners in ESL/EFL/ELL contexts. Their L2 status and language learning context are not specified.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is used only to generate a comparison paragraph for plagiarism-detection purposes. There is no experimental or quasi-experimental design integrating an LLM into writing instruction or students\u2019 writing processes as an intervention; instead, the focus is on assessment and detection of AI-generated plagiarism.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is safeguarding authenticity and differentiating human vs. AI-generated text using a rubric, not improving writing competence or writing-related pedagogical outcomes. It is essentially an assessment/detection study rather than a writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although rubric scores and thresholds are reported, they are used to distinguish human vs. AI text and to detect plagiarism, not to evaluate the effectiveness of an LLM-mediated writing intervention on learners\u2019 writing outcomes. No quantifiable writing improvement attributable to LLM use is assessed.""}}"
Teaching Chatbot Prompt Strategies in Efl Essay Writing Instruction,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are EFL students in an essay writing unit, which fits the target population of L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cAI chatbots\u201d and \u201cchatbot outputs\u201d but does not specify that these are large language model-based tools (e.g., ChatGPT, GPT-4). It could involve LLMs, but this is not explicit from the title or abstract alone.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly EFL essay writing instruction, focusing on AI chatbot prompt-based learning within an essay writing unit, which aligns with writing competence and writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study focuses on students\u2019 perceptions and reflections, with content analysis of opportunities and challenges. There is no mention of quantitative or experimental writing outcome measures (e.g., writing scores, quality ratings) to assess effectiveness of the intervention.""}}"
"The Challenges of Developing Technological, Pedagogical, and Content Knowledge in Aviation English Field",2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are seven Indonesian aviation English teachers working in an ESP/EFL context, so the population is clearly related to L2 English teaching/learning, with a focus on English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a qualitative investigation of teachers\u2019 perceptions of their TPACK development. It does not describe any experimental or quasi-experimental intervention integrating LLMs (e.g., ChatGPT, GPT-4) into writing instruction. Technology is discussed generically (e.g., technologies to teach writing and listening), with no mention of LLM-based tools.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although writing is mentioned as a macro skill, the primary focus is on teachers\u2019 TPACK (technological, pedagogical, and content knowledge) and challenges in using technology, not on writing competence or a specific writing intervention. There is no structured pedagogical writing intervention being evaluated.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses qualitative interview data to explore perceptions. It does not report quantifiable writing outcome metrics or any measured change in learners\u2019 writing performance resulting from an LLM-mediated intervention.""}}"
Integration of Big Data and Artificial Intelligence in Constructing Learners' Individualized Feedback System,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are described as \u201c65 intermediate Chinese second language learners.\u201d The population appears to be learners of Chinese as an L2, not L2 English learners in ESL/EFL/ELL contexts. The abstract does not indicate that English is the target language.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses an \u201cAI-based feedback system\u201d for L2 writing, but there is no indication that it is a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model). It could be any AI feedback tool; the underlying architecture is not specified.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on L2 writing feedback and its impact on \u201cwriting quality,\u201d \u201cwriting proficiency,\u201d and \u201coverall writing gains\u201d through multi-draft essay writing. This aligns with writing competence and writing-related variables in an instructional context.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses an experimental vs. control group design and reports that the AI-based feedback system \u201csignificantly improve[s] learners' overall writing gains,\u201d implying quantifiable writing outcome metrics, even though specific measures are not detailed in the abstract.""}}"
An Investigation into the Use of Educational Apps in Efl Courses,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are 43 English teachers, not L2 English learners. The study focuses on teachers\u2019 use of apps in EFL courses rather than on data from L2 learners themselves.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study investigates general educational apps (Quizizz, Blooket, Kahoot) used in English teaching. These are not described as LLM-based tools (e.g., ChatGPT, GPT-4), and there is no LLM-mediated intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on overall use of apps across multiple skills (vocabulary, grammar, speaking, listening, writing, reading) and teacher perceptions, not specifically on writing competence or a writing-focused intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported. The article discusses app usage patterns and engagement, not experimental measures of writing performance or related variables.""}}"
Incorporating a Reflective Thinking Promoting Mechanism into Artificial Intelligence-supported English Writing Environments,2023,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are clearly described as EFL university students in two EFL writing classes, and the focus is on English writing quality, satisfying the L2 English learner population criterion.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses an \u201cAI-supported English writing\u201d environment and compares a reflective-thinking mechanism-based AI-supported approach with \u201cconventional AI-supported EFL writing.\u201d However, the abstract does not specify whether the AI system is a large language model (e.g., ChatGPT/GPT-like transformer-based generative model) or another type of automated feedback tool. Without this detail, it is unclear if the intervention is LLM-based.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on EFL writing quality and related constructs (self-efficacy, self-regulated learning, cognitive load) within an AI-supported English writing environment. This aligns with writing competence and writing-related variables rather than essay scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract reports that the proposed approach \u2018significantly improved the experimental group students' English writing performance\u2019 and also measured self-efficacy, self-regulated learning, and cognitive load, indicating quantifiable outcome metrics from a quasi-experimental design.""}}"
Leveraging Artificial Intelligence (ai) Technology for English Writing: Introducing Wordtune as a Digital Writing Assistant for Efl Writers,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly targets English as a Foreign Language (EFL) writers and discusses English writing, so the population and language focus align with L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The article is described as a 'tech review' that provides an overview of Wordtune and its affordances. There is no indication of an experimental or quasi-experimental design, nor of a structured pedagogical intervention integrating the AI tool.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on English writing support for EFL writers, including assistance in formulating and rewriting ideas, which is clearly writing-related.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not mention any empirical study, experimental measures, or quantifiable writing outcomes. It is a descriptive review of the tool\u2019s features, benefits, and limitations.""}}"
Engaging Efl Students' Critical Thinking Tendency and In-depth Reflection in Technology-based Writing Contexts: a Peer Assessment-incorporated Automatic Evaluation Approach,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are clearly described as university EFL (English as a Foreign Language) writing students, i.e., L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses an Automatic Writing Evaluation (AWE) system, but there is no indication that it is based on a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model). AWE here appears as a conventional automated feedback tool, not an LLM-integrated writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on EFL writing instruction and writing performance in technology-based writing contexts, integrating AWE and peer assessment to improve writing-related outcomes.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The quasi-experiment reports quantifiable outcomes such as EFL writing performance, learning motivation, critical thinking, and writing anxiety, comparing an experimental PA-AWE group with a conventional AWE control group.""}}"
Ai and Recognition Technologies to Facilitate English as Foreign Language Writing for Supporting Personalization and Contextualization in Authentic Contexts,2023,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 104 undergraduate English as a Foreign Language (EFL) students, clearly L2 English learners in an EFL context, and the focus is on English writing.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The intervention uses an app (Smart RoamLingo) with \u2018AI-Sample Sentences\u2019 and \u2018AI-Writing Feedback\u2019 based on \u2018recognition technologies\u2019. The abstract does not specify whether these AI components are large language models/transformer-based generative models (e.g., ChatGPT-like) or more traditional NLP/ASR/MT/grammar-checking tools. Thus, it is unclear if an LLM is involved.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study explicitly targets EFL writing, aiming to improve meaningful content, cohesion, consistency, and writing quality via AI-generated sample sentences and AI-based feedback. The primary focus is on writing competence, not on automated scoring or system evaluation alone.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses an experimental design with an experimental group and two control groups, reports that the experimental group significantly outperformed others in a post-test, and mentions assignment scores and number of revisions predicting post-test performance. These are quantifiable writing outcome measures.""}}"
Exploring the Potential and Limitations of Chatgpt for Academic Peer-reviewed Writing: Addressing Linguistic Injustice and Ethical Concerns,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The abstract discusses \u201cnon-native English speakers in academic publishing\u201d in general, not a defined population of L2 English learners in ESL/EFL/ELL instructional contexts. It focuses on researchers using English for publication, not language learners in a pedagogical setting.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The article is explicitly described as a commentary exploring the potential and limitations of ChatGPT. There is no indication of an experimental or quasi-experimental design, nor a structured instructional intervention integrating ChatGPT into writing instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""While it addresses academic writing and linguistic injustice, the focus is conceptual and ethical (potential, limitations, injustice, ethics), not on a concrete pedagogical context or intervention aimed at developing writing competence in an L2 learning environment.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics or empirical evaluation are reported. The piece is a commentary without experimental measures, structured intervention outcomes, or assessment of writing performance changes.""}}"
Validity Arguments for Automated Essay Scoring of Young Students' Writing Traits,2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions K-12 students in grades 3\u20136 and refers to language backgrounds, but does not specify that the participants are L2 English learners in ESL/EFL/ELL contexts or that the focus is specifically on English as the target language.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study investigates machine learning models for automated essay scoring and human\u2013machine score alignment. It does not describe an instructional or quasi-experimental intervention integrating large language models (e.g., ChatGPT, GPT-4) into writing instruction or writing processes; rather, it focuses on assessment validity.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on the validity of automated essay scoring models (evaluation and explanation inferences, human\u2013machine score alignment, detection of off-topic/gibberish). This is an assessment/measurement study, not a pedagogical intervention targeting writing competence or writing-related learning outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although writing trait scores are analyzed, they are used to evaluate the performance of ML scoring models, not to measure the effectiveness of an LLM-mediated writing intervention. There is no experimental or quasi-experimental design assessing changes in learners\u2019 writing outcomes due to an instructional use of LLMs.""}}"
Using Ai-based Detectors to Control Ai-assisted Plagiarism in Esl Writing: 'the Terminator Versus the Machines',2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The context is ESL composition, implying participants or focal texts are from L2 English learners in ESL settings: \u201cdisrupts traditional assessment practices in ESL composition\u2026 in ESL contexts.\u201d""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study investigates RoBERTa-based AI detectors for identifying ChatGPT-generated texts. It does not describe an instructional or experimental intervention integrating LLMs into writing instruction or processes; ChatGPT is only a source of machine-generated essays for detection testing.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on plagiarism detection and classifier performance, not on developing or assessing writing competence or writing-related pedagogical interventions. It is an assessment/detection study rather than a writing intervention study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) are reported. Outcomes concern detection accuracy of classifiers, not learners\u2019 writing performance following an LLM-mediated intervention.""}}"
Ai-generated Feedback on Writing: Insights into Efficacy and Enl Student Preference,2023,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as 'university English as a new language (ENL) learners,' which aligns with L2 English learners in an ELL/ESL-type context. The focus is clearly on English writing.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""Study 1 uses a six-week repeated-measures quasi-experimental design where the experimental group receives writing feedback generated from ChatGPT (GPT-4) and the control group receives human tutor feedback. This is an LLM-based intervention integrated into writing instruction/feedback.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is explicitly writing-focused: AI-generated feedback on student writing, ENL essay evaluation, and development of students' writing skills. The study compares AI vs human feedback as part of a pedagogical intervention, not just as an automated scoring benchmark.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Study 1 'examined learning outcomes' and reports 'no difference in learning outcomes between the two groups,' implying quantifiable writing outcome metrics were used to assess the effect of ChatGPT-mediated feedback on writing performance over six weeks.""}}"
An Assistive Environment for Eal Academic Writing Using Formulaic Sequences Classification,2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""Participants are described as novice English as an additional language (EAL) writers, which likely corresponds to L2 English learners, but the abstract does not clearly specify ESL/EFL/ELL instructional contexts or learner status (e.g., students vs. researchers).""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is an assistive environment based on formulaic sequences extracted and classified with a machine learning technique. There is no indication that a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model) is used; it appears to be corpus-based FS extraction and classification, not an LLM-mediated writing tool.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on academic writing improvement for EAL writers through use of domain-specific formulaic sequences, clearly targeting writing competence in research article writing rather than automated scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract reports a \u2018positive impact\u2019 and \u2018significantly higher degree of perceived usefulness\u2019 but does not clearly state whether objective, quantifiable writing outcome measures (e.g., writing scores, text quality metrics) were collected, or only perceptions and usefulness ratings.""}}"
"Trends, Research Issues and Applications of Artificial Intelligence in Language Education",2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The article is a bibliometric review of 516 papers on AI in language education. The abstract does not specify that its own data are drawn specifically from L2 English learners in ESL/EFL/ELL contexts; it aggregates across many AI-in-language-education studies without detailing participant populations.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""This is a bibliometric review, not an experimental or quasi-experimental study implementing an LLM-based intervention. It surveys trends and applications of AI (e.g., automated writing evaluation, ITS) but does not itself integrate an LLM (such as ChatGPT or GPT-4) into writing instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although writing-related topics (e.g., automated writing evaluation, ITS for writing) are mentioned among the reviewed themes, the paper\u2019s primary focus is mapping research trends and applications across multiple skills, not conducting a specific pedagogical writing intervention or study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a bibliometric review, the study does not report original, quantifiable writing outcome metrics from an LLM-mediated intervention. It summarizes existing literature rather than measuring writing performance changes in an experimental design.""}}"
The Impact of Ai Writing Tools on the Content and Organization of Students' Writing: Efl Teachers' Perspective,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL students in Indonesian universities, as reported via interviews with four EFL teachers. The focus is clearly on English as a foreign language learners\u2019 writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although several AI tools are mentioned (Quillbot, WordTune, Jenni, ChatGPT, Paperpal, Copy.ai, Essay Writer), the study is a qualitative case study based on teacher perceptions and does not describe an experimental or quasi-experimental LLM-based writing intervention. It surveys tools in use rather than implementing and testing a specific LLM-mediated instructional design.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on the impact of AI writing tools on students\u2019 writing, specifically content and organization, which are core writing competence variables in an EFL context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses a qualitative case study design with semi-structured interviews and reports teachers\u2019 perceptions of improvement. It does not report quantifiable writing outcome metrics or experimental measures of writing performance.""}}"
Chatbot-based Training on Logical Fallacy in Efl Argumentative Writing,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as 'Chinese EFL undergraduate and graduate students,' clearly indicating L2 English learners in an EFL context, with outcomes focused on EFL argumentative writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses an 'educational chatbot' for training on logical fallacies, but the abstract does not indicate that this chatbot is a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model). It could be a rule-based or non-LLM system, so it does not clearly meet the LLM intervention criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is explicitly EFL argumentative writing, with the chatbot-based intervention designed to address logical fallacies that affect argumentative writing quality. The primary focus is on writing proficiency and related variables (self-efficacy).""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcomes: pre-post argumentative writings analyzed using the Illinois Critical Thinking Essay Scoring Rubric, and pre-post questionnaires on writing self-efficacy. These provide measurable effects of the chatbot-based training on writing-related outcomes.""}}"
