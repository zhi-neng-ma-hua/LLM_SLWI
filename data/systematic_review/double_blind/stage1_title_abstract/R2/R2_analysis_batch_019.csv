Title,Year,Decision,Notes
Exploring Efl Learners’ Academic Emotions and Emotion Regulation Strategies in Ai-assisted Collaborative Academic Writing Tasks,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are explicitly described as EFL learners, indicating second language English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions an \u201cAI-assisted collaborative academic writing project\u201d and \u201cAI feedback limitations,\u201d but does not specify that the AI is a large language model (e.g., ChatGPT, GPT-4) or transformer-based generative system. It could be another type of AI feedback tool.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly academic writing (\u201ccollaborative academic writing project\u201d and \u201cAI-assisted collaborative academic writing tasks\u201d), aligning with writing-focused intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study focuses on academic emotions and emotion regulation strategies, using questionnaires and interviews. There is no indication of quantifiable writing outcome metrics (e.g., writing scores, quality measures) to assess the effectiveness of the AI-assisted writing intervention.""}}"
The Benefits and Risks of Ai-assisted Academic Writing: Insights from Current Research; Prednosti in Tveganja Pri Znanstvenem Pisanju S Pomočjo Umetne Inteligence: Spoznanja Iz Aktualnih Raziskav,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers broadly to \u201cEnglish language students\u201d and \u201cacquisition of English as a foreign language,\u201d which suggests an EFL context, but it does not clearly specify the participant population or any concrete sample in an empirical study.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The paper is described as \u201ca review of existing literature and a discussion of the findings of recent studies\u201d about ChatGPT in language education. It does not report an original experimental or quasi-experimental intervention integrating an LLM; instead, it synthesizes prior work.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The focus is on AI-assisted academic writing and the potential of ChatGPT to improve writing abilities, but as a literature-based discussion rather than a specific pedagogical intervention with measured outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not mention any original quantitative writing outcome metrics or experimental results; it summarizes \u2018insights from multiple studies\u2019 and discusses benefits and risks conceptually, consistent with a narrative review.""}}"
Enhancing Writing Accuracy and Empowering Students: the Transformative Influence of Chatgpt’s Informative Feedback on Students’ Writing,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were 50 undergraduate students enrolled in English language courses, indicating L2 English learners in an ESL/EFL/ELL context. The focus is clearly on English language learning and writing.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study evaluates instructional assistance formative feedback provided by ChatGPT, a large language model, as part of writing instruction. This constitutes an LLM-based intervention integrated into learners\u2019 writing processes.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on enhancing learners\u2019 writing skills and writing quality (coherence, grammar, engagement with the writing process) through ChatGPT feedback. This is a pedagogical writing intervention, not an automated scoring or purely functional evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Quantitative data were collected from students\u2019 essays, and results report significant improvements in writing quality (coherence, grammar, engagement). This implies measurable writing outcome metrics were used to assess the effectiveness of the ChatGPT-mediated intervention.""}}"
Exploring Potential Biases in Gpt-4o’s Ratings of English Language Learners’ Essays,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study uses the ELLIPSE corpus (English Language Learner Insight, Proficiency and Skills Evaluation), which consists of essays written by English language learners, indicating an L2 English learner population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""GPT-4o is used as an automated essay scoring (AES) tool to rate existing essays. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on GPT-4o\u2019s fairness and bias as an AES system (gender, race/ethnicity, SES), not on improving learners\u2019 writing competence or implementing a writing intervention. This aligns with excluded AES-functionality studies.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports GPT-4o rating patterns and bias analyses, not quantifiable outcomes of an LLM-mediated writing intervention. No instructional treatment or pre/post writing performance measures are described.""}}"
"The Impact of Self-revision, Machine Translation, and Chatgpt on L2 Writing: Raters’ Assessments, Linguistic Complexity, and Error Correction",2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are learners in a South Korean high school English as a Foreign Language (EFL) context, clearly indicating L2 English learners in an EFL setting. The focus is on English writing outcomes.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses a controlled experiment with three proofreading interventions: self-proofreading, neural machine translation, and ChatGPT-assisted proofreading. ChatGPT, an LLM, is explicitly integrated into the writing process as a structured proofreading tool.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on L2 writing competence and related variables: overall writing quality, text length, lexical diversity, sentence complexity, and error reduction. ChatGPT is used pedagogically to enhance writing, not merely for automated scoring.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcomes: improvements in overall writing quality, text length, lexical diversity, sentence complexity, verb cohesion, and grammatical and prepositional error rates, comparing ChatGPT-assisted proofreading with other conditions.""}}"
Trinka: Facilitating Academic Writing through an Intelligent Writing Evaluation System,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions potential integration into second language (L2) writing instruction but does not specify any actual participant population, nor whether they are L2 English learners in ESL/EFL/ELL contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The article is described as a technology review of Trinka, an intelligent writing evaluation system. There is no indication of an experimental or quasi-experimental study design, nor explicit evidence that Trinka is an LLM-based (transformer generative) tool; it appears to be an AI/NLP-based evaluation system.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on reviewing features and potential integration into L2 writing instruction, not on an implemented pedagogical intervention with measured effects. It is a technology review rather than an empirical study of writing competence outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics or experimental results are reported. The paper discusses potential benefits, limitations, and integration, but not measured changes in learners\u2019 writing performance.""}}"
A Qualitative Descriptive Study of Teachers’ Beliefs and Their Design Thinking Practices in Integrating an Ai-based Automated Feedback Tool,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study involves 9th-grade students learning English as a second language in Norway, and three ESL teachers. The context is clearly L2 English in school settings.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses an AI-driven automated feedback tool called Essay Assessment Technology (EAT). The abstract does not indicate that EAT is a large language model or transformer-based generative system (e.g., ChatGPT, GPT-4). It is framed as an automated feedback/assessment tool, not as an LLM-based generative assistant.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on teachers\u2019 beliefs, perceptions, and design thinking practices when integrating an AI-based automated feedback tool into process writing. It is about technology integration and pedagogical decision-making, not on systematically evaluating writing competence or writing-related learning outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is explicitly described as a descriptive qualitative study using teacher interviews. No quantifiable writing outcome metrics or experimental/quasi-experimental measures of students\u2019 writing performance are reported.""}}"
The Differential Impact of Ai Tools among Efl University Learners: a Process Writing Approach,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Vietnamese EFL university students (\u201cVietnamese EFL majors\u2019 writing proficiency\u2026 200 Vietnamese first-year public and private university students\u201d), clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses Grammarly, Write & Improve, and Slick Write. These are AI writing assistants but are not described as large language model (LLM)-based transformer generative systems (e.g., ChatGPT, GPT-4). They primarily provide grammar checking, feedback, and readability analysis, which falls outside the review\u2019s required focus on LLM-based tools.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study explicitly targets writing proficiency and related variables (grammatical correctness, task completion, coherence, language range) within a process writing approach, aligning with a primary focus on writing competence.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Quantitative pre- and post-test scores are analyzed via paired t-tests and logistic regression, reporting significant changes in grammatical correctness, task completion, and language range. These are clear, quantifiable writing outcome metrics.""}}"
Integrating Quillbot to Enhance Students’ Academic Writing: Opportunities and Challenges,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The article is a review of 15 peer-reviewed studies on QuillBot use in academic writing. While it mentions EFL students, it does not present primary empirical data on a specific population of L2 English learners; instead, it synthesizes prior work. As a review article, it does not itself meet the primary-study population criterion.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is explicitly described as a critical review of existing research on QuillBot, not an experimental or quasi-experimental intervention study. Moreover, QuillBot is generally not categorized as an LLM-based generative tool in the sense required (e.g., ChatGPT, GPT-4). Thus, it does not meet the intervention criterion.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the review focuses on academic writing and related variables (paraphrasing, grammar, vocabulary, motivation), it is not an original pedagogical intervention study but a synthesis of prior work. The context criterion requires a primary study implementing an LLM-mediated writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The article uses qualitative thematic analysis of prior studies and emphasizes emotional/behavioral impact, user experience, and ethical issues. It does not report original, quantifiable writing outcome metrics from an intervention; instead, it summarizes others\u2019 findings. Review articles are excluded by design.""}}"
Effects of the Use of Generative Ai Tools on Eap Writing Development: a Case Study with Medicine Undergraduates,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are undergraduate EFL learners at a Saudi university taking English for Academic Purposes (EAP) writing, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses multiple AI tools: ResearchRabbit (referencing), Acrobat Chat with PDFs (summarization), and Otio (grammar check, planning, drafting, revising). The abstract does not indicate that any of these are large language model\u2013based tools like ChatGPT/GPT-4 or similar transformer-based generative models; they appear to be specialized support tools rather than LLM-centered writing instruction. Thus it does not clearly meet the requirement of integrating LLMs into writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study explicitly targets EAP writing development, teaching students to plan, organize, draft, revise, and produce final drafts of short essays on medical issues. The primary focus is on writing competence and writing processes.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Quantitative writing outcomes are reported: pre-test and post-test essay scores, comparison between experimental and control groups, mean score differences, and t-test statistics showing significant improvement in writing performance for the AI tools group.""}}"
Efl Pre-service Teachers’ Acceptance of Chatgpt for Writing: a Sequential Explanatory Mixed-method Study,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 143 EFL pre-service teachers from universities in Indonesia, clearly positioning them as L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines acceptance and intention to use ChatGPT via a Technology Acceptance Model questionnaire and interviews. There is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction or tasks; ChatGPT is the object of attitudes, not a structured treatment.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on technology acceptance, perceptions, and ethical concerns regarding ChatGPT for writing, not on implementing a pedagogical writing intervention or systematically integrating ChatGPT into writing processes for competence development.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes are TAM constructs (perceived usefulness, ease of use, attitude, behavioral intention) and qualitative perceptions, without measures of writing performance or related quantitative writing variables.""}}"
From Prompting to Proficiency: a Mixed-methods Analysis of Prompting with Chatgpt Versus Lecturer Interaction in an Efl Classroom,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 60 Indonesian university students in an EFL classroom context. The abstract explicitly refers to English as a Foreign Language (EFL) and reports outcomes in general English proficiency and writing competency, indicating L2 English learners.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention is prompting with ChatGPT, explicitly described as an extensive/large language model (Generative AI). Students were allocated to an experimental (ChatGPT) and a control (lecturer) group, indicating an experimental design integrating an LLM into instruction/help-seeking.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""Writing competency is one of the primary measured outcomes, alongside general proficiency and self-efficacy. The study compares ChatGPT versus lecturer interaction in an EFL classroom with a clear focus on academic help-seeking and learning, including writing-related outcomes.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses pre/post-tests including a writing test and analyzes data via ANCOVA. It reports that the ChatGPT group significantly outperformed the control group in writing competency (p < .001), providing quantifiable writing outcome metrics for the LLM-mediated intervention.""}}"
Using Ai-supported Peer Review to Enhance Feedback Literacy: an Investigation of Students' Revision of Feedback on Peers' Essays,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 44 Chinese undergraduate students providing peer feedback on peers\u2019 English argumentative essays in an L2 writing context, i.e., L2 English learners in an EFL setting.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study introduces EvaluMate, an AI-supported peer review system with a large language model-based chatbot (Eva) that evaluates and provides feedback on students\u2019 comments. This is an LLM-based intervention integrated into the writing/feedback process.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on improving the quality of students\u2019 peer review comments (feedback literacy and peer feedback provision), not on learners\u2019 own writing competence or writing-related performance outcomes. The outcome variable is comment quality, not writing quality.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although the study reports quantifiable improvement in the quality of peer review comments, it does not report quantifiable writing outcome metrics (e.g., changes in students\u2019 own essay quality). The measured outcomes are feedback-related, not writing performance outcomes.""}}"
Leveraging Chatgpt for Research Writing: an Exploration of Esl Graduate Students’ Practices,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are explicitly described as two ESL graduate students, indicating they are L2 English learners in an ESL context and the focus is on English research writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is central, the study is a case study of students\u2019 self-directed use after a tutorial, not an experimental or quasi-experimental intervention design. There is no indication of controlled instructional treatment or comparison conditions to test the effect of an LLM-based writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is research writing by ESL graduate students, focusing on how they use ChatGPT for genre, content, language use, documentation, coherence, and clarity\u2014clearly centered on writing processes and competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports qualitative findings about practices, approaches, and ethical use. It mentions textual analysis of drafts but does not report any quantifiable writing outcome metrics (e.g., scores, measurable gains) to assess effectiveness of the LLM-mediated intervention.""}}"
“teaching Is Basically Feeling”: Unpacking Efl Teachers’ Perceived Emotions and Regulatory Strategies in Ai-powered L2 Speaking and Writing Skills Instruction,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 21 Iranian EFL teachers working in L2 speaking and writing instruction, clearly within an EFL/ESL context focused on English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although AI tools are used in L2 speaking and writing classes, the study is qualitative and focuses on teachers\u2019 emotions and regulatory strategies. There is no indication of an experimental or quasi-experimental design evaluating an LLM-based writing intervention (e.g., ChatGPT) or specifying that the AI tools are LLMs.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is teacher emotionality (positive/negative emotions and regulation) when integrating AI in L2 productive skills. Writing competence or writing-related performance variables are not the central outcome; writing is only a context for examining emotions.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is explicitly qualitative, using semi-structured interviews and narrative frames with thematic analysis. It does not report quantifiable writing outcome metrics or measure the effectiveness of AI/LLM-mediated writing interventions.""}}"
"The Impact of Artificial Intelligence and Machine Learning on Linguistic Accuracy, Fluency, and Self-direction among Advanced Efl Students",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as 'advanced EFL students' and 'those who speak English as a foreign language,' clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses 'technology-enhanced adaptive grammar tools, translation software, and artificial intelligence-driven feedback systems.' There is no indication that these tools are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems; they could be traditional NLP/AI tools. Thus it does not clearly meet the LLM-based intervention requirement.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus includes 'linguistic accuracy, fluency, and self-direction' and reports 'significant improvement in students\u2019 writing fluency,' indicating a primary focus on writing competence and related variables within an instructional context.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract reports 'significant improvement in students\u2019 writing fluency' and mentions changes in 'learners\u2019 autonomy and linguistic precision,' implying quantitative outcome measures comparing control and experimental groups after a 12-week intervention.""}}"
Guarding Integrity: a Case Study on Tackling Ai-generated Content and Plagiarism in Academic Writing,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""Participants are in an ENG102 advanced writing course and are likely L2 English learners, but the abstract does not explicitly state ESL/EFL/ELL status or that English is a second/foreign language for the students.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study analyzes AI-generated content and plagiarism rates in essays submitted to Turnitin and discusses students\u2019 perceptions of AI. There is no indication of an experimental or quasi-experimental LLM-based writing intervention (e.g., using ChatGPT as part of instruction); AI is treated as a source of potential misconduct and as a detection tool, not as an instructional intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is academic integrity (plagiarism and AI-generated content) rather than improving writing competence or writing-related pedagogical outcomes. Writing is the context of the misconduct analysis, not the target of an instructional intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Reported quantitative outcomes are plagiarism percentages, AI usage rates, and attitudes toward AI and plagiarism. No quantifiable writing performance metrics (e.g., writing quality scores, complexity, accuracy, organization) are reported to assess the effectiveness of an LLM-mediated writing intervention.""}}"
Teachers' Use of Generative Ai in Jordanian Universities: Practices and Perceptions,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The study population consists of EFL instructors at Jordanian universities, not L2 English learners. The focus is on teachers\u2019 perceptions and practices, not learner participants or learner data.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although generative AI tools such as ChatGPT and ChatPDF are mentioned, the study investigates how instructors use them for materials development and their perceptions. There is no experimental or quasi-experimental design integrating LLMs into learners\u2019 writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on instructors\u2019 use of AI for developing reading and writing materials and their perceptions, institutional support, and policy. It is not a pedagogical intervention study targeting learners\u2019 writing competence or writing-related performance.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable learner writing outcomes are reported. The quantitative data are survey responses from instructors about perceptions and practices, not measures of changes in students\u2019 writing performance following an LLM-mediated intervention.""}}"
Ai-assisted L2 Assessment: a Biblio-systematic Analysis,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses L2 assessment in general and mentions L2 learners but does not specify that the focus is on L2 English learners in ESL/EFL/ELL contexts, nor that the data are specifically about English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""This is a biblio-systematic/bibliometric review of 57 SSCI-indexed articles on AI-assisted L2 assessment. It does not itself implement an experimental or quasi-experimental LLM-based intervention; it synthesizes prior work and focuses on tools such as automated scoring systems and NLP technologies in general.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is L2 assessment broadly (writing and speaking assessments) and the role of AI tools in scoring and feedback, not a specific pedagogical writing intervention or instructional context. It is a field-level analysis rather than an intervention study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a bibliometric and systematic review, the study does not report its own experimental writing outcome metrics. It summarizes effectiveness, advantages, and challenges from prior literature rather than measuring writing performance changes in an intervention.""}}"
Korean Efl Learners’ Perceptions of Using Chatgpt for English Writing,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as Korean EFL (English as a foreign language) learners, so the population is L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used, the design is exploratory and perception-focused. Students compared their original writing with ChatGPT-edited versions and wrote reflection notes; there is no indication of an experimental or quasi-experimental intervention structure (e.g., treatment vs. control, pre/post with measured effects).""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly English writing: students\u2019 original writing, ChatGPT-edited versions, and feedback types (vocabulary, expressions, clarification, elaboration). The focus is on writing and writing-related feedback.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports learners\u2019 perceptions, engagement with feedback types, and questionnaire responses about advantages/disadvantages. There is no mention of quantifiable writing outcome metrics (e.g., scores, accuracy, complexity) assessing effectiveness of the ChatGPT-mediated intervention.""}}"
