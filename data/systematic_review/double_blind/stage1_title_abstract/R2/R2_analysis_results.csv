No.,Title,Year,Decision,Notes
1,Same Assignment-two Different Feedback Contexts: Lower Secondary Students' Experiences with Feedback during a Three Draft Writing Process,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as lower secondary students in English as a foreign language (EFL) classes, which suggests they are L2 English learners. However, the abstract does not explicitly state their L1 or confirm that English is a second/foreign language for all participants, though this is strongly implied by the EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study contrasts AI-generated feedback with peer feedback in an EFL writing process, but the abstract does not specify what AI system is used, nor whether it is a large language model (e.g., ChatGPT, GPT-4). It could be a non-LLM feedback tool. Without explicit mention of an LLM-based system, it is unclear whether the intervention meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is a three-draft writing process in EFL classes, focusing on feedback during writing and students’ engagement with AI-generated vs. peer feedback. The primary focus is clearly on writing processes and feedback in writing, not on automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract emphasizes students’ conceptions, experiences, dialogic interactions, and feedback literacy, investigated via observations and interviews with thematic analysis. There is no indication of quantitative or otherwise explicit writing outcome measures (e.g., writing scores, quality ratings, accuracy gains) comparing the two feedback contexts. Outcomes are qualitative and process-oriented rather than quantifiable writing performance metrics.""
    }
}"
2,Efl Learners' Perceptual Perezhivaniya and Actual Writing Revision Behaviors Mediated by Genai: a Sociocultural Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are nineteen EFL learners at a university in Southern China, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that learners revised L2 continuation writing tasks \""using GenAI\"" but does not specify that the GenAI tool is an LLM (e.g., ChatGPT, GPT-4) or provide its technical nature. It could be any generative AI, not necessarily an LLM-based system.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on L2 writing revision processes (word choice, content, discourse, syntax, errors, alignment, typographic elements) mediated by GenAI, which is central to writing competence and writing-related behaviors.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses interviews, Q-methodology, and Translog screen recordings to explore revision processes and the alignment between perceived experiences and actual revision behaviors. The abstract does not report any quantifiable writing outcome metrics (e.g., writing quality scores, accuracy gains) assessing the effectiveness of the GenAI-mediated intervention; it focuses on process and perceptions rather than outcome measures.""
    }
}"
3,Students' Perceptions of Generative Artificial Intelligence (genai) Use in Academic Writing in English as a Foreign Language,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 56 undergraduate university students in Ecuador engaged in academic writing in English as a foreign language (EFL), clearly an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates students’ perceptions of GenAI/ChatGPT use and academic integrity. There is no indication of an experimental or quasi-experimental design integrating LLMs into writing instruction or structured writing processes; it is a perception/survey study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is academic writing, the primary focus is on perceptions of academic integrity, cheating, and AI-giarism, not on a pedagogical writing intervention or instructional use of LLMs to develop writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports attitudinal and perception data (worries about skill development, views on dishonesty, beliefs about detectability). It does not report any quantifiable writing outcome metrics or effectiveness of an LLM-mediated writing intervention.""
    }
}"
4,Chatbots or Cheatbots? University Students' Uses of Ai Literacy Tools across Four Nations,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are undergraduate and graduate students in English-medium programs across four nations, but the abstract does not specify that they are L2 English learners; some may be L1 English users (e.g., in the United States). The focus is on English-medium instruction, not explicitly on L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students use LLMs such as ChatGPT, the study is a cross-case analysis of first-person accounts, not an experimental or quasi-experimental intervention integrating LLMs into writing instruction. There is no structured pedagogical treatment or controlled use of LLMs as an intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on how students use LLMs to support reading, writing, and learning, and on perceived opportunities and challenges, rather than on a designed writing competence intervention. It is more about usage patterns and ethical considerations than a writing-focused instructional context with measured outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports qualitative accounts of uses, opportunities, and challenges. It does not mention any quantifiable writing outcome metrics or experimental measures of writing performance resulting from LLM use.""
    }
}"
5,"A Comparative Study of the Human, Automated Scoring Model, and Gpt-4 Ratings of Young Efl Students' Writing",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'young English as a foreign language learners,' clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""GPT-4 is used as an automated writing evaluation (AWE) scoring model, not as part of an instructional or intervention design to support learners’ writing processes or instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on comparing GPT-4 scoring performance with human raters and an operational AWE model on TOEFL Junior Writing tasks. This is an assessment/measurement study, not a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics for learners are reported; the outcomes are psychometric/accuracy measures of scoring models relative to human ratings, not changes in learners’ writing performance following an LLM-mediated intervention.""
    }
}"
6,Efl Learners' Motivation and Acceptance of Using Large Language Models in English Academic Writing: an Extension of the Utaut Model,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners engaged in business-related English academic writing, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although participants had completed a semester of training in using LLMs for English academic writing, the study itself does not describe or test an experimental or quasi-experimental LLM-based writing intervention. It focuses on technology acceptance and motivation after prior exposure, not on implementing and evaluating a specific LLM-mediated instructional treatment.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on motivation and acceptance (UTAUT, L2 Motivational Self System) regarding LLM use, not on writing competence or writing-related performance variables. Writing is the context, but not the measured outcome domain.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, quality ratings, accuracy, complexity) are reported. The outcomes are motivational and acceptance constructs, not writing performance, so the effectiveness of LLM-mediated writing intervention is not assessed.""
    }
}"
7,Edcew-llm: Error Detection and Correction in English Writing: a Large Language Model-based Approach,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “error profiles of English language learners across CEFR proficiency levels (A, B, and C)” but does not specify whether these are actual L2 learner participants in an instructional context or simply learner corpora used for model training/evaluation. No ESL/EFL/ELL educational setting or participant group is described.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study develops and benchmarks an LLM-based error detection and correction pipeline (fine-tuned LLM plus GPT‑3.5 explanations) as a WEDC tool. It is a system/methods paper evaluating model performance (F1 scores, benchmarks), not an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction with learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automated error detection/correction performance and generation of explanations, framed as improving GEC tools. There is no described instructional context, classroom implementation, or writing pedagogy intervention; it is essentially an NLP system evaluation rather than a study of writing competence development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are model-centric (F1 scores on BEA-2019, JFLEG, multilingual datasets; human evaluation of correction quality and explanations). There are no quantifiable learner writing outcomes (e.g., pre/post writing scores, accuracy gains) from an LLM-mediated intervention with L2 writers.""
    }
}"
8,Investigating Efl Students' Perceptions of Feedback: a Comparative Study of Instructor and Chatgpt-generated Responses in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Saudi English as a Foreign Language (EFL) learners enrolled in an advanced writing course, clearly fitting the L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study compares instructor feedback with ChatGPT-generated feedback on students’ writing assignments, integrating an LLM (ChatGPT) into the writing feedback process within a course, which qualifies as an LLM-based intervention component.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is academic writing; feedback (from instructor and ChatGPT) is provided on writing assignments with the stated aim of developing writing skills, so the primary focus is on writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports only students’ perceptions and preferences via a survey (e.g., instructor feedback perceived as more useful, ChatGPT feedback as immediate and accessible). It does not mention any quantitative writing outcome measures (e.g., changes in writing scores, quality, accuracy) to assess the effectiveness of the LLM-mediated intervention.""
    }
}"
9,Large Language Models Fall Short in Classifying Learners' Open-ended Responses,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 143 Japanese university students studying English as a foreign language (EFL), which fits the L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""LLMs are used to classify learners’ open-ended survey responses about their essay-writing process, not as part of an instructional or experimental writing intervention. The focus is methodological (classification accuracy), not integrating LLMs into writing instruction or processes for learning.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on LLMs as tools for qualitative data analysis (classifying self-regulated learning processes) rather than on improving writing competence or writing-related pedagogical interventions. It is not a writing instruction or intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes concern agreement (Cohen’s kappa) between LLMs and human coders on classification tasks, not changes in learners’ writing performance or related measurable writing outcomes.""
    }
}"
10,A Linguistic Comparison between Chatgpt-generated and Nonnative Student-generated Short Story Adaptations: a Stylometric Approach,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as “nonnative ESL students in an Egyptian university,” so the population is L2 English learners in an ESL/EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used only to generate comparison texts; there is no experimental or quasi-experimental instructional intervention integrating the LLM into students’ writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on stylometric comparison and authorship attribution (distinguishing AI- vs human-generated texts), not on improving writing competence through a pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No writing outcome measures assessing the effectiveness of an LLM-mediated writing intervention are reported; the study analyzes existing texts rather than evaluating changes in learners’ writing performance.""
    }
}"
11,Artificial Intelligence Vs. Instructor Supported Ai: Teaching Second Language Writing Via Write&improve,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study investigates second language writing, English writing success, and English writing self-efficacy. Although the abstract does not explicitly label participants as EFL/ESL/ELL, the focus is clearly on learners of English as an L2 in an instructional context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses the Write&Improve system. Write&Improve is an automated writing evaluation tool based on Cambridge technology, not described here as a large language model (e.g., ChatGPT, GPT-4). The abstract frames it as an AI feedback system, but there is no indication it is an LLM-based, transformer generative model integrated into instruction, which is required by the review criteria.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on second language writing: outcomes include English writing success and related variables (self-efficacy, achievement emotions, teacher-student interaction). The intervention is clearly situated in L2 writing instruction.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an 8-week pretest-posttest control group design and reports a statistically significant increase in English writing success in the experimental group, indicating quantifiable writing outcome metrics are collected and analyzed.""
    }
}"
12,Developing L2 Postgraduate Students' Strategic and Responsible Use of Genai through a Purposefully Designed Workshop in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as L2 postgraduate students facing challenges in academic writing, indicating second language English learners in an academic writing context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The workshop uses “diverse GenAI tools” and focuses on “strategic and responsible GenAI use,” but the abstract does not specify that these are large language models (e.g., ChatGPT, GPT-4) as opposed to other generative or AI tools. The exact nature of the GenAI tools is not detailed.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly academic writing: the workshop targets stages of the writing process (brainstorming, literature searching, revising, ethical considerations) and aims to support L2 students’ academic writing practices.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are technology proficiency, critical evaluation skills, ethical competence, and AI agency, measured via pre- and post-workshop questionnaires. No quantifiable writing performance or writing quality metrics are mentioned; the focus is on attitudes/skills related to AI use rather than writing outcomes.""
    }
}"
13,Linguistic Analyses of Written Corrective Feedback for Chinese as a Second Language: Chatgpt Versus Human Teachers,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are learners of Chinese as a second language (CSL), specifically a Vietnamese CSL writing sample corpus. The focus is not on L2 English learners in ESL/EFL/ELL contexts, and the target language is Chinese, not English.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study analyzes written corrective feedback generated by ChatGPT (an LLM) versus human teachers. Although primarily comparative, it does integrate an LLM into a feedback context relevant to writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is second language writing, focusing on written corrective feedback on CSL learners’ writing, with an analytic framework for language accuracy and content expressivity—both writing-related variables.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports linguistic analyses of feedback quality (e.g., word order changes, vocabulary difficulty) but does not indicate any measured learning or writing outcome for students (e.g., post-test writing scores). It appears to evaluate feedback characteristics rather than intervention effectiveness.""
    }
}"
14,A Translanguaging Perspective on Students' Use of Generative Artificial Intelligence in L2 Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'Chinese multilingual undergraduates' engaged in 'L2 writing', which in this context strongly implies English as the target language in an EFL/ESL-type setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates students' naturalistic use of 'generative artificial intelligence (GAI)' in L2 writing, using screen recordings, journals, and interviews. It does not describe an experimental or quasi-experimental pedagogical intervention integrating a specific LLM into instruction; rather, it is an observational, qualitative study of existing practices.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on 'GAI-assisted L2 writing' and how students use GAI for creation, translation, evaluation, and revision in their writing processes, aligning with a writing competence/writing-process context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses thematic analysis of qualitative data (screen recordings, reflective journals, interviews) and reports patterns and stances. There is no mention of quantitative writing outcome measures or experimental comparison to assess effectiveness of GAI-mediated writing interventions.""
    }
}"
15,Saudi Efl Learners' Perceptions of Using Artificial Intelligence and Its Impact on Their Writing Skills,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are female Saudi learners of English as a Foreign Language at the University of Jeddah, clearly an EFL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “Artificial Intelligence tools” and explicitly mentions ChatGPT, but does not specify whether all tools are LLM-based or how they are integrated as an instructional intervention beyond general use. However, the main focus is on perceptions rather than a structured experimental or quasi-experimental intervention design.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on learners’ perceptions, attitudes, perceived benefits, and drawbacks of AI tools for writing. There is no description of a designed pedagogical writing intervention being evaluated; instead, it is an attitudinal/perception study about AI use in writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although one research question asks about the impact of AI on writing competency, the abstract reports only qualitative perceptions (e.g., students valued AI, appreciated prompt responses, help with grammar and vocabulary) and does not indicate any quantifiable writing outcome measures or experimental comparison of writing performance.""
    }
}"
16,Enhancing Efl Writing through Ai-driven Video-to-text Recognition in Authentic Learning Contexts,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as EFL learners: “22 first-year university students” in an EFL context, and the focus is on English writing skills (“writing skills of English as a Foreign Language (EFL) learners”).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is an “AI-driven video-to-text recognition” (VTR) system that combines AI and cloud-based technologies. There is no indication that it is a large language model or transformer-based generative model (e.g., ChatGPT, GPT-4). It appears to be a recognition/transcription tool rather than an LLM-based writing assistant.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence: the system is designed “to help learners build vocabulary and write sentences,” and the study evaluates “the impact of the VTR system on writing proficiency,” clearly centering on writing-related outcomes.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that “The results showed improvement in writing skills,” implying quantitative assessment of writing proficiency after a two-week experimental study. Thus, quantifiable writing outcome metrics are likely used, even though specific measures are not detailed in the abstract.""
    }
}"
17,Harnessing Generative Ai for English Curriculum Innovation in Higher Education: a Case Study at Al-zaytoonah University of Jordan,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is English as a Foreign Language (EFL) at a Jordanian university, so participants are L2 English learners in an EFL setting, with focus on English language instruction.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study integrates GenAI/LLMs (ChatGPT) as a supplementary tool in English language classrooms and discusses curriculum design. However, the abstract does not clearly state that there is an experimental or quasi-experimental design specifically targeting writing instruction or writing processes; it may be broader language curriculum use.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing fluency is mentioned as one of several outcomes (along with linguistic autonomy and critical thinking), but the primary focus appears to be overall curriculum innovation and EFL instruction, not necessarily a writing-focused intervention. It is unclear if writing competence is the central focus.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract notes that a mixed-method approach with qualitative and quantitative data was used and claims improvements in writing fluency, but it does not specify any quantifiable writing outcome metrics or structured writing assessments. It is unclear whether concrete writing measures were collected and analyzed, or if writing fluency is inferred from perceptions.""
    }
}"
18,Exploring the Use of Generative Ai on Students’ Academic Writing: an Exploratory Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) learners, and the context is academic writing in English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses ‘generative AI (GenAI)’ to support students’ academic writing, but the abstract does not specify whether the tool is an LLM (e.g., ChatGPT/GPT-based) or another type of generative system. However, even if it were an LLM, the design appears exploratory rather than experimental/quasi-experimental in terms of instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on students’ use of GenAI during an academic writing task, including question categories and adoption of GenAI responses, which is directly related to writing processes and competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines questioning behaviors, adoption of GenAI responses, and perceptions of usefulness and ease of use. There is no indication of quantifiable writing outcome measures (e.g., writing quality scores, accuracy, complexity) to assess the effectiveness of the GenAI-mediated intervention.""
    }
}"
19,Understanding How Ai Chatbots Influence Efl Learners’ Oral English Learning Motivation and Outcomes: Evidence from Chinese Learners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 351 EFL students in China learning spoken English with an AI chatbot, clearly fitting an EFL/ELL L2 English population.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “artificial intelligence chatbots” but does not specify that they are large language model–based (e.g., ChatGPT, GPT-4). The type of AI chatbot (rule-based vs. LLM) is not identified, so it is unclear whether an LLM is involved.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on spoken/oral English learning, motivation, social presence, and self-efficacy. There is no indication that writing competence or writing-related variables are targeted; the context is oral language learning, not writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes concern learning motivation and learning outcomes in spoken English, analyzed via SEM and moderation analysis. No quantifiable writing outcomes or writing performance measures are reported.""
    }
}"
20,Unveiling the Writing Self-efficacy and Its Relationship with Writing Engagement Based on Generative Ai Feedback,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract does not specify that participants are L2 English learners (ESL/EFL/ELL) or that the target language is English. It only refers to “students” and their writing self-efficacy, with no language context provided.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses “generative AI feedback,” but the abstract does not indicate whether this is specifically an LLM (e.g., ChatGPT/GPT-4) or another type of generative system. The nature of the AI tool is not described in sufficient detail to confirm it is an LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on writing self-efficacy and writing engagement, not on writing competence or performance. The abstract does not mention assessment of writing quality, accuracy, or other competence-related writing outcomes, but rather psychological and behavioral variables around writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported concern changes in writing self-efficacy dimensions and their correlation with writing engagement. There is no indication of quantifiable writing performance metrics (e.g., scores, quality ratings) used to evaluate the effectiveness of the AI-mediated writing intervention.""
    }
}"
21,Investigating Efl Students' Attitudes towards Ai-powered Tools in English Language Learning,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 479 Vietnamese university students learning English as a Foreign Language (EFL), clearly an L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates attitudes and perceptions toward various AI-powered tools (e.g., ChatGPT, Grammarly, Duolingo Max, Gemini) via surveys and interviews. There is no indication of an experimental or quasi-experimental design implementing an LLM-based intervention in writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is broad English language learning (grammar, vocabulary, pronunciation, writing skills, motivation, autonomy), not a targeted writing competence intervention. It is an attitudinal/perception study rather than a writing-focused pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports self-reported improvements and attitudes but does not mention any quantifiable writing outcome measures or experimental assessment of writing performance. Outcomes are qualitative/attitudinal, not measured writing gains.""
    }
}"
22,Developing an Ai-driven Contextualized Short Video Learning System for Efl Speaking and Writing,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as EFL learners (45 seventh graders), indicating second language English learners in an EFL context. The focus is on English speaking and writing proficiency.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is ClipTalk, an AI-driven system using GPT-enabled chatbots and intelligent contextual chatbots to provide feedback. The study is an eight-week experimental study integrating LLM-based tools into language learning tasks.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The system is explicitly designed to enhance EFL learners' speaking and writing proficiency, with real-world video production tasks and AI-driven feedback. Writing competence is a primary outcome, not just automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that the study assessed the system's impact on writing and speaking proficiency and found significant improvements in EFL writing and speaking skills, implying quantifiable outcome measures in an experimental design.""
    }
}"
23,What Motivates Second Language Majors to Use Generative Ai for Informal Learning? Insights from the Theory of Planned Behavior,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as “L2 majors at various Chinese universities,” but the target L2 is not specified. It may or may not be English; this cannot be determined from the abstract alone.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates intention to use generative AI via a questionnaire and structural equation modeling. There is no experimental or quasi-experimental design integrating a specific LLM into instruction or writing processes; it is an attitudinal/behavioral intention study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on informal L2 learning intentions and psychological predictors (attitude, subjective norm, perceived behavioral control, GenAI literacy), not on writing competence or writing-related variables. Writing is not mentioned in the abstract.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No writing outcomes or performance metrics are reported. The study uses questionnaire scales and SEM to model behavioral intention, without any measured changes in writing ability or writing-related performance.""
    }
}"
24,Enhancing Chinese Character Writing Learning: the Role of Mllm-based Intelligent Tutoring Systems,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are learners of Chinese as a foreign language, focusing on Chinese character learning. The target language is Chinese, not English, so the population is outside the scope of L2 English (ESL/EFL/ELL) learners required for this review.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an Intelligent Tutoring System grounded in a Multimodal Large Language Model with a feedback mechanism and conducts a teaching experiment to validate its effectiveness, which fits an LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing Chinese characters and the role of corrective feedback in character writing, which is a writing-related competence in the target language.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that students using the ITS perform better in writing Chinese characters than with traditional teaching, indicating quantifiable writing performance outcomes from the intervention.""
    }
}"
25,Future Changes in Teachers' Professional Roles under the Impact of Artificial Intelligence: a Study in English as a Foreign Language Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states the context is English as a foreign language (EFL) education and refers to students learning English as a foreign language, which fits the target L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study involves ‘Generative artificial intelligence (GenAI)’ and ‘student-GenAI interactions’ and ‘teacher-student-GenAI collaboration’. However, the abstract does not specify that the GenAI is a large language model (e.g., ChatGPT, GPT-4) or detail its use in writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on human agency in AI in education and its impact on intrinsic motivation, classroom anxiety, and willingness to communicate in EFL classes. There is no indication that the intervention specifically targets writing competence or writing-related variables; it appears to concern general EFL learning and affective/communicative outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The measured outcomes are intrinsic motivation, classroom anxiety, and willingness to communicate. No quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity, fluency) are mentioned, and writing is not identified as a target skill.""
    }
}"
26,Optimizing English Learning with Ai: Machine Learning Techniques and Tools,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions the ELLIPSE corpus of essays by grade 8–12 learners, but does not clearly state whether these are L2 English learners (ESL/EFL/ELL) or native speakers. The learner population and context are not specified as L2.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a TF-IDF-based GRU model for automated text classification (scoring coherence, syntax, vocabulary, etc.). This is a neural text classifier, not a large language model (LLM) such as ChatGPT/GPT-4, nor is it integrated as an instructional or writing-process intervention. It is essentially an automated scoring/assessment system.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on building an AI model to classify writing quality dimensions (coherence, syntax, etc.) with high accuracy. There is no described pedagogical intervention in writing instruction; rather, it is an assessment framework. It aligns with automated essay scoring functionality, which is outside the review scope.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are model performance metrics (accuracy, precision, recall, F1-score) for text classification, not quantifiable changes in learners’ writing performance resulting from an LLM-mediated intervention. No experimental or quasi-experimental design assessing writing improvement is described.""
    }
}"
27,Enhancing Spelling Proficiency in Higher Education: Leveraging Ai for Improved Learning Outcomes,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 50 English department students at a Moroccan university (EFL/ESL context is strongly implied). The focus is on their use of AI tools for spelling in English, fitting L2 English learner contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study ‘explores the opportunities and the challenges associated with AI-powered learning tools and examines students' attitudes.’ There is no indication of an experimental or quasi-experimental design integrating LLMs into instruction; it appears attitudinal/descriptive rather than an intervention study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on spelling proficiency and attitudes toward AI vs. traditional approaches, not on writing competence or broader writing-related variables. Spelling is treated as a general learning outcome rather than within a writing instruction context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantifiable writing or spelling outcome metrics or an evaluated intervention. It provides ‘insights into implications’ and attitudes, suggesting a non-experimental, perception-focused study without measured learning gains.""
    }
}"
28,Design and Evaluation of a Gamified Chat Generative Pre-trained Transformer-assisted English Course Learning System with Selfregulation Support,2025,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “English language learners” but does not specify whether they are L2 English learners in ESL/EFL/ELL contexts (e.g., school/university learners) or another population. No contextual details (country, educational level) are provided, so it is unclear if the population matches the review’s target.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly uses “Chat Generative Pre-Trained Transformer (ChatGPT)” as the core tool. It employs an experimental design with stratified random assignment to a control group (ChatGPT-assisted learning only) and an experimental group (ChatGPT plus gamified reinforcement and self-regulation nudges), satisfying the requirement for an LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention covers “weekly modules that includes reading, writing, speaking, and listening.” Writing is one of several skills, but the abstract does not indicate that writing competence or writing-related variables are the primary focus of the intervention or analysis. It appears to be a general English course system rather than a writing-focused intervention.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions pre- and post-tests and surveys to capture “learning outcomes and motivational shifts,” with t-tests and effect sizes to compare groups. However, it does not specify whether any of the measured outcomes are writing-specific (e.g., writing scores, text quality metrics). Without explicit mention of quantifiable writing outcomes, it is unclear if C4 is met.""
    }
}"
29,Analysis of Personalized English Teaching Path Planning and Strategies under the Integration of Big Data and Artificial Intelligence,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to 200 students in an English teaching context but does not specify whether they are L2 English learners in ESL/EFL/ELL settings. It could be either L1 or L2 English instruction; this is not clarified.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is described broadly as an AI-supported, big-data-driven personalized learning model using unspecified ‘AI platforms.’ There is no indication that large language models (e.g., ChatGPT, GPT-4) or transformer-based generative models are used; the AI could be any adaptive or analytics system.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study reports improvement in ‘the four skills’ and mentions writing and speaking, but the primary focus appears to be overall English learning outcomes and personalized path planning, not specifically writing instruction or writing-related variables as the central focus.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative post-test outcomes are reported, including a mean improvement of 22% in writing and speaking skills and an 8-point increase in post-test scores, indicating measurable writing-related outcomes.""
    }
}"
30,Balancing Technology with Pedagogy in Smart Classrooms for English Language,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 200 secondary school students in English language instruction, indicating an L2/ELL-type context focused on English language acquisition (reading, writing, speaking, listening).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is ‘smart classroom technologies’ (interactive whiteboards, augmented reality, adaptive learning platforms). There is no mention of large language models (e.g., ChatGPT, GPT-4) or transformer-based generative AI being integrated into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on English language acquisition, including writing skills as one of several language abilities, and compares smart classroom technology versus conventional teaching. Writing competence is part of the targeted outcomes.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantifiable outcomes are reported, including percentage score increases in writing skills (15%) and other language skills, based on pre- and post-tests using standardized assessments.""
    }
}"
31,Understanding Efl Student Writers' Metacognitive Awareness in Utilizing Chatgpt,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 452 EFL undergraduate students in a semester-long writing course, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used by students for academic writing feedback, the study is described as a mixed-method investigation of metacognitive awareness, not as an experimental or quasi-experimental intervention integrating ChatGPT into instruction. There is no indication of treatment vs. control or structured intervention design.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context is EFL academic writing and use of ChatGPT for writing feedback, which is writing-related. However, the primary focus is on metacognitive awareness and practices rather than on systematically improving writing competence through an instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports validation of a metacognitive awareness scale and qualitative insights into metacognitive practices. It does not mention any quantifiable writing outcome metrics (e.g., writing scores, text quality measures) to assess the effectiveness of ChatGPT-mediated writing intervention.""
    }
}"
32,Unlocking Efl Learners' Insights into Chatgpt Use for L2 Writing: the Impacts of Usage Frequency and Gender Variations,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 874 Turkish undergraduate English majors (EFL learners) at a state university in Türkiye, and the focus is on their use of ChatGPT for L2 (English) writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates learners’ perceptions of ChatGPT use and how gender and usage frequency affect these perceptions. There is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction; ChatGPT use is self-initiated ‘beyond the classroom’ rather than a structured LLM-mediated intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on perceptions of ChatGPT use (Technology Acceptance Model) and gender/usage frequency differences, not on writing competence or writing-related performance variables. No pedagogical writing intervention is described.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are perceptions (via the ChatGPT Perception Scale), usage frequency, and gender differences. The abstract does not mention any quantifiable writing performance metrics or changes in writing quality attributable to ChatGPT use.""
    }
}"
33,A Comparative Study of the Efficacy of Llms in Generating Learning Resources for Non-english Major Postgraduates,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as 'non-English major postgraduate students at a university.' Their L2 status and whether the focus is specifically on English as a second/foreign language is not explicitly stated, though it is implied they are learning English. This is not fully clear from the abstract alone.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares ERNIE Bot and ChatGPT in 'producing pertinent language learning materials' and 'supplementary learning resources.' There is no indication of an experimental or quasi-experimental pedagogical intervention where LLMs are integrated into students’ writing instruction or writing processes; instead, the focus is on evaluating generated materials.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although 'writing' is one of four dimensions (vocabulary, translation, reading, writing) used to assess generated materials, the primary focus is on the LLMs’ ability to create learning resources across multiple skills, not on learners’ writing competence or writing-related development. It is essentially a functionality/comparative study of LLM outputs as educational resources.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics for learners (e.g., changes in writing scores, accuracy, complexity). Evaluations are of the LLM-generated materials by students and educators, not of learners’ writing performance following an LLM-mediated intervention.""
    }
}"
34,Teaching Is Basically Feeling: Unpacking Efl Teachers' Perceived Emotions and Regulatory Strategies in Ai-powered L2 Speaking and Writing Skills Instruction,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 21 Iranian EFL teachers working in L2 speaking and writing instruction, clearly within an EFL/ESL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although AI tools are used in L2 speaking and writing classes, the study is qualitative and explores teachers’ emotions and regulatory strategies. There is no indication of an experimental or quasi-experimental design assessing an LLM-based writing intervention (e.g., ChatGPT). The specific AI tools and whether they are LLMs are not specified.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on teacher emotionality and emotion regulation when integrating AI in L2 productive skills, not on learners’ writing competence or writing-related performance variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly qualitative, using semi-structured interviews and narrative frames, and reports thematic findings about emotions and strategies. It does not report quantifiable writing outcome metrics or effectiveness of AI/LLM-mediated writing interventions.""
    }
}"
35,The Impact of Integrating Chatgpt with Teachers' Feedback on Efl Writing Skills,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 68 intermediate Iranian EFL learners working on IELTS Task 2 argumentative essays. This clearly indicates L2 English learners in an EFL context, with English as the target language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention explicitly integrates ChatGPT, described as a state-of-the-art AI chatbot, with teacher feedback to provide individualized writing feedback. Learners were randomly assigned to ChatGPT+teacher feedback vs teacher-only feedback, indicating an experimental design using an LLM in writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL essay writing (IELTS Task 2) and writing proficiency. ChatGPT is used pedagogically to provide feedback on writing, and outcomes are reported in terms of writing criteria (task achievement, coherence, cohesion, vocabulary, grammar range and accuracy).""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative writing outcomes are reported: a Paired Samples t-Test showed significantly greater improvement for the ChatGPT+teacher group across IELTS scoring criteria (task achievement, coherence, cohesion, vocabulary, grammar range and accuracy). These are clear, quantifiable writing outcome measures.""
    }
}"
36,"Chinese College Students' Usage, Evaluation, Perception and Attitude Toward Generative Ai in English as a Foreign Language Writing",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese college students using generative AI tools in EFL (English as a Foreign Language) writing, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a two-stage survey on students' usage, evaluation, perceptions, and attitudes toward generative AI tools. It does not describe an experimental or quasi-experimental intervention integrating a specific LLM into writing instruction or processes; it is observational and perception-focused.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is EFL writing, the primary focus is on how students use and perceive AI tools (benefits, concerns, attitudes), not on a structured pedagogical writing intervention or systematic integration of an LLM into instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports survey ratings of benefits and concerns but does not mention any quantifiable writing performance outcomes (e.g., writing scores, text quality measures) resulting from an LLM-mediated intervention.""
    }
}"
37,Exploring Efl Students' Prompt Engineering in Human-ai Story Writing: an Activity Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) students: sixty-seven Hong Kong secondary school students writing short stories in English, which fits the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""Students created and used their own generative-AI tools based on open-source language models during short story writing. These are transformer-based generative models (LLMs) integrated into the writing process, satisfying the LLM intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly writing-focused: students used generative AI tools specifically for short story writing, and the study examines prompting behavior and story development, aligning with writing competence and writing-related processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative themes (purposes for prompting, characteristics of activity systems) and mentions story quality descriptively, but does not indicate any experimental or quasi-experimental design, control/comparison, or quantifiable writing outcome metrics to assess effectiveness of the LLM-mediated intervention. It is primarily exploratory/qualitative, so it does not meet the requirement for measurable writing outcomes.""
    }
}"
38,Artificial Intelligence as an Equaliser: How Chatgpt Empowers Academics in the Global South,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract refers broadly to 'early-career scholars, non-native English speakers, and unaffiliated researchers' in the Global South, not specifically to L2 English learners in ESL/EFL/ELL instructional contexts. The focus is on academic researchers, not language learners in a pedagogical setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT is mentioned, the article is conceptual/argumentative, discussing potential uses and policy issues. There is no indication of an experimental or quasi-experimental design integrating LLMs into writing instruction or structured writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on academic publishing, equity, and policy debates around AI-assisted writing, not on a pedagogical context targeting writing competence or writing-related variables in an instructional setting.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any empirical study, intervention, or quantifiable writing outcome metrics. It appears to be a discursive piece advocating for ethical AI use rather than reporting measured effects on writing.""
    }
}"
39,"Negotiating Understanding, Control, and Authorship: L2 Learners' Experiences with Ai-assisted Paraphrasing in Academic Writing",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are twelve English-as-a-foreign-language (EFL) students at a university, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study explores students’ experiences with unspecified ‘AI tools’ for paraphrasing, but there is no indication these are large language models (e.g., ChatGPT, GPT-4) or that there is an experimental or quasi-experimental intervention design. It is a qualitative interview study of existing practices.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on academic paraphrasing, an aspect of academic writing, and how AI tools are used in that process, which aligns with writing-related variables rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is purely qualitative, based on interviews and thematic analysis. It does not report quantifiable writing outcome metrics or measure the effectiveness of an AI-mediated writing intervention.""
    }
}"
40,"Integrating Ai in Pakistani Esl Classrooms: Teachers' Practices, Perspectives, and Impact on Student Performance",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 100 undergraduate students in Pakistani ESL classrooms, clearly L2 English learners in an ESL context. The focus is on English vocabulary and writing skills.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses AI tools such as Grammarly and QuillBot. These are not described as large language model-based instructional systems in the abstract and are typically categorized as non-LLM tools (grammar checker/paraphraser) rather than transformer-based generative LLMs like ChatGPT or GPT-4, which the review specifically targets.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on ESL instruction with outcome measures including writing performance and vocabulary, and examines how AI tools are integrated into classroom teaching, which is directly related to writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative pre- and post-tests on vocabulary and writing skills are reported, with specific gains in writing performance (+46%, d = 1.03), providing measurable writing outcomes for the AI-mediated intervention.""
    }
}"
41,Chatgpt-supported Collaborative Argumentation: Integrating Collaboration Script and Argument Mapping to Enhance Efl Students' Argumentation Skills,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are clearly identified as EFL (English as a Foreign Language) university freshmen, and the focus is on their English argumentation skills in speaking and writing contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is a quasi-experimental design using ChatGPT, explicitly described as a large language model, to support collaborative argumentation through a structured collaboration script (preparation, interaction, reflection).""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary measured outcomes are argumentative speaking performance, critical thinking awareness, and collaboration tendency. While argumentation is relevant to writing, the abstract emphasizes speaking performance rather than writing competence or writing-related performance measures as the main focus.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports quantitative outcomes (e.g., effect sizes) for argumentative speaking performance, critical thinking awareness, and collaboration tendency. It does not specify any quantifiable writing outcome metrics (e.g., written argument quality scores), so it is unclear whether writing performance was measured at all.""
    }
}"
42,Teachers' Perceptions and Students' Strategies in Using Ai-mediated Informal Digital Learning for Career Esl Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are university students in an English writing course in an ESL context (“career ESL writing instruction”), so they are L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students use AI tools including ChatGPT (an LLM) and other tools (Grammarly, Canva with Magic Write, Invideo), the design is described as a case study focusing on teachers’ perceptions and students’ strategies. There is no indication of an experimental or quasi-experimental intervention design testing LLM integration; it is exploratory/qualitative rather than an intervention study.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly writing-focused: “career ESL writing instruction,” “English writing course,” and exploration of how AI-mediated informal digital learning tools are used in writing projects and rhetorical accessibility.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses demographic questionnaires, think-aloud protocols, and semi-structured interviews, and reports strategies and perceptions. There is no mention of quantitative writing outcome measures (e.g., scores, rubric-based gains, accuracy measures) assessing effectiveness of the LLM-mediated intervention.""
    }
}"
43,"Using Ai to Enhance Digital Multimodal Composing: Efl Learners' Semiotic Decision-making, Self-efficacy, Enjoyment, and Continuance Intention",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners in an academic English course, clearly fitting the L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses an unspecified AI-powered text-to-video technology for digital multimodal composing. There is no indication that this is an LLM-based tool (e.g., ChatGPT, GPT-4) or that transformer-based generative language models are integrated into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on digital multimodal composing (text-to-video) and learners’ semiotic decision-making, self-efficacy, enjoyment, and continuance intention, not on writing competence or writing-related variables as primary outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports reflections, questionnaire responses, and evaluations of AI-generated videos, focusing on perceptions and intentions. It does not report quantifiable writing outcome metrics assessing changes in writing performance due to the AI intervention.""
    }
}"
44,Exploring High School Students' Preferences for English Writing Feedback: Non-native English Teacher Vs. Native English Teacher Vs. Chatgpt,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 20 high school students from an English newspaper club in Korea, clearly an EFL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used as one of several feedback providers, but the study is observational/comparative, focusing on students’ preferences for different feedback sources. There is no experimental or quasi-experimental LLM-based instructional intervention aimed at improving writing performance.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on preferences and perceptions of feedback sources (non-native teacher, native teacher, ChatGPT, and collaborative feedback), not on writing competence or development as an outcome of a pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are Likert-scale ratings of feedback preference and qualitative themes. No quantifiable writing performance metrics (e.g., scores, quality measures, accuracy) are reported to assess the effectiveness of ChatGPT-mediated writing intervention.""
    }
}"
45,"I, Too, Shall Have to Prompt? a Study of Efl Students and Their Unmonitored Use of Genai in the Completion of an Imitation Task in Poetry",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students in a university English as a Foreign Language Literature course, so they are L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to a ‘GenAI model’ and ‘GenAI-assisted creative writing exercise’ but does not specify whether the tool is a large language model (e.g., ChatGPT/GPT-4) or another type of generative AI. The specific technology and architecture are not identified.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on a literature course and on how the GenAI-assisted imitation task supports application of literary analysis elements, prompt characteristics, and pedagogical implications. Writing competence or writing-related performance is not the central outcome; rather, it is use of literary terms and analysis.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is based on qualitative data from surveys and observational studies. The abstract does not report any quantifiable writing outcome metrics (e.g., writing scores, rubric-based assessments) to evaluate the effectiveness of the GenAI intervention on writing performance.""
    }
}"
46,Investigating Efl Teachers' Lesson Planning for Chatbot-assisted Learning of Argumentative Writing: a Tpack Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly English as a foreign language (EFL), and the focus is on teaching argumentative writing in English, implying L2 English learners.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses a chatbot named Argumate, but the abstract does not specify whether it is an LLM-based, transformer generative model (e.g., ChatGPT-like) or a rule-based/other type of chatbot. Thus it is unclear if it meets the LLM requirement.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on teachers’ lesson planning and professional knowledge (TPACK) for chatbot-assisted argumentative writing. It analyzes lesson plans and interviews, not an implemented pedagogical intervention with learners’ writing performance as the primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No experimental or quasi-experimental design with learners is reported, and no quantifiable writing outcome metrics are mentioned. The study is conceptual/qualitative about planning and integration, not about measured writing gains.""
    }
}"
47,Comparing Hong Kong Secondary School Students' Perceptions of Chatgpt-assisted Efl Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 107 Hong Kong secondary school students in an EFL context, and the focus is explicitly on EFL (English as a foreign language) writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines ChatGPT-assisted EFL writing and compares three teaching approaches (process-based, genre-based, and prompt-engineering-only) in a quantitative design, indicating an LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary outcomes are motivation, cognitive load, and satisfaction. While situated in a writing context, the abstract does not indicate that writing competence or writing performance measures are a focus; instead, it centers on affective and cognitive variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, quality ratings, accuracy, complexity) are reported. The measured variables are motivation, cognitive load, and satisfaction, which do not meet the requirement for writing outcome measures.""
    }
}"
48,Does Metalinguistic Explanation of Teacher and Chatgpt Feedback Improve Efl Learners' Writing Quality and Engagement? Findings from an Intervention Study,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL learners (foreign language writing instruction, EFL learners), indicating L2 English learners in an EFL context with focus on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is a quasi-experimental intervention examining scaffolded metalinguistic explanations of teacher and ChatGPT feedback. ChatGPT is a large language model integrated into the writing feedback process, satisfying the LLM-based intervention requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is foreign language writing instruction, focusing on how feedback (including ChatGPT feedback) affects EFL learners’ writing quality and engagement. The primary pedagogical target is writing competence, not automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pre-tests and post-tests, written drafts, and reports significant improvements in writing performance (grammatical accuracy, vocabulary use, mechanical control) and incorporation of feedback, indicating quantifiable writing outcome measures within an intervention design.""
    }
}"
49,Assigning Cefr-j Levels to English Learners' Writing: an Approach Using Lexical Metrics and Generative Ai,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The system is designed for assessing English learners’ writing proficiency in an EFL context (CEFR-J, tailored to EFL in Japan). The ICNALE GRA dataset consists of English learner writing, so the population focus is on L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study presents CWLA as an automated scoring system that combines lexical metrics with AI-based analytical scores. It is an assessment tool, not an experimental or quasi-experimental pedagogical intervention integrating an LLM into writing instruction or writing processes. No LLM-mediated instructional treatment is described.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automated writing proficiency assessment (CEFR-J level assignment) and validation against human ratings, not on improving writing competence through instructional use. This aligns with automated essay scoring functionality, which is explicitly excluded.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are correlations between CWLA scores and human ratings, entropy analysis, and expert agreement rates. These are validation metrics for an assessment tool, not quantifiable writing outcome measures from an LLM-mediated writing intervention or instructional experiment.""
    }
}"
50,Rnn Hybrid Model for Evaluating Efl Teachers' Classroom Performance in Higher Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract focuses on evaluating EFL teachers’ classroom performance in higher education using an RNN-based model. There is no indication that the participants are L2 English learners or that learner data in an ESL/EFL/ELL context is the focus; instead, the target of evaluation is teachers.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses an Elman RNN combined with a Dolphin Echolocation Algorithm (DEA-RNN) as a predictive/evaluation model. This is a traditional recurrent neural network approach, not a large language model (e.g., ChatGPT, GPT-4, Gemini), and it is not integrated into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is teacher performance evaluation in higher education, not writing competence or writing-related variables. There is no mention of writing instruction, writing tasks, or writing development as a primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are model performance metrics (accuracy, precision, recall, F1-score, specificity) for evaluating teachers, not quantifiable writing outcomes or measures of L2 writing performance following an intervention.""
    }
}"
51,Exploring Ai to Automate Efl Corrective Written Feedback in the First Language,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The title and abstract indicate an EFL context with students whose L1 is Japanese, implying they are L2 English learners receiving corrective written feedback on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a ChatGPT-powered plugin (a large language model) within Moodle to provide automated written corrective feedback as part of a classroom intervention, satisfying the LLM-based intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention centers on a free-writing activity and subsequent written corrective feedback on students’ writing, clearly focusing on writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports analysis of survey data and ChatGPT-generated feedback, focusing on perceptions of accuracy, comprehensibility, and appreciation. It does not mention any quantitative writing outcome measures (e.g., changes in writing quality, accuracy, complexity) or pre/post comparisons of learners’ writing performance.""
    }
}"
52,"Exploring Efl Students' Ai Literacy in Academic Writing: Insights into Familiarity, Knowledge and Ethical Perceptions",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Turkish English as a Foreign Language (EFL) students, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a descriptive exploratory survey to examine AI literacy, familiarity, and perceptions. There is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on AI literacy, familiarity, usage patterns (translation, grammar proofreading), and ethical perceptions, not on a structured pedagogical writing intervention or systematic use of LLMs to develop writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports survey-based perceptions and literacy levels; it does not report quantifiable writing outcome metrics (e.g., changes in writing quality, scores) resulting from an LLM-mediated intervention.""
    }
}"
53,"A Q Method Study on Turkish Efl Learners' Perspectives on the Use of Ai Tools for Writing: Benefits, Concerns, and Ethics",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Turkish English language learners enrolled in a preparatory program at a state university in Istanbul, clearly an EFL/ELL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study explores learners’ perspectives on the use of unspecified AI tools for writing via a Q methodological approach. There is no indication of an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on perceptions of benefits, concerns, and ethics regarding AI tools in writing, not on a structured pedagogical writing intervention or instructional design using LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative perspectives and Q-sort results but does not mention any quantifiable writing outcome measures (e.g., writing scores, text quality metrics) resulting from an AI-mediated intervention.""
    }
}"
54,"The Role of Techno-competence in Ai-based Assessments: Exploring Its Influence on Students' Boredom, Self-esteem, and Writing Development",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 66 Saudi Arabian male EFL learners, clearly L2 English learners in an EFL context: “EFL learners… 66 Saudi Arabian male students…”.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract refers only to “AI-driven evaluations” and “AI-enhanced assessments” without specifying the technology. There is no indication that a large language model (e.g., ChatGPT, GPT-4) or transformer-based generative model was used; it could be any AI-based assessment tool. Thus it does not clearly meet the LLM requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing development is one of the main outcome variables: the study examines how AI-based assessments affect “writing skills,” “writing proficiency,” and “writing abilities,” which aligns with a primary focus on writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an experimental design with EG vs. CG and “pre- and post-assessments… to gauge… writing proficiency,” indicating quantifiable writing outcome metrics are reported alongside boredom and self-esteem.""
    }
}"
55,Interactive Eassessment of Writing Competency in French as a Foreign Language: Development and Implementation of an Ai-enhanced Progress Monitoring System,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are learners of French as a Foreign Language in Moroccan primary schools. The focus is on writing competency in French, not on L2 English learners in ESL/EFL/ELL contexts, and the target language is French rather than English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions an 'AI-enhanced progress monitoring system' and 'automated analysis,' but does not specify that the AI is a large language model (e.g., ChatGPT, GPT-4) or a transformer-based generative model, nor that it is integrated into writing instruction rather than assessment.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on formative e-assessment and progress monitoring of writing competency via an AI-enhanced system, not on writing instruction or intervention. It is essentially an assessment/monitoring tool, aligning more with writing assessment functionality than with pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study reports qualitative teacher responses, system interaction statistics, and feedback analysis. It does not clearly report quantifiable writing outcome metrics (e.g., pre/post writing scores) demonstrating changes in learners’ writing performance attributable to the AI system.""
    }
}"
56,Leveraging Ai for Writing Instruction in Efl Classrooms: Opportunities and Challenges,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 150 fourth-year English major students in an EFL context (a university in the Mekong Delta), clearly L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract refers generically to “AI writing tools” without specifying large language models (e.g., ChatGPT, GPT-4). It appears to be a broad exploration of AI tools rather than a defined LLM-based intervention, and no particular LLM is identified.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on EFL writing instruction and how AI tools support writing skills, including feedback and learner independence in writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study is mixed methods, the abstract only reports perceptions and self-reported improvement (e.g., ‘help… achieve better writing skills’) without mentioning any experimental or quasi-experimental design or quantifiable writing outcome measures (e.g., scores, rubric-based gains).""
    }
}"
57,"Generative Ai-assisted Feedback and Efl Writing: a Study on Proficiency, Revision Frequency and Writing Quality",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are sixty postgraduate English as a Foreign Language (EFL) students, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Grammarly as the AI-enhanced feedback system. Grammarly is generally not an LLM-based, transformer-style generative model like ChatGPT, GPT-4, or Gemini; it is typically categorized as an AI writing assistant outside the scope of LLM-focused interventions specified in the review criteria.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on writing proficiency, revision practices, and writing quality, with Grammarly used as feedback during the writing process. The primary focus is on writing competence and related variables, not on automated essay scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative outcomes: pre- and post-test writing proficiency scores, correlations between AI feature use and revision frequency, and improvements in content, organization, and cohesion, providing measurable writing outcome metrics.""
    }
}"
58,"Generative Ai Vs. Teachers: Feedback Quality, Feedback Uptake, and Revision",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 60 EFL secondary students from a high school in China. The context is explicitly EFL, and the task involves writing in English, satisfying the L2 English learner population requirement.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a generative AI bot (ChatGPT), a large language model, to provide feedback on students’ writing. It employs a 2x2 counter-balanced experimental design comparing AI-generated and teacher feedback, thus integrating an LLM into the writing process in an experimental framework.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on written samples, feedback quality, feedback uptake, and revision. The intervention directly targets writing (students write on two topics, receive feedback, and resubmit revised work), aligning with writing competence and writing-related variables rather than mere automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative analyses of feedback quality and uptake (e.g., AI outperformed a teacher in meaning-level feedback; teacher feedback had higher uptake rates). It also involves revision outcomes after feedback, indicating measurable writing-related outcomes within an experimental design.""
    }
}"
59,"Bridging Ai and Pedagogy: How Ai-adaptive Feedback Shapes Chinese Efl Students' Writing Engagement, Metacognitive Writing Strategies, and Writing Performance",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Chinese university EFL learners in EFL writing contexts, so they are L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract refers to “AI-adaptive feedback” and “AI-enhanced adaptive feedback” but does not specify that the system is based on large language models (e.g., ChatGPT, GPT-4). It appears to be an adaptive feedback system rather than an LLM-integrated writing intervention, and no LLM is named or implied.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly EFL writing pedagogy, focusing on writing engagement, metacognitive writing strategies, and writing performance, which are writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes, including writing performance and its relationships with AI-adaptive feedback, engagement, and metacognition, analyzed via structural equation modeling with reported beta coefficients.""
    }
}"
60,Enhancing Students' L2 Writing by Integrating Artificial Intelligence with Corpus-based Language Pedagogy,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 50 English as a Foreign Language (EFL) learners majoring in English at an English-Medium Instruction university in China, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers only to generic 'AI tools' and does not specify that they are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems. They could be non-LLM tools (e.g., grammar checkers). Without explicit indication of LLM use, it cannot be confirmed that the intervention integrates LLMs.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on L2 students’ writing revision, integrating AI and corpus-based language pedagogy to support writing development, with attention to lexico-grammatical patterns, collocations, and sentence revision—clearly a writing-focused pedagogical context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although drafts and revisions were collected and changes analyzed, the abstract does not report or clearly indicate quantifiable writing outcome metrics (e.g., scores, error rates, quality ratings) to assess effectiveness. The emphasis is on types of changes, tool preferences, and attitudes, not on experimental outcome measures of writing performance.""
    }
}"
61,From Spicing up My Writing to Convincing My Supervisors: Efl Learners' Motivations for Using Promotional Language ('hypes') in Academic Texts,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Indonesian EFL learners writing theses and dissertations, so they are L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although AI tools are mentioned as one of several external motivational factors, there is no indication of an experimental or quasi-experimental design integrating LLMs into writing instruction or processes. The study is qualitative, based on interviews, and does not describe a structured LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on motivations for using promotional language (hypes) and identity/power dynamics in academic discourse, not on writing competence or a pedagogical writing intervention. AI tools are discussed as influences, not as part of a designed instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses in-depth interviews and thematic analysis; it does not report quantitative writing outcome measures or assess the effectiveness of any LLM-mediated writing intervention.""
    }
}"
62,Probing into Efl Students' Perceptions about the Impact of Utilizing Ai-powered Tools on Their Academic Writing Practices,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 30 EFL students enrolled in an Academic Writing 2 course at a private university in Oman, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is one of several AI-powered tools used, the study is framed as an exploration of perceptions, not as an experimental or quasi-experimental design assessing an LLM-based writing intervention. The abstract does not describe controlled conditions, treatment vs. comparison, or structured LLM integration as an intervention with measured effects.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is academic writing in an EFL course, focusing on grammar, style, paraphrasing, summarizing, brainstorming, and stages of the writing process, which are all writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a qualitative approach (learning journals, observations, focus-group interviews) to explore perceptions. While it claims that tools improved writing skills and performance, no quantifiable writing outcome metrics or experimental measures are reported in the abstract; outcomes are described qualitatively.""
    }
}"
63,Effects of Human-ai Collaborative Writing Strategy on Efl Students' Argumentative Writing Skills,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Indonesian EFL university freshmen, so they are L2 English learners in an EFL context and the focus is on English argumentative writing skills.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to a “human-AI collaborative writing strategy,” “AI-assisted tools,” and “intelligent technology-enhanced writing instruction,” but does not specify which AI tools were used or whether they are LLM-based (e.g., ChatGPT, GPT-4). It could involve non-LLM tools such as grammar checkers, so it is not possible to confirm that an LLM is the core of the intervention from the abstract alone.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on improving students’ argumentative writing skills and critical thinking as realized in written discourse. The intervention is clearly pedagogical and writing-focused, not an evaluation of automated scoring systems.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a one-group pretest–posttest design with essay tests scored using established rubrics (Hamp-Lyons’ MT and Facione’s HCTSR) and reports statistical outcomes (t-values, p-values, eta squared). These are quantifiable writing outcome metrics assessing the effectiveness of the intervention.""
    }
}"
64,Investigating L2 Learners' Text-to-video Resemiotisation in Ai-enhanced Digital Multimodal Composing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 75 undergraduates in an English writing course at a comprehensive university in China, i.e., L2 English learners in an EFL context. The focus is on English writing (technical proposals).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Pictory, an AI-powered text-to-video platform that generates video clips from search queries. The abstract does not indicate that this is a large language model (LLM) such as ChatGPT/GPT-4 or a transformer-based generative text model integrated into writing instruction; it is primarily a text-to-video tool for multimodal composing.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on digital multimodal composing (DMC) and text-to-video resemiotisation, examining how students integrate linguistic, semiotic, and technological elements to create videos. Writing is present (technical proposals), but the central outcome is multimodal/video composition processes rather than writing competence or writing-related variables as the main focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study relies on content analysis of reasons for revising search queries and comparative analysis of original/revised search texts and resulting videos. There is no mention of quantitative writing outcome metrics (e.g., writing scores, accuracy, complexity) to assess the effectiveness of the AI-mediated intervention on writing performance.""
    }
}"
65,"Ai in Academic Writing: Assessing the Effectiveness, Grading Consistency, and Student Perspectives of Chatgpt and You.com for Efl Students",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 16 B1–B2 level students majoring in English Language and Literature or English Language Teaching at a School of Foreign Languages. The context is explicitly English as a Foreign Language (EFL) education, and the focus is on English academic writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses ChatGPT and You.com (both LLM-based tools) to generate feedback and grade initial and revised drafts. AI-generated feedback plus targeted training sessions constitute an instructional intervention integrated into students’ writing processes, with an experimental/mixed-methods design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on academic writing skills in EFL. The study examines AI-generated feedback and training sessions as part of writing instruction, not merely as an automated scoring validation study. It explicitly aims to enhance writing skills and inform writing pedagogy.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative writing outcomes are reported: rubric-based scores (Grammar and Mechanics, Sentence Structure, Cohesion and Coherence, Argumentation/Content Development, Vocabulary Usage, Task Achievement) out of 30, with statistical analyses (paired t-tests, independent t-tests, ANOVA) showing significant improvements from first to final drafts.""
    }
}"
66,'critical Chatting' or 'casual Cheating': How Graduate Efl Students Utilize Chatgpt for Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are four graduate EFL students using ChatGPT for academic writing, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly investigates ChatGPT-assisted academic writing, i.e., integration of an LLM (ChatGPT) into students’ writing processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on academic writing practices (language editing, knowledge inquiry, inspiration seeking) and how ChatGPT is used within these writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes a qualitative case study exploring purposes, rationales, and critical thinking in ChatGPT-assisted writing, using thematic analysis. It does not mention any experimental or quasi-experimental design, nor any quantifiable writing outcome metrics (e.g., writing scores, rubric-based improvements). Outcomes are qualitative (uses, roles, CT), so it does not meet the requirement for measurable writing outcomes.""
    }
}"
67,English as a Foreign Language (efl) Secondary School Students' Use of Artificial Intelligent (ai) Tools for Developing Writing Skills: Unveiling Practices and Perceptions,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL secondary school students using AI tools to develop English writing skills, clearly fitting an EFL/ESL/ELL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is descriptive/exploratory, examining students’ existing practices and perceptions of AI writing tools (Grammarly, ChatGPT, Google Translate) via questionnaires and interviews. There is no experimental or quasi-experimental intervention integrating LLMs into instruction; tools are not systematically implemented as a treatment.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on how AI writing tools mediate stages of the writing process and support idea generation, vocabulary, and accuracy—clearly centered on writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are students’ practices and perceptions; no quantifiable writing performance metrics or experimental measures of writing improvement are mentioned. The mixed methods design uses questionnaires and interviews about use and views, not pre/post or controlled writing outcome measures.""
    }
}"
68,"The Impact of Self-revision, Machine Translation, and Chatgpt on L2 Writing: Raters' Assessments, Linguistic Complexity, and Error Correction",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as learners in a South Korean high school English as a Foreign Language (EFL) context, clearly indicating L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a controlled experiment with three proofreading interventions, including ChatGPT-assisted proofreading (CAP). ChatGPT is an LLM integrated into the writing process as part of an experimental design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on L2 writing outcomes and proofreading interventions (self, MT, ChatGPT) to enhance L2 writing, with attention to writing quality, linguistic complexity, and error correction—core writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports quantifiable writing outcomes: overall writing quality (raters’ assessments), text length, lexical diversity, sentence complexity, verb cohesion, and grammatical/prepositional error rates, comparing SP, MAP, and CAP conditions.""
    }
}"
69,Chat Gpt a Project Based Professional Learning as an Alternative Learning to Traditional Writing : a Quick Response Generator to Improve Writing Skills,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are a 'selected group of students enrolled in different programs at university level' focused on 'English Language development' and 'professional writing topics' such as business correspondence. This indicates L2 English learners in an EFL/ESL academic context, with English as the target language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study compares 'the traditional mode of writing skills' with a 'techno-aided tool i.e. Chat GPT an open AI Tool (CHAT-OAI).' It is described as a 'quasi-experimental design' where the treatment group is taught/appraised using ChatGPT, an LLM-based tool, integrated into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on 'improving Writing Skills' and 'professional writing topics' (letters, emails, reports, notices, memorandums, etc.). ChatGPT is used as part of a 'Project Based professional Learning' intervention specifically targeting writing competence, not just automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The design is 'a quasi-experimental design with pre-recorded test and post recorded test experimental set-up where the impact of techno tools on Professional writing topics is studied.' This implies quantifiable pre/post writing outcome measures comparing traditional vs. ChatGPT-supported instruction.""
    }
}"
70,"The Impact of Ai-enhanced Natural Language Processing Tools on Writing Proficiency: an Analysis of Language Precision, Content Summarization, and Creative Writing Facilitation",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly situates the study in the context of English as a Foreign Language (EFL) education, indicating participants are L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses “AI-enhanced tools for grammar checking, vocabulary enhancement, and sentence structure refinement” and more generally “AI-driven NLP tools.” There is no indication these are transformer-based generative large language models (e.g., ChatGPT, GPT-4). The description aligns more with traditional NLP/grammar-checking tools rather than LLM-mediated interaction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing proficiency, including language precision, content summarization, and creative writing facilitation in EFL writing, which fits the writing-competence context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a pretest–posttest experimental design with random assignment and reports that the treatment group showed superior improvements in writing proficiency, implying quantifiable writing outcome metrics analyzed via descriptive and inferential statistics.""
    }
}"
71,Human-ai Collaborative Feedback in Improving Efl Writing Performance: an Analysis Based on Natural Language Processing Technology,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 260 EFL students from tertiary institutions, so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to a “human-AI collaborative feedback mechanism” and “integrating AI into EFL feedback systems,” but does not specify that the AI is a large language model (e.g., ChatGPT/GPT-4) or transformer-based generative tool. It could be another form of NLP-based feedback system, so it is unclear whether an LLM is involved.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on EFL writing proficiency and performance, with outcomes such as language accuracy, complexity, and fluency, and on feedback for writing. This aligns with a primary focus on writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses regression and mediation tests to examine relationships between feedback and writing performance and reports that human-AI feedback “significantly enhances writing performance.” However, the abstract also notes reliance on self-reported data and does not clearly state whether objective, quantifiable writing performance measures (e.g., rated texts) were collected, or if analyses are solely based on perceived improvement.""
    }
}"
72,Enhancing Learning Outcomes in Written Production by Implementing Writing Strategies and Using Ai Writing Tools,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are university students taking English for Specific Purposes and English for Academic Purposes courses at Slovak universities, indicating an EFL/ESL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions that student assignments were screened for AI use and that some students rely heavily on AI tools, but it does not specify the use of large language models (e.g., ChatGPT, GPT-4) nor describe an experimental or quasi-experimental LLM-based instructional intervention. AI use appears incidental and unstructured rather than a designed LLM-mediated intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study focuses on written production in ESP/EAP courses and examines progress in study results, which likely involves writing competence. However, the abstract does not clearly state that the primary focus is on writing competence as opposed to broader course performance.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses pre-test and post-test results with a t-test showing statistically significant differences, suggesting quantifiable outcomes. However, it is unclear whether these measures are specifically writing outcome metrics or more general course performance, and no explicit link is made between AI tool use and measured writing gains.""
    }
}"
73,The Impact of Chatgpt on Academic Writing Skills and Knowledge: an Investigation of Its Use in Argumentative Essays,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as EFL students and third-year English majors, indicating L2 English learners in an EFL context. The focus is on their English argumentative writing development.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The title and abstract specify ChatGPT and AI-assisted writing, implying an LLM-based tool. However, the abstract does not clearly describe the intervention design (e.g., how ChatGPT was integrated, whether there was a structured experimental or quasi-experimental treatment, or any comparison/control condition). It is unclear if this is a systematic LLM-mediated instructional intervention versus observational use.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on academic argumentative writing skills: writing quality, argument construction, evidence integration, academic voice, and related dimensions (content, organization, language use, critical thinking, AI integration, academic integrity). This aligns with writing competence as the central outcome.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative writing outcomes are reported: comparative analysis of first and fifth drafts as pre- and post-tests, evaluated with a multi-dimensional rubric (AIAS framework), and significant enhancements in writing performance (e.g., +3.0 points in academic integrity). Thus, there are measurable writing outcome metrics.""
    }
}"
74,Genai as a Learning Buddy for Non-english Majors: Effects on Listening and Writing Performance,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 93 undergraduates enrolled in mandatory English as a Foreign Language (EFL) courses at a public university. The focus is explicitly on English listening and writing skills, fitting ESL/EFL/ELL L2 English learner contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ‘guided chatbot interactions’ and ‘researcher-designed GenAI-mediated listening and writing activities’ as the core intervention, contrasted with a traditional curriculum. GenAI chatbots are a form of LLM-based tool, and the design is quasi-experimental with experimental vs comparison groups.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention explicitly targets ‘listening and writing skills’ and involves 10 weekly GenAI-mediated listening and writing activities. Writing competence is a primary outcome domain, not just automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes: both groups improved over time, with the experimental group showing significantly greater gains in listening and writing at immediate post-test, though not maintained at follow-up. These are measurable writing performance outcomes from an LLM-mediated intervention.""
    }
}"
75,Leveraging Ai to Enhance Writing Skills of Senior Tfl Students in Kazakhstan: a Case Study Using 'write & Improve',2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are senior undergraduate students in a 'two foreign language' (TFL) program in Kazakhstan, working on English writing tasks (task achievement, coherence and cohesion, lexical resource, grammar and accuracy), which aligns with an EFL/ESL-type context focused on English writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses the Write & Improve platform. While it is an AI-based feedback tool, the abstract does not indicate that it is a large language model (LLM) or transformer-based generative model like ChatGPT, GPT-4, Gemini, etc. Write & Improve is typically an automated feedback system, not an LLM-based generative assistant, so it does not meet the LLM integration criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on enhancing writing skills and compares teacher feedback with AI-generated feedback on multiple writing dimensions (task achievement, coherence and cohesion, lexical resource, grammar and accuracy, overall score). This is clearly a writing competence intervention, not just automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study employs a quasi-experimental design with pre- and post-tests over five weeks and reports quantitative writing outcome metrics (scores on task achievement, coherence and cohesion, lexical resource, grammar and accuracy, and overall score), analyzed via Mann-Whitney U tests and MANCOVA.""
    }
}"
76,Chatgpt-assisted Language Learning: Effects on Vietnamese English Majors' Writing Skills and Motivation,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Vietnamese first-year English majors, clearly L2 English learners in an EFL context. The focus is on English writing skills, as evidenced by the use of IELTS writing assessments.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is explicitly described as 'ChatGPT-assisted writing instruction' for the experimental group, compared with traditional instruction. ChatGPT is a large language model integrated into the writing instruction over a 15-week semester in an experimental design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence: the study examines effects on 'writing skills' and uses IELTS writing assessments, with reported improvements in writing performance domains such as task achievement and coherence. ChatGPT is used pedagogically within writing instruction, not merely for scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantifiable writing outcomes are reported via pre- and post-tests using IELTS writing assessments, with ANCOVA results and effect sizes (e.g., np² for task achievement and coherence). Thus, the study provides measurable writing performance data to evaluate the LLM-mediated intervention.""
    }
}"
77,"Artificial Intelligence in Efl Education in China: a Systematic Review of Trends, Gaps, and Future Directions (2015-2024)",2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a systematic review of AI in EFL education in China, not a primary empirical study with its own participant sample. While it discusses EFL learners in general, it does not report original data from a specific L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a systematic review summarizing prior work on AI systems and platforms (including ChatGPT and Pigai). It does not itself implement an experimental or quasi-experimental LLM-based writing intervention; it only reviews others’ studies.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is broad—AI in EFL education across multiple skills (speaking, writing, etc.) and roles (administration, tutoring). It is not a primary study centered on a specific writing competence intervention, but a landscape review of diverse applications.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a review article, it does not report original, quantifiable writing outcome metrics from an LLM-mediated intervention. It synthesizes existing literature instead of presenting new experimental measures or structured intervention outcomes.""
    }
}"
78,Undergraduate Students' Perceptions on the Use of Chatgpt for English Learning at a Korean University,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Korean and international undergraduate students using ChatGPT for English language learning at a Korean university, fitting an EFL/ELL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is the focus, the study investigates students’ perceptions of its usefulness rather than implementing a structured experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The study addresses general English language learning (grammar, listening, vocabulary, reading, writing) and overall perceptions of ChatGPT. Writing is only one of several skills mentioned and is not the primary focus of the research design or analysis.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are Likert-scale perceptions and qualitative comments about perceived improvements. There are no reported quantitative writing performance measures or experimental writing outcomes attributable to ChatGPT use.""
    }
}"
79,Preparing Teachers for the Algorithmic Educational Landscape: a Critical Mapping of Generative Ai Integration in Language Teacher Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a bibliometric-based systematic literature review on generative AI in language teacher education. It does not report on a primary study with a defined participant population of L2 English learners; instead, it maps existing research themes, including one on EFL writing skills, at a meta level.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic literature review, the study does not implement an experimental or quasi-experimental LLM-based writing intervention itself. It analyzes prior research thematically (e.g., ‘Generative AI as a Tool for Enhancing EFL Writing Skills’) rather than conducting an intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on mapping how generative AI is addressed in language teacher education (professional development, AI literacy, perceptions, etc.), not on a specific writing competence intervention. Writing appears only as one thematic cluster within the reviewed literature, not as the central empirical context of this study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a review and does not report original, quantifiable writing outcome metrics. It synthesizes themes in existing research rather than measuring changes in learners’ writing performance following an LLM-mediated intervention.""
    }
}"
80,Comprehensive Review of Writing Assessments in Efl Contexts: a Meta-synthetic Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The article is a meta-synthesis of prior research on writing assessments in EFL contexts. While many included primary studies likely involve EFL learners (L2 English), this paper itself does not report on a specific participant population; it is a secondary review study.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a meta-synthetic review of various assessment practices (teacher feedback, self-assessment, peer-assessment, blended assessment, AWE, and AI). It does not implement an experimental or quasi-experimental LLM-based intervention itself; it only synthesizes existing literature.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is EFL writing assessment, the paper is a broad review of assessment approaches rather than a focused pedagogical intervention integrating LLMs into writing instruction or processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a meta-synthesis, the article does not report original, quantifiable writing outcome metrics from an LLM-mediated intervention. It summarizes prior work and offers recommendations, fitting the category of a review article, which is excluded by the protocol.""
    }
}"
81,Comparative Analysis of Human Graders and Ai in Assessing Secondary School Efl Journal Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are secondary school EFL students in a private school in Istanbul, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares grading and feedback from a GenAI platform and human graders. There is no indication of an experimental or quasi-experimental instructional intervention integrating an LLM into the writing process; the GenAI is used as an assessor, not as part of teaching or practice.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on assessment—grading performance, consistency, and feedback quality of the GenAI platform versus human graders. This aligns with evaluating AI as an automated essay scoring/feedback system rather than a pedagogical writing intervention aimed at improving writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study does not report quantifiable writing outcome gains attributable to an LLM-mediated intervention. It analyzes agreement in scores and feedback quality, not changes in students’ writing performance over time due to GenAI-supported instruction.""
    }
}"
82,Thai Efl University Students' Writing in the Digital Age: Error Analysis Revisited,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Thai EFL university students, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions Google Translate and ChatGPT and discusses the impact of digital tools, there is no indication of an experimental or quasi-experimental LLM-based writing intervention. The tools are surveyed as resources students use, not as a structured instructional intervention integrating an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing (grammatical errors, writing strategies, and writing instruction). The context is clearly writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports error analysis and survey findings but does not describe an LLM-mediated intervention with pre/post or comparative quantitative writing outcome measures. It is observational/descriptive rather than testing the effectiveness of an LLM-based writing intervention.""
    }
}"
83,Effects of Interaction with Ai-assisted Writing Evaluation on Efl Students' Writing Performance,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 30 Omani EFL learners, explicitly described as learning English as a foreign language. The focus is on English writing performance, satisfying the L2 English learner population requirement.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses EditGPT, described as an automated written evaluation feedback instrument providing writing feedback. Given the name and context, it is an LLM-based tool (GPT), and the design is experimental with control and treatment groups receiving different feedback sources.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing performance and feedback on writing. The study compares teacher feedback, EditGPT feedback, and general feedback, clearly embedding the LLM within a pedagogical writing intervention rather than as a pure scoring system.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pretest and posttest writing tasks (narration and compare-and-contrast) to measure students’ progress, and reports differential performance across groups. These are quantifiable writing outcome metrics assessing the effectiveness of the LLM-mediated intervention.""
    }
}"
84,The Effect of Ai-assisted Learning on Efl Writing Proficiency: Quasi-experimental and Cluster Analysis,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as EFL high school students in Dhahran, with proficiency levels A2–B1. The context is clearly English as a foreign language, and the focus is on English writing proficiency.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT as an AI tool providing real-time feedback on grammar, vocabulary, and coherence during writing practice. It explicitly states a quasi-experimental design with AI-assisted learning, indicating an LLM-based intervention integrated into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL writing proficiency, assessing five core dimensions of writing (content, organization, vocabulary, language use, mechanics). ChatGPT is used pedagogically to support writing, not merely for automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantifiable writing outcomes are reported via pre-test and post-test scores using Jacobs et al.’s (1981) analytical scoring rubric. Statistical analyses (Wilcoxon Signed Rank Test, cluster analysis) show significant gains in content, language use, vocabulary, and total scores.""
    }
}"
85,Imitating Mistakes in a Learning Companion Ai Agent for Online Peer Learning,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions a focus on English composition but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts. It could involve general learners or native speakers; the population is not clearly defined.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study develops an AI Agent as a learning companion, but the abstract does not indicate that this agent is based on a large language model (e.g., ChatGPT, GPT-4) or transformer-based generative architecture. It could be another form of AI or rule-based system.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly focuses on English composition and peer learning, which aligns with writing-related instructional contexts. The AI agent is used as a learning companion in writing (English composition).""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that English composition is used as an example to validate the approach but does not mention any experimental or quasi-experimental design with quantifiable writing outcome measures. It is unclear whether writing performance is measured quantitatively.""
    }
}"
86,The Collaboration of Ai and Teacher in Feedback Provision and Its Impact on Efl Learner's Argumentative Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 28 tenth-grade EFL learners focusing on English argumentative writing, which fits the ESL/EFL/ELL L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The AI tool used is DeepL Write. Based on current knowledge, DeepL Write is primarily a neural machine translation / writing assistance tool and is not clearly identified as an LLM-based, transformer generative model like ChatGPT, GPT-4, Gemini, etc. The abstract does not specify that it is an LLM or generative transformer-based system, so it does not meet the explicit LLM intervention requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly targets English argumentative writing and examines the impact of AI and teacher feedback on writing quality (lexical, grammatical, content, coherence, cohesion), which aligns with a primary focus on writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing outcomes are quantitatively analyzed using Coh-Metrix across three drafts to compare AI-only versus teacher+AI feedback, providing measurable writing quality metrics.""
    }
}"
87,Revisiting Trends in Genai-assisted Second Language Writing: Retrospect and Prospect,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract states that GenAI primarily assists learners of English as a second language (ESL), indicating that the synthesized studies focus on L2 English learners in ESL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This article is itself a review that synthesizes 73 empirical studies on GenAI-assisted L2 writing. It does not report an original experimental or quasi-experimental intervention integrating LLMs; instead, it summarizes others’ work.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on GenAI-assisted second language writing, including academic writing practices and writing metrics such as content, organization, grammar, and mechanics, which are core writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions that the reviewed studies report effect sizes and focus on writing metrics, this paper does not itself present primary quantitative writing outcome data from an intervention; it is a review article, which is an exclusion category.""
    }
}"
88,Enhancing Chatgpt-based Writing Research through Effective Prompt Use,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions 'student essays' but does not specify that the students are L2 English learners in ESL/EFL/ELL contexts. Their language background and learning context are not described.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used to identify logical fallacies in student essays and to study prompt design and reliability/validity of its analytical outputs. This is a methodological/case study on tool use, not an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or writing processes for learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on ChatGPT’s analytical behavior (precision, accuracy, validity) and prompt strategies for research/assessment, not on developing learners’ writing competence or writing-related skills through instruction. It is essentially about using ChatGPT for written assessment/analysis, not a teaching intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes are reported. The results concern precision, accuracy, and validity of ChatGPT’s outputs under different prompting conditions, not changes in students’ writing performance or related measurable learning outcomes.""
    }
}"
89,"Including the Tech, Keeping the Human: Integrating Generative Ai in the Feedback Writing Process",2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions ‘the language learner’ and ‘EL/COS student’ at UNSW College, suggesting English learners in a pathway/college context, but it does not clearly specify that participants are L2 English learners in ESL/EFL/ELL contexts or provide language background details.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study integrates ‘generative AI’ in feedback and sentence-editing tasks, but the abstract does not specify whether the tools are large language models (e.g., ChatGPT/GPT-4) or other AI systems. The design is described as ‘trialling two highly scaffolded feedback tasks,’ but it is not explicit whether this is an experimental or quasi-experimental intervention with comparison or control conditions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on integrating generative AI into the feedback and editing stages of the writing process, aiming to support language development, feedback literacy, and writing-related skills. This aligns with a primary focus on writing competence and writing-related variables rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports ‘observations from trialling these tasks’ and discusses potential benefits and negative effects, but it does not indicate any quantitative or experimental writing outcome measures (e.g., scores, rubric-based gains, error rates). The outcomes appear to be descriptive/observational rather than quantifiable measures of writing performance.""
    }
}"
90,Implementing Ai Literacy Teaching in University-level L2 Writing Instruction: Exploring One Pedagogical Approach,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract specifies a ‘first-year writing course for L2 writers,’ indicating university-level second language learners in an English writing context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study discusses integrating ‘GenAI tools’ and AI literacy into L2 writing instruction, but it is not explicit that these are LLMs (e.g., ChatGPT) used as part of an experimental or quasi-experimental intervention. It is framed as a ‘classroom exploration piece’ and ‘practitioner account,’ suggesting descriptive rather than experimental design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly L2 writing instruction, focusing on ‘L2 writing teaching and learning’ and ‘uses of GenAI for written and multimodal communication,’ which aligns with writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract presents a ‘classroom exploration piece’ and ‘one pedagogical approach’ with emphasis on AI literacy, trust, and transparency. There is no indication of quantitative writing outcome measures or experimental assessment of writing performance.""
    }
}"
91,Generative Ai for Learning Languages Other Than English: L2 Writers' Current Uses and Perceptions of Ethics,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are L2 learners of five languages other than English (LOTEs). The focus is explicitly on writing in languages other than English, not on L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study concerns learners’ self-initiated uses of generative AI tools, but it does not clearly describe an experimental or quasi-experimental instructional intervention integrating specific LLMs into writing instruction. It appears more observational/survey-based.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is L2 writing in LOTEs, focusing on how learners use GenAI tools for writing and their ethical perceptions. Writing use is central, not automated scoring or purely technical evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports survey findings on frequency and types of GenAI use and ethical beliefs, but does not indicate any quantifiable writing outcome measures (e.g., changes in writing quality, accuracy, complexity) resulting from an intervention.""
    }
}"
92,Structured or Semi-structured? the Use of Reflection Journals in Postgraduates' Generative Artificial Intelligence Literacy Development in an L2 Academic Writing Context,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is conducted in an L2 academic writing context with postgraduate students, indicating participants are L2 English learners engaged in English academic writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study involves GenAI-assisted writing tasks and GenAI tools (implying LLMs), the experimental manipulation focuses on types of reflection journals (structured vs semi-structured) to develop GenAI literacy, not on differing LLM-based writing interventions themselves.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary outcome is GenAI literacy (operational competence, ethics, critical evaluation, reflection). Writing competence or writing-related performance is not the main focus; GenAI is used as context rather than as a targeted writing skill intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports quantitative outcomes on GenAI literacy dimensions, not on writing quality or other quantifiable writing performance metrics. No experimental writing outcome measures (e.g., scores, complexity, accuracy, fluency) are described in the abstract.""
    }
}"
93,Interacting with Chatgpt for Internal Feedback and Factors Affecting Feedback Quality,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 48 Chinese students in an English writing course, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines students’ interaction with ChatGPT (a Generative Pre-Trained Transformer) to generate internal feedback during an English writing course, so an LLM is integrated into the writing process, albeit in a qualitative case-study design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly L2 writing: students in an English writing course use ChatGPT for feedback related to their writing, and the focus is on feedback processes in L2 writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as a qualitative case study using self-reflective questions, interviews, and conversation logs, analyzed via thematic coding. The abstract reports no experimental or quasi-experimental design and no quantifiable writing outcome metrics; it focuses on experiences, factors affecting feedback quality, and qualitative insights.""
    }
}"
94,Artificial Intelligence Tools for Research Writing: Practical Tips for Teachers,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract does not specify the learner population, language background, or whether students are L2 English learners in ESL/EFL/ELL contexts. It appears to be a general discussion of students and teachers without a defined L2 English population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper discusses “artificial intelligence (AI) tools” in general (content generation, literature review, editing, citation management) and offers practical tips. It does not specify the use of large language models (e.g., ChatGPT, GPT-4) nor describe an experimental or quasi-experimental intervention design; it appears to be conceptual/instructional guidance.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus is on research writing, the article is framed as an exploration of tools and instructional strategies rather than an empirical study of a writing intervention’s effects. It is more of a practical/overview piece than a study centered on measuring changes in writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental results are mentioned. The abstract describes benefits and strategies but does not report measured changes in writing performance or related variables.""
    }
}"
95,Exploring the Use of Chatgpt-generated Model Texts as a Feedback Instrument: Efl Students' Text Quality and Perceptions,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 104 Chinese high school EFL students, i.e., learners of English as a foreign language. The focus is explicitly on EFL students’ English writing quality (content, organisation, vocabulary, grammar).""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses ChatGPT-generated model texts as a feedback instrument for writing. ChatGPT is a large language model, and the study employs a quasi-experimental design with control and experimental groups comparing human- vs ChatGPT-generated model texts.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL writing competence: effects of ChatGPT-generated model texts on students’ text quality (content, organisation, vocabulary, grammar) and their use as feedback in writing classrooms. This is a pedagogical writing intervention, not automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a pretest–post-test quasi-experimental design and reports analytical measures of text quality (content, organisation, vocabulary, grammar) with descriptive and inferential statistics, providing quantifiable writing outcome metrics.""
    }
}"
96,Leveraging Chatgpt for Research Writing: an Exploration of Esl Graduate Students' Practices,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as two ESL graduate students, indicating L2 English learners in an ESL context, and the focus is on their English research writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the design is a case study of naturally occurring use after a tutorial, not an experimental or quasi-experimental intervention. There is no controlled instructional treatment or comparison condition to test the effect of an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on research writing practices (genre, content, language use, documentation, coherence, clarity) and how ChatGPT is integrated into academic writing processes, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative findings about practices, integrity, and agency but does not mention any quantifiable writing outcome metrics (e.g., scores, rubric-based gains, measurable changes in writing quality) to assess effectiveness of the LLM-mediated intervention.""
    }
}"
97,Efl Students' Use of Ai Chatbots in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as students in a university-level English as a Foreign Language (EFL) class at a French university, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that students were trained to use AI chatbots for feedback on their writing. However, it does not specify that these are large language model-based tools (e.g., ChatGPT, GPT-4), nor does it clearly describe an experimental or quasi-experimental design; it appears more exploratory/observational.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is an academic writing unit in an EFL class, and the focus is on how students use chatbot feedback in their writing, including grammar, word choice, and style. This aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports that students’ responses were coded to identify patterns in how they used chatbot feedback and discusses hesitancy to accept certain changes. There is no indication of quantifiable writing outcome metrics (e.g., pre/post writing scores, measurable improvement); the outcomes are qualitative patterns and perceptions.""
    }
}"
98,Ai-powered Digital Tools for Vocabulary Retention in Foreign Language Learners: a Perception-based Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are students in an Ecuadorian university program where English is taught as a foreign language, i.e., EFL learners, so the population matches L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students use AI tools including ChatGPT, the study is a quantitative, descriptive, perception-based survey. There is no experimental or quasi-experimental design integrating LLMs into instruction; it only surveys prior use and perceptions.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is vocabulary retention and general language learning (including some mention of writing accuracy), not a structured writing intervention or writing-focused pedagogy. Writing is incidental rather than the main context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are self-reported perceptions (e.g., perceived better retention, improved writing accuracy, increased motivation) collected via survey. No quantifiable writing performance measures or experimental writing outcomes are reported.""
    }
}"
99,Translanguaging with Generative Ai in Efl Writing: Students' Practices and Perceptions,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students in China (six college students with lower to intermediate proficiency), clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study involves generative AI (ERNIE Bot), it is a qualitative exploration of how students use the tool and their perceptions. There is no indication of an experimental or quasi-experimental design or a structured pedagogical intervention integrating the LLM into instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL writing processes and how generative AI is used in writing, framed through translanguaging practices. This aligns with a writing-related context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes a qualitative study using interviews and artefacts, focusing on practices and perceptions. It does not report quantifiable writing outcome metrics or experimental measures of writing improvement.""
    }
}"
100,"Descriptive Writing Using Generative Ai as a Cognitive Scaffold in the Metaverse Environment: University Students' Perceptions, Learning Engagement, and Performance",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as undergraduate students in two EFL writing classes, indicating L2 English learners in an EFL context. The task is English descriptive writing about a historical place in the metaverse.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses a generative AI tool called 'GAIscaffold' as a cognitive scaffold. However, the abstract does not specify whether GAIscaffold is an LLM-based, transformer-style generative model (e.g., similar to ChatGPT/GPT-4) or another form of generative AI. Without this detail, it is unclear if it meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on EFL descriptive writing performance in a metaverse environment, with GAIscaffold integrated into the writing task. The primary outcomes include writing performance and engagement, aligning with writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative writing outcomes: final writing performance compared between experimental and control groups using MANCOVA, with statistically significant improvements in the experimental group. This provides measurable writing outcome metrics.""
    }
}"
101,Impact of Chatgpt on English Academic Writing Ability and Engagement of Chinese Efl Undergraduates,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese undergraduate students majoring in English as a foreign language (EFL) at a private university in China. The focus is explicitly on English academic writing, fitting ESL/EFL/ELL L2 English learner contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study investigates the impact of ChatGPT, explicitly identified as an AI tool, on students’ English academic writing. A quasi-experimental design with experimental and control classes is used, indicating an LLM-based writing intervention integrated into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on English academic writing ability and engagement. Outcomes include content, structure and coherence, grammar, linguistic range, vocabulary, spelling, and form—clearly writing competence variables rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: improvements in multiple dimensions of English academic writing ability, analyzed via independent and paired sample t-tests. Engagement is also measured via survey with percentages, satisfying the requirement for quantitative outcome metrics.""
    }
}"
102,Understanding Efl Learners' Strategies in Ai-assisted English Writing: an Activity Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) learners, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study involves AI-assisted writing and interaction with AI tools, the abstract does not indicate an experimental or quasi-experimental intervention design integrating a specific LLM (e.g., ChatGPT) into instruction. It is an exploratory, strategy-focused study using screenshots, chat logs, and interviews.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on AI-assisted English writing processes and strategies during completion of writing tasks, which aligns with writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study analyzes strategies and perceptions qualitatively (screenshots, chat logs, interviews) without experimental measures of writing performance or competence.""
    }
}"
103,Korean Efl Learners' Perceptions of Using Chatgpt for English Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Korean EFL (English as a foreign language) learners, so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, the design is exploratory and perception-focused. There is no indication of an experimental or quasi-experimental intervention structure (e.g., treatment vs. control, pre/post measures) integrating ChatGPT into instruction; instead, students compare their writing with ChatGPT-edited versions and reflect on it.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly English writing: students compare their original writing with ChatGPT-edited versions, and the study discusses types of feedback (vocabulary, expressions, clarification, elaboration) in a writing context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports perceptions, engagement with feedback types, and questionnaire responses about advantages/disadvantages. It does not mention any quantitative writing outcome metrics (e.g., scores, accuracy, complexity) to assess effectiveness of the ChatGPT-mediated writing activity.""
    }
}"
104,Assessing the Impact of Microsoft Copilot and Chatgpt on Efl Learners' Interactional Metadiscourse in Argumentative Writing,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Iranian English-as-a-foreign-language (EFL) learners. The focus is on English argumentative writing and interactional metadiscourse markers in that context, which fits ESL/EFL/ELL L2 English criteria.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study compares ChatGPT-based instruction and Microsoft Copilot against a conventional control group. Both ChatGPT and Copilot are LLM-based chatbots integrated into instruction for identifying and using interactional metadiscourse markers in writing, with structured prompts and training, indicating an experimental LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on argumentative writing, specifically on identifying and realizing interactional metadiscourse markers (IMMs) in learners’ writing. The intervention and outcomes are clearly tied to writing competence and writing-related variables, not to automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative posttest performance on identifying IMMs, analyzed via ANCOVA, comparing ChatGPT, Copilot, and control groups. This constitutes a quantifiable writing-related outcome metric assessing the effectiveness of the LLM-mediated writing interventions.""
    }
}"
105,The Role of Chatgpt in Enhancing Efl Students' Esp Writing Skills: an Experimental Study of Gender and Major Differences,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 117 university students learning English for Specific Purposes (ESP) writing in an EFL context, indicating L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is explicitly experimental and investigates the impact of ChatGPT, a large language model, used as a self-directed learning tool in ESP writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on ESP writing skills and their enhancement through ChatGPT use, not on automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pre- and post-tests with statistical analyses (Wilcoxon signed-rank test and ANOVA) to measure improvements in writing skills, providing quantifiable writing outcome metrics.""
    }
}"
106,Supporting 2e Bilingual Students with Motor Dysgraphia and Adhd in Writing: Efficacy and Acceptability of Human-ai Hybrid Tutoring,2025,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as “twice exceptional (2e) bilingual students,” but the abstract does not specify that they are L2 English learners in ESL/EFL/ELL contexts, nor that English is the target language of instruction or assessment.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention is a “human-artificial intelligence (AI) hybrid tutoring” system, but the abstract does not indicate whether the AI component is a large language model (e.g., ChatGPT/GPT-4 or similar transformer-based generative model) or another type of AI (e.g., adaptive tutoring, handwriting support).""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on improving writing skills, including handwriting fluency, orthographic coding, fine motor control, and composition skills, within a tutoring intervention. This aligns with a writing-focused pedagogical context rather than automated scoring or non-instructional evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: handwriting fluency (speed and legibility), orthographic coding, fine motor control, and composition skills, with interval post-tests comparing hybrid tutoring and traditional instruction.""
    }
}"
107,Effectiveness of Generative Ai in Automated Written Corrective Feedback with Prompting,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions “teachers and students” and “English writing instruction” but does not specify that the students are L2 English learners (ESL/EFL/ELL). Their language background and whether English is a second/foreign language are not stated.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study evaluates GAI models (including GPT-4) as automated written corrective feedback tools and compares them to commercial AWCF systems. It focuses on model performance and prompting strategies, not on an instructional intervention where learners themselves use LLMs as part of a structured writing pedagogy or experimental teaching design.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the functionality and performance of GAI-based AWCF (error detection and correction accuracy, consistency) and user perspectives. It is not framed as a writing competence intervention study; rather, it is a system evaluation and usability/practical efficacy study of feedback tools.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract claims the system has potential to enhance students’ writing quality and confidence, it does not report quantifiable writing outcome metrics (e.g., pre/post writing scores, measurable gains in writing performance). The quantitative results concern error correction performance of models, not learners’ writing outcomes in an intervention.""
    }
}"
108,Artificial Intelligence as an Automated Essay Scoring Tool: a Focus on Chatgpt,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL learners writing essays in English at the B2 level, which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used solely as an Automated Essay Scoring (AES) tool to grade essays, not as part of an instructional or experimental writing intervention. There is no integration of ChatGPT into teaching or supporting the writing process.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on evaluating ChatGPT’s functionality and agreement with human raters as an AES system, not on improving learners’ writing competence or implementing a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports quantitative comparisons between human and ChatGPT scores, but these are assessment reliability/validity outcomes, not writing outcome measures resulting from an LLM-mediated intervention on learners’ writing performance.""
    }
}"
109,"Under the World of Ai-generated Feedback on Writing: Mirroring Motivation, Foreign Language Peace of Mind, Trait Emotional Intelligence, and Writing Development",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a Foreign Language (EFL) learners at the College of Languages, Nawroz University, focusing on English writing proficiency. This matches the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract repeatedly refers to “AI-generated feedback” in an online writing development context but does not specify the AI tool or architecture (e.g., ChatGPT, GPT-4, other LLMs). It could be an LLM or a non-LLM feedback system (e.g., rule-based or traditional NLP). Without explicit mention of an LLM or transformer-based generative model, it is not possible to confirm that the intervention is LLM-based.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study centers on “online writing development” and “writing proficiency/skills” as key outcomes, with AI-generated feedback integrated into writing instruction. The primary pedagogical focus is on writing competence and related affective variables, not on automated scoring or system evaluation alone.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""A quasi-experimental design with pretest and posttest is used, and the abstract notes that quantitative outcomes showed AI-generated feedback enhanced writing skills. This implies measurable writing proficiency outcomes alongside scales for motivation, FLPoM, and trait EI.""
    }
}"
110,Exploring Chatgpt as a Writing Assessment Tool,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is situated in teaching English as a Foreign Language (EFL) in Thailand, so the participants are EFL learners with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used as an Automated Writing Evaluation (AWE) tool to assess students’ writing and compare its ratings with human raters. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating ChatGPT into the writing instruction or writing process itself.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on ChatGPT’s functionality and validity as a writing assessment tool (AWE) and its comparison with human ratings, not on a structured instructional intervention to improve writing competence. This aligns with excluded contexts (LLM as essay scoring system).""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although quantitative analyses compare ChatGPT and human ratings, there is no report of writing outcome measures used to evaluate the effectiveness of an LLM-mediated writing intervention. The study evaluates assessment performance, not changes in learners’ writing due to an intervention.""
    }
}"
111,Exploring the Transformative Influence of Artificial Intelligence in Efl Context: a Comprehensive Bibliometric Analysis,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The population is broadly EFL learners in the literature analyzed, but as a bibliometric study it aggregates many different participant types and does not focus on a specific, well-defined L2 English learner sample with primary data collection.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a bibliometric analysis of AI in EFL from 2013–2023. It does not report an experimental or quasi-experimental intervention integrating LLMs into writing instruction; instead, it maps existing publications and mentions tools like ChatGPT, Grammarly, and Quillbot at a descriptive level.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study notes AI’s impact on EFL writing skills, its primary focus is on bibliometric trends (contributors, keyword clusters, etc.), not on implementing or evaluating a specific writing-focused pedagogical intervention using LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study synthesizes publication patterns and thematic trends rather than measuring changes in learners’ writing performance following an LLM-mediated intervention.""
    }
}"
112,Chatgpt Affordances and Indonesian Efl Students' Perceptions in L2 Writing: a Collaborative Reflexive Thematic Analysis,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Indonesian EFL students, clearly indicating L2 English learners in an EFL context: “Indonesian EFL students’… in L2 writing.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, the design is qualitative and exploratory, focusing on affordances, prompts, and perceptions. There is no indication of an experimental or quasi-experimental intervention design; instead, data come from screen capture observations and semi-structured interviews.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on EFL writing and L2 writing development, including aspects like brainstorming, outlining, idea development, and feedback on hedging devices, all of which are writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports perceived potential to improve essay quality but does not mention any quantifiable writing outcome metrics or experimental measures. Findings are based on thematic analysis of interactions and interviews, i.e., qualitative perceptions rather than measured writing gains.""
    }
}"
113,From Prompts to Plans: a Case Study of Pre-service Efl Teachers' Use of Generative Ai for Lesson Planning,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are pre-service teachers in a South Korean university course designing lesson plans for a middle-school EFL class. The abstract does not indicate that the study collects data on L2 English learners’ writing; the focus is on teachers’ use of AI for lesson planning, not on learners as participants.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although generative AI tools (LLMs) are used, they are employed for lesson planning (topic selection, material creation, lesson organization, language checking), not as an experimental or quasi-experimental writing intervention for L2 learners’ writing processes or instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on pedagogical planning and teacher education (use of AI in lesson planning), not on writing competence or writing-related variables as learning outcomes. Writing is only tangentially mentioned as ‘language checking’ within lesson plans.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a qualitative case study with thematic analysis and does not report quantifiable writing outcome metrics for L2 learners. Outcomes concern PSTs’ use of AI and needed training, not measured changes in learners’ writing performance.""
    }
}"
114,"Digital Plagiarism in Efl Education during the Ai Era: a Comparative Study of Perceptions among Learners and Instructors in Korea, Mongolia, and China",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL education in Korea, Mongolia, and China, implying participants are L2 English learners and their instructors in EFL settings.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines perceptions of digital plagiarism and AI usage via scenario-based survey items. There is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is academic integrity and perceptions of digital plagiarism in the AI era, not on writing competence or writing-related performance variables. L2 writing is mentioned only as a context for integrity concerns, not as the main outcome of an instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are perceptions measured via survey items about plagiarism and AI use. No quantifiable writing performance metrics or writing quality measures are reported to assess an LLM-mediated writing intervention.""
    }
}"
115,"Factors Influencing Bangladeshi English Teachers' Perceptions of Academic Policy, Academic Culture and Knowledge Related to Plagiarism in Higher Education",2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are English teachers at tertiary level in Bangladesh, not L2 English learners (ESL/EFL/ELL). The focus is on teachers’ perceptions of plagiarism and academic integrity, not on learner outcomes.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions AI-based plagiarism and AI tools, there is no experimental or quasi-experimental design integrating LLMs into writing instruction or writing processes. AI is discussed as a concern, not as an instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on plagiarism, academic policy, and institutional factors, not on developing writing competence through LLM-mediated pedagogy. Writing courses are mentioned only as a contextual factor, not as an intervention under study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes relate to factor analysis of perceptions and institutional drivers of plagiarism, not to measured changes in learners’ writing performance following an LLM-based intervention.""
    }
}"
116,Integrating Corpus-based Methods to Determine Grammatical Topics for Teaching English Writing in the Thai Context,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Thai university students learning English writing, i.e., EFL learners in a non-English-speaking context, with a clear focus on English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used to improve students’ essays to create a refined corpus for analysis, not as part of an instructional intervention or experimental/quasi-experimental teaching design. There is no LLM-mediated teaching or structured pedagogical use being evaluated.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on using corpus-based methods to identify grammatical topics for teaching writing, not on implementing or evaluating a writing intervention. ChatGPT is a tool to generate comparison texts, not a component of a writing-instruction process under study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports corpus-derived grammatical features and needs analysis, but does not report quantifiable writing outcome measures (e.g., pre/post writing scores) assessing the effectiveness of an LLM-mediated intervention on learners’ writing performance.""
    }
}"
117,Integration of Artificial Intelligence (ai) in Learning English Writing in Higher Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses AI in learning English writing in higher education but does not specify that the participants are L2 English learners in ESL/EFL/ELL contexts, nor does it describe any concrete participant population, as this is a conceptual paper.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a conceptual paper that applies a conceptual approach exploring literature. It does not report an experimental or quasi-experimental design, nor a specific LLM-based intervention (e.g., ChatGPT, GPT-4) integrated into writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus is on AI in English writing, the paper is conceptual and descriptive, outlining concepts, integration, and expectations. It does not describe an implemented pedagogical intervention or study context where writing competence is empirically evaluated.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract indicates no empirical data or quantifiable writing outcome metrics. It is a conceptual analysis and literature-based discussion without experimental measures or structured intervention outcomes.""
    }
}"
118,Transforming Ai Chatbots for a Brainstorming Teaching Technique of Process Writing,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are third-year Thai university students working with foreign English lecturers, indicating an EFL context with English as the target language for writing instruction.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses AI chatbots, with ChatGPT explicitly mentioned as the most popular tool. ChatGPT is a large language model, and the design is experimental with an intervention group using these AI tools versus a conventional group.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on process writing instruction and students’ writing outcomes, specifically using AI-driven brainstorming tools as part of writing pedagogy, not for automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that the intervention group significantly outperformed the conventional group on two of three writing assignments, with p-values provided, indicating quantifiable writing outcome measures.""
    }
}"
119,"Comparing Teacher E-feedback, Ai Feedback, and Hybrid Feedback in Enhancing Efl Writing Skills",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Iranian intermediate-level EFL learners, i.e., L2 English learners in an EFL context. The focus is on English writing (IELTS writing tasks).""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention includes AI-generated feedback using tools such as ChatGPT (an LLM) alongside Grammarly. A randomized controlled trial compares teacher e-feedback, AI-based feedback, and hybrid feedback, integrating an LLM into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on enhancing EFL writing skills and writing performance. Feedback (teacher, AI, hybrid) is used as a pedagogical intervention directly targeting writing competence and related dimensions (task achievement, coherence, grammatical accuracy, lexical resources).""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantifiable writing outcomes are reported: pre- and post-intervention writing proficiency measured via IELTS writing tasks, with significant differences between groups in task achievement, coherence, grammatical accuracy, and lexical resources.""
    }
}"
120,Exploring Potential Biases in Gpt-4o's Ratings of English Language Learners' Essays,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses the ELLIPSE corpus (English Language Learner Insight, Proficiency and Skills Evaluation), which consists of essays written by English language learners, indicating an L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""GPT-4o is used solely as an automated essay scoring (AES) tool to rate existing essays. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating the LLM into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on GPT-4o’s fairness and bias as an AES system (gender, race/ethnicity, SES), not on improving writing competence or implementing a writing-focused instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports rating bias and fairness metrics, not outcomes of an LLM-mediated writing intervention. There are no quantifiable writing outcome measures assessing changes in learners’ writing due to an LLM-based instructional treatment.""
    }
}"
121,Do Ai-generative Tools Kill or Nurture Creativity in Efl Teaching and Learning?,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are clearly described as English as a Foreign Language (EFL) undergraduates, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT and other AI-generative tools are mentioned, the study uses a descriptive-survey design to explore students’ perspectives. There is no experimental or quasi-experimental intervention integrating LLMs into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing is mentioned only as one of several uses (conversation practice, idea generation, feedback on writing, vocabulary building, collaborative learning). The primary focus is creativity in EFL learning broadly, not specifically writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study relies on questionnaires and interviews about perceptions. It does not report quantifiable writing outcome metrics or measure changes in writing performance following an LLM-mediated intervention.""
    }
}"
122,Ai Tools for Writing: a Q-method Study with Turkish Instructors of English,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study concerns Turkish learners of English and their writing skill development, which fits L2 English learners in an EFL context, even though the direct participants are instructors.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a Q-methodological investigation of instructors’ perspectives on AI tools. It does not describe an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes; the tools are discussed in general and at the level of opinion.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on instructors’ perspectives, ethical concerns, and policy implications regarding AI tools, not on implementing or evaluating a concrete writing intervention or instructional context using LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study uses Q-sorts and interviews to capture perceptions and attitudes, without experimental measures of changes in learners’ writing performance.""
    }
}"
123,Chatgpt-3.5 as an Automatic Scoring System and Feedback Provider in Ielts Exams,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions IELTS essays and second language writing, implying L2 English learners, but it does not explicitly describe a participant population or learner context (ESL/EFL/ELL). Essays are taken from an official IELTS preparatory book, not clearly from a defined learner sample within an instructional setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT-3.5 is used as an Automatic Essay Scoring (AES) system and feedback provider, with alignment to official examiners examined. The study analyzes ChatGPT’s scoring and revision strategies on pre-rated essays; there is no experimental or quasi-experimental pedagogical intervention integrating ChatGPT into learners’ writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on evaluating ChatGPT-3.5’s reliability as an AES and its capability to revise essays, not on a teaching/learning intervention aimed at improving learners’ writing competence. This aligns with tool evaluation rather than an instructional context or intervention in L2 writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes are reported. The study compares ChatGPT’s scores with official IELTS scores and describes its revision capabilities, but there is no measurement of changes in learners’ writing performance resulting from an LLM-mediated intervention.""
    }
}"
124,Ai-generated Feedback in English Writing Instruction for Language Learners: a Systematic Review,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to 'language learners' in English writing instruction but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts. As this is a systematic review aggregating multiple studies, the exact population composition is not clear from the abstract alone.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a systematic review of 22 studies on generative AI (primarily ChatGPT) feedback in English writing instruction. Review articles are to be excluded according to the protocol, which requires primary experimental or quasi-experimental studies rather than secondary syntheses.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on AI-generated feedback in English writing instruction, including types of feedback and its effectiveness relative to teacher and peer feedback. This aligns with a primary focus on writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract notes that the review examines the effectiveness of AI feedback and perceptions, but it does not specify whether the included primary studies report quantifiable writing outcome metrics. As a secondary study, it does not itself report original experimental outcome data.""
    }
}"
125,Digital Tools and Writing Education: a Thematic Analysis of Technology's Role in Writing Skills Development,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions that the review includes diverse groups of learners, including EFL students and those with dyslexia, but it does not specify that the data or outcomes are focused on L2 English learners in ESL/EFL/ELL contexts, nor that English is the primary target language across the included studies.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a systematic review and thematic analysis of 40 articles on digital tools, including AI-based feedback systems, but it does not describe a primary experimental or quasi-experimental study integrating a specific LLM (e.g., ChatGPT, GPT-4) into writing instruction. It is a secondary synthesis, not an LLM-based intervention study.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is broadly on writing skills, including higher-order skills such as creativity and critical thinking, and on categories like computer-based tools, collaborative environments, and automatic feedback systems. However, it is not centered on a specific pedagogical intervention with LLMs; rather, it surveys multiple technologies at a general level.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic review, the study synthesizes themes and general findings but does not itself report original, quantifiable writing outcome metrics from an LLM-mediated intervention. It discusses that tools can increase creativity and critical thinking but not as measured outcomes of a specific LLM-based experimental design.""
    }
}"
126,Integrating Automated Writing Evaluation into Saudi Efl Students' Writing Practice,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 154 Arabic-speaking EFL undergraduate students at a Saudi university, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is an Automated Writing Evaluation (AWE) system. The abstract does not indicate that it is an LLM-based tool (e.g., ChatGPT, GPT-4, transformer-based generative model); it is framed as conventional AWE providing feedback, which falls outside the specified LLM-focused scope.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on integrating AWE into EFL writing practice and discusses enhancement of writing skills, critical thinking, autonomy, and motivation to write in English, which are writing-related variables.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions collecting samples of EFL writing assignments before and after using the AWE system, but it does not explicitly state that quantifiable writing outcome metrics were analyzed or reported; emphasis is on experiences, evaluations, challenges, satisfaction, and perceived effectiveness.""
    }
}"
127,Interacting with Chatgpt in Essay Writing: a Study of L2 Learners' Task Motivation,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are L2 learners writing English argumentative essays at a public university in a non-English-speaking country, which fits an EFL/ESL/ELL context focused on English.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT 4.0 (an LLM) as part of an experimental, AI-enhanced intervention for teaching L2 essay writing, indicating an LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly L2 English argumentative essay writing, with ChatGPT used as a tutor and writing support tool; the focus is on writing and writing-related processes, not on automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract states the study explored effects on learners' motivation and reports a positive lasting effect on motivation. Outcomes mentioned are motivational (task motivation), not quantifiable writing performance or competence measures. No writing quality or other writing outcome metrics are reported.""
    }
}"
128,Enhancing or Impairing? Exploring Indian Efl Learners' Academic Writing Narratives with Chatgpt,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Indian English as a Foreign Language (EFL) learners, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study concerns learners’ use of ChatGPT (an LLM), it is not an experimental or quasi-experimental intervention. Learners had already been using ChatGPT informally for over a year, and the study only explores their use and perceptions via interviews, without a structured instructional intervention or controlled treatment.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on academic writing, including writing fluency, confidence, and cognitive engagement, and on the role of ChatGPT in these writing-related processes, aligning with a writing competence context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study employs a qualitative design using semi-structured interviews and thematic analysis. It reports perceived impacts (e.g., on fluency, motivation, anxiety) but does not mention any quantitative or experimental writing outcome measures.""
    }
}"
129,Ai-based Assessment of Students' Writing Skill Progress: Implementing Artificial Neural Network Modeling Vs. Time Series Prediction,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract refers to students’ progress in second language (L2) writing skills and mentions English language learning and assessment, indicating an L2 English learner population in an ESL/EFL/ELL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is the use of AI-based prediction models (ANN vs. time series) to assess writing progress, not an LLM-based tool (e.g., ChatGPT, GPT-4) integrated into writing instruction or writing processes. The AI here is for modeling/prediction, not an LLM-mediated pedagogical intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on AI-based assessment and prediction of writing scores (model performance: MAE, RMSE, R²), not on a pedagogical writing intervention using LLMs. It aligns more with automated assessment/analytics than with instructional use of LLMs for writing development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing test scores are reported, they are used to evaluate prediction models and group improvement, not to assess the effectiveness of an LLM-mediated writing intervention. No LLM-based instructional treatment is described, so the required outcome context is missing.""
    }
}"
130,An Ai-assisted Critical Thinking Intervention to Enhance Undergraduate Efl Learners' Writing Proficiency,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 250 undergraduate EFL learners from three public universities. The context is EFL and the focus is on English writing proficiency and critical thinking reflected in writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines an AI-assisted critical thinking-oriented writing intervention supported with ChatGPT, a large language model. It uses a pretest–posttest experimental design to investigate the effects of this ChatGPT-supported intervention on learners’ writing.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing proficiency and critical thinking as reflected in writing. ChatGPT is used as a scaffolding tool in CT-oriented writing training, clearly situating the intervention within writing instruction rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative writing outcomes are reported: pre–post writing tests for 250 students, evaluated across nine dimensions (clarity, accuracy, precision, relevance, depth, breadth, logic, significance, fairness). The abstract states that the intervention significantly enhanced students’ CT reflected in writing, indicating measurable writing-related gains.""
    }
}"
131,Factors Affecting Efl Students' Behavioral Intention to Use Ai in Efl Writing Development,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese university students using AI for English as a Foreign Language (EFL) writing development, which fits L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a cross-sectional survey to investigate behavioral intention to adopt AI; there is no experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes as an intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is technology acceptance (behavioral intention, attitudes) toward AI in EFL writing, not on implementing a writing competence intervention. No pedagogical LLM-based writing treatment is described.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are behavioral intention and related psychological constructs analyzed via SEM. The abstract does not report any quantifiable writing performance or writing-related proficiency outcomes resulting from AI/LLM use.""
    }
}"
132,Students' Self-determination in Using Machine Translation and Generative Ai Tools for English for Academic Purposes,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EAP students in an ESL context (Australia) and an EFL context (Vietnam), explicitly focusing on English for Academic Purposes, so the population is L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates students’ use of MT and generative AI tools and their motivations, but there is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) as a structured writing intervention. It is primarily a survey/interview study of existing practices and perceptions.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context is academic writing in EAP and MT/GAI-assisted academic writing is mentioned, but the focus is on motivational constructs (autonomy, competence, relatedness) and perceptions rather than a defined pedagogical writing intervention with LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are motivational (autonomy, competence, relatedness) and perceptions of MT/GAI use. The abstract does not report any quantifiable writing performance or writing quality measures resulting from an LLM-mediated intervention.""
    }
}"
133,Artificial Intelligence as a Catalyst for Overcoming Barriers to English Language Learning in Higher Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract focuses on dyslexic students in English as a Second Language (ESL) classrooms in higher education, clearly indicating L2 English learners in an ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study discusses AI broadly (speech recognition, NLP, adaptive learning platforms) and appears to be a critical evaluation and case-based discussion, not an experimental or quasi-experimental intervention using LLMs such as ChatGPT or GPT-4. No specific LLM-based tool or controlled intervention is described.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Written expression is mentioned as one of several difficulties (reading, comprehension, written expression), but the focus is on overall language proficiency and learning experiences, not specifically on writing competence or writing-related variables as the primary outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantitative writing outcome metrics or experimental measures. It appears to be a critical evaluation and examination of case studies, focusing on opportunities, challenges, and pedagogical efficacy in general rather than measured writing outcomes.""
    }
}"
134,Enhancing Efl Writing Skills for Adult Deaf and Hard of Hearing Individuals,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as Deaf and hard of hearing (D/HH) learners developing English as a Foreign Language (EFL) writing skills during EU-funded summer schools. This fits L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract notes use of internet tools including ChatGPT (an LLM) along with Google Translate and online dictionaries, but it does not specify an experimental or quasi-experimental instructional design integrating ChatGPT as a structured intervention; it appears more exploratory/observational.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on developing EFL writing skills and how tools affect writing quality, coherence, and confidence, which are writing-related variables rather than automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are reported as participants’ perceptions that tools improved vocabulary, grammar, coherence, and confidence. There is no indication of quantitative writing outcome metrics or experimental measures; findings appear primarily perception-based and qualitative.""
    }
}"
135,The Effects of Chatgpt-generated Feedback on Saudi Efl Learners' Writing Skills and Perception at the Tertiary Level: a Mixed-methods Study,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Saudi EFL (English as a Foreign Language) university students, i.e., L2 English learners in an EFL context. The focus is on English academic writing skills.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is ChatGPT-generated feedback on writing, compared with teacher-generated feedback, using a pretest–posttest control group design. ChatGPT is a large language model integrated into the writing instruction/feedback process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing skills and academic writing, specifically the impact of ChatGPT-generated corrective feedback on EFL learners’ writing performance and perceptions. This is a pedagogical intervention, not an automated scoring study.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative writing outcomes are reported: pretests and posttests of writing skills analyzed via ANCOVA. The abstract notes no statistically significant differences in posttest scores between groups, indicating measurable writing performance metrics.""
    }
}"
136,"A Mixed-methods Study on the Use of Chatgpt in the Pre-writing Stage: Efl Learners' Utilization Patterns, Affective Engagement, and Writing Performance",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a Foreign Language (EFL) learners: 56 first-year university students performing argumentative writing tasks in an EFL context, with outcomes focused on English writing performance.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses ChatGPT, a large language model, as support in the pre-writing stage. The design is quasi-experimental: each learner completes two argumentative writing tasks, one with and one without ChatGPT support, enabling comparison of conditions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence and related variables: pre-writing strategies, text quality, and affective engagement during the writing process. ChatGPT is integrated pedagogically in the planning stage of EFL writing, not merely as an assessment tool.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: it compares text quality between ChatGPT and non-ChatGPT conditions and examines correlations between affective engagement and overall writing performance, indicating measurable writing performance metrics.""
    }
}"
137,Predicting Kazakhstani Tefl Students' Continuance Intention towards Using Chatgpt in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are TEFL (Teaching English as a Foreign Language) students at two Kazakhstani universities, i.e., L2 English learners in an EFL context, and the focus is on academic writing in English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines perceptions and continuance intention toward using ChatGPT via a survey-based model (perceived usefulness, ease of use, satisfaction, continuance intention). There is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is academic writing, the primary focus is on technology acceptance (perceptions, satisfaction, continuance intention), not on a pedagogical writing intervention or development of writing competence. It is essentially a usage-intention study rather than a writing-focused instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports survey constructs and factor analysis results but does not report quantifiable writing outcome metrics (e.g., writing scores, text quality measures). Outcomes are attitudinal and behavioral intentions, not measured changes in writing performance.""
    }
}"
138,Probing Language Teachers' Complaints about Chatgpt and Genai Tools: a Social Media Dataset Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on language teachers’ reactions and complaints about ChatGPT and GenAI tools using social media data. There is no indication that participants are L2 English learners in ESL/EFL/ELL contexts, nor that learner data are analyzed.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is an interpretive, qualitative analysis of teachers’ social media posts about GenAI. It does not describe an experimental or quasi-experimental intervention integrating LLMs into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on perceived negative impacts of GenAI on language education, academic integrity, and trust, not on writing competence or writing-related instructional interventions.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental measures are reported. The study is qualitative and interpretive, centered on teachers’ perceptions rather than measured effects on L2 writing.""
    }
}"
139,Metacognitive Awareness and Efl Learners' Perceptions and Experiences in Utilising Chatgpt for Writing Feedback,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 40 EFL undergraduates in a semester-long writing course, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used for writing feedback, the study is framed as exploring students’ perceptions and experiences, not as an experimental or quasi-experimental pedagogical intervention comparing LLM-mediated instruction to another condition. There is no clear structured intervention design manipulating ChatGPT use as a treatment.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is a semester-long writing course, and ChatGPT is used for writing feedback. The focus is on writing-related variables such as motivation for writing, engagement, self-efficacy, and collaborative writing tendency, which are directly tied to writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are perceptions and experiences (motivation, engagement, self-efficacy, collaborative writing tendency) and their relation to metacognitive awareness. The abstract does not report any quantifiable writing performance outcomes (e.g., writing scores, text quality measures) assessing the effectiveness of ChatGPT on writing competence.""
    }
}"
140,Students' Appraisals Post-chatgpt Use: Students' Narrative after Using Chatgpt for Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 'students learning English as a Foreign Language,' indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used by students, the study is exploratory and based on semi-structured interviews about their experiences. There is no indication of an experimental or quasi-experimental design or a structured pedagogical intervention being evaluated.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is academic writing classes and the use of ChatGPT for essay writing, focusing on translation, writing accuracy, efficiency, and idea generation—clearly writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is qualitative, using semi-structured interviews to explore experiences and appraisals. No quantifiable writing outcome metrics or measured effectiveness of the intervention are reported in the abstract.""
    }
}"
141,'what' Is the Machine? Teachers' Professional Learning about Generative Artificial Intelligence as Tutors for Children,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses teachers’ professional learning about generative AI as tutors for children in schools. It does not specify that the children are L2 English learners in ESL/EFL/ELL contexts, nor that the focus is on English language learning.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a critical posthuman analysis of professional learning scenarios around GenAI. There is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into instruction; rather, it theorizes and critiques discourses about GenAI adoption.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on teachers’ professional learning, discourses of technology, and critical perspectives on GenAI in schools. Writing competence or writing-related variables are not mentioned as a primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learning or writing outcomes are reported. The work is described as a ‘critical posthuman diffractive reading’ with implications for understanding GenAI adoption, not as an intervention study with measurable writing outcomes.""
    }
}"
142,University Students' Perceptions of Ai-assisted Writing Tools in Supporting Self-regulated Writing Practices,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students at an Islamic-based university in East Java, Indonesia, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study explores students’ perceptions of unspecified ‘AI-assisted writing tools’ (e.g., grammar checking, spelling correction, paraphrasing, translation). There is no indication that these are LLM-based tools (e.g., ChatGPT) or that there is an experimental/quasi-experimental intervention integrating LLMs into instruction; it is a qualitative case study of existing perceptions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on writing-related practices (planning, monitoring, evaluation) and how AI tools support self-regulated writing strategies, which aligns with writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study employs a qualitative case study with questionnaires, interviews, and document analysis to explore perceptions. It does not report quantifiable writing outcome metrics or measure the effectiveness of an AI/LLM-mediated writing intervention.""
    }
}"
143,Ai-based Assessment of Students’ Writing Skill Progress: Implementing “artificial Neural Network Modeling” Vs. “time Series Prediction”,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to students’ progress in second language (L2) writing skills and mentions English language learning and assessment, but does not clearly specify that participants are L2 English learners in ESL/EFL/ELL contexts or that the target language is English rather than another L2.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares Artificial Neural Networks (MLFN, GRNN) with time series prediction methods as scoring/prediction models. These are not described as large language models (e.g., ChatGPT, GPT-4) integrated into instruction or writing processes, but as AI-based assessment/prediction tools.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on AI-based assessment and prediction of writing skill progress (model performance: MAE, RMSE, R²), not on a pedagogical writing intervention using LLMs. It functions as an automated assessment/comparison of models rather than an instructional writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing test scores are used, they serve as outcome variables for evaluating prediction models, not for assessing the effectiveness of an LLM-mediated writing intervention. No LLM-based instructional treatment or its impact on writing is experimentally evaluated.""
    }
}"
144,‘critical Chatting’ or ‘casual Cheating’: How Graduate Efl Students Utilize Chatgpt for Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as four graduate EFL students, indicating L2 English learners in an EFL context, with a focus on their academic writing in English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the study is described as a qualitative case study exploring how students utilize ChatGPT, not as an experimental or quasi-experimental intervention in writing instruction. There is no indication of a structured pedagogical treatment or controlled intervention design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly academic writing: the study examines ChatGPT-assisted academic writing, students’ purposes and rationales, and how critical thinking is embedded in this writing process.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports a qualitative thematic analysis of purposes, rationales, and critical thinking roles. It does not mention any quantifiable writing outcome metrics (e.g., scores, rubric-based improvements, measurable changes in writing quality) or experimental measures of effectiveness.""
    }
}"
145,Navigating Ai Writing Tools in Medical Education: a Swot Analysis of L2 Academic Writing Perspectives,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 42 medical students in Iran engaged in an L2 academic writing course, clearly indicating L2 English learners in an EFL/ESL-type context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers generically to “AI writing tools” without specifying whether they are LLM-based (e.g., ChatGPT, GPT-4) or other tools (e.g., grammar checkers). No particular LLM is named, so it is not possible to confirm that transformer-based generative models were used.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on students’ perspectives via SWOT and thematic analysis of reflections about AI tools in their academic writing practice. There is no description of an experimental or quasi-experimental pedagogical intervention targeting writing competence; rather, it is an exploratory perception-focused study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports qualitative findings (strengths, weaknesses, opportunities, threats) and thematic analysis of reflections. It does not mention any quantitative or experimental writing outcome measures (e.g., writing scores, rubric-based gains), so effectiveness of AI-mediated writing intervention is not assessed.""
    }
}"
146,Leveraging Open-source Large Language Models for Native Language Identification,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions NLI based on writing in a second language (L2), but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor that the target L2 is English specifically.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study uses open-source and closed-source LLMs, they are applied for Native Language Identification (a classification task), not as an instructional or experimental intervention integrated into L2 writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on NLI model performance (for forensics, marketing, SLA research), not on improving writing competence or writing-related pedagogical variables. It evaluates LLMs as classifiers, not as tools in a writing pedagogy context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) are reported. Outcomes are model accuracy on NLI, not learner writing development following an LLM-mediated intervention.""
    }
}"
147,Modeling Chinese Efl Learners' Intention to Use Generative Ai for L2 Writing through an Integrated Model of the Tam and Ttf,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese EFL university students using generative AI for L2 English writing, clearly fitting an EFL/ELL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a survey and structural equation modeling to examine intention to use generative AI tools. There is no indication of an experimental or quasi-experimental pedagogical intervention where LLMs are integrated into actual writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is technology acceptance (TAM, TTF) and behavioral intention, not on implementing or evaluating a concrete writing intervention. It discusses potential integration conceptually rather than as an instructional context with measured writing development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes are psychological/attitudinal (perceived usefulness, ease of use, attitude, behavioral intention), not measures of writing performance or related competence.""
    }
}"
148,The Effects of Generative Ai Usage in Efl Classrooms on the L2 Motivational Self System,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Japanese university students in an EFL writing class, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention integrates the generative pre-trained AI chatbot ChatGPT into an instructor-led writing class; the treatment group received feedback from ChatGPT during writing workshops, indicating an LLM-based writing intervention with control vs. treatment groups.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is an instructor-led writing class where students participate in writing workshops and receive feedback from ChatGPT, with the stated aim of enhancing motivation and writing skills. The primary pedagogical focus is on writing instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports only motivational outcomes (Ideal L2 Self, Ought-to L2 Self, L2 Learning Experience) measured via questionnaires. While it mentions potential enhancement of writing skills, no quantifiable writing outcome metrics (e.g., writing scores, text quality measures) are reported. Thus, it does not meet the requirement for measured writing outcomes.""
    }
}"
149,"An Ai Chatbot for Efl Writing: Students' Usage Tendencies, Writing Performance, and Perceptions",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students at a high school in Northern Vietnam, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses a 'Writing Assistant Bot (WAB), an artificial intelligence (AI) chatbot designed to support their writing practice at home.' However, the abstract does not specify whether WAB is based on a large language model (e.g., ChatGPT/GPT-like transformer-based generative model) or a non-LLM AI/chatbot system. Without this information, it is unclear if it meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on EFL writing practice, examining how students engage with the chatbot at different writing stages and how this affects writing performance. The primary focus is clearly on writing competence and writing-related variables, not on automated scoring or system evaluation alone.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports that 'The chatbot significantly enhanced writing performance across all aspects: content, organization, vocabulary, language use, and mechanics.' This implies quantifiable writing outcome metrics (e.g., timed-writing tests with analytic scoring), satisfying the requirement for measurable intervention outcomes.""
    }
}"
150,Fostering Transparency: a Critical Introduction of Generative Ai in Students' Assignments,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions 'language learners in two Swiss universities' and 'L2 writing', but does not explicitly state that the target language is English (it could be any L2). Thus, it is unclear whether participants are L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students could use GenAI tools (including ChatGPT), the study focuses on a transparency protocol allowing any online tools and requiring students to highlight AI-derived text. There is no clear experimental or quasi-experimental design integrating LLMs as a structured writing intervention; rather, LLM use is incidental and self-directed.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on transparency, trustworthiness, and preserving take-home written assignments in the GenAI era, not on systematically improving writing competence or specific writing-related skills through an LLM-based pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported concern students’ use of tools, attitudes, transparency, and trustworthiness. The abstract does not indicate any quantifiable writing performance metrics (e.g., scores, quality ratings, accuracy measures) used to assess the effectiveness of LLM-mediated writing intervention.""
    }
}"
151,Generative Artificial Intelligence (gen-ai) in Undergraduate Literature Courses,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions 'undergraduate literature courses' and 'language educators' but does not specify that participants are L2 English learners (ESL/EFL/ELL) or that English is being learned as a second/foreign language. The literary work referenced is Don Quixote, originally in Spanish, and the context could be L1 English literature courses.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses OpenAI's ChatGPT 3.5 (a large language model) in structured classroom activities involving interpretive reading and presentational writing, indicating an LLM-based intervention integrated into course tasks.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The activities include 'interpretive reading and presentational writing activities' and 'presentational writing and conference-style speaking.' Writing is a primary component of the instructional design, with Gen-AI used in relation to essay and presentation tasks.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes two instructional activities and their pedagogical aims (e.g., inspiring close readings, discouraging cheating) but does not indicate any experimental or quasi-experimental design, nor any quantifiable writing outcome measures assessing the effectiveness of the Gen-AI-mediated writing intervention.""
    }
}"
152,Utilizing Large Language Models for Efl Essay Grading: an Examination of Reliability and Validity in Rubric-based Assessments,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are English as a foreign language (EFL) students whose essays are being graded, fitting the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""LLMs (ChatGPT and Bard) are used solely as automated graders. There is no experimental or quasi-experimental design integrating LLMs into writing instruction or the writing process as an intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the reliability and validity of LLMs for rubric-based essay grading, not on improving writing competence or implementing a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics related to learners’ improvement are reported. Outcomes concern reliability (ICC scores) of LLM grading, not changes in students’ writing performance following an LLM-mediated intervention.""
    }
}"
153,Revolutionising Essay Evaluation: a Cutting-edge Rubric for Ai-assisted Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract specifies that the context is English as a Foreign Language (EFL), implying participants are L2 English learners producing AI-assisted essays in English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT and Claude are used, they are employed as evaluators (AI tools to score essays) rather than as part of an instructional or experimental writing intervention aimed at improving learners’ writing. The focus is rubric development and AI-based assessment, not LLM-mediated instruction or writing support.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on developing and validating a rubric and examining AI tools’ assessment consistency. It does not describe a pedagogical intervention targeting writing competence; instead, it centers on evaluation/assessment functionality.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., pre/post writing scores, improvement measures) are reported to assess the effectiveness of an LLM-mediated writing intervention. The quantitative results concern inter-rater reliability, validity, and AI scoring consistency, not learner writing gains.""
    }
}"
154,Incorporating Chatgpt for Efl Writing and Its Effects on Writing Engagement,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners: first-year undergraduate students in China enrolled in a mandatory English writing class. The context is explicitly an English as a Foreign Language (EFL) writing context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention compares peer feedback versus ChatGPT-generated feedback in an EFL writing class. The treatment group used ChatGPT with designed prompts to receive feedback on their writing, indicating an LLM-based writing intervention with a control group.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is situated in an EFL writing course and focuses on how learners interact with written feedback on their language production. The context is clearly writing instruction and writing processes (feedback on writing).""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes measured are affective, behavioral, and cognitive engagement via a survey. The abstract does not report any quantifiable writing performance or competence outcomes (e.g., writing scores, quality measures). The focus is on engagement, not on writing outcome metrics, so it does not meet the requirement for quantifiable writing outcomes.""
    }
}"
155,The Impact of Ai-assisted Blended Learning on Writing Efficacy and Resilience,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'lower intermediate English as a foreign language learners,' which clearly indicates L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that the experimental group used 'AI tools' that provided personalized feedback and reduced cognitive load, but it does not specify whether these tools are large language model–based (e.g., ChatGPT, GPT-4) or other forms of AI (e.g., grammar checkers, analytics). Thus, it is unclear if LLMs are involved.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is writing instruction: the study focuses on 'writing self-efficacy and resilience' and mentions enhanced 'linguistic accuracy' and 'writing development' within a blended learning environment, indicating a primary focus on writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental design comparing an AI-assisted group with a traditional instruction group and reports outcomes such as 'linguistic accuracy, performance self-efficacy, and resilience,' implying quantifiable measures of writing-related outcomes.""
    }
}"
156,Effectiveness and Moderating Factors of Computer-mediated Feedback in L2 Writing: a Meta-analysis,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states that the meta-analysis focuses on EFL and ESL contexts and L2 learners’ writing performance, indicating participants are L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a meta-analysis of computer-mediated feedback (CMF) and does not describe an original experimental or quasi-experimental intervention integrating specific LLMs (e.g., ChatGPT, GPT-4). It synthesizes prior studies rather than implementing an LLM-based writing intervention itself.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 writing performance and how computer-mediated feedback affects writing proficiency, which aligns with writing competence as the central outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a meta-analysis, it aggregates effect sizes from other studies rather than reporting original, study-level quantitative writing outcomes from a specific LLM-mediated intervention. Review/meta-analytic articles are to be excluded per the criteria.""
    }
}"
157,Transforming Efl Teaching with Ai: a Systematic Review of Empirical Studies,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The population is clearly EFL learners in school-based contexts: “integration and impact of Artificial Intelligence in English as a Foreign Language teaching in schools… school-based EFL education.” The focus is on English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a systematic review of various AI tools in EFL teaching, not an experimental or quasi-experimental primary study integrating a specific LLM (e.g., ChatGPT, GPT-4) into writing instruction. It mentions “AI-driven tools,” “Natural Language Processing,” and “Intelligent Tutoring Systems,” but does not specify LLM-based interventions, and as a review article it is excluded by design.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The review covers multiple skills: “reading, writing, listening, speaking, vocabulary, and overall language comprehension.” Writing is only one of several skills and not the primary focus on writing competence or writing-related variables required by the review’s scope.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic review, it synthesizes prior empirical studies and does not itself report original, quantifiable writing outcome metrics from a specific LLM-mediated writing intervention. Review articles are explicitly excluded.""
    }
}"
158,Integrating Ai: Challenges and Opportunities in Teaching English Writing Skills,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract focuses on students learning English as a second or foreign language in the Arab world, with data from English language instructors at universities in KSA and UAE. This aligns with L2 English learners in EFL/ESL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT and AI tools are mentioned, the study is a qualitative exploration of instructors’ perceptions, challenges, and opportunities. There is no indication of an experimental or quasi-experimental design integrating LLMs into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The title and abstract mention teaching English writing skills and concerns about students’ skills development, but the primary focus appears to be general AI use in teaching and related challenges, not a specific, structured writing competence intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is based on qualitative interviews and discusses perceptions, challenges, and recommendations. It does not report quantifiable writing outcome metrics or measured effects of an LLM-mediated writing intervention.""
    }
}"
159,Chatgpt Affordances and Indonesian Efl Students’ Perceptions in L2 Writing: a Collaborative Reflexive Thematic Analysis,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Indonesian EFL students, clearly indicating L2 English learners in an EFL context, and the focus is on EFL writing in English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the study is exploratory/observational. It uses screen capture and interviews to examine affordances, prompt use, and perceptions. There is no mention of an experimental or quasi-experimental instructional intervention design (e.g., treatment vs. control, pre/post measures).""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL writing, specifically essay quality and writing processes (brainstorming, outlining, idea development, feedback on hedging). This aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports perceived potential to improve essay quality but does not indicate any quantifiable writing outcome metrics or experimental measures (e.g., scores, rubrics, statistical comparisons). Data are analyzed via thematic analysis of interactions and interviews, indicating a qualitative design without measured intervention outcomes.""
    }
}"
160,"23rd International Conference on Web-based Learning, Icwl 2024 Was Held in Conjunction with the 9th International Symposium on Emerging Technologies for Education, Sete 2024",2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a proceedings volume description listing multiple papers across diverse topics (e.g., Edu-Metaverse, novice programmers, robotics, interpreting, translation, academic writing platforms). The abstract does not specify any single study with a defined population of L2 English learners in ESL/EFL/ELL contexts, nor does it indicate that the collected papers are limited to such populations.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""Some listed papers mention AI, LLMs, or AI-assisted writing (e.g., ‘AI-Assisted Writing on News Report’, ‘A Robust and Secure Framework for an AI-Assisted Academic Writing Platform’, ‘AI-Enhanced Intercultural Teaching… LLMs’), but the abstract provides no detail on whether any of them use LLMs in an experimental or quasi-experimental writing intervention. As a proceedings overview, it does not describe a specific intervention study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus of the proceedings is broad web-based learning and emerging technologies. While one title mentions ‘AI-Assisted Writing on News Report’ and another an ‘AI-Assisted Academic Writing Platform’, the abstract does not indicate that the volume centers on writing competence or writing-related pedagogical interventions; it is a mixed collection across many domains (programming, robotics, interpreting, etc.).""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported in the abstract. It is a high-level description of 21 papers, not a report of an intervention with measured writing outcomes. Therefore, it does not meet the requirement for reported experimental writing outcome measures.""
    }
}"
161,Exploring whether Generative Artificial Intelligence Can Enhance Chinese Efl Learners’ Academic Writings,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Chinese EFL learners, and the focus is on their English academic writing, satisfying the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, the design is not an experimental or quasi-experimental pedagogical intervention. The study compares original student texts with ChatGPT-revised versions via computational analysis; there is no instructional treatment or learner use of the tool as part of a teaching/learning intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on evaluating ChatGPT’s performance as an editor (a text-revision tool) using Coh-Metrix features, not on a writing instruction context or learner writing processes within a pedagogical setting. It functions more as a tool-performance evaluation than a teaching intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports quantitative changes in textual features (narrativity, deep cohesion) between human and ChatGPT-revised texts, but these are not outcomes of an LLM-mediated writing intervention on learners’ own writing competence. No experimental measures of learner improvement or structured instructional outcomes are reported.""
    }
}"
162,Shifting Roles: Employing Ai-driven Translation Engines to Enhance the Writing Proficiency of Efl Learners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL learners at Qassim University, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses neural machine translation (MT) engines described as AI-driven translation engines. There is no indication these are large language models (e.g., ChatGPT/GPT-4-style generative transformers used interactively for writing), but rather MT systems repurposed for writing support. The focus is on MT, not LLM-based writing assistance.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly aims to shift MT engines from translation to developing writing proficiency among EFL learners, and reports gains in writing skills such as spelling, construction, concordance, and meaning. The primary focus is writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports a pre–post comparison of learners’ writings with significant differences in favor of the AI-based MT intervention, and mentions documented gains in specific writing skills, indicating quantifiable writing outcome measures.""
    }
}"
163,The Role of Ai-based Writing Tools on L2 Writing Competency: Evidence from Palestinian Efl Learners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Palestinian EFL learners (“learning English as a foreign language (EFL)”) and the focus is on English writing aspects, satisfying the population criterion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Grammarly, described as an “AI-based tool.” Grammarly is not a large language model-based generative tool like ChatGPT, GPT-4, or Gemini; it is primarily a grammar-checking/writing support system and is explicitly listed in the protocol as an exclusionary non-LLM tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly investigates the effectiveness of Grammarly on “enhancing EFL learners’ writing aspects” and reports differences in “respects and mechanics of writing,” indicating a primary focus on writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""A quasi-experimental pretest–posttest design with control and experimental groups is used to measure writing before and after the intervention, and statistically significant differences in writing mechanics are reported, indicating quantifiable writing outcomes.""
    }
}"
164,Effects of Human-ai Collaborative Writing Strategy on Efl Students’ Argumentative Writing Skills,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Indonesian EFL university freshmen, so they are L2 English learners in an EFL context, with outcomes focused on English argumentative writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to a “human-AI collaborative writing strategy” and “AI-assisted tools” and “intelligent technology-enhanced writing instruction,” but it does not specify which AI tools were used or whether they are LLM-based (e.g., ChatGPT, GPT-4). Without this detail, it is unclear if the intervention integrates large language models rather than other forms of AI support.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on argumentative writing skills, including constructing well-structured argument traits and conveying critical thinking skills through written discourse. The AI-supported strategy is embedded in writing instruction, not in automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a pre-experimental one-group pretest–posttest design with essay tests scored via established rubrics (MT and HCTSR). It reports quantitative writing outcomes (t-values, p-values, effect sizes) for argumentative writing and critical thinking in writing, satisfying the requirement for quantifiable writing outcome metrics.""
    }
}"
165,Undergraduate Esl Students' Use and Perceptions of Chatgpt for Academic Writing Purposes,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are undergraduate ESL students in an intensive academic writing course at a public science and engineering institute in India, clearly fitting an L2 English/ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study surveys students’ existing use of ChatGPT; there is no mention of an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction or a designed treatment condition.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly ESL academic writing, focusing on students’ use of ChatGPT to generate and review academic texts, summarise, and correct grammar and vocabulary—clearly writing-related.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses Likert-scale and multiple-choice survey items plus one open-ended question, analyzed with descriptive statistics to capture perceptions and usage patterns. It does not report quantifiable writing performance outcomes or measures of writing competence.""
    }
}"
166,Chatgpt and the Development of Core Language Skills: an Exploratory Study of Efl College Students,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 30 English as a foreign language (EFL) college students from Iraq and the Czech Republic, clearly indicating L2 English learners in EFL contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explores the application of ChatGPT, explicitly identified as an AI-powered chatbot (LLM), used as a guide, exercise partner, and rater in language learning over six weeks. This constitutes an LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on the development of multiple core language skills (speaking, reading, writing, listening, communication) and general language learning, not specifically on writing competence or writing-related variables as the primary focus. Writing is only one of several skills and not clearly the central outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The design is phenomenographic, using interviews to capture participants’ views. Reported outcomes are mainly attitudinal percentages (e.g., students finding ChatGPT essential for speaking, writing, etc.). There is no indication of quantifiable writing performance measures (e.g., writing scores, quality ratings) assessing effectiveness of a writing intervention.""
    }
}"
167,Artificial Intelligence-supported Procedural Scaffolding for Promoting Efl Learners' Writing Performance in Flipped Peer Assessment Activities,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners: “English as a Foreign Language (EFL) learners’ writing performance… 74 university students from three intact English writing classes in northern Taiwan.” The focus is clearly on English writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention is described as “AI-based Procedural Scaffolding Peer Assessment (AI-PSPA)” and “AI-based procedural scaffolding,” but the abstract does not specify that the AI is a large language model (e.g., ChatGPT, GPT-4) or transformer-based generative model. It could be rule-based or another non-LLM AI system. Without this detail, it is unclear whether the tool qualifies as an LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence: “to enhance… learners’ writing performance,” with outcome measures including “writing accuracy.” The context is a writing course using peer assessment and flipped learning, which aligns with writing-focused pedagogical intervention rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: “Pre- and posttests of writing performance… Results showed that the AI-PSPA group outperformed the others in writing accuracy.” This indicates measurable writing performance metrics within a quasi-experimental design.""
    }
}"
168,Examining Language Learners' Genai-assisted Writing Self-efficacy Profiles and the Relationship with Their Writing Self-regulated Learning Strategies,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English-as-a-foreign-language (EFL) learners, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “Generative artificial intelligence (GenAI)” and “GenAI-assisted writing,” which likely involves LLMs, but no specific tools (e.g., ChatGPT, GPT-4) or model types are named. It is not fully clear whether the GenAI tools are transformer-based LLMs.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on self-efficacy profiles and writing self-regulated learning (SRL) strategies in GenAI-assisted writing, not on writing competence or performance as primary outcomes. It is about motivational constructs and strategy use rather than a pedagogical intervention targeting writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, text quality measures) are reported. Outcomes are psychological/behavioral (self-efficacy profiles, SRL strategy use, antecedents like years of learning and perceived proficiency), not experimental measures of writing performance under an LLM-mediated intervention.""
    }
}"
169,Efl Secondary Students' Use of Chatgpt for Writing Task Completion Pathways,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) secondary students, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study involves EFL students using ChatGPT, a large language model, to complete a writing task. Although there is no prior instruction, ChatGPT is integrated into the writing process as the main tool for task completion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly writing-focused: students use ChatGPT to complete a writing task, and the discussion centers on prompt engineering in EFL writing classrooms and collaboration with ChatGPT on writing tasks.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative analysis of prompt content, sequencing, and pathways, but does not mention any quantitative writing outcome measures (e.g., writing quality scores, accuracy, complexity) or an experimental/quasi-experimental evaluation of intervention effectiveness.""
    }
}"
170,Gpt Api-based Chatbots as Adaptive and Facilitative Tutors for L2 English Process Writing,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL secondary school students (six ninth-graders) engaged in L2 English process writing, clearly fitting ESL/EFL/ELL L2 English learner contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses GPT-4 Turbo API-based chatbots as adaptive and facilitative tutors across stages of the L2 writing process, which is an LLM-based instructional integration.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on L2 English process writing (prewriting, drafting, revising, editing) and how GPT-based chatbots support these writing stages, i.e., writing competence and process.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports that learners acknowledged a positive impact on writing quality and that chatbots effectively assisted them, but it does not specify any quantitative or experimental writing outcome metrics (e.g., scores, rubric-based gains, pre-post comparisons). It may be primarily a qualitative case study; this cannot be confirmed from the abstract alone.""
    }
}"
171,Chatgpt-assisted Writing: Learners’ Perceptions of Ai Feedback and Influencing Factors,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are intermediate and advanced university students who are clearly described as English language learners, focusing on English writing. This fits L2 English learners in an EFL/ESL/ELL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses ChatGPT 3.5 as an AI chatbot writing aid, which is an LLM. However, the abstract does not clearly describe a structured experimental or quasi-experimental instructional intervention in writing; it mainly mentions use of ChatGPT and subsequent surveys.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly English writing, with ChatGPT used for creating ideas, vocabulary, organization, and grammar in writing. The focus is on writing abilities and the writing process, not on automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are changes in confidence and perceptions (pre- and post-surveys) and qualitative attitudes toward ChatGPT. There is no mention of quantifiable writing performance measures (e.g., writing scores, text quality metrics), only affective and perceptual data.""
    }
}"
172,Improving Academic Writing Proficiency for Efl Students: Leveraging Chatgpt Using Data-driven Learning Principles,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 92 international students in a pre-sessional foundation writing course at a Thai university, described as EFL students in the title and engaged in IELTS-style essay writing in English. This fits L2 English learners in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention explicitly uses ChatGPT (GPT-3.5), a large language model, to generate paraphrases of students’ own compositions, integrated into essay writing instruction via guided worksheets. The design is quasi-experimental with control and comparison groups.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on academic essay writing proficiency and short essay writing skills. ChatGPT is used pedagogically within writing instruction, not merely for automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative writing outcomes: posttest writing scores for control and experimental groups (e.g., control x = 74.03%, Experimental Group 2 x = 94.3%) and statistical significance (p < 0.05). These are clear, quantifiable measures of writing performance.""
    }
}"
173,Exploring Factors Influencing L2 Learners’ Use of Gai-assisted Writing Technology: Based on the Utaut Model,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 419 graduate students in China using generative AI for second language writing, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study concerns generative AI (GAI) use in L2 writing, it is framed with the UTAUT model to examine factors influencing usage behavior, not an experimental or quasi-experimental pedagogical intervention integrating a specific LLM into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is technology acceptance and usage behavior (performance expectancy, effort expectancy, social influence, facilitating conditions), not writing competence or writing-related performance outcomes. It is not a writing-focused instructional intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, quality measures) are reported. Outcomes are behavioral intention and actual usage behavior of GAI, not measured changes in writing performance.""
    }
}"
174,"Assessing the Use of Ai Tools for Efl Exam Preparation at Saudi Universities: Efficiency, Benefits, and Challenges",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL teachers at Saudi universities, working in an EFL context. While the focus is on teachers rather than learners, the context is clearly EFL/ESL-related and involves English exam preparation.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although LLM-based tools such as ChatGPT and Gemini are mentioned, the study is a survey of teachers’ adoption and perceptions of AI tools for exam preparation. There is no experimental or quasi-experimental design integrating LLMs into writing instruction or learners’ writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on exam preparation and question generation (often lower-order items like multiple-choice/true-false), not on developing students’ writing competence or writing-related variables. Essay prompt design is mentioned only tangentially, without pedagogical intervention in writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports survey-based perceptions of efficiency, benefits, and challenges. It does not report quantifiable writing outcome metrics for learners or any measured impact of LLM-mediated writing interventions.""
    }
}"
175,"Examining the Impact of Gamified Mobile and Ai-assisted Language Learning on Academic Integrity, Creative Trait Motivation and Writing Performance",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as upper-intermediate English as a foreign language learners, which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to an “AI-assisted language learning (AIALL)” condition but does not specify the AI technology used. It is unclear whether this involves a large language model (e.g., ChatGPT/GPT-based system) or other non-LLM AI tools. Without explicit mention of LLMs or transformer-based generative models, the nature of the AI intervention cannot be determined from the abstract alone.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing performance is one of the primary outcome variables, alongside academic integrity and creative trait motivation. The study compares different instructional conditions (GMLL, AIALL, control) with a clear focus on writing performance as a key learning outcome.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental design with validated pre-tests and post-tests and reports that both experimental groups outperformed the control group on post-tests for writing performance. This indicates quantifiable writing outcome metrics are collected and analyzed.""
    }
}"
176,From Retrieval to Generative Models: a Design-based Research Approach to Developing a Chatbot for Argumentative Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states that the chatbot Argumate is designed to facilitate EFL students’ argumentative writing, indicating a population of English as a foreign language learners.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The paper describes a design-based research project developing a chatbot, moving from retrieval models to generative models. While generative models are mentioned, it is not clearly stated that these are LLMs (e.g., ChatGPT-like transformer-based models) or that they are integrated as an instructional intervention in an experimental or quasi-experimental study.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on supporting EFL students’ argumentative writing through a chatbot, which aligns with writing competence and writing-related variables rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is described as an ‘Innovative Practice paper’ detailing the development process of the chatbot. There is no indication of experimental or quasi-experimental evaluation or of quantifiable writing outcome metrics; the emphasis is on design and development insights rather than measured intervention effects.""
    }
}"
177,The Impact of Genai-based Collaborative Inquiry on Critical Thinking in Argumentation: a Case Study of Blended Argumentative Writing Pedagogy,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as seven EFL university freshmen, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “GenAI” and “GenAI-based collaborative inquiry” but does not specify that the tool is a large language model (e.g., ChatGPT, GPT-4). It could be an LLM, but this is not explicit from the title/abstract alone.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on critical thinking in argumentation (CTA) and how GenAI-based collaborative inquiry affects CTA. While the context is argumentative writing pedagogy, the reported main outcome is enhancement of CTA in discourse and writings, not writing competence or writing-related variables as primary targets.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study analyzes ‘argumentative writing products’ and notes that CTA was enhanced ‘in both collaborative discourse and writings,’ but the abstract does not state that quantifiable writing outcome metrics (e.g., writing scores, rubric-based measures) were used to assess writing performance. The emphasis appears to be on critical thinking rather than measurable writing outcomes.""
    }
}"
178,Efl Secondary Students’ Use of Chatgpt for Writing Task Completion Pathways,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'English as a foreign language (EFL) secondary students,' clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, the study is observational: students used ChatGPT 'with no prior instruction' and the researchers examined their prompt pathways. There is no experimental or quasi-experimental instructional intervention integrating the LLM into teaching; rather, it analyzes spontaneous use.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is a writing task in EFL, focusing on how students use ChatGPT to complete that task and on implications for EFL writing classrooms. The primary focus is on writing-related processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative findings about prompt types, pathways, and the need for prompt engineering education. It does not mention any quantifiable writing outcome metrics (e.g., writing scores, quality ratings, accuracy measures) to assess effectiveness of the LLM-mediated writing process.""
    }
}"
179,Students’ Appraisals Post-chatgpt Use: Students’ Narrative after Using Chatgpt for Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 12 students learning English as a Foreign Language who used ChatGPT in academic writing classes, clearly fitting an EFL L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""ChatGPT is an LLM and students used it for essay writing support, but the abstract does not specify an experimental or quasi-experimental intervention design; it only mentions exploratory interviews about their experience.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on ChatGPT as scaffolding for writing essays, including translation, writing accuracy, efficiency, and idea generation, which are all writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is based on semi-structured interviews exploring experiences and appraisals. No quantifiable writing outcome metrics or experimental measures of writing performance are reported in the abstract.""
    }
}"
180,Investigating L2 Learners’ Text-to-video Resemiotisation in Ai-enhanced Digital Multimodal Composing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 75 undergraduates in an English writing course at a university in China, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The AI tool is an AI-powered text-to-video platform (Pictory) used for digital multimodal composing. There is no indication that it is a large language model (e.g., ChatGPT, GPT-4) or that transformer-based generative text models are integrated into writing instruction; it is used for generating video clips from text prompts.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on digital multimodal composing and text-to-video resemiotisation, not on writing competence per se. The study examines how learners use AI tools to integrate linguistic, semiotic, and technological elements in converting written genres into videos, emphasizing DMC skills rather than writing-focused pedagogical outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative content and comparative analyses of students’ query revisions and multimodal elements in videos. It does not mention any experimental or quasi-experimental design with quantifiable writing outcome metrics (e.g., writing scores, accuracy, complexity) to assess the effectiveness of the AI intervention on writing.""
    }
}"
181,Exploring the Impact of Chatgpt on Psychological Factors in Learning English Writingamong Undergraduate Students,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 142 undergraduate students at a university in Saudi Arabia learning English writing, which fits an EFL/ESL/ELL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT is the AI tool discussed, the abstract describes an exploratory, questionnaire-based study of psychological factors, not an experimental or quasi-experimental writing intervention integrating ChatGPT into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on psychological factors (cognition, emotions, motivation, attitudes, resilience, stress, coping) rather than on writing competence or writing-related performance variables. Writing is the context, but not the main outcome focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are correlations between ChatGPT use and psychological constructs; there is no mention of quantifiable writing performance metrics (e.g., scores, quality ratings, accuracy) assessing effectiveness of an LLM-mediated writing intervention.""
    }
}"
182,Investigating Efl Teachers’ Lesson Planning for Chatbot-assisted Learning of Argumentative Writing: a Tpack Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is English as a foreign language (EFL), implying L2 English learners in an EFL setting. The focus is on teaching argumentative writing in English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses a chatbot named Argumate for argumentative writing instruction. However, the abstract does not specify whether Argumate is an LLM-based, transformer-based generative model (e.g., ChatGPT-like) or a rule-based/other type of chatbot.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on teachers’ lesson planning and professional knowledge (TPACK) for integrating a chatbot, not on implementing or evaluating a writing intervention with learners. It analyzes lesson plans and teacher interviews rather than actual writing instruction outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study does not describe experimental or quasi-experimental measures of students’ writing performance; it focuses on teachers’ approaches and perceptions.""
    }
}"
183,Exploring Multimodality of Chatgpt for Language Teaching and Learning: a Preliminary Study on Its Pedagogical Prospects,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses language pedagogy in general and mentions L1 and L2 texts, but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor that the focus is specifically on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper is described as presenting ChatGPT as a novel tool and exploring its pedagogical prospects, informed by the authors’ first-hand use and simulated task performance evidence. There is no indication of an experimental or quasi-experimental design or a structured intervention with learners.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing and writing devices are mentioned among several skills (vocabulary, speaking, communicative practices, idioms), but the primary focus appears to be broad language pedagogy and multimodality rather than a focused writing competence intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics or experimental measures. It is framed as a preliminary, conceptual exploration intended to stimulate future empirical research, not as a study assessing intervention effectiveness.""
    }
}"
184,Chatgpt-assisted Language Learning: Effects on Vietnamese English Majors’ Writing Skills and Motivation,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Vietnamese first-year English majors, clearly L2 English learners in an EFL context. The focus is on English writing skills, satisfying the population requirement.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT-assisted writing instruction for the experimental group and compares it with traditional instruction over a 15-week semester. ChatGPT is a large language model, and the design is experimental with control and treatment groups.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing skills, with instruction and outcomes centered on writing performance (IELTS writing assessments) and writing-related motivation. ChatGPT is integrated into the writing instruction process, not just for scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative writing outcomes are reported via pre- and post-tests using IELTS writing assessments, analyzed with ANCOVA, including effect sizes for domains such as task achievement and coherence. This provides measurable writing outcome metrics.""
    }
}"
185,Bringing Cinderella into Spotlight: Genai-assisted Grammar Acquisition in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions “first-year undergraduate students in an academic writing context” but does not specify that they are L2 English learners (ESL/EFL/ELL). Their language background and whether English is a second/foreign language is not stated.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines “the potential of ChatGPT to enhance grammar development in an academic writing context” and explores how a localized version of ChatGPT assists students in improving grammar in writing tasks. ChatGPT is an LLM and is integrated into instruction, satisfying the LLM-based intervention requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is academic writing, focusing on “grammar development in an academic writing context” and “improving their grammar in writing tasks.” This aligns with writing-related competence, even though the emphasis is on grammar within writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as a “qualitative case study” aiming to explore effectiveness, perceptions, and pedagogical implications. The abstract reports that ChatGPT “positively promotes grammar proficiency and learning experience” but does not indicate any quantitative or experimental outcome measures; it appears to rely on qualitative data only.""
    }
}"
186,The Robustness of Ai-classifiers in the Face of Ai-assisted Plagiarism: the Case of Turnitin Ai Content Detector,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly includes English as a foreign language (EFL) texts and discusses issues with AI detectors when dealing with English as a second language writings, indicating an L2 English learner context is part of the data.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study evaluates Turnitin’s AI content detector and compares its detection accuracy across EFL, AI-generated, paraphrased, and humanized AI texts. There is no experimental or quasi-experimental pedagogical intervention integrating an LLM into writing instruction or writing processes; LLMs are only a source of text for detection.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the robustness and accuracy of an AI classifier (Turnitin AI Detector) in identifying AI-assisted plagiarism, not on improving writing competence or writing-related pedagogical outcomes. This aligns with system evaluation rather than instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported concern detection accuracy of AI-generated or modified texts, not quantifiable measures of learners’ writing performance or development following an LLM-mediated writing intervention.""
    }
}"
187,Investigating the Effects of Ai-assisted Teacher Instruction on Online Ielts Writing,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as EFL learners and IELTS candidates in an online IELTS writing course. The context is clearly English as a foreign language, focusing on IELTS Writing Task 2, which is an English writing test.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that teachers used an “AI Copilot” and “AI-assisted teachers using an AI Copilot” to inform instruction and feedback. However, it does not specify whether this AI Copilot is a large language model (e.g., ChatGPT/GPT-4 or another transformer-based generative model) or a different type of AI tool. Without clarification that the AI Copilot is LLM-based, it is unclear if the intervention meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is IELTS Writing Task 2 instruction and students’ writing performance. The study examines writing score improvements and components such as Task Achievement, Coherence and Cohesion, Lexical Resource, and Grammatical Range and Accuracy, indicating a clear focus on writing competence rather than automated scoring alone.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pre- and post-tests and a paired-sample analysis to compare writing scores, reporting significant improvements in four IELTS writing components (TA, CC, LR, GRA). These are quantifiable writing outcome metrics aligned with the effectiveness of the AI-assisted intervention.""
    }
}"
188,Using Generative Artificial Intelligence as an Automated Essay Scoring Tool: a Comparative Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions 120 essays and implications for L2 writing teaching and assessment, but does not clearly state that the essays were written by L2 English learners in ESL/EFL/ELL contexts. The population is therefore not explicitly identifiable as L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses ChatGPT-4 and Gemini solely as automated essay scoring tools to compare their reliability and consistency with human raters. There is no experimental or quasi-experimental integration of LLMs into writing instruction or writing processes as an intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the functionality of LLMs as automated essay scoring systems (reliability, consistency, correlations with human raters), not on pedagogical use for improving writing competence or writing-related variables through instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although essay scores are reported, they are used to evaluate the scoring performance of LLMs versus human raters, not to assess the effectiveness of an LLM-mediated writing intervention. No writing outcome metrics are tied to an instructional or process-oriented intervention with L2 learners.""
    }
}"
189,Comparing Hong Kong Secondary School Students’ Perceptions of Chatgpt-assisted Efl Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 107 Hong Kong secondary school students in an EFL context, and the focus is explicitly on ChatGPT-assisted EFL (English) writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines ChatGPT-assisted EFL writing and compares three teaching approaches (process-based, genre-based, prompt engineering only), indicating an instructional intervention integrating an LLM (ChatGPT) into writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is EFL writing and ChatGPT-assisted writing, the measured outcomes are motivation, cognitive load, and satisfaction. The abstract does not indicate that writing competence or writing-related performance variables (e.g., text quality, accuracy, complexity) were assessed.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports quantitative outcomes only for motivation, cognitive load, and satisfaction. There is no mention of quantifiable writing outcome metrics used to evaluate changes in learners’ writing performance, so it does not meet the requirement for writing outcome measures.""
    }
}"
190,Investigating Efl Students’ Perceptions of Feedback: a Comparative Study of Instructor and Chatgpt-generated Responses in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Saudi English as a Foreign Language (EFL) learners in an advanced writing course, so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study compares instructor feedback with feedback generated by ChatGPT, a large language model, on students’ writing assignments. ChatGPT is integrated as part of the feedback process in an instructional context.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is an advanced academic writing course, and the intervention concerns feedback on writing assignments, with the stated aim of developing learners’ writing skills.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract focuses on students’ perceptions and preferences regarding ChatGPT vs. instructor feedback, collected via a survey. It does not report any quantitative writing outcome measures (e.g., changes in writing scores, quality, accuracy) to assess effectiveness of the LLM-mediated intervention.""
    }
}"
191,Thai Efl University Students’ Writing in the Digital Age: Error Analysis Revisited,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Thai EFL university students, clearly L2 English learners in an EFL context: “Thai EFL university students… 70 undergraduates.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions Google Translate and ChatGPT and discusses the impact of digital tools, there is no indication of an experimental or quasi-experimental LLM-based instructional intervention. The tools are surveyed as resources students use, not as a structured LLM-mediated teaching treatment.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence and errors: “investigated the grammatical errors and writing strategies… mechanical errors… word- and sentence-level errors.” This is clearly about writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports error analysis and survey findings but does not describe any LLM-mediated intervention with pre/post or comparative quantitative writing outcome measures. It is descriptive/diagnostic rather than testing the effectiveness of an LLM-based writing intervention.""
    }
}"
192,Motivation and Achievement in Efl: the Power of Instructional Approach,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 43 first-year EFL students at a Chinese university, clearly L2 English learners in an EFL context, with outcomes reported for English academic achievement and specific English skills.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The AI-blended approach uses AWE, ASR, and the chatbot DouBao. The abstract does not indicate that DouBao (or the other tools) is a large language model or transformer-based generative model; it is only described generically as a chatbot. Without explicit evidence of LLM use (e.g., ChatGPT, GPT-4, similar), this does not meet the LLM-based intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing is one of the key language skills measured (“key language skills such as listening comprehension, translation, and writing”), and AWE is part of the AI-blended instruction, indicating a focus that includes writing competence within broader English achievement.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes: English academic achievement and specific skills including writing, analyzed via repeated measures ANOVA and Friedman tests. Thus, there are measurable writing-related outcomes within an experimental instructional comparison.""
    }
}"
193,Exploring the Use of Chatgpt-generated Model Texts as a Feedback Instrument: Efl Students’ Text Quality and Perceptions,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 104 Chinese high school EFL students, clearly indicating L2 English learners in an EFL context. The focus is on English writing quality (content, organisation, vocabulary, grammar).""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses ChatGPT-generated model texts as a feedback instrument for writing. ChatGPT is a large language model, and the study employs a quasi-experimental pretest–post-test design with control and experimental groups.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL students’ text quality in writing (content, organisation, vocabulary, grammar) and the use of ChatGPT within a writing classroom as feedback. This is a pedagogical writing intervention, not an automated scoring or purely technical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: pretest and post-test writing performance analyzed with descriptive and inferential statistics across analytical measures (content, organisation, vocabulary, grammar), comparing control and experimental groups.""
    }
}"
194,The Revolution of Artificial Intelligence in Scientific Writing: Analysis and Perspectives from Multiple Studies,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract refers broadly to 'researchers' and 'non-native English speakers' in scientific writing, not to L2 English learners in ESL/EFL/ELL instructional contexts. There is no indication of a defined learner population in a language education setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a 'narrative review' and a 'non-systematic assessment of the most recent literature.' It does not report an experimental or quasi-experimental intervention integrating LLMs into writing instruction; it synthesizes existing studies conceptually.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on scientific writing in general (literature review, reference management, publication quality and integrity), not on pedagogical contexts or writing instruction aimed at improving L2 writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a narrative review, the paper does not report original quantitative writing outcome measures from an intervention. It discusses benefits, drawbacks, and ethical implications rather than presenting experimental results on writing performance.""
    }
}"
195,Boosting Punctuation Proficiency: the Power of an Interactive Chatbot for Efl Learners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 60 Omani EFL learners at Sohar University in Oman, clearly an EFL (L2 English) context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses a WhatsApp-based interactive chatbot, but there is no indication it is a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model). It appears to be a rule-based or scripted chatbot designed for punctuation practice, not an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on improving rule-based writing skills, specifically English punctuation, which is a writing-related subskill. The intervention targets punctuation knowledge as part of writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes: pretest, posttest, and delayed posttest scores on punctuation, with statistical analyses (Kruskal-Wallis, p-values, effect sizes) comparing control and experimental groups.""
    }
}"
196,Exploring Patterns of Ai-powered Machine Translation Use in Second Language Writing: a Translanguaging Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are L2 English learners at a Chinese university (English and non-English majors) engaged in L2 writing, fitting ESL/EFL/ELL-type contexts with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is AI-powered machine translation (MT), not a large language model–based tool such as ChatGPT or GPT-4. The abstract frames MT as an AI technology but does not indicate use of transformer-based generative LLMs; it focuses on MT use patterns, not LLM-mediated writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly concerns MT use in L2 writing and identifies patterns of MT use in L2 writing tasks, so the primary focus is on writing-related behavior and competence in context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is qualitative, examining patterns and ideological factors shaping MT use. It does not describe an experimental or quasi-experimental intervention with quantifiable writing outcome metrics; instead it uses narrative frames, interviews, screen recordings, and reflective journals without reported quantitative writing gains.""
    }
}"
197,Enhancing Vocabulary Learning through Technology: Ai-driven Pushed Output Hypothesis for Saudi Efl Learners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are three male Saudi undergraduate EFL learners enrolled in an English degree program at Albaha University, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract refers broadly to “AI-driven technology” and “AI tools” and highlights a ‘pushed email condition’ as an AI-enhanced tool, but there is no indication that a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model) is used. Email as a medium does not constitute an LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is vocabulary acquisition, vocabulary size, and lexical errors, framed under the Pushed Output Hypothesis. While writing samples are collected, the intervention is not clearly a writing competence intervention but a vocabulary learning study using written output as a vehicle.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative vocabulary size (V_Words) and lexical errors (Engber’s taxonomy), and compares conditions (pushed email vs classroom-based), providing measurable outcomes related to written lexical performance.""
    }
}"
198,The Role of Generative Ai and Hybrid Feedback in Improving L2 Writing Skills: a Comparative Study,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 60 Chinese EFL students, clearly indicating L2 English learners in an EFL context, with outcomes focused on English academic writing skills.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is Generative AI (GenAI)–generated feedback and hybrid feedback (GenAI plus human tutor). GenAI is explicitly described as generative AI, implying an LLM-based tool integrated into writing instruction in an experimental comparative design (two groups over 12 weeks).""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 academic writing skills, including grammar, sentence variety, organization, and critical thinking. The AI is used pedagogically to provide feedback on writing, not merely for automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing performance was assessed using GRE writing rubrics, and the study reports measurable improvements in specific writing dimensions (grammar, sentence variety, organization, critical thinking) between groups, providing quantifiable writing outcome metrics.""
    }
}"
199,English as a Foreign Language (efl) Secondary School Students’ Use of Artificial Intelligent (ai) Tools for Developing Writing Skills: Unveiling Practices and Perceptions,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL secondary school students (K12), clearly English-as-a-foreign-language learners, fitting ESL/EFL/ELL contexts with focus on English writing skills.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is exploratory, examining students’ existing practices and perceptions of AI tools (Grammarly, ChatGPT, Google Translate). There is no experimental or quasi-experimental intervention integrating LLMs into instruction; rather, it uses questionnaires and interviews to document current use.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on how AI writing tools mediate stages of the writing process and support idea generation, vocabulary, and accuracy—i.e., writing competence and writing-related variables in an educational context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports practices and perceptions via questionnaires and interviews, with no mention of quantifiable writing outcome metrics (e.g., pre/post writing scores, rubric-based performance) assessing effectiveness of AI-mediated writing interventions.""
    }
}"
200,We Should Promote Genai Writing Tools for Linguistic Equity,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions 'English as an additional language students' in general, but does not specify any actual participant sample or empirical data collection. It appears to be a conceptual/position essay rather than a study with defined L2 participants.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although GenAI writing tools and chatbots (e.g., ChatGPT, Copilot, Claude) are discussed, there is no indication of an experimental or quasi-experimental intervention. The piece is an essay arguing for their use, not an empirical study implementing LLMs in instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on arguing that GenAI tools can promote linguistic equity and on policy/ethical considerations, not on a concrete pedagogical intervention targeting writing competence with measured outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or empirical results are reported. The abstract clearly frames the work as an essay/argument, not a study with measured effects on writing.""
    }
}"
201,The Design and Evaluation of an Interactive Ai Companion for Foreign Language Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “foreign language writing” and “language educators,” but does not specify that the target language is English or that participants are L2 English learners in ESL/EFL/ELL contexts. The specific language and learner population are not identified.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""An “interactive AI companion” and “AI chatbot” are mentioned, but the abstract does not state that it is a large language model (e.g., ChatGPT/GPT-4) or transformer-based generative system. It could be another type of AI tool; the underlying technology is not described.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The tool is explicitly a “collaborative AI writing companion” designed for a “process-oriented…approach to writing,” emphasizing writing as a collaborative process and textual conventions. The context is clearly writing-focused.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes measured are perceptions and psychological constructs (writing self-efficacy, anxiety, self-regulation, anthropomorphism, teaching presence, enjoyment). The abstract does not report any quantifiable writing performance outcomes (e.g., text quality, accuracy, complexity) to assess effectiveness on writing competence.""
    }
}"
202,Exploring Ai-assistance in L2 Chinese Writing with Standardized Assessment Tasks,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are 'Mandarin Chinese foreign language students' completing AP Chinese writing tasks. The target language is Mandarin Chinese, not English, so the population and data focus are not on L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study allows students to use ChatGPT, a large language model, for assistance on one of the writing prompts, and compares performance with and without ChatGPT. This constitutes an experimental design integrating an LLM into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 writing performance in standardized assessment tasks, examining how ChatGPT assistance affects writing scores and aspects of writing support (vocabulary, translation). This aligns with writing competence as the main outcome.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: writing scores with and without ChatGPT, evaluated by two professional raters with high inter-rater reliability. It also analyzes which aspects of ChatGPT students relied on, alongside quantitative and qualitative data.""
    }
}"
203,Generative Ai and English Essay Writing: Exploring the Role of Chatgpt in Enhancing Learners' Task Engagement,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 60 undergraduate learners in an English as a Foreign Language (EFL) context, writing English argumentative essays. This fits the target population of L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT, explicitly described as a generative AI-based tool, within a mixed-methods experimental design over a 2‑month instructional period. This aligns with an LLM-based intervention integrated into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is English argumentative essay writing, and ChatGPT is used as an instructional tool in writing tasks. The primary focus is on writing tasks and related engagement, not on automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports significantly higher engagement levels and qualitative themes (motivation, anxiety, interest, etc.) but does not mention any quantifiable writing performance outcomes (e.g., writing quality, accuracy, complexity). The measured outcome is task engagement, not writing competence or writing-related performance metrics, so it does not meet the requirement for quantifiable writing outcomes.""
    }
}"
204,Generative Ai in Academic Writing: Exploring Esl Students' Strategies and Performance,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 13 university students in Malaysia doing academic writing in English, which strongly implies an ESL/EFL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as an exploratory case study of students’ self-reported GenAI-assisted writing strategies. There is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT; rather, it observes existing usage without a designed treatment.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on GenAI-assisted academic writing in English and how students incorporate ChatGPT into their writing, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports a thematic analysis of self-reported usage and identifies six strategies. It does not mention any quantitative or experimental writing outcome measures; performance effects are discussed qualitatively, not via measurable writing scores or metrics.""
    }
}"
205,English Language Teaching (elt) in the Digital Age: a Meta-thematic Analysis of Artificial Intelligence Research,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The article is a meta-thematic analysis of AI in EFL instruction, not a primary empirical study with a clearly defined participant group. While it concerns EFL contexts, it aggregates prior research rather than reporting on a specific L2 learner sample.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a meta-analysis/content analysis of 18 prior studies on AI in EFL, not an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT, GPT-4) into writing instruction. It does not itself implement or test an LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although it notes that AI can facilitate academic writing, the primary focus is broad AI use in EFL instruction across multiple themes, not a focused investigation of writing competence or writing-related variables within a concrete intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The article synthesizes themes (e.g., motivation, personalized learning, academic writing facilitation) rather than presenting experimental measures of writing performance or structured intervention outcomes.""
    }
}"
206,Incorporating Chatgpt into Genre-based Instruction for Argumentative Writing among Efl College Students,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 48 first-year EFL English majors at universities of technology in Taiwan. This clearly identifies them as L2 English learners in an EFL context, with the focus on English argumentative writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly examines “ChatGPT-integrated genre-based instruction” over a six-week experiment. ChatGPT is a large language model, and it is integrated into the writing instruction as part of an experimental design with pre- and post-tests.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on argumentative writing performance and related constructs (willingness to write, perceptions). ChatGPT is used pedagogically for idea generation and feedback within genre-based writing instruction, not merely for automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative outcomes: pre- and post-writing tests showing “significant improvements in some moves” and pre- and post-instruction WtW questionnaire scores. These provide measurable writing-related outcomes for evaluating the intervention’s effectiveness.""
    }
}"
207,Empowering Authorship with Ai: a Novel Academic Writing Technology for Authorial Voice,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as “first-year ESL students at a Fijian university,” and the focus is on their academic writing in English. This matches the target population of L2 English learners in an ESL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that AVATAR is an “intelligent tutoring system” using “Generative Artificial Intelligence (GAI)” but does not specify whether it is based on a large language model (e.g., transformer-based generative model such as ChatGPT/GPT-4 or similar). Without explicit indication that AVATAR is LLM-based, it is unclear if it meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on academic writing, specifically argumentative essays, and examines “authorial voice” performance and beliefs in students’ essays. AVATAR is integrated into the writing process as an intelligent tutoring system, so the primary context is writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes: statistically significant improvement in authorship beliefs (survey scores, self-scores) and in performance (authorial voice strength scores for essays edited in AVATAR). These are measurable writing-related outcomes linked to the intervention.""
    }
}"
208,Are Ai Tools Effective in Reducing Cognitive Load or Boosting Writing Self-efficacy for L2 Postgraduates?,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as L2 postgraduates engaged in research-based L2 writing, but the target language is not explicitly stated as English. It is likely but not certain that the L2 is English, so this cannot be confirmed from the abstract alone.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract refers generically to “AI tools” with no indication that they are large language model–based (e.g., ChatGPT, GPT-4). It could include tools for reading support or other non-LLM systems. There is no explicit mention of LLMs or transformer-based generative models, so it does not meet the specified intervention criterion.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary outcomes are writing self-efficacy and cognitive load. The abstract emphasizes AI tools for reading lengthy texts and evaluative reading/idea planning, not on writing competence or writing performance. The focus is on psychological and cognitive variables rather than writing competence as such.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing performance outcomes (e.g., writing scores, text quality measures) are reported. The study measures self-efficacy and cognitive load via questionnaires and explores perceptions via interviews, without experimental writing outcome metrics.""
    }
}"
209,Examining the Impact of Artificial Intelligence (ai) Tools for Saudi Arabian English as a Second Language (esl) Students,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are ESL students at a Saudi Arabian university, explicitly described as ESL learners, with outcomes focused on English writing proficiency.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention involves a bundle of AI formative feedback tools: ChatGPT, Grammarly, and QuillBot. While ChatGPT is an LLM, Grammarly and QuillBot are not clearly LLM-based in this context, and the study treats them collectively as ‘AI tools’ rather than isolating an LLM-specific intervention or design. The review requires an LLM-focused experimental or quasi-experimental intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing proficiency and writing-related variables, examining the impact of AI tools on ESL students’ writing proficiency and discussing writing-related opportunities and challenges.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative data from 130 students show statistically significant positive impacts of AI tools on ESL writing proficiency (p-values reported for each tool), indicating measurable writing outcomes.""
    }
}"
210,Empowering Efl Learning: Leveraging Chatgpt for Lesson Planning and Activity Generation in the Efl Classroom,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is an EFL classroom with first-year EFL students in Algeria, and the course is on paragraph writing in English. This fits L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used to generate a lesson plan and activities, but the study investigates teachers’ opinions of these materials via a questionnaire. There is no experimental or quasi-experimental design integrating ChatGPT into learners’ writing instruction with measured learner outcomes.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The course topic is paragraph writing, so the context is writing-related. However, the focus of the study is on the quality of ChatGPT-generated materials as perceived by teachers, not on learners’ writing competence or performance.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports teachers’ opinions collected via questionnaire and does not mention any quantifiable writing outcome metrics for students (e.g., writing scores, text quality measures). It is an evaluative perception study, not an intervention with measured writing outcomes.""
    }
}"
211,Willm: a System for Academic Writing Improvement Based on Large Language Models,2025,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that the study involved 19 non-native English-speaking participants, which suggests L2 English learners. However, it does not specify whether they are in ESL/EFL/ELL instructional contexts (e.g., enrolled in English courses) or simply non-native speakers using the tool, so alignment with the target population is not fully clear.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The paper introduces WILLM, explicitly described as a system for academic writing improvement based on Large Language Models (LLMs). A three-week user study is reported, indicating an intervention using an LLM-based system integrated into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The system provides context-aware feedback on grammar, vocabulary, coherence, and organization, and integrates quizzes and personalized reviews to enhance long-term writing proficiency. The focus is clearly on academic writing improvement rather than on automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that the three-week user study demonstrated improvements in grammar and vocabulary scores, which are quantifiable writing-related outcome metrics assessing the effectiveness of the LLM-mediated intervention.""
    }
}"
212,Integrating Various Types of Feedback in L2 Writing Instruction: Teachers' and Students' Perspectives,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 286 tertiary EFL students and 65 teachers in L2 writing classrooms, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions “automated feedback” enabled by advances in NLP and AI, it does not specify the use of large language models (e.g., ChatGPT, GPT-4) nor describe an experimental or quasi-experimental intervention integrating LLMs into writing instruction. The study is survey-based, focusing on preferences and perspectives rather than an LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on integrating teacher, peer, and automated feedback and examining teachers’ and students’ perspectives and preferences, not on implementing and evaluating a specific writing competence intervention. It is a perception-focused survey, not a pedagogical trial.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, text quality measures) are reported. Outcomes concern judgments of task complexity, feedback preferences, and correlations between these perceptions, without measured changes in writing performance.""
    }
}"
213,Exploring Student Engagement with Artificial Intelligence-guided Chatbot Feedback in Efl Writing: Interactions and Revisions,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are three Chinese university students engaged in English writing learning, clearly an EFL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to an “AI-guided chatbot” providing feedback, but does not specify that it is a large language model (e.g., ChatGPT/GPT-based or similar transformer LLM). It could be a rule-based or non-LLM system; the underlying technology is not described.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is second language writing instruction, focusing on engagement with AI-guided chatbot feedback in English writing learning, which is directly related to writing processes and instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a multiple-case study examining behavioral, cognitive, and emotional engagement. Data sources are chat records, drafts, and interviews. The abstract reports engagement patterns and perceptions but does not mention any experimental or quasi-experimental design or quantifiable writing outcome metrics assessing effectiveness of the AI intervention on writing performance.""
    }
}"
214,Quantum Psychology Approach on Enjoyment as Mediator in Relationship between L2 Flow and Engagement,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 162 high school students in English as a Foreign Language (EFL) speaking and writing classes, so they are L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is described as “AI-assisted” EFL speaking and writing classes, there is no indication that a large language model (e.g., ChatGPT, GPT-4) is used as an instructional intervention. The study is a cross-sectional survey of psychological variables, not an experimental or quasi-experimental LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on psychological flow, enjoyment, and academic engagement, not on writing competence or writing-related performance. Writing is only part of the course context, not the main outcome of interest.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports quantitative measures of flow, enjoyment, and engagement, but no quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity). There is no assessment of the effectiveness of an LLM-mediated writing intervention.""
    }
}"
215,Enhancing Students’ L2 Writing by Integrating Artificial Intelligence with Corpus-based Language Pedagogy,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 50 English as a Foreign Language (EFL) learners majoring in English at an English-Medium Instruction university in China, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract repeatedly refers to “AI tools” but does not specify whether these are large language model–based systems (e.g., ChatGPT/GPT-4) or other AI tools (e.g., grammar checkers, non-LLM systems). Without explicit mention of LLMs or transformer-based generative models, it is not possible to confirm that the intervention integrates LLMs.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on L2 writing and revision: students used corpus and AI tools in writing revision, and the study examines how these tools support writing development and changes in drafts. This aligns with a primary focus on writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports that learners made various changes in revised drafts and describes tool preferences and attitudes, but the abstract does not indicate any experimental or quasi-experimental design with quantifiable writing outcome metrics (e.g., pre/post writing scores, rubric-based gains). The emphasis is on attitudes, usage patterns, and qualitative analysis of revisions rather than measured effectiveness of an AI-mediated intervention.""
    }
}"
216,Effects of Ai Chatbots on Efl Students’ Critical Thinking Skills and Intrinsic Motivation in Argumentative Writing,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 40 Chinese undergraduates in an EFL context (“integrating AI chatbots into EFL classroom activities”), so they are L2 English learners and the focus is on English argumentative writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses “AI chatbots” and specifically “Spark Desk” for writing activities, but the abstract does not state whether Spark Desk is an LLM-based, transformer generative model (e.g., ChatGPT-like) or a different type of AI tool. Without confirmation that Spark Desk is an LLM, it is unclear if this meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is argumentative writing in an EFL classroom. The chatbot is integrated into writing activities, and outcomes relate to critical thinking skills in argumentative writing and intrinsic motivation in that writing context, aligning with writing-focused intervention rather than pure scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""A pretest–posttest quasi-experimental design with control group is used. CTS in argumentative writing is quantitatively assessed using the Illinois Critical Thinking Essay Scoring Rubric, and intrinsic motivation is measured via the Intrinsic Motivation Inventory, with Quade’s test used to detect significant improvements. These are structured, quantifiable outcome measures related to writing performance and associated variables.""
    }
}"
217,Efl Student Engagement with Chatgpt in College Reading Classes Via Prompts and Perceptions,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL university freshmen in college English classes, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines EFL students’ interactions with ChatGPT, an LLM, in a college English class. Although not strictly experimental, it is an instructional context integrating an LLM into coursework.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on prompting practices, usage patterns, and perceptions in a reading class. Writing is mentioned only as one of several skills (reading, writing, vocabulary, grammar) supported; there is no clear focus on writing competence or a structured writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study analyzes prompt types, frequencies, and questionnaire responses (perceptions). It explicitly calls for future research to use standardized assessments; no quantifiable writing outcome metrics or experimental measures of writing performance are reported.""
    }
}"
218,Generative Ai–mediated Scaffolds for Enhanced Critical Thinking in Efl Writing,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL students in vocational colleges, indicating English is the target L2 in an EFL context: “enhancing critical thinking (CT) in English as a Foreign Language (EFL) writing instruction… across three vocational colleges, involving 92 students.”""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “Generative AI tools” and “GenAI-CT framework” and “AI interaction logs,” suggesting use of generative AI, but it does not specify that these are large language models (e.g., ChatGPT/GPT-like transformer-based systems) as opposed to other generative tools. The experimental design is action research with structured integration, but the underlying AI architecture is not clearly identified as an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing instruction with iterative writing and revision cycles. The intervention is embedded in “English as a Foreign Language (EFL) writing instruction” and uses generative AI–mediated scaffolds to support writing processes and critical thinking in writing tasks, aligning with a writing-focused pedagogical context rather than assessment-only use.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study reports “statistically significant gains across all CT dimensions (p<.001)” and mentions student essays as data, but it is not explicit whether any quantifiable writing outcome metrics (e.g., writing quality scores, organization, accuracy) were measured, as opposed to purely critical thinking measures derived from essays. Thus, it is unclear if writing competence outcomes were quantitatively assessed.""
    }
}"
219,Teachers as End-user Developers: Two Case Studies of Adapting Language Models for Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions English as a foreign language and language education, implying possible EFL learners, but it focuses on teachers as end-user developers. It does not clearly state that the study involves L2 English learners as participants with measured learning data.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""Two AI systems are described: an AI-based writing tool (EssayCritic) and a customized chatbot (SchoolGPT), with one explicitly a large language model. However, the focus is on end-user development and adaptation of AI systems, not clearly on an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although EssayCritic is an AI-based writing tool for EFL and feedback is mentioned, the primary focus of the paper is on EUD processes, contrasting specialized vs. large language models, and design/customization issues. Writing competence or writing-related learning outcomes are not the central evaluative focus; rather, the study examines adaptability and teacher development roles.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report or indicate any quantifiable writing outcome metrics (e.g., writing scores, quality measures, accuracy). It discusses how adaptable AI systems can help educators and facilitate language learning, but only at a conceptual level, without mention of experimental measures or structured intervention outcomes on learners’ writing.""
    }
}"
220,"Chinese College Students’ Usage, Evaluation, Perception and Attitude Toward Generative Ai in English as a Foreign Language Writing",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese college students using generative AI tools in EFL (English as a Foreign Language) writing, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a two-stage survey (interviews and questionnaire) about students’ usage, perceptions, and attitudes toward generative AI tools. There is no experimental or quasi-experimental design integrating LLMs as a structured writing intervention; it is descriptive, not an intervention study.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL writing, focusing on how students use AI tools in academic English writing and their perceived benefits and concerns, which is writing-related.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports perceptions, attitudes, and self-reported usage patterns only. It does not mention any quantifiable writing outcome metrics (e.g., writing scores, text quality measures) resulting from an LLM-mediated intervention.""
    }
}"
221,Reimagining Ai Integration: Vietnamese Efl Instructors’ Cultural Reconceptualization of the 6-p Framework,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Vietnamese English as a Foreign Language (EFL) instructors working in academic writing instruction in Vietnamese universities. The context is clearly EFL with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study discusses integrating generative AI into academic writing instruction via the 6-P framework, it is a qualitative investigation of instructors’ cultural adaptation, based on interviews, focus groups, and workshops. There is no experimental or quasi-experimental design implementing an LLM-based intervention with learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on instructors’ cultural reconceptualization of an AI-integrated framework and related professional and institutional issues, not on learners’ writing competence or writing-related performance variables in an instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is purely qualitative and does not report quantifiable writing outcome metrics or measure the effectiveness of an LLM-mediated writing intervention. It focuses on perceptions, cultural adaptation, and theoretical implications.""
    }
}"
222,Exploring Feedback Literacy in L2 Students' Academic Writing: Insights from Their Reported Engagement with Genal for Typical Revision Activities,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are described as “16 L2 Chinese graduate students.” This indicates they are learning Chinese as an L2, not English. The review requires L2 English learners in ESL/EFL/ELL contexts with a focus on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly mentions use of GenAI tools such as DeepSeek and ChatGPT for feedback on academic writing. These are LLM-based tools integrated into students’ revision activities.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is L2 academic writing, focusing on revision activities (grammar correction, linguistic refinement, logical optimization) and feedback literacy, which are directly related to writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses surveys, interviews, and reflective reports to explore perceptions of feedback literacy (cognitive, behavioral, affective, ethical). No quantifiable writing outcome metrics (e.g., writing scores, text quality measures) are reported to assess effectiveness of the GenAI-mediated intervention.""
    }
}"
223,Predictors of Childhood Vaccination Uptake in England: an Explainable Machine Learning Analysis of Regional Data (2021-2024),2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study analyzes childhood vaccination coverage across districts in England using regional-level geographic, demographic, socioeconomic, and cultural variables. It does not involve L2 English learners in ESL/EFL/ELL contexts or any language learning population; English proficiency is only one predictor variable in a public health context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is not educational and does not involve integrating large language models into writing instruction or processes. The study uses CatBoost (a gradient boosting algorithm) and SHAP for explainable machine learning, not LLMs such as ChatGPT or GPT-4.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is public health and vaccination uptake, not writing competence or writing-related variables. There is no focus on writing instruction, writing performance, or any pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No writing outcomes are reported. The outcomes concern vaccination coverage and predictors of uptake, with no quantitative measures of writing performance or writing-related constructs.""
    }
}"
224,Students’ Perceptions of Multiliteracies Development Using Ai-assisted Portfolio Assessment,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 50 freshmen in an EFL classroom, indicating L2 English learners in an EFL context: “an EFL, GenAI-supported portfolio assessment classroom.”""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “Generative Artificial Intelligence (GenAI)” and “AI-generated feedback,” but does not specify whether the tools are large language models (e.g., ChatGPT/GPT-4) or other AI systems. The nature of the GenAI is not detailed.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on multiliteracies, multimodal competence, and portfolio-based multiliteracies development, not specifically on writing competence or writing-related variables. Writing is one component of broader multimodal artefacts, and the outcomes emphasized are multiliteracies, metacognitive development, and professional growth.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly qualitative: “Employing a qualitative design… reflective journals, focus group interviews and narrative inquiries were collected and analysed thematically.” No quantifiable writing outcome metrics or experimental/quasi-experimental measures of writing performance are reported.""
    }
}"
225,Does Writing about Ai Detection Tools Benefit Ethical Conduct?,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract states that all students were “second-language speakers of English” enrolled in a written communication course dedicated to scientific writing, which fits the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study manipulates the topic of an assignment (cognitive biases vs. AI detection accuracy) to see whether it deters students from using generative AI tools, but there is no structured pedagogical integration of an LLM into writing instruction or the writing process. Use of generative AI is explicitly prohibited and not part of an experimental LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is a writing course and students write and revise research report introductions, the focus is on ethical conduct and deterrence of AI tool use, not on designing or evaluating an LLM-mediated writing intervention to improve writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Grades are reported, but they are used to compare AI users vs. non-users under a prohibition context, not to assess the effectiveness of an LLM-based writing intervention. There is no experimental condition where LLMs are intentionally integrated as part of instruction or support, so the required writing outcome for an LLM-mediated intervention is not met.""
    }
}"
226,Exploring the Use of Generative Ai on Students' Academic Writing: an Exploratory Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) learners, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “generative AI (GenAI)” but does not specify whether it is an LLM-based tool (e.g., ChatGPT/GPT-4) or another kind of generative system. However, the main reason for exclusion is not C2 but C4.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on the use of GenAI in academic writing, examining students’ questioning behaviors and adoption of GenAI responses during a designed writing task. The context is clearly writing-related.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates question categories, adoption/modification of GenAI responses, and perceptions of usefulness and ease of use. There is no mention of quantitative writing performance outcomes or measures of writing competence; the outcomes are behavioral and perceptual, not writing-quality metrics.""
    }
}"
227,Generative Ai-powered Non-player Characters in Digital Storyline-based Learning: an Innovative Approach to Efl Writing,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as being in an EFL writing workshop, indicating they are L2 English learners in an EFL context. The focus is on English as a foreign language writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses “generative AI-powered NPCs” enabling dynamic, free-flowing interactions, which strongly suggests an LLM-based system, but the abstract does not explicitly state that the generative AI is a large language model (e.g., ChatGPT/GPT-4 or similar transformer-based LLM). Without this clarification, it is uncertain whether the underlying technology meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing instruction within digital storyline-based learning. The intervention is integrated into writing activities, and the purpose is to enhance EFL writing, indicating that writing competence and writing-related variables are the primary focus rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""Data sources include questionnaires, chat histories, essays, and interviews. The findings reported in the abstract emphasize situational interest, intrinsic motivation, and cognitive load. While it mentions that the approach is essential for improving writing performance and that essays were analyzed, it does not clearly state that quantifiable writing outcome metrics (e.g., writing scores, rubric-based performance measures) were computed and reported.""
    }
}"
228,From Clueless to Confident: How Chatgpt Transforms Academic Writing in Chinese as a Second Language,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are L2 Chinese learners working on academic writing in Chinese as a second language. The focus is explicitly on L2 Chinese, not on English as L2 (ESL/EFL/ELL). Therefore, the population does not meet the review’s requirement of L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines students’ use of ChatGPT (a large language model) in their L2 academic writing processes, indicating integration of an LLM into writing activities. Although qualitative, it clearly involves LLM-mediated writing support.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 academic writing processes and how ChatGPT is used within them, including its role in fostering interactive learning experiences and improving writing skills. This aligns with a writing-focused context rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes a qualitative approach (usage-history screenshots, written assignments, interviews) and focuses on perceptions, attitudes, and self-regulated learning phases. It does not report quantifiable writing outcome metrics or an experimental/quasi-experimental evaluation of effectiveness.""
    }
}"
229,Engaging Multimodal Literacy through Generative Artificial Intelligence: a Case Study from an English as Second Language Writing Classroom,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states the context is an English as a second language (ESL) writing classroom and focuses on two ESL students, indicating L2 English learners in an ESL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses “generative artificial intelligence (GenAI)” and “AI-assisted multimodal writing,” but the abstract does not specify that the tool is an LLM (e.g., ChatGPT, GPT-4) or a transformer-based generative model. It could involve image generation or other non-LLM GenAI tools. Thus, it is unclear whether an LLM is integrated into writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on multimodal literacy and metafunctions (ideational, interpersonal, textual) in AI-assisted multimodal storytelling and photo essays. The outcomes concern awareness of multimodality and the role of images, not writing competence or writing-related variables in a traditional sense. The emphasis is on multimodal composition and literacy rather than writing performance as such.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes a case study of two students, focusing on how they attend to different metafunctions and self-report increased awareness of multimodality. There is no indication of quantifiable writing outcome metrics or experimental/quasi-experimental evaluation of intervention effectiveness; the data appear primarily qualitative and descriptive.""
    }
}"
230,An Autoethnographic Study of Esl Academic Writing with Chatgpt: from Psychological Insights to the Super Framework,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The population is clearly ESL higher education students (and specifically the author as an ESL academic writer), situated in ESL academic writing contexts in the US and Ireland, with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the study is autoethnographic and reflective, not an experimental or quasi-experimental intervention study. There is no structured instructional design or controlled integration of ChatGPT as a pedagogical intervention; rather, it explores lived experiences and proposes a conceptual framework.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on academic writing challenges and how ChatGPT is used in that process, including psychological aspects of writing. The context is clearly writing-related, with data from writing classes, drafts, and annotations.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses autoethnographic reflection and thematic analysis of diaries, logs, and drafts, focusing on psychological needs and experiences. It does not report quantifiable writing outcome metrics or experimental measures of writing performance; outcomes are qualitative and conceptual (e.g., the SUPER framework).""
    }
}"
231,Possibilities for Improving Esp Curriculum Design and Assessment Strategies for Saudi Universities with Chatgpt,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students in Saudi Arabian universities enrolled in ESP writing courses. The abstract explicitly states 'ESP writing courses for EFL students at Saudi Arabian universities,' indicating L2 English learners in an EFL context with focus on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study 'investigates the impact of integrating ChatGPT, an Artificial Intelligence-powered language model, into English for Specific Purposes (ESP) writing courses.' ChatGPT is a large language model, and it is used as part of the instructional intervention, with pre- and post-tests indicating an experimental or quasi-experimental design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence: 'ESP writing courses,' 'enhance students' writing performance,' and 'effectiveness of ChatGPT in improving ESP writing skills.' The context is clearly pedagogical writing instruction, not automated scoring or purely technical evaluation of the model.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses 'pre-and post-tests' and reports 'significant improvements in students' writing proficiency, particularly in grammar accuracy, vocabulary enrichment, creativity, and critical thinking.' This indicates quantifiable writing outcome metrics within a mixed-methods design.""
    }
}"
232,Exploring the Impact of Ai on Critical Thinking Development in Esl: a Systematic Literature Review,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on ESL learners and ESL writing, so the population is L2 English learners in an ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is described as a scoping/systematic literature review synthesizing 15 peer-reviewed articles. It does not report an original experimental or quasi-experimental intervention integrating LLMs; instead, it reviews existing studies.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The review examines how AI influences ESL learners’ critical thinking and writing skills, with explicit reference to ESL writing, so the primary focus includes writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic literature review, it does not itself report original quantifiable writing outcome metrics from an intervention; it synthesizes prior work and focuses on critical thinking development and ethical concerns.""
    }
}"
233,Unlocking Potential: Saudi Efl Male Students' Perspectives on Ai Tools for Enhancing English Writing Proficiency,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Saudi EFL male students from the Languages and Translation Department at a Saudi university, clearly positioning them as L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study explores students’ perceptions of unspecified ‘AI tools’ for writing via qualitative group interviews. There is no indication of an experimental or quasi-experimental design, nor explicit integration of a specific LLM (e.g., ChatGPT) as a structured instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on English writing proficiency and how AI tools affect students’ writing skills, including grammar, vocabulary, confidence, and cultural nuances in writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a qualitative methodology (group interviews, thematic analysis) to examine perceptions and challenges. It does not report quantifiable writing outcome metrics or experimental measures of writing improvement.""
    }
}"
234,Enhancing or Impairing? Exploring Indian Efl Learners’ Academic Writing Narratives with Chatgpt,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Indian English as a Foreign Language (EFL) learners, clearly fitting the L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study involves learners’ use of ChatGPT, it is not an experimental or quasi-experimental intervention. It is a qualitative study based on semi-structured interviews with learners who have already been using ChatGPT informally for over a year, without a structured instructional intervention or controlled design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on academic writing and writing-related variables such as writing fluency, confidence, and cognitive engagement, aligning with a writing competence context rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study employs a qualitative design with thematic analysis of interviews and reports perceptions and narratives. It does not report quantifiable writing outcome metrics or experimental measures of writing performance.""
    }
}"
235,Integrating Large Language Models with Corpus-based Language Pedagogy: an Approach to Collocation Use in L2 Writing Instruction,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 70 sophomore students learning lexical collocations in English writing. The context is clearly L2 English writing instruction, consistent with EFL/ESL-type learners, and the focus is on English as the target language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly investigates integrating large language models (LLMs) with corpus-based pedagogy, implementing a CBLP-LLM intervention. An experimental group receives CBLP-LLM instruction versus a traditional corpus-based control, indicating an experimental design using LLMs in instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 writing instruction, specifically teaching lexical collocations in English writing. Outcomes include writing performance and lexical quality, clearly tying the intervention to writing competence rather than mere system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports significant improvements in writing performance, lexical quality, motivational beliefs, and reduced cognitive load, with pre-, post-, and follow-up measures. These are quantifiable outcome metrics assessing the effectiveness of the LLM-mediated writing intervention.""
    }
}"
236,Exploring the Use of Chatbots in Efl Argumentative Writing: from the Perspective of Dynamic Assessment,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 49 Chinese English as a foreign language (EFL) undergraduate students, clearly L2 English learners in an EFL context, with a focus on English argumentative writing performance.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses “chatbots” for chatbot-assisted dynamic assessment (CA-DA) and non-dynamic assessment (CA-NDA). However, the abstract does not specify whether these chatbots are large language model–based (e.g., ChatGPT/GPT-like transformer models) or simpler rule-based/ELIZA-style systems. Without this information, it is unclear if an LLM is actually integrated.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on learners’ argumentative writing performance and the use of chatbot-assisted assessment in argumentative writing. The study examines how chatbot mediation affects idea generation and development in writing, which aligns with writing competence and writing-related variables rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports effects on ‘argumentative writing performance’ using data from an argumentative essay writing test and compares outcomes across CA-DA, CA-NDA, and a comparison group. This implies quantifiable writing outcome metrics, in addition to qualitative questionnaire and interview data.""
    }
}"
237,Enhancing the Retrieval and Application of English Teaching Resources through Artificial Intelligence Technology as Computational Creativity in Short Story Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are Indonesian EFL undergraduate students in an informatics engineering program, clearly positioning them as L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions AI, conversational chatbots, and an 'AI story' tool, the study is described as a survey investigating how educators implement AI and students’ emotions/attitudes. There is no indication of an experimental or quasi-experimental design testing an LLM-based writing intervention; the AI use is discussed descriptively rather than as a structured intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context includes short story writing and creative writing skills, suggesting a writing focus, but the primary emphasis appears to be on perceptions, implementation issues, and policy needs rather than a targeted writing competence intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports survey findings about emotions, engagement, and perceived benefits/challenges. It does not mention any quantifiable writing outcome measures (e.g., writing scores, text quality metrics) resulting from AI use, only perceptions and self-reported advantages.""
    }
}"
238,"Bridging Ai and Pedagogy: How Ai-adaptive Feedback Shapes Chinese Efl Students’ Writing Engagement, Metacognitive Writing Strategies, and Writing Performance",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese university EFL learners, clearly indicating L2 English learners in an EFL context. The focus is on EFL writing performance, which implies English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract refers to 'AI-adaptive feedback' and 'AI-enhanced adaptive feedback' but does not specify that the system is based on large language models (e.g., ChatGPT, GPT-4, transformer-based generative models). It could be any AI-driven adaptive system, not necessarily an LLM. Without explicit indication of LLM use, it does not meet the LLM-specific intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is situated in EFL writing pedagogy and examines how AI-adaptive feedback affects writing engagement, metacognitive writing strategies, and writing performance. The primary focus is clearly on writing competence and related variables, not on automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing performance is explicitly measured as an outcome variable, and structural equation modeling reports effect sizes (e.g., β = 0.32 for AI-adaptive feedback on writing performance). This indicates quantifiable writing outcome metrics are included.""
    }
}"
239,"Writing with Ai, Thinking with Toulmin: Metacognitive Gaps and the Rhetorical Limits of Argumentation",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Indonesian EFL undergraduates (“Indonesian EFL settings… 30 final-year students”), so they are L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students report using AI tools such as Grammarly and ChatGPT, the study is described as an exploratory mixed-methods mapping of existing practices and gaps. There is no indication of an experimental or quasi-experimental LLM-based instructional intervention or structured integration of ChatGPT into teaching; AI use is observed/self-reported rather than manipulated pedagogically.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on argumentative writing quality, metacognition, and AI literacy in “AI-assisted argumentative writing,” clearly centering on writing competence and related variables rather than on automated scoring or non-pedagogical system evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""While the study reports quantitative measures (e.g., Toulmin element scores, MAI scores, AI literacy questionnaire), these are descriptive of existing abilities and practices. There is no pre/post or comparative design assessing the effectiveness of an LLM-mediated writing intervention; thus, no quantifiable writing outcome attributable to an LLM-based intervention is reported.""
    }
}"
240,"Unmasking the Impacts of Self-evaluation in Ai-supported Writing Instruction on Efl Learners’ Emotion Regulation, Self-competence, Motivation, and Writing Achievement",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as EFL learners in pre-intermediate writing classes at a high school in Iran, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that the experimental group received instruction that combined AI tools with structured self-evaluation activities, but it does not specify whether these AI tools are large language models (e.g., ChatGPT, GPT-4) or other non-LLM tools. Without this detail, it is unclear if the intervention meets the LLM requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly AI-supported writing instruction in EFL classes, with a focus on writing achievement alongside emotion regulation, self-competence, and motivation. Writing instruction and performance are central to the study.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses standardized writing assessments and reports that the experimental group significantly outperformed the control group in writing achievement, providing quantifiable writing outcome metrics.""
    }
}"
241,Engagements with Gpt Responses and Learner Prompts in Chatgpt-based Learning of English Argumentative Writing Logic and Their Impacts,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 42 Chinese university students learning English as a foreign language (EFL). The focus is explicitly on English argumentative writing logic, so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study developed a discipline-specific GPT-4-powered chatbot for learning English argumentative writing logic. Learners used this ChatGPT-based tool as the core of the instructional intervention, indicating an experimental design integrating an LLM into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on learning English argumentative writing logic, a key component of writing competence. The intervention is a ChatGPT-based learning environment for argumentative writing, not an automated scoring or purely functional evaluation of the model.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Learning outcomes were assessed via pre-post-delayed tests and pre-post writing tasks, providing quantifiable measures of writing-related performance (logic knowledge and writing logic). Thus, the study reports experimental outcome metrics for the LLM-mediated writing intervention.""
    }
}"
242,Enhancing Writing Skills through Ai-powered Tools: Perceived Benefits and Challenges among Vietnamese Efl Students,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Vietnamese EFL students: “English-majored students at a university in Vietnam… in enhancing their writing skills in EFL classes,” which fits L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students use AI tools such as ChatGPT, QuillBot, and Claude, the study is observational and perception-based. There is no experimental or quasi-experimental design integrating LLMs as a structured writing intervention; it only surveys existing usage and perceptions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on writing: “using AI-powered tools in enhancing their writing skills in EFL classes… complex academic writing tasks… across nearly all stages of the writing process,” so the primary context is writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are perceptions and correlations about perceived benefits, not objective or experimental writing performance measures. The abstract reports “perceived writing benefits” and a correlation between frequency of AI use and perceived benefits, but no quantifiable writing outcome metrics (e.g., scores, rubric-based writing gains) from an intervention.""
    }
}"
243,Academic Socialization with Generative Ai: a Longitudinal Case Study of an L2 Graduate Student's Academic Literacies Development,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participant is described as an international, English as a Second Language graduate student. The context is clearly L2 English academic discourse socialization, so the population criterion is met.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study involves the learner leveraging ChatGPT (an LLM) for academic literacy development. However, it is framed as a longitudinal case study of naturally occurring use rather than an experimental or quasi-experimental intervention. There is no mention of a designed instructional treatment, control/comparison, or structured pedagogical integration beyond the learner’s own use.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing support is mentioned, the primary focus is broader academic socialization and academic literacies (reading, exploring genres, navigating disciplinary expectations, generating research ideas, identity, confidence). Writing competence is only one of several aspects and not the central evaluative focus of the study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative outcomes such as research interest, genre knowledge, disciplinary identity, and confidence. There is no indication of quantifiable writing outcome metrics or experimental measures of writing performance; data sources are interviews, surveys, and ChatGPT records, used qualitatively.""
    }
}"
244,Evaluating the Potential of Chatgpt-reformulated Essays as Written Feedback in L2 Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses 1,200 argumentative essays written for the TOEFL iBT independent writing task, which are produced by L2 English learners preparing for or taking an English proficiency test. The focus is clearly on L2 English writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study evaluates ChatGPT’s ability to reformulate existing L2 essays and compares different prompts, but there is no indication of an experimental or quasi-experimental pedagogical intervention where learners use LLMs as part of instruction or writing processes. It is a tool-performance study, not an instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is L2 writing and written corrective feedback, the study focuses on assessing ChatGPT-generated reformulations (meaning retention and linguistic development) rather than implementing and evaluating a teaching/learning intervention that targets learners’ writing competence over time.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported (ROUGE-L, syntactic complexity, lexical sophistication/diversity, cohesion) are applied to ChatGPT’s reformulations versus original essays, not to learners’ post-intervention writing performance. There is no quantifiable measure of learner writing gains resulting from an LLM-mediated intervention.""
    }
}"
245,"The Role of Techno-competence in Ai-based Assessments: Exploring Its Influence on Students’ Boredom, Self-esteem, and Writing Development",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 66 Saudi Arabian male EFL learners, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “AI-driven evaluations” and “AI-enhanced assessments” but does not specify the AI technology (e.g., ChatGPT, GPT-4, or any LLM-based system). It could be non-LLM automated assessment. Without explicit mention of LLMs or transformer-based generative models, it is unclear whether the intervention uses an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing skills/proficiency is one of the primary outcome variables, and the intervention is situated in language assessment with a focus on writing development, satisfying the writing-related context requirement.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although pre- and post-assessments of writing proficiency are mentioned, the AI component is described only as part of assessment, not as a writing instruction or process intervention mediated by an LLM. The study evaluates AI-based assessment effects on boredom, self-esteem, and writing, but not an LLM-mediated writing intervention as required. Given the unclear LLM use and assessment-focused design, it does not meet the specified outcome criterion for LLM-mediated writing intervention.""
    }
}"
246,Predictors of Childhood Vaccination Uptake in England: an Explainable Machine Learning Analysis of Regional Data (2021–2024),2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study analyzes district-level childhood vaccination coverage in England using NHS records and geographic, demographic, socioeconomic, and cultural variables. It does not involve L2 English learners in ESL/EFL/ELL contexts; English proficiency is only a predictor variable in a public health dataset.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is not educational and does not involve integrating large language models into writing instruction. The study uses CatBoost (a gradient boosting algorithm) and SHAP for explainable machine learning, not LLMs such as ChatGPT or GPT-4.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is public health and vaccination uptake, not writing competence or writing-related variables. There is no focus on writing instruction, writing processes, or language learning tasks.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No writing outcomes are reported. The outcomes concern vaccination coverage and predictors of disparities, with no assessment of writing performance or writing-related measures.""
    }
}"
247,Tracking the Effects of Gemini as a Genai Tool on L2 Learners' Writing Proficiency and Anxiety: Latent Growth Curve Modeling Approach,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 274 undergraduate English learners in Iran enrolled in academic writing classes. The context is clearly L2 English (EFL) learners, and the focus is on English writing proficiency and anxiety.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses Gemini, explicitly described as a generative AI (GenAI) tool, in a treatment group receiving GenAI-assisted instruction versus a control group with traditional instruction. Gemini is a large language model, and the design is experimental with random assignment.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 writing competence and related affective variables: writing proficiency and writing anxiety in academic writing classes. Gemini is integrated into writing instruction, not just for scoring or evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: writing proficiency measured via a standardized rubric-based assessment and writing anxiety via an L2 writing anxiety scale, with statistical results (MD, SE, CR, p-values) comparing treatment and control groups over time.""
    }
}"
248,Exploring Factors Influencing L2 Learners' Use of Gai-assisted Writing Technology: Based on the Utaut Model,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 419 graduate students in China using GAI for second language writing, indicating L2 English learners in an EFL context, though the target language is implied rather than explicitly stated.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is framed with the UTAUT model and investigates factors influencing L2 learners’ usage behavior of GAI. It is a technology acceptance/usage study, not an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on determinants of GAI usage (performance expectancy, effort expectancy, social influence, etc.), not on improving writing competence or writing-related performance through an instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes are behavioral intention and actual usage behavior of GAI, not measures of writing quality, accuracy, complexity, or related writing performance indicators.""
    }
}"
249,Exploring Second Language Writers' Engagement with Chatgpt Feedback: Revision Behaviors and Perceptions,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 25 B1-level English as a Foreign Language (EFL) university students in Türkiye, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""ChatGPT (an LLM) is used as a feedback tool on students’ opinion essays, but the abstract does not specify an experimental or quasi-experimental design (e.g., no control/comparison group, no pre-post intervention structure is mentioned). It appears more exploratory/descriptive than an intervention study.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on L2 writing, specifically how EFL writers engage with ChatGPT feedback when revising opinion essays. The context is clearly writing competence and revision behavior, not automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study analyzes revision behaviors (acceptance/rejection of feedback, types of revision operations) and perceptions via questionnaires and interviews. There is no indication of quantifiable writing outcome metrics (e.g., changes in writing quality scores, accuracy, complexity) to assess effectiveness of the ChatGPT-mediated intervention.""
    }
}"
250,Using Chatgpt to Bring Non-player Characters to Life: Effects on Students' Storyline-driven Game-based Writing Learning,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese undergraduate students in English as a Foreign Language (EFL) writing classrooms, clearly indicating L2 English learners in an EFL context with a focus on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study integrates ChatGPT, an LLM, into a game-based learning environment via ChatGPT-powered NPCs. It uses a quasi-experimental design comparing a ChatGPT condition with a conventional NPC condition, constituting an LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL writing classrooms, with the game designed to enhance argumentative writing skills. The primary focus is on writing learning and writing performance, not on automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative writing outcomes: student essays were evaluated to compare writing performance, with findings that the ChatGPT group produced clearer, more elaborated, more persuasive essays that better addressed opposing viewpoints. These are measurable writing performance metrics.""
    }
}"
251,Chinese Efl Learners' Genai Literacy in Digital Multimodal Composing and Self-regulated Writing: Chain Mediation Effects of Needs Satisfaction and Creative Self-concept,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 634 Chinese EFL learners, which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines students’ ‘GenAI literacy in digital multimodal composing’ via questionnaires; there is no indication of an experimental or quasi-experimental intervention where an LLM (e.g., ChatGPT, GPT-4) is integrated into writing instruction or tasks. It is a correlational/structural equation modeling study of literacy and psychological variables, not an LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing, focusing on digital multimodal composing and self-regulated writing, which are writing-related constructs and align with the review’s focus on writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are self-report measures (GenAI literacy, needs satisfaction, creative self-concept, self-regulated writing) analyzed via SEM. There are no quantifiable writing performance outcomes (e.g., text quality, accuracy, complexity) from an LLM-mediated writing intervention; the study is about psychological mediation, not measured changes in writing performance.""
    }
}"
252,Exploring the Effectiveness of a Ddl-genai Teaching Mode in Students' Efl Writing Classroom,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 75 second-year Chinese university students in an EFL writing classroom, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract describes an intervention integrating Data-Driven Learning with Generative Artificial Intelligence (GenAI) and mentions a separate GenAI class. However, it does not specify whether the GenAI tools are large language models (e.g., ChatGPT/GPT-based) or other non-LLM generative tools. Without explicit mention of LLM-based systems, it is unclear if the intervention meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL expository writing performance and related variables (structure, content quality, efficiency, engagement) within a writing classroom, indicating a writing-focused pedagogical context rather than automated scoring or non-instructional evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental design with three instructional modes and reports that the DDL-GenAI mode significantly improved students’ writing performance, including specific aspects such as structure and content quality, implying quantifiable writing outcome measures.""
    }
}"
253,Students' Perceptions of Multiliteracies Development Using Ai-assisted Portfolio Assessment,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 50 freshmen students in an EFL classroom, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that the classroom is 'GenAI-supported' and mentions 'AI-generated feedback', but does not specify that the AI is an LLM (e.g., ChatGPT, GPT-4) or provide details about the underlying technology. It could be any GenAI tool.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on multiliteracies, multimodal competence, and portfolio-based multiliteracies development, not specifically on writing competence or writing-related variables. Writing is one component of multimodal artefacts, but the outcomes and discussion center on multiliteracies, metacognition, and professional growth rather than writing performance.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study employs a qualitative design using reflective journals, focus group interviews, and narrative inquiries, analyzed thematically. No quantifiable writing outcome metrics or experimental/quasi-experimental measures of writing performance are reported.""
    }
}"
254,"Impacts of Genai-assisted Collaborative Prewriting on University Efl Students' Interactions with Genai, Outline Quality, and Task Motivation",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 69 Chinese undergraduates in an EFL context, and the study explicitly concerns English as a foreign language (EFL) writing instruction, so the population is L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study integrates a GenAI tool (a generative AI, i.e., LLM-type system) into prewriting instruction via GenAI-assisted collaborative prewriting (GACP) and GenAI-assisted individual prewriting (GAIP) in a within-subjects comparative design.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on prewriting/outline generation, students’ interactions with GenAI, outline quality, and task motivation. It does not examine actual writing competence or written text performance as an outcome, but rather planning artifacts (outlines) and motivational variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantitative outcomes are reported for outline quality (content, organization, language) and task motivation, but not for writing performance or writing-related competence measures. The review requires quantifiable writing outcome metrics; here, only prewriting outline quality and motivation are assessed, not the quality of produced texts.""
    }
}"
255,"The Role of Generative Ai in Writing Doctoral Dissertation: Perceived Opportunities, Challenges, and Facilitating Strategies to Promote Human Agency",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly situates the work in ESL and EFL academic writing contexts and involves doctoral scholars and thesis supervisors, implying participants are L2 English users in higher education.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study explores perceived usefulness and use of ‘GenAI-assisted dissertation writing’ but does not describe an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into instruction. It is framed as a perception study using survey and test data, not as a structured pedagogical intervention with controlled use of an LLM.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on perceived opportunities, challenges, and strategies related to GenAI in dissertation writing, framed through the Technology Acceptance Model and human agency. It does not describe a targeted writing competence intervention or instructional design; rather, it discusses attitudes and institutional implications.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative perceptions (perceived usefulness, challenges, technological singularity syndrome) and does not mention quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity) resulting from an LLM-mediated intervention.""
    }
}"
256,Evaluating Chatgpt's Effectiveness in Enhancing Argumentative Writing: a Quasi-experimental Study of Efl Learners in Pakistan,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Pakistani secondary school students in an English as a Foreign Language (EFL) environment, explicitly focusing on English argumentative writing skills for SSC students.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT, explicitly identified as an artificial intelligence tool, as an intervention over three months. It is described as a quasi-experimental study with ChatGPT interaction integrated into learning, satisfying the LLM-based instructional intervention requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on improving argumentative writing skills, including key components of argumentative writing and error types, clearly situating the study in writing competence rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study employs a quasi-experimental pre-test/post-test design to measure changes in argumentative writing abilities and error types, reporting significant progress and decreased errors as quantifiable writing outcomes.""
    }
}"
257,Assessing the Reliability and Relevance of Deepseek in Efl Writing Evaluation: a Generalizability Theory Approach,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners: 92 CET-4 essays written by non-English majors in China, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""DeepSeek-V3 and R1 are used as automated raters to score and provide feedback on existing essays. There is no experimental or quasi-experimental instructional intervention integrating the LLM into learners’ writing processes or teaching; the focus is on assessment reliability and feedback characteristics.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on writing assessment reliability and feedback relevance (G-theory analysis of scores and feedback) rather than on a pedagogical writing intervention or development of writing competence. It evaluates DeepSeek as an assessment tool, not as part of a teaching/learning intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes or pre/post measures are reported. The study analyzes reliability coefficients and feedback relevance, not changes in students’ writing performance resulting from an LLM-mediated intervention.""
    }
}"
258,Ai Partner Versus Human Partner: Comparing Ai-based Peer Assessment with Human-generated Peer Assessment in Examining Writing Skills,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL college students from the University of Diyala (Iraq) and the University of Hradec Kralove (Czech Republic), indicating L2 English learners in EFL/ESL contexts with a focus on English writing skills.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention contrasts traditional peer assessment (group A) with AI-based assessment using ChatGPT (group B). ChatGPT is a large language model integrated into the peer assessment process, constituting an LLM-mediated writing intervention with a quasi-experimental comparison between groups.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on improving and examining EFL students’ writing skills through peer assessment. The study compares human versus AI-based feedback mechanisms specifically in relation to writing performance, not for automated scoring alone or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantifiable writing outcomes are reported: final writing scores for group A range from 7 to 14 out of 15, and for group B from 6 to 12 out of 15. The abstract notes improvement in writing skills in both groups and significant differences between conditions, indicating measurable writing outcomes.""
    }
}"
259,"Integrating Flipped Learning in Ai-enhanced Language Learning: Mapping the Effects on Metacognitive Awareness, Writing Development, and Foreign Language Learning Boredom",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 70 intermediate Iranian EFL learners, clearly indicating L2 English learners in an EFL context, with outcomes including writing development in English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract repeatedly refers to an “AI-enhanced” flipped learning environment and “AI-enhanced instruction,” but does not specify the AI tool or whether it is an LLM (e.g., ChatGPT, GPT-4) versus other AI (e.g., grammar checkers, analytics). Without explicit mention of an LLM or transformer-based generative model, it is impossible to confirm that the intervention meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""One of the primary variables is “writing development,” and pre- and post-intervention writing tasks were used, indicating that writing competence is a central focus of the intervention, not just assessment or non-pedagogical use.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental design with pre- and post-intervention writing tasks and analyzes inter-group differences via ANCOVA. This implies quantifiable writing outcome metrics were collected to evaluate the effect of the AI-enhanced flipped learning intervention on writing development.""
    }
}"
260,Exploring Teacher Perspectives on Gpt in L2 Disciplinary Academic Writing through the Lens of Feedback Literacy: a Q-methodology Approach,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The participants are 27 L2 university instructors, not L2 English learners. The study focuses on teacher perspectives and teacher feedback literacy rather than on data from L2 learners themselves.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although GPT/LLMs are the topic, the study is a Q-methodology investigation of teacher perspectives and does not describe an experimental or quasi-experimental design where LLMs are integrated as an intervention in learners’ writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is L2 disciplinary academic writing education, but the primary focus is on teacher feedback literacy, ethical considerations, and policy, not on implementing a concrete LLM-mediated writing pedagogy with learners.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study analyzes teacher perspectives via Q-sorts and interviews, without measuring changes in learners’ writing performance or related quantitative outcomes.""
    }
}"
261,Chatwell: an Ai-enabled Adaptive Tutoring System for Improving Mandarin Composition Skills in L2 Students with Learning Difficulties,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are HSK4 learners studying Mandarin Chinese: “100 HSK4 learners… for Chinese language learners.” The target language is Mandarin, not English, so the population does not match the review’s focus on L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study develops CHATWELL, “an intelligent tutoring platform that incorporates optimised large language models to deliver… writing assistance.” It uses a 12-week quasi-experiment comparing this LLM-based system to a Bi-LSTM AES, satisfying the requirement for an LLM-mediated experimental/quasi-experimental intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence in Mandarin composition: “for Improving Mandarin Composition Skills… assessing improvements in writing scores, error reduction, and accessibility metrics.” This is a pedagogical writing intervention, not just automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantifiable writing outcomes are reported: “score gains (14.2 vs. 6.8 points, t(98) = 7.85, p < 0.001), with marked reductions in grammatical (72.1%) and logical (75.3%) errors.” These are clear experimental measures of writing improvement.""
    }
}"
262,A Duoethnographic Study of Writing-with as a Mode of Efl Teacher Professional Development Practice in the Age of Ai,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract focuses on EFL teacher professional development and teacher reflection. Participants are teachers, not L2 English learners in ESL/EFL/ELL contexts, and there is no indication of learner writing data or learner-focused outcomes.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT is mentioned, it appears as an object of teacher reflection within a duoethnographic inquiry, not as an experimental or quasi-experimental pedagogical intervention integrating an LLM into learners’ writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on teacher professional development, reflection, and ethical inquiry around digital tools, not on writing competence or writing-related variables for L2 learners. Writing is framed as a reflective practice for teachers, not as L2 writing instruction or intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is duoethnographic and qualitative, surfacing themes such as emotional labor and pedagogical ambivalence. It does not report quantifiable writing outcome metrics or experimental measures of LLM-mediated writing interventions.""
    }
}"
263,Algorithmic Feedback and Multilingual Identity: Translanguaging Practices in Jordanian Efl Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as multilingual EFL students and instructors in a Jordanian university, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “AI-mediated writing support” and “algorithmic feedback systems” but does not specify that these are large language models (e.g., ChatGPT, GPT-4) as opposed to other AI tools (e.g., grammar checkers). The underlying technology is not identified.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is academic writing in EFL, focusing on how students respond to AI-mediated writing support and algorithmic feedback in their texts, which is directly related to writing practices and pedagogy.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly qualitative (multi-case design using interviews, observations, samples, and journals) and focuses on identity, translanguaging, and critical responses to AI feedback. No quantifiable writing outcome metrics or experimental/quasi-experimental evaluation of intervention effectiveness are reported.""
    }
}"
264,Optimizing Self-regulated Learning: a Mixed-methods Study on Gai's Impact on Undergraduate Task Strategies and Metacognition,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on self-regulated learning in second language (L2) writing among 40 undergraduate students in Eastern China. The context is explicitly L2 writing, which in China typically refers to English; no other target language is mentioned, and the abstract frames it as L2 writing in general, aligning with ESL/EFL/ELL-type contexts focused on English.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses a generative AI (GAI) chatbot platform, Tongyi.ai, over an 8-week intervention. This is a GAI chatbot (i.e., LLM-based) integrated into students’ L2 writing-related learning processes, with an experimental group using the chatbot and a control group using traditional resources, indicating an experimental design with an LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 writing and self-regulated learning variables (task strategy diversity, metacognitive awareness) and writing performance. The abstract explicitly mentions ‘writing performance assessments’ and discusses how GAI tools support task planning and writing processes in L2 writing instruction, not just automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative analysis includes ‘writing performance assessments’ and reports that the experimental group showed greater improvements in writing performance than the control group. Thus, the study provides quantifiable writing outcome metrics alongside other SRL measures, satisfying the requirement for measurable writing outcomes.""
    }
}"
265,Is Generative Ai Ready to Replace Human Raters in Scoring Efl Writing? Comparison of Human and Automated Essay Evaluation,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are English as a Foreign Language (EFL) learners: 35 undergraduate students producing essays in English. The population clearly consists of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses Generative AI as an Automated Essay Scoring (AES) system to compare its scores with human raters. There is no experimental or quasi-experimental instructional intervention integrating LLMs into writing instruction or writing processes; GenAI is only used for scoring.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on rating reliability and comparison between human and GenAI scoring of EFL essays, not on improving writing competence or implementing a pedagogical writing intervention. It is an assessment/measurement study rather than a writing instruction context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports score differences and correlations between human and GenAI ratings, but does not report any writing outcome changes resulting from an LLM-mediated intervention. There is no pre/post or controlled measure of writing improvement attributable to LLM use.""
    }
}"
266,Formally Integrating Generative Ai into Secondary Education: Application of Chatgpt in Efl Writing Instruction,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 99 Grade-10 students in a Hong Kong secondary school enrolled in an English as a foreign language (EFL) writing course. The focus is explicitly on EFL (English) learners in a school context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is a quasi-experiment integrating ChatGPT, a generative AI large language model, into a compulsory EFL writing course. The treatment group used ChatGPT as the tool for EFL writing instruction, compared with conventional media in the control group.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is an EFL writing course, and the intervention is described as ChatGPT-supported EFL writing instruction. The primary focus is on writing instruction and performance, not on automated scoring or non-pedagogical evaluation of the model.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports analysis of participants’ EFL writing performance at the end of the experiment, showing the treatment group outperformed the control group and reporting interaction effects with baseline proficiency. These are quantifiable writing outcome measures.""
    }
}"
267,Efl Lecturers’ Experiences and Perceptions towards Using Chatgpt in Teaching Writing: a Case Study in Vietnam,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The population involves EFL lecturers in Vietnam discussing their use of ChatGPT in EFL writing classes, clearly situated in an EFL/ESL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used in writing instruction, the study is a qualitative case study of lecturers’ experiences and perceptions, not an experimental or quasi-experimental intervention study. There is no structured LLM-mediated intervention being tested with outcome measures.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL writing instruction, with ChatGPT used at pre-, while-, and post-writing stages for brainstorming, grammar checks, proofreading, and feedback—clearly focused on writing competence and related processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses semi-structured interviews and a qualitative case study design, reporting perceptions of benefits and concerns. It does not report quantifiable writing outcome metrics or experimental measures of writing improvement.""
    }
}"
268,Tame the Beast of Chatgpt: Developing Design Principles to Strategically Integrate Chatgpt into Efl Writing through an Activity Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as four Chinese EFL writers, i.e., English as a Foreign Language learners, and the focus is on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study develops and iteratively revises an intervention with design principles to guide ChatGPT-assisted writing, clearly integrating an LLM (ChatGPT) into EFL writing processes within a design-based research framework.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing; the study focuses on how to strategically integrate ChatGPT into EFL writing, with implications for EFL writing instruction, self-regulated learning, and AI literacy. This aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative data sources (screen recordings, semi-structured interviews, stimulated-recall interviews) and thematic analysis to derive contradictions and design principles. It does not mention any quantitative or otherwise explicit, measurable writing outcome metrics (e.g., writing scores, text quality measures, error rates) assessing the effectiveness of the intervention.""
    }
}"
269,Artificial Intelligence-supported Procedural Scaffolding for Promoting Efl Learners’ Writing Performance in Flipped Peer Assessment Activities,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners: 74 university students in English writing classes in Taiwan. The focus is explicitly on English as a Foreign Language (EFL) learners’ writing performance.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention is described as an “AI-based Procedural Scaffolding Peer Assessment (AI-PSPA) approach,” but the abstract does not specify that the AI is a large language model (e.g., ChatGPT, GPT-4) or transformer-based generative model. It could be another form of AI (e.g., rule-based, analytics), so it is unclear whether it meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence: the study aims to enhance EFL learners’ writing performance and reports outcomes such as writing accuracy within a peer assessment and flipped learning context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental design with pre- and posttests of writing performance and reports that the AI-PSPA group outperformed others in writing accuracy. These are quantifiable writing outcome metrics.""
    }
}"
270,University Students' Acceptance of Chatgpt as a Writing Assistance Tool in Esl and Esp Studies,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are ESL and ESP students at two universities, clearly indicating L2 English learners in ESL/ESP contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines students’ perceptions and acceptance of ChatGPT using a TAM-based questionnaire in a non-mandatory use context. There is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is technology acceptance (perceptions and willingness to use ChatGPT) rather than writing competence or writing-related performance variables. It is not a pedagogical writing intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports only questionnaire-based acceptance measures and does not mention any quantifiable writing outcome metrics (e.g., writing scores, quality measures, revisions) to assess the effectiveness of ChatGPT-mediated writing intervention.""
    }
}"
271,Ai Vs. Teacher Feedback on Efl Argumentative Writing: a Quantitative Study,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners: “English as a Foreign Language (EFL) learners at different proficiency levels” in a “writing-focused EFL course in Jordan.” The focus is clearly on English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “AI-generated feedback” and later explicitly mentions “large language models (LLMs), when carefully scaffolded and ethically deployed.” However, it does not specify which AI system was used or confirm that the feedback tool is indeed an LLM-based system (e.g., ChatGPT, GPT-4). Without explicit identification of an LLM tool or architecture, it is uncertain whether the AI feedback is LLM-based rather than another AI technology.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on argumentative writing performance: “effectiveness of AI-generated feedback compared to teacher-generated feedback on the argumentative writing performance of EFL learners.” The intervention is feedback on writing and subsequent revision, clearly a writing-instruction context rather than automated scoring only.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantifiable writing outcomes are reported: “An analytic rubric was used to assess writing performance… pre- and post-test scores analyzed for gains.” Results include significance tests, effect size (Cohen’s d = 0.10), and group comparisons, satisfying the requirement for measurable writing outcomes.""
    }
}"
272,Ai-driven Corrective Feedback for Low-proficiency Learners: a Study on Writing Skill Development,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract refers to 'second language (L2) acquisition' and 'second language writing instruction' with low-proficiency learners. While it does not explicitly say ESL/EFL or English, the context of L2 writing and typical Springer L2 writing research strongly suggests L2 English learners; no other target language is mentioned.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is 'AI-driven corrective feedback, specifically utilizing ChatGPT' over a 10-week intervention. ChatGPT is a large language model, and the design is quasi-experimental with an explicit instructional intervention in writing.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on 'writing skill development' and 'improving the writing skills of low-proficiency learners,' addressing grammar, vocabulary, sentence structure, coherence, and task achievement. This is clearly a pedagogical writing intervention, not an automated scoring or purely functional evaluation of the LLM.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports 'statistically significant improvements across all five assessed components of writing: grammar, vocabulary, sentence structure, coherence, and task achievement.' These are quantifiable outcome measures of writing performance following the LLM-mediated intervention.""
    }
}"
273,Assessing Ai Literacy in Second Language Writing: a Scale Development and Validation Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are university-level English as a Foreign Language (EFL) learners in China, clearly an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on developing and validating the AI Literacy in L2 Writing Scale (AIL-L2WS). It does not describe an experimental or quasi-experimental pedagogical intervention integrating a specific LLM (e.g., ChatGPT, GPT-4) into writing instruction or processes; rather, it measures literacy regarding AI tools in general.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is L2 writing, the primary focus is on constructing a scale of AI literacy (understanding, ethics, attitudes, self-efficacy), not on implementing or evaluating a writing intervention or instructional use of LLMs to improve writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports psychometric properties (EFA, CFA, reliability, validity) of an AI literacy scale. It does not report quantifiable writing outcome metrics (e.g., writing quality scores, complexity, accuracy, fluency) resulting from an LLM-mediated writing intervention.""
    }
}"
274,On the Role of Engagement in Automated Feedback Effectiveness: Insights from Keystroke Logging,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were N = 453 English-as-a-foreign-language (EFL) learners (mean age 16.11). The abstract explicitly states an EFL context and the writing tasks are in English, satisfying the L2 English learner population requirement.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is automated feedback generated by a large language model (GPT-3.5 Turbo). Learners were assigned to receive LLM-generated feedback or no feedback in a classroom experiment, which is an experimental design integrating an LLM into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study centers on a writing task, revision of drafts, and a second writing (transfer) task. The focus is on feedback effectiveness for revision and transfer performance in writing, not on LLM evaluation per se, thus directly targeting writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing outcomes are quantitatively assessed: all texts were scored automatically to assess performance, and the study reports effects of automated feedback on learners’ revision and transfer performance, including mediation analyses via engagement measures. This provides quantifiable writing outcome metrics.""
    }
}"
275,Using Chatgpt to Bring Non-player Characters to Life: Effects on Students’ Storyline-driven Game-based Writing Learning,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese undergraduate students in English as a Foreign Language (EFL) writing classrooms. The focus is on English argumentative writing skills, clearly situating the population as L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study integrates ChatGPT, a large language model, into a game-based learning environment by using ChatGPT-powered NPCs. It employs a quasi-experimental design comparing a ChatGPT condition with a conventional NPC condition, constituting an LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is implemented in EFL writing classrooms with the explicit goal of enhancing argumentative writing skills. The primary learning focus is on writing competence and writing-related variables (motivation, cognitive load, effort regulation) within a pedagogical context, not on automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative writing outcomes: student essays were evaluated to compare writing performance across conditions. Results indicate superior writing performance (clarity, elaboration, persuasiveness, addressing opposing viewpoints) for the ChatGPT group, satisfying the requirement for measurable writing outcomes.""
    }
}"
276,Tracking Progress to Foster Motivation: Implementing a Rubric-based P-score Model in Japanese University Efl Courses,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are in Japanese university EFL courses, i.e., learners of English as a foreign language. The context is clearly English-focused (EFL).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Generative AI is used for rubric-based writing assessments and feedback generation to support consistency, but the study centers on implementing a rubric-based P-score assessment model, not on an LLM-mediated instructional or writing-process intervention. The AI functions primarily as an automated scoring/feedback tool within testing.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on assessment (P-score model) and student perceptions of this assessment system. While writing tests are involved, the AI is used for rubric-based assessment and feedback in testing, aligning more with automated essay scoring/assessment functionality than with a pedagogical writing intervention aimed at improving writing competence.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""Timed writing tests are administered and assessed with the P-score rubric, but the abstract reports survey-based perceptions and feasibility rather than quantifiable changes in writing performance attributable to the AI-supported intervention. It is unclear whether any experimental or quasi-experimental outcome measures of writing improvement are analyzed.""
    }
}"
277,Do Ai Chatbot-integrated Writing Tasks Influence Writing Self-efficacy and Critical Thinking Ability? an Exploratory Study,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract refers to “second language (L2) writing self-efficacy” and “vocational college students with limited language proficiency” in an L2 context. Although the target language is not explicitly stated as English, the framing as L2 writing in a vocational college context suggests L2 learners; however, the specific target language (English vs. another language) is not clearly identified.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses “AI chatbot-integrated writing tasks” and “generative AI chatbots,” but it does not specify whether the chatbot is an LLM-based system (e.g., ChatGPT, GPT-4) or a different, possibly rule-based or non-transformer tool. Without explicit mention of an LLM or a clearly generative transformer-based model, it is unclear whether it meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is L2 writing: the intervention is ‘AI chatbot-integrated writing tasks,’ and outcomes include writing self-efficacy and aspects of critical thinking related to language construction and organization in students’ writings. The focus is pedagogical, not automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports quantitative outcomes only for writing self-efficacy and critical thinking ability via questionnaires. There is no explicit mention of quantifiable writing performance metrics (e.g., writing scores, text quality measures). The only writing-related outcome is self-efficacy, which is an affective/psychological construct rather than a direct writing performance measure.""
    }
}"
278,Harnessing Ai in Academic Writing: the Complex Interplay of Ai Literacy and Self-directed Learning among University L2 Learners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese university students engaged in academic English writing, i.e., L2 English learners in an EFL context: “academic English writing among Chinese university students.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines AI literacy and self-directed learning, not an experimental or quasi-experimental LLM-based writing intervention. AI tools are mentioned generically (summarization, translation, feedback), but there is no indication of a structured LLM-mediated instructional treatment or comparison group design.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on AI literacy and its relationship with self-directed learning, not on writing competence as an outcome. Writing is the context (academic English writing tasks), but the constructs measured are AI literacy dimensions and SDL, not writing performance or writing-related skill development through an intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantitative outcomes are about SDL and AI literacy components (awareness, ethics, usage, evaluation). The abstract does not report any quantifiable writing outcome metrics (e.g., writing scores, quality ratings, accuracy, complexity) to assess effectiveness of AI/LLM-mediated writing intervention.""
    }
}"
279,"Impacts of Genai-assisted Collaborative Prewriting on University Efl Students’ Interactions with Genai, Outline Quality, and Task Motivation",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 69 Chinese undergraduates in an EFL context, and the study explicitly concerns English as a foreign language (EFL) writing instruction, so the population is L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study integrates a generative AI (GenAI) tool—described as supporting outline creation—into EFL writing instruction, comparing GenAI-assisted collaborative prewriting (GACP) and GenAI-assisted individual prewriting (GAIP) in a within-subjects design. This aligns with an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on prewriting (outline creation), interactions with GenAI, and task motivation. While related to writing, the measured outcomes are outline quality and motivation, not actual writing competence or performance. The abstract does not indicate that full written texts or writing proficiency were assessed.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantitative outcomes are reported for outline quality (content, organization, language) and task motivation, but there is no indication of quantifiable outcomes for full L2 writing performance or competence. As the review requires writing outcome metrics, this study does not meet that criterion based on the abstract.""
    }
}"
280,Understanding Efl Student Writers’ Metacognitive Awareness in Utilizing Chatgpt,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 452 EFL undergraduate students in a semester-long writing course, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students use ChatGPT for academic writing feedback, the study is described as a mixed-method investigation of metacognitive awareness, not as an experimental or quasi-experimental intervention testing the effects of an LLM-based instructional treatment on writing.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context involves using ChatGPT for EFL academic writing feedback, which is writing-related, but the primary focus is on metacognitive awareness and practices rather than a structured pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports validation of a metacognitive awareness scale and qualitative insights into metacognitive practices. It does not mention any quantifiable writing outcome metrics (e.g., writing scores, text quality measures) assessing the effectiveness of ChatGPT-mediated writing intervention.""
    }
}"
281,"Ai-driven Language Learning in Higher Education: an Empirical Study on Self-reflection, Creativity, Anxiety, and Emotional Resilience in Efl Learners",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 205 English as a Foreign Language (EFL) undergraduate learners from Chinese universities, clearly fitting an EFL/ESL/ELL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “AI-powered feedback” (grammar/vocabulary corrections, motivational feedback) but does not specify that these tools are large language model–based (e.g., ChatGPT, GPT-4). They could be traditional NLP/grammar-checking systems. No explicit mention of LLMs or transformer-based generative models is made.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing is mentioned (enjoyment in writing and speaking), the primary focus is on self-reflection, creativity, anxiety, and emotional resilience. The study does not frame itself as a writing competence intervention; it examines psychological and affective variables rather than writing performance or writing-related skill development as the main outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are self-reflection, creativity, anxiety reduction, and emotional resilience. There is no indication of quantifiable writing performance metrics (e.g., writing scores, text quality measures) used to assess the effectiveness of AI-mediated writing intervention.""
    }
}"
282,From Algorithms to Annotations: Rethinking Feedback Practices in Academic Writing through Ai-human Comparison,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on Malaysian L2 students in an English for Academic Purposes (EAP) setting, explicitly described as L2 writers of academic introductions in English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is involved, the design is a comparative analysis of feedback characteristics (epistemic strategies and delivery methods) from ChatGPT vs. instructors on existing texts. There is no experimental or quasi-experimental instructional intervention integrating ChatGPT into a writing course or process.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the nature of feedback (assertiveness, mitigation, monologic vs. dialogic) and AI–human comparison, not on a pedagogical intervention aimed at improving writing competence. It is essentially a discourse/feedback analysis rather than an instructional study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics (e.g., changes in writing quality, scores, accuracy) resulting from ChatGPT-mediated intervention. It only analyzes and compares feedback styles, with no measured impact on learners’ writing performance.""
    }
}"
283,The Role of Ai Assisted Writing Feedback in Developing Secondary Students Writing Skills,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as secondary-level EFL students, specifically 60 Turkish high school students. This clearly indicates L2 English learners in an EFL context, with outcomes focused on English writing skills.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention is described as feedback from an 'AI writing assistant' but the abstract does not specify whether this tool is an LLM (e.g., ChatGPT, GPT-4) or a non-LLM AI tool (e.g., rule-based or traditional NLP). Without explicit indication that a transformer-based generative model is used, it is not possible to confirm it meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on developing writing skills: students wrote multiple essays, and the study examines the impact of AI-assisted writing feedback on overall writing performance and subcomponents (grammar, vocabulary, coherence). This is clearly a writing competence intervention, not automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pre-test and post-test writing assessments and reports significant improvement in overall writing performance and specific dimensions (grammar, vocabulary, coherence) for the experimental group. These constitute quantifiable writing outcome metrics.""
    }
}"
284,Chatgpt-generated Versus Human Direct Corrective Feedback on L2 Writing,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are second-year English Pedagogy students at a Chilean university, i.e., L2 English learners in an EFL/ESL context. The study explicitly concerns L2 essay writing in English.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention compares direct written corrective feedback delivered by ChatGPT (an LLM) versus a human teacher. Students were randomly assigned to ChatGPT or teacher feedback conditions over four sessions, indicating an experimental design integrating an LLM into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 essay writing and written corrective feedback. Outcomes are writing-related dimensions: task response, cohesion and coherence, lexical resource, and grammatical range and accuracy. This is a pedagogical intervention, not an automated scoring study.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports that both feedback sources significantly enhanced writing development and that ChatGPT was superior across assessed criteria. These criteria (task response, cohesion/coherence, lexical resource, grammatical range/accuracy) are quantifiable writing outcome measures used to evaluate intervention effectiveness.""
    }
}"
285,Efl Students’ Writing Engagement and Ai Attitude in Genai-assisted Contexts: a Mixed-methods Study Grounded in Sdt and Tam,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners in GenAI-assisted writing contexts, clearly indicating L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines engagement profiles and attitudes toward GenAI and reports that few teachers have actively integrated such tools into their teaching. There is no indication of a structured experimental or quasi-experimental LLM-based writing intervention; GenAI use appears to be contextual/background rather than a designed instructional treatment.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on writing engagement in GenAI-assisted contexts, which is a writing-related variable within EFL learning and teaching.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are engagement profiles and attitudes, not quantifiable writing performance or competence measures. The study does not assess the effectiveness of GenAI on writing quality or other writing outcome metrics.""
    }
}"
286,Examining Language Learners’ Genai-assisted Writing Self-efficacy Profiles and the Relationship with Their Writing Self-regulated Learning Strategies,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as English-as-a-foreign-language (EFL) learners, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study concerns GenAI-assisted writing, the abstract does not describe an experimental or quasi-experimental instructional intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction. Instead, it analyzes learners’ self-efficacy profiles and SRL strategies related to GenAI use, without indicating a designed treatment or controlled instructional use of an LLM.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on motivational constructs (GenAI-assisted writing self-efficacy profiles and writing self-regulated learning strategies), not on writing competence or writing-related performance variables. The study is about psychological profiles in a GenAI context rather than a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, text quality measures) are reported. Outcomes are self-efficacy profiles, SRL strategy use, and antecedents such as years of English learning and perceived proficiency, which are not direct writing performance measures.""
    }
}"
287,"Effects of Three Levels of Ai Integration on Second Language Academic Writing: Evaluating Restricted, Guided, and Free Use of Chatgpt",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Korean college students in English essay writing courses, explicitly described as L2-English learners. The focus is on English academic writing, fitting ESL/EFL/ELL L2 English contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention manipulates three levels of ChatGPT use (Restricted, Guided, Free) as instructional tools in writing courses. ChatGPT is a large language model, and the design is quasi-experimental with comparison groups.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is academic English essay writing. The study examines how different levels of AI (ChatGPT) integration affect writing instruction and learning outcomes, not just system performance or scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: essay scores and sub-dimensions (content quality, organization, language use) comparing groups. These metrics are used to evaluate the effectiveness of the LLM-mediated writing intervention.""
    }
}"
288,Exploring Second Language Writers’ Engagement with Chatgpt Feedback: Revision Behaviors and Perceptions,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 25 B1-level English as a Foreign Language (EFL) students at a university in Türkiye, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly investigates EFL writers’ engagement with ChatGPT feedback on their opinion essays. ChatGPT is a large language model integrated into the writing process as a feedback tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on L2 writing: revision behaviors in response to ChatGPT feedback on opinion essays, and perceptions of its effectiveness for writing improvement. This is directly tied to writing development rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports descriptive and thematic analyses of revision behaviors (acceptance/rejection patterns, types of revision operations) and perceptions from questionnaires and interviews. It does not indicate any quantifiable pre/post or comparative writing outcome measures (e.g., writing scores, quality ratings) assessing effectiveness of the intervention; the focus is on process and perceptions, not measured gains in writing performance.""
    }
}"
289,Empowering Students' Autonomy in Efl Learning: Ai Innovations in Schools of the Global South,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract focuses on English as a Foreign Language (EFL) learning in schools across the Global South, which fits the target population of L2 English learners in EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a PRISMA-guided systematic review synthesizing 22 empirical studies on AI in EFL learning. It does not itself implement an experimental or quasi-experimental LLM-based intervention; rather, it is a secondary review article, which is excluded by the protocol.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on student autonomy in EFL learning broadly (speaking, reading, writing, listening, vocabulary) and AI-supported autonomy, not specifically on writing competence or writing-related variables as the central outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic review, it does not report original experimental writing outcome metrics from a specific LLM-mediated intervention; instead, it synthesizes diverse AI uses and focuses on autonomy, context, and implications.""
    }
}"
290,"Negotiating Understanding, Control, and Authorship: L2 Learners’ Experiences with Ai-assisted Paraphrasing in Academic Writing",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are twelve English-as-a-foreign-language (EFL) students at a Chinese university, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study involves AI tools for paraphrasing, the abstract does not specify that these are large language model–based tools (e.g., ChatGPT, GPT-4). It generically refers to “AI tools” and focuses on how students use them, not on an experimental or quasi-experimental LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on learners’ experiences and interactions with AI-assisted paraphrasing, not on a structured pedagogical intervention targeting writing competence. It is an interview-based qualitative exploration rather than an intervention study of writing instruction or processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is purely qualitative, based on interviews and thematic analysis. No quantifiable writing outcome metrics or experimental measures of writing performance are reported.""
    }
}"
291,"Exploring L2 Writing Motivation in Ai-mediated Efl Contexts: the Role of Teacher Affective Support, Ai Literacy, and Self-efficacy through the Lens of Self-determination Theory",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 627 Chinese university students in an EFL context, focusing on L2 (English) writing motivation in AI-mediated environments.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is situated in an AI-mediated context but does not specify any particular LLM-based tool (e.g., ChatGPT, GPT-4) nor describe an experimental or quasi-experimental LLM-integrated writing intervention. It is a correlational/structural model study based on questionnaires.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on L2 writing motivation and its predictors (teacher affective support, AI literacy, self-efficacy) rather than on writing competence or writing-related performance variables. It is motivational, not a writing instruction or performance intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are questionnaire-based measures of motivation, AI literacy, self-efficacy, and teacher affective support. No quantifiable writing performance or competence metrics are reported to assess the effectiveness of an LLM-mediated writing intervention.""
    }
}"
292,The Psychology of Pedagogical Compromise: Written Corrective Feedback in Chinese Efl Writing through an Ecological Systems Lens,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese university EFL (English as a Foreign Language) students and teachers, clearly situated in an EFL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention concerns types of written corrective feedback (selective, comprehensive, minimal) delivered by teachers. There is no mention of large language models, ChatGPT, or any transformer-based generative AI being integrated into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence, specifically writing accuracy and feedback practices in EFL writing, examined through an ecological systems lens.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative results are reported (e.g., F = 15.61, p < .001, d = 1.08) showing effects of different feedback types on students’ writing accuracy and satisfaction, indicating measurable writing outcomes.""
    }
}"
293,Threshold-triggered Dual Effects in Ai-assisted Efl Writing: Self-efficacy Modulates Grammar Learning Pathways,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly concerns EFL learners (“revolutionizing EFL grammar instruction,” “East Asia’s enduring EFL dilemma”), indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “Artificial intelligence writing tools” and “AI-assisted EFL writing,” but does not specify that these tools are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems. They could be other forms of AI grammar tools. Thus, it is unclear whether an LLM is the core intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on grammar instruction and grammatical competence (“EFL grammar instruction,” “grammatical competence growth/erosion”), not on writing competence or writing-related variables as the main outcome. Writing is mentioned only as a context (“AI-assisted EFL writing”), while the measured construct appears to be grammar learning rather than writing performance.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes related to grammatical competence (e.g., a self-efficacy threshold T=3.278, 60.32% showing regression), indicating experimental or quasi-experimental measures of learning outcomes, even though these are grammar-focused rather than writing-focused.""
    }
}"
294,A Student-centered Framework for Understanding Efl Thesis Writing Difficulties in Vietnam,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Vietnamese English as a Foreign Language undergraduate students writing theses in English, clearly fitting an EFL L2 English learner context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although AI tools are mentioned as part of the support systems and in relation to institutional policies on AI integration, there is no indication of an experimental or quasi-experimental design integrating LLMs (e.g., ChatGPT) into writing instruction or processes. The study is qualitative and exploratory, not an LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on understanding thesis writing difficulties and support systems broadly (including supervisors, peers, family, institutional services, and AI tools), not on a specific LLM-mediated writing intervention or pedagogy.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses qualitative semi-structured interviews and thematic analysis, with no quantifiable writing outcome metrics or experimental measures of the effectiveness of AI/LLM-mediated writing support.""
    }
}"
295,Feedback Literacy and Efl Learner Engagement with Chatgpt Feedback: Predicting Feedback Uptake and Perceived Usefulness,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 51 Chinese university students in EFL writing, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT, a large language model, to provide feedback on three ChatGPT-supported writing assignments, integrating it into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing with a focus on engagement with ChatGPT-generated feedback and feedback uptake in writing assignments, which is directly writing-related.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are feedback uptake (behavioral adoption of feedback) and perceived usefulness, analyzed via regression and mediation. The abstract does not indicate any quantifiable writing performance outcomes (e.g., writing quality scores, accuracy, complexity). The focus is on engagement and perceptions, not measured changes in writing competence.""
    }
}"
296,Exploring Sentence-level Revision Capabilities of Large Language Models in English for Academic Purposes Writing Assistance,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions challenges for non-native English speakers in English for Academic Purposes, but it does not state that there are human participants, learners, or any educational setting. It appears to be a system-level evaluation of LLMs rather than a learner study.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study ‘rigorously assess[es] the performance of LLMs in the Sentence-level Revision (SentRev) task’ via three sets of experiments on LLM behavior. There is no indication of an instructional or quasi-experimental pedagogical intervention with learners; it is an NLP evaluation of LLM capabilities.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is EAP writing assistance and sentence-level revision, the focus is on benchmarking LLM performance and evaluation methods, not on improving learner writing competence through an instructional intervention. It is a tool/benchmark study rather than a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The experiments report LLM performance metrics on SentRev and GEC tasks, not quantifiable writing outcomes for L2 learners. No learner writing scores, gains, or writing-related outcome measures from an intervention are described.""
    }
}"
297,A Multi-stage Interactive Writing Task for the Assessment of English Language Writing Proficiency,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to an assessment of English language writing proficiency but does not specify that participants are L2 English learners (ESL/EFL/ELL). They could be native or mixed populations; the population type is not stated.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""A large language model is used to automatically analyze responses and generate customized follow-up prompts, but this is within a testing/assessment system, not an instructional or pedagogical intervention. There is no experimental or quasi-experimental design integrating LLMs into writing instruction or learning processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on developing and validating an innovative interactive writing assessment task and examining fairness and validity. The LLM is used for theme detection and prompt customization in a high-stakes test context, not for improving writing competence through instruction or feedback.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although scores and response relevance are discussed, they are used to validate an assessment design rather than to evaluate the effectiveness of an LLM-mediated writing intervention. There is no structured pedagogical intervention with pre/post or comparative writing outcome measures aimed at improving learners’ writing.""
    }
}"
298,Integrating Move Analysis and Sentence Reconstruction in Automated Writing Evaluation for L2 Academic Writers,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “L2 academic writers” and “learners,” implying L2 English users in academic writing, but it does not explicitly specify ESL/EFL/ELL participants or any concrete learner sample; the focus is primarily on system development and evaluation, not on a defined learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although GURUS uses transformer-based LLMs and is framed as an AWE system for academic writing, the study described is about system training and performance evaluation (classification, reconstruction) rather than an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction with learners as participants.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on developing and validating an AWE system (classification performance, sentence reconstruction quality). While the paper discusses potential instructional use, the reported study centers on system functionality, not on an implemented writing intervention or measured impact on learners’ writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are system-level metrics (F1-score, Brier score, BERTscore, human assessment of reconstructed sentences), not quantifiable pre/post or comparative writing performance measures for L2 learners following an LLM-mediated intervention.""
    }
}"
299,Examining the Consistency of Instructor Versus Large Language Model Ratings on Summary Content: Toward Checklist-based Feedback Provision with Second Language Writers,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Japanese undergraduate students producing learner-generated summaries in an L2 writing instruction context in Japan, indicating EFL/L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines consistency between instructor ratings and LLM-estimated ratings under different prompts. The LLM is used as an automated rater, not as part of an experimental or quasi-experimental pedagogical intervention in writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on rating consistency and prompt design for LLM-based assessment of summary content, not on an instructional intervention to improve writing competence. It is essentially an evaluation of LLM functionality as an automated scoring/feedback system.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No experimental or quasi-experimental intervention with pre/post or comparative writing outcome measures is reported. The study analyzes agreement between human and LLM ratings, not the effectiveness of LLM-mediated writing instruction on learners’ writing performance.""
    }
}"
300,"Evaluating Generative Ai Tools for Improving English Writing Skills: a Preliminary Comparison of Chatgpt-4, Google Gemini, and Microsoft Copilot",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are B+ level English as a Foreign Language (EFL) students at a preparatory school in Türkiye, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study uses LLM-based tools (ChatGPT-4, Gemini, Copilot), the design compares the tools’ performance and student preferences rather than implementing an experimental or quasi-experimental pedagogical intervention that measures changes in learners’ writing performance attributable to LLM use.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on opinion essay writing, with tools used for brainstorming, outlining, and feedback in EFL writing instruction, so the primary context is writing competence and writing-related processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Rubric-based evaluations are applied to the tools’ outputs (idea generation, structuring, feedback actionability), not to students’ own writing development over time. The abstract does not report quantifiable learner writing outcome metrics (e.g., changes in essay scores pre/post intervention), but rather comparative tool performance and perceptions.""
    }
}"
301,The Role of Chatgpt in Enhancing Efl Students’ Esp Writing Skills: an Experimental Study of Gender and Major Differences,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as EFL university students learning ESP writing, which clearly indicates L2 English learners in an EFL context with a focus on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is an experimental study using ChatGPT as a self-directed learning tool to enhance ESP writing skills. ChatGPT is a large language model integrated into the writing learning process, satisfying the LLM-based intervention requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on ESP writing skills, and the intervention explicitly targets enhancement of writing performance, not automated scoring or system evaluation. Thus, the context is writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pre- and post-tests with statistical analyses (Wilcoxon signed-rank test and ANOVA) and reports substantial improvements in writing skills across measured dimensions, indicating quantifiable writing outcome metrics.""
    }
}"
302,Perceptions and Effectiveness of Ai-assisted Written Corrective Feedback: a Case Study of Chinese Efl University Students,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese EFL university students in a College English course, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “AI-assisted written corrective feedback (AI-WCF)” and “AI tools,” but does not specify that these are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems. The underlying AI technology is not identified, so it is unclear whether an LLM is used.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on argumentative writing and subskills such as unity, support, cohesion and coherence, and language use. AI is integrated into writing tasks via AI-WCF, so the primary context is writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are based on self-assessed progress via questionnaires and perceived gains in writing subskills. There is no indication of objective, performance-based writing measures (e.g., rated texts, scores) being analyzed; the design centers on attitudes and perceived improvement rather than quantifiable writing performance outcomes.""
    }
}"
303,A Hybrid System for Automated Assessment of Korean L2 Writing: Integrating Linguistic Features with Llm,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The population consists of learners of Korean as an L2, not L2 English learners. The abstract focuses on Korean L2 writing and uses the Korean Language Learner Corpus and TOPIK scale, indicating the target language is Korean rather than English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although an LLM is used, it is employed to generate a reference answer for an automated essay scoring (AES) system, not as part of an instructional or quasi-experimental pedagogical intervention in writing. The design is system development and evaluation, not an LLM-mediated teaching/learning intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automated assessment of writing (AES) and improving scoring accuracy, not on writing instruction, writing processes, or pedagogical use of LLMs. This falls under evaluation of AES functionality, which is excluded by the review criteria.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports system performance metrics (e.g., scoring accuracy, alignment with human judgments) rather than quantifiable learner writing outcomes resulting from an LLM-mediated intervention. There is no experimental measure of changes in learners’ writing proficiency due to LLM-based instruction.""
    }
}"
304,Teachers’ Perceptions and Students’ Strategies in Using Ai-mediated Informal Digital Learning for Career Esl Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are university students in an English writing course in an ESL context (“career ESL writing instruction”), so they are L2 English learners in an ESL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although LLM tools such as ChatGPT are mentioned among “AI-IDLE” tools, the study is described as a case study exploring “teachers’ perceptions and students’ strategies” rather than an experimental or quasi-experimental intervention design. There is no indication of controlled treatment conditions or structured LLM-based instructional intervention being evaluated for effectiveness.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly writing-focused: “career ESL writing instruction,” “English writing course,” and exploration of how AI tools are used to improve rhetorical accessibility and writing aligned with professional identities.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative findings about strategies and perceptions (think-aloud protocols, interviews) and notes that students “became more aware of how to improve their writing,” but it does not mention any quantifiable writing outcome metrics or experimental measures of writing performance.""
    }
}"
305,Blending Focus on Form and Technology: Teaching Essay Writing with Ai Tools; Biçim Ve Teknolojiye Odaklanmayı Harmanlamak: Yapay Zekâ Araçlarıyla Makale Yazmayı Öğretme,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states that the participants were 120 undergraduate ESL learners, indicating L2 English learners in an ESL context with a focus on English essay writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study integrates “AI tools” into essay writing instruction but does not specify whether these are large language models (e.g., ChatGPT, GPT-4) or other non-LLM tools (e.g., grammar checkers). Without explicit mention of LLM-based tools or generative transformer models, it is not possible to determine if the intervention meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on teaching essay writing and examining effects on accuracy, fluency, and overall writing proficiency. This aligns with writing competence and writing-related variables in a pedagogical intervention context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a mixed-methods design with pre- and post-tests and reports quantitative outcomes such as accuracy, fluency, and overall proficiency in writing, indicating measurable writing outcome metrics.""
    }
}"
306,Pre-service Teachers’ Perceptions of the Use of Artificial Intelligence in an English as a Foreign Language Learning Context,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 120 EFL university students (B1–B2 CEFR) in an English as a Foreign Language context, clearly L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study involves generative AI tools, specifically ChatGPT, it focuses on perceptions of integration rather than an experimental or quasi-experimental intervention design assessing its instructional impact. No structured LLM-mediated instructional treatment is described.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on perceptions of AI in EFL learning broadly, not on a targeted writing competence intervention. Writing is mentioned as one perceived benefit, but not as the central, systematically designed focus of the study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses surveys, narratives, questionnaires, and interviews to gather perceptions. It does not report quantifiable writing outcome metrics (e.g., pre/post writing scores, rubric-based writing performance) to evaluate the effectiveness of ChatGPT on writing.""
    }
}"
307,Artificial Intelligence in Esl/efl Education: Evidence from Recent Reviews (2024–2025),2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a “review of reviews,” synthesizing 14 systematic reviews, meta-analyses, and meta-syntheses. It does not report on a primary study with a defined participant population of L2 English learners; instead, it aggregates findings from other reviews.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""As a secondary review study, it does not implement an experimental or quasi-experimental LLM-based intervention itself. It summarizes evidence on AI-enhanced instruction (including generative AI like ChatGPT) from prior reviews rather than conducting an intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on synthesizing broad themes (overall effectiveness, applications in writing and speaking, learner roles) across prior reviews, not on a specific, primary writing-focused pedagogical intervention. It is a higher-level evidence synthesis, not an intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The article aggregates effectiveness data from other reviews and does not report original, quantifiable writing outcome metrics from a primary LLM-mediated intervention. As a review-of-reviews, it falls under the exclusion of reviews and meta-analyses.""
    }
}"
308,Genai and Human Assessments of L2 Chinese Writing: Interrater Reliability and Rater Bias,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The population consists of learners of Chinese as a second language (L2 Chinese writing). The review targets L2 English learners in ESL/EFL/ELL contexts with a focus on English writing, so this population does not meet the inclusion criterion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT and DeepSeek are used as GenAI raters to assess L2 Chinese writing. The study focuses on their rating performance (interrater reliability, severity, bias), not on integrating LLMs into writing instruction or writing processes as an experimental or quasi-experimental pedagogical intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on writing assessment (interrater reliability, rater bias) rather than on improving writing competence or writing-related learning outcomes. It evaluates GenAI as automated raters, which falls under excluded contexts (automated essay scoring/assessment studies).""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports metrics related to rating performance (agreement, correlation, severity, bias) but does not report quantifiable writing outcome measures assessing the effectiveness of an LLM-mediated writing intervention on learners’ writing performance.""
    }
}"
309,Examining the Efficacy of Chatgpt and Human-derived Corrective Feedback in Addressing Grammatical Errors in Saudi Efl Students’ Compositions,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 53 Saudi EFL undergraduates at the University of Jeddah. The context is explicitly EFL and the focus is on English grammatical accuracy in students’ compositions.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses ChatGPT to provide written corrective feedback (WCF) on students’ compositions for the experimental group, compared against human WCF in a control group over eight weeks. ChatGPT is a large language model integrated into the writing instruction process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on writing (students’ compositions) and written corrective feedback aimed at improving linguistic accuracy in writing. The context is pedagogical writing intervention, not automated essay scoring or purely system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Pretests and posttests assessed participants’ grammatical competence before and after the intervention, and quantitative findings report that the experimental group significantly outperformed the control group in the posttest. These are quantifiable writing-related outcome measures.""
    }
}"
310,Exploring Efl Teachers' Strategies in Employing Ai Chatbots in Writing Instruction to Enhance Student Engagement,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL students, i.e., L2 English learners in an EFL context: “the incorporation of chatbots… in EFL writing… The research involved 40 students and two faculty members.”""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “AI chatbots, one of the advanced AI language models,” but does not specify that they are LLM-based tools such as ChatGPT/GPT-4 or similar transformer-based generative models. It could include non-LLM chatbots. Thus, whether the intervention uses an LLM is unclear from title and abstract alone.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on student engagement and teachers’ strategies in using AI chatbots in writing instruction: “evaluate student engagement levels with AI chatbots and assess EFL teachers' strategies for stimulating this engagement.” Writing competence or writing-related performance is not the main outcome; engagement is.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports quantitative engagement outcomes (affective, behavioral, cognitive engagement) but does not mention any quantifiable writing performance metrics (e.g., writing scores, accuracy, complexity, organization). It focuses on engagement and strategies rather than measured changes in writing quality.""
    }
}"
311,Self-assessment Accuracy in the Age of Artificial Intelligence: Differential Effects of Llm-generated Feedback,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are N = 459 upper secondary students who wrote an argumentative essay in English as a foreign language, clearly indicating EFL learners and an English L2 writing context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a randomized control experiment where the experimental group receives GPT-3.5-turbo-generated feedback on their first draft during revision, which is an LLM-based intervention integrated into the writing process.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary outcome is self-assessment accuracy (SAA) regarding writing performance, not writing competence or writing-related performance variables themselves. The abstract reports effects of LLM feedback on SAA and its moderators, not on writing quality or other writing competence measures as focal outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantitative outcomes are reported for self-assessment accuracy (SAA) and its change, not for writing performance (e.g., text quality scores, linguistic measures). The intervention is evaluated in terms of SAA, so there is no quantifiable writing outcome metric assessing the effectiveness of the LLM-mediated intervention on writing competence.""
    }
}"
312,Evaluating L2 Learners’ Experience with Genai-powered Academic Reading Tool in Higher Education: a Small-scale Exploratory Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly refers to “L2 learners” and “L2 learners in higher education,” indicating that participants are second language learners. Although the target language is not named, the context of academic reading in higher education and typical usage suggests English, but this is not central since other criteria fail.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses Fullpicture, an academic reading tool powered by ChatGPT (an LLM), but only for academic reading support. There is no indication of an experimental or quasi-experimental design integrating the LLM into writing instruction or writing processes; the focus is on reading reports and reading experiences.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is academic reading and reading comprehension (literal, inferential, critical levels). While the tool may indirectly influence academic writing perspectives, the intervention is not designed as a writing-focused pedagogy or to develop writing competence; it is a reading intervention with incidental links to writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are learners’ reflections and Likert-scale ratings of perceived effectiveness for reading and argument evaluation. There are no reported quantitative writing outcome measures (e.g., writing quality scores, revisions, or writing performance metrics) assessing the effectiveness of an LLM-mediated writing intervention.""
    }
}"
313,Effects of Deepseek-assisted Writing Instruction on Efl Learners' Writing Performance,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL learners, and the study focuses on their English writing skills. This matches the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is a prospective quasi-experimental design where DeepSeek, an LLM, is employed to assist learners’ writing during a defined intervention period. This constitutes an LLM-mediated writing instruction intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on English writing competence, examining different dimensions of learners’ writing skills (micro-level: vocabulary, grammar, mechanics; macro-level performance) within EFL writing pedagogy. This aligns with writing-focused instructional context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Learners’ writing production from baseline, intervention, and follow-up periods was collected and rated, and the abstract reports significant enhancements in specific writing dimensions. These are quantifiable writing outcome measures assessing the effectiveness of the LLM intervention.""
    }
}"
314,Ai-driven Scaffolding and Affective Support in Esl Argumentative Writing: a Multimodal Analytics Approach,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly refers to ESL students and an ESL system for writing argumentative essays, indicating L2 English learners in an ESL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The system uses a Transformer architecture with an emotion recognition model and provides AI-based scaffolding and feedback. However, it is not clear whether this is a large language model used for generative writing support (e.g., ChatGPT-like text generation) or primarily a multimodal emotion-recognition/analytics system. The abstract does not specify LLM-based generative writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on ESL argumentative writing, writing quality, writing patterns, and performance, with AI-driven scaffolding and affective support as part of a dynamic intervention framework. This aligns with writing competence and writing-related variables in a pedagogical context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract notes that it was ‘experimentally determined’ that the system improved writing quality and performance, and that statistical modeling was used to examine correlations between multimodal characteristics and writing performance. This implies quantifiable writing outcome metrics were collected.""
    }
}"
315,Understanding Efl Learners’ Strategies in Aiassisted English Writing: an Activity Theory Perspective; Comprensión De Estrategias De Los Estudiantes De Efl En La Escritura Asistida Por Ia,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) learners, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to ‘artificial intelligence (AI)’ and ‘AI-assisted writing’ but does not specify that the tools are large language models (e.g., ChatGPT, GPT-4). It could include various AI tools, not necessarily LLM-based.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on understanding learners’ strategies and interactions with AI during writing tasks from an activity theory perspective. It does not describe an instructional intervention or experimental/quasi-experimental design aimed at improving writing competence; rather, it is exploratory/qualitative about strategy use and perceptions.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Data sources are screenshots, chat logs, and semi-structured interviews, and findings concern strategies, usefulness, concerns, and ethical issues, without experimental measures of writing performance.""
    }
}"
316,Bridging the Gap: a Systematic Deconstruction Strategy for Esl Student Success in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The population is explicitly ESL students: “tailored to help English as a Second Language (ESL) … students to navigate the challenges of academic writing,” with focus on English academic writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper proposes a “systematic deconstruction strategy” and discusses prompt engineering to help students use AI tools, but there is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT, GPT-4) into writing instruction. It appears conceptual/pedagogical rather than an LLM-based intervention study.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on “academic writing” and a strategy to help ESL students with writing prompts, addressing rhetorical and disciplinary requirements in writing tasks. Thus, the primary focus is writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any empirical data, experimental measures, or quantifiable writing outcomes. It describes a proposed strategy and an illustrative example using “The Gift of the Magi,” but no structured intervention outcomes or metrics are reported.""
    }
}"
317,Students’ Self-determination in Using Machine Translation and Generative Ai Tools for English for Academic Purposes,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EAP students in an English as a Second Language context in Australia and an English as a Foreign Language context in Vietnam, i.e., L2 English learners in ESL/EFL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates students’ use of machine translation and generative AI tools and their motivations, but the abstract does not describe an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT, GPT-4) as a structured writing intervention. It is primarily a survey/interview study of existing practices and perceptions.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is academic writing and MT/GAI-assisted writing, the focus is on self-determination, motivations, and perceptions, not on a pedagogical writing intervention designed and tested with LLMs. Mention of ‘innovations from an Australian EAP course’ is illustrative rather than an evaluated intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are motivational constructs (autonomy, competence, relatedness) and perceptions of MT/GAI use. There is no indication of quantifiable writing performance metrics (e.g., writing scores, text quality measures) used to assess the effectiveness of an LLM-mediated writing intervention.""
    }
}"
318,The Algorithmic Adjuvant: Synthesizing Human Pedagogy and Artificial Intelligence in the Modern Esl Classroom with Insights from Uzbekistan,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are in ESL classrooms in Uzbekistan, clearly indicating English as a Second Language learners in an ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions general AI technologies such as intelligent tutoring systems, automated writing aids, and speech recognition software, but does not specify the use of large language models (e.g., ChatGPT, GPT-4). The tools described could be non-LLM AI systems, and there is no indication of transformer-based generative models or an experimental/quasi-experimental LLM intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing is mentioned only indirectly via ‘automated writing aids’; the broader focus is on ESL instruction, learner engagement, fluency, and general language learning, not specifically on writing competence or writing-related variables as the primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is based on qualitative case studies and observational evidence, discussing opportunities and challenges and reporting outcomes like motivation, fluency, and autonomy in a descriptive way. No quantifiable writing outcome metrics or experimental measures of writing performance are reported.""
    }
}"
319,Probing into Efl Students’ Perceptions about the Impact of Utilizing Ai-powered Tools on Their Academic Writing Practices,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL students enrolled in an “Academic Writing 2” course at a private university in Oman, so they are L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is one of several AI-powered tools used, the study is not described as an experimental or quasi-experimental design assessing an LLM-based intervention. It is a qualitative perception study using multiple tools (Grammarly, Wordtune, Quillbot, ChatGPT) without a structured experimental manipulation focused on LLM integration.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is an academic writing course, and the focus is on academic writing practices and stages of the writing process, i.e., writing competence and related variables, not automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract states that the study uses a qualitative approach (learning journals, observations, focus-group interviews) to explore perceptions. It does not report quantifiable writing outcome metrics or experimental measures of effectiveness; improvements are described qualitatively (e.g., ‘acknowledged’ improvement) rather than via measurable writing scores.""
    }
}"
320,When Ai Meets Source Use: Exploring Chatgpt's Potential in L2 Summary Writing Assessment,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study concerns L2 summary writing and L2 integrated writing assessment, implying participants are L2 English learners producing L2 English summaries.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used as an automated rater (GPT_original, GPT_calibrated) to score L2 summary writing, compared with human raters. There is no indication of an instructional or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on ChatGPT’s performance as a scoring tool (rating reliability, strictness, alignment with human raters) in integrated writing assessment, not on improving learners’ writing competence through an instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing scores are analyzed, they are used solely to evaluate ChatGPT as an assessment tool, not as outcomes of an LLM-mediated writing intervention. No experimental teaching or feedback treatment is applied to learners’ writing.""
    }
}"
321,Investigating a Customized Generative Ai Chatbot for Automated Essay Scoring in a Disciplinary Writing Task,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are engineering students in a disciplinary English course at a university in Hong Kong, which implies L2 English learners in an EFL/ESL academic context. The writing is in English and assessed by English teachers.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a customized GenAI chatbot for automated essay scoring (AES) and examines correlations between chatbot scores and teacher scores. There is no experimental or quasi-experimental instructional intervention integrating the LLM into writing instruction or writing processes; it is an assessment/validation study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the functionality and validity of GenAI for automated essay scoring (correlations between chatbot and teacher scores), not on improving writing competence or implementing a pedagogical writing intervention. This fits the excluded category of studies evaluating LLMs as AES systems.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although quantitative writing scores are reported, they are used solely to evaluate the chatbot’s scoring performance, not as outcomes of an LLM-mediated writing intervention. There is no pre/post or comparative design assessing changes in learners’ writing due to LLM use.""
    }
}"
322,Attitudes of Pakistani Undergraduate Esl Students Toward Artificial Intelligence in Improving English Writing Skills,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Pakistani undergraduate ESL students, clearly identified as English as a Second Language learners, and the focus is on English writing skills.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines attitudes toward AI in general and AI adoption, not a specific LLM-based tool (e.g., ChatGPT, GPT-4) within an experimental or quasi-experimental instructional design. No particular LLM intervention is described.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly English writing skills and how AI might improve them, so the primary focus is on writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports attitudes, perceived usefulness, ease of use, motivation, and engagement, but does not report quantifiable writing outcome measures or evaluate the effectiveness of an AI/LLM-mediated writing intervention.""
    }
}"
323,Exploring the Efficacy of Chatgpt-4 Feedback in Second Language Spanish Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are described as advanced Spanish learners in an L2 Spanish writing context. The focus is on Spanish as the target language, not English (ESL/EFL/ELL). Therefore, the population does not meet the review’s requirement of L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study integrates ChatGPT-4, a large language model, into a writing intervention: students receive AI-generated, rubric-aligned feedback on their drafts and then revise. This constitutes an LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing development in L2 Spanish, with AI-generated feedback on argumentation, linguistic concepts, research and analysis, grammar and language, and structure and formality. This is clearly a writing-focused pedagogical context.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract labels the study as qualitative and emphasizes thematic analysis of questionnaires, revisions, and reflections. While participants completed pre- and post-treatment questionnaires and a formal writing task, the abstract does not clearly state that quantifiable writing outcome metrics (e.g., scores, rubric ratings) were analyzed to assess effectiveness, so it is unclear whether C4 is met.""
    }
}"
324,Efl Learners’ Perceptual Perezhivaniya and Actual Writing Revision Behaviors Mediated by Genai: a Sociocultural Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are nineteen EFL learners at a university in Southern China, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that learners revised L2 continuation writing tasks \""using GenAI\"" but does not specify that the GenAI tool is an LLM (e.g., ChatGPT/GPT-based) rather than another form of generative AI. The specific technology and model type are not identified.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on L2 writing revision processes (word choice, content, discourse, syntax, errors, alignment, typographic elements) mediated by GenAI, clearly centering on writing competence and writing-related behaviors rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses interviews, Q-methodology, and Translog screen recordings to explore revision processes and the alignment between perceived experiences and actual revision behaviors. The abstract does not report any quantifiable writing outcome metrics (e.g., writing quality scores, accuracy gains) assessing the effectiveness of the GenAI-mediated intervention; it focuses on process and perceptions, not outcome measures.""
    }
}"
325,Automated Scoring in the Era of Artificial Intelligence: an Empirical Study with Turkish Essays,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are learners of Turkish as a second language; the target language is Turkish, not English. The review focuses on L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""GPT-4o is used as an automated scoring engine via a custom interface. There is no indication of an instructional or quasi-experimental pedagogical intervention integrating the LLM into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automated essay scoring reliability and validity (alignment between human and AI scores), not on improving writing competence or writing-related learning outcomes through an intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports scoring agreement metrics (Quadratic Weighted Kappa, Pearson correlation, overlap) but does not report quantifiable writing outcome measures resulting from an LLM-mediated writing intervention.""
    }
}"
326,Can Chatgpt Serve as a Writing Collaborator? Insights from Chinese Efl Learners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese EFL learners at a tier-one university in China with over ten years of English learning experience and upper-intermediate English proficiency. The context is clearly L2 English learning (EFL).""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly investigates how Chinese EFL learners interact with ChatGPT, a large language model, in an argumentative writing task. ChatGPT is integrated into the writing process as a collaborator, satisfying the LLM-based intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on L2 argumentative writing: how student–chatbot collaboration affects the writing process and the quality of the final writing products, as well as perceptions of ChatGPT as a writing collaborator. This is clearly about writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions examining the influence of collaboration on the ‘quality of writing’ and analyzing final writing texts, it specifies that data were ‘qualitatively analysed’ and emphasizes interaction modes and perceptions. There is no indication of experimental or quasi-experimental design, control/comparison conditions, or reported quantitative writing outcome metrics. The study appears to be qualitative and exploratory rather than an intervention study with measurable writing gains.""
    }
}"
327,Large Language Models Fall Short in Classifying Learners’ Open-ended Responses,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 143 Japanese university students studying English as a foreign language (EFL), which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""LLMs are used to classify learners’ open-ended responses about their essay-writing process, not as part of an instructional or experimental writing intervention. There is no integration of LLMs into writing instruction or learners’ writing processes as a pedagogical tool.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the methodological accuracy of LLMs in qualitative data classification (self-regulated learning categories), not on improving writing competence or writing-related performance through an intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports Cohen’s kappa for agreement between LLMs and human coders, but does not report any quantifiable writing outcome metrics (e.g., writing quality scores, complexity, accuracy) resulting from an LLM-mediated writing intervention.""
    }
}"
328,"Enhancing Efl Writing with Visualised Genai Feedback: a Cognitive Affective Theory of Learning Perspective on Revision Quality, Emotional Response, and Human-computer Interaction",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL learners, indicating second language English learners in an EFL context. The focus is on their English writing and revision performance.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a self-developed GenAI-powered writing chatbot based on large language models to provide feedback during revision. A 2×2 quasi-experimental design compares visualised vs. non-visualised GenAI feedback, integrating LLMs into writing instruction/processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL writing performance, specifically revision quality (coherence and cohesion) and related variables (emotional response, cognitive load) within GenAI-assisted writing instruction.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes via pre- and post-tests, showing that visualised feedback significantly improved coherence and cohesion in learners’ writing, alongside measured emotional and cognitive load outcomes.""
    }
}"
329,Examining Longitudinal Development of Writing Motivation in the Genai Context: a Self-determination Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as '261 Chinese EFL student writers,' clearly indicating L2 English learners in an EFL context with a focus on English writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to 'GenAI-supported writing contexts' and 'GenAI scaffolds psychological needs,' but does not specify that the GenAI is a large language model (e.g., ChatGPT, GPT-4) or detail the nature of the tool. It is unclear whether the intervention is explicitly LLM-based.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on 'development of motivation' and four SDT constructs (autonomy, competence, relatedness, identified regulation) in GenAI-supported writing contexts. There is no indication that writing competence or writing performance is a main outcome; the emphasis is motivational, not on writing ability.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports 'motivational gains over time' and curvilinear trajectories of motivation, but does not mention any quantifiable writing outcome metrics (e.g., writing scores, text quality measures). Outcomes are psychological (motivation), not writing performance.""
    }
}"
330,"Mastering Efl Writing with Chatgpt: a Systematic Review of Benefits, Challenges, and Best Practices",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on EFL students and their English writing skills, which fits the target population of L2 English learners in EFL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is described as a systematic review drawing on 21 studies about ChatGPT in EFL writing, not as an experimental or quasi-experimental primary study implementing an LLM-based intervention itself. Review articles are to be excluded.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The review’s primary focus is on EFL writing instruction and writing-related outcomes (accuracy, vocabulary, fluency, coherence) when using ChatGPT, aligning with the writing competence context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the review summarizes effects on writing outcomes, it does not itself report original experimental or quasi-experimental outcome data; as a secondary synthesis, it falls under review articles, which are excluded by the protocol.""
    }
}"
331,Exploring High School Students’ Preferences for English Writing Feedback: Non-native English Teacher Vs. Native English Teacher Vs. Chatgpt,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are high school students in Korea in an English newspaper club, clearly an EFL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used to provide feedback, the design focuses on comparing feedback preferences (non-native teacher vs native teacher vs ChatGPT) rather than an instructional or quasi-experimental intervention aimed at improving writing performance. It is essentially a preference/comparison study, not a structured LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on students’ preferences and perceptions of different feedback sources, not on developing or evaluating a pedagogical writing intervention. Writing competence or related skills are not the central outcome; instead, attitudes toward feedback providers are.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The quantitative data consist of Likert-scale ratings of feedback sources and statistical comparisons of these ratings. There is no report of quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity) following LLM-mediated intervention.""
    }
}"
332,An Ai-assisted Critical Thinking Intervention to Enhance Undergraduate Efl Learners’ Writing Proficiency,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 250 undergraduate EFL learners from three public universities. The context is explicitly EFL, and the abstract focuses on English as the target language in writing proficiency and CT-oriented writing practices.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an AI-assisted critical thinking-oriented writing intervention supported with ChatGPT. ChatGPT is a large language model, and the design is experimental (pretest-posttest single-group), integrating the LLM into writing instruction/practice.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing proficiency and CT as reflected in writing. ChatGPT is used as a scaffolding tool for CT-oriented writing training in EFL contexts, clearly centering on writing pedagogy rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study employs pre-post writing tests evaluated across nine dimensions (clarity, accuracy, precision, relevance, depth, breadth, logic, significance, fairness) and reports that the intervention significantly enhanced students’ CT reflected in writing, providing quantifiable writing outcome metrics.""
    }
}"
333,"Generative Ai Is Useful for Second Language Writing, but When, Why, and for How Long Do Learners Use It?",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states that the participants are L2 learners of English, indicating an L2 English learner population in a second language writing context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study investigates how L2 learners utilize ChatGPT, a large language model, during a writing task, indicating integration of an LLM into the writing process. However, it is observational rather than experimental in design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on L2 writing processes and how ChatGPT is used for idea generation, grammar/word search, polishing, and example generation, which are all writing-related activities.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports frequency and time-series analyses of ChatGPT use and semantic network analyses of perceptions, but it does not mention any quantifiable writing outcome metrics (e.g., writing quality scores, accuracy, complexity) or an intervention effect. The study is descriptive/observational rather than assessing effectiveness of an LLM-mediated writing intervention.""
    }
}"
334,From Feedback to Artificial Intelligence: a Bibliometric Mapping Analysis of the Thematic Evolution of Efl Writing Assessment Research Trends (2014–2024),2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a bibliometric mapping analysis of published research on EFL writing assessment, not an empirical study with a defined participant population of L2 English learners. It aggregates literature from Scopus rather than reporting on specific learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a review/bibliometric study and does not implement any experimental or quasi-experimental intervention using LLMs in writing instruction. AI and automated writing evaluation are mentioned only as emerging themes in the literature, not as an intervention in the study itself.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on mapping research trends in EFL writing assessment, not on conducting a pedagogical intervention targeting writing competence. It is a meta-level analysis of topics such as feedback and assessment, not a study of an instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study analyzes publication patterns, themes, and networks, rather than measuring changes in learners’ writing performance following an LLM-mediated intervention.""
    }
}"
335,"Integrating Ai in Pakistani Esl Classrooms: Teachers’ Practices, Perspectives, and Impact on Student Performance",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 100 undergraduate students in Pakistani ESL classrooms, clearly English L2 learners in an ESL context. The study focuses on English vocabulary and writing skills.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses AI tools such as Grammarly and QuillBot. These are not described as large language model–based tools (e.g., ChatGPT, GPT-4, Gemini) and are typically categorized as non-LLM writing assistants in this review’s criteria, so the study does not meet the requirement of integrating LLMs into instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is ESL instruction with a focus on vocabulary and writing skills. Writing performance is a primary outcome, aligning with writing competence as a central focus rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: pre- and post-tests on writing skills, with a reported +46% gain and effect size (d=1.03) for the experimental group, satisfying the requirement for measurable writing outcomes.""
    }
}"
336,Investigating the Role of Ai Tool Interactions in Enhancing English Language Acquisition among Saudi College Students,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Saudi college students learning English as a second language in an EFL context, and the focus is explicitly on English language acquisition.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is mentioned, the study is a qualitative investigation using semi-structured interviews about how students use AI tools. There is no experimental or quasi-experimental design integrating ChatGPT into instruction; it is an exploratory, interview-based study of existing practices and perceptions.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Students reportedly use ChatGPT primarily for writing assistance, brainstorming, and translation, but the study’s primary focus is on general language acquisition, AI literacy, attitudes, and institutional support, not on a structured writing intervention or writing competence as the main outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study employs a qualitative design with thematic analysis of interviews and does not report any quantifiable writing outcome metrics or measured changes in writing performance following an LLM-mediated intervention.""
    }
}"
337,A Comparative Study of Human and Ai-assisted Assessment Using Chatgpt: the Case of Moroccan Efl Learners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses writing assignments from EFL classes in Moroccan higher education, indicating participants are L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT-4 is used solely as an AI-assisted grader to compare AI and human assessment. There is no experimental or quasi-experimental instructional intervention integrating the LLM into writing instruction or the writing process.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on summative e-assessment and the comparability of AI vs. human grading. It evaluates ChatGPT-4 as an automated essay scoring system, not as part of a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports grading score differences between AI and human raters, but not as outcomes of an LLM-mediated writing intervention. No writing development or change in writing performance due to LLM use is measured.""
    }
}"
338,Preserving Authorial Voice in Academic Texts in the Age of Generative Ai: a Thematic Literature Review,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract notes that the review is particularly relevant in ESL university settings and that most synthesized studies were conducted there, implying a focus on L2 English learners. However, as a literature review, it aggregates various studies and does not itself report primary data on a specific L2 learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is explicitly described as a thematic literature review synthesizing 18 scholarly papers. It does not report an experimental or quasi-experimental intervention integrating LLMs into writing instruction; instead, it summarizes existing work and pedagogical implications.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the topic concerns academic writing, authorial voice, and AI writing tools, the article is a review, not a primary study implementing a writing-focused LLM intervention in an instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any original quantitative writing outcome measures. It synthesizes empirical findings from other studies and discusses stylistic differences and pedagogical implications, which falls outside the requirement for primary, quantifiable writing outcomes from an LLM-mediated intervention.""
    }
}"
339,"A Q Method Study on Turkish Efl Learners’ Perspectives on the Use of Ai Tools for Writing: Benefits, Concerns, and Ethics",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Turkish English language learners enrolled in an EFL preparatory program at a state university in Istanbul, clearly fitting an L2 English EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a Q methodological investigation of learners’ perspectives on AI tools. It does not describe an experimental or quasi-experimental pedagogical intervention integrating a specific LLM (e.g., ChatGPT) into instruction; rather, it surveys existing usage and attitudes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on perceptions of benefits, concerns, and ethics regarding AI tools in writing, not on a structured writing intervention or instructional design aimed at improving writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study uses Q methodology and qualitative interviews to explore perspectives, without measuring changes in writing performance or related quantitative outcomes.""
    }
}"
340,From Struggle to Mastery: Ai-powered Writing Skills in Esl Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 10th grade ESL learners in a bilingual secondary school in Colombia, explicitly described as ESL students working on academic writing in English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study integrates AI-powered tools, specifically Grammarly and ChatGPT, within the Writing Workshop Instructional Model. ChatGPT is an LLM, but Grammarly is not. The abstract does not specify whether the experimental evaluation isolates or quantifies the effect of the LLM component (ChatGPT) as opposed to the combined AI package, nor does it clearly describe an experimental or quasi-experimental design (it is framed as design-based research). It is unclear whether there is a structured LLM-mediated intervention with measurable, attributable effects.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on improving academic writing skills, including grammar accuracy, textual coherence, and organizational structure, within a writing instructional model. The context is clearly writing instruction rather than automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract states that combining WWIM with AI feedback 'significantly improved students’ academic writing performance' and mentions improved grammar accuracy, coherence, and organization, it does not report or clearly indicate the use of quantifiable writing outcome metrics (e.g., test scores, rubric-based ratings, statistical results). The description is general and could reflect qualitative or mixed findings without explicit experimental measures. Based on the abstract alone, the presence of structured, quantifiable outcome metrics is not sufficiently clear.""
    }
}"
341,The Impact of Automated Writing Evaluation on Writing Gains,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 105 first-year university students in Belgium described as English as a foreign language (EFL) students, indicating L2 English learners in an EFL context with focus on English writing skills.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines the effectiveness of ChatGPT, explicitly a large language model, in improving English writing skills. It uses an experimental design comparing a teacher-feedback-only group with a group using ChatGPT alongside teacher feedback over a nine-week intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence, specifically syntactic and lexical complexity as key dimensions of writing development, and overall English writing skills. ChatGPT is integrated as part of writing instruction, not merely as an assessment tool.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes, including text length and measures of syntactic and lexical complexity, and compares gains between groups to assess ChatGPT’s impact on writing development over nine weeks.""
    }
}"
342,Exploring the Impact of Ai Technologies on Efl Writing Proficiency,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The participants are Saudi EFL teachers at King Saud University, not L2 English learners. The study focuses on teachers’ perspectives rather than learner data or learner outcomes.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is mentioned, the study uses a descriptive survey design to explore teachers’ perceptions. There is no experimental or quasi-experimental intervention integrating ChatGPT into learners’ writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on teachers’ views of using ChatGPT in writing classes, not on implementing and evaluating a pedagogical writing intervention. It is a perception study rather than an instructional context with measured impact on writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports perceived merits and challenges but does not provide quantifiable writing outcome metrics for learners. No experimental measures of writing performance or related variables are described.""
    }
}"
343,Cognitive Offload Instruction with Generative Ai: a Quasi-experimental Study on Critical Thinking Gains in English Writing,2025,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions “first-year university students” and refers to “English essay writing” and “second-language writing contexts,” but it does not explicitly state that the participants are L2 English learners (ESL/EFL/ELL). They could be native or mixed-proficiency students. Thus, it is unclear whether the population is specifically L2 English learners.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses “generative AI-enabled cognitive offload instruction” and “generative AI tools” for brainstorming and co-revision. However, the abstract does not specify that these tools are LLM-based (e.g., ChatGPT, GPT-4) as opposed to other generative or assistive AI. Without explicit indication that transformer-based LLMs are used, this criterion remains unclear.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is English essay writing, with structured writing cycles including AI brainstorming, critique, and co-revision. Outcomes include essay quality (logical coherence, evidence use, originality) and critical thinking in writing. The focus is clearly on writing competence and writing-related variables within an instructional intervention, not on automated scoring or purely technical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes: standardized critical thinking assessment scores and measures of essay quality (logical coherence, evidence use, originality), with significant improvements for the AI group and mediation analysis. These constitute measurable writing-related outcomes within an experimental/quasi-experimental design.""
    }
}"
344,Revising with Intelligence: Chatgpt Feedback and Its Impact on Efl Students’ Revision and Self-efficacy,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 82 university-level EFL students, i.e., learners of English as a foreign language. The focus is clearly on English writing development in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT-supported feedback as the core intervention in a quasi-experimental design, comparing a ChatGPT-supported writing group with a teacher-supported writing group over ten weeks. ChatGPT is a large language model integrated into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing development and revision in process-based writing instruction. Outcomes include revision productivity, macro-level and content-based revisions, and writing self-efficacy related to substantive revision, discourse organization, and writing conventions.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative outcomes: significant increases in revision productivity, more macro-level and content-based revisions, and higher self-efficacy gains across three measured dimensions. These are structured, quantifiable writing-related outcome measures.""
    }
}"
345,Traditional Strategies and Ai-integrated Strategies in Learning English among Efl Omani Students,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL Omani students at a public Omani university, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a survey using SILL plus AI-related questionnaire items to measure use of AI-integrated learning strategies. It does not describe an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into instruction; AI tools are referenced generically as strategies, not as a controlled LLM-based pedagogical treatment.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on general English learning strategies (listening, speaking, pronunciation, grammar, writing) and gender/academic level differences in their use. It is not a writing-focused instructional intervention; writing is only one of several skills and is not the primary context of a pedagogical treatment.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are self-reported strategy-use frequencies on Likert scales, not objective or quantifiable writing performance measures. The study does not assess changes in writing competence or related performance metrics following an LLM-mediated intervention.""
    }
}"
346,Design Opportunities for Explainable Ai Paraphrasing Tools: a User Study with Non-native English Speakers,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as non-native English speakers (NNESs), but the abstract does not specify whether they are in ESL/EFL/ELL instructional contexts or simply general NNES users. The focus is on interaction with an AI paraphrasing assistant rather than a defined L2 learning context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses ParaScope, an AI paraphrasing assistant, but the abstract does not state that it is based on a large language model (e.g., ChatGPT/GPT-4 or similar transformer-based generative model). It could be any AI paraphrasing system, so LLM use cannot be confirmed from the abstract alone.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on user interaction with explainable AI paraphrasing tools, information aids, and design implications. Outcomes emphasized are confidence, autonomy, and writing efficiency, not writing competence or instructional intervention in writing. It is more a usability/design study than a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity). It mentions confidence, autonomy, and efficiency, but without indication of experimental measures of writing performance or structured intervention outcomes.""
    }
}"
347,The Role of Ai in Improving Writing Skills of Indian Undergraduate Efl Learners: a Research Review,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The population is clearly Indian undergraduate EFL learners (“Indian undergraduates studying English as a foreign language”), which fits the L2 English learner criterion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a “research review” examining the potential of AI writing tools. It does not describe an experimental or quasi-experimental intervention using a specific LLM (e.g., ChatGPT, GPT-4); instead, it conceptually reviews potential benefits and challenges.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on improving EFL learners’ writing skills, including feedback, vocabulary expansion, and writing structure, which are writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a review article, it does not report original quantitative writing outcome metrics or results from a structured intervention; it only discusses potential benefits and calls for further investigation.""
    }
}"
348,Coachgpt: a Scaffolding-based Academic Writing Assistant,2025,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions supporting academic writing, including when writing in a second language, but does not specify that study participants are L2 English learners in ESL/EFL/ELL contexts, nor that the focus is specifically on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study develops CoachGPT, an AI agent-based web application that uses large language models to provide real-time feedback and suggestions for academic writing. This is an LLM-based writing assistant integrated into the writing process, and the paper reports user studies, suggesting an intervention-like use.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on academic writing assistance, with CoachGPT providing scaffolding, feedback, and suggestions during writing. The context is clearly writing competence and writing-related support, not automated essay scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that “user studies prove the usefulness of CoachGPT,” but does not specify whether these studies include quantifiable writing outcome metrics (e.g., writing quality scores, accuracy, complexity) versus only usability, perceptions, or engagement measures.""
    }
}"
349,Chatgpt for English Writing: a Qualitative Inquiry among English Major Students at Thai Higher Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are seven fourth-year English majors in Thailand, explicitly described as Thai English as a Foreign Language (EFL) students, so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a qualitative inquiry into attitudes and perceptions about ChatGPT. There is no indication of an experimental or quasi-experimental design, nor a structured instructional intervention integrating ChatGPT into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on ChatGPT’s roles in English writing, including vocabulary, grammar, and content organization, which are writing-related variables in an L2 context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses semi-structured interviews and thematic analysis to explore perceptions and attitudes. It does not report quantifiable writing outcome metrics or measure changes in writing performance; outcomes are purely qualitative.""
    }
}"
350,The Collaboration of Ai and Teacher in Feedback Provision and Its Impact on Efl Learner’s Argumentative Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 28 tenth-grade EFL learners focusing on English argumentative writing, which fits ESL/EFL/ELL L2 English learner contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses DeepL Write as the AI tool. DeepL Write is primarily a machine translation/AI writing assistance system and is not clearly identified as an LLM-based (transformer generative) model like ChatGPT, GPT-4, Gemini, etc. The abstract does not specify use of a large language model; thus it does not meet the explicit LLM requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly targets English argumentative writing and examines the impact of AI and teacher feedback on writing quality (lexical, grammatical, content, coherence, cohesion), which are core writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing outcomes are quantitatively analyzed using Coh-Metrix across three drafts to assess changes in writing quality, providing measurable writing outcome metrics.""
    }
}"
351,Assigning Cefr-j Levels to English Learners’ Writing: an Approach Using Lexical Metrics and Generative Ai,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The system is designed for assessing English learners’ writing proficiency in an EFL context (CEFR-J, particularly in Japan), so the population is L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study presents CWLA as an automated assessment system using lexical metrics and AI-based analytical scores. It focuses on developing and validating an automated scoring tool, not on an experimental or quasi-experimental pedagogical intervention integrating an LLM into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automated writing proficiency assessment (alignment with CEFR-J, correlation with human ratings, entropy analysis), i.e., functionality as an automated essay scoring system. There is no described instructional or intervention context targeting writing competence development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are tool validation metrics (correlation with human ratings, entropy analysis, expert agreement). There is no experimental or quasi-experimental writing intervention and no quantifiable pre/post or comparative writing outcome measures for learners.""
    }
}"
352,Modeling Chinese Efl Learners’ Intention to Use Generative Ai for L2 Writing through an Integrated Model of the Tam and Ttf,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese EFL learners (304 university students in China) using generative AI for L2 English writing, which fits the ESL/EFL/ELL English-focused population criterion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a survey and structural equation modeling (TAM + TTF) to examine intention to use generative AI. There is no experimental or quasi-experimental pedagogical intervention integrating an LLM into actual writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is technology acceptance and behavioral intention, not an implemented writing intervention or measured impact on writing competence. It is about attitudes toward using generative AI as an assistant, not a writing-focused instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes are psychological constructs (perceived usefulness, ease of use, attitude, behavioral intention), not measures of writing performance or related skills.""
    }
}"
353,"A Mixed-methods Study on the Use of Chatgpt in the Pre-writing Stage: Efl Learners’ Utilization Patterns, Affective Engagement, and Writing Performance",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a Foreign Language (EFL) learners: 56 first-year university students performing argumentative writing tasks in an EFL context, with outcomes focused on English writing performance.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses ChatGPT, a large language model, as support in the pre-writing stage. The design is quasi-experimental: each learner completes two argumentative writing tasks, one with and one without ChatGPT support, enabling comparison of conditions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence and related variables: pre-writing strategy use, affective engagement during planning, and subsequent text quality in argumentative writing. ChatGPT is integrated pedagogically into the writing process rather than used solely for scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: it compares text quality between ChatGPT and non-ChatGPT conditions and examines correlations between affective engagement and overall writing performance, indicating measurable writing performance metrics.""
    }
}"
354,Predicting Kazakhstani Tefl Students’ Continuance Intention towards Using Chatgpt in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are TEFL (Teaching English as a Foreign Language) students at two Kazakhstani universities, i.e., L2 English learners in an EFL context, and the focus is on academic writing in English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is the focal tool, the study is not an experimental or quasi-experimental intervention in writing instruction. It examines perceptions and continuance intention via a survey model, not a structured pedagogical writing intervention using ChatGPT.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on technology acceptance variables (perceived usefulness, ease of use, satisfaction, continuance intention) rather than on developing or assessing writing competence through an instructional intervention. Writing is the context, but not the main outcome of an educational treatment.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, text quality measures) are reported. Outcomes are psychological/behavioral (perceptions and intention to continue using ChatGPT) and qualitative comments, not measured changes in writing performance.""
    }
}"
355,Exploring the Potential of Genai for Personalised English Teaching: Learners' Experiences and Perceptions,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are first-year English for Academic Purposes students, i.e., L2 learners in an EAP/ESL-type context, and the focus is on English language competencies.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines learners’ use of GenAI tools such as Grammarly and Quillbot. These are not clearly specified as LLM-based tools in an experimental or quasi-experimental instructional design; rather, they are general-purpose support tools whose underlying models may not be transformer-based generative LLMs as required. The focus is on existing tool use, not a structured LLM-mediated intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on learners’ experiences and perceptions of GenAI tools across multiple skills (grammar, writing, vocabulary, reading), not on a defined writing instruction intervention or writing process design. It is more a perception/usage study than a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study uses surveys and interviews, the abstract reports usage rates and perceived helpfulness, not quantifiable writing outcome metrics (e.g., changes in writing scores, text quality measures) resulting from a structured intervention. Outcomes are attitudinal and self-reported rather than experimental writing performance measures.""
    }
}"
356,The Impact of Integrating Chatgpt with Teachers’ Feedback on Efl Writing Skills,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 68 intermediate Iranian EFL learners, clearly indicating L2 English learners in an EFL context, with outcomes focused on English IELTS Task 2 argumentative essays.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention explicitly integrates ChatGPT, a large language model chatbot, with teacher feedback to provide individualized writing feedback. Learners were randomly assigned to ChatGPT+teacher feedback vs teacher-only feedback, indicating an experimental design using an LLM in instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL writing skills and improvement in IELTS Task 2 argumentative essays. ChatGPT is used pedagogically to support writing feedback, not merely for automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative writing outcomes are reported: Paired Samples t-Test results show significantly greater improvement in the experimental group across specific writing criteria (task achievement, coherence, cohesion, vocabulary, grammar range and accuracy). These are clear, quantifiable writing outcome metrics.""
    }
}"
357,Mobile Ai Tools in Language Learning: Efl Students’ Acceptance of Chatgpt for Writing Brainstorming,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 257 EFL students at a private Vietnamese university, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used for writing brainstorming, the study is described as inspecting students’ acceptance using questionnaires and interviews. There is no indication of an experimental or quasi-experimental instructional intervention design; it is primarily an acceptance/perception study.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is writing, specifically brainstorming in a writing class and perceived support for enhancing writing quality and skills, which aligns with writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The methods mention a Likert-scale questionnaire and semi-structured interviews focusing on acceptance, perceptions, advantages, and disadvantages. The abstract does not report any quantifiable writing outcome metrics (e.g., writing scores, text quality measures) resulting from the ChatGPT use.""
    }
}"
358,The Development and Validation of a Scale on Student Ai Literacy in L2 Writing: a Domain-specific Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 435 and 350 Chinese university students engaged in L2 writing, implying they are L2 English learners in an EFL context. The scale is explicitly for L2 writing, and in Chinese university contexts this typically refers to English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study develops and validates a self-report scale (L2W-SAILS) to measure student AI literacy in L2 writing. There is no experimental or quasi-experimental integration of a specific LLM (e.g., ChatGPT, GPT-4) into writing instruction or writing processes; AI tools are discussed conceptually, not implemented as an intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on constructing and validating a measurement instrument for AI literacy, not on an instructional or intervention context targeting writing competence. While situated in L2 writing, it does not describe an AI-mediated writing pedagogy or intervention being tested.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are psychometric properties of the AI literacy scale (factor structure, reliability). The study does not report quantifiable writing performance or writing-related outcome measures resulting from an LLM-mediated intervention; it only measures self-reported AI literacy.""
    }
}"
359,Students' Perceptions and Usage Patterns of Chatgpt as an Automated Writing Evaluation (awe) Tool,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL graduate students at a university in Hong Kong, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used as an Automated Writing Evaluation tool, the study is not described as experimental or quasi-experimental. It focuses on existing usage and perceptions via a questionnaire, not on a structured LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is academic writing, with ChatGPT used for revision, grammar, and vocabulary enhancement, which are writing-related variables rather than pure scoring or grading.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports questionnaire-based perceptions (trustworthiness, usefulness, ease of use) and usage patterns, but does not mention any quantifiable writing outcome measures (e.g., writing scores, quality ratings, error counts) to assess effectiveness of the intervention.""
    }
}"
360,A Pilot Study on Bridging Efl Writing and Speaking Skills through Ai-enhanced Authentic Short Video-making,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 20 first-year university students in an EFL context (public university in central Taiwan), so they are L2 English learners and the focus is on English proficiency.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “Artificial Intelligence-enhanced authentic short video-making (AI-eSV)” but does not specify the type of AI or name any LLM tools (e.g., ChatGPT, GPT-4). It is unclear whether the AI component is an LLM-based generative model or another form of AI (e.g., video editing, recommendation, or non-LLM support).""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention explicitly targets writing and speaking skills through collaborative scriptwriting and video recording. Writing competence (creativity, content organization) is a primary focus, not just assessment or non-pedagogical use.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study uses a pretest–posttest design and reports “significant improvements in writing and speaking skills,” the abstract does not indicate that the AI (possibly LLM) component itself is the focus of the experimental contrast. More importantly, the AI type is unspecified, and there is no clear evidence that an LLM-mediated writing intervention is being evaluated with quantifiable writing outcomes attributable to LLM use, as required by the review.""
    }
}"
361,Exploring Efl Learners’ Academic Emotions and Emotion Regulation Strategies in Ai-assisted Collaborative Academic Writing Tasks,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as EFL learners, indicating second language English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions an “AI-assisted collaborative academic writing project” and “AI feedback limitations,” but does not specify that the AI is a large language model (e.g., ChatGPT, GPT-4) or transformer-based generative system. It could be another type of AI feedback tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly academic writing (“collaborative academic writing project” and “AI-assisted collaborative academic writing tasks”), aligning with writing-focused intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on academic emotions and emotion regulation strategies, using questionnaires and interviews. There is no indication of quantifiable writing outcome metrics (e.g., writing scores, quality measures) to assess the effectiveness of the AI-assisted writing intervention.""
    }
}"
362,The Benefits and Risks of Ai-assisted Academic Writing: Insights from Current Research; Prednosti in Tveganja Pri Znanstvenem Pisanju S Pomočjo Umetne Inteligence: Spoznanja Iz Aktualnih Raziskav,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “English language students” and “acquisition of English as a foreign language,” which suggests an EFL context, but it does not clearly specify the participant population or any concrete sample in an empirical study.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper is described as “a review of existing literature and a discussion of the findings of recent studies” about ChatGPT in language education. It does not report an original experimental or quasi-experimental intervention integrating an LLM; instead, it synthesizes prior work.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on AI-assisted academic writing and the potential of ChatGPT to improve writing abilities, but as a literature-based discussion rather than a specific pedagogical intervention with measured outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any original quantitative writing outcome metrics or experimental results; it summarizes ‘insights from multiple studies’ and discusses benefits and risks conceptually, consistent with a narrative review.""
    }
}"
363,Enhancing Writing Accuracy and Empowering Students: the Transformative Influence of Chatgpt’s Informative Feedback on Students’ Writing,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 50 undergraduate students enrolled in English language courses, indicating L2 English learners in an ESL/EFL/ELL context. The focus is clearly on English language learning and writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study evaluates instructional assistance formative feedback provided by ChatGPT, a large language model, as part of writing instruction. This constitutes an LLM-based intervention integrated into learners’ writing processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on enhancing learners’ writing skills and writing quality (coherence, grammar, engagement with the writing process) through ChatGPT feedback. This is a pedagogical writing intervention, not an automated scoring or purely functional evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative data were collected from students’ essays, and results report significant improvements in writing quality (coherence, grammar, engagement). This implies measurable writing outcome metrics were used to assess the effectiveness of the ChatGPT-mediated intervention.""
    }
}"
364,Exploring Potential Biases in Gpt-4o’s Ratings of English Language Learners’ Essays,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses the ELLIPSE corpus (English Language Learner Insight, Proficiency and Skills Evaluation), which consists of essays written by English language learners, indicating an L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""GPT-4o is used as an automated essay scoring (AES) tool to rate existing essays. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on GPT-4o’s fairness and bias as an AES system (gender, race/ethnicity, SES), not on improving learners’ writing competence or implementing a writing intervention. This aligns with excluded AES-functionality studies.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports GPT-4o rating patterns and bias analyses, not quantifiable outcomes of an LLM-mediated writing intervention. No instructional treatment or pre/post writing performance measures are described.""
    }
}"
365,"The Impact of Self-revision, Machine Translation, and Chatgpt on L2 Writing: Raters’ Assessments, Linguistic Complexity, and Error Correction",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are learners in a South Korean high school English as a Foreign Language (EFL) context, clearly indicating L2 English learners in an EFL setting. The focus is on English writing outcomes.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a controlled experiment with three proofreading interventions: self-proofreading, neural machine translation, and ChatGPT-assisted proofreading. ChatGPT, an LLM, is explicitly integrated into the writing process as a structured proofreading tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 writing competence and related variables: overall writing quality, text length, lexical diversity, sentence complexity, and error reduction. ChatGPT is used pedagogically to enhance writing, not merely for automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: improvements in overall writing quality, text length, lexical diversity, sentence complexity, verb cohesion, and grammatical and prepositional error rates, comparing ChatGPT-assisted proofreading with other conditions.""
    }
}"
366,Trinka: Facilitating Academic Writing through an Intelligent Writing Evaluation System,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions potential integration into second language (L2) writing instruction but does not specify any actual participant population, nor whether they are L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is described as a technology review of Trinka, an intelligent writing evaluation system. There is no indication of an experimental or quasi-experimental study design, nor explicit evidence that Trinka is an LLM-based (transformer generative) tool; it appears to be an AI/NLP-based evaluation system.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on reviewing features and potential integration into L2 writing instruction, not on an implemented pedagogical intervention with measured effects. It is a technology review rather than an empirical study of writing competence outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental results are reported. The paper discusses potential benefits, limitations, and integration, but not measured changes in learners’ writing performance.""
    }
}"
367,A Qualitative Descriptive Study of Teachers’ Beliefs and Their Design Thinking Practices in Integrating an Ai-based Automated Feedback Tool,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study involves 9th-grade students learning English as a second language in Norway, and three ESL teachers. The context is clearly L2 English in school settings.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses an AI-driven automated feedback tool called Essay Assessment Technology (EAT). The abstract does not indicate that EAT is a large language model or transformer-based generative system (e.g., ChatGPT, GPT-4). It is framed as an automated feedback/assessment tool, not as an LLM-based generative assistant.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on teachers’ beliefs, perceptions, and design thinking practices when integrating an AI-based automated feedback tool into process writing. It is about technology integration and pedagogical decision-making, not on systematically evaluating writing competence or writing-related learning outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly described as a descriptive qualitative study using teacher interviews. No quantifiable writing outcome metrics or experimental/quasi-experimental measures of students’ writing performance are reported.""
    }
}"
368,The Differential Impact of Ai Tools among Efl University Learners: a Process Writing Approach,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Vietnamese EFL university students (“Vietnamese EFL majors’ writing proficiency… 200 Vietnamese first-year public and private university students”), clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Grammarly, Write & Improve, and Slick Write. These are AI writing assistants but are not described as large language model (LLM)-based transformer generative systems (e.g., ChatGPT, GPT-4). They primarily provide grammar checking, feedback, and readability analysis, which falls outside the review’s required focus on LLM-based tools.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly targets writing proficiency and related variables (grammatical correctness, task completion, coherence, language range) within a process writing approach, aligning with a primary focus on writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative pre- and post-test scores are analyzed via paired t-tests and logistic regression, reporting significant changes in grammatical correctness, task completion, and language range. These are clear, quantifiable writing outcome metrics.""
    }
}"
369,Integrating Quillbot to Enhance Students’ Academic Writing: Opportunities and Challenges,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a review of 15 peer-reviewed studies on QuillBot use in academic writing. While it mentions EFL students, it does not present primary empirical data on a specific population of L2 English learners; instead, it synthesizes prior work. As a review article, it does not itself meet the primary-study population criterion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly described as a critical review of existing research on QuillBot, not an experimental or quasi-experimental intervention study. Moreover, QuillBot is generally not categorized as an LLM-based generative tool in the sense required (e.g., ChatGPT, GPT-4). Thus, it does not meet the intervention criterion.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the review focuses on academic writing and related variables (paraphrasing, grammar, vocabulary, motivation), it is not an original pedagogical intervention study but a synthesis of prior work. The context criterion requires a primary study implementing an LLM-mediated writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The article uses qualitative thematic analysis of prior studies and emphasizes emotional/behavioral impact, user experience, and ethical issues. It does not report original, quantifiable writing outcome metrics from an intervention; instead, it summarizes others’ findings. Review articles are excluded by design.""
    }
}"
370,Effects of the Use of Generative Ai Tools on Eap Writing Development: a Case Study with Medicine Undergraduates,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are undergraduate EFL learners at a Saudi university taking English for Academic Purposes (EAP) writing, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses multiple AI tools: ResearchRabbit (referencing), Acrobat Chat with PDFs (summarization), and Otio (grammar check, planning, drafting, revising). The abstract does not indicate that any of these are large language model–based tools like ChatGPT/GPT-4 or similar transformer-based generative models; they appear to be specialized support tools rather than LLM-centered writing instruction. Thus it does not clearly meet the requirement of integrating LLMs into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly targets EAP writing development, teaching students to plan, organize, draft, revise, and produce final drafts of short essays on medical issues. The primary focus is on writing competence and writing processes.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative writing outcomes are reported: pre-test and post-test essay scores, comparison between experimental and control groups, mean score differences, and t-test statistics showing significant improvement in writing performance for the AI tools group.""
    }
}"
371,Efl Pre-service Teachers’ Acceptance of Chatgpt for Writing: a Sequential Explanatory Mixed-method Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 143 EFL pre-service teachers from universities in Indonesia, clearly positioning them as L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines acceptance and intention to use ChatGPT via a Technology Acceptance Model questionnaire and interviews. There is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction or tasks; ChatGPT is the object of attitudes, not a structured treatment.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on technology acceptance, perceptions, and ethical concerns regarding ChatGPT for writing, not on implementing a pedagogical writing intervention or systematically integrating ChatGPT into writing processes for competence development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes are TAM constructs (perceived usefulness, ease of use, attitude, behavioral intention) and qualitative perceptions, without measures of writing performance or related quantitative writing variables.""
    }
}"
372,From Prompting to Proficiency: a Mixed-methods Analysis of Prompting with Chatgpt Versus Lecturer Interaction in an Efl Classroom,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 60 Indonesian university students in an EFL classroom context. The abstract explicitly refers to English as a Foreign Language (EFL) and reports outcomes in general English proficiency and writing competency, indicating L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is prompting with ChatGPT, explicitly described as an extensive/large language model (Generative AI). Students were allocated to an experimental (ChatGPT) and a control (lecturer) group, indicating an experimental design integrating an LLM into instruction/help-seeking.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing competency is one of the primary measured outcomes, alongside general proficiency and self-efficacy. The study compares ChatGPT versus lecturer interaction in an EFL classroom with a clear focus on academic help-seeking and learning, including writing-related outcomes.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pre/post-tests including a writing test and analyzes data via ANCOVA. It reports that the ChatGPT group significantly outperformed the control group in writing competency (p < .001), providing quantifiable writing outcome metrics for the LLM-mediated intervention.""
    }
}"
373,Using Ai-supported Peer Review to Enhance Feedback Literacy: an Investigation of Students' Revision of Feedback on Peers' Essays,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 44 Chinese undergraduate students providing peer feedback on peers’ English argumentative essays in an L2 writing context, i.e., L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study introduces EvaluMate, an AI-supported peer review system with a large language model-based chatbot (Eva) that evaluates and provides feedback on students’ comments. This is an LLM-based intervention integrated into the writing/feedback process.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on improving the quality of students’ peer review comments (feedback literacy and peer feedback provision), not on learners’ own writing competence or writing-related performance outcomes. The outcome variable is comment quality, not writing quality.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study reports quantifiable improvement in the quality of peer review comments, it does not report quantifiable writing outcome metrics (e.g., changes in students’ own essay quality). The measured outcomes are feedback-related, not writing performance outcomes.""
    }
}"
374,Leveraging Chatgpt for Research Writing: an Exploration of Esl Graduate Students’ Practices,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as two ESL graduate students, indicating they are L2 English learners in an ESL context and the focus is on English research writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the study is a case study of students’ self-directed use after a tutorial, not an experimental or quasi-experimental intervention design. There is no indication of controlled instructional treatment or comparison conditions to test the effect of an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is research writing by ESL graduate students, focusing on how they use ChatGPT for genre, content, language use, documentation, coherence, and clarity—clearly centered on writing processes and competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative findings about practices, approaches, and ethical use. It mentions textual analysis of drafts but does not report any quantifiable writing outcome metrics (e.g., scores, measurable gains) to assess effectiveness of the LLM-mediated intervention.""
    }
}"
375,“teaching Is Basically Feeling”: Unpacking Efl Teachers’ Perceived Emotions and Regulatory Strategies in Ai-powered L2 Speaking and Writing Skills Instruction,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 21 Iranian EFL teachers working in L2 speaking and writing instruction, clearly within an EFL/ESL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although AI tools are used in L2 speaking and writing classes, the study is qualitative and focuses on teachers’ emotions and regulatory strategies. There is no indication of an experimental or quasi-experimental design evaluating an LLM-based writing intervention (e.g., ChatGPT) or specifying that the AI tools are LLMs.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is teacher emotionality (positive/negative emotions and regulation) when integrating AI in L2 productive skills. Writing competence or writing-related performance variables are not the central outcome; writing is only a context for examining emotions.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly qualitative, using semi-structured interviews and narrative frames with thematic analysis. It does not report quantifiable writing outcome metrics or measure the effectiveness of AI/LLM-mediated writing interventions.""
    }
}"
376,"The Impact of Artificial Intelligence and Machine Learning on Linguistic Accuracy, Fluency, and Self-direction among Advanced Efl Students",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'advanced EFL students' and 'those who speak English as a foreign language,' clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses 'technology-enhanced adaptive grammar tools, translation software, and artificial intelligence-driven feedback systems.' There is no indication that these tools are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems; they could be traditional NLP/AI tools. Thus it does not clearly meet the LLM-based intervention requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus includes 'linguistic accuracy, fluency, and self-direction' and reports 'significant improvement in students’ writing fluency,' indicating a primary focus on writing competence and related variables within an instructional context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports 'significant improvement in students’ writing fluency' and mentions changes in 'learners’ autonomy and linguistic precision,' implying quantitative outcome measures comparing control and experimental groups after a 12-week intervention.""
    }
}"
377,Guarding Integrity: a Case Study on Tackling Ai-generated Content and Plagiarism in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are in an ENG102 advanced writing course and are likely L2 English learners, but the abstract does not explicitly state ESL/EFL/ELL status or that English is a second/foreign language for the students.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study analyzes AI-generated content and plagiarism rates in essays submitted to Turnitin and discusses students’ perceptions of AI. There is no indication of an experimental or quasi-experimental LLM-based writing intervention (e.g., using ChatGPT as part of instruction); AI is treated as a source of potential misconduct and as a detection tool, not as an instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is academic integrity (plagiarism and AI-generated content) rather than improving writing competence or writing-related pedagogical outcomes. Writing is the context of the misconduct analysis, not the target of an instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Reported quantitative outcomes are plagiarism percentages, AI usage rates, and attitudes toward AI and plagiarism. No quantifiable writing performance metrics (e.g., writing quality scores, complexity, accuracy, organization) are reported to assess the effectiveness of an LLM-mediated writing intervention.""
    }
}"
378,Teachers' Use of Generative Ai in Jordanian Universities: Practices and Perceptions,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study population consists of EFL instructors at Jordanian universities, not L2 English learners. The focus is on teachers’ perceptions and practices, not learner participants or learner data.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although generative AI tools such as ChatGPT and ChatPDF are mentioned, the study investigates how instructors use them for materials development and their perceptions. There is no experimental or quasi-experimental design integrating LLMs into learners’ writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on instructors’ use of AI for developing reading and writing materials and their perceptions, institutional support, and policy. It is not a pedagogical intervention study targeting learners’ writing competence or writing-related performance.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes are reported. The quantitative data are survey responses from instructors about perceptions and practices, not measures of changes in students’ writing performance following an LLM-mediated intervention.""
    }
}"
379,Ai-assisted L2 Assessment: a Biblio-systematic Analysis,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses L2 assessment in general and mentions L2 learners but does not specify that the focus is on L2 English learners in ESL/EFL/ELL contexts, nor that the data are specifically about English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a biblio-systematic/bibliometric review of 57 SSCI-indexed articles on AI-assisted L2 assessment. It does not itself implement an experimental or quasi-experimental LLM-based intervention; it synthesizes prior work and focuses on tools such as automated scoring systems and NLP technologies in general.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is L2 assessment broadly (writing and speaking assessments) and the role of AI tools in scoring and feedback, not a specific pedagogical writing intervention or instructional context. It is a field-level analysis rather than an intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a bibliometric and systematic review, the study does not report its own experimental writing outcome metrics. It summarizes effectiveness, advantages, and challenges from prior literature rather than measuring writing performance changes in an intervention.""
    }
}"
380,Korean Efl Learners’ Perceptions of Using Chatgpt for English Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Korean EFL (English as a foreign language) learners, so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, the design is exploratory and perception-focused. Students compared their original writing with ChatGPT-edited versions and wrote reflection notes; there is no indication of an experimental or quasi-experimental intervention structure (e.g., treatment vs. control, pre/post with measured effects).""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly English writing: students’ original writing, ChatGPT-edited versions, and feedback types (vocabulary, expressions, clarification, elaboration). The focus is on writing and writing-related feedback.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports learners’ perceptions, engagement with feedback types, and questionnaire responses about advantages/disadvantages. There is no mention of quantifiable writing outcome metrics (e.g., scores, accuracy, complexity) assessing effectiveness of the ChatGPT-mediated intervention.""
    }
}"
381,Unleashing the Transformers: Nlp Models Detect Ai Writing in Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not describe any participant sample of L2 English learners in ESL/EFL/ELL contexts. It focuses on datasets of human- and AI-generated abstracts and general educational implications, not on a defined learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although GPT-4 and transformer models are mentioned, they are used to detect AI-generated text, not as an instructional or quasi-experimental intervention integrated into learners’ writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on AI-writing detection (classification of AI vs. human text) and related ethical issues, not on improving writing competence or implementing a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) for learners are reported. The outcomes concern model accuracy in detecting AI-generated text, not learner writing performance.""
    }
}"
382,Exploring Learner Prompting Behavior and Its Effect on Chatgpt-assisted English Writing Revision,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL learners engaged in English writing revision, indicating L2 English learners in an EFL context with a focus on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines ChatGPT-assisted English writing revision and learner prompting behavior. ChatGPT is a large language model, and the design is a one-group pretest–posttest experiment integrating ChatGPT into the revision process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on English writing revision quality, including surface-level features and higher-order elements such as content, organization, and cohesion, within a pedagogical context using ChatGPT for writing revision.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a one-group pretest–posttest experiment and applies the Wilcoxon signed-rank test to assess changes in writing quality, reporting improvements in surface-level aspects and minimal enhancement in higher-order elements, thus providing quantifiable writing outcome metrics.""
    }
}"
383,The Effects of Chatgpt-generated Feedback on Saudi Efl Learners’ Writing Skills and Perception at the Tertiary Level: a Mixed-methods Study,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Saudi EFL students at the university level, i.e., English as a Foreign Language learners, with a focus on English writing skills.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is ChatGPT-generated feedback (a generative AI LLM) compared to teacher-generated feedback, implemented via a pretest–posttest control group design, satisfying the requirement for an experimental LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on writing skills and academic writing, examining corrective feedback on students’ writing and their perceptions of using ChatGPT for academic writing.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative writing outcomes are reported: pretests and posttests of writing skills analyzed via ANCOVA, with findings on posttest score differences between experimental and control groups.""
    }
}"
384,"An Ai Chatbot for Efl Writing: Students’ Usage Tendencies, Writing Performance, and Perceptions",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students at a high school in Northern Vietnam, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses an 'AI chatbot' called the Writing Assistant Bot (WAB) to support EFL writing practice. However, the abstract does not specify whether WAB is based on a large language model (e.g., transformer-based generative model like ChatGPT/GPT-4) or a non-LLM AI system. Without this detail, it is unclear if it meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on EFL writing practice, usage at different writing stages (Planning, Translating), and writing aspects (content, organization, vocabulary, language use, mechanics). The context is clearly writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports that the chatbot 'significantly enhanced writing performance across all aspects: content, organization, vocabulary, language use, and mechanics,' implying quantifiable writing outcome metrics (e.g., timed-writing tests and scoring).""
    }
}"
385,Assessing the Efficacy of Ai-driven Corrective Feedback Via Whatsapp Application to Improve Esl Learners’ Writing Skills: an Experimental Study,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as ESL learners: 112 undergraduate participants in India learning English as a second language. The focus is clearly on English writing skills and grammatical accuracy in English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention is described as “AI-driven corrective feedback via WhatsApp application” and outcomes are scored using ChatGPT 4.0. However, the abstract does not specify whether the AI-driven feedback itself is generated by a large language model (e.g., ChatGPT or another transformer-based LLM) integrated into WhatsApp, or by some other non-LLM AI system. Without clarification that the corrective feedback is LLM-based, it is unclear if this meets the LLM intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on improving ESL learners’ writing skills by reducing grammatical errors in written submissions. The study is framed as writing instruction and feedback, not as automated essay scoring research per se. Writing competence (error reduction in grammar, word choice, etc.) is the central outcome.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental design with pre-test and post-test writing tasks, and applies RM-ANOVA to compare scores between experimental and control groups. It reports that learners receiving AI-driven corrective feedback via WhatsApp performed better, indicating quantifiable writing outcome metrics (scores and error reduction).""
    }
}"
386,"Chatgpt Usage Patterns in Essay Writing: a Case Study of Advanced, Intermediate, and Low-proficiency English Learners",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as ‘second language learners at different English proficiency levels’ and ‘three university students’ working on argumentative essays in English, indicating L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly investigates how learners ‘interact with ChatGPT during argumentative essay writing,’ which is an LLM-based tool integrated into the writing process. Although it is a case study, it still involves an LLM-mediated writing activity.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly L2 argumentative essay writing, focusing on how ChatGPT is used for language, structure, content generation, argument development, and translation—core writing-related processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions analysis of ‘writing processes and interviews’ and reports ‘usage strategies’ and implications for AI literacy. It does not indicate any experimental or quasi-experimental design, nor any quantifiable writing outcome metrics (e.g., scores, quality ratings, pre-post measures). It appears to be a qualitative case study of usage patterns rather than an intervention effectiveness study.""
    }
}"
387,Comparing Native and Non-native English Speakers' Behaviors in Collaborative Writing through Visual Analytics,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study compares native speakers (NS) and non-native speakers (NNS) in collaborative writing. While NNS may be L2 English users, the abstract does not specify that they are ESL/EFL/ELL learners or that the context is language learning rather than general communication or writing research.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Large language models are used to generate behavior summaries within a visual analytics tool (COALA), not as part of an instructional or experimental writing intervention for learners. There is no indication of an LLM-mediated pedagogical treatment aimed at improving participants’ writing.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on analyzing and visualizing collaborative writing behaviors and model interpretability, not on writing instruction or improving writing competence. The LLM is used for summarizing behaviors, not as a teaching or feedback tool in a learning context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports validation of the tool via user studies and insights discovered, but does not mention quantitative writing outcome measures (e.g., writing quality scores, complexity, accuracy) resulting from an LLM-based intervention. Outcomes relate to tool effectiveness and insights, not learner writing gains.""
    }
}"
388,Mind the Gap! Choice Independence in Using Multilingual Llms for Persuasive Co-writing Tasks in Different Languages,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are described as globalized workers and Spanish-speaking female participants, but there is no indication that they are L2 English learners in ESL/EFL/ELL contexts. The focus is multilingual use (Spanish and English), not specifically L2 English learning.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly involves an LLM-based writing assistant (multilingual LLMs) used in a charity advertisement writing task, examining user utilization and AI performance across languages.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on behavioral economics concepts (choice independence), utilization patterns, beliefs about AI, and donation behavior, not on writing competence or pedagogical writing instruction. The writing task is a vehicle for studying decision-making, not an instructional writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study quantifies persuasiveness of generated advertisements and donation behavior, these are not reported as writing proficiency or writing development outcomes for L2 learners. There is no structured LLM-mediated writing intervention with learning-related writing metrics.""
    }
}"
389,Feedback Seeking Abilities of L2 Writers Using Chatgpt: a Mixed Method Multiple Case Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as three EFL learners in L2 writing classrooms, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""ChatGPT, an LLM, is used as an automated written corrective feedback (AWCF) provider in L2 writing classrooms, constituting an LLM-mediated writing-related intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is L2 writing classrooms and the use of ChatGPT for written corrective feedback, which is directly related to writing processes and instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a mixed-method multiple case study focusing on feedback-seeking abilities, strategies, and perceptions. Data sources are observations, prompts, and in-depth interviews. The abstract does not report any quantitative writing outcome measures (e.g., writing scores, accuracy gains) assessing effectiveness of the intervention on writing performance.""
    }
}"
390,Analysis of a Comparative Study between Traditional Online Automatic Writing Evaluation Systems and Large Language Model-assisted Online Revision for Second Language Writing,2025,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “L2 writing” and “learners,” implying second language learners, but it does not explicitly state that the target language is English or that the context is ESL/EFL/ELL. The specific L2 is not identified in the title or abstract.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study compares a traditional online automatic writing evaluation system (Pigaiwang) with “Large Language Models (LLMs)” for online revision of L2 writing. It is described as using experimental data and LLM-assisted online writing correction and feedback, which indicates an experimental or quasi-experimental design integrating LLMs into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on “two online revision modes of L2 writing” and how they assist learners’ writing levels and enthusiasm for writing revision. This aligns with a primary focus on writing competence and writing-related variables in a pedagogical context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract notes that “through experimental data” significant differences were found between the two modes in assisting learners’ writing levels, and that LLM-assisted correction can improve learners’ writing levels. This implies quantifiable outcome measures of writing performance were collected and analyzed.""
    }
}"
391,Assessing the Impact of Chatgpt on Efl Students’ Writing Productivity and Proficiency,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 52 Saudi female university students in an English as a Foreign Language (EFL) course, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study investigates incorporating ChatGPT, explicitly identified as an AI-based tool, into an EFL course. ChatGPT is a large language model, and its use is part of an instructional intervention rather than only evaluation.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence, specifically writing productivity and proficiency, including topic sentence formation, organization, supporting details, mechanics, and word count. ChatGPT is integrated into the writing process to support these skills.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""A pretest–posttest design is used to evaluate changes in key writing skills and word count, providing quantifiable writing outcome metrics (e.g., proficiency in topic sentences, supporting details, mechanics, organization, and productivity).""
    }
}"
392,Students’ Perceptions of Generative Artificial Intelligence (genai) Use in Academic Writing in English as a Foreign Language †,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 56 undergraduate university students in Ecuador studying English as a foreign language (EFL), clearly an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a perception survey about GenAI/ChatGPT use and academic integrity. There is no indication of an experimental or quasi-experimental design integrating LLMs into writing instruction or writing processes as an intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is academic writing in EFL, the focus is on perceptions of academic dishonesty, AI-giarism, and institutional policies, not on a pedagogical writing intervention or structured use of LLMs to develop writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports attitudinal and perception data (worries about skill development, views on dishonesty, beliefs about detectability). It does not report any quantifiable writing outcome metrics or measures of writing performance following an LLM-mediated intervention.""
    }
}"
393,Use of Ai Tools in Efl Writing Instruction: a Case Study of Chinese Vocational College Instructors,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is English as a foreign language (EFL) writing at Chinese vocational and technical colleges. Although the participants are instructors, the focus is clearly on EFL writing instruction for L2 English learners in China.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers generically to “AI writing tools” without specifying whether they are LLM-based (e.g., ChatGPT, GPT-4) or other tools (e.g., automated feedback systems). However, the study is a qualitative case study of instructors’ experiences and perceptions, not an experimental or quasi-experimental intervention study integrating LLMs into instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on instructors’ experiences and perceptions of AI tools in EFL writing instruction, not on implementing and evaluating a specific pedagogical writing intervention. It is a qualitative case study, not an intervention study centered on writing competence outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses semi-structured interviews and reports perceptions and experiences. There is no mention of quantitative writing outcome measures or experimental evaluation of AI-mediated writing improvement.""
    }
}"
394,Navigating the Digital Writing Landscape: Efl Students’ Perspectives on Chatgpt Utilization,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are English as a foreign language (EFL) students at an Indonesian university, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines students’ perspectives on various AI tools (grammar checkers, text-to-speech, language learning apps, and ChatGPT) via surveys and interviews. There is no experimental or quasi-experimental design integrating an LLM into instruction; it is a perception/acceptance study based on the technology acceptance model.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on technology acceptance (usefulness, ease of use, social influence) and general language skills development, not on a structured writing competence intervention. Writing is not specified as the central outcome or instructional focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study relies on self-reported perceptions and experiences; it does not report quantifiable writing outcome metrics or measure changes in writing performance following an LLM-mediated intervention.""
    }
}"
395,Integrating Generative Ai into Digital Multimodal Composition: a Study of Multicultural Second-language Classrooms,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are “eleven culturally diverse students from two high schools in Hong Kong” in “multicultural second-language classrooms,” indicating L2 English learners in an EFL/ESL context, with outcomes such as vocabulary and grammar improvements in English writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses “generative AI tools” integrated via the IDEA framework, but the abstract does not specify that these are LLM-based tools (e.g., ChatGPT, GPT-4). However, given current usage, it is plausible they are LLMs; still, the specific tools are unnamed in the abstract.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is “digital multimodal composition (DMC)” and multimodal literacy, including visual representation and multimodal design. While vocabulary, grammar, and structure in written work are mentioned, the central context is broader DMC rather than a focused L2 writing competence intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Data sources are “tool-usage history, classroom video observations, surveys, and interviews.” The abstract reports qualitative findings (how students leveraged AI, stages in composition, enhancements) but does not indicate any experimental or quasi-experimental design with quantifiable writing outcome metrics (e.g., pre/post test scores, rubric-based ratings with statistical analysis).""
    }
}"
396,Artificial Intelligence as a Provider of Feedback on Efl Student Compositions,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 29 English major students at a Saudi university, described as foreign language writers (EFL context), so they are L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used to provide feedback on student essays, the study is descriptive/analytical. There is no experimental or quasi-experimental design integrating ChatGPT into instruction (no control/comparison group, no pre-post intervention, no measured treatment effect). The focus is on analyzing the nature and quality of ChatGPT feedback, not on testing an instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly writing-focused: EFL student compositions and AI-provided feedback on those compositions. The study examines feedback types and quality in relation to writing practice in the classroom.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports only qualitative analysis of ChatGPT’s feedback (consistency, credibility, feedback types). It does not report quantifiable writing outcome metrics (e.g., changes in writing scores, accuracy, complexity) to assess the effectiveness of the AI-mediated intervention on learners’ writing performance.""
    }
}"
397,Translanguaging with Generative Ai in Efl Writing: Students’ Practices and Perceptions,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students in China (six college students with lower to intermediate proficiency), clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study involves generative AI (ERNIE Bot), it is described as a qualitative exploration of how students utilize AI, with data from interviews and artefacts. There is no indication of an experimental or quasi-experimental instructional intervention design; rather, it documents existing practices and perceptions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL writing, specifically how students use generative AI in their writing process and translanguaging practices, which aligns with writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly qualitative, examining practices and perceptions. The abstract does not mention any quantifiable writing outcome metrics or experimental measures of writing performance; it focuses on logs, writing products as artefacts, and perceptions.""
    }
}"
398,Secondary School English Teachers’ Application of Artificial Intelligence-guided Chatbot in the Provision of Feedback on Student Writing: an Activity Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are secondary school English teachers in China providing feedback on student L2 English writing. The context is clearly L2 English writing instruction in an EFL setting, so the population criterion is met.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses Kimi, described as an AI-guided chatbot, to support teacher feedback on student writing. It is not explicitly stated that Kimi is a large language model (e.g., GPT-like transformer-based generative model), only that it is an AI-guided chatbot. Based on the abstract alone, it cannot be confirmed that the tool is an LLM as defined in the review criteria.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on how teachers incorporate an AI-guided chatbot into their feedback practices, examining features and patterns of feedback and components of the activity system. The abstract does not indicate a pedagogical intervention aimed at improving learners’ writing competence; rather, it analyzes feedback characteristics and teacher–AI interaction, not learner writing development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics for students are reported. The results concern differences between Kimi and teacher feedback (amount, length, foci, types) and the structure of the activity system. There is no mention of experimental measures of student writing performance or changes in writing quality attributable to the AI-mediated intervention.""
    }
}"
399,Using Ai-text Generated Mentor Texts for Genre-based Pedagogy in Second Language Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers generally to “second language (L2) writing instruction” and “L2 writing classrooms” but does not specify that the learners are L2 English learners (ESL/EFL/ELL) or that the focus is on English rather than another target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""GenAI tools are used to generate mentor texts, but the study appears to be conceptual/descriptive, illustrating how AI-generated texts can demonstrate genre features. There is no indication of an experimental or quasi-experimental design or a structured intervention where LLMs are integrated into writing instruction with measured effects.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context is L2 writing pedagogy and genre-based instruction, which is writing-focused. However, the article seems to focus on demonstrating genre features in AI-generated mentor texts and their potential use, rather than reporting on an implemented pedagogical intervention with learners.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantifiable writing outcome metrics, experimental measures, or assessment of learners’ writing performance. It appears to be a theoretical or illustrative piece without empirical outcome data.""
    }
}"
400,Unlocking Efl Learners’ Insights into Chatgpt Use for L2 Writing: the Impacts of Usage Frequency and Gender Variations,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 874 Turkish undergraduate English majors at a state university in Türkiye, clearly EFL learners using English as an L2.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study concerns ChatGPT use, it does not describe an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction. It investigates existing usage and perceptions, not a designed LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on learners’ perceptions of ChatGPT use for L2 writing and how these vary by gender and usage frequency, rather than on writing competence or writing-related performance variables within a pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, text quality measures) are reported. The quantitative data concern perceptions (ChatGPT Perception Scale) and usage frequency, not measured changes in writing performance.""
    }
}"
401,An Exploratory Research on Effects of Ai Chabots on Syntactic Complexity of L2 Writing,2025,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “second language learners” and “English writing,” indicating L2 English writing, but it does not explicitly specify ESL/EFL/ELL contexts or participant characteristics. Population appears to be L2 English learners, yet the context is not fully clear from the abstract alone.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention is an “AI-powered chatbot” used as an “AI Writing Assistant.” However, the abstract does not specify whether the chatbot is a large language model (e.g., ChatGPT/GPT-based) or another type of AI tool. Without confirmation that it is LLM-based, it is unclear if this meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly focuses on “second language writing instruction,” “English writing,” and examines how chatbot use affects “syntactic complexity” and “writing proficiency.” The primary focus is clearly on writing competence and writing-related variables, not on automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a control and experimental group, collects English compositions, and analyzes them with the Web-based L2 Syntactic Complexity Analyzer and SPSS. It reports that the experimental group showed superior writing proficiency and a positive correlation between syntactic complexity and writing quality, indicating quantifiable writing outcome metrics.""
    }
}"
402,An Empirical Research on Ai Chatbot-assisted Continuation Writing Task,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is conducted in the context of the Chinese college entrance examination and focuses on English continuation writing tasks in a foreign language teaching context. This implies participants are L2 English learners (EFL in China).""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to an “AI chatbot” providing feedback but does not specify whether it is a large language model (e.g., ChatGPT/GPT-based) or a non-LLM chatbot. Without explicit indication that the tool is LLM-based, it is unclear if it meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on English continuation writing tasks and the effects of AI chatbot feedback on L2 learners’ writing proficiency, including overall quality and syntactic development, clearly centering on writing competence in a pedagogical context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study “employs quantitative research methods” and reports that AI chatbot integration has positive effects on “overall quality and syntactic development” of writing, indicating quantifiable writing outcome metrics are used to assess the intervention’s effectiveness.""
    }
}"
403,Impact of Gpt on the Academic Ecosystem,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a broad discussion of GPT’s impact on the academic ecosystem and on academic writing in general. It mentions non-native English speakers but does not specify L2 English learners in ESL/EFL/ELL instructional contexts or any defined learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a conceptual/review-style paper discussing potential uses of GPT-like technologies. There is no experimental or quasi-experimental design, no implemented intervention, and no structured integration of LLMs into writing instruction or processes for a learner group.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although academic writing and drafting are mentioned, the focus is on general academic and publishing workflows, not on a pedagogical context targeting L2 writing competence or writing-related learning variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantitative writing outcomes or measured effects of an LLM-mediated writing intervention. It is a narrative discussion without experimental measures or structured intervention outcomes.""
    }
}"
404,Finding Your Voice: Using Generative Ai to Help International Students Improve Their Writing,2025,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “international students” and “non-native English speakers” writing in academia, which suggests L2 English learners, but it does not explicitly state ESL/EFL/ELL status or that English is the target language of instruction. The context (computing degrees, likely in an English-medium university) implies English, but this is not fully explicit.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses “Gen-AI tools built on large language models (LLMs) such as ChatGPT and Claude” in “a series of structured exercises” to improve student writing. This indicates an LLM-based intervention integrated into writing tasks, with some experimental structure (exercises, repeated with an independent group).""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on improving student writing (literature reviews, summaries, reflective reports) and how Gen-AI can “improve student writing” and help students “develop their own distinct voice.” This aligns with writing competence and writing-related variables, not just system evaluation.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that the paper reports on structured exercises to determine how Gen-AI tools might improve student writing and that two exercises were repeated with another group. However, it does not specify any quantitative or otherwise clearly measurable writing outcome metrics; it may be descriptive or conceptual. Without explicit mention of measured writing gains or scores, the presence of quantifiable outcomes is uncertain.""
    }
}"
405,Complementing but Not Replacing: Comparing the Impacts of Gpt-4 and Native-speaker Interaction on Chinese L2 Writing Outcomes,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 23 Chinese L2 learners completing an L2 (English) writing task. The context is clearly L2 writing, and the abstract focuses on L2 writing outcomes, fitting ESL/EFL/ELL-type populations.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention explicitly uses a large language model, GPT-4, as a support tool in the pre-writing phase. A within-subject behavioral experiment compares three conditions: no interaction, interaction with GPT-4, and interaction with a human language partner, indicating an experimental design integrating an LLM into writing processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 writing competence: overall writing scores, organization, language, and content. GPT-4 is used pedagogically in the pre-writing phase to support writing, not merely as an automated scoring tool.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: overall writing scores and subcomponents (organization, language, content), and compares these across conditions. It also measures topic familiarity, writing confidence, and perceived difficulty, but crucially includes measurable writing performance outcomes.""
    }
}"
406,The Impact of Digital Storytelling on Efl Learners' Speaking and Writing Skills,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a Foreign Language (EFL) learners, which fits the target population of L2 English learners in EFL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is digital storytelling in general. Although the abstract notes that educators have integrated digital storytelling with AI technologies, it does not specify the use of large language models (e.g., ChatGPT, GPT-4) nor describe an LLM-based writing intervention. The study focuses on digital storytelling as a pedagogical modality, not on LLM integration.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing competence is one of the primary outcomes: the study examines enhancements in grammatical accuracy and creativity in writing as part of the impact of digital storytelling.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports quantitative improvements (e.g., significant improvement in oral fluency, accuracy, and enhancements in grammatical accuracy and creativity in writing) based on survey data from 20 EFL participants, indicating measurable writing-related outcomes.""
    }
}"
407,Envisioning the Future of Ai-assisted Efl Teaching and Learning: Conceptual Representations of Prospective Teachers,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are 67 prospective EFL teachers, not L2 English learners in ESL/EFL/ELL contexts whose own L2 writing development is being measured. The focus is on teachers’ conceptualizations of AI, not learner outcomes.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a descriptive qualitative exploration of how teachers envision AI’s future role. There is no experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing assistants are mentioned among AI tools, the study’s primary focus is on general AI in EFL teaching and learning, teacher replacement risk, and AI–teacher collaboration, not on writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a descriptive qualitative approach and reflexive thematic analysis, reporting themes and nodes. It does not report quantifiable writing outcome metrics or evaluate the effectiveness of an LLM-mediated writing intervention.""
    }
}"
408,Ai and Discourse Analysis: Implications for Esp Genre Pedagogy in Efl Settings,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly refers to ESP writing courses in EFL settings, where speakers of English as a second language are taught domain-specific communication. This matches L2 English learners in EFL/ESP contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the article discusses generative AI tools conceptually, there is no indication of an experimental or quasi-experimental design, nor of an implemented LLM-based intervention. It appears to be a conceptual/pedagogical discussion, not an empirical study integrating LLMs into instruction.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on ESP genre pedagogy and discourse analytical skills in professional/ESP writing, which is writing-related. However, the abstract does not specify a concrete instructional context or implemented intervention; it is more about implications for pedagogy.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or empirical evaluation are mentioned. The article argues conceptually that learning to use generative AI offers opportunities for discourse analytical skill development, but does not report measured outcomes.""
    }
}"
409,Applying Neural Machine Translation and Chatgpt in the Teaching of Business English Writing,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as students in EFL (English as a foreign language) business English writing classes across three majors (finance, economics, business administration). The focus is on English writing, not another target language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study evaluates the application of NMT and ChatGPT in teaching EFL writing. ChatGPT is a large language model integrated into the teaching process to complement NMT by making improvements and providing feedback to students, indicating an instructional intervention using an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is business English writing competence. The study builds corpora of students’ direct-writing and post-edited writing and examines how NMT and ChatGPT affect dimensions of academic writing (word, syntax, cohesion, content, organization, mechanics), clearly centering on writing instruction and performance rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports statistical analyses of writing performance across multiple quantified dimensions (word level, syntax, cohesion, content, organization, mechanics) and compares direct-writing vs. post-edited writing. These constitute quantifiable writing outcome metrics assessing the effectiveness of the technology-mediated intervention.""
    }
}"
410,Evaluating Chatgpt's Reliability in Second Language Acquisition (sla): Insights on Language Skills and Technology's Role,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any participants or learners. The study evaluates ChatGPT-4.0’s responses to 48 SLA-related questions rated by five expert linguists, not by L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT-4.0 (an LLM) is the focus, it is evaluated for reliability and quality of responses to SLA questions. There is no experimental or quasi-experimental design integrating ChatGPT into writing instruction or learners’ writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The study concerns ChatGPT’s responses about SLA topics broadly (technology’s role and language skills). It does not implement a pedagogical intervention targeting writing competence or writing-related variables; writing is only one of several skills mentioned conceptually.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No learner writing outcomes or writing performance metrics are reported. The only quantitative measures are expert ratings of ChatGPT’s answer quality and inter-rater agreement, not L2 writing outcomes following an LLM-mediated intervention.""
    }
}"
411,Assessing Human Evaluations of Cover Letters Written or Edited by Ai and Non-native English Speakers,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study concerns non-native English speakers (NNES) as writers, but the participants in the experiment are 118 native English speakers who only read and evaluate cover letters. There is no indication that L2 learners themselves are the participants receiving an instructional intervention; rather, NNES texts are stimuli for NES raters.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""AI is used to write or edit cover letters (AI-written, AI-edited), but the design is a survey-embedded experiment on human evaluations, not an instructional or quasi-experimental intervention integrating an LLM into L2 writing instruction or learner writing processes. No specific LLM (e.g., ChatGPT, GPT-4) is identified, and the focus is on evaluation of texts, not pedagogy.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on how human raters assess hireability and writing quality of different types of cover letters. This is essentially an evaluation of perceptions of AI- vs NNES-produced texts, not a study of writing competence development or a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although quantitative outcomes (ratings of hireability and writing quality) are reported, they are not writing outcomes of L2 learners following an LLM-mediated intervention. They are judgments by native speakers on pre-produced texts, with no measurement of changes in learners’ writing performance.""
    }
}"
412,Chatgpt-supported Collaborative Argumentation: Integrating Collaboration Script and Argument Mapping to Enhance Efl Students’ Argumentation Skills,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students: “Argumentation is a complex skill essential for English as a Foreign Language (EFL) students… A total of 67 freshmen university students participated…”. The context is clearly English as a foreign language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT, explicitly identified as a large language model, as part of a quasi-experimental intervention: “we proposed using ChatGPT, a large language model, to guide students through three stages of collaboration script… 34 of them using ChatGPT-supported collaborative argumentation (ChatGPT-CA) and 33 using conventional-based collaborative argumentation (C-CA)…”.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on argumentation and argumentative speaking, not writing: “The findings showed that the ChatGPT-CA approach significantly enhanced EFL students’ argumentative speaking performance, critical thinking awareness, and collaboration tendency…”. Writing competence or writing-related variables are not reported as outcomes; speaking is the central assessed skill.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantifiable outcomes are reported for “argumentative speaking performance, critical thinking awareness, and collaboration tendency,” but there is no indication of quantitative writing outcome metrics. The abstract does not mention written products being measured or scored, so it does not meet the requirement for writing outcome measures.""
    }
}"
413,Artificial Intelligence Integration in Acquisition of English Academic Writing: a Comparative Analysis of Student Perspectives in School and University Settings,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are upper-secondary school and university students from Latvia using AI when acquiring academic writing skills in English, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a questionnaire survey about student experiences and types of AI-powered tools used. There is no experimental or quasi-experimental design integrating LLMs into instruction; it is purely descriptive of existing practices and perceptions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on the acquisition of English academic writing skills and how students apply AI in academic writing, which aligns with writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports survey-based perceptions and usage patterns but does not mention any quantifiable writing outcome metrics or measured changes in writing performance resulting from LLM-mediated interventions.""
    }
}"
414,Ai and Uncertain Motivation: Hidden Allies That Impact Efl Argumentative Essays Using the Toulmin Model,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Saudi EFL learners, i.e., learners of English as a foreign language. The focus is on their argumentative writing in English, satisfying the population requirement.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that the study uses 'artificial intelligence (AI) tools' that provide real-time feedback, but it does not specify whether these tools are large language model–based (e.g., ChatGPT, GPT-4) or other forms of AI (e.g., grammar checkers, rule-based systems). Without explicit mention of LLMs or transformer-based generative models, it is unclear if C2 is met.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on argumentative writing performance using the Toulmin Model. AI tools are integrated into the writing process to provide feedback on claims, data, backing, and counterarguments, directly targeting writing competence rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports 'significant improvements in essay quality, particularly in clarity, structure, and depth' across four writing tasks, indicating quantifiable writing outcome metrics were used to assess the intervention’s effectiveness, even though specific measures are not detailed in the abstract.""
    }
}"
415,The Role of Ai-assisted Learning in Academic Writing: a Mixed-methods Study on Chinese as a Second Language Students,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are described as 'Chinese as a Second Language (CSL) students' and writing is evaluated using rubrics for 'Chinese academic writing.' The target language is Chinese, not English, so the population and language focus do not match the review’s requirement of L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The experimental group used 'AI-assisted learning using ChatGPT,' which is a large language model, in contrast to a traditional learning control group. This constitutes an experimental design integrating an LLM into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on 'academic writing' and evaluates 'CSL learners’ academic writing performance,' clearly centering on writing competence and writing-related variables in a pedagogical context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses 'pre- and post-test quantitative data' and 'writing samples ... evaluated using established scoring rubrics for Chinese academic writing,' providing quantifiable writing outcome metrics to assess the AI-assisted intervention.""
    }
}"
416,Enhancing Efl Writing Revision Practices: the Impact of Ai- and Teacher-generated Feedback and Their Sequences,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students: fourteen Vietnamese undergraduates in an EFL academic writing course. The focus is clearly on English as a foreign language writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses Gemini, explicitly described as a generative AI tool, to provide AI-generated feedback on student writing. This constitutes an LLM-based intervention integrated into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL academic writing, focusing on revision practices and feedback (local grammar/vocabulary and global content/organization). The intervention is pedagogical and directly tied to writing development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are revision frequencies (quantity of revisions) after different feedback conditions and sequences. The abstract does not indicate any quantifiable measures of writing quality or competence (e.g., scores, rubric-based quality ratings, accuracy gains). Since only revision behavior, not writing outcomes, is measured, it does not meet the requirement for quantifiable writing outcome metrics.""
    }
}"
417,Bothorship: Ai Chatbot Authorship after Two Years,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract discusses non-native English speakers in scholarly publishing in general terms but does not describe a defined participant group of L2 English learners in ESL/EFL/ELL instructional contexts. It is a perspective/review piece, not an empirical study with a specific learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is described as exploring recent publications and discourse and presenting a perspective on AI authorship and copyediting. There is no indication of an experimental or quasi-experimental design integrating LLMs into writing instruction or processes for learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on scholarly publishing, AI authorship, and copyediting practices, not on pedagogical writing interventions or writing competence development in L2 learning contexts.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or intervention results are reported. The paper is a review/perspective on issues and future directions of AI authorship, not an empirical evaluation of writing outcomes.""
    }
}"
418,Using Ai Large Language Model (llm-chatgpt) to Mitigate Spelling Errors of Efl Learners,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states that the participants are 60 EFL (English as a Foreign Language) students. The focus is on English spelling and writing proficiency, so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an AI Large Language Model, specifically LLM-GPT (ChatGPT-type Generative Pre-training Transformer), to provide automated feedback and spelling assistance in writing. A between-subjects design with control and experimental groups is described, indicating an experimental intervention integrating an LLM into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention targets spelling errors and writing skills, aiming to improve spelling and overall writing proficiency. The context is pedagogical use of an LLM in writing practice, not automated essay scoring or non-instructional evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that learners taught using the LLM_GPT application outscored the control group and better remembered word spellings in the post-test. This implies quantifiable outcome measures (test scores on spelling/writing), alongside perceptions, satisfying the requirement for measurable writing-related outcomes.""
    }
}"
419,Decoding Efl Learners’ Intention to Use Chatgpt for Academic Writing: Cognitive and Emotional Drivers,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Bangladeshi English as a Foreign Language (EFL) learners in public and private universities, clearly fitting an EFL/ESL/ELL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates learners’ cognitive and affective attitudes and behavioral intentions to use ChatGPT via a Likert-scale questionnaire. There is no experimental or quasi-experimental integration of ChatGPT into actual writing instruction or writing processes; it is an attitudinal survey, not an intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is academic writing, the focus is on attitudes and intentions toward using ChatGPT, not on a pedagogical writing intervention or structured use of ChatGPT to develop writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, text quality measures) are reported. The outcomes are psychological constructs (cognitive and affective attitudes, behavioral intention), not writing performance measures.""
    }
}"
420,The Role of Generative Ai in Mediating L2mss and Engagement with Written Feedback in Efl Learning: a Structural Equation Modeling Approach,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students in Japan (“within an English as a Foreign Language context in Japan… 174 students participated”), and the task is English writing, so the population is L2 English learners.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses “Generative AI (GenAI)” for feedback on writing, but the abstract does not specify that the tool is an LLM (e.g., ChatGPT, GPT-4). However, given the 2025 date and terminology, it is likely LLM-based, though not explicitly stated.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is writing classes where students “use Generative AI (GenAI) to receive feedback on their writing” and “collaboratively construct essays during the semester using GenAI,” so the primary focus is on writing and GenAI-mediated writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are motivation, AI usage, and engagement (affective, behavioral, cognitive) measured via survey and analyzed with structural equation modeling. The abstract does not report any quantitative writing performance outcomes (e.g., writing scores, quality measures), only engagement-related constructs.""
    }
}"
421,Integrating Automated Writing Evaluation into Saudi Efl Students’ Writing Practice,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 154 Arabic-speaking undergraduate EFL students at a Saudi university, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses generic 'AWE systems' (Automated Writing Evaluation). There is no indication these are LLM-based tools such as ChatGPT/GPT-4 or other transformer-based generative models; AWE typically refers to scoring/feedback systems like e-rater or Criterion, which are not LLM interventions as defined in the review.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on integrating AWE into EFL writing practice and its effects on writing skills, critical thinking, autonomy, and motivation to write in English—clearly a writing-focused pedagogical context.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions collecting 'samples of EFL writing assignments before and after utilising the AWE system' and claims effectiveness in enhancing lower-level writing skills, but it does not explicitly state that quantifiable writing outcome metrics were analyzed; emphasis is on experiences, evaluations, challenges, satisfaction.""
    }
}"
422,The Impact of Ai-generated Feedback Explicitness (generic Vs. Specific) on Efl Students' Use of Automated Written Corrective Feedback,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL university students in Saudi Arabia (Arab schools and universities), clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is described as AI-driven Automated Written Corrective Feedback and Automated Essay Scoring systems/AWE systems. There is no indication that these tools are LLM-based (e.g., ChatGPT, GPT-4); they are framed as generic AWE/AES systems, which are typically not transformer-based generative models.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL writing, corrective feedback, and writing proficiency in L2 writing instruction, which aligns with writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the main research question mentions writing proficiency, the abstract reports only perceptions (ease of use, clarity, usefulness, preferences for specific vs. generic feedback). The analysis centers on perceptions via questionnaires and factor analysis; no explicit quantifiable writing outcome measures (e.g., changes in writing scores, accuracy) are reported.""
    }
}"
423,Saudi Efl Learners’ Perceptions of Using Artificial Intelligence and Its Impact on Their Writing Skills,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are female Saudi learners of English as a Foreign Language at the University of Jeddah, clearly an EFL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT and other AI tools are mentioned, the abstract frames the study as examining learners’ perceptions and experiences, not as an experimental or quasi-experimental intervention integrating LLMs into instruction. No controlled or structured LLM-based instructional treatment is described.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is broadly on writing skills and writing development, but the study centers on perceptions and experiences rather than a defined pedagogical writing intervention. It is not clear that there is a specific instructional design around writing competence being tested.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports attitudes, perceived benefits, and drawbacks, but does not mention any quantifiable writing outcome measures (e.g., pre/post writing scores, rubric-based assessments). The impact on writing competency is discussed in terms of perceptions, not measured outcomes.""
    }
}"
424,Evaluating the Quality of Ai Feedback: a Comparative Study of Ai and Human Essay Grading,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students: “30 essays written by English as a foreign language (EFL) students,” so the population is L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""AI tools are used as essay graders/feedback providers and compared to human evaluators. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction or writing processes; the focus is on evaluation quality.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the quality and comparability of AI vs. human essay grading and feedback, not on improving writing competence through an instructional intervention. This aligns with automated essay scoring research rather than a writing intervention context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study does not report changes in learners’ writing performance or other outcome measures following an AI-mediated intervention. It only analyzes AI vs. human scoring and feedback on existing essays, with no pre/post or comparative learning outcomes.""
    }
}"
425,The Integration of Chatgpt in English for Foreign Language Course: Elevating Ai Writing Assistant Acceptance,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 95 English as a Foreign Language (EFL) students in Indonesia, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study integrates ChatGPT, an LLM, into students’ writing process over a four-week assignment, constituting an LLM-based writing aid intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on technology acceptance (perceived ease of use, usefulness, attitude toward change, behavioral intention) using the Technology Acceptance Model, not on writing competence or writing-related performance variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, quality measures, accuracy, complexity) are reported. Outcomes are limited to acceptance and behavioral intention constructs, not writing performance.""
    }
}"
426,Investigating Students’ Uptake of Teacher- and Chatgpt-generated Feedback in Efl Writing: a Comparison Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are twenty Chinese undergraduate EFL students writing argumentative essays in English, clearly fitting an EFL/ESL L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used as a feedback provider, but the design is a comparison of teacher- vs ChatGPT-generated feedback uptake, not an experimental or quasi-experimental LLM-mediated instructional intervention aimed at improving writing performance (e.g., no pre/post or controlled treatment vs control conditions).""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL argumentative writing, specifically on how students use feedback from teachers and ChatGPT in revising their essays, which is directly related to writing competence and writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are engagement with feedback, appropriateness of revisions, and questionnaire-based perceptions and preferences. There is no indication of quantifiable writing outcome metrics (e.g., overall writing quality scores, rubric-based gains) assessing the effectiveness of an LLM-mediated intervention over time.""
    }
}"
427,"Beyond Policing: Ai Writing Detection Tools, Trust, Academic Integrity, and Their Implications for College Writing",2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions bias against non-native English speakers and focuses on college writing, but it does not specify that the participants are L2 English learners in ESL/EFL/ELL contexts, nor that data are specifically about L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article discusses AI writing detection tools, trust, and academic integrity, and argues for collaborative AI integration in writing. However, it does not describe an experimental or quasi-experimental study using a specific LLM (e.g., ChatGPT, GPT-4) as an instructional intervention; it appears to be conceptual/perspective-based.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""While the context is college writing and AI, the focus is on detection tools, institutional guidelines, and academic integrity rather than a concrete pedagogical intervention targeting writing competence or writing-related variables using LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental results are reported. The abstract discusses implications, frameworks, and recommendations, but not measured changes in writing performance following an LLM-mediated intervention.""
    }
}"
428,Unpacking the Rejection of L2 Students Toward Chatgpt-generated Feedback: an Explanatory Research,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are L2 learners (L2 students in a university Computer Science program) working on an argumentative writing report in an AI-assisted educational environment, indicating an L2 English writing context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study involves students being encouraged to seek corrective feedback from ChatGPT, a large language model, on their argumentative writing report. This constitutes an LLM-based writing-related intervention, even though it is not strictly experimental in the sense of comparing conditions.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on learners’ challenges and rejection of ChatGPT-generated feedback (technology acceptance and use), not on improving writing competence or systematically evaluating writing performance. Outcomes center on feedback acceptance/rejection and reasons, rather than writing development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study reports quantitative data (e.g., 45.9% of AI-generated feedback rejected), it does not report quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity). The measures relate to feedback uptake and perceptions, not to writing performance gains.""
    }
}"
429,Collaborative Writing Based on Generative Ai Models: Revision and Deliberation Processes in German as a Foreign Language,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The population consists of learners of German as a foreign language. The title and abstract explicitly state the context is German as a Foreign Language, not English (ESL/EFL/ELL). Therefore, it does not meet the requirement that the target language be English.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study integrates generative AI models (e.g., ChatGPT) into a classroom-based collaborative writing intervention, where students compare their own writing with GenAI models. This constitutes an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on L2 writing and revision processes in collaborative writing, including how GenAI influences revision and deliberation, clearly centering on writing competence and writing-related variables rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports changes in text quality and evaluates texts for functional adequacy, which are quantifiable writing outcome metrics linked to the GenAI-mediated intervention.""
    }
}"
430,Exploring Chatgpt as a Tool for Thesis Writing: Perspectives of Efl Supervisors in Jordanian Universities,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The participants are 47 Jordanian EFL supervisors, not L2 English learners. The study reports supervisors’ perceptions of ChatGPT’s use in students’ thesis writing, but the data are not collected from learners themselves, nor are learner outcomes directly measured.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is the focal tool, the study is not an experimental or quasi-experimental intervention integrating ChatGPT into writing instruction. It is a perception study using a questionnaire to gauge supervisors’ views, without a structured LLM-mediated instructional treatment.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context is thesis writing in EFL, which is writing-focused, but the study centers on supervisors’ opinions about ChatGPT’s usefulness rather than on an implemented pedagogical intervention or writing process design. The abstract does not describe an actual instructional context where ChatGPT is systematically integrated.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study quantifies supervisors’ perceptions (Likert-scale responses) about ChatGPT’s effects, not students’ writing performance. No quantifiable learner writing outcome metrics (e.g., scores, text quality measures, revisions) are reported to assess the effectiveness of an LLM-mediated writing intervention.""
    }
}"
431,More Human Than Human? Differences in Lexis and Collocation within Academic Essays Produced by Chatgpt-3.5 and Human L2 Writers,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly involves human L2 writers producing academic essays, indicating a population of second language learners writing in English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT-3.5 is used to generate essays, there is no experimental or quasi-experimental pedagogical intervention integrating the LLM into L2 writing instruction or learners’ writing processes. The design is a comparative corpus analysis of AI vs. human texts, not an instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on linguistic differences (lexis and collocation) between AI-generated and human L2 essays and implications for academic integrity and AI detection, rather than on improving writing competence through an instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study does not report quantifiable writing outcome measures assessing the effectiveness of an LLM-mediated writing intervention. It analyzes textual features but does not evaluate changes in learners’ writing performance following LLM use.""
    }
}"
432,Chatgpt and L2 Chinese Writing: Evaluating the Impact of Model Version and Prompt Language on Automated Corrective Feedback,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are not L2 English learners; the focus is on L2 Chinese writing. The dataset consists of erroneous Chinese sentences from a textbook, and the study explicitly addresses the need for Chinese grammar checking and L2 Chinese writing, not English.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT-3.5 and ChatGPT-4.0 (LLMs) to generate automated corrective feedback for L2 Chinese writing, comparing model versions and prompt languages. This is an LLM-based intervention in writing-related tasks, albeit not with human learners directly involved.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is writing-focused: automated corrective feedback for L2 Chinese writing, with evaluation of grammaticality, fluency, and feedback quality. The primary concern is writing error correction, not general language skills or pure system evaluation unrelated to writing.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcome metrics such as grammaticality, fluency, minimal alterations, over-correction, correctness, understandability, and detail of feedback, rated by teachers. These are measurable outcomes of the LLM-generated corrective feedback.""
    }
}"
433,Using an Ai-powered Chatbot for Improving L2 Korean Grammar: a Comparison between Proficiency Levels and Task Types,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are L2 Korean learners, not L2 English learners. The abstract explicitly states the study is about using an AI chatbot (Iruda) in L2 Korean teaching to improve Korean lexico-grammar, and it is framed as work on a less commonly taught language, not English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The tool is described as an AI-powered chatbot (Iruda), but the abstract does not specify whether it is based on a large language model or transformer-based generative model. It could be rule-based or another AI architecture; this cannot be determined from the abstract alone.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on improving Korean lexico-grammar and grammar test performance (selected-response and constructed-response tasks), not on writing competence in English. While constructed-response tasks include sentence composition, the context is grammar instruction in Korean, not L2 English writing intervention.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study reports quantifiable outcomes (item mean differences on grammar test items) and uses t-tests, regression, and ANOVAs. However, these outcomes relate to Korean grammar performance, not English writing outcomes, so they do not meet the review’s required focus on L2 English writing metrics.""
    }
}"
434,Interacting with Chatgpt in Essay Writing: a Study of L2 Learners’ Task Motivation,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are L2 learners writing English argumentative essays at a public university in a non-English-speaking country, which fits an EFL/ESL/ELL context focused on English.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study involves interacting with ChatGPT 4.0 (an LLM) as part of an experimental design to support L2 essay writing, which qualifies as an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly L2 English essay (argumentative) writing, and ChatGPT is used as a tutor/support tool in the writing process, aligning with a focus on writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract states the study explored effects on learners’ motivation and reports positive lasting effects on motivation, with no mention of quantitative writing performance or other objective writing outcome measures. The primary measured outcome is task motivation, not writing quality or competence.""
    }
}"
435,Empowering Dialogic Feedback in Flw with Llm,2025,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to foreign/second language (L2) writing and L2 learners but does not specify that the target language is English or that the context is ESL/EFL/ELL. The population could involve any L2, so it is unclear whether it fits the English-focused inclusion criterion.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly proposes leveraging large-language models (LLMs) to facilitate dialogic feedback in L2 writing, including creating an AI-writing tool and testing its effectiveness through experimental sessions. This indicates an LLM-based intervention with an experimental component.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 writing instruction and feedback, aiming to enhance editing, rewriting, and overall writing development. The intervention is pedagogical, centered on feedback practices in writing, not on automated scoring or non-instructional evaluation.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that the study will test the effectiveness of the AI-writing tool and understand its impact on L2 learners' writing progress, as well as perceptions and interaction patterns. However, it does not explicitly state that quantifiable writing outcome metrics will be reported, leaving uncertainty about whether measurable writing gains are assessed.""
    }
}"
436,Exploring Efl Students’ Prompt Engineering in Human–ai Story Writing: an Activity Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'English as a foreign language (EFL) students' who are Hong Kong secondary school students, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""Students 'created their own generative-AI tools using open-source language models and wrote short stories with them.' These are generative LLM-based tools integrated into the writing process, satisfying the LLM intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is 'short story writing' and the study focuses on how students prompt generative AI during story writing, which is directly related to writing processes and competence rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports thematic findings about purposes for prompting and characteristics of activity systems (e.g., sophistication of tools, quality of stories, school achievement level) but does not indicate any experimental or quasi-experimental design, control/comparison, or quantifiable writing outcome metrics assessing effectiveness of the LLM-mediated intervention. It appears exploratory/qualitative rather than an outcome-focused intervention study.""
    }
}"
437,Ai-assisted Feedback in Clil Courses as a Self-regulated Language Learning Mechanism: Students’ Perceptions and Experiences; Retroalimentación Asistida Por Ia En Cursos Clil Como Mecanismo De Aprendizaje Autorregulado De Idiomas: Percepciones Y Experiencias De Estudiantes,2025,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are university students in a business CLIL (Content and Language Integrated Learning) course, which strongly suggests they are L2 learners, but the abstract does not explicitly state that they are L2 English learners or that English is the target language. The title and abstract are bilingual (English/Spanish), adding ambiguity about the target language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT, explicitly named, as an AI tool to provide criteria-based feedback on weekly writing compositions in a 15-week course. This is an instructional intervention integrating an LLM into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is a Data Description writing course where students write weekly compositions and receive AI-assisted feedback on writing (content clarity, grammar, vocabulary). The primary focus is on improving writing skills and linguistic proficiency, not on automated scoring or system evaluation alone.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study analyzes a coded sample of 336 compositions to evaluate linguistic enhancement and reports ‘significant improvement in content accuracy and linguistic proficiency,’ indicating quantifiable writing outcome measures beyond perceptions.""
    }
}"
438,Empowering Efl Learners: Assessing the Ai Brainstorming Tools' Impact on Essay Writing Proficiency,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are thirty Saudi EFL learners enrolled in English departments, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses an AI brainstorming tool (AYOA). The abstract does not indicate that AYOA is a large language model or transformer-based generative model (e.g., ChatGPT, GPT-4). It appears to be a general AI/brainstorming tool rather than an LLM-based writing assistant, so it does not meet the LLM-specific intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on essay writing proficiency: learners brainstorm ideas (with or without AI) and then write essays based on those ideas. The primary outcome is writing performance, fitting the writing competence context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an experimental design with control and experimental groups and reports that the experimental group showed better performance in essay writing, indicating quantifiable writing outcome metrics were used.""
    }
}"
439,Efl Teachers and Feedback Fatigue: Ai to the Rescue?,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses L2 writing and feedback in general but does not specify the learner population, target language (English), or context (ESL/EFL/ELL). It appears to be a conceptual or discussion paper rather than an empirical study with a defined participant group.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper \""looks at the contribution of Automated Writing Evaluation (AWE) programmes and Generative Artificial Intelligence (GenAI) to feedback\"" in a general, discursive way. There is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT, GPT-4) into instruction; it appears to be a conceptual or reflective piece.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus is on feedback in L2 writing, the article is framed as a discussion of potential benefits, teacher roles, and claims about automation, not as a pedagogical intervention study with implemented LLM-based writing activities.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or empirical evaluation. It raises questions about whether AI can improve writers and not just texts, but does not report data or structured intervention outcomes.""
    }
}"
440,Cognitive Load Scale for Ai-assisted L2 Writing: Scale Development and Validation,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to 'L2 writing' and 'second language (L2) composition' but does not specify that participants are L2 English learners (ESL/EFL/ELL) or that the target language is English. The specific language context is not stated.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on developing and validating the Cognitive Load Scale for AI-assisted L2 Writing. It does not describe an experimental or quasi-experimental pedagogical intervention integrating a specific LLM (e.g., ChatGPT, GPT-4) into instruction; rather, it is a measurement instrument development study about cognitive load in human-AI collaborative writing.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is AI-assisted L2 writing, the primary focus is on cognitive load measurement and scale validation, not on improving writing competence or writing-related performance through an instructional intervention. The study advances theory and measurement, not a writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are psychometric properties of the scale (factor structure, internal consistency, criterion-related validity via correlations with anxiety, self-efficacy, and mental effort). No quantifiable writing performance outcomes (e.g., writing quality scores, accuracy, complexity) are reported to assess effectiveness of an LLM-mediated writing intervention.""
    }
}"
441,Chatgpt Affordance for Logic Learning Strategies and Its Usefulness for Developing Knowledge and Quality of Logic in English Argumentative Writing,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 40 EFL university students, indicating second language English learners in an EFL context, with outcomes focused on English argumentative writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study developed a GPT-4-based logic learning bot (ChatGPT-based) and engaged students in learner-bot conversations as part of a structured logic learning intervention, satisfying the requirement for an LLM-mediated instructional design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly English argumentative writing, focusing on developing knowledge and quality of logic in that writing through ChatGPT-based logic learning strategies, which is a writing-related pedagogical intervention rather than mere scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Effectiveness is evaluated via pre-post knowledge tests and essay writing tasks, and the abstract reports that ChatGPT-based strategies significantly developed knowledge and quality of logic in English argumentative writing, indicating quantifiable writing outcome metrics.""
    }
}"
442,Exploring the Effectiveness of a Ddl-genai Teaching Mode in Students’ Efl Writing Classroom,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 75 second-year Chinese university students in an EFL context, and the focus is explicitly on EFL student expository writing, i.e., English as the target language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental design with three instructional modes, including a GenAI class and an integrated DDL-GenAI class. GenAI here refers to generative AI, which in current educational writing contexts is typically implemented via LLM-based tools, and it is explicitly integrated into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL expository writing and writing instruction. The intervention is a teaching mode (DDL-GenAI) in the EFL writing classroom, aiming to enhance writing performance and related variables such as structure, content quality, efficiency, and engagement.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that the DDL-GenAI mode ‘significantly improved students’ writing performance’ with notable improvements in structure and content quality, indicating quantifiable writing outcome measures were collected and analyzed, alongside other data sources.""
    }
}"
443,"Longitudinal Comparison of Ai, Exemplar, and Teacher Feedback for Sustainable L2 Writing Development: a Latent Growth Curve Analysis",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 181 Chinese L2 learners, clearly indicating L2 English learners in an EFL context. The focus is on L2 writing development, which in this journal context typically refers to English; no other target language is mentioned.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study compares Generative AI-generated feedback (AF) with exemplar-based feedback and traditional teacher feedback. AF is explicitly described as using GAI tools, implying a generative AI/LLM-based feedback intervention integrated into writing instruction over 12 weeks in an experimental design with three conditions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is L2 writing development and writing performance under different feedback modalities. The intervention is pedagogical (feedback on writing) rather than system evaluation or automated scoring, aligning directly with writing competence and development.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study models developmental trajectories in writing performance using latent growth curve analysis, examining initial proficiency and growth rates. It reports quantifiable writing proficiency outcomes and comparative effectiveness of AF, EF, and TF over time.""
    }
}"
444,"Ai Feedback Literacy in Higher Education: Understanding, Measuring, and Predicting Student Feedback Uptake",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL university students (“EFL learners’ ability…”, “data from 486 university students”), so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on developing and validating a psychometric scale of AI feedback literacy and examining predictors of AI feedback uptake. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction; AI tools are treated as a context, not as a structured instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on AI feedback literacy, motivational variables, and feedback uptake, not on writing competence or writing-related performance outcomes. It is about how students engage with AI-generated feedback rather than an intervention targeting writing development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports psychometric properties and predictive relationships (e.g., AIFL predicting feedback uptake), but does not report quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity) resulting from an LLM-mediated writing intervention.""
    }
}"
445,Does Metalinguistic Explanation of Teacher and Chatgpt Feedback Improve Efl Learners’ Writing Quality and Engagement? Findings from an Intervention Study,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL learners (foreign language writing instruction context), indicating L2 English learners in an EFL setting. The focus is on English writing quality and engagement.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is a quasi-experimental intervention examining scaffolded metalinguistic explanations of teacher and ChatGPT feedback. ChatGPT is a large language model integrated into the writing feedback process as part of the instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on foreign language writing instruction, specifically how feedback (from teacher and ChatGPT) affects EFL learners’ writing quality and engagement. This directly targets writing competence and writing-related variables, not automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pre-tests and post-tests, written drafts, and reports significant improvements in writing performance (grammatical accuracy, vocabulary use, mechanical control) and feedback incorporation. These are quantifiable writing outcome metrics within an intervention design.""
    }
}"
446,Exploring Feedback Literacy in L2 Students’ Academic Writing: Insights from Their Reported Engagement with Genal for Typical Revision Activities,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are described as “16 L2 Chinese graduate students.” The abstract does not indicate that they are learning English, nor that the writing context is ESL/EFL/ELL with English as the target language. The focus appears to be on Chinese L2 learners, not clearly on L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study involves L2 students’ engagement with GenAI tools such as DeepSeek and ChatGPT, which are LLM-based, for grammar correction, linguistic refinement, and logical optimization in academic writing. This constitutes integration of LLMs into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is L2 academic writing, with GenAI used for feedback on grammar, refinement, and coherence. The focus is on feedback literacy in writing, not on automated scoring or non-pedagogical evaluation of LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses surveys, interviews, and reflective reports to explore perceptions of feedback literacy (cognitive, behavioral, affective, ethical). The abstract reports no experimental or quasi-experimental design, no control/comparison, and no quantifiable writing outcome measures (e.g., writing scores, quality ratings, error counts). Outcomes are primarily qualitative perceptions.""
    }
}"
447,A Translanguaging Perspective on Students’ Use of Generative Artificial Intelligence in L2 Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as Chinese multilingual undergraduates engaged in L2 writing, implying they are L2 English learners using generative AI for L2 (English) writing tasks.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to ‘Generative artificial intelligence (GAI)’ and ‘GAI-assisted L2 writing’ but does not specify whether the tools are large language model–based systems such as ChatGPT or GPT-4. However, the broader description suggests contemporary GAI tools likely based on LLMs, though not explicitly named.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is framed as an exploration of how students use GAI in naturalistic L2 writing contexts from a translanguaging perspective. It is not an instructional intervention; rather, it is an observational, qualitative study of usage patterns and stances, without a designed pedagogical treatment or experimental manipulation focused on writing instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Data sources are screen recordings, reflective journals, and semi-structured interviews analyzed thematically. The abstract reports patterns of use and stances but does not mention any quantitative or experimental writing outcome measures (e.g., scores, accuracy, complexity) to assess effectiveness of GAI-mediated writing intervention.""
    }
}"
448,Demystifying Large Language Models in Second Language Development Research,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on Chinese L2 learners’ English writing development and compares L2 and L1 writing, clearly situating the population as L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""LLMs are used to develop an automatic assessment metric (LLM-Surprisal) and an NLP pipeline, not as an instructional or intervention tool integrated into learners’ writing processes. There is no experimental or quasi-experimental pedagogical intervention using LLMs with learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automatic writing assessment and computational metrics (LLM-Surprisal) to study L2 development, not on a teaching/learning context aimed at improving writing competence through LLM-mediated instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports how LLM-Surprisal relates to human scores and L2 development stages, but these are not outcomes of an LLM-based writing intervention. There is no experimental manipulation of LLM use in instruction or writing tasks with pre/post or comparative writing outcome measures.""
    }
}"
449,Flow in Chatgpt-based Logic Learning and Its Influences on Logic and Self-efficacy in English Argumentative Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 40 Chinese university English-as-a-foreign-language (EFL) students, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a ChatGPT-based environment (an LLM) for learning, with students engaging in tasks and receiving instant feedback. This constitutes an LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary instructional focus is on ‘developing logic in English argumentative writing’ and examining flow, logic understanding, and self-efficacy. While writing is involved, the intervention targets logic learning and flow rather than writing competence or writing-related performance variables as the main outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are understanding of argumentative writing logic and writing self-efficacy. The abstract does not indicate quantifiable measures of writing performance/quality (e.g., scores on essays), but rather cognitive (logic) and affective (self-efficacy, flow) outcomes, so it does not meet the requirement for quantifiable writing outcome metrics.""
    }
}"
450,"Metacognitive Strategies, Ai-based Writing Self-efficacy and Writing Anxiety in Ai-assisted Writing Contexts: a Structural Equation Modeling Analysis",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners, and the focus is explicitly on English writing and related affective variables (writing anxiety) in AI-assisted writing contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is correlational/SEM-based using questionnaires about metacognitive strategies, AI-based writing self-efficacy, and writing anxiety. There is no indication of an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into instruction or writing processes; AI is only the contextual background for self-report measures.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary outcome is writing anxiety, not writing competence or performance. The study examines psychological constructs (metacognitive strategies, AI-based writing self-efficacy, anxiety) rather than implementing or evaluating a pedagogical writing intervention using LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing performance or competence metrics are reported. Outcomes are questionnaire-based measures of strategies, self-efficacy, and anxiety, without experimental measures of writing quality or other writing-related performance variables.""
    }
}"
451,Chatbots or Cheatbots? University Students’ Uses of Ai Literacy Tools across Four Nations,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are undergraduate and graduate students in English-medium programs across India, Indonesia, Morocco, and the US, implying many are L2 English users in ESL/EFL/ELL contexts. The focus is on their use of LLMs for English literacy (reading, writing, learning).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a cross-case analysis of first-person accounts of how students use LLMs such as ChatGPT. There is no experimental or quasi-experimental design, nor a structured pedagogical intervention integrating LLMs; it is descriptive/reflective rather than an intervention study.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing is a key focus: students report using LLMs for brainstorming ideas, learning to write more complex and precise sentences, and revising prompts to fine-tune their writing. The context is second-language literacy instruction, including writing-related uses.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative accounts of opportunities and challenges and discusses implications. It does not mention any quantifiable writing outcome metrics or measured changes in writing performance resulting from LLM use.""
    }
}"
452,Developing L2 Postgraduate Students’ Strategic and Responsible Use of Genai through a Purposefully Designed Workshop in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as L2 postgraduate students facing challenges in academic writing, indicating a second language English academic writing context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The workshop uses “a diverse range of GenAI tools” and focuses on GenAI use in academic writing. However, the abstract does not specify that these are large language models (e.g., ChatGPT, GPT-4) as opposed to other GenAI tools, nor does it clearly describe an experimental or quasi-experimental design beyond pre/post questionnaires.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The workshop is explicitly about academic writing, covering stages from brainstorming and literature searching to revising and ethical considerations, and is clearly pedagogical rather than an evaluation of automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are enhanced technology proficiency, critical evaluation skills, ethical competence, and AI agency based on pre- and post-workshop questionnaires. No quantifiable writing performance or writing quality metrics are mentioned; the focus is on attitudes/skills related to GenAI use rather than measurable writing outcomes.""
    }
}"
453,Ai-powered Feedback in Second Language Writing: a Systematic Scoping Review of Technological Innovations in Digital Language Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “second language (L2) writing instruction” and “L2 learners” but does not specify that the target language is English or that the context is ESL/EFL/ELL. It may include multiple target languages, so it is unclear whether data are focused on English L2 learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a “systematically reviews empirical research” and “A systematic review was conducted following PRISMA guidelines.” It is a review of AI-driven feedback systems, not an experimental or quasi-experimental primary study integrating LLMs into instruction. Review articles are to be excluded.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on “AI-driven feedback systems in second language (L2) writing instruction” and their effectiveness in improving writing proficiency (grammar, vocabulary, coherence, argumentation). This aligns with a primary focus on writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract notes that the review examines effectiveness and reports that AI-powered feedback systems are effective in enhancing certain writing skills, but as a secondary synthesis it does not itself report primary experimental outcome measures. The inclusion criterion requires primary studies with quantifiable writing outcomes, whereas this is a systematic review.""
    }
}"
454,"Poe or Gemini for Fostering Writing Skills in Japanese Upper-intermediate Learners: Uncovering the Consequences on Positive Emotions, Boredom to Write, Academic Self-efficacy and Writing Development",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 519 Japanese upper-intermediate EFL learners. The context is clearly English as a Foreign Language, and the focus is on English writing skills and related affective variables.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention integrates AI-based platforms Poe and Gemini into writing instruction, with two experimental groups (Poe-assisted and Gemini-assisted writing instruction) and a control group receiving traditional instruction. Both Poe and Gemini are LLM-based tools, and the design is experimental with random assignment.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on fostering writing skills and writing development, along with related constructs (positive emotions, boredom to write, academic self-efficacy). The AI tools are used pedagogically within writing instruction, not merely for automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing development is explicitly assessed through pre- and post-tests, and outcomes are quantitatively analyzed using ANOVA and MANOVA to compare groups. Thus, the study reports quantifiable writing outcome metrics for the LLM-mediated intervention.""
    }
}"
455,A Skill-specific Perspective on Ai-mediated Informal Digital Learning of English (ai-idle): Examining the Contributing Roles of L2 Writing Motivation and Enjoyment,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 412 Chinese university students engaged in informal digital learning of English, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study concerns AI-mediated informal digital learning, it is not described as an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction. It is a correlational/motivational study using questionnaires and interviews about AI-IDLE-W, not an LLM-based instructional treatment.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on motivational and affective constructs (L2 writing future selves, enjoyment) related to AI-mediated informal learning, not on a defined writing instruction or process intervention. It examines psychological mechanisms rather than implementing and evaluating a concrete writing pedagogy using LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing performance outcomes are reported. The quantitative data concern motivation, enjoyment, and AI-IDLE-W engagement, not measurable changes in writing competence or writing quality following an LLM-mediated intervention.""
    }
}"
456,Generative Ai and L2 Written Feedback Studies: a Scoping Review,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract indicates that the included primary studies involve L2 contexts and writing, but this article itself is a scoping review synthesizing 51 studies. It does not report on a single primary population of L2 English learners; instead, it aggregates prior work with varied L2 foci.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a PRISMA-informed scoping review of 51 studies on GenAI-written feedback. It does not itself implement an experimental or quasi-experimental LLM-based writing intervention; rather, it summarizes others’ interventions.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the topic is GenAI-influenced written feedback and writing quality, the paper’s primary purpose is to map and synthesize existing studies, not to conduct a pedagogical intervention or original empirical study focused on writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports that the review summarizes findings such as improvements in writing quality, perceptions, and revision behaviors, but it does not present original, quantifiable writing outcome metrics from a new LLM-mediated intervention. As a review article, it falls under the exclusion criteria for non-primary research.""
    }
}"
457,Embrace or Resist? Efl Teachers on Adopting Chatgpt as a Teaching and Feedback Tool,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The participants are 301 Iranian EFL teachers, not L2 English learners. The focus is on teachers’ perceptions and practices, not learner outcomes.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the study uses a questionnaire about perceptions and reported practices. There is no experimental or quasi-experimental design integrating ChatGPT into actual writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is teachers’ attitudes toward using ChatGPT for L2 instruction, writing, and feedback. It does not implement or evaluate a concrete writing intervention; it is attitudinal rather than pedagogical-outcome focused.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes are reported. The study analyzes questionnaire factors and background variables related to teacher perceptions and practices, not changes in students’ writing performance.""
    }
}"
458,Designing Chatgpt-mediated Feedback Activities in Efl Writing: a Design-based Study of the Dialogic Feedback Triangle,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study involves four EFL learners in GenAI-assisted English as a Foreign Language writing, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""ChatGPT, an LLM, is integrated as a formative feedback provider and interactive partner in EFL writing. The study is explicitly about designing ChatGPT-mediated dialogic feedback activities, which constitutes an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing, focusing on ChatGPT-mediated feedback during writing processes and dialogic feedback, which is directly related to writing competence and writing instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes a design-based research approach with data from observations and interviews about writing experiences and feedback on the intervention. It reports identification of design elements and principles, but does not mention any quantitative or experimental writing outcome measures (e.g., writing scores, accuracy, complexity). Outcomes are qualitative and design-oriented rather than quantifiable writing performance metrics.""
    }
}"
459,"Evaluating the Effectiveness of Ai Tools across the Essay Writing Process: a Comparative Study of Pre-writing, Drafting, and Post-writing Stages",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a Foreign Language learners at Arab Open University, Kuwait, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that the experimental group used 'AI tools' across the writing process but does not specify whether these are large language model-based tools (e.g., ChatGPT, GPT-4) or other non-LLM AI tools (e.g., grammar checkers). Without explicit mention of LLMs or transformer-based generative models, it is unclear if the intervention meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on the essay writing process (pre-writing, drafting, post-writing) and on students’ writing performance, indicating that the primary context is writing competence rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an experimental design with pre- and post-tests and reports statistically significant differences in writing performance between experimental and control groups, indicating quantifiable writing outcome metrics.""
    }
}"
460,Incorporating Ai-administered Personalized Feedback in an Inquiry-based Learning Efl Writing Class,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as EFL learners: 95 female undergraduate native speakers of Arabic in an academic writing class. The context is clearly English as a Foreign Language, with writing in English as the target skill.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses ChatGPT-3.5, a large language model, to provide personalized feedback on students’ essays via the prompt “correct my grammar.” This is integrated into the course as part of the writing process over a semester, constituting an LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL academic writing: students complete four essays, receive AI-administered feedback, and engage in reflections to improve future writing. Outcomes discussed are essay-writing grades and grammar sub-scores, clearly tied to writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: higher essay-writing grades on a handwritten final exam and grammar sub-scores are statistically related to completion of reflections following AI feedback. These provide measurable effects of the LLM-mediated intervention on writing performance.""
    }
}"
461,Non-academic Learner Socialisation with Chatgpt and Its Influences on Learning English Argumentative Writing Logic,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 40 EFL university students learning English argumentative writing. The context is clearly English as a foreign language, with outcomes tied to English argumentative writing logic.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study developed a GPT-4-powered bot (an LLM-based tool) for learning English argumentative writing logic. Learners used it in a structured session (45–75 minutes), indicating an experimental instructional intervention integrating an LLM into the writing learning process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on English argumentative writing, specifically on learning outcomes such as logical knowledge and logical quality in English argumentative writing. The LLM is used pedagogically, not merely for automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports pre–post tests, writing tasks, and questionnaires to assess learning outcomes, including logical knowledge, logical quality, and self-efficacy in English argumentative writing. These constitute quantifiable writing-related outcome measures within an intervention framework.""
    }
}"
462,Genai-assisted Critical Reading Report Revision: a Mixed-methods Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described only as 22 postgraduate students and L2 learners engaged in critical reading and writing. The abstract does not explicitly state that they are L2 English learners in ESL/EFL/ELL contexts or that the target language is English, though it is likely. This cannot be confirmed from the abstract alone.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses “GenAI tools” and mentions “interactions with the chatbot” and “GenAI-generated critical reading reports,” which suggests but does not explicitly confirm the use of LLM-based tools (e.g., ChatGPT). The specific technology (LLM vs. other AI) is not identified in the abstract.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on critical reading and writing dimensions and student engagement patterns during revision, not on writing competence as an outcome. The study examines which dimensions receive engagement and the factors influencing selective engagement, emphasizing critical thinking and agency rather than a pedagogical writing intervention aimed at improving writing performance.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports engagement patterns across dimensions (e.g., research aims, contributions, quality of evidence) using lag sequential and thematic analysis, but does not indicate any quantifiable writing outcome metrics (e.g., writing scores, quality ratings, accuracy, complexity) to assess effectiveness of the GenAI-supported revision. It focuses on process/engagement, not measured writing gains.""
    }
}"
463,"Ai-generated, L2 Learner, and Native German Writing: a Comparative Analysis of Linguistic Complexity",2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on German argumentative essays and compares texts by ChatGPT, DeepSeek, L1 speakers, and L2 learners of German. The target language is German, not English, so it does not meet the population/language focus requirement on L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study analyzes texts generated by LLMs (ChatGPT, DeepSeek), there is no indication of an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or learner writing processes. It is a comparative linguistic analysis, not an instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on linguistic complexity and formality of AI-generated vs. human-authored German essays. While pedagogical implications are discussed, there is no actual writing instruction context or intervention being implemented or evaluated.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study does not report quantifiable writing outcome measures for learners following an LLM-mediated intervention. It compares linguistic features of existing texts rather than assessing changes in learner writing performance due to an LLM-based instructional treatment.""
    }
}"
464,Experiences of Esl Students and Instructors Using Grammarly in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are English as a second language (ESL) graduate students at a Malaysian public university, clearly fitting an L2 English learner population in an ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention tool is Grammarly, described as an AI writing assistant. Grammarly is not an LLM-based, transformer generative model like ChatGPT or GPT-4; it is a separate class of AI tool and is explicitly listed in the exclusion examples. Therefore, it does not meet the LLM-based intervention requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on academic writing, formative assessment, and feedback for ESL students’ writing, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Data were collected through semi-structured interviews and focus groups, and the abstract reports perceived improvements (motivation, engagement, proficiency) but does not indicate any experimental or quasi-experimental design with quantifiable writing outcome metrics. The outcomes are qualitative perceptions rather than measured writing performance.""
    }
}"
465,Tracking the Effects of Gemini as a Genai Tool on L2 Learners’ Writing Proficiency and Anxiety: Latent Growth Curve Modeling Approach,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 274 undergraduate English learners in Iran enrolled in academic writing classes. The context is clearly L2 English (EFL) learners, and the focus is on English writing proficiency and anxiety.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is GenAI-assisted instruction using Gemini, a large language model, compared to traditional instruction. Learners in the treatment group received Gemini-mediated support during a 16-week course, indicating an experimental design integrating an LLM into instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 writing competence and writing-related affective variables (writing proficiency and writing anxiety) within academic writing classes. Gemini is used pedagogically to provide tailored, immediate feedback in writing instruction, not merely for automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: writing proficiency measured via a standardized rubric-based assessment and writing anxiety via an L2 writing anxiety scale. Results include specific statistics (MD, SE, CR, p-values), demonstrating measured intervention effects.""
    }
}"
466,"Comparing the Effects of Teacher- and Ai-mediated Corrective Feedback on Accuracy, Complexity, and Quality in L2 Written Narratives",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 166 upper-intermediate ESL undergraduates in international writing classes at a U.S. university. The context is clearly L2 English (ESL).""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that 86 students received 'AI-mediated WCF' and refers to 'generative artificial intelligence (AI)', but it does not specify whether the AI system is a large language model (e.g., ChatGPT/GPT-4 or another transformer-based generative model) versus another type of AI feedback tool. Without the tool being named or its architecture described, it is unclear if an LLM is used.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on written corrective feedback in L2 narrative writing and examines effects on complexity, accuracy, and quality of L2 written narratives. This is clearly a writing-focused pedagogical intervention, not just automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: changes in accuracy (error reduction), lexical and syntactic complexity (e.g., T-unit length, subordination, coordination, nominalization), and writing quality (conventions and overall scores) between pre- and post-revision drafts across teacher vs. AI feedback groups.""
    }
}"
467,"Artificial Intelligence in Language Education: a Systematic Review of Multilingual Applications, Large Language Models, and Emerging Challenges",2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a broad systematic review of AI in language education across multilingual settings. It does not focus specifically on L2 English learners in ESL/EFL/ELL contexts; instead, it covers multiple languages, including low-resourced and marginal languages in general.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a review article synthesizing 161 studies and discussing various AI tools (conversational agents, speech recognition, writing assistants, LLMs like Aya and LLaMA). It does not itself implement an experimental or quasi-experimental LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is broad AI use in language education (anxiety reduction, pronunciation support, real-time feedback, mobile learning, gamification, ethics, infrastructure). Writing is only one of several skills mentioned and not the central focus of the review.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic review, it does not report original experimental writing outcome metrics from an LLM-mediated intervention; instead, it summarizes prior work and discusses gaps and implications at a high level.""
    }
}"
468,Efl Teachers’ Inquisitive Agency in Ai-enhanced Writing Instruction,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The participants are twelve Indonesian EFL teachers. The abstract does not specify that data are collected from L2 English learners or that learner outcomes are analyzed; the focus is on teachers’ practices, not learners as participants.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study concerns integration of AI tools in EFL writing instruction, it does not specify that these are large language models (e.g., ChatGPT, GPT-4). It focuses on teachers’ agency in exploring and adapting unspecified AI technologies, with no clear indication of LLM-based intervention or experimental/quasi-experimental design.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on teacher inquisitive agency, resource exploration, and professional development in AI-enhanced writing instruction, not on learners’ writing competence or writing-related variables as outcome measures. It is a pedagogical/teacher practice study rather than a writing competence intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses qualitative methods and reports thematic categories about teacher practices. There is no mention of quantifiable writing outcome metrics or experimental measures of students’ writing performance resulting from AI/LLM-mediated interventions.""
    }
}"
469,Evaluating the Performance of Chatgpt and Claude in Automated Writing Scoring: Insights from the Many-facet Rasch Model,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 117 English as a Foreign Language (EFL) students in China, clearly an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT and Claude are used as automated writing scorers (LLM-based raters). There is no indication of an instructional or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or writing processes; the focus is on scoring performance.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is automated writing scoring (AWS) and comparison of LLM raters with human raters using Many-Facet Rasch Model. It evaluates rater severity, consistency, and bias, not writing competence or writing-related learning outcomes, and there is no pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports metrics on scoring behavior (severity, consensus, consistency, gender bias) of LLMs versus human raters. It does not report quantifiable writing outcome measures assessing the effectiveness of an LLM-mediated writing intervention on learners’ writing performance.""
    }
}"
470,Genai Image Creation in Efl: Prompt Writing as an Emerging Writing Activity for Sustainability-focused Artivism,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 21 preparatory-year students in an EFL setting at a university in Northern Cyprus, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses GenAI image generation with English prompt writing, but the abstract does not specify that the GenAI system is a large language model (e.g., ChatGPT, GPT-4). It focuses on AI image generation, not an LLM-based writing assistant or transformer-based generative text model.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is sustainability awareness and artivism via image creation; writing is limited to prompt writing and descriptive texts as language practice. The study emphasizes qualitative experiences, confidence, and sustainability awareness rather than systematic development of writing competence as the main outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as a qualitative descriptive study with thematic analysis. Reported outcomes include perceived gains in writing confidence and strategy use, but there is no mention of quantifiable writing outcome metrics (e.g., pre/post writing scores, rubric-based assessments).""
    }
}"
471,"Lexical Diversity, Syntactic Complexity, and Readability: a Corpus-based Analysis of Chatgpt and L2 Student Essays",2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions a corpus of 50 student essays and notes implications for L2 learners, but it does not explicitly state that the 50 student essays are written by L2 English learners in ESL/EFL/ELL contexts. The learner population is therefore not clearly defined as L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares AI-generated texts via ChatGPT with student-written essays using corpus-based measures. There is no indication of an experimental or quasi-experimental pedagogical intervention where LLMs are integrated into writing instruction or writing processes; ChatGPT is only a source of comparison texts.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on textual features (lexical diversity, syntactic complexity, readability) of ChatGPT vs. student essays, not on an instructional context or intervention aimed at improving writing competence. It is an analytic comparison, not a pedagogical study of writing development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although quantitative measures (TTR, MLT, readability indices) are reported, they are used to compare ChatGPT output and student essays, not to evaluate the effectiveness of an LLM-mediated writing intervention on learners’ writing outcomes over time or across conditions.""
    }
}"
472,Factors Affecting Efl Students’ Behavioral Intention to Use Ai in Efl Writing Development,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 415 Chinese university students using AI for English as a Foreign Language (EFL) writing development, clearly an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a cross-sectional survey to investigate behavioral intention to adopt AI; there is no experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into actual writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is technology acceptance (behavioral intention, attitudes) toward AI in EFL writing, not on implementing a writing intervention or instructional use of LLMs to develop writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes are psychological/behavioral (e.g., performance expectancy, attitude, intention), not measures of writing performance or related skills after an AI-mediated intervention.""
    }
}"
473,A Case Study of Applying Grammarly for Mastering Pre-service Teachers' Writing Skills,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are university students majoring in English at Pavlo Tychyna Uman State Pedagogical University (Ukraine), i.e., L2 English learners in an EFL/ESL context. The focus is on mastering English academic writing skills.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention tool is Grammarly. While described as AI-based, Grammarly is not an LLM-based, transformer-style generative model like ChatGPT, GPT-4, or Gemini. The review explicitly excludes tools such as Grammarly that do not utilize LLMs as the core intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on improving English academic writing skills, including pragmatic components of writing and language accuracy (grammar, vocabulary, spelling). Grammarly is integrated into the writing process to support these aspects.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions pre- and post-interviews to collect data on writing problems and refers to criteria for pragmatic components and language accuracy, but it does not clearly state that quantifiable writing outcome metrics (e.g., scores, error rates) were measured and analyzed. The outcomes are described in general terms (e.g., Grammarly enhances writing skills) without explicit quantitative results.""
    }
}"
474,Leveraging Chatgpt for L2 Writing: Teacher Cognition and the Impact of Professional Development,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are 11 EFL teachers working in L2 writing contexts, and the abstract mentions student writing with ChatGPT feedback, implying an English-as-a-foreign-language setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on teacher cognition and a professional development (PD) program about using ChatGPT. There is no indication of an experimental or quasi-experimental LLM-based writing intervention implemented with learners; ChatGPT is used as an object of teacher learning, not as a structured instructional treatment for students.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""While the context is L2 writing and feedback, the primary focus is on teacher beliefs and professional development, not on a pedagogical intervention aimed at improving learners’ writing competence. The study is conceptual/teacher-focused rather than an instructional trial of LLM-mediated writing support.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics for students (e.g., writing scores, complexity, accuracy, fluency). Outcomes are changes in teacher cognition and feedback literacy, not measured changes in learner writing performance.""
    }
}"
475,"Comparing Peer Feedback and Generative Artificial Intelligence Feedback in Japanese English as a Foreign Language Speaking Context: Impacts on Motivation, Engagement, and Writing Self-efficacy",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Japanese university students learning English as a Foreign Language (EFL), clearly an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study contrasts peer feedback with generative AI feedback using ChatGPT, a large language model, as part of an instructional intervention across semesters.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary context is speaking preparation; writing is limited to script-writing for speaking tasks. The main outcomes are motivation, engagement, and self-efficacy in a speaking context, not writing competence or writing-related performance variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports changes in motivation, engagement, ideal L2 self, and writing self-efficacy, but does not report quantifiable writing performance outcomes (e.g., writing quality, accuracy, complexity). Thus, it lacks measurable writing outcome metrics required for inclusion.""
    }
}"
476,Artificial Intelligence in Efl Writing Enhancement: a Study on Chatbot Feedback and Learner Autonomy,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on English as a Foreign Language (EFL) learners and their writing, which fits the target population of L2 English learners in EFL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the tool is described as an online AI chatbot using a transformer-based NLP system, it appears to be a feedback generator trained on ICLE essays, not a general-purpose large language model like ChatGPT/GPT-4. The description suggests a specialized NLP feedback system rather than an LLM-based generative model integrated as an instructional partner in the sense defined for this review.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on writing enhancement, with the chatbot providing feedback on grammar, vocabulary, and discourse-level characteristics, and on learner autonomy in writing. This aligns with a focus on writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantifiable writing outcomes are reported: changes in lexical diversity (MTLD), syntactic complexity (C/T), and cohesion in a simulated revision task, with findings of significant language gains among high-level learners.""
    }
}"
477,Guided or Guiding: Contradictions and Conflicts in Ai-assisted Second Language Writing for Efl Learners from the Activity Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a Foreign Language (EFL) learners engaged in second language writing, so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that learners are “engaging with artificial intelligence (AI) in second language writing” and discusses “AI-assisted writing practices,” but it does not specify that the AI is a large language model (e.g., ChatGPT, GPT-4) or describe the AI tool’s nature. It could be any AI-based support, not necessarily an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is clearly on second language writing practices and human–AI collaboration in writing, examining tensions between learning, assessment, and AI-assisted writing. Thus, the primary context is writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as a qualitative analysis of three EFL learners, focusing on contradictions, tensions, and resolution strategies. There is no mention of experimental or quasi-experimental design, nor of quantifiable writing outcome metrics; the outcomes are theoretical and qualitative (e.g., learner agency, resolution strategies).""
    }
}"
478,"Descriptive Writing Using Generative Ai as a Cognitive Scaffold in the Metaverse Environment: University Students’ Perceptions, Learning Engagement, and Performance",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were two undergraduate English as a foreign language (EFL) writing classes, clearly indicating L2 English learners in an EFL context, with a focus on English descriptive writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses a tool termed a “generative AI tool called ‘GAIscaffold’” as a cognitive scaffold. However, the abstract does not specify whether GAIscaffold is an LLM/transformer-based generative model (e.g., ChatGPT-like) or another form of generative AI. Without this detail, it is unclear if it meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL descriptive writing performance in a metaverse environment, using generative AI as a scaffold in the writing task. Outcomes include engagement and writing performance, aligning with writing competence–related variables rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative writing outcomes: final writing performance compared between experimental and control groups using MANCOVA, with statistically significant improvements in writing performance for the experimental group.""
    }
}"
479,Overview of the Clef 2025 Joker Task 1: Humour-aware Information Retrieval,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes an information retrieval task (JOKER-2025 Track) with English and Portuguese text collections. There is no mention of participants, learners, or L2 English learning contexts (ESL/EFL/ELL). It is a dataset/task overview, not a learner study.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on humour-aware information retrieval and dataset creation. It does not describe any experimental or quasi-experimental pedagogical intervention using LLMs (e.g., ChatGPT, GPT-4) in writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is humour-aware information retrieval and cross-linguistic humour detection, not writing competence or writing-related instructional variables. Any mention of potential use in writing or translation is speculative and not part of an educational intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No writing outcomes or metrics are reported. The paper reports dataset statistics and system runs for an IR task, without assessing effects on learners’ writing performance.""
    }
}"
480,Personalized L2 Argumentative Writing Instruction through Genai-enhanced Corpus-based Language Pedagogy: an Intervention Study,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are L2 learners engaged in IELTS Task 2 argumentative writing, which is an English proficiency exam context. The study explicitly focuses on L2 argumentative writing, implying L2 English learners in an EFL/ESL-type setting.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses GPT-4o (a large language model) to analyze learners’ essay corpus and generate individualized linguistic profiles, tailored writing tips, coherence/cohesion checks, vocabulary lists, and grammar exercises. This is an experimental design integrating an LLM into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 argumentative writing instruction and improvement. GenAI is used pedagogically to personalize writing instruction (tips, feedback, exercises) rather than for automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative results from IELTS writing tasks, showing significant differences between control and experimental groups in short- and long-term outcomes. These are clear, quantifiable writing outcome measures assessing the effectiveness of the LLM-mediated intervention.""
    }
}"
481,Postgraduate Students' Attitude Toward Using Chatgpt in Enhancing Their Master's Thesis: a Mixed Method Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as postgraduate EFL learners, indicating they are L2 English learners in an EFL context and the focus is on English thesis writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the study is not an experimental or quasi-experimental intervention. It investigates students’ attitudes and self-reported uses of ChatGPT rather than implementing and testing a structured LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on enhancing the quality of Master’s thesis writing, including content, structure, grammar, and citation, which are core writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses semi-structured interviews and a questionnaire to explore attitudes and perceived benefits. There is no indication of quantifiable pre/post or comparative writing performance measures assessing the effectiveness of ChatGPT on writing outcomes.""
    }
}"
482,Enhancing Argumentative Essay Skills: Evaluating the Efficacy of Ai-powered Tools Versus the Traditional Approach among Learners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly refers to “second language (L2) learners” and focuses on teaching argumentative essay writing, which is typically in English in such contexts, though the specific language is not named. This is reasonably consistent with an L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses “AI-powered writing tools like Quill Bot, Jeni AI, and others.” QuillBot is not an LLM-based pedagogical tool in the sense required (it is primarily a paraphrasing/rewriting tool and not framed here as an LLM such as ChatGPT, GPT-4, Gemini, etc.). The abstract does not indicate that any large language model is being integrated; it only mentions generic AI tools, which fall outside the specified LLM-focused scope.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on teaching and improving argumentative essay writing skills (“mentoring students to write argumentative essays,” “improved writing competency and the long-term retention of argumentative writing abilities”), which aligns with writing competence as the central outcome.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is described as a quasi-experimental design with experimental and control groups, and it reports that integration of AI-driven tools with conventional methods “significantly improved writing competency and the long-term retention of argumentative writing abilities,” implying quantitative outcome measures of writing performance over a semester.""
    }
}"
483,Leveraging Llm-based Chatbots for Interactional Grammar Feedback in L2 Writing: Opportunities and Challenges,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 89 second-year pre-service teachers at a university of education in South Korea who wrote English essays, indicating an EFL/L2 English context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The title and abstract state the study uses an ‘LLM-based chatbot’ and references ChatGPT, suggesting an LLM intervention. However, details on whether the chatbot is actually powered by a large language model (vs. rule-based or template-based) are not explicit in the abstract.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on L2 writing instruction and grammar feedback on students’ English essays, framed as ‘interactional writing feedback for L2 writing instruction’ in classrooms.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports that the chatbot ‘offers several advantages as a feedback provider’ and could be a complementary resource, but it does not mention any quantitative writing outcome measures (e.g., gains in writing accuracy, scores, or other measurable writing performance). The emphasis appears to be on showcasing practice and perceived advantages rather than experimentally measured writing outcomes.""
    }
}"
484,Chinese Efl Learners’ Genai Literacy in Digital Multimodal Composing and Self-regulated Writing: Chain Mediation Effects of Needs Satisfaction and Creative Self-concept,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 634 Chinese EFL learners, i.e., L2 English learners in an EFL context, satisfying the population criterion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines students’ GenAI literacy in digital multimodal composing via questionnaires and structural equation modeling. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes; it is a correlational/mediation study of literacy, not an LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing, focusing on digital multimodal composing and self-regulated writing, which are writing-related constructs rather than automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are self-report measures (GenAI literacy, needs satisfaction, creative self-concept, self-regulated writing) analyzed via SEM. The abstract does not report quantifiable writing performance outcomes or effectiveness of an LLM-mediated writing intervention; it focuses on psychological/behavioral constructs rather than measured writing quality or competence.""
    }
}"
485,Artificial Intelligence Vs. Instructor Supported Ai: Teaching Second Language Writing Via “write&improve”,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study investigates second language writing, focusing on students’ English writing success, self-efficacy, and related variables. This implies participants are L2 English learners in an ESL/EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses the Cambridge Write&Improve system. While it is an AI-based automated writing evaluation tool, it is not described as a large language model (e.g., ChatGPT/GPT-4-type transformer-based generative model). The abstract frames it as an AI feedback system, not an LLM-based generative tool integrated into instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on second language writing competence and related constructs (writing success, self-efficacy, achievement emotions, teacher-student interaction) within an instructional context using AI-supported feedback.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an 8-week pretest-posttest control group design and reports statistically significant increases in English writing success and other quantifiable outcomes, indicating measurable writing-related effects of the intervention.""
    }
}"
486,"International Conference on Artificial Intelligence and Networks, Icain 2024",2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract is for a conference proceedings volume listing many diverse papers. One title mentions EFL teachers and another mentions Indonesian higher education, but no specific participant details (e.g., L2 English learners) are provided for any individual study.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The proceedings description does not specify any experimental or quasi-experimental integration of large language models (e.g., ChatGPT, GPT-4) into writing instruction. One listed paper is about ‘AI-Enhanced Writing Instruction’ but the abstract provides no indication that LLMs specifically are used, nor any design details.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Among the 50 papers, only one title clearly relates to writing (‘EFL Teachers’ Inquisitive Agency in AI-Enhanced Writing Instruction’). However, the overall proceedings focus is broad AI and networks, not specifically writing competence, and no information is given about the pedagogical or writing-focused nature of that individual study.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The proceedings abstract does not report any quantifiable writing outcome metrics. It only lists paper titles without methodological or results information, so it is impossible to confirm the presence of experimental writing outcome measures for any included study.""
    }
}"
487,"Ai-assisted Academic Writing in a Blended Efl Setting: Practices and Perceived Effectiveness at Fpt University, Hanoi",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are first-year EFL students at FPT University Hanoi, clearly indicating L2 English learners in an EFL context, with outcomes reported in terms of IELTS writing scores (English).""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study involves AI tools including ChatGPT, QuillBot, and DeepSeek for writing support. ChatGPT and DeepSeek are LLMs, but QuillBot may or may not be LLM-based depending on version, and the abstract does not specify which tools were central to the intervention or how systematically LLMs (as opposed to generic AI tools) were integrated in an experimental or quasi-experimental design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on academic writing in an EFL setting, examining how AI tools are used for idea generation, grammar correction, and content refinement, and discussing AI’s pedagogical potential in EFL writing instruction. This aligns with writing competence and writing-related variables, not automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: writing scores improved by an average of 0.94 IELTS band scores, based on 45 paired writing samples. This indicates measurable effects of AI-assisted writing use, alongside qualitative perceptions.""
    }
}"
488,Large Language Model-driven Dynamic Assessment of Grammatical Accuracy in English Language Learner Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions 'learners of English' and 'English Language Learner writing', suggesting an ELL context, but it does not specify that participants are L2 English learners in ESL/EFL/ELL settings, nor does it clearly describe an actual learner sample versus simulated input.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study develops DynaWrite and tests 21 LLMs (with focus on GPT-4o and neural-chat) for their ability to provide dynamic assessment feedback and identify grammatical errors. The focus is on system performance and model comparison, not on an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction with learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on LLM-driven dynamic assessment capabilities (error detection, hint quality, responsiveness, stability), not on improving writing competence or writing-related learner outcomes. It evaluates tool functionality rather than a teaching/learning intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcome metrics are reported. The outcomes concern model accuracy in error identification, quality of hints, and system performance, not changes in learners’ writing performance following an LLM-mediated intervention.""
    }
}"
489,Prompt Engineering as Mediation: Investigating Ai Chatbot-assisted Writing Process from an Activity Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Chinese EFL undergraduates, i.e., L2 English learners in an EFL context, with a focus on English expository writing tasks.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to an “AI chatbot” and “chatbot-supported expository writing tasks,” but does not specify that the chatbot is an LLM (e.g., ChatGPT/GPT-4) or a transformer-based generative model. It could be any AI chatbot, so LLM use cannot be confirmed from the abstract alone.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly EFL expository writing, focusing on how prompt engineering mediates chatbot-assisted writing processes and outcomes, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions that prompt engineering shapes “writing outcomes,” it does not indicate any experimental or quasi-experimental design, comparison groups, or quantifiable writing outcome metrics. The study appears primarily qualitative (logs, artifacts, interviews) and theoretical, without measured intervention effects.""
    }
}"
490,The Role of Artificial Intelligence in Writing Assessment: Learner Perceptions and System Effectiveness,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions 'learners of varying educational levels' but does not specify that they are L2 English learners in ESL/EFL/ELL contexts. Their language background and whether English is an L2 is not stated.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on AI-driven writing tools such as Grammarly and Turnitin, which are not described as large language model (LLM)-based generative systems. There is no mention of ChatGPT, GPT-4, or other LLMs, nor of an experimental or quasi-experimental LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on writing assessment, learner perceptions, and system effectiveness (accuracy, fairness, clarity of feedback), not on a pedagogical writing intervention or instructional integration of LLMs. It evaluates an assessment tool rather than a structured teaching/learning intervention in writing.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports that regular usage 'significantly enhances writing skills, particularly in grammar,' but does not specify concrete, quantifiable writing outcome measures (e.g., pre/post test scores, rubric-based writing quality metrics). It is unclear whether rigorous experimental outcome data on writing performance were collected.""
    }
}"
491,The Potential Advantages of Using an Llm-based Chatbot for Automated Writing Evaluation for English Teaching Practitioners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Korean high school EFL students, i.e., L2 English learners in an EFL context: “narrative essays written by Korean high school EFL students.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study develops an AWE chatbot based on ChatGPT 4.0-turbo and uses it as an automated rater. There is no experimental or quasi-experimental pedagogical intervention integrating the LLM into writing instruction or learners’ writing processes; it is a tool validation study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the chatbot’s scoring reliability and alignment with human raters: “these were then compared with the scores administered by two professional raters using various analytic measures.” This is an automated essay scoring validation study, not a writing competence intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing scores are analyzed, they are used only to evaluate the AWE chatbot’s rating performance, not to assess the effectiveness of an LLM-mediated writing intervention. No pre/post or comparative instructional outcomes are reported.""
    }
}"
492,Development and Validation of a Multidimensional Chatgpt Feedback Engagement Scale in Second Language Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to 'second language (L2) writing' and 'students' but does not specify that the target language is English or that participants are ESL/EFL/ELL learners. The L2 could be any language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is present, but the study focuses on developing and validating a 'ChatGPT Feedback Engagement Scale.' There is no indication of an experimental or quasi-experimental pedagogical intervention integrating ChatGPT into instruction; instead, it is a psychometric scale development study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on engagement with ChatGPT feedback (cognitive, behavioral, emotional, ethical) and scale validation, not on improving writing competence or systematically intervening in writing processes for instructional purposes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, text quality measures) are reported. Outcomes are engagement dimensions and psychometric properties of the scale, not changes in writing performance following an LLM-mediated intervention.""
    }
}"
493,Understanding How Ai Chatbots Influence Efl Learners' Oral English Learning Motivation and Outcomes: Evidence from Chinese Learners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 351 EFL students in China learning spoken English with an AI chatbot, clearly fitting an EFL/ELL population focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a questionnaire survey of students who already have experience using an AI chatbot; it does not describe an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT, GPT-4) into instruction. The chatbot type/architecture is unspecified and may not be an LLM, and there is no controlled instructional treatment.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on spoken/oral English learning, motivation, human likeness, self-efficacy, and social presence, not on writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are modeled via SEM on motivation and related constructs; there is no mention of quantifiable writing outcomes or writing performance measures. The study concerns oral English learning, not writing.""
    }
}"
494,A Qualitative Descriptive Study of Teachers' Beliefs and Their Design Thinking Practices in Integrating an Ai-based Automated Feedback Tool,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is Norwegian 9th-grade students learning English as a second language, taught by ESL teachers. The abstract explicitly mentions L2 writing and English as a second language teachers, indicating L2 English learners in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The tool is described as an 'AI-driven automated feedback tool, the Essay Assessment Technology (EAT)'. It is not specified whether EAT is based on a large language model (e.g., transformer-based generative model) or a more traditional automated essay scoring/feedback system. Thus, it is unclear if it qualifies as an LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on teachers’ beliefs, perceptions, user experiences, and pedagogical decisions when integrating an AI-based automated feedback tool. Although situated in L2 writing assessment, the study is framed as a qualitative descriptive exploration of teacher practices and design thinking, not as a writing competence intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports a descriptive qualitative study using teacher interviews and focuses on beliefs, experiences, and instructional choices. There is no mention of quantitative writing outcome measures or experimental/quasi-experimental evaluation of students’ writing performance.""
    }
}"
495,Effects of Ai Chatbots on Efl Students' Critical Thinking Skills and Intrinsic Motivation in Argumentative Writing,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 40 Chinese undergraduates in an EFL context (“integrating AI chatbots into EFL classroom activities”), so they are L2 English learners and the focus is on English argumentative writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses an “AI chatbot” called Spark Desk in writing activities, but the abstract does not specify whether Spark Desk is an LLM-based, transformer generative model (e.g., similar to ChatGPT/GPT-4) or a different type of AI tool. Without confirmation that Spark Desk is an LLM, it is unclear if this meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is argumentative writing in an EFL classroom. The chatbot is integrated into writing activities, and outcomes include critical thinking skills in argumentative writing and intrinsic motivation related to writing. This aligns with a writing-focused pedagogical intervention rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""Quantitative outcomes are reported for critical thinking skills (using the Illinois Critical Thinking Essay Scoring Rubric) and intrinsic motivation. However, it is not explicit whether the rubric scores are treated as writing performance metrics or purely as CTS measures; no direct writing quality scores are clearly mentioned. Thus, it is uncertain whether there are quantifiable writing outcome metrics per se.""
    }
}"
496,To Disclose or Not to Disclose: Exploring the Risk of Being Transparent about Genai Use in Second Language Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on second language (L2) writers and L2 writing assessment, which aligns with the target population of L2 English learners in ESL/EFL/ELL-type contexts, though the specific target language is not stated but is implied to be English writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines the impact of disclosing GenAI use on teachers’ grading, not an instructional intervention integrating LLMs into writing instruction or processes. There is no indication of an experimental or quasi-experimental pedagogical design where LLMs (e.g., ChatGPT) are systematically used as part of a writing intervention; GenAI use is only a contextual factor for assessment.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on how disclosure of GenAI use affects L2 writing assessment and teacher bias, not on improving writing competence or writing-related skills through LLM-mediated pedagogy. It is essentially an assessment/perception study rather than a writing intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study reports quantitative differences in grades under different disclosure conditions, these are not outcomes of an LLM-based writing intervention aimed at improving writing. The GenAI tools are not manipulated as an instructional treatment; thus, the reported metrics do not assess the effectiveness of an LLM-mediated writing intervention.""
    }
}"
497,Creating an Internationally Equitable Playing Field for Publishing in English-language Scholarly Journals,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article discusses non-Anglophone authors in general, not specifically L2 English learners in ESL/EFL/ELL instructional contexts. It focuses on scholars publishing in English-language journals rather than language learners in educational settings.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""AI is mentioned only as a recommendation to facilitate translation. There is no experimental or quasi-experimental design, nor any concrete integration of LLMs (e.g., ChatGPT, GPT-4) into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on equity in academic publishing and policy recommendations, not on writing competence or pedagogical writing interventions. It is a conceptual/policy piece rather than a study of writing instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental measures are reported. The article offers recommendations and discussion without empirical assessment of writing outcomes.""
    }
}"
498,Digital Literacy in the Age of Artificial Intelligence: Exploring Student Engagement with Automated Writing Evaluation (awe) Feedback,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract is situated in the context of L2 writing, but it does not specify the target language (e.g., English) or clearly identify the participants as ESL/EFL/ELL learners. It may be conceptual rather than empirical.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the title mentions AI and automated writing evaluation (AWE), the abstract describes a review and conceptual integration of digital literacy and student engagement, not an experimental or quasi-experimental intervention using an LLM (e.g., ChatGPT, GPT-4) in writing instruction. AWE tools are typically not LLM-based in this context, and no specific LLM is mentioned.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on theorizing digital literacy and student engagement in L2 writing, not on a concrete pedagogical intervention targeting writing competence or writing-related performance variables. It is more conceptual than intervention-focused.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental results are reported. The article appears to be a review/conceptual piece discussing models and constructs rather than measuring changes in writing performance following an LLM-mediated intervention.""
    }
}"
499,Secondary School English Teachers' Application of Artificial Intelligence-guided Chatbot in the Provision of Feedback on Student Writing: an Activity Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are 13 secondary school English teachers in China. The abstract does not specify the learners’ L1 or explicitly state that the student writers are L2 English learners, though this is likely. However, the data and analysis focus on teachers’ use of AI for feedback, not on learner outcomes.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses Kimi, an AI-guided chatbot, to support teacher feedback on student writing. Kimi may be an LLM-based tool, but the abstract does not explicitly identify it as a large language model (e.g., ChatGPT/GPT-4-type transformer). Thus, it is unclear whether the intervention meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on how teachers incorporate an AI-guided chatbot into their feedback practices, analyzed through Activity Theory. The outcomes reported concern characteristics of AI vs. teacher feedback and components of the activity system, not on changes in students’ writing competence or writing-related performance variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics for students are reported. The study examines features of feedback (amount, length, foci, types) and the facilitative role of AI in teacher feedback, but does not measure or report experimental effects on learners’ writing quality or related performance indicators.""
    }
}"
500,Efl Students' Writing Engagement and Ai Attitude in Genai-assisted Contexts: a Mixed-methods Study Grounded in Sdt and Tam,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as EFL learners in GenAI-assisted writing contexts, which fits the target population of L2 English learners in EFL settings.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study concerns GenAI and EFL writing, the abstract does not describe an experimental or quasi-experimental instructional intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction. It focuses on engagement profiles and attitudes, and notes that few teachers have actively integrated such tools into their teaching, suggesting no structured LLM-based intervention was implemented.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on writing engagement and attitudes toward GenAI, not on writing competence or writing-related performance variables. The study examines behavioral, emotional, and cognitive engagement rather than instructional effects on writing ability.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, text quality measures) are reported. Outcomes are engagement profiles and attitudes, plus qualitative teacher perceptions, without measured changes in writing performance.""
    }
}"
501,Is This Really Your Work?: a Qualitative Study of Teacher-led Interviews and Student Accountability in the Age of Generative Ai,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 24 Master's-level English as a Foreign Language (EFL) students, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study concerns student engagement with generative AI in writing, the intervention is teacher-led interviews as an assessment practice, not an LLM-mediated writing instruction or process. There is no indication that a specific LLM (e.g., ChatGPT) is systematically integrated as an instructional tool in an experimental or quasi-experimental design.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on authorship, integrity, accountability, and ethical engagement with GenAI via teacher-led interviews, not on improving writing competence or writing-related performance variables. The emphasis is on assessment and ethical orientation rather than writing skill development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly described as qualitative, using thematic analysis of reflection data. Reported outcomes are cognitive, emotional, and agentive developments, with no mention of quantifiable writing outcome metrics (e.g., writing scores, text quality measures) to assess effectiveness of an LLM-mediated writing intervention.""
    }
}"
502,Integrating Iwrite Tools into English Writing Instruction,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract describes English writing instruction in Chinese universities, implying learners are EFL students (L2 English learners). The focus is clearly on English writing proficiency.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The tool mentioned is ‘iWrite’, described as an AI tool for grammar correction, vocabulary enhancement, and structural analysis. The abstract does not specify that it is an LLM or transformer-based generative model (e.g., ChatGPT, GPT-4). It could be a traditional NLP/automated feedback system. Without explicit indication of LLM use, its eligibility as an LLM-based intervention is unclear.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is English writing instruction, focusing on improving writing proficiency, academic writing conventions, and related instructional challenges. The primary focus is clearly on writing competence and pedagogy, not on automated scoring or system evaluation alone.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract states that the paper ‘examines the implementation’ and ‘focuses on methods, outcomes, and challenges’ but does not indicate any experimental or quasi-experimental design with quantifiable writing outcome metrics. It appears descriptive/practice-oriented rather than reporting measured intervention effects (e.g., pre/post test scores, rubric-based gains).""
    }
}"
503,A Literature Review on Generative Artificial Intelligence Applications in Foreign Language Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a literature review of generative AI in foreign language education, not a primary empirical study with a defined participant population of L2 English learners. It synthesizes 30 empirical studies rather than reporting original participant data.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""As a literature review, the paper does not itself implement an experimental or quasi-experimental LLM-based writing intervention. It only summarizes existing studies on GenAI tools in foreign language education.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although it notes that many included studies focus on writing instruction, the review’s own primary focus is not a specific writing intervention or context but a broad overview of GenAI applications across multiple domains (user perceptions, assessment, teacher preparation, etc.).""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study does not report original quantitative writing outcome measures. It is a qualitative synthesis of prior work and thus does not provide direct experimental outcome data on LLM-mediated writing interventions.""
    }
}"
504,"Effects of Speech-enabled Corrective Feedback Technology on Efl Speaking Skills, Anxiety and Confidence",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are clearly described as learners of English as a foreign language (EFL) from China and Kazakhstan, so they are L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is a speech-enabled corrective feedback (SECF) system combining speech-to-text recognition with automated corrective feedback. There is no indication that this system is based on a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model); it appears to be an STR + rule-based/ACF tool rather than an LLM-mediated intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on speaking skills (pronunciation, discourse length, confidence to speak, anxiety) in EFL speaking practice. Writing is only involved as an intermediate representation of speech (speech-to-text), not as a target competence or writing instruction context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The reported outcomes are EFL speaking ability, foreign language anxiety, and confidence. No quantifiable writing outcomes or writing-related performance measures are reported.""
    }
}"
505,Chatgpt in Foreign Language Teaching and Assessment: Exploring Efl Instructors' Experience,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study involves English language teachers of EFL and ESP courses in Ukraine, the EU, and the USA. While the participants are instructors rather than learners, the context is clearly EFL/ESL with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a survey of teachers’ perceptions and familiarity with ChatGPT for teaching and assessment. It does not describe an experimental or quasi-experimental intervention integrating ChatGPT into learners’ writing instruction or processes; it focuses on instructors’ experiences and intentions.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing is mentioned as one of several skills (along with vocabulary and grammar), the primary focus is on general foreign language teaching and assessment development, not specifically on writing competence or writing-related variables as the main outcome of an intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper reports survey findings about perceptions, confidence, hesitancy, and satisfaction. It does not report any quantifiable learner writing outcomes or measured changes in writing performance resulting from an LLM-mediated writing intervention.""
    }
}"
506,Evaluating Automated Grammar Corrective Feedback Tools: a Comparative Study of Grammarly and Quillbot in Esl Expository Essays,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses expository essays authored by Malaysian ESL students, clearly identifying the population as L2 English learners in an ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The tools investigated are Grammarly and Quillbot as automated grammar feedback applications. These are not described as LLM-based generative models integrated into instruction, but as error-detection tools. The focus is on their error-identification performance, not on an LLM-mediated pedagogical intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on comparing the tools’ ability to detect and classify errors in existing writing samples, not on a writing instruction or intervention aimed at improving learners’ writing competence. It is essentially a tool evaluation study, not a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., pre/post writing scores, improvement measures) are reported. The study analyzes frequencies of errors flagged by the tools, not changes in learners’ writing performance following an intervention.""
    }
}"
507,Engage Learn: an Ai-based English Proficiency Improviser,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract describes an English learning and teaching platform but does not specify the target population (e.g., EFL/ESL/ELL learners) or provide details about participants. It is unclear whether the study involves L2 English learners in ESL/EFL/ELL contexts or a general user base.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The platform uses generative models including ChatGPT 3.5 Turbo and Gemini 1.5 Flash, enhanced via RAG, to provide targeted feedback on users’ English. These are clearly LLM-based tools integrated into language learning, satisfying the LLM intervention criterion.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The system aims to improve users’ ability to write and speak English and includes feedback on grammar, vocabulary, and fluency. However, the abstract emphasizes system architecture and speech-based interaction; it does not clearly state that the primary focus of the evaluation is writing competence or writing-related variables, as opposed to general language proficiency or speaking.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions only ‘planned evaluation methods’ and ‘user testing and data analysis’ but does not describe any experimental or quasi-experimental design, nor any quantifiable writing outcome metrics. It appears to be a system description with prospective evaluation rather than a reported intervention study with measurable writing outcomes.""
    }
}"
508,Personalized Recommendation Design of English Writing Marking System Based on Corpus,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract discusses college English writing teaching and higher vocational English teaching, implying learners of English in an EFL/ESL context. The focus is on English composition and college English writing, consistent with L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on a corpus-based automatic scoring and computer-aided composition marking system. There is no indication that the system is an LLM (e.g., ChatGPT, GPT-4) or transformer-based generative model; it appears to be a traditional automated scoring/evaluation system rather than an LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on an automatic scoring/marking system and corpus-based teaching integration, not on an LLM-based pedagogical writing intervention. It describes computer-aided composition marking and online automatic evaluation, which aligns more with automated essay scoring functionality than with LLM-supported instructional processes.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract does not report or clearly indicate quantifiable writing outcome metrics (e.g., pre/post writing scores, accuracy, complexity). It mainly describes the teaching approach and context without specifying experimental measures or results.""
    }
}"
509,University Students' Perceptions of Artificial Intelligence-based Tools for English Writing Courses,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Korean university students who have taken English writing courses and are explicitly described as English language learners (ELLs), fitting an EFL/ESL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines perceptions of various AI-based tools (Google Translate, Naver Papago, Grammarly). These are not clearly LLM-based writing interventions, and the design is not experimental or quasi-experimental; it is a survey plus focus group on tool perceptions, not an instructional intervention using LLMs.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is English writing courses, the primary focus is on students’ perceptions, strengths/weaknesses, and potential interference with writing processes, rather than a structured pedagogical intervention aimed at improving writing competence via LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports no quantifiable writing outcome measures (e.g., pre/post writing scores, rubric-based gains). Data are survey responses and interview findings about perceptions and experiences, not measured changes in writing performance following an LLM-mediated intervention.""
    }
}"
510,Investigating Efl Faculty Members' Perceptions of Integrating Artificial Intelligence Applications to Improve the Research Writing Process: a Case Study at Majmaah University,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are EFL faculty members/teachers, not L2 English learners in ESL/EFL/ELL contexts. The focus is on teachers’ own research writing, not on student L2 learning.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “AI applications and tools” without specifying whether they are large language models (e.g., ChatGPT, GPT-4) or other types of AI. No particular LLM-based intervention is described.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is faculty research writing processes and their perceptions of AI tools, not pedagogical writing instruction or student writing development. It is not an instructional intervention in L2 writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports attitudes and perceptions via questionnaires and interviews. It does not report quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity) resulting from an AI-mediated intervention.""
    }
}"
511,The Effects of Generative Ai Usage in Efl Classrooms on the L2 Motivational Self System,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Japanese university students in an EFL writing class, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention integrates the generative pre-trained AI chatbot ChatGPT into an instructor-led writing class, with a control and treatment group, fitting an experimental/quasi-experimental LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""ChatGPT is used in writing workshops where students collaborate and receive feedback from the chatbot; the context is clearly writing instruction and writing-related activities.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The reported outcomes are changes in motivational constructs (Ideal L2 Self, Ought-to L2 Self, L2 Learning Experience) measured via questionnaires. While the abstract mentions potential enhancement of writing skills, it does not report any quantifiable writing performance metrics or writing quality measures; the focus is on motivation, not writing outcomes.""
    }
}"
512,Investigating the Impact of Chatgpt as an Ai Tool on Esl Writing : Prospects and Challenges in Saudi Arabian Higher Education,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states the participants are ESL students at a Saudi Arabian university, indicating L2 English learners in an EFL/ESL context with focus on English writing proficiency.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""ChatGPT is clearly an LLM, and the study examines its impact on ESL writing. However, the abstract does not specify whether there was an experimental or quasi-experimental design (e.g., control group, pre-post intervention) or how ChatGPT was systematically integrated into instruction versus being used in an unstructured way.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on ESL students’ writing proficiency and how ChatGPT affects writing-related aspects such as feedback, language skill development, vocabulary, autonomy, and creativity. This aligns with a writing competence context rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports that data from 130 students showed a ‘significant positive effect’ on writing, implying quantitative outcomes, but it does not specify the nature of the measures (e.g., rubric scores, test scores) or whether these are structured writing outcome metrics versus self-reported perceptions. Thus, it is unclear if quantifiable writing outcomes were actually measured.""
    }
}"
513,Beyond Syntax: Exploring Moroccan Undergraduate Efl Learners' Engagement with Ai-assisted Writing,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Moroccan undergraduate EFL learners in a general English course, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “AI-supported writing tools” and “AI assistance” but does not specify whether these are large language model-based tools (e.g., ChatGPT, GPT-4) or other forms of AI (e.g., grammar checkers). Without explicit mention of LLMs or transformer-based generative models, it is unclear if the intervention meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on “AI-assisted writing,” examining the impact of AI tools on the writing process and writing quality, including organization, vocabulary, and creativity, within a pedagogical context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""It is described as a quasi-experimental study with a control group and reports “positive outcomes in language proficiency, creativity, organizational skills, and vocabulary use,” implying quantifiable writing-related outcome measures to assess the AI-assisted intervention.""
    }
}"
514,Chatgpt for Language Learning: Assessing Teacher Candidates' Skills and Perceptions Using the Technology Acceptance Model (tam),2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL teacher candidates performing tasks in Spanish (L1) and English (L2), so they are L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT-4 is used only to generate comparison texts; there is no experimental or quasi-experimental instructional intervention where learners use the LLM as part of their writing instruction or process. The focus is on evaluating critical skills and perceptions, not on an LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although participants complete writing tasks, the primary focus is on critical skills in distinguishing human vs. machine texts and perceptions of ChatGPT, not on improving writing competence or writing-related pedagogical outcomes through LLM use.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Text analysis metrics (SC, ASL, VOCD) are used to compare human and machine texts, but not as outcome measures of an LLM-based instructional intervention. The study does not report changes in learners’ writing performance attributable to using ChatGPT; instead it reports perceptions and discrimination skills.""
    }
}"
515,"Graduate Students' Use of Chatgpt for Academic Text Revision: Behavioral, Cognitive, and Affective Engagement",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as six Iranian graduate ESL students from STEM fields, indicating L2 English learners in an ESL context with a focus on English academic writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used for academic text revision, the study is observational/qualitative: it examines how students engage with ChatGPT via screencasts, stimulated recall, interviews, and surveys. There is no experimental or quasi-experimental instructional intervention or comparison condition designed to test the effect of an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly L2 academic writing: students revise research proposals, focus on lower-order concerns, paraphrasing, and professionalism in writing. The study centers on writing processes and engagement with ChatGPT for text revision.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports behavioral, cognitive, and affective engagement and satisfaction, but does not mention any quantifiable writing outcome metrics (e.g., scores, quality ratings, error counts) to assess effectiveness. Outcomes are qualitative/engagement-focused rather than experimental measures of writing improvement.""
    }
}"
516,Understanding Efl Students ' Use of Self-made Ai Chatbots as Personalized Writing Assistance Tools: a Mixed Methods Study,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 69 Chinese undergraduate EFL students, clearly L2 English learners in an EFL context, and the focus is on English writing (‘learning to write’ in English).""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention involves students creating and using self-made RAG chatbots via Poe to assist with their writing processes. These are LLM-based chatbots integrated into writing support, fitting the LLM intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL writing: chatbots are used for idea generation, outlines, and error identification in writing. The study examines chatbots as pedagogical tools for personalized writing assistance, so the primary focus is writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports outcomes on writing motivation, confidence, beliefs, and attitudes, but does not mention any quantitative writing performance metrics (e.g., scores, quality ratings, accuracy measures). Data sources include essays, but no experimental or quasi-experimental writing outcome measures are described; the reported effects are affective, not performance-based.""
    }
}"
517,Identifying Chatgpt-generated Texts in Efl Students' Writing: through Comparative Analysis of Linguistic Fingerprints,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Japanese EFL learners (140 first-year university students), clearly fitting an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is present but not as a structured instructional or experimental writing intervention. The study focuses on distinguishability of human vs. ChatGPT-generated texts and uses ChatGPT mainly to generate comparison essays, not as a pedagogical tool in a designed intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on detecting ChatGPT-generated texts via linguistic fingerprints and machine learning classification, not on improving writing competence or implementing a writing pedagogy using LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., gains in writing quality, accuracy, complexity) are reported. Outcomes concern distinguishability and classification performance, not effectiveness of an LLM-mediated writing intervention.""
    }
}"
518,Generative Ai's Recolonization of Efl Classrooms,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is Chinese English as a Foreign Language (EFL) classrooms and EFL assessment, clearly involving L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study discusses the potential use of generative AI to provide sample writings and illustrates risks using data generated via AI chatbots, but it does not describe an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction. It is a critical/analytical piece rather than an intervention study.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on continuation writing and AI-generated sample texts, but the primary aim is to critique cultural and ideological implications (recolonization, native-speakerism), not to evaluate writing competence or a structured writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental measures are reported. The study uses SFL to analyze AI-generated texts and discusses risks, without assessing effects on learners’ writing performance.""
    }
}"
519,Korean-as-a-foreign-language Learners' Engagement with Machine Translation Output,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are US university students learning Korean as a foreign language. The target language is Korean, not English, and the context is KFL rather than ESL/EFL/ELL. The abstract explicitly frames the study around Korean writing, not L2 English writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses 'machine translators and other artificial intelligence-assisted programs' and a Guided Use of Machine Translation model. It does not specify whether the machine translator is an LLM-based system (e.g., GPT-based) or a traditional MT system (e.g., phrase-based or NMT without LLM interaction).""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on how learners use machine translators to revise their writing in Korean, examining engagement with MT output as feedback in the writing process. This aligns with a primary focus on writing competence and writing-related processes.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract describes an exploratory case study analyzing cognitive and behavioral engagement and reporting that students could identify and correct errors and used various revision strategies. It does not clearly state that quantifiable writing outcome metrics (e.g., pre/post writing scores, error rates) were collected to assess intervention effectiveness.""
    }
}"
520,Automatic Scoring of Arabic Essays: a Parameter-efficient Approach for Grammatical Assessment,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on automatic scoring of Arabic essays and uses Arabic datasets (QALB-2014, QALB-2015, ZAEBUC). There is no indication that the participants are L2 English learners or that the target language is English; the focus is on Arabic grammatical assessment.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The paper leverages a pre-trained AraBART model, which is a transformer-based large language model, fine-tuned with parameter-efficient methods for essay scoring. This satisfies the requirement of using an LLM-based system, though not in a pedagogical intervention context.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automated essay scoring (AES) for grammaticality and other criteria, not on writing instruction or intervention to improve learners’ writing competence. It is a scoring/assessment tool, not a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports system performance on AES tasks (e.g., error-based grammatical scoring) rather than quantifiable outcomes of an LLM-mediated writing intervention on learners’ writing. There is no experimental design measuring changes in learner writing performance.""
    }
}"
521,Technology-assisted Language Learning Systems: a Systematic Literature Review,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract indicates that most reviewed studies targeted English, but as this is a systematic review of multiple technologies and languages, it is not focused on a specific L2 English learner population with primary data. The exact participant populations are not detailed in the abstract.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a systematic literature review of technology-assisted language learning in general. It does not report an experimental or quasi-experimental intervention using LLMs such as ChatGPT or GPT-4; instead, it synthesizes prior work across various technologies.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is broad technology-assisted language learning, covering multiple skills (vocabulary, writing, grammar, etc.) and general benefits. It is not an empirical study implementing a specific writing-focused pedagogical intervention with LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a review article, it does not present original experimental outcome measures of a particular LLM-mediated writing intervention. It summarizes empirical evidence from other studies rather than reporting its own quantifiable writing outcomes.""
    }
}"
522,Automatic Correction Method for English Composition Errors Assisted by Artificial Intelligence,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to students’ English composition as a second language but does not clearly specify that the participants are L2 English learners in ESL/EFL/ELL contexts, nor does it describe an actual learner sample; it mainly presents a system description and simulation results.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study presents an AI-assisted deep learning–based automatic correction system. It is framed as an intelligent essay correction and scoring tool using feature extraction and dynamic time normalization. There is no indication that it uses a large language model (e.g., ChatGPT/GPT-style transformer-based generative model); it appears to be an automated scoring/correction engine rather than an LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on developing an automatic essay correction and grading system to support teachers’ efficiency. It is essentially an automated essay correction/scoring tool, not a pedagogical writing intervention study examining changes in learners’ writing competence through instructional use of LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports only ‘simulation results’ showing that the system supports teachers and improves efficiency. It does not report quantifiable learner writing outcome measures (e.g., pre/post writing scores, accuracy, complexity) from an experimental or quasi-experimental intervention with students.""
    }
}"
523,Chatgpt over My Friends: Japanese English-as-a-foreign-language Learners' Preferences for Editing and Proofreading Strategies,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 33 Japanese English-as-a-foreign-language learners, clearly an EFL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT-3.5 (an LLM) is used, the design is not experimental or quasi-experimental in terms of learning outcomes. Learners simply experience two activities (writing groups and ChatGPT) and then complete questionnaires about their experiences and preferences; there is no controlled intervention to test effectiveness on writing performance.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is academic writing in an EFL classroom, focusing on editing and proofreading to improve clarity and cohesion in writing, which is directly writing-related.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are students’ preferences, perceived value, and experiences via questionnaires. The abstract does not mention any quantifiable writing performance metrics (e.g., scores, error rates, rubric-based assessments) to evaluate the effectiveness of the LLM-mediated intervention.""
    }
}"
524,Exceptional Talent and Enthusiasm for Math: an Examination of Storylines Circulated by Chatgpt about Mathematical Learners,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are described broadly as different types of mathematical learners, including English language learners, but the focus is not on L2 English learners in ESL/EFL/ELL contexts nor on English as the target language. The context is mathematics learning and identity, not L2 English learning.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used to provide feedback to learners’ mathematical writing, but the study is explicitly described as an exploratory examination of storylines and narratives in ChatGPT’s feedback, not as an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on mathematical learning, identity, and narratives about different learner groups, not on writing competence or writing-related variables as an instructional target. Writing is only the medium (mathematical writing) through which ChatGPT’s feedback is analyzed.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative analysis of ChatGPT’s feedback and the storylines it promotes. There is no indication of quantifiable writing outcome metrics or an intervention designed to assess changes in learners’ writing performance.""
    }
}"
525,Chatgpt as Artificial Intelligence-based Generative Multimedia for English Writing Pedagogy: Challenges and Opportunities from an Educator's Perspective,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses English language writing pedagogy and English language teachers’ views on ChatGPT, but it does not specify any empirical participant population (e.g., EFL/ESL/ELL learners). It is a literature-based discussion rather than a study with defined L2 learners as participants.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper is explicitly described as a narrative literature review synthesizing existing studies, blog posts, and other sources about ChatGPT in English writing pedagogy. It does not report an experimental or quasi-experimental intervention where ChatGPT is directly integrated into instruction with measured outcomes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus is on English writing pedagogy and ChatGPT, the article is conceptual/review-based, examining opportunities, challenges, and educator perspectives. It does not implement or evaluate a specific pedagogical intervention in a research context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The findings concern themes about teachers’ views, benefits, and challenges of ChatGPT, without experimental measures of changes in learners’ writing performance.""
    }
}"
526,Leveraging Chatgpt for Second Language Writing Feedback and Assessment,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to 'L2 writing contexts' and 'second language writing' but does not specify that the focus is on L2 English learners (ESL/EFL/ELL) or that the target language is English specifically.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper is described as reviewing representative studies and explaining sub-topics, drawing on multiple projects, but it is framed as a discussion/review article rather than reporting a specific experimental or quasi-experimental LLM-based intervention study with its own design and data.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on L2 writing feedback, assessment, and the L2 writing process, including ChatGPT-student collaboration and ChatGPT-supported teacher feedback, which are clearly writing-related pedagogical contexts.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantifiable writing outcome metrics or experimental results; it instead reviews literature and discusses potential and innovative sub-topics, indicating a conceptual/review nature without reported intervention outcomes.""
    }
}"
527,Whether English Proficiency and English Self-efficacy Influence the Credibility of Chatgpt-generated English Content of Emi Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are college students in English-medium instruction (EMI) courses, i.e., non-English majors using English as an additional language in content courses. The focus is on English proficiency and English self-efficacy, indicating L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, the study is observational/survey-based. Instructors ‘encouraged’ students to use ChatGPT, but there is no experimental or quasi-experimental design testing a structured LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on perceived credibility of ChatGPT-generated English content and its relation to English proficiency and self-efficacy. While the course is ‘Technical Writing and Presentation’, the abstract does not focus on writing competence or writing-related performance outcomes, but on credibility judgments.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are survey-based measures of perceived credibility (CCGEC) and their relation to EP and ESE. No quantifiable writing performance metrics or writing quality measures are reported to assess the effectiveness of ChatGPT as a writing intervention.""
    }
}"
528,Investigating the Impact of Chatgpt as an Ai Tool on Esl Writing: Prospects and Challenges in Saudi Arabian Higher Education,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as ESL students at a Saudi Arabian university, indicating L2 English learners in an EFL/ESL context with a focus on English writing proficiency.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that the study explores the impact of ChatGPT on ESL students' writing proficiency and mentions integration into writing instruction, but it does not clearly describe an experimental or quasi-experimental intervention design (e.g., treatment vs. control, pre/post with structured use of ChatGPT). The nature of the design and how ChatGPT was systematically integrated remain unspecified.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on ESL writing proficiency and writing instruction. Reported opportunities (personalized feedback, vocabulary expansion, autonomy) and challenges (loss of individuality, reduced creativity) are all framed around writing development, not automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract notes that data from 130 students showed a ‘significant positive effect on their writing,’ implying quantitative outcome measures of writing proficiency were collected and analyzed, alongside qualitative focus group data.""
    }
}"
529,Generative Ai's Recolonization of Efl Classrooms: the Case of Continuation Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is Chinese English as a Foreign Language (EFL) classrooms and continuation writing in China's EFL assessment, clearly involving L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the paper discusses using generative AI to provide sample writings and uses data generated via AI chatbots, it is a critical/discursive analysis rather than an experimental or quasi-experimental pedagogical intervention study. There is no structured LLM-mediated instructional intervention being tested.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on ideological, cultural, and discourse implications (recolonization, native-speakerism, cultural hollowness) of AI-generated continuation writing samples, not on developing or evaluating writing competence through an instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics or experimental measures. It illustrates arguments with AI-generated data and SFL analysis, focusing on risks and power dynamics rather than measured changes in learners’ writing performance.""
    }
}"
530,Generative Ai as a Collaborative Companion: Enhancing Peer Feedback in Efl Writing Classes,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as being in an English as a Foreign Language (EFL) writing class, which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “Generative Artificial Intelligence (GAI)” as a collaborative companion in peer feedback, but does not specify that it is an LLM (e.g., ChatGPT, GPT-4) or any transformer-based generative model. The nature of the AI system is not clearly defined.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL writing classes, focusing on peer feedback in writing and aiming to improve overall writing ability, which aligns with a primary focus on writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as exploratory, proposing a framework and discussing advantages and implications. There is no mention of experimental or quasi-experimental design, nor of quantifiable writing outcome metrics; it appears conceptual/descriptive rather than reporting measured intervention outcomes.""
    }
}"
531,A Lesson Study on a Mooc-based and Ai-powered Flipped Teaching and Assessment of Efl Writing Model: Teachers' and Students' Growth,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are clearly described as college EFL students (66 in total) and EFL teachers, indicating L2 English learners in an EFL context with a focus on English writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention is described as a \""MOOC-based and AI-powered flipped teaching and assessment of EFL writing (MAFTA).\"" However, the abstract does not specify whether the AI component is a large language model (e.g., ChatGPT/GPT-like transformer-based generative system) or another type of AI tool (e.g., analytics, automated scoring, or non-LLM support). Without this detail, it is impossible to confirm that an LLM is integrated into the writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL writing instruction and assessment. The study examines a flipped teaching model for EFL writing and analyzes students’ argumentative essays before and after the intervention, indicating a focus on writing competence and writing-related variables rather than solely on automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that \""substantial improvements were detected in students' essays\"" based on pre- and post-instruction argumentative essays, implying quantifiable writing outcome measures were used to assess the effectiveness of the MAFTA intervention.""
    }
}"
532,"Enhancing Efl Reading and Writing through Ai-powered Tools: Design, Implementation, and Evaluation of an Online Course",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 43 senior high school students in Taiwan enrolled in an online English course aimed at cultivating autonomous EFL learners, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention used three AI-powered tools: Linggle Write, Linggle Read, and Linggle Search. These are not identified as large language model (LLM)-based tools (e.g., ChatGPT, GPT-4, Gemini) but rather AI-powered corpus/phrase-suggestion tools. The abstract does not indicate use of transformer-based generative LLMs in the writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The course explicitly targeted EFL reading and writing, and the tools (Linggle Write/Read/Search) supported these skills. The primary pedagogical focus is on reading and writing competence within an online course context.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study collected both qualitative and quantitative data and reports that language proficiency predicted semester grade and assignment quantity. However, the abstract does not clearly state that specific, quantifiable writing outcome measures (e.g., writing scores, quality metrics) were used to assess the effect of the AI tools on writing performance.""
    }
}"
533,Chatgpt Vs Teacher Roles in Developing Efl Writing,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 50 English-language learners at a public university in an EFL context (“developing English as a Foreign Language writing”). The focus is clearly on English L2 learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention explicitly uses ChatGPT (a large language model) to provide revisions on students’ writing, and compares this with teacher instruction. This is an experimental comparison of LLM-mediated writing support versus teacher feedback.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on developing EFL writing and comparing ChatGPT’s role with teacher roles in writing instruction. The study is pedagogical, not just system evaluation or scoring, and centers on writing development.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative outcomes are reported: learners’ writing performance is measured before and after revisions by ChatGPT and before and after teacher instruction, with scores based on TOEFL iBT criteria and comparative improvement between groups.""
    }
}"
534,Recursive Editing with Google Translate: the Impact on Writing and Error Correction,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as EFL university sophomores, indicating second language English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Google Translate as a machine translation (MT) tool. The abstract does not indicate that a large language model (e.g., ChatGPT, GPT-4, Gemini) or transformer-based generative model is being used for writing instruction; it is standard MT, not an LLM-based writing assistant.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on writing competence and related variables (fluency, complexity, accuracy) and uses Google Translate within a recursive editing process as part of writing instruction.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantifiable writing outcomes are reported: error correction test performance, writing scores, and specific measures of fluency, accuracy, and syntactic complexity pre- and post-intervention.""
    }
}"
535,"The Effectiveness of Chatgpt as a Lexical Tool for English, Compared with a Bilingual Dictionary and a Monolingual Learner's Dictionary",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 166 university students working with uncommon English phrasal verbs as English language learners, indicating an L2 English learner population in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, it is framed as a lexical tool compared against dictionaries for task performance, not as part of an instructional or pedagogical writing intervention with experimental teaching design.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on receptive and productive lexical tasks (understanding and producing phrasal verbs) rather than broader writing competence or writing-related instruction. It is essentially a vocabulary support/comprehension/production study, not a writing-focused intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are accuracy in understanding and producing specific lexical items, not quantifiable measures of writing performance or writing quality as a whole. The study does not report writing outcome metrics for an LLM-mediated writing intervention.""
    }
}"
536,Assessing Human Evaluations of Cover Letters Written or Edited by Al and Non-native English Speakers,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study concerns non-native English speakers (NNES) as writers, but the participants in the experiment are 118 native English speakers who read and evaluate cover letters. There is no indication that L2 learners themselves are the experimental participants whose learning outcomes are measured.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""AI is involved in producing or editing cover letters (AI-written, AI-edited), but the abstract does not specify that a large language model (e.g., ChatGPT, GPT-4) is used, nor that there is an instructional or pedagogical intervention integrating an LLM into NNES writing processes. It is framed as a survey-embedded experiment on evaluations, not an LLM-based teaching intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on how native English speakers evaluate hireability and writing quality of different types of cover letters. It does not describe a writing instruction context or an intervention aimed at improving L2 writing competence; rather, it examines perceptions of texts already produced/edited by humans or AI.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics for L2 learners’ development are reported. Outcomes are ratings of hireability and writing quality by native speakers, not pre/post measures of NNES writing performance following an LLM-mediated intervention.""
    }
}"
537,Students' Perceptions of the Impact of Ai Chatbots on Vocabulary and Grammar in Efl Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 100 undergraduate EFL students from universities in Indonesia, clearly positioning them as L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students use various AI chatbots (e.g., ChatGPT, Gemini, Perplexity), the study is observational, focusing on which tools students already use and their perceptions. There is no experimental or quasi-experimental LLM-based instructional intervention or structured integration into writing instruction.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on perceived impact of AI chatbots on vocabulary and grammar in EFL writing, but the design is not a pedagogical intervention targeting writing competence; it is more a perception study of existing use. Writing competence is discussed, yet not within a controlled instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are self-reported perceptions of improvement (questionnaires, interviews, observations) analyzed descriptively and thematically. There is no indication of objective, quantifiable writing performance measures (e.g., pre/post writing scores, rubric-based assessments) used to evaluate an LLM-mediated intervention.""
    }
}"
538,Avery: a Genai-based Approach to Enhancing Learner Engagement in English Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “English Language learners” but does not specify whether they are L2 English learners in ESL/EFL/ELL contexts or provide any detail on their linguistic background or setting.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The system is described as “GenAI-based” and uses image generation and AI hints, but the abstract does not specify that it is powered by a large language model (e.g., ChatGPT, GPT-4) or any transformer-based generative text model. The underlying AI architecture is not identified.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on a gamified learning experience and learner engagement. While the game involves describing images in English and receiving feedback, the study evaluates affective responses and engagement rather than systematically targeting writing competence or writing-related performance as the main outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are based on a questionnaire about learner engagement and affect toward the system. No quantifiable writing performance metrics (e.g., scores, accuracy, complexity, quality ratings) are reported to assess the effectiveness of the intervention on writing.""
    }
}"
539,Co-creating Stories with Generative Ai: Reflections from Undergraduate Students of a Storytelling Service-learning Subject in Hong Kong,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are undergraduate students in Hong Kong taking a language-related service-learning subject and are described as ESL learners, indicating L2 English learners in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses ‘publicly available Generative Artificial Intelligence (GenAI) tools’ to help students co-create digital stories. However, the abstract does not specify that these are LLM-based tools (e.g., ChatGPT, GPT-4) or detail the nature of the tools beyond being GenAI, so it is unclear whether transformer-based LLMs are central to the intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on digital storytelling, creative potential, and linguistic/digital/cultural awareness. While writing is involved (co-creating written stories), the primary emphasis is on creative storytelling, agency, and intercultural engagement rather than systematic writing instruction or writing competence as the main outcome variable.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is based on qualitative content analysis of semi-structured interviews and reports perceived expansion of creative potential and awareness. No quantifiable writing outcome metrics or experimental/quasi-experimental measures of writing performance are mentioned.""
    }
}"
540,"Using Artificial Intelligence to Foster Students' Writing Feedback Literacy, Engagement, and Outcome: a Case of Wordtune Application",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract clearly states the context is second language (L2) learning and focuses on L2 writing skills development. The 46 students at upper-intermediate level are L2 learners, and the focus is on L2 writing outcomes.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Wordtune, described only as an AI-based application. Wordtune is primarily a rewriting/paraphrasing tool and is not clearly identified as an LLM-based, transformer generative model in the abstract. Under the review criteria, tools like Grammarly/QuillBot-style systems that are not explicitly LLM-based are to be excluded. There is no explicit mention of ChatGPT, GPT-4, or other LLMs, nor of generative transformer-based functionality.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on L2 writing competence and related variables: writing outcomes, engagement, and writing feedback literacy. It is a pedagogical intervention using AI in writing instruction, not an automated scoring or purely functional evaluation study.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that the experimental group using Wordtune ‘significantly improve[d] their writing outcomes, engagement, and feedback literacy when compared to the control group,’ indicating quantifiable outcome measures in a mixed-method, experimental design.""
    }
}"
541,The Impact of Chatgpt on Learners in English Academic Writing: Opportunities and Challenges in Education,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on EFL learners and their use of ChatGPT for academic English writing, which fits the target population of L2 English learners in EFL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the study is exploratory and interview-based, examining learners’ self-initiated use. There is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction or a structured writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is clearly on English academic writing, including how ChatGPT affects writing fluency, content, and knowledge, and on challenges and opportunities in using ChatGPT as an academic English writing tool.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses semi-structured and open-ended interviews and thematic analysis, yielding qualitative findings about perceptions, challenges, and opportunities. No quantifiable writing outcome metrics or experimental measures of writing performance are reported.""
    }
}"
542,"A Scholarly Dialogue: Writing Scholarship, Authorship, Academic Integrity and the Challenges of Ai",2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract discusses higher education in general and writing scholars’ perspectives on AI. It does not specify any participant group of L2 English learners in ESL/EFL/ELL contexts, nor does it focus on data related to English language learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a conceptual/dialogical piece about AI, academic integrity, and writing scholarship. It does not describe an experimental or quasi-experimental intervention integrating LLMs into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""While the article is situated within writing studies, its focus is on theoretical and ethical issues (authorship, integrity, assessment) rather than a concrete pedagogical intervention targeting writing competence or related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or empirical evaluation of an LLM-mediated writing intervention are mentioned. The piece appears to be a scholarly dialogue and historical/theoretical mapping, not an outcome-based study.""
    }
}"
543,Artificial Intelligence Pedagogical Chatbots as L2 Conversational Agents,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL undergraduate students at a Saudi university, clearly L2 English learners in an EFL context: “EFL students… The sample (n = 143) consisted of undergraduate students from a Saudi university.”""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses a “text-based pedagogical chatbot” as an L2 conversational agent, but the abstract does not specify that it is an LLM (e.g., ChatGPT, GPT-4) or transformer-based generative model. It could be a rule-based or non-LLM chatbot. Thus, whether it meets the LLM requirement is unclear from the abstract alone.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on “students' experiences and perspectives” and “cognitive and affective domains of learning” (motivation, anxiety, perceptions of usefulness). Writing is mentioned only as perceived support: “supportive of L2 practice and writing development, interest-provoking, enhancing motivation, and alleviating writing anxiety.” There is no indication of a structured writing instruction intervention or primary focus on writing competence; rather, it is a general conversational practice tool with attitudinal outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports quantitative analyses of perceptions (e.g., Mann-Whitney U test on views of chatbot-mediated interaction) but does not mention any quantifiable writing outcome measures (e.g., writing scores, text quality metrics). Outcomes are affective and perceptual, not measured changes in writing performance.""
    }
}"
544,Artificial Intelligence in Writing Courses: Attitudes of University Instructors in Lebanon,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study population consists of Lebanese university writing instructors, not L2 English learners in ESL/EFL/ELL contexts. No learner data are reported.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study explores instructors’ attitudes toward AI (including generative AI like ChatGPT) via survey; it does not implement an experimental or quasi-experimental LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on attitudes toward AI use and grading facilitation, not on an implemented pedagogical intervention targeting writing competence or writing-related performance variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes or performance metrics are reported; the study reports only instructors’ attitudinal survey results.""
    }
}"
545,Understanding Chinese University Efl Learners' Perceptions of Ai in English Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 140 Chinese university EFL learners in a Chinese university setting, clearly an EFL/ESL context focused on English writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines perceptions of Grammarly, which is not described as an LLM-based tool, and there is no indication of an experimental or quasi-experimental design integrating an LLM into instruction or writing processes. It is a technology acceptance/perception study, not an LLM intervention study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on learners’ perceptions and technology acceptance (ease of use, usefulness, enjoyment, task relevance) of Grammarly, not on writing competence or writing-related performance variables within a pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports structural equation modeling of perception variables and intention to use AI; it does not report quantifiable writing outcome metrics (e.g., writing scores, quality measures) resulting from an AI-mediated writing intervention.""
    }
}"
546,Revolutionizing Efl Writing: Unveiling the Strategic Use of Chatgpt by Indonesian Master's Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are postgraduate EFL students (Indonesian Master's students), clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, the study is a qualitative case study exploring students’ experiences and strategies. There is no experimental or quasi-experimental intervention design integrating ChatGPT into instruction; it is descriptive/observational.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL students’ use of ChatGPT in their writing process (vocabulary, grammar, idea generation, essay structuring, language refinement), which is directly related to writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study relies on self-reported experiences and perceptions; no quantifiable writing outcome metrics or experimental measures of writing improvement are reported.""
    }
}"
547,Assessing Interactional Metadiscourse in Efl Writing through Intelligent Data-driven Learning: the Microsoft Copilot in the Spotlight,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'English as a foreign language (EFL) learners' and 'advanced language learners', clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The hands-on group used 'Microsoft Copilot, artificial intelligence (AI) chatbot' as part of a data-driven learning intervention. Copilot is an LLM-based chatbot, and the design is experimental with three groups (hands-on, hands-off, control).""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary outcome is 'realization and identifying interactional metadiscourse markers (IMMs)' and perceptions of DDL. While the authors claim this helps 'develop their writing performance through metadiscourse realization', the measured variables are recognition/identification of IMMs, not actual writing performance or writing products. The focus is on metadiscourse awareness rather than writing competence as such.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantitative outcomes reported are ANCOVA results on 'realizing and identifying IMMs' and questionnaire perceptions. There is no indication of quantified writing outcomes (e.g., writing quality scores, text-based measures). Thus, no direct, quantifiable writing performance metrics are reported for the LLM-mediated intervention.""
    }
}"
548,A Multi-strategy Computer-assisted Efl Writing Learning System with Deep Learning Incorporated and Its Effects on Learning: a Writing Feedback Perspective,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly refers to EFL students and EFL writing learning, indicating participants are English as a Foreign Language learners and the focus is on English writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is a computer-assisted EFL writing system (MsCAEWL) using neural network models and semantic-based NLP techniques, positioned as an AWE-like system. There is no indication that it uses large language models (e.g., transformer-based generative models like ChatGPT/GPT-4). It appears to be an automated evaluation/feedback system rather than an LLM-based tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The system is explicitly designed for EFL writing learning and feedback, and the study evaluates its effects on EFL writing proficiency, so the primary focus is on writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports comparison experiments, correlations with human raters, and independent- and paired-sample t-tests showing significant impact on students’ EFL writing proficiency, indicating quantifiable writing outcome metrics.""
    }
}"
549,Understanding Efl Students' Chatbot-assisted Argumentative Writing: an Activity Theory Perspective,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are five Chinese undergraduate EFL students composing argumentative essays in English, clearly fitting an EFL/ESL L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses a chatbot named Argumate to assist argumentative writing, but the abstract does not specify whether Argumate is an LLM-based system (e.g., transformer-based generative model) or a rule-based/chatbot of another type.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on chatbot-assisted argumentative writing, examining how students engage with the chatbot while composing essays and discussing implications for writing pedagogy. The primary context is writing competence and writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as qualitative, using activity theory to understand engagement processes. Data include screen recordings, chat logs, essays, and a questionnaire, but the abstract does not indicate any experimental or quasi-experimental design or report quantifiable writing outcome metrics to assess effectiveness of the chatbot intervention.""
    }
}"
550,A Systematic Review of Grammarly in L2 English Writing Contexts,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract clearly states that the review focuses on Grammarly research involving L2 learners in L2 English writing contexts, so the population criterion is satisfied.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention examined is Grammarly, an automated writing evaluation (AWE) system that is not a large language model and is not described as using transformer-based generative LLM technology. The study is also a systematic review, not an experimental or quasi-experimental primary study integrating LLMs.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on L2 English writing and how Grammarly supports L2 English writing, which aligns with a writing competence context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic review of Grammarly studies, this article does not itself report primary experimental writing outcome metrics for an LLM-mediated intervention. It synthesizes prior work on a non-LLM AWE tool, which falls outside the required scope.""
    }
}"
551,Chatgpt in English Writing: Experiences and Perceptions of Saudi Efl Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Saudi English as a Foreign Language (EFL) students, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, the study is exploratory/qualitative, focusing on students who already utilize ChatGPT. There is no indication of an experimental or quasi-experimental design integrating ChatGPT as a structured instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is English writing tasks, with attention to content structuring and feedback, which are writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is based on semi-structured interviews about experiences and perceptions. No quantifiable writing outcome metrics or measured effectiveness of ChatGPT-mediated writing intervention are reported.""
    }
}"
552,An Application of Many-facet Rasch Measurement to Evaluate Automated Essay Scoring: a Case of Chatgpt-4.0,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The essays are from the International Corpus Network of Asian Learners of English (ICNALE), which consists of English language learners in Asian regions, i.e., L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT-4.0 is used solely as an automated essay scoring (AES) tool to assign scores to existing essays. There is no experimental or quasi-experimental pedagogical intervention integrating the LLM into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on evaluating ChatGPT-4.0’s performance as an AES system (severity, consistency, correlation with human raters) using many-facet Rasch measurement. There is no instructional context or intervention aimed at improving writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study does not report writing outcome gains or changes resulting from an LLM-mediated intervention. It analyzes scoring properties and rater alignment, not learner writing development or treatment effects.""
    }
}"
553,Strategic Use of Machine Translation,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are CEFR A2 university students engaged in L2 writing, but the abstract does not specify that the target language is English; it only refers to ‘foreign languages (L2)’ and ‘L2 writing’ in general.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention focuses on machine translation (MT) use and strategy instruction. MT is not identified as an LLM-based tool (e.g., ChatGPT, GPT-4, Gemini), and the study is framed around MT rather than large language models or transformer-based generative systems.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly L2 writing with MT, examining learners’ strategies in the writing process and how these change after strategy instruction, which aligns with a primary focus on writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a qualitative case study exploring strategy use and changes in strategies. Outcomes reported concern increased and more elaborate strategy use, not quantifiable writing performance metrics (e.g., scores, accuracy, complexity). Thus, it does not provide quantitative writing outcome measures required for inclusion.""
    }
}"
554,Tapping into the Pedagogical Potential of Infinigochatic: Evidence from Iwrite Scoring and Comments and Lu & Ai's Linguistic Complexity Analyzer,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are postgraduate students taking an English reading and writing course in Southwest China, clearly functioning as L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares original L2 learner texts with versions polished by infinigoChatIC using a single prompt. There is no indication of an instructional or quasi-experimental pedagogical intervention where learners interact with the LLM as part of writing instruction; instead, the teacher uses the tool offline to generate improved versions for comparison.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on how LLM-polished texts differ from learner texts in quality and linguistic complexity, not on a teaching/learning context or writing instruction process. It functions more as a text-improvement and evaluation study than a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing quality and complexity metrics are reported, they compare LLM-polished texts to learner texts without an intervention applied to learners or measurement of learner writing development over time. There is no experimental measure of LLM-mediated writing instruction outcomes on learners’ own performance.""
    }
}"
555,Distributed Agency in Second Language Learning and Teaching through Generative Ai,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses second language learning and teaching in general but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor does it focus on English specifically.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article appears to be a conceptual/theoretical discussion of generative AI (e.g., ChatGPT) affordances and agency, not an experimental or quasi-experimental study implementing an LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing is mentioned as one possible modality (chats in written or voice formats), but the focus is broad language learning, immersive technologies, and agency, not specifically on writing competence or writing-related variables as the primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or structured intervention outcomes are reported; the abstract is theoretical, addressing affordances, limitations, ethics, and agency rather than empirical measures.""
    }
}"
556,Effects of Learner Uptake Following Automatic Corrective Recast from Artificial Intelligence Chatbots on the Learning of English Caused-motion Construction,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 69 novice-level EFL learners in a Korean high school, clearly indicating L2 English learners in an EFL context with a focus on English caused-motion construction.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses “artificial intelligence (AI) chatbots” providing automatic corrective recasts. However, the abstract does not specify whether these chatbots are based on large language models (e.g., transformer-based generative models like ChatGPT/GPT-4) or on earlier rule-based/statistical systems. Without this information, it is unclear if the tool qualifies as an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary outcome is performance on elicited writing tasks (EWT) targeting the English caused-motion construction. The study examines instructional effects of AI chatbot corrective recasts on written production, aligning with a focus on writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports statistically significant gains in immediate and delayed posttests on elicited writing tasks and analyzes correlations between learner uptake and learning gains. These are quantifiable writing outcome metrics assessing the effectiveness of the AI-mediated intervention.""
    }
}"
557,The Impact of Chatgpt on L2 Writing and Expected Responses: Voice from Doctoral Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as doctoral students using ChatGPT for L2 writing, indicating they are L2 English writers in an academic context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the study is purely qualitative, using reflection papers and focus group interviews to explore views. There is no indication of an experimental or quasi-experimental design or structured pedagogical intervention being evaluated.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is clearly on L2 writing processes and how ChatGPT supports pre-, during-, and post-writing stages, as well as concerns about its use in L2 writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports thematic analysis of perceptions, benefits, drawbacks, and expectations. It does not mention any quantitative or objective writing outcome measures to assess effectiveness of ChatGPT-mediated writing intervention.""
    }
}"
558,Impact of Chatgpt on Esl Students' Academic Writing Skills: a Mixed Methods Intervention Study,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 'undergraduate ESL students' and 'tertiary level ESL students,' indicating L2 English learners in an ESL context with a focus on English academic writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses ChatGPT, described as a 'generative artificial intelligence-propelled tool,' as a formative feedback tool within an intervention study. This is an experimental/mixed-methods design integrating an LLM into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on 'academic writing skills' and the use of ChatGPT as a formative feedback tool in writing classes. The study is pedagogical, not an automated scoring evaluation, and centers on writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports that 'data were collected... through three tests' and that findings show 'a significant positive impact of ChatGPT on students' academic writing skills,' indicating quantifiable writing outcome measures within an intervention.""
    }
}"
559,The Impact of Chatgpt Feedback on the Development of Efl Students' Writing Skills,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 110 university students learning English as a Foreign Language (EFL), clearly indicating L2 English learners in an EFL context. The focus is on English writing proficiency.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention explicitly uses ChatGPT feedback as part of a quasi-experimental design. ChatGPT is a large language model integrated into the writing process as an instructional tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing skills and writing proficiency (conciseness, grammar, inclusion of key information, passive voice) in the context of foreign language education, not on automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pre-tests and post-tests to evaluate the impact of ChatGPT feedback on writing proficiency and reports significant quantitative improvements in specific writing aspects, satisfying the requirement for quantifiable writing outcomes.""
    }
}"
560,Genre-based Writing in the German Classroom in the Age of Generative Ai,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are learners in an intermediate, fifth-semester German class. The target language is German, not English, and the focus is on genre-based writing in German. The review is limited to L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The case study examines genre-based instruction in a German class without implementing ChatGPT or other LLMs as an actual intervention. Generative AI is only discussed in a final section suggesting potential future uses, not as an experimental or quasi-experimental LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing pedagogy and student writing products (film reviews) within a genre-based L2 writing framework, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantifiable writing outcomes are reported for genre-based instruction (pre/post film reviews), but there are no experimental measures of an LLM-mediated writing intervention. ChatGPT is only discussed conceptually, so no LLM-related outcome metrics are provided.""
    }
}"
561,"Learner Interaction With, and Response To, Ai-programmed Automated Writing Evaluation Feedback in Efl Writing: an Exploratory Study",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are five Chinese university-level English as a foreign language (EFL) students, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Pigai, described as an AI-programmed automated writing evaluation (AWE) system. Pigai is a traditional AWE tool, not identified as a large language model (e.g., ChatGPT, GPT-4, Gemini). The study focuses on interaction with AWE feedback, not an LLM-based generative system.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing and student interaction with automated writing evaluation feedback, clearly centered on writing processes and responses to feedback in writing tasks.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as an exploratory analysis of how students interact with Pigai feedback and their response patterns. There is no indication of experimental or quasi-experimental design with quantifiable pre/post or comparative writing outcome measures; it focuses on interaction patterns and take-up rates, not on measured changes in writing competence.""
    }
}"
562,Efl Teachers' Perceptions of the Use of an Ai Grading Tool (cograder) in English Writing Assessment at Saudi Universities: an Activity Theory Perspective,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are EFL teachers, not L2 English learners. The focus is on teachers' beliefs about an AI grading tool, not on learner outcomes or learner participants.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines perceptions of an AI grading tool (CoGrader) used for essay scoring and feedback. There is no indication that it is an LLM-based generative model integrated into instruction; it is positioned as scoring software, not as a transformer-based LLM writing assistant in an experimental or quasi-experimental intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is assessment (AI grading of essays) and teachers’ beliefs, not a pedagogical writing intervention aimed at improving writing competence. It evaluates CoGrader as a scoring and feedback tool rather than as part of a structured instructional context for writing development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports teachers’ perceptions and beliefs; it does not report quantifiable writing outcome metrics for learners or measure the effectiveness of an LLM-mediated writing intervention. No experimental writing performance data are mentioned.""
    }
}"
563,Indonesian University Students' Perspectives on Integrating Aied into English Language Learning,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Indonesian university students in English language learning contexts, which fits L2 English learners (EFL/ESL/ELL).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a quantitative survey of perceptions of AIEd tools. It lists various AI-related writing features (translation, grammar checkers, paraphrasers, idea generators, citation management) but does not specify that these are LLM-based tools (e.g., ChatGPT, GPT-4) nor implement an experimental or quasi-experimental LLM-mediated intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing skills and related tools are mentioned as questionnaire items, the primary focus is on technology acceptance and perceptions of AIEd in general, not on a structured writing instruction or intervention targeting writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports perception indices (Likert-scale scores) but no quantifiable writing performance outcomes or writing-related achievement measures resulting from an intervention.""
    }
}"
564,"Chatgpt Is Powerful, but Does It Have Power Distance? a Study of Culturally Imbued Discourse in Ai-generated Essays",2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are L1-English university learners and ChatGPT-generated texts. There is no mention of L2 English learners in ESL/EFL/ELL contexts; the comparison is between AI output and native-speaker essays.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used as a text generator for comparison, not as part of an experimental or quasi-experimental pedagogical intervention in writing instruction. No instructional design integrating LLMs into learners’ writing processes is described.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on culturally imbued discourse (power distance) in AI-generated vs. human essays, not on improving learners’ writing competence through an intervention. It is essentially a discourse/linguistic analysis of texts, not a teaching/learning context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics for learners are reported. The study reports statistical differences in linguistic features between ChatGPT and L1 essays, but not outcomes of an LLM-mediated writing intervention on learner performance.""
    }
}"
565,Investigating the Accuracy of Chatgpt as a Writing Error Correction Tool,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly refers to ESL learners and their writing errors, indicating the population is L2 English learners in an ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates ChatGPT’s accuracy as an error correction tool using pre-created data sets and content analysis. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating ChatGPT into instruction or learners’ writing processes; it is a tool-evaluation study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on ChatGPT’s error detection and correction performance across error categories, not on developing or assessing learners’ writing competence through an instructional intervention. This aligns more with system performance evaluation than with a writing pedagogy context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are accuracy levels of ChatGPT across error categories (high, moderate, low), not quantifiable changes in learners’ writing performance following an LLM-mediated intervention. No pre/post or comparative learner writing outcomes are mentioned.""
    }
}"
566,Enhancing L2 Writing Skills: Chatgpt as an Automated Feedback Tool,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Turkish pre-service teachers of English in an academic writing course, clearly functioning as L2 English learners in an EFL/ESL higher education context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly uses ChatGPT, an AI-powered large language model, as an automated feedback tool for L2 writing in a course context, integrated alongside peer and instructor feedback.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on L2 writing, specifically on using ChatGPT as a feedback tool in an academic writing course, i.e., writing instruction and the writing process.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The methodology relies on focus-group interviews and thematic analysis of perceptions about ChatGPT as a feedback tool. The abstract does not report any quantitative or experimental writing outcome measures (e.g., changes in writing scores, accuracy, complexity), and future research is suggested to examine long-term influence on L2 writing, implying such outcomes were not measured here.""
    }
}"
567,The Differential Role of Ai-operated Wcf in L2 Students' Noticing of Errors and Its Impact on Writing Scores,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 75 university undergraduate EFL students, clearly indicating L2 English learners in an EFL context. Writing tasks are IELTS Task 2 argumentative prompts, which are in English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The AI tools used are Grammarly and E-rater. These are automated writing evaluation/correction systems and are not described as large language models (e.g., ChatGPT, GPT-4, Gemini). The study focuses on AI-operated WCF via these tools, which do not qualify as LLM-based generative models under the review’s criteria.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on written corrective feedback (WCF), noticing of errors, and writing scores in argumentative writing tasks, which are core writing-related variables in L2 instruction.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The quasi-experimental design compares four feedback conditions and explicitly examines their impact on writing scores and noticing, providing quantifiable outcome measures related to writing performance.""
    }
}"
568,"Which One? Ai-assisted Language Assessment or Paper Format: an Exploration of the Impacts on Foreign Language Anxiety, Learning Attitudes, Motivation, and Writing Performance",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 70 intermediate English learners at Bangladeshi universities, clearly L2 English learners in an EFL/ESL context, with outcomes focused on English writing (TOEFL iBT writing section).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is described only as “AI-assisted language assessment” versus “paper-format assessment.” The abstract does not specify that the AI tool is a large language model (e.g., ChatGPT, GPT-4) or a transformer-based generative model integrated into writing instruction or processes. It appears to be an assessment modality rather than an LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing skills are one of several outcomes (along with foreign language anxiety, attitudes, and motivation), and the AI is used in assessment rather than clearly in instruction or process-oriented writing support. The primary focus seems broader than writing competence alone, and the pedagogical use of AI for writing is not clearly described.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: TOEFL iBT writing scores were used as pretest and posttest measures, with comparisons between experimental and control groups, even though posttest differences were not statistically significant.""
    }
}"
569,Examining Ai-based Accuracy Assessment in L2 Learners' Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract refers to L2 learners’ academic writings and mentions EFL learners, indicating a population of English L2 learners in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used solely as an evaluator of writing accuracy, compared to human raters. There is no experimental or quasi-experimental instructional intervention integrating ChatGPT into the writing process or teaching; it is a rater-functionality study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the reliability/validity of AI-based accuracy assessment (ChatGPT as an evaluator) rather than on improving writing competence through a pedagogical intervention. This aligns with automated essay scoring/assessment research, which is excluded by the review criteria.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing scores and error counts are reported, they are used to compare human vs. AI ratings, not as outcomes of an LLM-mediated instructional or writing intervention. No pre/post or controlled intervention effects on learners’ writing are examined.""
    }
}"
570,Strategic Use of Machine Translation: a Case Study of Japanese Efl University Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Japanese EFL university students at CEFR A2 level, clearly L2 English learners in an EFL context: “Japanese EFL university students… CEFR A2 university students.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention focuses on the use of machine translation (MT) in L2 writing. The abstract does not indicate that the MT system is an LLM-based generative model (e.g., ChatGPT, GPT-4). It is framed as conventional MT use, not as an LLM-integrated writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly targets L2 writing processes and strategies with MT: “research on MT use in L2 writing… explore how… students employ strategies for L2 writing with MT and how their strategies change after strategy instruction.” The primary focus is on writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are qualitative changes in strategy use and cognitive engagement, not quantifiable writing performance metrics. The abstract reports increased and more elaborate strategy use, but no measured writing quality scores or other quantitative writing outcomes.""
    }
}"
571,Incorporating Ai in Foreign Language Education: an Investigation into Chatgpt's Effect on Foreign Language Learners,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as ‘preparatory class students studying at the School of Foreign Languages at a university in Turkey.’ The target language is not explicitly stated as English, only ‘foreign language education.’ It is therefore unclear whether they are L2 English learners or learners of another language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study ‘aimed to utilize ChatGPT in foreign language education’ and students ‘were introduced to ChatGPT through learning experiences over a span of four weeks.’ ChatGPT is an LLM and is integrated into instruction, satisfying the LLM-based intervention requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract notes that ChatGPT ‘positively affects students' learning experiences, especially in writing, grammar, and vocabulary acquisition,’ and that it is used ‘in various learning activities.’ Writing is explicitly mentioned as a focus area within the language learning context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as a ‘qualitative case study’ with data from interviews analyzed via thematic analysis. No mention is made of quantitative or experimental writing outcome measures; findings are reported in terms of perceived effects and experiences, not measurable writing performance.""
    }
}"
572,Leveraging Chatgpt in the Writing Classrooms: Theoretical and Practical Insights,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “second language (L2) writing pedagogy” and “L2 writing teachers and students,” but does not specify that the target language is English or that participants are ESL/EFL/ELL learners. It appears conceptual rather than reporting on a specific participant population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper is described as exploring the potential of integrating ChatGPT and providing theoretical and practical insights, challenges, and recommendations. There is no indication of an experimental or quasi-experimental design, nor of an implemented LLM-based intervention with participants.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus is on L2 writing pedagogy and integrating ChatGPT into stages of the writing process, the article is conceptual and pedagogical rather than an empirical study of a specific instructional context or intervention with measured outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or empirical assessment of effectiveness. It offers theoretical discussion, challenges, and research recommendations, but no reported intervention results or metrics.""
    }
}"
573,"Teacher- Versus Ai-generated (poe Application) Corrective Feedback and Language Learners' Writing Anxiety, Complexity, Fluency, and Accuracy",2024,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described only as “language learners” and “undergraduate language learners at East China University of Political Science and Law.” The abstract does not explicitly state that they are L2 English learners, nor that the target language is English. The mention of ‘primary school settings’ at the end further confuses the context. Thus, it is unclear whether the population is L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses an “AI-driven application called Poe” that provides corrective feedback. However, the abstract does not specify whether Poe is using a large language model (e.g., GPT-based, transformer generative model) or some other AI technology. Without confirmation that Poe is LLM-based, it is unclear whether this meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on writing-related variables: writing anxiety, writing complexity, fluency, and accuracy. The intervention is corrective feedback on learners’ writing, not automated essay scoring or purely functional evaluation of an AI system. Thus, the primary focus aligns with writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental pretest–posttest design with three groups and reports quantitative outcomes on writing complexity, fluency, accuracy, and writing anxiety, analyzed via one-way ANOVA. These are quantifiable writing outcome metrics assessing the effectiveness of the AI-mediated writing intervention.""
    }
}"
574,Exploratory Study on the Potential of Chatgpt as a Rater of Second Language Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Korean secondary-level EFL students writing English essays, clearly fitting an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT (GPT-4) is used as an automated writing evaluation (AWE) scoring tool, not as part of an instructional or experimental/quasi-experimental pedagogical intervention in writing. The focus is on rating reliability, not on integrating LLMs into writing instruction or processes for learning.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on assessment—comparing ChatGPT’s essay scores with human raters—rather than on improving writing competence or writing-related learning outcomes. This aligns with automated essay scoring functionality, which the criteria specify should be excluded.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports reliability metrics (intraclass correlation, Rasch model deviations) for scoring, not quantifiable outcomes of an LLM-mediated writing intervention (e.g., changes in learners’ writing performance after using ChatGPT). There is no structured instructional intervention with pre/post writing measures.""
    }
}"
575,Facilitating Learners' Self-assessment during Formative Writing Tasks Using Writing Analytics Toolkit,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers only to “learners” and does not specify that they are L2 English learners in ESL/EFL/ELL contexts, nor that the target language is English. Their language background and instructional context are not described.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is a “writing analytics toolkit” using “data visualisation and cutting-edge machine learning technology” to provide feedback. There is no indication that it is based on large language models (e.g., ChatGPT, GPT-4, transformer-based generative models). It appears to be an analytics/ML feedback tool rather than an LLM-integrated writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on formative writing tasks, revision, and self-assessment of writing products and processes. The primary context is writing competence and writing-related processes (self-assessment during writing).""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative outcomes: differences in self-assessment accuracy between experimental and control groups, and analysis of self-assessment processes. These are structured, measurable outcomes related to the writing process.""
    }
}"
576,The Effect of Chatgpt-integrated English Teaching on High School Efl Learners' Writing Skills and Vocabulary Development,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 10th grade Turkish EFL learners in English lessons. The focus is explicitly on English as a foreign language, satisfying the requirement for L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines “ChatGPT-integrated English lessons” and compares an experimental group receiving ChatGPT-integrated vocabulary and writing instruction with a control group receiving traditional instruction, indicating an experimental/quasi-experimental LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary outcomes are “writing skill and vocabulary development,” and the intervention is explicitly described as vocabulary and writing instruction. The focus is pedagogical, not on automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pre- and post-tests for writing and vocabulary, analyzed statistically with SPSS, and reports comparative effects of traditional vs. ChatGPT-integrated instruction. This provides quantifiable writing outcome metrics.""
    }
}"
577,Potentials and Implications of Chatgpt for Esl Writing Instruction,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a systematic review and meta-analysis of prior research on ChatGPT for L2 writing instruction. It does not report on a specific primary study with its own participant sample of L2 English learners; instead, it synthesizes other studies.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic review, the paper does not itself implement an experimental or quasi-experimental LLM-based writing intervention; it only summarizes existing research on ChatGPT’s educational potentials.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus is on L2 writing instruction, the article is a secondary study (systematic review/meta-analysis) rather than a primary pedagogical intervention study, which the inclusion criteria explicitly exclude.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports synthesized findings (e.g., boosting motivation, automating tasks, providing feedback) but does not present original, quantifiable writing outcome metrics from a primary intervention; as a review/meta-analysis, it falls under excluded publication types.""
    }
}"
578,Enhancing English as a Foreign Language (efl) Learners' Writing with Chatgpt: a University-level Course Design,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as university-level English as a Foreign Language (EFL) learners, which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study clearly integrates OpenAI’s GPT-3.5 (an LLM) into a writing course and discusses course design (ADDIE, TPACK). However, the abstract does not specify whether there is an experimental or quasi-experimental design (e.g., control group, pre/post comparison, or structured intervention study) versus a purely design-oriented or descriptive implementation.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on an EFL writing course and on improving aspects of writing such as efficiency, organization, and feedback, indicating that the primary context is writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports that GPT-3.5 ‘enhances efficiency,’ ‘ensures cohesive organization,’ and ‘promotes writing proficiency,’ but it does not indicate whether these findings are based on quantifiable writing outcome metrics (e.g., scores, rubric-based assessments, statistical comparisons) or are derived from qualitative/descriptive evaluation only.""
    }
}"
579,Generating Genre-based Automatic Feedback on English for Research Publication Purposes,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to L2 writers and multilingual classrooms and to English for research publication purposes, but does not specify that the participants are L2 English learners in ESL/EFL/ELL contexts, nor does it clearly describe an empirical learner sample.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on the development of an AI-mediated L2 writing technology leveraging large language models and reports on the accuracy, precision, and recall of its network classification. It appears to be a system-development and evaluation study, not an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction with learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on generating genre-based automatic feedback and evaluating the performance of the classification network (accuracy, precision, recall). It is framed as tool development and automated feedback provision, not as an implemented writing intervention with measured effects on learners’ writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Reported outcomes are technical metrics of the system (accuracy, precision, recall of classification). There is no indication of quantifiable writing outcome measures (e.g., changes in writing quality, complexity, accuracy) for L2 learners following an LLM-mediated writing intervention.""
    }
}"
580,A Study on Chatgpt-4 as an Innovative Approach to Enhancing English as a Foreign Language Writing Learning,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 76 undergraduate students in Algeria learning English as a Foreign Language (EFL). The abstract explicitly focuses on EFL writing, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is the use of ChatGPT-4, explicitly named as the tool used by the experimental group to support EFL writing. ChatGPT-4 is a large language model, and the study uses an experimental design with experimental and control groups.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL writing learning and how ChatGPT-4 is used to address challenges in EFL writing. The outcome discussed is improvement in EFL writing skills, not automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports that the experimental group outperformed the control group and that post-test scores exceeded pre-test scores, indicating quantifiable writing outcome measures. Additional quantitative measures include perceived usefulness, ease of use, attitudes, and behavioral intention.""
    }
}"
581,Towards a Taxonomy of Artificial Intelligence in Teaching Writing in a Foreign Language,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to 'foreign language teaching' and 'teaching writing in a foreign language' without specifying English or L2 English learners (ESL/EFL/ELL). The target language and learner population are not clearly identified.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article aims to identify characteristics and capacities of AI sites and proposes a taxonomy, describing advantages, disadvantages, and potential applications. There is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into instruction; it appears to be a conceptual/overview piece.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus is on AI in teaching writing in a foreign language, the work is described as proposing a taxonomy, describing tools, and suggesting applications, rather than implementing and evaluating a concrete pedagogical intervention in writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any empirical data collection or quantifiable writing outcome measures. It focuses on taxonomy, description, and evaluation of benefits/drawbacks at a conceptual level, without reporting experimental outcomes.""
    }
}"
582,Using Ai-generative Tools in Tertiary Education: Reflections on Their Effectiveness in Improving Tertiary Students' English Writing Abilities,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The population is ‘tertiary students’ in Hong Kong, and the study focuses on their English writing abilities, implying L2 English learners in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions ‘AI-generative tools, such as ChatGPT’ and ‘their experience using AI in learning and writing,’ but does not clearly describe an experimental or quasi-experimental instructional intervention; it appears more exploratory/reflective.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The stated aim is to find out whether AI-generative tools can help improve students’ English writing skills, and the context is explicitly about using AI in writing and learning writing skills.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Methods are described as interviews to gather opinions from students and teachers. No mention is made of quantitative writing outcome measures or experimental evaluation of writing performance; the focus is on perceptions and reflections.""
    }
}"
583,An Investigation of Artificial Intelligence Tools in Editorial Tasks among Arab Researchers Publishing in English,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are described as 'Arab researchers who publish in English,' i.e., academic researchers using English for publication, not L2 English learners in ESL/EFL/ELL instructional contexts. The focus is on scholarly publishing practices, not language learners in educational settings.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study surveys use of AI tools such as Grammarly, Endnote, and QuillBot. These are not clearly LLM-based writing-intervention tools in an experimental or quasi-experimental design; rather, they are general-purpose editorial aids, and no structured pedagogical intervention is implemented.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is editorial tasks in scholarly publishing, not an instructional setting focused on developing writing competence. The study examines adoption, challenges, and ethics of AI tools, not a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports survey-based perceptions of usage, challenges, and ethical considerations. It does not report quantifiable writing outcome metrics (e.g., changes in writing quality, scores, or performance) resulting from an AI-mediated writing intervention.""
    }
}"
584,Analyzing the Use of Ai Writing Assistants in Generating Texts with Standard American English Conventions: a Case Study of Chatgpt and Bard,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any human participants, learners, or educational setting (ESL/EFL/ELL). It analyzes AI-generated texts using corpus methods, not data from L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT and Bard are examined as text generators, but there is no experimental or quasi-experimental pedagogical intervention integrating these LLMs into writing instruction or learner writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on linguistic conventions and collocational patterns in AI-generated texts and their implications, not on an instructional context aimed at improving learner writing competence through LLM use.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics for learners are reported. The study is a corpus-based analysis of AI output, with only general pedagogical implications, not measured intervention outcomes.""
    }
}"
585,Network Algorithms for Intelligent Evaluation of Composition in Middle School English Cloud Classrooms,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions 'English compositions for middle school students' but does not specify whether these are L2 English learners (ESL/EFL/ELL) or native speakers. The learner population and L2 status are not clearly identified.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study proposes a method combining a link grammar detector with an N-grammar model and compares it to Grammarly. This is an automated scoring/evaluation algorithm, not an LLM-based (e.g., ChatGPT, GPT-4) intervention integrated into writing instruction or processes. No large language model is mentioned.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automated evaluation and scoring of compositions (accuracy, recall, mean square error, runtime) rather than on a pedagogical writing intervention or development of writing competence. It is essentially an automated essay scoring system.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although quantitative metrics are reported, they concern system performance (recall, accuracy, error vs. manual scoring, MSE, runtime), not learner writing outcomes following an LLM-mediated instructional intervention. No experimental measures of changes in students’ writing performance are provided.""
    }
}"
586,Can My Writing Be Polished Further? When Chatgpt Meets Human Touch,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL learners (“19 EFL learners”), indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study investigates the use of ChatGPT, a large language model, in EFL writing classrooms and describes a collaborative writing process with ChatGPT, indicating an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL writing processes and refinement (grammar correction, vocabulary enrichment, sentence structuring) within a classroom context, aligning with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports think-aloud sessions, interviews, and qualitative findings about collaborative work, emotional reassurance, and metacognitive awareness. It does not mention any experimental or quasi-experimental design with quantifiable writing outcome metrics (e.g., scores, rubric-based gains, pre-post tests).""
    }
}"
587,To Resist It or to Embrace It? Examining Chatgpt's Potential to Support Teacher Feedback in Efl Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses 50 English argumentative essays composed by Chinese undergraduate students in an EFL context, clearly involving L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is exploratory and examines ChatGPT’s potential to support teacher feedback by comparing ChatGPT- and teacher-generated feedback and surveying teacher perceptions. There is no described experimental or quasi-experimental pedagogical intervention where learners use ChatGPT within a structured writing instruction or process.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on evaluating ChatGPT’s feedback characteristics and teachers’ perceptions, not on an implemented writing intervention. It does not describe an instructional context where ChatGPT is integrated into teaching to improve writing competence; rather, it analyzes feedback quantity/type and attitudes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcome metrics (e.g., pre/post writing scores, quality ratings) are reported. The study compares feedback features and gathers teacher perceptions, but does not measure changes in students’ writing performance resulting from an LLM-mediated intervention.""
    }
}"
588,"Automated Writing Evaluation Systems: a Systematic Review of Grammarly, Pigai, and Criterion with a Perspective on Future Directions in the Age of Generative Artificial Intelligence",2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a systematic review of studies on Grammarly, Pigai, and Criterion. While many included primary studies involve non-native English-speaking students, this paper itself is not an empirical study with a defined participant population; it is a secondary review article, which falls under the exclusion criteria.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on automated writing evaluation systems (Grammarly, Pigai, Criterion), which are not described as large language model-based generative tools. Moreover, the article is a review, not an experimental or quasi-experimental intervention study integrating LLMs into writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is writing and AWE systems, the paper is a systematic review of existing tools and studies, not a primary pedagogical intervention study. The review nature places it outside the scope of the targeted intervention-focused systematic review.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The article synthesizes findings from 39 studies but does not itself report original, quantifiable writing outcome metrics from an LLM-mediated intervention. As a review article, it is excluded by the protocol.""
    }
}"
589,Adopting Chatgpt as a Writing Buddy in the Advanced L2 Writing Class,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are advanced L2 writers of German producing summaries in L2 German. The focus is on German as the target language, not English (ESL/EFL/ELL), so the population does not meet the review’s requirement of L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study integrates ChatGPT-3.5 (an LLM) into a classroom-based writing intervention. Students compare their drafts with ChatGPT-produced texts and then revise their own writing, which constitutes an LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly the L2 writing and revision process. ChatGPT is used as a writing buddy/model to support revision, and the study examines how this affects students’ revision behavior and writing processes, not automated scoring.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions rubric-based ratings of ChatGPT models and coded revision processes (focus, source, success), and notes that students improved their texts. However, it does not clearly state that quantifiable writing outcome metrics (e.g., pre/post writing quality scores) for students’ own writing were reported, so it is unclear if formal writing outcome measures are included.""
    }
}"
590,“chatgpt Seems Too Good to Be True”: College Students’ Use and Perceptions of Generative Ai,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are U.S. college students in general; while some are non-native English speakers, the study is not situated in an ESL/EFL/ELL instructional context nor focused specifically on L2 English learners as the target population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is examined as a tool students choose to use, but there is no experimental or quasi-experimental instructional intervention integrating LLMs into writing instruction or structured writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on perceptions and patterns of ChatGPT use across general, writing, and programming tasks, not on a pedagogical writing intervention or systematic development of writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or pre/post measures of writing performance are reported; the study centers on usage frequency, demographics, and attitudes.""
    }
}"
591,Identifying Chatgpt-generated Texts in Efl Students’ Writing: through Comparative Analysis of Linguistic Fingerprints,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Japanese EFL learners (140 first-year university students), clearly fitting an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is present but not as a structured instructional intervention. The study focuses on distinguishability of human vs. ChatGPT-generated texts and students’ incidental use (proofreading or full generation), not on an experimental or quasi-experimental LLM-based writing pedagogy or designed writing support process.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on detecting ChatGPT-generated texts via linguistic fingerprints and machine learning classification, not on improving writing competence or evaluating a pedagogical writing intervention. It is essentially a detection/forensics study, not a writing instruction study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality gains, accuracy, complexity) are reported to assess the effectiveness of an LLM-mediated intervention. Outcomes concern distinguishability and classification performance, not changes in learners’ writing performance.""
    }
}"
592,Using Chatgpt for Second Language Writing: Experiences and Perceptions of Efl Learners in Thailand and Vietnam,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Thai and Vietnamese EFL learners using ChatGPT for second language (L2) writing, clearly indicating L2 English learners in EFL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study concerns ChatGPT use, it is an exploratory survey/interview study of learners’ experiences and perceptions. There is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction or processes; rather, it documents existing practices and attitudes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on using ChatGPT for L2 writing (brainstorming, organizing ideas, refining outlines, editing drafts), which is directly related to writing competence and writing-related practices.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are perceptions and experiences (e.g., perceived usefulness, engagement, differences in perceptions between Thai and Vietnamese learners). The abstract does not mention any quantifiable writing performance metrics or measured changes in writing quality resulting from ChatGPT use.""
    }
}"
593,Evaluating the Role of Chatgpt in Enhancing Efl Writing Assessments in Classroom Settings: a Preliminary Investigation,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners: 30 CET-4 essays written by non-English majors at a university in Beijing, China. The context is clearly English-as-a-foreign-language writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT 3.5 and 4 are used as raters to assign holistic scores and provide feedback on existing essays. There is no experimental or quasi-experimental instructional intervention integrating LLMs into the writing process; the focus is on assessment reliability and feedback relevance, not on a teaching/learning intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on writing assessment—reliability of holistic scores and relevance of feedback—rather than on improving learners’ writing competence through a pedagogical intervention. It functions as an evaluation of LLMs as automated raters/feedback providers, not as a structured instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcome measures (e.g., pre/post writing quality, accuracy, complexity) are reported. Outcomes concern reliability coefficients of ChatGPT vs. teachers and relevance of feedback, not changes in students’ writing performance following an LLM-mediated intervention.""
    }
}"
594,The Grass Is Not Always Greener: Teacher Vs. Gpt-assisted Written Corrective Feedback,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to student writing and L2 writing practice but does not specify that participants are L2 English learners or that the target language is English. The learner population and language are not explicitly identified.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares written corrective feedback (WCF) produced by teachers and ChatGPT, focusing on their characteristics. There is no indication of an experimental or quasi-experimental pedagogical intervention where LLMs are integrated into instruction or writing processes; rather, it is an analytic comparison of feedback types.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the topic is WCF in L2 writing, the primary focus is on describing and contrasting teacher vs. ChatGPT feedback practices, not on an instructional intervention aimed at improving writing competence. It does not describe an implemented teaching/learning context using LLMs with learners.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative findings about the nature, accuracy, and variability of teacher vs. ChatGPT WCF. It does not mention any quantitative writing outcome measures (e.g., pre/post writing scores, error rates, rubric-based gains) assessing the effectiveness of LLM-mediated intervention.""
    }
}"
595,"Brave New World or Not?: a Mixed-methods Study of the Relationship between Second Language Writing Learners' Perceptions of Chatgpt, Behaviors of Using Chatgpt, and Writing Proficiency",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'second or foreign language (L2) writing learners' at university level, and the outcomes are L2 writing proficiency measures (complexity, accuracy, fluency), which in this context strongly implies L2 English learners in an ESL/EFL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines learners’ perceptions of ChatGPT and their self-reported usage behaviors. There is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction; rather, it is a correlational/mixed-methods study of existing usage.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 writing proficiency (complexity, accuracy, fluency) and how these relate to ChatGPT usage, clearly centering on writing competence rather than automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study reports quantitative writing proficiency measures, these are not outcomes of a structured LLM-mediated writing intervention. The design does not manipulate or implement ChatGPT as an instructional treatment; it only examines associations between existing usage and proficiency, which falls outside the required intervention-outcome framework.""
    }
}"
596,Using Generative Ai to Provide High-quality Lexicographic Assistance to Chinese Learners of English,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly targets “Chinese learners of English,” which fits the L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper explores how generative AI (ChatGPT, Ernie Bot) can be used to produce explanations and argues for their integration into writing assistants, but it does not describe an experimental or quasi-experimental pedagogical intervention where LLMs are actually integrated into learners’ writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on lexicographic assistance and error explanations (subject-verb disagreement) for potential use in writing assistants. While related to writing, the abstract centers on tool development and comparison of chatbots, not on an implemented writing intervention or measured writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study discusses identification of error subcategories and the quality of AI-generated explanations, but does not measure changes in learners’ writing performance or related variables.""
    }
}"
597,Instructors' and Learners' Perspectives on Using Chatgpt in English as a Foreign Language Courses and Its Effect on Academic Integrity,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are university learners of English as a foreign language (EFL), which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) was used and integrated into teaching for one trimester, the study focuses on perspectives and academic integrity rather than an experimental or quasi-experimental evaluation of a structured LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on attitudes toward ChatGPT use in EFL learning and its implications for academic integrity. While written work is mentioned, the study does not center on writing competence or writing-related instructional interventions as the main outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses questionnaires, open-ended responses, and interviews to gather opinions and attitudes. It does not report quantifiable writing outcome metrics (e.g., writing scores, quality measures) to assess the effectiveness of ChatGPT-mediated writing interventions.""
    }
}"
598,A Case Study of Implementing Generative Ai in University's General English Courses,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as English as a foreign language (EFL) learners in Korean university-level general English courses, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that learners were exposed to a \""generative AI-based instruction model\"" but does not specify whether this is an LLM (e.g., ChatGPT/GPT-4) or another type of generative AI. However, it is at least plausible that LLMs are involved.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract notes that the AI-based instruction is for \""writing and speaking\"" and mentions supporting linguistic proficiency, but the primary stated research focus is on affective factors (motivation, interest, confidence). It is not clear that writing competence or writing-related variables are the primary focus of the study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as investigating effects on affective factors (motivation, interest, confidence). There is no indication that quantifiable writing outcome metrics (e.g., writing scores, text quality measures) were collected or reported; writing is only mentioned generally as a skill area, not as an assessed outcome.""
    }
}"
599,Investigating Students' Uptake of Teacher- and Chatgpt-generated Feedback in Efl Writing: a Comparison Study,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL students: “Twenty Chinese undergraduate students participated in the study… in the context of argumentative writing.” This fits L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used to generate feedback, the design is not an experimental or quasi-experimental intervention assessing the effectiveness of an LLM-mediated writing instruction. It is a comparison of uptake of teacher vs. ChatGPT feedback without a structured pedagogical intervention aimed at testing LLM-based instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL writing: students compose argumentative essays, receive feedback, and revise. The study examines engagement with feedback and revision quality, which are writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are engagement with feedback and appropriateness/accuracy of revisions, not quantifiable writing competence measures (e.g., holistic/analytic writing scores, complexity/accuracy/fluency metrics) used to assess the effectiveness of an LLM-mediated intervention. The study is primarily about feedback uptake and perceptions rather than experimental writing outcome metrics.""
    }
}"
600,Uncovering Students' Processing Tactics towards Chatgpt's Feedback in Efl Education Using Learning Analytics,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as EFL students (“potential use in English as a Foreign Language (EFL) education”), indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines students’ interaction with ChatGPT, a generative AI chatbot based on LLMs, during reading and writing tasks. It analyzes their processing tactics toward ChatGPT’s feedback, implying an LLM-mediated learning activity, though the design is observational/analytic rather than a controlled intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although reading and writing tasks are mentioned, the primary focus is on processing tactics toward ChatGPT’s feedback and learning modes, with outcomes framed as ‘improvement of domain knowledge’ rather than writing competence or writing-related variables. Writing development is not the central measured construct.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantitative outcomes reported concern ‘differences in learning gains… specifically in the improvement of domain knowledge.’ There is no indication of quantifiable writing outcome metrics (e.g., writing quality scores, accuracy, complexity) to assess effectiveness of LLM-mediated writing intervention.""
    }
}"
601,Metacognitive Mastery: Transformative Learning in Efl through a Generative Ai Chatbot Fueled by Metalinguistic Guidance,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL students, i.e., learners of English as a foreign language, which fits the target L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a Generative AI Chatbot (GAC) and compares CF-based GAC vs. MG-based GAC in a quasi-experimental pretest–posttest design. GAC is a generative AI chatbot, consistent with an LLM-type intervention integrated into instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is EFL linguistics courses, focusing on learning achievement, reflective performance, perception, and metacognitive awareness. The abstract does not indicate that the primary focus is on writing competence or writing-related variables; it appears to target general course learning and metacognition rather than writing.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study reports quantitative outcomes (learning achievement, reflective performance, metacognitive awareness), but the abstract does not specify that these are writing outcomes or writing performance measures. They seem to be broader learning and cognitive measures, not writing-specific metrics.""
    }
}"
602,Exploring Efl Learners' Integration and Perceptions of Chatgpt's Text Revisions: a Three-stage Writing Task Study,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) learners in an EFL classroom context, so the population is L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT’s reformulations as feedback within a three-stage writing task (composing–comparison–rewriting), which constitutes an LLM-based writing intervention in an instructional context.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL writing: learners compose, compare their texts with ChatGPT reformulations, and then rewrite. The study examines how ChatGPT-mediated feedback affects revision behavior in writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports noticing behaviors, integration of reformulated segments, and perceptions via questionnaire, but does not indicate any quantifiable writing outcome metrics (e.g., scores, quality ratings, accuracy measures) assessing improvement in writing performance. The integration counts are process measures, not outcome measures of writing competence.""
    }
}"
603,Chatgpt as a Tool for Self-learning English among Efl Learners: a Multi-methods Study,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 344 English as a Foreign Language (EFL) learners, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines factors influencing ChatGPT acceptance and use in self-directed English learning via survey and interviews, plus a systematic review. There is no experimental or quasi-experimental design implementing a structured LLM-based writing intervention; it is a technology acceptance/usage study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing is mentioned as one of several language dimensions (reading, writing, vocabulary, grammar), the primary focus is on general English learning and technology acceptance, not specifically on writing competence or writing-related variables as the main outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports factors affecting continued use (interactivity, enjoyment, trust, etc.) and proposes an extended TAM. It does not report quantifiable writing outcome metrics or measure changes in writing performance resulting from a ChatGPT-mediated writing intervention.""
    }
}"
604,Ai or Student Writing? Analyzing the Situational and Linguistic Characteristics of Undergraduate Student Writing and Ai-generated Assignments,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The corpus consists of undergraduate assignments from an English as a Foreign Language (EFL) context, so participants are L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares existing student assignments with ChatGPT-generated texts; there is no experimental or quasi-experimental pedagogical intervention integrating ChatGPT into instruction or students’ writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on analyzing situational and linguistic characteristics of human vs. AI-generated texts, not on improving writing competence through an instructional intervention. It is essentially a comparative text/register analysis, not a writing intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics for learners are reported. The study does not measure changes in students’ writing performance following an LLM-mediated intervention; it only analyzes and compares text features.""
    }
}"
605,Ai-powered Efl Pedagogy: Integrating Generative Ai into University Teaching Preparation through Utaut and Activity Theory,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are EFL lecturers in Indonesian higher education, focusing on their adoption of generative AI for teaching preparation. The population is teachers, not L2 English learners, and no learner writing data are mentioned.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study involves generative AI in EFL teaching preparation, but the abstract does not specify that LLMs are integrated into learners’ writing instruction or writing processes in an experimental or quasi-experimental way. It focuses on adoption factors via UTAUT and Activity Theory.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on EFL pedagogy and lecturers’ adoption of generative AI, not on writing competence or writing-related variables. Writing is not identified as a central outcome domain.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes concern behavioral intention, actual use behavior, and factors influencing adoption, not learners’ writing performance.""
    }
}"
606,Success through Error: Using Error Analysis of Chatgpt Output in English as a Foreign Language Learner Writing Instruction,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were Arabic-English speakers in an English communication course, described as foreign language learners (EFL) with proficiency from modest to competent per IELTS. The focus is clearly on English as the target L2.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses ChatGPT-generated text for in-class error detection exercises in an English communication course. ChatGPT is a large language model, and the design compares a treatment condition (with ChatGPT) to a control condition (without ChatGPT), fitting an experimental/quasi-experimental LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly aims to see whether ChatGPT-based error detection exercises can aid students’ foreign language writing. The primary outcomes are writing-related (essay length, lexical sophistication, syntactic complexity), indicating a focus on writing competence rather than on automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantifiable writing outcomes are reported: essay length (number of words, number of sentences, sentence length) and quality indicators such as use of low-frequency and abstract words and complex syntactic structures. The study compares these metrics between treatment and control groups to assess the effect of the ChatGPT-mediated intervention.""
    }
}"
607,"Unlocking English Proficiency: Transforming the English Learning Curriculum for Colombian Middle Schoolers with Ipt Powered by Elsa’s Ai-assisted App & Asr; Desbloqueando a Competência Em Inglês: Transformando O Currículo De Aprendizagem De Inglês Para Alunos Colombianos Do Ensino Médio Com Ipt Alimentado Pelo Aplicativo Assistido Por Ia Da Elsa E Asr; Desbloqueando La Proficiencia En Inglés: Cómo La Aplicación Asistida Por Inteligencia Artificial Elsa, Basada En Asr E Ipt, Beneficia La Competencia En Inglés De Los Estudiantes De Educación Secundaria En Colombia",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Colombian middle school students learning English as a Foreign Language (EFL), and the focus is on English proficiency (intonation, fluency, pronunciation, listening, writing, and reading).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Elsa Speak, described as an AI app with Automatic Speech Recognition (ASR) and Intentional Phonetic Training (IPT). There is no indication that it is based on a large language model (e.g., ChatGPT/GPT-4 or similar transformer-based generative model); it is primarily an ASR/phonetics tool.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on pronunciation, intonation, fluency, and phonetic skills. Writing is only mentioned as being indirectly affected; there is no indication that the intervention targets writing instruction or writing processes as a main focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are mainly IELTS Speaking scores and improvements in pronunciation-related skills. There are no explicit, quantifiable writing outcome measures reported to assess writing performance or writing-related variables.""
    }
}"
608,Generative Ai’s Recolonization of Efl Classrooms the Case of Continuation Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is Chinese English as a Foreign Language (EFL) classrooms and continuation writing in China’s EFL assessment, so the population is clearly L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study discusses using generative AI to provide sample writings and illustrates arguments with data generated via AI chatbots, but there is no indication of an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction. It is a critical/analytical paper, not an intervention study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on ideological and cultural implications (recolonization, native-speakerism, power in language patterns) of AI-generated texts, not on developing or evaluating writing competence or a writing intervention. There is no structured pedagogical context aimed at improving writing performance.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or assessment of learners’ writing performance. It focuses on linguistic analysis of AI-generated samples and theoretical risks, without reporting experimental outcomes.""
    }
}"
609,Worddecipher: Enhancing Digital Workspace Communication with Explainable Ai for Non-native English Speakers,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are described broadly as non-native English speakers (NNES) in digital workspace communication, not as L2 English learners in ESL/EFL/ELL instructional contexts. The focus is workplace communication rather than formal L2 learning settings.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states that WordDecipher leverages large language models (LLMs) and word embeddings as an AI-assisted writing tool, indicating an LLM-based intervention in writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on enhancing digital workspace communication (emails, Slack messages) and social intention clarity, not on developing writing competence in an educational or instructional context. It is a communication support tool rather than a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions a usage scenario demonstrating potential benefits but does not report any experimental or quasi-experimental design with quantifiable writing outcome metrics. There are no measured writing gains or structured intervention outcomes.""
    }
}"
610,"Proceedings of the 3rd Workshop on Intelligent and Interactive Writing Assistants, In2writing 2024, Co-located with the Acm Chi Conference on Human Factors in Computing Systems, Chi 2024",2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract summarizes a proceedings volume with 17 papers on AI writing assistants. It mentions non-native English speakers and students, but does not specify that any study focuses on L2 English learners in ESL/EFL/ELL contexts, nor that data are specifically about English as a target L2.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""Several papers involve AI/LLM-based writing assistants (e.g., ChatGPT, LLMs for educational materials), but the abstract does not clarify whether any individual paper uses an experimental or quasi-experimental design integrating LLMs into writing instruction or processes. It mainly lists themes and systems, not study designs.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Some topics relate to writing (essay writing, personal narrative co-writing, AI-based writing assistants), but the proceedings as a whole cover broader HCI and ecosystem issues. It is not clear that any specific paper’s primary focus is on L2 writing competence or writing-related pedagogical variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not indicate that any paper reports quantifiable writing outcome metrics (e.g., writing quality scores, complexity, accuracy). It mentions empirical studies of use and ownership, risks, and interaction patterns, but no explicit experimental measures of writing improvement or performance are described.""
    }
}"
611,They May Have Seen My Chatgpt Tab: Exploring Social Perceptions of Ai-assisted Writing for Esl Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on English as a Second Language (ESL) students using generative AI tools to improve their writing artifacts, so the population is L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although generative AI tools (likely LLM-based) are mentioned, the study is not an experimental or quasi-experimental intervention integrating LLMs into instruction. It is a diary and interview study about perceptions and social dynamics, not a designed pedagogical intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on social perceptions and socio-technical implications of AI usage, not on writing competence or writing-related performance variables as an instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses diary studies and interviews and does not report any quantifiable writing outcome metrics or experimental measures of writing performance; it is qualitative and exploratory.""
    }
}"
612,Exploring Chatgpt-supported Teacher Feedback in the Efl Context,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 102 students in a Chinese tertiary EFL context, clearly L2 English learners in an EFL setting: “Chinese tertiary EFL context… two undergraduate classes in the world language education program.”""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study integrates ChatGPT (an LLM) into writing pedagogy: “integrating ChatGPT into teacher writing feedback provisions… Two prompts were provided to ChatGPT… corrective feedback… holistic rhetorical feedback. Afterwards, the teachers adapted the ChatGPT feedback and shared… with each student.” This is an LLM-mediated feedback intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on L2 writing feedback and revision: “students completed two writing tasks… we closely examined the types and features of ChatGPT-supported teacher feedback and how EFL students incorporate this feedback into their writing revisions… potential in L2 writing feedback provision.” This is clearly writing-focused.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports engagement with feedback and incorporation into revisions but does not indicate any quantifiable writing outcome metrics (e.g., scores, accuracy, complexity, quality gains). It appears descriptive/qualitative: “we closely examined… types and features… how students incorporate this feedback… students incorporated more of the feedback into their revisions,” without explicit experimental measures of writing performance improvement.""
    }
}"
613,Cognitive and Sociocultural Dynamics of Self-regulated Use of Machine Translation and Generative Ai Tools in Academic Efl Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 79 learners in a compulsory EFL course at a Japanese university, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on students’ self-regulated use of AI tools (ChatGPT and Google Translate) rather than an experimental or quasi-experimental instructional intervention. There is no indication of a structured LLM-mediated teaching design; instead, it examines naturally occurring use and perceptions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is academic EFL writing, and the tools are used for writing tasks and editing, so the primary focus is on writing-related activity.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are based on pre- and post-surveys of attitudes and perceived improvement. There is no report of objective, quantifiable writing performance measures (e.g., scores, linguistic features); the study centers on perceptions and experiences.""
    }
}"
614,Chatgpt as an Automated Writing Evaluation (awe) Tool: Feedback Literacy Development and Awe Tools' Integration Framework,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 18 English as a Foreign Language (EFL) students in Indonesia, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""ChatGPT (an LLM-based generative AI) is used as part of an automated writing evaluation (AWE) toolset in a writing course, integrated into the instructional context alongside Grammarly and Quillbot.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on feedback literacy development and proposing an AWE Tools Integration Framework, not on writing competence or writing-related performance variables. Writing is the context, but the outcome of interest is feedback literacy, not writing quality or ability.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a single qualitative case study design with interviews, reflective journals, and artifacts, and reports thematic findings. There is no indication of quantifiable writing outcome metrics or experimental evaluation of changes in writing performance.""
    }
}"
615,Exploring Ai-generated Text in Student Writing: How Does Ai Help?,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 23 Hong Kong secondary school students described as English as a foreign language (EFL) students, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines students’ use of unspecified “AI-writing tools” that generate human-like text. There is no indication these are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems; the tools are not named or characterized as LLMs. Given the review’s strict requirement for LLM-based interventions, this cannot be confirmed and thus fails C2.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on story writing: students wrote stories with AI-writing tools, and the study analyzes structure, organization, syntactic complexity, and expert-rated quality (content, language, organization). The context is clearly writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantifiable writing outcomes are reported: experts scored story quality (content, language, organization), and analyses (multiple linear regression, cluster analysis) relate human vs. AI-generated word counts to writing scores. These are structured, quantitative outcome measures of writing performance.""
    }
}"
616,Rethinking Ai: Bias in Speech-recognition Chatbots for Elt,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are ELT students using English with a speech-recognition chatbot, implying an English language learning context (ESL/EFL/ELL).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on a speech-recognition chatbot and bias in its recognition of pronunciation. There is no indication that the tool is an LLM-based generative model (e.g., ChatGPT, GPT-4) or that it is used for writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on pronunciation, speech recognition, and attitudes toward English within a Global Englishes framework, not on writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are qualitative (text-mining of reflections, thematic analysis of interviews) about attitudes and conceptions of English; no quantifiable writing outcomes or writing intervention effects are mentioned.""
    }
}"
617,"Teaching Efl Students to Write with Chatgpt: Students' Motivation to Learn, Cognitive Load, and Satisfaction with the Learning Process",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are twenty-one Hong Kong secondary school students described as EFL students completing a 500-word English language writing task, clearly fitting an EFL/ESL English-learning context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is a workshop where students are introduced to ChatGPT, learn prompt engineering, and complete an English composition with ChatGPT’s support. ChatGPT is a large language model integrated into the writing process in an instructional context.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL writing instruction: students complete a 500-word English composition with ChatGPT’s support in a classroom workshop. The focus is on using ChatGPT in the writing classroom, not on automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes measured are motivation, cognitive load, and satisfaction. The abstract does not report any quantitative writing performance metrics (e.g., scores, quality ratings, accuracy, complexity). It focuses on perceptions and cognitive/affective variables rather than measurable writing outcomes.""
    }
}"
618,"Utilising Artificial Intelligence (ai) in Vocabulary Learning by Efl Omani Students: the Effect of Age, Gender, and Level of Study",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL Omani students learning English vocabulary, clearly an EFL/ESL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study surveys use of various AI tools (Google Translation, dictionary apps, ChatGPT, chatbots, Duolingo) and attitudes toward them. There is no experimental or quasi-experimental LLM-based instructional intervention; it is descriptive/correlational.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is vocabulary learning strategies and frequency of AI tool use, not writing competence or writing-related variables. Writing is mentioned only as a low-frequency use, not as a central outcome or intervention focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes concern frequency of AI tool use, attitudes, and demographic effects on vocabulary learning, not measured changes in writing performance.""
    }
}"
619,Analyzing the Impact of Call Tools on English Learners' Writing Skills: a Comparative Study of Errors Correction,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as ESL/EFL learners (English as a second/foreign language), and the focus is on their English writing errors (spelling, verb forms, subject-verb agreement, etc.), so the population and target language match the review scope.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an experimental design with four classes: Class A uses ChatGPT, Class B Grammarly, Class C Google Translate, and Class D is a control group. ChatGPT is a large language model integrated into the writing instruction/error correction process, satisfying the LLM-based intervention requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence, specifically correction of common writing errors in learners’ texts. The tools are used pedagogically to improve writing accuracy, not merely for automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes: changes in frequencies of eight types of writing errors before and after the intervention across groups, and comparative effectiveness of each tool in correcting specific error types. These are measurable writing outcome metrics.""
    }
}"
620,The Effects of Chatgpt on English Language Learning in Regards to Language Proficiency and Learning Motivation,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly refers to EFL students and English language learning, indicating a population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the paper concerns ChatGPT, it is a review article: “By selecting eight targeted studies based on the STARLITE standards, the researcher reviewed the studies…”. It does not itself implement an experimental or quasi-experimental LLM-based intervention; instead, it synthesizes prior work.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""One of the focal areas is “automated writing evaluation and writing ability,” and the abstract notes that ChatGPT could improve EFL students’ writing ability, so the context includes writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a review of eight targeted studies, this article does not report original experimental outcome data or quantifiable writing metrics from its own intervention. It summarizes prior findings rather than presenting new measured writing outcomes, and review articles are to be excluded.""
    }
}"
621,Undergraduate Esl Students’ Use and Perceptions of Chatgpt for Academic Writing Purposes; O Uso E as Percepções De Estudantes De Graduação Em Esl Sobre O Chatgpt Para Fins De Escrita Acadêmica,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are undergraduate ESL students in an intensive academic writing course at a public science and engineering institute in India, clearly fitting an L2 English/ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a survey of students’ existing use and perceptions of ChatGPT. There is no experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction; it is observational, not an intervention study.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly ESL academic writing, focusing on how students use ChatGPT to generate and review academic texts, including summarising and correcting grammar and vocabulary mistakes—clearly writing-related.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are perceptions (trustworthiness, utility, confidence, willingness to use) gathered via Likert-scale, multiple-choice, and open-ended items. No quantifiable writing performance or competence measures are reported to assess the effectiveness of ChatGPT on writing quality.""
    }
}"
622,Understanding Vietnamese English Majors' Use and Acceptance of Ai-powered Tools for English Academic Writing at University,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Vietnamese English majors (EFL learners) using AI tools for English academic writing at university, clearly fitting an L2 English EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates students’ use and acceptance of a range of AI-powered tools, with generative AI noted as popular, but it is not an experimental or quasi-experimental intervention integrating a specific LLM into instruction. It is a survey/interview study of existing practices and attitudes, not a controlled LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on AI tools for English academic writing, including their role in refining academic English, ideation, and writing-related learning attitudes, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports questionnaire-based perceptions (UTAUT constructs) and qualitative interview themes about advantages and concerns. There is no indication of quantifiable writing performance outcomes (e.g., writing scores, text quality measures) resulting from an LLM-mediated intervention.""
    }
}"
623,Impact of Chatgpt on Esl Students’ Academic Writing Skills: a Mixed Methods Intervention Study,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 'undergraduate ESL students' and 'tertiary level ESL students,' indicating L2 English learners in an ESL context with a focus on English academic writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is an 'intervention study' using 'ChatGPT, a generative artificial intelligence-propelled tool,' as a formative feedback tool. This reflects an experimental integration of an LLM into writing instruction/processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on 'the impact of ChatGPT as a formative feedback tool on the writing skills of undergraduate ESL students' and specifically 'students' academic writing skills,' clearly centering on writing competence within a pedagogical context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is a 'mixed methods intervention study' with 'data collected ... through three tests,' and reports 'a significant positive impact of ChatGPT on students' academic writing skills,' indicating quantifiable writing outcome measures.""
    }
}"
624,Detecting Contract Cheating through Linguistic Fingerprint,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 150 learners majoring in engineering and business who were studying English as a foreign language at a college in Saudi Arabia, i.e., EFL learners with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study introduces a machine learning model (TF-IDF + logistic regression) to detect contract cheating. Although ChatGPT is mentioned as a contextual concern, no large language model is integrated into instruction or the writing process; the AI is used only for detection/classification.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on detecting contract cheating via linguistic fingerprinting, not on improving writing competence or writing-related pedagogical variables. It is an authorship verification/academic integrity study rather than a writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Reported outcomes are ML performance metrics (accuracy, precision, recall, F1) for detecting non-consistent essays. There are no quantifiable writing outcome measures assessing the effectiveness of an LLM-mediated writing intervention.""
    }
}"
625,"“chatgpt Is the Companion, Not Enemies”: Efl Learners’ Perceptions and Experiences in Using Chatgpt for Feedback in Writing",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 45 EFL learners in Macau, clearly indicating L2 English learners in an EFL context with focus on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines learners’ use of ChatGPT, an LLM, for feedback in their English writing process over a semester-long writing course, indicating an instructional context integrating an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL writing, focusing on using ChatGPT to generate feedback for writing and its impact on writing-related constructs (motivation, self-efficacy, engagement, collaborative writing).""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although described as mixed-methods, the quantitative data come from a questionnaire about perceptions and affective variables (motivation, self-efficacy, engagement). The abstract does not report any objective or quantifiable writing performance outcomes (e.g., scores, quality measures); it focuses on perceptions and psychological variables, which does not meet the requirement for quantifiable writing outcome metrics.""
    }
}"
626,Exploring Eap Students' Perceptions of Genai and Traditional Grammar-checking Tools for Language Learning,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are first-year students in an English for Academic Purposes (EAP) course at a Hong Kong university, i.e., L2 English learners in an EAP/ESL-type context focusing on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is exploratory and qualitative, focusing on students’ perceptions of GenAI and traditional grammar-checking tools. There is no indication of an experimental or quasi-experimental design integrating LLMs into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on perceptions, ethical and pedagogical implications, and institutional guidance, not on a structured writing intervention aimed at improving writing competence through LLM use.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses semi-structured interviews and qualitative analysis only; it does not report quantifiable writing outcome metrics or measure the effectiveness of an LLM-mediated writing intervention.""
    }
}"
627,L2 Writer Engagement with Automated Written Corrective Feedback Provided by Chatgpt: a Mixed-method Multiple Case Study,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract clearly states the focus is on L2 writers in L2 writing classrooms, indicating a second language learning context. While the specific target language is not explicitly named, the context of AWCF and L2 writing pedagogy strongly suggests L2 English learners, which aligns with ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT, a generative AI large language model, as an automated written corrective feedback (AWCF) provider in L2 writing. This constitutes an LLM-based intervention integrated into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly L2 writing, focusing on AWCF for writing products and learners’ engagement with feedback during revision. This is directly related to writing competence and writing-related processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as a mixed-method multiple case study examining behavioral, cognitive, and affective engagement (e.g., prompt writing techniques, revision operations, strategies, attitudes). The abstract does not indicate any experimental or quasi-experimental design assessing changes in writing quality or other quantifiable writing outcome metrics; it focuses on engagement and perceptions rather than measured writing improvement.""
    }
}"
628,Examining the Relationship between the L2 Motivational Self System and Technology Acceptance Model Post Chatgpt Introduction and Utilization,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 35 second-year university English as a foreign language (EFL) students, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study includes two sessions of instructor-led ChatGPT usage writing workshops, indicating an intervention that integrates an LLM (ChatGPT) into writing activities.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT is used in writing workshops, the primary focus is on the relationship between the L2 Motivational Self System and the Technology Acceptance Model post-ChatGPT introduction, not on writing competence or writing-related performance variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported concern correlations between L2MSS constructs and TAM (e.g., Ought-to L2 Self predicting Actual Usage). The abstract does not mention any quantifiable writing outcome metrics or assessment of writing performance.""
    }
}"
629,Gen Z Students and Their Perceptions of Technology in the Process of Second Language Acquisition Based on the Language Proficiency Level,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Gen Z students at different levels of English proficiency (A2–C2), indicating L2 English learners in an ESL/EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is based on a survey of perceptions and usage of NMT and ChatGPT; there is no indication of an experimental or quasi-experimental intervention integrating LLMs into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on general second language acquisition and technology use (NMT and ChatGPT) for tasks like word translation, mistake correction, and summary writing. Writing competence or writing-focused pedagogy is not the primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports survey-based perceptions and usage patterns, not quantifiable writing outcome metrics or measured effects of an LLM-mediated writing intervention.""
    }
}"
630,"Graduate Students’ Use of Chatgpt for Academic Text Revision: Behavioral, Cognitive, and Affective Engagement",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were six Iranian graduate ESL students revising academic research proposals, clearly indicating L2 English learners in an ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used for academic text revision, the study is observational/qualitative: it examines how students engaged with ChatGPT, not an experimental or quasi-experimental pedagogical intervention designed and tested for effectiveness.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on academic text revision and professionalism in writing, i.e., writing-related processes and engagement with ChatGPT for revising research proposals.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports behavioral, cognitive, and affective engagement and satisfaction, but does not mention any quantifiable writing outcome metrics (e.g., scores, quality ratings, pre-post measures) to assess effectiveness of the ChatGPT-mediated revision.""
    }
}"
631,Ai Language Models: an Opportunity to Enhance Language Learning,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract refers to “second language writing,” “language learners’ proficiency levels,” and “interlanguage development,” indicating an L2 learner population, though not explicitly limited to English. However, the focus is on L2 writing, which aligns with the target population domain.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""AI language models are used to derive similarity metrics for analyzing learner texts and assessing proficiency. There is no indication of an experimental or quasi-experimental pedagogical intervention where LLMs are integrated into instruction or learners’ writing processes; the models function as analytic/assessment tools.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on using AI language models to quantitatively characterize and index second language writing and to relate similarity metrics to proficiency and test scores. This is an assessment/measurement study, not a writing instruction or intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing proficiency and test scores are analyzed, they are used to validate similarity metrics, not to evaluate the effectiveness of an LLM-mediated writing intervention. There is no structured instructional treatment whose impact on writing outcomes is measured.""
    }
}"
632,The Impact of Using Interactive Chatbots on Self-directed Learning,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were fifty Omani EFL students, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study used an 'interactive chatbot' implemented via WhatsApp, but there is no indication it is a large language model (e.g., ChatGPT/GPT-based or similar transformer generative model). It appears to be a delivery platform for instructions and tests rather than an LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on self-directed learning abilities (awareness, learning strategies, activities, evaluation, interpersonal skills). Writing tasks are mentioned as part of researcher-made tests, but the intervention and outcomes center on self-directed learning, not writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantitative outcomes reported concern self-directed learning questionnaire scores. No quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity) are reported to assess the effect of the chatbot on writing performance.""
    }
}"
633,Potential Uses and Concerns of Chatgpt in Efl Academic Writing Classrooms: a Preliminary Portrait,2024,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Only the title is available. It mentions 'EFL academic writing classrooms', which suggests L2 English learners in an EFL context, but without an abstract it is not certain whether actual participants/data are involved or if this is a conceptual piece.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The title refers to 'Potential Uses and Concerns of ChatGPT', which may indicate a descriptive or conceptual discussion rather than an experimental or quasi-experimental intervention study. No abstract is available to confirm the presence of an LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus appears to be on EFL academic writing classrooms, which aligns with writing-related context, but it is unclear whether the study empirically examines writing competence or only discusses pedagogical implications and concerns.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""There is no information about whether quantifiable writing outcome metrics are reported. The title suggests a preliminary, possibly exploratory or opinion-based portrait, which may not include experimental measures, but this cannot be confirmed without an abstract.""
    }
}"
634,Enhancing English as a Foreign Language Academic Writing through Ai and Peer-assisted Learning,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a Foreign Language (EFL) learners, and the focus is on academic writing in English. This matches the target population of L2 English learners in EFL contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention integrates AI, specifically ChatGPT (a large language model), within a peer-assisted learning framework. Peer mentors used ChatGPT to provide personalized, immediate feedback on writing tasks, constituting an LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on enhancing academic writing skills and writing proficiency. ChatGPT is used pedagogically to support writing development, not merely for automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative pre- and post-tests assessing writing proficiency and reported improvements in writing scores indicate that the study includes measurable writing outcomes to evaluate the effectiveness of the LLM-mediated intervention.""
    }
}"
635,Efl Tertiary Teachers’ and Students’ Conceptualizations and Challenges of Using Ai Tools to Improve Writing Skills Ithailand and Vietnam during the Covid-19 Pandemic,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL tertiary teachers and students in Thailand and Vietnam, clearly indicating L2 English learners in EFL contexts, with focus on English writing skills.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates perceptions and challenges of using unspecified AI tools (AITs) via questionnaires and interviews. There is no indication that the tools are LLM-based (e.g., ChatGPT) nor that there is an experimental or quasi-experimental intervention integrating LLMs into instruction; it is a perception study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is writing skills, the focus is on conceptualizations and challenges of using AI tools, not on a structured pedagogical writing intervention or instructional design being tested. It is primarily attitudinal and descriptive.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses descriptive analysis of survey data and content analysis of interviews to report perceptions and challenges. It does not report quantifiable writing outcome metrics (e.g., changes in writing scores, accuracy, complexity) resulting from an AI-mediated intervention.""
    }
}"
636,Efl Students’ Perception in Indonesia and Taiwan on Using Artificial Intelligence to Enhance Writing Skills,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students in Indonesia and Taiwan, described as second-year students specializing in English. The focus is clearly on English as a Foreign Language learners.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers generically to 'Artificial Intelligence (AI)' and 'AI tools' used in writing, but does not specify whether these are large language models (e.g., ChatGPT, GPT-4) or other non-LLM tools (e.g., grammar checkers, paraphrasers).""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a qualitative exploration of students’ perceptions of AI in enhancing writing skills, not an experimental or quasi-experimental pedagogical intervention. It does not describe a structured writing instruction intervention using AI; rather, it investigates perceptions of existing use.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses qualitative methods (semi-structured interviews, thematic analysis) and reports perceptions, benefits, and concerns. No quantifiable writing outcome metrics or experimental measures of writing performance are reported.""
    }
}"
637,Can Novice Teachers Detect Ai-generated Texts in Efl Writing?,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing and involves novice English teachers evaluating EFL learners’ texts. The focus is on English as a foreign language, aligning with L2 English contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although AI-generated texts are central, the study does not describe an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or learners’ writing processes. It is a qualitative study of teachers’ detection abilities.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on teachers’ ability and strategies to detect AI-generated writing, not on improving learners’ writing competence or implementing a writing intervention. There is no instructional use of LLMs for writing development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports qualitative findings about detection success and strategies, not quantifiable writing outcome metrics for learners or the effectiveness of an LLM-mediated writing intervention.""
    }
}"
638,Exploring Chatgpt's Potential as an Ai-powered Writing Assistant: a Comparative Analysis of Second Language Learner Essays,2024,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Only the phrase 'Second Language Learner Essays' is available from the title. It suggests L2 learners but does not specify that they are L2 English learners in ESL/EFL/ELL contexts or that the essays are in English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The title indicates exploration of ChatGPT as an AI-powered writing assistant and a comparative analysis of essays, but without an abstract it is unclear whether there is an experimental or quasi-experimental pedagogical intervention, or merely an evaluation/comparison of outputs.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus appears to be on writing (essays) and ChatGPT as a writing assistant, but it is not clear whether the study is about instructional use in writing development versus system performance or text comparison only.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""No abstract is available, so it is unknown whether the study reports quantifiable writing outcome metrics (e.g., gains in writing quality) or only conducts a comparative textual analysis without intervention outcomes.""
    }
}"
639,Incorporating Ai in Foreign Language Education: an Investigation into Chatgpt’s Effect on Foreign Language Learners,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as ‘preparatory class students studying at the School of Foreign Languages at a university in Turkey.’ The target language is not explicitly stated as English, only ‘foreign language education.’ It is unclear whether the data focus specifically on L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study ‘aimed to utilize ChatGPT in foreign language education’ and students ‘were introduced to ChatGPT through learning experiences over a span of four weeks.’ ChatGPT is an LLM and is integrated into instruction, satisfying the LLM-based intervention requirement, even though the design is qualitative.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract notes that ChatGPT ‘positively affects students’ learning experiences, especially in writing, grammar, and vocabulary acquisition,’ indicating that writing is one of the primary foci of the intervention and outcomes, not just automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly a ‘qualitative case study’ with data from interviews analyzed via thematic analysis. Reported outcomes are perceptions of effects on ‘learning experiences’ in writing, grammar, and vocabulary, with no mention of quantitative or otherwise measurable writing performance metrics. Thus, it does not meet the requirement for quantifiable writing outcome measures.""
    }
}"
640,Effects of an Ai-supported Approach to Peer Feedback on University Efl Students' Feedback Quality and Writing Ability,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 124 Chinese undergraduate English as a foreign language (EFL) students, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention used an AI chatbot named Eva integrated into an online peer review system to assist students in generating feedback. However, the abstract does not specify whether Eva is a large language model (e.g., transformer-based generative model like ChatGPT/GPT-4) or another type of AI tool. Without this information, it is unclear if the AI meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on EFL writing instruction, examining effects on feedback quality and the feedback providers’ writing ability within a peer review context, which is directly related to writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Pre- and post-tests were conducted to assess feedback quality and the writing performance of student reviewers. The abstract reports significant improvements, indicating quantifiable writing outcome measures were used.""
    }
}"
641,A Case Study of Implementing Generative Ai in University’s General English Courses,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners in Korean university-level general English courses, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions a 'generative AI-based instruction model' but does not specify whether this is an LLM (e.g., ChatGPT/GPT-like) or another form of generative AI. The specific tool or model type is not identified.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract notes that the AI-based instruction is for 'writing and speaking' and mentions 'linguistic proficiency,' but the primary stated focus of the study is on affective factors (motivation, interest, confidence), not explicitly on writing competence or writing-related variables as the main outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as investigating effects on affective factors (motivation, interest, confidence). While it mentions potential effectiveness for writing and speaking proficiency, it does not indicate that quantifiable writing outcome metrics were collected or reported; outcomes appear to be affective rather than writing-performance measures.""
    }
}"
642,Detecting and Assessing Ai-generated and Human-produced Texts: the Case of Second Language Writing Teachers,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The participants in focus are second language writing teachers, not L2 English learners. The abstract does not indicate that data are collected on L2 learners’ own writing development or performance as participants; instead, it examines teachers’ assessment of AI- vs. human-produced texts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT-generated text is involved, the study does not describe an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or learners’ writing processes. It focuses on teachers’ ability to detect AI-generated texts, not on LLM-mediated instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on assessment and detection of AI-generated versus human-produced essays by teachers, not on improving writing competence or writing-related learning outcomes through an instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study analyzes teachers’ scores and comments and their strategies for identifying AI-generated texts. It does not report quantifiable writing outcome metrics for L2 learners following an LLM-based writing intervention.""
    }
}"
643,The Impact of Chatgpt on English Language Learners’ Writing Skills: an Assessment of Ai Feedback on Mobile,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as English as a second language (ESL) learners in a senior secondary public school in India. The focus is explicitly on English writing skills and common English grammatical errors.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT’s mobile application to provide feedback on students’ writing error corrections in a quasi-experimental design, comparing it to traditional teacher feedback. ChatGPT is a large language model integrated into the writing instruction process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on ESL writing skills, including grammar and composition proficiency, and the impact of AI feedback on common writing errors. ChatGPT is used pedagogically to support writing development, not merely for scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative outcomes are reported via pre- and post-tests involving story writing based on pictures, with measured reductions in specific error types and improved writing proficiency in the experimental group compared to the control group.""
    }
}"
644,Large Language Models and Automated Essay Scoring of English Language Learner Writing: Insights into Validity and Reliability,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses 119 essays from an English language placement test written by English language learners, indicating an ELL/L2 English population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although multiple LLMs (PaLM 2, Claude 2, GPT-3.5, GPT-4) are used, they are employed solely as automated essay scoring tools, not as part of an instructional or quasi-experimental writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on the validity and reliability of LLM-based automated essay scoring, not on improving learners’ writing competence or integrating LLMs into writing instruction or processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No pedagogical intervention or LLM-mediated writing support is tested; the outcomes are psychometric properties of scoring (validity, reliability), not quantifiable changes in learners’ writing performance due to an intervention.""
    }
}"
645,Evaluating Cami Ai across Samr Stages: Students’ Achievement and Perceptions in Efl Writing Instruction,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states that participants are 126 EFL (English as a Foreign Language) university students, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses “Cami, an AI-powered tool” and refers to “Cami AI technology,” but it does not specify whether Cami is a large language model (e.g., ChatGPT-like, transformer-based generative model) or another type of AI (e.g., annotation, feedback, or grading tool). Without clarification that it is LLM-based, it is unclear if it meets the LLM intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL writing instruction, and the study examines the impact of Cami AI-SAMR implementation on EFL students’ writing achievement, indicating a primary focus on writing competence within a pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that Cami AI-SAMR implementation “significantly impacted EFL students’ writing achievement,” implying quantitative measures of writing performance as outcomes, alongside qualitative perceptions.""
    }
}"
646,Advancing Efl Writing Proficiency in Jordan: Addressing Challenges and Embedding Progressive Strategies,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 150 Jordanian EFL students majoring in English across three public universities, clearly an EFL (L2 English) context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions the integration of advanced technologies such as AI as a potential strategy, there is no indication that an LLM-based tool (e.g., ChatGPT) was actually implemented as an experimental or quasi-experimental intervention. The study is descriptive/exploratory, not an LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on identifying challenges in EFL writing and proposing general strategies, including AI, rather than empirically examining a specific LLM-integrated writing intervention or process.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics related to an LLM-mediated intervention are reported. The study uses surveys and interviews to explore challenges and suggested strategies, without experimental measures of writing improvement due to LLM use.""
    }
}"
647,Can Chatgpt Reliably and Accurately Apply a Rubric to L2 Writing Assessments? the Devil Is in the Prompt(s),2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to 'second language (L2) writing' and is published in the Journal of Technology and Chinese Language Teaching. It is unclear whether the target language is English or Chinese, and no explicit mention of English L2 learners (ESL/EFL/ELL) is made.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used as an assessment tool to score L2 writing and compare its scores with human raters. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating ChatGPT into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the accuracy and reliability of ChatGPT as an automated writing assessment tool, not on improving learners’ writing competence or implementing a teaching/learning intervention. This aligns with excluded contexts (automated essay scoring functionality).""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports on the reliability and accuracy of AI-generated scores compared to human raters, not on quantifiable changes in learners’ writing performance following an LLM-mediated intervention. No writing outcome metrics related to instructional impact are described.""
    }
}"
648,Paraphrase or Plagiarism? Exploring Eap Students’ Use of Source Material in a Transnational University Context,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states that the study investigates English as a Second Language (ESL) student writers in an English for Academic Purposes (EAP) context, which fits the target L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions Generative AI and students’ confidence in technological tools, there is no indication that an LLM-based tool (e.g., ChatGPT) is actually integrated as an experimental or quasi-experimental intervention in the writing process. The study is exploratory, using text-based interviews and a custom writing task, not an LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on academic writing practices—specifically paraphrasing, plagiarism, and use of source material in EAP writing—so the primary context is writing competence and writing-related behaviors.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as exploratory, using interviews and a writing task to examine how students make decisions about source use. The abstract does not report any quantifiable writing outcome metrics assessing the effectiveness of an LLM-mediated intervention; instead, it focuses on qualitative insights and perceptions, including views on technological tools.""
    }
}"
649,Improving Writing Feedback for Struggling Writers: Generative Ai to the Rescue?,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions students with and without disabilities who struggled with writing and notes that AI feedback did not reflect student characteristics such as ELL status. However, it does not specify that the target population is L2 English learners in ESL/EFL/ELL contexts, nor that the data focus specifically on English as an L2.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study imports existing student essays into two versions of ChatGPT and analyzes the feedback and instructional suggestions generated, comparing them with teachers’ feedback. There is no experimental or quasi-experimental pedagogical intervention where LLMs are integrated into writing instruction or writing processes for learners; rather, it is an evaluation/comparison of AI-generated feedback.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is writing instruction and feedback, the focus is on comparing AI and teacher feedback quality and characteristics, not on implementing an LLM-mediated instructional intervention aimed at improving learners’ writing competence. It functions more as an evaluation of AI feedback than a pedagogical intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics (e.g., pre/post writing scores, rubric-based gains) resulting from an LLM-based intervention. Analyses are qualitative (inductive thematic analysis of AI and teacher feedback), with no experimental measures of changes in student writing performance.""
    }
}"
650,Efl Learners’ Attitudes towards Utilizing Chatgpt for Acquiring Writing Skills in Higher Education: a Case Study of Computing Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL learners taking an English language course at a private university in Sharjah, focusing on acquisition of English writing skills.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT is an LLM and is used for essay writing, the study is framed as exploring students’ attitudes toward utilizing ChatGPT rather than implementing an experimental or quasi-experimental instructional intervention. No controlled or structured LLM-mediated teaching design is described.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly writing-focused: acquisition of writing skills in English, higher-order thinking skills related to effective writing, and comparison of ChatGPT-based essay writing versus self-dependent essay writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a questionnaire and semi-structured interviews to measure attitudes, advantages, and drawbacks. There is no indication of quantifiable writing performance outcomes (e.g., scores, rubric-based writing measures) resulting from an intervention; reported findings concern perceived effectiveness, not measured writing gains.""
    }
}"
651,Detecting Chatgpt-generated Essays in a Large-scale Writing Assessment: Is There a Bias Against Non-native English Speakers?,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study involves GRE writing assessment data that likely includes non-native English speakers, the focus is not on L2 learners’ development or instruction but on detector bias. The abstract does not specify an L2 learner population in ESL/EFL/ELL instructional contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study develops detectors of ChatGPT-generated essays using linguistic and perplexity features. ChatGPT is only the source of generated texts; there is no experimental or quasi-experimental integration of an LLM into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on AI-generated text detection and bias in large-scale assessment, not on improving writing competence or writing-related pedagogical interventions. It is essentially an assessment/detector performance study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics related to learners’ writing performance or development are reported. Outcomes concern detection accuracy and bias, not changes in writing quality or related variables following an LLM-mediated intervention.""
    }
}"
652,Testing the Viability of Chatgpt as a Companion in L2 Writing Accuracy Assessment,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses the Cambridge Learner Corpus First Certificate in English (CLC FCE), which consists of L2 English learner writing. The focus is clearly on L2 English writing accuracy.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used as an automated evaluator of linguistic accuracy, not as part of an instructional or experimental intervention in learners’ writing processes. The design compares ChatGPT, Grammarly, and human raters on an existing corpus; there is no LLM-mediated teaching or practice component.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the viability of ChatGPT for automated accuracy assessment within the CAF framework, not on improving writing competence through pedagogical use. It evaluates tool performance as an assessment system rather than implementing a writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing accuracy scores are analyzed, they are used to validate ChatGPT as an assessment tool, not as outcome measures of an LLM-based instructional intervention. No experimental or quasi-experimental teaching treatment or pre/post writing outcomes are reported.""
    }
}"
653,"A Meta-analysis of Effects of Automated Writing Evaluation on Anxiety, Motivation, and Second Language Writing Skills",2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to second language (L2) writing skills but does not specify that the population is L2 English learners in ESL/EFL/ELL contexts, nor that the focus is specifically on English rather than other L2s.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a PRISMA-based meta-analysis of automated writing evaluation (AWE) technologies in general. It does not focus on large language models (e.g., ChatGPT, GPT-4) but on AWE systems as a category, many of which are not LLM-based. It is also a secondary study, not an experimental or quasi-experimental primary intervention study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the meta-analysis concerns writing skills and related affective variables, it is not a primary pedagogical intervention study but a synthesis of prior work on AWE. The review’s focus is not on implementing an LLM-mediated writing intervention in a specific instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a meta-analysis, it aggregates effect sizes from prior studies rather than reporting original experimental outcomes of an LLM-based writing intervention. The review protocol excludes secondary research such as meta-analyses.""
    }
}"
654,Understanding Efl Students’ Use of Self-made Ai Chatbots as Personalized Writing Assistance Tools: a Mixed Methods Study,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 69 Chinese undergraduate EFL students, clearly L2 English learners in an EFL context: “English as a foreign language (EFL) students… 69 Chinese undergraduate students.”""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention involves students creating and using self-made retrieval augmented generation (RAG) chatbots via Poe to assist with their writing processes. RAG chatbots are LLM-based tools, and the study integrates them into writing instruction/workshop activities.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on writing processes and support: chatbots assist with idea generation, outlines, and error identification, and students write essays using their chatbots. The context is clearly writing competence and writing-related variables (motivation, goals, confidence).""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports outcomes on writing motivation, goals, confidence, beliefs, and attitudes, but does not mention any quantitative writing performance metrics (e.g., scores, quality ratings, accuracy measures). The mixed methods design appears to focus on motivational and attitudinal outcomes rather than measurable changes in writing quality, so it does not meet the requirement for quantifiable writing outcome metrics.""
    }
}"
655,Chatgpt for L2 Learning: Current Status and Implications,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a review of 44 studies on ChatGPT for L2 learning, not a primary empirical study with its own participant sample. Thus, it does not itself involve a defined population of L2 English learners as participants in an intervention.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is described as a systematic review of existing studies on ChatGPT for L2 learning, not an experimental or quasi-experimental study implementing an LLM-based writing intervention. It synthesizes others’ interventions rather than conducting one.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract notes that many included studies target writing skills, this article’s primary focus is mapping the literature (roles of ChatGPT, participants, objectives, theories, methods, outcomes), not implementing or evaluating a specific writing-focused pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a review article, it does not report original, quantifiable writing outcome metrics from a new intervention. It summarizes benefits and challenges from prior studies instead of presenting its own experimental outcome data.""
    }
}"
656,"The Metaphor of Ai in Writing in English: a Reflection on Efl Learners’ Motivation to Write, Enjoyment of Writing, Academic Buoyancy, and Academic Success in Writing",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 86 intermediate EFL students from China in an English as a foreign language context, clearly L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses an automated writing evaluation (AWE) system. The abstract does not indicate that this AWE is an LLM-based, transformer generative model (e.g., ChatGPT, GPT-4). AWE tools are typically rule-based or non-LLM machine learning systems, which fall outside the review’s inclusion criteria.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on fostering learners’ writing skills and related variables (motivation to write, enjoyment of writing, academic buoyancy, and academic success in writing) in an EFL writing context, aligning with a writing-focused intervention.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative outcomes, including academic success in writing and measures of motivation, enjoyment, and academic buoyancy, analyzed via one-way MANOVA, satisfying the requirement for quantifiable writing-related outcomes.""
    }
}"
657,Effect of Editgpt on the Learners` Autonomy and Learning Anxiety,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were thirty Omani EFL learners, clearly indicating L2 English learners in an EFL context, with English as the target language in writing instruction.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention used an automated writing evaluation system called EditGPT, described as an AI application. Given the name and context, it is reasonably inferred to be based on GPT (a large language model), and it was integrated into instruction for the experimental group.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the tool is used in English writing instruction, the study’s primary focus and measured outcomes are learning anxiety and learner autonomy, not writing competence or writing-related performance variables. No writing performance or writing quality measures are mentioned.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports quantitative outcomes only for foreign language anxiety and autonomy scales. It does not report any quantifiable writing outcome metrics (e.g., writing scores, accuracy, complexity, fluency), so it does not assess the effectiveness of the LLM-mediated intervention on writing performance.""
    }
}"
658,"Chatgpt-empowered Writing Strategies in Efl Students’ Academic Writing: Calibre, Challenges and Chances",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 60 Chinese university juniors majoring in English (EFL context), and the focus is on English academic writing. This matches the target population of L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a CSE-based questionnaire and focus group interviews to investigate current usage, perceptions, and potential applications of ChatGPT. There is no indication of an experimental or quasi-experimental instructional intervention where ChatGPT is systematically integrated into writing instruction or processes with controlled conditions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on English academic writing strategies (planning, composing, revising) and how ChatGPT can empower these writing strategies for EFL students, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although mixed methods are used, the quantitative component is based on a questionnaire (CSE-based) and analyzed with descriptive statistics and regression. The abstract does not report objective, quantifiable writing performance outcomes (e.g., writing scores, text quality measures) resulting from an LLM-mediated intervention; it focuses on perceived assistance and usage patterns.""
    }
}"
659,Exploring the Use of Chatgpt as a Tool for Written Corrective Feedback in an Efl Classroom,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are five Form Four students in a Band 2 secondary school in Hong Kong, clearly an EFL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention explicitly uses ChatGPT, a large language model, as a writing feedback tool. Students write tasks and revise based on ChatGPT feedback, indicating an LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on written corrective feedback (WCF) in an EFL classroom, with students writing and revising texts. The study examines the effectiveness of ChatGPT feedback in relation to writing improvement, so the primary focus is on writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes exploration of cognitive factors via stimulated recall interviews and students’ perceptions. It does not mention any quantitative or otherwise explicit writing outcome measures (e.g., scores, error rates, rubric-based gains) to assess effectiveness. Outcomes are reported qualitatively (valuing feedback, difficulties understanding/attending to feedback), so it fails the requirement for quantifiable writing outcome metrics.""
    }
}"
660,Tapping into the Pedagogical Potential of Infinigochatic: Evidence from Iwrite Scoring and Comments and Lu & Ai’s Linguistic Complexity Analyzer,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are postgraduate students taking an English reading and writing course in Southwest China, clearly functioning as L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although infinigoChatIC (a ChatGPT-based LLM) is used to polish learner texts, the design is not an experimental or quasi-experimental pedagogical intervention with learners. The teacher inputs existing homework into the LLM and compares LLM-polished texts to original learner texts; learners do not interact with the LLM as part of instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on comparing LLM-polished texts with learner texts using automated scoring and linguistic complexity analysis, not on a teaching/learning intervention targeting writing competence. It functions more as an evaluation of LLM output quality than a structured writing pedagogy study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""While quantitative measures (iWrite scores, lexical and syntactic complexity) are reported, they assess differences between LLM output and learner writing, not changes in learners’ writing performance following an LLM-mediated intervention. No learner outcome over time or treatment effect is measured.""
    }
}"
661,Beyond Syntax: Exploring Moroccan Undergraduate Efl Learners’ Engagement with Ai-assisted Writing,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Moroccan undergraduate EFL learners in a general English course, clearly an EFL/ESL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “AI-supported writing tools” and “AI writing tools” but does not specify whether these are large language model–based systems (e.g., ChatGPT, GPT-4) or other non-LLM tools (e.g., grammar checkers). Thus, it is unclear if the intervention integrates LLMs.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing: the study explores EFL learners’ interaction with AI-supported writing tools and their impact on writing quality, including organization, vocabulary, and creativity, within a pedagogical context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""A quasi-experimental design with a control group is reported, and the abstract notes ‘positive outcomes in language proficiency, creativity, organizational skills, and vocabulary use,’ implying quantifiable writing-related outcome measures, even though specific metrics are not detailed.""
    }
}"
662,Harnessing Ai Chatbots for Efl Essay Writing: a Paradigm Shift in Language Pedagogy,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The title and abstract explicitly refer to EFL (English as a Foreign Language) essay writing and English learners, indicating an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the paper discusses AI chatbots, it is described as a 'comprehensive review' that 'presents insights' and 'advocates for a paradigmatic shift.' There is no indication of an experimental or quasi-experimental design or an implemented intervention; it appears to be a narrative/review article.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL essay writing and developing writing proficiency, including feedback on essay-writing skills, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any empirical data, quantifiable writing outcome metrics, or measured effects. It is framed as a review of pedagogical benefits and challenges rather than reporting experimental outcomes.""
    }
}"
663,Investigating Students’ Cognitive Processes in Generative Ai-assisted Digital Multimodal Composing and Traditional Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) writers, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study investigates generative AI-assisted composing using ChatGPT, Bing Chat, and Bing Image Creator, which are LLM-based tools, integrated into students’ composing processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on generative AI-assisted composing processes in multimodal PPT projects and traditional argumentative essay writing, i.e., writing and composing processes, with pedagogical implications discussed.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes a qualitative study of cognitive and composing processes using think-alouds, screen recordings, and interviews. It does not mention any experimental or quasi-experimental design with quantifiable writing outcome metrics (e.g., scores, measurable gains), focusing instead on patterns and processes.""
    }
}"
664,Generative Artificial Intelligence in the Efl Writing Context: Students' Literacy in Perspective,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as language learners in an EFL writing context, focusing on learning EFL writing skills. This matches the target population of L2 English learners in EFL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a descriptive-survey method to detect learners’ generative AI literacy. There is no indication of an experimental or quasi-experimental intervention integrating LLMs into instruction or writing processes; it only measures literacy/awareness and perceptions.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is EFL writing, the primary focus is on students’ literacy regarding generative AI tools (challenges, affordances, suggestions), not on a pedagogical writing intervention or structured use of LLMs to develop writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports levels of generative AI literacy and factors affecting responses, but does not report quantifiable writing outcome metrics (e.g., writing scores, quality measures) resulting from an LLM-mediated writing intervention.""
    }
}"
665,Patterns of Utilizing Ai–assisted Tools among Efl Students: Need Surveys for Assessment Model Development,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Indonesian EFL university students, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a survey of AI-tool utilization patterns based on TAM. There is no experimental or quasi-experimental design integrating LLMs into writing instruction or processes; tools mentioned (Grammarly, Google Translate) are not specified as LLM-based interventions.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on technology acceptance and usage patterns of AI tools in general, not on writing competence or a writing-focused pedagogical intervention. Writing outcomes or writing instruction are not central.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports questionnaire-based perceptions (knowledge, frequency, ease of use, usefulness, acceptance) and does not report any quantifiable writing outcome metrics or effects of an AI-mediated writing intervention.""
    }
}"
666,Chatgpt as an Artificial Intelligence (ai) Writing Assistant for Efl Learners: an Exploratory Study of Its Effects on English Writing Proficiency,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL learners in an English writing classroom, indicating L2 English learners in an EFL context with focus on English writing proficiency.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study applies ChatGPT, a large language model, as an AI Writing Assistant. Learners in the experimental group are encouraged to use ChatGPT during pre-writing and after-writing stages for planning, interaction, and feedback, within an experimental control vs. treatment design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on English writing proficiency and the use of ChatGPT in the writing classroom, including stages of the writing process (pre-writing, after-writing) and writing-related support (content planning, feedback).""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: the experimental group showed better writing proficiency in terms of content, structure, and language use compared with the control group, based on writing tasks over 10 weeks.""
    }
}"
667,"Proceedings of the 9th International Conference on Information and Education Innovations, Iciei 2024",2024,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract is for a proceedings volume and lists multiple topics, one of which is “ChatGPT as an artificial intelligence (AI) writing assistant for EFL learners: an exploratory study of its effects on English writing proficiency.” This suggests EFL learners (L2 English) for that specific paper, but no participant details are provided at the proceedings level.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The listed paper title indicates use of ChatGPT as an AI writing assistant, which is an LLM-based tool. However, the proceedings abstract does not specify whether the individual study used an experimental or quasi-experimental design or how ChatGPT was integrated into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The specific paper title mentions “writing assistant” and “effects on English writing proficiency,” implying a focus on writing competence. Yet, the proceedings abstract provides no methodological or contextual detail to confirm that the primary focus is on writing instruction rather than, for example, general language learning or tool evaluation.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The phrase “exploratory study of its effects on English writing proficiency” suggests outcome measures, but the proceedings-level abstract does not confirm that quantifiable writing outcome metrics were reported, nor does it describe the study design. Without the individual paper’s abstract, this cannot be verified.""
    }
}"
668,Enhancing English as a Foreign Language (efl) Learners’ Writing with Chatgpt: a University-level Course Design,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as university-level English as a Foreign Language (EFL) learners in a writing course, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports the integration of OpenAI’s GPT-3.5 (a large language model) within a university-level EFL writing course, using ADDIE and TPACK to structure its pedagogical use (feedback, idea generation, organization guidance, peer-review substitute). This is an instructional intervention using an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on an EFL writing course and on improving academic writing: efficiency in writing, cohesive organization, feedback on drafts, and writing proficiency. These are writing-related pedagogical outcomes, not just system evaluation.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract claims that GPT-3.5 enhances efficiency, cohesion, and writing proficiency, but it does not specify any experimental or quasi-experimental design, control/comparison, or quantifiable writing outcome metrics (e.g., scores, rubric ratings, statistical results). It may be descriptive or design-focused rather than reporting measurable intervention outcomes.""
    }
}"
669,Exploring the Feasibility and Efficacy of Chatgpt3 for Personalized Feedback in Teaching,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “language learning” and “student writing” but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor that the target language is English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is primarily a literature review plus a reliability analysis of ChatGPT-3’s feedback and grading. It does not describe an experimental or quasi-experimental pedagogical intervention integrating an LLM into writing instruction; instead, it compares AI and human grading using rubrics.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on feasibility, reliability, and pedagogical implications of AI feedback and grading, not on a structured instructional intervention aimed at improving writing competence. It resembles an evaluation of AI as an assessment/feedback tool rather than a writing intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports comparison of AI and human grading to assess reliability, but does not report quantifiable writing outcome measures (e.g., pre/post writing scores) showing changes in learners’ writing performance due to LLM-mediated intervention.""
    }
}"
670,To Resist It or to Embrace It? Examining Chatgpt’s Potential to Support Teacher Feedback in Efl Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese undergraduate students composing English argumentative essays in an EFL context, clearly L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is exploratory and examines ChatGPT’s performance in generating feedback and compares it with teacher feedback. There is no experimental or quasi-experimental pedagogical intervention where learners use ChatGPT within instruction; ChatGPT is evaluated as a feedback generator, not as an implemented teaching tool.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on comparing ChatGPT- and teacher-generated feedback (amount, type, focus) and teachers’ perceptions of using ChatGPT feedback. It does not describe an implemented writing instruction intervention or learner use of ChatGPT; it is essentially a functionality/performance and perception study around feedback.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcome metrics (e.g., pre/post writing scores, quality gains) are reported. The study analyzes characteristics of feedback and teacher perceptions, not changes in students’ writing performance following an LLM-mediated intervention.""
    }
}"
671,"Using Llms to Bring Evidence-based Feedback into the Classroom: Ai-generated Feedback Increases Secondary Students’ Text Revision, Motivation, and Positive Emotions",2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were N = 459 upper secondary students of English as a foreign language, clearly indicating L2 English learners in an EFL context. The writing task was an argumentative essay in English.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention used the LLM GPT-3.5-turbo to generate feedback on students’ essays. The design is randomized controlled, comparing an experimental group receiving LLM-generated feedback with a control group receiving no feedback, integrating the LLM directly into the writing revision process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence and related variables: students wrote and revised argumentative essays, and the intervention centers on feedback for text revision. Outcomes include revision performance and affective-motivational variables tied to the writing task, not generic system evaluation or pure scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: improvement in revision performance assessed via automated essay scoring, with effect size (d = .19). It also quantifies task motivation and positive emotions (d = 0.36 and d = 0.34), satisfying the requirement for measurable intervention effects.""
    }
}"
672,"“brave New World” or Not?: a Mixed-methods Study of the Relationship between Second Language Writing Learners’ Perceptions of Chatgpt, Behaviors of Using Chatgpt, and Writing Proficiency",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'second or foreign language (L2) writing learners' at university level, implying L2 English learners in an L2 writing course. The outcomes measured (complexity, accuracy, fluency) are standard L2 English writing metrics, and the context is L2 writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines learners’ perceptions of ChatGPT and their self-reported usage behaviors, not an experimental or quasi-experimental pedagogical intervention integrating ChatGPT into instruction. There is no indication of a designed LLM-mediated instructional treatment or controlled use of ChatGPT as part of an intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 writing proficiency (complexity, accuracy, fluency) and how ChatGPT usage relates to these writing outcomes, clearly centering on writing competence rather than automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcome metrics (complexity, accuracy, fluency) and analyzes how ChatGPT usage predicts these, including the finding that usage significantly predicted only complexity.""
    }
}"
673,"Three-wave Cross-lagged Model on the Correlations between Critical Thinking Skills, Self-directed Learning Competency and Ai-assisted Writing",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly refers to 'EFL learners', indicating participants are English as a Foreign Language learners, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines 'AI-assisted writing' and 'AI-assisted tools' but does not specify that these are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems. It appears to be a correlational study of competencies and AI-assisted writing behavior, not an experimental or quasi-experimental LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the relationships among critical thinking skills, self-directed learning competency, and AI-assisted writing via a cross-lagged model. There is no indication of a pedagogical writing intervention or instructional design integrating an LLM into writing instruction; instead, it models correlations among constructs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although a writing task is mentioned, the abstract reports only correlational and moderating relationships among variables over three waves. There is no description of an intervention with pre/post or comparative conditions to assess the effectiveness of an LLM-mediated writing intervention, nor explicit quantifiable outcome measures tied to such an intervention.""
    }
}"
674,Improving Efl Students’ Cultural Awareness: Reframing Moral Dilemmatic Stories with Chatgpt,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is situated in a Chinese EFL context and discusses EFL teachers and students, indicating that the population involves L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used by teachers to co-produce moral dilemmatic stories as teaching materials. There is no indication of an experimental or quasi-experimental design integrating LLMs into students’ writing instruction or writing processes; the focus is on material creation and prompt engineering, not learner-facing writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on cultural awareness and analysis of cultural biases in AI-generated stories for a curriculum unit on ‘Morals and Virtues’. The abstract does not indicate that the study targets writing competence or writing-related learner variables; it is about reading/teaching materials and cultural content, not writing development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study presents appraisal analysis of AI-generated texts and proposes a prompt engineering method, but does not measure changes in students’ writing performance or related quantitative outcomes.""
    }
}"
675,Is Artificial Intelligence for Everyone? Analyzing the Role of Chatgpt as a Writing Assistant for Medical Students,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are medical students taking an English academic writing course. The abstract explicitly refers to their 'English academic writing skills,' indicating they are L2 English learners in an EFL/ESL academic context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT as a 'writing assistant' and compares an experimental group using ChatGPT with a control group receiving conventional writing training, indicating an experimental/quasi-experimental LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on academic writing skills and components of writing (content, organization, vocabulary, mechanics, language use). ChatGPT is integrated into writing instruction, not just for scoring or evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports significant effects with large effect sizes and specifies impacts on different components of academic writing, implying quantifiable outcome measures of writing performance were collected and analyzed.""
    }
}"
676,Llm-as-a-tutor in Efl Writing Education: Focusing on Evaluation of Student-llm Interaction,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly situates the work in English as a Foreign Language (EFL) writing education and refers to EFL learners, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study clearly involves LLMs used as tutors providing essay feedback, which implies an LLM-based tool. However, the abstract does not specify whether there is an experimental or quasi-experimental intervention design (e.g., treatment conditions, controlled implementation in a course) versus a more exploratory/system-evaluation setup.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL writing education, with LLM-as-a-tutor providing real-time feedback on essays and criteria designed for EFL writing education. The primary context is writing instruction and feedback, not automated scoring or general language ability.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract notes that EFL learners assess their ‘learning outcomes from interaction with LLM-as-a-tutor,’ but it does not specify whether these outcomes are quantifiable writing performance measures (e.g., scores, rubric-based gains) or only self-reported perceptions. Without clarity on objective writing outcome metrics, inclusion cannot be confirmed.""
    }
}"
677,Comparing Individual Vs. Collaborative Processing of Chatgpt-generated Feedback: Effects on L2 Writing Task Improvement and Learning,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 117 sophomore EFL learners at a Chinese university, clearly indicating L2 English learners in an EFL context. The focus is on L2 writing, which in this context is English.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is a seven-week experiment using ChatGPT-generated feedback integrated into writing instruction. Different experimental conditions (individual vs. collaborative processing with teacher/peer) indicate an experimental design involving an LLM (ChatGPT).""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 writing development, specifically how processing ChatGPT-generated feedback (individually vs. collaboratively) affects writing task improvement and learning. This is a pedagogical intervention centered on writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing outcomes are quantitatively measured as gain scores from draft to final products across three during-intervention writing tasks and performance on a post-intervention similar new writing task. These are clear, quantifiable writing outcome metrics.""
    }
}"
678,Ai-enhanced Collaborative Story Writing in the Efl Classroom,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are students in compulsory English-as-a-foreign-language (EFL) classes at a Japanese university, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses an AI-enhanced collaborative story-writing application (Collabowrite) with grammar checks, virtual group members, artwork generation, and story narration. However, the abstract does not specify that these AI features are powered by large language models (e.g., ChatGPT/GPT-like transformer-based generative models) rather than other AI techniques. Thus, it is unclear whether an LLM is involved.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is collaborative story writing in EFL classes, with AI used for grammar checks and other support during writing. The primary focus is on writing activities and writing-related perceptions, not on automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports AI grammar-check accuracy, adherence to AI guidance, enjoyment ratings, and pre/post shifts in perceptions toward English writing, collaboration, and technology. It does not report quantifiable writing performance outcomes (e.g., writing quality, accuracy, complexity, scores) assessing changes in learners’ writing competence. Outcomes are attitudinal and usage-based rather than direct writing measures.""
    }
}"
679,Efl Learners’ Motivation and Acceptance of Using Large Language Models in English Academic Writing: an Extension of the Utaut Model,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL learners engaged in business-related English academic writing, which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although participants had completed a semester of training in using LLMs for English academic writing, the study itself does not implement or evaluate an experimental or quasi-experimental LLM-based writing intervention. It focuses on technology acceptance and motivation, not on testing an instructional treatment.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on motivation and acceptance (UTAUT, L2 Motivational Self System) regarding LLM use, rather than on writing competence or writing-related performance variables. Writing is the context, but not the main outcome under investigation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, quality measures, accuracy, complexity) are reported. The outcomes are psychological/behavioral (motivation, behavioral intention, use behavior), not writing performance, so the effectiveness of LLM-mediated writing intervention is not assessed.""
    }
}"
680,Enhancing Efl Writing Skills for Adult Deaf and Hard of Hearing Individuals,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are adult Deaf and hard of hearing learners developing English as a Foreign Language (EFL) writing skills during EU-funded summer schools, which fits an EFL/ELL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is mentioned among internet tools, the abstract does not describe an experimental or quasi-experimental design integrating LLMs into instruction. It appears to be an exploratory study of tool use and perceptions, not a structured LLM-mediated intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL writing skills, including vocabulary, grammar, coherence, clarity, and structure of texts, which are core writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports perceived improvements in writing quality and confidence but does not indicate any quantifiable writing outcome metrics or experimental measures; it appears to rely on perceptions and qualitative findings.""
    }
}"
681,Indocl: Benchmarking Indonesian Language Development Assessment,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are L2 learners of Indonesian: “IndoCL corpus (Indonesian Corpus of L2 Learners), which comprises compositions written by undergraduate students majoring in Indonesian language.” The target language is Indonesian, not English, so it does not match the review’s focus on L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study explores using pre-trained language models and LLMs for language development assessment (LDA), not as an instructional or intervention tool in writing pedagogy. There is no experimental or quasi-experimental design integrating LLMs into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is automated language development assessment and benchmarking (LDA tasks), not improving learners’ writing competence through pedagogical intervention. It is essentially an assessment/benchmarking study, not a writing instruction context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports model performance on LDA tasks and feasibility of LLMs for LDA, but does not describe any intervention with learners or quantifiable writing outcome metrics resulting from LLM-mediated instruction. Outcomes are system performance metrics, not learner writing gains.""
    }
}"
682,Exploring the Influence of Ai and Chatgpt on University Efl Learners,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are university-level English as a Foreign Language (EFL) learners, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention explicitly uses ChatGPT (an LLM) and other AI tools in an experimental design with experimental and control groups to support language learning.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary outcome is grammatical proficiency/accuracy and related language skills. Writing is used mainly for reflective essays to capture perceptions, not as the main instructional focus or target competence. The context is grammar learning rather than writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantitative outcomes reported concern grammatical accuracy and learner engagement. There is no indication that writing quality or writing-related performance metrics were measured as outcomes; reflective essays are used for perceptions, not assessed as writing outcomes.""
    }
}"
683,Students’ Engagement in Seeking and Accepting Chatgpt Feedback in Essay Writing: a Study of Second Language Learners at Varying Proficiency Levels,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The title and abstract indicate the participants are second language learners engaged in academic English writing, which aligns with L2 English learners in an ESL/EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used as a feedback tool, the study is described as a case study focusing on utilization patterns, human-computer interaction, and interviews. There is no indication of an experimental or quasi-experimental design testing an instructional intervention with control/comparison conditions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly L2 academic English essay writing, with ChatGPT used to provide feedback during the writing process. The focus is on writing-related processes and strategies, not on automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative findings about metacognitive strategies and perceptions across proficiency levels, based on interaction and interview data. It does not mention any quantifiable writing outcome measures (e.g., scores, rubric-based gains, error rates) assessing the effectiveness of the ChatGPT-mediated intervention.""
    }
}"
684,"The Effects of a Quillbot-based Intervention on English Language Majors’ Efl Writing Performance, Apprehension, and Self-efficacy",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 18 fourth-year English Language majors in an EFL context at Matrouh University. The abstract explicitly refers to EFL writing performance, indicating L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is based on QuillBot, described as an AI-powered writing assistant. QuillBot is not clearly identified as an LLM-based pedagogical tool in the abstract, and in the review’s criteria, tools like QuillBot are explicitly listed as examples of AI tools to be excluded when they are not transformer-based generative LLMs integrated as such in instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL writing performance and related affective variables (writing apprehension and self-efficacy). The intervention involves drafting, receiving AI-generated feedback, revising, and producing final drafts, which is clearly a writing-focused pedagogical context rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a pre/post-test design with one writing test and two scales to measure writing performance, apprehension, and self-efficacy. It reports significant positive effects on writing performance, providing quantifiable outcome metrics for the intervention.""
    }
}"
685,Developing an Ai-enhanced Video Drama-making Learning System to Support Efl Learners in Authentic Contexts,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL university students, clearly L2 English learners in an EFL context: “improve English as a Foreign Language (EFL) learning… involving sixty-three university students.”""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The system uses “GPT-generated sentences” alongside other AI components, indicating integration of an LLM (GPT) into the learning system, which is an AI-enhanced instructional intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The system aims to enhance “speaking and writing skills” via video drama-making, but the abstract does not specify that the primary focus is writing competence; speaking and multimodal production may be equally or more central.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are reported only in terms of Technology Acceptance Model (TAM): “usability, usefulness, and positive influence on learners’ attitudes towards technology.” No quantifiable writing performance or writing-related outcome measures are described.""
    }
}"
686,Exploring the Impact of Ai in Language Education: Vietnamese Efl Teachers’ Views on Using Chatgpt for Fairy Tale Retelling Tasks,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Vietnamese tertiary-level English as a Foreign Language (EFL) teachers discussing students’ fairy tale retelling writing tasks in English, fitting an EFL/ESL/ELL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is the focal tool, the study is purely qualitative and explores teachers’ perceptions. There is no experimental or quasi-experimental design implementing ChatGPT as an actual intervention with learners.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is writing-related: the use of ChatGPT in students’ fairy tale retelling writing tasks and its integration into language teaching, which is directly tied to writing activities.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses semi-structured interviews and thematic analysis to explore perceptions, challenges, and opportunities. It does not report quantifiable writing outcome metrics or measure the effectiveness of an LLM-mediated writing intervention.""
    }
}"
687,Synergizing Generative Pre-trained Transformer (gpt) Chatbots in a Process-based Writing Paradigm to Enhance University Students’ Writing Skill,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 'university EFL students,' indicating learners of English as a foreign language. The focus is on their English writing skills (organization, content, coherence-cohesion, logical connection, argumentation), satisfying the requirement for L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is 'GPT-based chatbots within a process-based writing framework.' GPT-based chatbots are large language models (Generative Pre-trained Transformer). The study uses them as part of a structured instructional design over 10 sessions, fulfilling the requirement for an LLM-mediated writing intervention with an experimental (pre–post) design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on enhancing 'students’ writing skills' within a 'process-based writing framework' (planning, drafting, revising, editing). The study examines specific writing components and how GPT chatbots support the writing process, not automated scoring or system evaluation, aligning with writing competence as the central outcome.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative writing outcomes are reported: pre- and post-writing test scores (mean scores 9.13 vs. 17.03) and progression across four writing quizzes for multiple writing components. These provide measurable writing performance data to assess the effectiveness of the GPT-based intervention.""
    }
}"
688,L2 Students’ Barriers in Engaging with Form and Content-focused Ai-generated Feedback in Revising Their Compositions,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are described as 'Forty-five L2 students in a computer science program' working on argumentative essays in English, indicating L2 English learners in an academic EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used to provide corrective feedback, the study is observational/analytic: students were 'tasked with seeking corrective feedback from ChatGPT' and their revisions and rationales were analyzed. There is no experimental or quasi-experimental design comparing conditions or systematically testing an instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on L2 writing ('revising their compositions', 'argumentative essays') and engagement with AI-generated feedback at form and content levels, which is directly related to writing processes and competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports proportions of feedback uptake/rejection and qualitative reasons for ignoring feedback, but does not mention any quantifiable writing outcome metrics (e.g., changes in writing quality, scores, accuracy) to assess the effectiveness of the LLM-mediated intervention.""
    }
}"
689,Enhancing English Writing Courses in the Uae: the Potential of Generative Ai Tools,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 38 postgraduate students in the UAE who were all non-native English speakers, indicating an L2 English learner population in an EFL/ESL-type context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as qualitative, exploring potential challenges and possibilities of incorporating generative AI tools like ChatGPT. There is no indication of an experimental or quasi-experimental intervention where LLMs are systematically integrated into instruction with measured effects.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on exploring challenges, possibilities, and educational implications of using generative AI in English writing courses, not on implementing and evaluating a concrete writing intervention or instructional design using LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses thematic analysis of qualitative data from open-ended questions. No quantifiable writing outcome metrics or experimental measures of writing performance are reported.""
    }
}"
690,Korean-as-a-foreign-language Learners’ Engagement with Machine Translation Output,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are US university students learning Korean as a foreign language. The target language is Korean, not English, and the focus is on Korean-as-a-foreign-language writing, which falls outside the review’s scope of L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “machine translators and other artificial intelligence-assisted programs” but does not specify whether these are LLM-based (e.g., ChatGPT, GPT-4) or traditional MT systems (e.g., phrase-based or NMT without LLM interaction). The specific technology is not identified.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly focuses on foreign language writing and how students use machine translators to revise their writing, analyzing their engagement and revision strategies. The primary context is writing processes and writing-related behavior.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study is described as an exploratory case study analyzing cognitive and behavioral engagement and reporting that students could identify and correct errors. However, the abstract does not clearly indicate quantifiable writing outcome metrics (e.g., pre/post writing scores), so it is unclear whether structured, quantitative writing outcomes are reported.""
    }
}"
691,Exploring Interrelationships among L2 Writing Subskills: Insights from Cognitive Diagnostic Models,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 500 English as a foreign language (EFL) students, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses cognitive diagnostic models (G-DINA, DINA, DINO, A-CDM, LLM, RRUM) to analyze writing subskills. Here, “LLM” refers to a log-linear model within CDM, not a transformer-based large language model like ChatGPT or GPT-4. No LLM-based writing intervention or instructional use is described.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on modeling interrelationships among L2 writing subskills using CDMs, not on a pedagogical intervention or instructional integration of (large) language models into writing instruction or processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing performance data are analyzed, there is no experimental or quasi-experimental intervention involving LLM-mediated writing instruction, and no comparison of writing outcomes attributable to such an intervention.""
    }
}"
692,Efl Teachers’ Perceptions of the Use of an Ai Grading Tool (cograder) in English Writing Assessment at Saudi Universities: an Activity Theory Perspective,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL teachers at Saudi universities, working with English as a Foreign Language learners. The context is clearly EFL/ESL with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on an AI grading tool (CoGrader) for essay scoring and feedback and examines teachers’ beliefs about its use. There is no indication that CoGrader is an LLM-based tool (e.g., ChatGPT-like transformer-based generative model), nor that it is integrated as an instructional writing intervention; it is framed as scoring software.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on writing assessment (AI grading) and teachers’ perceptions, not on pedagogical writing instruction or development of writing competence. It evaluates CoGrader as an essay scoring and feedback tool, not as part of a structured instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports teachers’ beliefs and perceptions via questionnaires and interviews. It does not report quantifiable student writing outcome measures or experimental effects of an AI-mediated writing intervention on learners’ writing performance.""
    }
}"
693,Crafting with Ai: Personalized Pathways to Boost Critical Language Awareness and Spark Creativity in Writing through Digital Adaptive Learning,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract refers to “L2 learners” and focuses on enhancing their writing skills, critical language awareness, and creativity in language learning contexts. While the target language is not explicitly stated as English, the general L2 context is acceptable for C1 unless otherwise specified.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is an “automated writing application equipped with adaptive learning (AL) strategy.” There is no indication that this tool is a large language model (e.g., ChatGPT, GPT-4) or transformer-based generative model. It is described in terms of adaptive learning, individualized instruction, and immediate feedback, which are typical of non-LLM adaptive/ITS systems. Thus it does not clearly meet the requirement of integrating an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence and related variables: “enhancing the writing skills, critical language awareness (CLA), and creativity of L2 learners.” The intervention is pedagogical, comparing an AL writing application to a non-AL application, not an essay scoring or purely functional evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative outcomes: “Quantitative data revealed that using AL strategy significantly improved writing outcomes compared to non-AL application,” and also measures CLA and creativity via questionnaires. Thus, it includes quantifiable writing outcome metrics within an experimental design.""
    }
}"
694,Understanding Chinese University Efl Learners’ Perceptions of Ai in English Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese university EFL learners, clearly an L2 English population in an EFL context: “Contextualized in a Chinese university setting, this study investigated Chinese university EFL learners’ perceptions…”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention tool is Grammarly, which is not described as an LLM-based generative model but as AI writing support. The focus is on perceptions of Grammarly, not on integrating a large language model (e.g., ChatGPT, GPT-4) into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on technology acceptance and perceptions of AI (Grammarly) using an extended TAM, not on a pedagogical writing intervention or systematic integration into writing instruction. It is not framed as an experimental or quasi-experimental instructional study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports quantitative data on perceptions (ease of use, usefulness, enjoyment, task relevance, behavioral intention) and variance explained, but there is no mention of quantifiable writing performance outcomes or measures of writing competence.""
    }
}"
695,Ai-enhanced Video Drama-making for Improving Writing and Speaking Skills of Students Learning English as a Foreign Language,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 77 university students learning English as a Foreign Language (EFL). The context is clearly EFL and the outcomes discussed are English writing and speaking skills.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses an AI-enhanced video drama (AI-EVD) application that includes GPT-generated sentences, explicitly referencing a generative pretrained transformer. The design is experimental with an experimental group using the AI features and two control groups (app without AI and conventional learning).""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on improving EFL writing and speaking skills through AI support that provides lexical resources (vocabulary and sentence structures) to inspire students’ writing. Writing competence is a primary outcome, not just system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that learning achievement in the experimental group was significantly higher than in both control groups, and that GPT-generated sentences had the strongest effect on writing and speaking skills, implying quantifiable outcome measures and statistical analyses (correlation, regression).""
    }
}"
696,Investigating Generative Ai Models and Detection Techniques: Impacts of Tokenization and Dataset Size on Identification of Ai-generated Text,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions that current detectors show reduced reliability for English as a Second Language learners, the study itself does not focus on L2 English learners as participants in an ESL/EFL/ELL instructional context. Instead, it uses essays from the ASAP Kaggle competition and AI-generated texts for detection research.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Generative AI models (ChatGPT, Claude, Gemini) are examined as sources of AI-generated text and as targets for detection, not as pedagogical tools in an experimental or quasi-experimental writing intervention. The study centers on cheating detection and model performance, not on integrating LLMs into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on detecting AI-generated or paraphrased text in high-stakes writing assessments using machine learning and LLM-based detectors. It does not investigate writing competence, instruction, or writing-related pedagogical variables; rather, it evaluates detection techniques and model performance.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity, organization) are reported as effects of an LLM-mediated intervention. Outcomes relate to detection accuracy and model performance, not to changes in learners’ writing ability.""
    }
}"
697,Chatgpt for Language Learning: Assessing Teacher Candidates’ Skills and Perceptions Using the Technology Acceptance Model (tam),2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL teacher candidates performing tasks in Spanish (L1) and English (L2), so the population includes L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT-4 is used to generate machine-written samples that participants compare and evaluate. There is no indication of an experimental or quasi-experimental pedagogical intervention where learners use the LLM as part of their own writing instruction or process; instead, the focus is on critical evaluation and perception.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on critical skills in distinguishing human vs. machine-generated texts and on perceptions (Technology Acceptance Model), not on improving writing competence or writing-related pedagogical outcomes through LLM-mediated instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Text analysis metrics (SC, ASL, VOCD) are used to compare human and machine texts, but not as outcome measures of an LLM-based writing intervention on learners’ own writing performance. The study reports perceptions (PU, BI) and critical discrimination skills, not quantifiable gains in writing ability due to LLM use.""
    }
}"
698,"Comparing Peer, Chatgpt, and Teacher Corrective Feedback in Efl Writing: Students’ Perceptions and Preferences",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL students in English as a Foreign Language classrooms, so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention includes an AI tool (ChatGPT), a large language model, used to provide written corrective feedback on students’ writing, alongside peer and teacher feedback.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is written corrective feedback on an EFL writing task, with revisions after each feedback mode; the focus is on writing skills and feedback practices in writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract states that a qualitative approach via survey analysis was used to explore students’ perceptions and preferences. It does not report quantitative writing outcome measures (e.g., scores, accuracy gains) to assess effectiveness of the LLM-mediated intervention; revisions are mentioned but not as measured outcomes. Thus it lacks quantifiable writing outcome metrics.""
    }
}"
699,An Analysis on the Implementation of Artificial Intelligence (ai) to Improve Engineering Students in Writing an Essay,2024,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions EFL essay elements and engineering students, suggesting they may be English as a Foreign Language learners, but it does not explicitly state that participants are L2 English learners in ESL/EFL/ELL contexts. The institutional or linguistic context is not clearly described.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study refers broadly to Artificial Intelligence technologies such as chatbots, NLP, and Sentiment Analysis, but does not specify whether a large language model (e.g., ChatGPT, GPT-4) was used. It is unclear if the intervention is LLM-based or relies on other AI tools not meeting the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on improving student writing skills in engineering, analyzing formal EFL essay elements (content and language) and the flow of information in essay writing. This aligns with a primary focus on writing competence and writing-related variables in an educational context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a mixed-method approach with quantitative data, including a control group of 224 essays from 52 students, and compares formal EFL essay elements. This implies quantifiable writing outcome metrics (e.g., content and language measures) are used to assess the AI-supported writing intervention.""
    }
}"
700,Utilizing an Adaptable Artificial Intelligence Writing Tool (chatgpt) to Enhance Academic Writing Skills among Yemeni University Efl Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Yemeni university EFL learners, clearly L2 English learners in an EFL context: “Yemeni EFL learners at the university level.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is the focus, the study is not an experimental or quasi-experimental intervention. It uses surveys to explore “opinions, benefits, and challenges” and “perceptions and experiences with ChatGPT,” not a structured instructional intervention with pre/post or comparison conditions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is academic writing: “AI-based writing tool in academic writing” and “enhance their academic writing skills,” focusing on writing-related variables such as fluency, accuracy, and quality.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is perception-based, using surveys and descriptive statistics; there is no indication of quantifiable writing outcome measures (e.g., pre/post writing scores, rubric-based assessments). Reported improvements are self-reported, not experimentally measured writing outcomes.""
    }
}"
701,Chatgpt as an Ai L2 Teaching Support: a Case Study of an Efl Teacher,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context is an EFL class in Spain, so it is likely that learners are L2 English users. However, the study is framed around an EFL teacher as the focal case, and the abstract does not explicitly describe learner participants or their characteristics.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is an exploratory single instrumental case study of one EFL teacher using ChatGPT as teaching support. The focus is on how ChatGPT assists the teacher in planning, designing lessons, and assessing writing, not on an experimental or quasi-experimental intervention measuring its impact on learners’ writing. There is no indication of controlled or structured LLM-mediated instructional intervention with outcome comparison.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing is mentioned (assessing learners’ writing), the primary focus is on ChatGPT as a support tool for teachers (lesson planning, design, implementation) and on reliability/helpfulness of outputs. The study does not center on developing learners’ writing competence through a pedagogical intervention, but on teacher use and perceptions.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses qualitative thematic analysis and a semi-structured interview to explore support, reliability, and helpfulness. It does not report quantifiable writing outcome metrics for learners or any experimental measures of writing improvement attributable to ChatGPT.""
    }
}"
702,"4th International Conference on Digital Technologies and Applications, Icdta 2024",2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a conference proceedings volume containing 53 papers across diverse topics in digital technologies. The abstract does not specify any individual study focused on L2 English learners in ESL/EFL/ELL contexts; it only lists various paper titles, most of which are unrelated to language learning. Therefore, the population criterion is not met for this aggregated entry.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although one listed paper mentions AI and academic writing and another mentions ChatGPT as a learning tool, the proceedings abstract does not indicate that any specific study uses an LLM-based intervention in writing instruction with an experimental or quasi-experimental design. As a whole, this proceedings entry is not an LLM-based writing intervention study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus of the proceedings is broad digital technologies and applications (e.g., data mining, cybersecurity, antennas, investment decision-making). Writing competence or writing-related variables are not the central focus of the volume; any writing-related work is incidental and not described as a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported in the abstract. The proceedings description does not present experimental results or structured intervention outcomes related to LLM-mediated writing; it only lists paper titles and general themes.""
    }
}"
703,Revolutionizing English Language Learning with Ai: Boosting Student Receptive and Productive Skills,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 183 EFL undergraduate students from three universities, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study evaluates three AI tools (Turboscribe, Gliglish, Jenni) via a survey based on TAM. There is no indication these are LLM-based writing interventions or that an experimental/quasi-experimental instructional design integrating LLMs into writing instruction was implemented.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on overall English skills (listening, reading, speaking, and writing) and technology acceptance/behavioral intent, not specifically on writing competence or a writing-focused pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are perceptions (user-friendliness, behavioral intent, perceived benefits) from a survey. No quantifiable writing performance metrics or measured changes in writing quality are reported.""
    }
}"
704,Second Language Writing Anxiety and Chatgpt Adoption as an Automated Writing Evaluation Tool,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'English second language learners' (639 undergraduate students), indicating an L2 English population in an academic context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a cross-sectional survey using TAM and SEM-PLS to examine intention to use ChatGPT. There is no experimental or quasi-experimental integration of ChatGPT into instruction or actual writing processes; ChatGPT is only considered as a potential tool.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on writing anxiety and technology acceptance (perceived usefulness, ease of use, attitude, intention) regarding ChatGPT as an automated writing evaluation tool, not on a pedagogical writing intervention or measured changes in writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes are psychological/attitudinal (writing anxiety, perceived usefulness, perceived ease of use, attitude, intention to use), with no assessment of writing performance or quality.""
    }
}"
705,The Impact of Using Chatgpt on Efl Students' Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as English as a foreign language (EFL) learners, and the focus is on English writing, satisfying the population criterion.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study investigates the impact of ChatGPT, a large language model, on EFL learners’ writing by comparing outlines written with and without ChatGPT assistance, indicating an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on writing-related variables: logical structure, content enrichment, vocabulary and grammar polishing, and overall writing ability. ChatGPT is used as a pedagogical tool in the writing process, not merely for scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports discourse analysis results and qualitative improvements (logical structure, content, vocabulary, grammar) and student reflections, but does not indicate any quantitative or experimental outcome measures (e.g., scores, rubric-based ratings, statistical comparisons). Outcomes appear qualitative only, which does not meet the requirement for quantifiable writing outcome metrics.""
    }
}"
706,Revolutionizing Efl Writing: Unveiling the Strategic Use of Chatgpt by Indonesian Master’s Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are postgraduate EFL students (Master’s degree students from Indonesian universities), clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a qualitative case study exploring students’ experiences and strategies in using ChatGPT. There is no indication of an experimental or quasi-experimental design, nor a structured instructional intervention integrating ChatGPT; it is descriptive/experiential.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL students’ use of ChatGPT throughout their writing process, including vocabulary, grammar, idea generation, essay structuring, and language refinement—clearly centered on writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports perceptions and self-reported experiences, with no mention of quantifiable writing outcome metrics or measured pre/post changes in writing performance. It is purely qualitative.""
    }
}"
707,Nurturing Responsible Ai Practices in L2 Writing: Empowering Student Voices,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are students in a freshman academic writing course at an English-medium American university in the UAE, indicating L2 English learners in an EFL/ESL context with focus on English academic writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to ‘Artificial Intelligence (AI)’ and ‘AI-generated texts’ but does not specify that the tools are large language models (e.g., ChatGPT, GPT-4). It may include LLMs, but this is not explicit from the title/abstract alone.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on responsible and ethical AI integration, digital literacy, learner autonomy, and policy development. Collaborative writing assignments involve contrastive analysis of human vs AI-generated texts, but the intervention is about digital literacy and policy-making rather than improving writing competence through AI-mediated instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses mixed methods with surveys and analysis of assignments, but the abstract does not report or indicate quantifiable writing outcome metrics (e.g., writing scores, quality measures) to assess effectiveness of AI-mediated writing intervention. Outcomes are framed in terms of digital literacy and policy engagement.""
    }
}"
708,"Leveraging Chatgpt to Enhance Students’ Writing Skills, Engagement, and Feedback Literacy",2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 50 Indonesian university students in an English as a Foreign Language (EFL) Economic English course. The context is clearly English language learning (ELT/EFL), satisfying the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The title specifies ‘Leveraging ChatGPT’ and the abstract refers to ‘AI chatbots’ used by the experimental group. ChatGPT is an LLM-based chatbot. The design is experimental with an experimental and control group, integrating the chatbot into students’ writing-related learning.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on EFL students’ writing: it aims to measure how AI chatbots affect writing learning outcomes, feedback literacy, and engagement in writing. This is a pedagogical intervention in writing, not an automated scoring or purely functional evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract states that the study measures ‘writing learning outcomes’ using tests and reports that the experimental group showed ‘significant improvements in writing outcomes.’ This indicates quantifiable writing outcome metrics within an experimental design.""
    }
}"
709,The Impact of Chatgpt Feedback on the Development of Efl Students’ Writing Skills,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 110 university students learning English as a Foreign Language (EFL), clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT feedback as the core intervention within a quasi-experimental design to enhance students’ writing skills, indicating integration of an LLM (ChatGPT) into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence: the impact of ChatGPT feedback on students’ writing proficiency and specific writing aspects (conciseness, grammar, inclusion of key information, passive voice).""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study employs pre-tests and post-tests to evaluate writing proficiency and reports significant quantitative improvements in specific writing features, providing measurable writing outcome metrics.""
    }
}"
710,Exploring the Attitudes of Efl University Instructors and Students Toward Utilizing Chatgpt for Acquiring Writing Fluency and Accuracy Skills,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL university instructors and students at a private university in Sharjah, clearly indicating an English-as-a-foreign-language context focused on English writing fluency and accuracy.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is the focal tool, the study is described as exploring attitudes toward its use. The methods mention only a Likert-scale questionnaire and semi-structured interviews; there is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT into actual writing instruction or tasks.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on attitudes toward using ChatGPT to enhance writing fluency and accuracy, not on a structured pedagogical intervention or measured changes in writing competence. It is essentially an attitudinal/perception study rather than an intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are perceptions (attitudes) gathered via questionnaires and interviews. There is no mention of quantifiable writing performance metrics (e.g., scores, rubric-based assessments, pre/post writing tests) to evaluate the effectiveness of ChatGPT-mediated writing intervention.""
    }
}"
711,Usability Study of Genai for English Learning in Vr,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as “7 undergraduate non-native English speakers,” which fits L2 English learners in a higher-education EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses a VR conversation game, EasyEnglish, with GenAI NPCs and a large language model for language assessment and feedback (grammar, vocabulary correction, suggestions). This is an LLM-based instructional tool.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on speaking practice in VR and system usability (SUS) and content validity (CVI). Writing competence or writing-related variables are not mentioned; the LLM is used for spoken conversation and assessment, not writing instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports SUS and CVI scores and qualitative system performance (e.g., diverse responses, grammar correction), but no quantifiable writing outcomes or writing performance measures are provided.""
    }
}"
712,Exploring the Use of Generative Ai in Student-produced Efl Podcasts: a Qualitative Study,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are university English as a Foreign Language (EFL) students, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “generative AI tools” and “Generative AI-based technologies” but does not specify whether these are large language models (e.g., ChatGPT, GPT-4) or other generative tools (e.g., audio, editing, or non-LLM systems). The design is qualitative, based on open-ended responses, not an experimental or quasi-experimental intervention study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on student-produced EFL podcasts and spoken language quality, with generative AI used across podcast aspects (ideas, script, editing). The outcomes emphasize spoken language and podcast production rather than writing competence or writing-related variables as the main focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly qualitative, using thematic analysis of open-ended responses. It reports perceptions and implications but does not mention any quantifiable writing outcome metrics or experimental measures of writing performance.""
    }
}"
713,Utilizing Elsa Speak and Busuu Apps to Enhance English for Professional Purposes among Indian Students: an Education 4.0 Approach,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Indian students learning English for professional purposes in a multilingual context, fitting an ESL/EFL/ELL population focus on English communication skills.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses ELSA Speak and Busuu apps framed under Education 4.0. These are general language learning platforms and the abstract does not indicate that they are LLM-based (e.g., ChatGPT, GPT-4) or that transformer-based generative models are integrated into writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The study targets overall professional English communication, reporting gains in listening, speaking, reading, and writing. Writing is only one of several skills and there is no indication that the primary focus is on writing competence or writing-related variables specifically.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports significant improvement in listening, speaking, reading, and writing skills based on pre- and post-questionnaires, but it is unclear whether there are specific, quantifiable writing outcome metrics (e.g., writing quality scores) as opposed to general self-reported communication measures.""
    }
}"
714,Using Generative Ai to Provide High-quality Lexicographic Assistance to Chinese Learners of English; Die Gebruik Van Generatiewe Ki Om Hoëkwaliteit Leksikografiese Hulp Aan Chinese Aanleerders Van Engels Te Bied,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly targets Chinese learners of English, i.e., L2 English learners in an EFL context: “writing assistants for Chinese learners of English.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although generative AI (ChatGPT, Ernie Bot) is used, it is employed to generate lexicographic explanations and error subcategory descriptions, not as an experimental or quasi-experimental pedagogical intervention with learners. The focus is on tool/content development and comparison of chatbots, not on an LLM-mediated instructional treatment with participants.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is lexicographic assistance and error explanation design (subject–verb disagreement) and the potential integration of generative AI into writing assistants, rather than an implemented writing intervention measuring changes in writing competence. It is conceptual/methodological, not a study of writing instruction outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental results with learners are reported in the abstract. The paper discusses chatbot performance and the need for human supervision, but not measured effects on learners’ writing quality or related variables.""
    }
}"
715,Investigating Chinese Learners ' Use and Perceptions of Chatgpt in Eap,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese learners in an English for Academic Purposes (EAP) context, which implies they are L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates learners’ use and perceptions of ChatGPT via questionnaire and interviews. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating ChatGPT into instruction; it is a descriptive/perceptual study.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Students report using ChatGPT for academic vocabulary and academic writing, but the study’s primary focus is on perceptions and usage patterns, not on a structured writing intervention or instructional design targeting writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports no quantitative writing outcome measures (e.g., writing scores, text quality metrics). It focuses on attitudes and perceived uses, without assessing changes in writing performance.""
    }
}"
716,Using Ai Tools to Enhance Academic Writing and Maintain Academic Integrity,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are undergraduate students whose first language was not English, i.e., L2 English learners in higher education, fitting ESL/EFL/ELL-type contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study explores students’ perceptions of paraphrasing and AI tools but does not describe an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes. It is a perception-focused qualitative study.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context involves academic writing, plagiarism, and use of AI tools in higher education, but the focus is on perceptions rather than a structured pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract states that data were analyzed using qualitative methods and does not mention any quantifiable writing outcome metrics or experimental measures of writing performance.""
    }
}"
717,Chatgpt as a Tool to Improve Written Expression in English as a Foreign Language; Chatgpt Comme Outil D’amélioration De L’expression Écrite En Anglais Langue Étrangère; Chatgpt Como Uma Ferramenta Para Aprimorar a Expressão Escrita No Inglês Língua Estrangeira; Chatgpt Como Herramienta Para Mejorar La Expresión Escrita En Inglés Como Lengua Extranjera,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The title and abstract indicate the focus is on written expression in English as a foreign language in higher education, implying EFL learners using English as an L2.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""ChatGPT, a large language model, is explicitly used as an aid for academic writing and for correcting and improving written expression in English essays.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly writing-focused: students perform a writing task in the essay genre, and ChatGPT is used to correct and improve written expression (vocabulary, grammar, text structure, content).""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes a detailed analysis of students’ interactions with ChatGPT and highlights mistakes and correct answers provided by the tool, but it does not indicate any experimental or quasi-experimental design with quantifiable writing outcome metrics (e.g., pre/post writing scores, rubric-based gains). The focus appears to be on tool performance and possibilities, not measured learner writing improvement.""
    }
}"
718,Utilising Artificial Intelligence-enhanced Writing Mediation to Develop Academic Writing Skills in Efl Learners: a Qualitative Study,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL learners preparing for the IELTS examination, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses ChatGPT, clearly an LLM-based AI platform, integrated into interactive writing activities where learners receive implicit and explicit writing mediation.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on developing EFL learners’ academic writing skills via AI-enhanced writing mediation and interactive writing activities, aligning with writing competence as the primary outcome domain.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly described as a qualitative research design using microgenetic tracking, observations, reflexive journal, and think-aloud interviews. The abstract reports perceived development and positive attitudes but does not indicate any quantifiable writing outcome metrics or experimental/quasi-experimental measures of effectiveness.""
    }
}"
719,Does It Really Help? Exploring the Impact of Al-generated Writing Assistant on the Students’ English Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as four seventh-semester EFL students, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study evaluates an “AI-generated writing assistant… ParagraphAI text generator,” but the abstract does not specify that it is a large language model (e.g., ChatGPT/GPT-like transformer-based generative model). It is treated as generic AI-powered writing software, and there is no clear indication it is an LLM-based intervention as required.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on English writing skills, including grammatical errors, cohesion, coherence, and content density, which are core writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses tests, questionnaires, and text comparison to measure Lexical Diversity indices and reports effects on grammatical accuracy, cohesion, and coherence, indicating quantifiable writing outcome metrics.""
    }
}"
720,Ghostbuster: Detecting Text Ghostwritten by Large Language Models,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions evaluation on documents by non-native English speakers but does not specify that these are L2 English learners in ESL/EFL/ELL instructional contexts; they appear only as a test set for detection performance, not as participants in a learning intervention.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study introduces Ghostbuster, a system for detecting AI-generated text. LLMs are used as text generators to be detected, not as an instructional intervention integrated into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on AI-text detection performance (F1 scores, robustness, generalization), not on writing competence or pedagogical use of LLMs in writing. There is no writing instruction or intervention context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are detection metrics (F1 scores, robustness to attacks), not quantifiable writing outcomes assessing the effectiveness of an LLM-mediated writing intervention.""
    }
}"
721,"A Systematic Review of Chatgpt for English as a Foreign Language Writing: Opportunities, Challenges, and Recommendations",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The article explicitly focuses on English as a Foreign Language (EFL) writing, indicating that the population of interest across the reviewed studies is EFL learners working with English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a systematic review of prior studies on ChatGPT in EFL writing, not an experimental or quasi-experimental primary study implementing an LLM-based intervention itself. Review articles are to be excluded.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL writing, discussing how ChatGPT is adopted for EFL writing, including opportunities and challenges in writing instruction and curricula.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic review, it synthesizes literature and provides recommendations but does not itself report original, quantifiable writing outcome metrics from an intervention it conducts. Review-type studies are excluded by design.""
    }
}"
722,Chatgpt over My Friends: Japanese English-as-a-foreign-language Learners’ Preferences for Editing and Proofreading Strategies,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 33 Japanese English-as-a-foreign-language learners, clearly an EFL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT-3.5 (an LLM) is used, the design is not experimental or quasi-experimental regarding learning outcomes. The study contrasts experiences and preferences between writing groups and ChatGPT use, but there is no indication of an intervention aimed at measuring effectiveness on writing performance.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is academic writing in an EFL classroom, focusing on editing and proofreading to improve clarity and cohesion in writing, which is directly writing-related.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are students’ preferences and perceptions gathered via questionnaires. The abstract does not mention any quantifiable writing performance metrics (e.g., scores, error rates, rubric-based improvements) to assess the effectiveness of the LLM-mediated intervention.""
    }
}"
723,Uncovering Students’ Processing Tactics towards Chatgpt’s Feedback in Efl Education Using Learning Analytics,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as EFL students, i.e., English as a Foreign Language learners, which fits the target population of L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines students’ interaction with ChatGPT, a generative AI large language model, during reading and writing tasks, and analyzes their processing tactics toward ChatGPT’s feedback. This constitutes an LLM-based intervention embedded in learning activities.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although reading and writing tasks are mentioned, the primary analytic focus is on Processing Tactics towards ChatGPT’s Feedback and learning modes, with reported outcomes being ‘learning gains’ and ‘improvement of domain knowledge.’ The abstract does not indicate that writing competence or writing-related performance measures are the main focus; instead, domain knowledge gains are emphasized.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports differences in learning gains and improvement of domain knowledge among groups, but it does not specify any quantifiable writing outcome metrics (e.g., writing quality scores, accuracy, complexity, organization). Thus, it lacks explicit quantitative writing performance outcomes required for inclusion.""
    }
}"
724,Towards Fair Detection of Ai-generated Essays in Large-scale Writing Assessments,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The population is described only as native and non-native English speakers in a large-scale writing assessment. There is no indication that the focus is on L2 English learners in ESL/EFL/ELL instructional contexts; rather, the concern is test security and detector bias across demographic groups.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on strategies for detecting AI-generated essays and mitigating detector bias. It does not describe an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or processes for learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on AI-generated text detection and fairness (bias across native vs. non-native speakers) in assessment security, not on improving writing competence or writing-related learning outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) are reported. Outcomes relate to detection accuracy and bias, not to the effectiveness of an LLM-mediated writing intervention.""
    }
}"
725,Advancing Sustainable Learning by Boosting Student Self-regulated Learning and Feedback through Ai-driven Personalized in Efl Education,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are junior high school EFL students (L2 English learners) in an Asian context: “English as a Foreign Language (EFL) students… The population in this study is junior high school class VIII…”. The focus is clearly on English language learning.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “AI-mediated language teaching” and “AI-powered platforms” but does not specify that these are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems. The type of AI (LLM vs. other forms such as adaptive or analytic tools) is not identified, so it is unclear whether an LLM is integrated into instruction.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study examines self-regulated learning, feedback-response, and overall English proficiency (vocabulary, reading, writing, grammar). While writing ability is one of several skills tested, the primary focus appears to be broader AI-mediated language teaching and self-regulation, not specifically writing competence or writing-related variables as the central context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although pre- and post-tests include “writing ability” among other skills, the abstract does not report any specific, quantifiable writing outcome metrics or analyses focused on writing performance. Outcomes are described in aggregate as “learning English” and “language learning outcomes,” with no clear writing-focused experimental measure reported, which does not meet the requirement for explicit quantifiable writing outcomes.""
    }
}"
726,Ai in Subconscious Language Learning for Error Remediation,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses second language acquisition in general and classroom contexts (e.g., a class of 25 pupils) but does not specify that the learners are L2 English learners or that English is the target language. It also mentions language learning apps (LingQ, Rosetta Stone) in a general multilingual sense.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""AI is discussed broadly (e.g., Siri, Alexa, AI-powered platforms) with no indication that large language models (ChatGPT, GPT-4, etc.) are used. The focus is conceptual/theoretical on AI and individualized learning, not on an experimental or quasi-experimental LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract addresses language acquisition and AI-supported language learning in general, not writing competence or writing-related variables. There is no mention of writing instruction, writing tasks, or writing performance as a primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No experimental or quasi-experimental design is described, and no quantifiable writing outcome metrics are reported. The piece appears to be conceptual or descriptive rather than an intervention study with measured outcomes.""
    }
}"
727,"Integrating Large Language Models into Efl Writing Instruction: Effects on Performance, Self-regulated Learning Strategies, and Motivation",2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are elementary school students in an English as a Foreign Language (EFL) context. The focus is explicitly on EFL writing, i.e., English as the target L2.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study develops and implements an 'LLM-supported Cognitive Academic Language Learning Model (CALLA-LLM)' and compares it to traditional CALLA in a randomized controlled trial. LLMs are integrated into the writing instruction as part of the experimental intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is EFL writing instruction and related variables: 'EFL writing performance, SRL strategy use, and writing motivation.' The LLM is used pedagogically within writing instruction, not merely for automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports 'significant improvements in writing performance' and describes a randomized controlled trial with pre-, post-, and follow-up measures, indicating quantifiable writing outcome metrics were collected and analyzed.""
    }
}"
728,Balancing Ai and Authenticity: Efl Students’ Experiences with Chatgpt in Academic Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as EFL students, indicating L2 English learners in an EFL context, and the focus is on their academic writing in English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the study is a qualitative case study of students’ experiences and strategies. There is no indication of an experimental or quasi-experimental design, structured instructional intervention, or controlled integration of ChatGPT into teaching.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly academic writing: the study examines how EFL students incorporate ChatGPT into their academic writing process and its impact on essay quality and authenticity.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is based on semi-structured interviews and self-reported experiences. The abstract does not mention any quantifiable writing outcome metrics or experimental measures; findings are qualitative (perceptions, concerns, strategies).""
    }
}"
729,The Impact of Chatgpt on Students’ Writing Proficiency in Second Language Acquisition: Students’ Perception and Experiences: a Qualitative Analysis,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “students’ writing proficiency in second language acquisition” but does not specify that the target L2 is English, nor that the context is ESL/EFL/ELL. The specific language is not identified.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""ChatGPT, an LLM, is used “as a tool for language learning,” but the abstract does not clearly describe an experimental or quasi-experimental instructional intervention (e.g., treatment vs. control, pre/post design). It focuses on experiences and perceptions rather than a structured intervention design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly focuses on “students’ writing proficiency” and “writing skills in the realm of second language acquisition,” indicating that the primary focus is on writing competence in an L2 context rather than on automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as “a qualitative analysis” using interviews and questionnaires to explore “subjective experiences and perceptions.” There is no indication of quantitative writing outcome measures or experimental assessment of writing performance.""
    }
}"
730,"Using Artificial Intelligence to Foster Students’ Writing Feedback Literacy, Engagement, and Outcome: a Case of Wordtune Application",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states the context is second language (L2) learning and L2 writing. Participants are upper-intermediate L2 students, implying an ESL/EFL context focused on English, though the language is not named. This fits the target L2 English learner population more likely than not.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Wordtune, described only as an “AI-based application.” Wordtune is primarily a rewriting/paraphrasing tool and is not clearly identified as an LLM-based, transformer generative model in the abstract. Under the review’s criteria, tools like Grammarly/QuillBot-style systems that are not explicitly LLM-based should be excluded. There is no explicit mention of ChatGPT, GPT-4, or other LLMs, nor of a transformer-based generative model.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on L2 writing: it examines writing feedback literacy, writing engagement, and writing outcomes. The AI tool is integrated into the writing process as an instructional aid, not as an automated scoring system. Thus, the context aligns with writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that the experimental group using Wordtune “significantly improve[d] their writing outcomes, engagement, and feedback literacy when compared to the control group,” indicating quantifiable outcome measures in a mixed-method, experimental design.""
    }
}"
731,Understanding Efl Students’ Chatbot-assisted Argumentative Writing: an Activity Theory Perspective,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are five Chinese undergraduate EFL students (“English as a foreign language students”), so they are L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses a chatbot called Argumate to assist argumentative writing, but the abstract does not specify whether Argumate is an LLM-based, transformer-style generative model (e.g., ChatGPT-like) or a rule-based/chatbot of another type.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on chatbot-assisted argumentative writing, examining how students engage with the chatbot while composing essays. The context is clearly writing pedagogy and writing processes, not automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as qualitative, using activity theory to analyze processes. Data include screen recordings, chat logs, essays, and questionnaire responses, but the abstract does not indicate any experimental or quasi-experimental design or report quantifiable writing outcome metrics to assess effectiveness of the chatbot intervention.""
    }
}"
732,Enhancing Efl Vocabulary Acquisition through Computational Thinking,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese non-English majors in foreign language education, clearly functioning as EFL learners focusing on English vocabulary and short essay writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT and AI are mentioned in the introduction, the described intervention is based on computational thinking (CT) skills (data analysis, pattern recognition, abstraction, decomposition, parallelization) applied to vocabulary acquisition. There is no indication that an LLM (e.g., ChatGPT) was actually integrated as part of the instructional or writing intervention; CT itself is the intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on improving vocabulary richness in English short essay writing and measures vocabulary-related indices in students’ writing, which is directly related to writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses QUITA software to measure vocabulary-related quantitative indices in short essay writing before and after the CT intervention, providing quantifiable writing outcome metrics.""
    }
}"
733,Examining Efl Students' Motivation Level in Using Quillbot to Improve Paraphrasing Skills,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students at Najran University enrolled in a Technical Writing course, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention tool is QuillBot. The abstract describes it as an online AI tool but does not indicate that it is an LLM-based, transformer generative model in the sense required (e.g., ChatGPT, GPT-4). Moreover, the design is descriptive-diagnostic (survey and interviews), not experimental or quasi-experimental writing instruction integrating an LLM.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on students’ motivation to use QuillBot for paraphrasing, not on a structured writing intervention or instruction. The study is framed around motivational factors and perceptions rather than a pedagogical writing intervention with measured impact on writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are motivational levels and gender differences in responses, gathered via questionnaire and interviews. There are no quantifiable writing outcome metrics (e.g., changes in paraphrasing quality, writing scores) assessing the effectiveness of the tool on writing performance.""
    }
}"
734,The Intersection of Ai and Language Assessment: a Study on the Reliability of Chatgpt in Grading Ielts Writing Task 2,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions IELTS Task 2 writing, which typically involves L2 English learners, but it does not explicitly state that the participants are ESL/EFL/ELL learners or provide details about their language learning context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT-4 is used solely as an automated grader to compare its scores with official human raters. There is no experimental or quasi-experimental pedagogical intervention integrating the LLM into writing instruction or learners’ writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the reliability of ChatGPT as an essay scoring system, not on improving writing competence or writing-related learning outcomes. It is an assessment-functionality study rather than a teaching/learning intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No writing outcome metrics for learners are reported; the outcomes are reliability statistics (e.g., Cohen’s kappa, ICC) comparing AI and human scores. There is no structured LLM-mediated writing intervention whose effectiveness on learner writing is measured.""
    }
}"
735,University Students’ Perceptions of Artificial Intelligence-based Tools for English Writing Courses,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Korean university students who have taken English writing courses and are explicitly described as English language learners (ELLs), fitting an EFL/ELL L2 English context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines perceptions of AI-based tools (Google Translate, Naver Papago, Grammarly). These are not clearly LLM-based writing interventions in an experimental or quasi-experimental design; rather, they are existing tools used by students, with no structured LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on students’ perceptions of AI-based tools in English writing courses, not on a designed pedagogical intervention targeting writing competence. It is exploratory/perceptual rather than an instructional study integrating LLMs into writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study uses mixed methods, it reports perceptions of usefulness and concerns. There is no indication of quantifiable writing outcome metrics (e.g., pre/post writing scores) assessing the effectiveness of an AI-mediated intervention.""
    }
}"
736,From Virtual Assistant to Writing Mentor: Exploring the Impact of a Chatgpt-based Writing Instruction Protocol on Efl Teachers’ Self-efficacy and Learners’ Writing Skill,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Iranian English language teachers (n=12) and learners (n=48) in an L2 writing context, explicitly described as EFL. The focus is on English writing skills, satisfying the requirement for L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is a ChatGPT-based writing instruction protocol (CGWIP). ChatGPT is a large language model, and it is integrated systematically into planning, instruction, and assessment phases of writing instruction. The study uses an experimental design with control and treatment groups and pre/post testing.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly L2 writing instruction. ChatGPT is used for brainstorming, engaging learners in the writing process, analyzing drafts, and simulating IELTS writing exams with feedback. The primary focus is on writing competence and related instructional processes, not on automated scoring alone.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative writing outcomes: learners’ writing skills were measured before and after a 10-week program, analyzed via One Way ANCOVA, showing significant improvement and persistence over time. Thus, it provides quantifiable writing outcome metrics for the LLM-mediated intervention.""
    }
}"
737,Utilizing Artificial Intelligence Tools for Improving Writing Skills: Exploring Omani Efl Learners’ Perspectives,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Omani EFL learners from the General Requirements Unit at the Preparatory Studies Centre, clearly an EFL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates learners’ perceptions and practices in using unspecified ‘artificial intelligence tools’ (e.g., for translation, spelling, grammar). There is no indication that these are LLM-based tools (e.g., ChatGPT) nor that there is an experimental or quasi-experimental intervention integrating a specific LLM into instruction; it is a survey of existing practices.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is writing skills, the study focuses on perceptions and self-reported use of AI tools, not on a structured pedagogical writing intervention using LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a Likert-scale questionnaire to measure perceptions and practices; it does not report quantifiable writing outcome measures (e.g., changes in writing quality, scores, or performance) resulting from an AI/LLM-mediated intervention.""
    }
}"
738,Paraphrasing Prowess: Unveiling the Insights of Efl Students and Teachers on Quillbot Mastery,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a Foreign Language (EFL) students and teachers, indicating an L2 English learning context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention tool is QuillBot, which is not clearly identified as an LLM-based transformer generative model in the abstract and is treated as a generic AI paraphrasing tool. Moreover, the design is a descriptive survey of perceptions, not an experimental or quasi-experimental integration of an LLM into instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on perceptions of using QuillBot for paraphrasing skills, not on a structured pedagogical writing intervention or instructional design aimed at improving writing competence. It is an attitudinal/perception study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports perceptions and the influence of demographic variables on responses. There is no mention of quantifiable writing outcome measures (e.g., pre/post writing scores, rubric-based writing quality, accuracy) to assess effectiveness of the tool on writing performance.""
    }
}"
739,Chatgpt as an Automated Writing Evaluation (awe) Tool: Feedback Literacy Development and Awe Tools’ Integration Framework,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 18 English as a Foreign Language (EFL) students in Indonesia, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines the use of ChatGPT (an LLM-based tool) along with Grammarly and Quillbot as automated writing evaluation tools in a writing course, indicating an instructional integration of an LLM.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on learners’ feedback literacy and the development of an AWE Tools Integration Framework, not on writing competence or writing-related performance variables. Writing is the context, but the outcome of interest is feedback literacy rather than writing ability.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a single qualitative case study design with interviews, reflective journals, and artifacts, and reports thematic findings about feedback literacy. There is no mention of quantifiable writing outcome metrics or experimental measures of writing performance.""
    }
}"
740,Evaluating Prompting Strategies for Grammatical Error Correction Based on Language Proficiency,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly mentions “learners of English as a foreign language” and analyzes grammatical error correction on “writing examples of English language learners” across proficiency levels A–C.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study evaluates prompting strategies (zero-shot, few-shot, fine-tuning) for LLM-based grammatical error correction, but there is no indication of an experimental or quasi-experimental pedagogical intervention in writing instruction. It is a system/performance evaluation, not an instructional intervention with learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on GEC system performance (overcorrection, precision/recall) across proficiency levels, not on developing or assessing learners’ writing competence through an instructional context. It treats learner texts as test data for GEC, not as part of a teaching/learning intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are GEC evaluation metrics (precision, recall, overcorrection) of LLMs, not quantifiable changes in learners’ writing performance following an LLM-mediated intervention. No learner outcome measures or pre/post comparisons are described.""
    }
}"
741,Recipe4u: Student-chatgpt Interaction Dataset in Efl Writing Education,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 212 college students in English as a Foreign Language (EFL) writing courses, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students used ChatGPT (an LLM) to revise their essays, the study is presented as a dataset paper focusing on interaction logs, intent labels, and baseline NLP subtasks (intent detection, satisfaction estimation). There is no indication of an experimental or quasi-experimental pedagogical intervention design to test instructional effects of LLM integration.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on creating and analyzing a dialogue dataset (intent detection, satisfaction estimation, interaction patterns), not on evaluating writing competence or a structured writing intervention. Writing is context, but not the main evaluative focus of the study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics (e.g., writing scores, quality measures, pre-post comparisons). Analyses center on dialogue patterns, essay data statistics, and edits descriptively, without experimental measures of writing improvement attributable to the LLM intervention.""
    }
}"
742,How Llms Support Efl Writing: a Case Study of K-12 English Learning Based on the Edipt Model,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on K-12 English as a Foreign Language (EFL) learners in Chinese English education, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as a case study that proposes a response strategy framework (EDIPT model) and discusses potential contributions of LLMs. There is no indication of an experimental or quasi-experimental design implementing a concrete LLM-based writing intervention; it appears conceptual/strategic rather than an implemented intervention study.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The paper’s stated focus is on how LLMs can support EFL writing in K-12, including using LLMs as language consultants and for feedback on students’ writing. Thus, the primary focus is on writing instruction and related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or assessment of effectiveness. It discusses potential benefits, challenges, and proposes a framework, but no experimental measures or reported writing performance data are described.""
    }
}"
743,Leveraging a Diagnostic Exam for Cultivating Ai Literacy: Postgraduate Student Reflections on Chatgpt,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are postgraduate L2 English Language Learner (ELL) students in a high-intermediate L2 English writing and communications course at a U.S. university, clearly fitting ESL/EAP L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is an AI literacy intervention exploring students’ views of AI tools (including ChatGPT) and how such technology affects their thinking. There is no indication of an experimental or quasi-experimental design integrating an LLM into the writing instruction or process; rather, it is about reflections and literacy around AI.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is AI literacy and students’ perspectives on AI tools, not on improving writing competence or specific writing-related performance variables. Writing is used as a diagnostic and as a vehicle for reflection, not as the main outcome of an LLM-mediated writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports students’ views and pedagogical implications, with no mention of quantifiable writing outcome metrics (e.g., scores, rubric-based improvements) assessing the effectiveness of an LLM-mediated writing intervention.""
    }
}"
744,Network of Discourses: Resistance and Negotiation within Chinese Students’ Ai-assisted Efl Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are English major students in an EFL context at a university in China, clearly L2 English learners: “English as a Foreign Language (EFL) writing assignments… at a university in China.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study involves “generative artificial intelligence (AI) chatbots” and ChatGPT logs, it is framed as an ANT and critical discourse analysis of students’ digital literacy practices and AI-assisted writing networks, not as an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on discourse, language ideologies, authority negotiation, and critical AI literacy, not on writing competence or structured writing instruction outcomes. It examines how authenticity and authority are negotiated, rather than implementing and evaluating a writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are mentioned. Data sources (drafts, chat logs, screen recordings, interviews) are used for qualitative analysis of practices and ideologies; there is no indication of experimental measures of writing performance or effectiveness of an LLM-mediated intervention.""
    }
}"
745,Voices of the Future: Exploring Students' Views on the Use of Genai in Academic and Professional Pr Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are described as 'native Thai PR major university students.' While they may write in English, the abstract does not specify that they are L2 English learners in ESL/EFL/ELL contexts or that the data focus on English as the target language.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study involves a 'workshop on GenAI' and students’ 'trial' use of GenAI, but it is framed as a qualitative exploration of adoption and perceptions, not as an experimental or quasi-experimental instructional intervention with LLMs. The specific GenAI tools and their LLM basis are not detailed.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on students’ views, attitudes, and adoption of GenAI in academic and professional PR writing, using DOI and TAM frameworks. It does not focus on developing writing competence or systematically integrating GenAI into writing instruction as a pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly qualitative, using semi-structured focus groups. No quantifiable writing outcome metrics or measured changes in writing performance are reported; the outcomes are perceptions, attitudes, and adoption intentions.""
    }
}"
746,Integrating Automated Written Corrective Feedback into E-portfolios for Second Language Writing: Notion and Notion Ai,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers generally to 'second language (L2) educators' and 'L2 learners' but does not specify that the target language is English or that participants are ESL/EFL/ELL learners. Moreover, it is framed as a technology review rather than an empirical study with a defined participant population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a 'review' and 'technology review' that 'proposes' the use of Notion and Notion AI and 'reports an overview' and 'discusses their affordances and limitations.' There is no indication of an experimental or quasi-experimental intervention being implemented or evaluated with learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus is on L2 writing pedagogy and automated written corrective feedback, the paper is conceptual/technological in nature, outlining potential uses and affordances rather than reporting on an implemented pedagogical intervention or study context with measured outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any empirical data, experimental measures, or quantifiable writing outcomes. It is a technology review discussing potential benefits, affordances, and limitations, without reporting structured intervention outcomes.""
    }
}"
747,The Use of Ai Tools in English Academic Writing by Saudi Undergraduates,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Saudi undergraduates enrolled in freshmen academic writing courses and are described as proficient in English. This fits an EFL/ESL/ELL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students use AI tools such as ChatGPT, Grammarly, and Google Translate, the study is a perception survey, not an experimental or quasi-experimental intervention integrating LLMs into instruction. There is no structured LLM-based pedagogical treatment being tested.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on perceptions of AI tools in academic writing, not on a designed writing intervention or instructional program. It examines attitudes and perceived benefits/concerns rather than implementing and evaluating a specific writing-focused LLM intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports survey-based perceptions and factor analysis, but no quantifiable writing outcome measures (e.g., writing scores, text quality metrics) assessing the effectiveness of AI/LLM-mediated writing instruction or processes.""
    }
}"
748,Navigating Ai Writing Assistance Tools: Unveiling the Insights of Thai Efl Learners,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'Thai EFL learners' and 'Thai non-English-major undergraduates,' clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to 'AI writing assistance tools' without specifying whether they are LLM-based (e.g., ChatGPT, GPT-4) or other tools (e.g., Grammarly). However, the study is not described as experimental or quasi-experimental; it is a qualitative interview study about perceptions, not an intervention study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is writing and AI tools, the focus is on learners’ perceptions and experiences, not on a structured pedagogical intervention aimed at improving writing competence. It is an exploratory qualitative study rather than an instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly qualitative, based on interviews, and reports perceived benefits and challenges. No quantifiable writing outcome metrics or experimental measures of writing performance are mentioned.""
    }
}"
749,Investigating Efl Faculty Members’ Perceptions of Integrating Artificial Intelligence Applications to Improve the Research Writing Process: a Case Study at Majmaah University,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are EFL faculty members/teachers at Majmaah University, not L2 English learners in ESL/EFL/ELL contexts. The focus is on teachers’ own research writing, not on student L2 writing development.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “AI applications and tools” without specifying large language models (e.g., ChatGPT, GPT-4) or detailing the underlying technology. It is also not an instructional intervention study but an attitudinal survey.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is research writing by EFL educators and their perceptions of AI integration, not pedagogical writing instruction for L2 learners. It does not describe an intervention aimed at improving learners’ writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports perceptions and attitudes via questionnaires and interviews; there are no experimental or quasi-experimental measures of writing outcomes or writing performance changes attributable to AI/LLM use.""
    }
}"
750,Transforming Academic Writing with Ai: Tools for Effective Learning,2024,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract does not specify that participants are L2 English learners (ESL/EFL/ELL). It mentions ‘students’ and CAE grades (which could imply Cambridge English exams and thus L2 learners), but this is not explicit. The learner population and language background remain unclear based on the abstract alone.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""ChatGPT (an LLM) is clearly central, and the study analyzes revision data from eleven student texts and provides guidelines for incorporating ChatGPT into instruction. However, it is not clearly stated that there is an experimental or quasi-experimental design (e.g., treatment vs. control, pre–post with structured intervention). It could be descriptive/observational rather than an intervention study.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on academic writing, revision, and essay quality. ChatGPT is used to support revision and improve student writing, addressing structural, grammatical, and stylistic issues. The primary context is writing competence and writing-related variables, not automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines ‘revision data from eleven student texts’ and explores how error types, word count changes, and revision behaviors relate to ‘improvements in essay quality,’ including ‘improved essay scores and CAE grades.’ These are quantifiable writing outcome metrics linked to the use of ChatGPT.""
    }
}"
751,Ai-empowered Applications Effects on Efl Learners' Engagement in the Classroom and Academic Procrastination,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as Chinese EFL learners, which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention involves AI-powered applications including ChatGPT and POE, which are LLM-based tools, used in a quasi-experimental design comparing an experimental group exposed to these tools with a control group.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on learner engagement (affective, cognitive, behavioural) and academic procrastination. The abstract does not mention writing instruction, writing processes, or writing competence as a target of the intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcome measures are engagement and academic procrastination scales. No quantifiable writing outcomes (e.g., writing quality, accuracy, complexity, or other writing-related metrics) are reported.""
    }
}"
752,Inheriting and Innovating Yishan Seal Art: Huang Mufus Style in Contemporary Seal Carving Education,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are three male Saudi undergraduate EFL learners enrolled in an English degree program at Albaha University, clearly fitting an EFL/ESL L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions “AI-driven technology” and “email as a viable AI-enhanced tool,” but does not specify the use of any large language model (e.g., ChatGPT, GPT-4). Email itself is not an LLM-based tool, and no transformer-based generative model is described as part of the intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is writing: learners submitted nine writing samples, and the study analyzes vocabulary size and lexical errors in written output, focusing on writing-related variables within EFL instruction.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative writing-related outcomes are reported, including vocabulary size (V_Words) and lexical errors (Engber’s 1995 taxonomy). The study compares conditions and finds the pushed email condition leads to greater vocabulary expansion and lexical accuracy.""
    }
}"
753,Enhancing University Level English Proficiency with Generative Ai: Empirical Insights into Automated Feedback and Learning Outcomes,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 918 university language students in Hong Kong, an EFL/ESL context, and the study explicitly concerns English essay writing proficiency, indicating L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is feedback generated by GPT-3.5-turbo (an LLM). A randomized controlled trial compares students who received LLM-based feedback with those who did not, integrating the LLM into the writing revision process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is essay writing proficiency, revisions, and engagement with writing tasks. LLMs are used pedagogically to provide automated feedback within a writing instruction/revision context, not merely for scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable metrics: statistical analysis of the impact of AI feedback on essay grading and effect sizes, indicating measurable writing outcomes (caliber of students’ essays) alongside surveys and interviews.""
    }
}"
754,Teachers or Chatgpt: the Issue of Accuracy and Consistency in L2 Assessment,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are B1-level students at an international branch university in Egypt whose L2 writing is being assessed, indicating an EFL/ESL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used solely as an automated rater to assess existing writing assignments. The design is quantitative correlational and non-experimental, with no instructional or intervention component integrating ChatGPT into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the accuracy, consistency, and reliability of ChatGPT as an assessment tool compared to teachers, not on improving writing competence or implementing a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No writing outcome metrics are reported to evaluate the effectiveness of an LLM-mediated writing intervention. Outcomes concern score correlations and reliability, not changes in learners’ writing performance following an intervention.""
    }
}"
755,Learning and Teaching with Chatgpt: Potentials and Applications in Foreign Language Education,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses foreign language acquisition and language learning in general but does not specify that the focus is on L2 English learners (ESL/EFL/ELL) or that the data are specifically about English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a literature review using content analysis of prior work on ChatGPT in education. It does not report an original experimental or quasi-experimental intervention integrating an LLM into writing instruction.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""While the review notes that ChatGPT can enhance foreign language writing skills and conversational capabilities, it synthesizes applications broadly in foreign language education rather than reporting a specific pedagogical intervention focused on writing competence in a primary study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a literature review, the study does not present original quantitative writing outcome metrics from an intervention; it summarizes potentials and implications instead of reporting measured writing gains.""
    }
}"
756,Generative Ai as Writing or Speaking Partners in L2 Learning: Implications for Learning-oriented Assessments,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses L2 learning in general but does not specify that the participants in the reviewed studies are L2 English learners in ESL/EFL/ELL contexts, nor that the focus is specifically on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a review of the literature on GenAI as writing and speaking partners, framed by the Learning-Oriented Assessment framework. It is not an experimental or quasi-experimental primary study; it synthesizes existing research.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing is one of the skills mentioned, but the paper’s primary focus is on learning-oriented assessment and how assessment data from GenAI tools can be leveraged, rather than on a specific pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a literature review, the paper does not itself report quantifiable writing outcome metrics from an intervention; it examines and discusses existing research conceptually through an LOA lens.""
    }
}"
757,Identifying whether a Short Essay Was Written by a University Student or Chatgpt,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses essays from Japanese university students who are English L2 learners (ICNALE corpus, CEFR A2 level). Thus, the population involves L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used only to generate comparison essays for a detection task. There is no experimental or quasi-experimental pedagogical intervention integrating an LLM into writing instruction or learners’ writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on teachers’ ability to distinguish human vs. ChatGPT-generated essays, not on improving writing competence or writing-related learning outcomes. This aligns more with authorship detection/assessment validity than with a writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics for learners are reported. The only quantitative result is teachers’ identification accuracy (54.25%), which does not assess the effectiveness of an LLM-mediated writing intervention.""
    }
}"
758,Evaluating Cami Ai across Samr Stages: Students' Achievement and Perceptions in Efl Writing Instruction,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 126 EFL (English as a Foreign Language) university students, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract describes ‘Cami, an AI-powered tool’ and refers to ‘Cami AI’ but does not specify whether it is a large language model (e.g., ChatGPT-like, transformer-based generative model) or another type of AI (e.g., feedback/annotation tool, non-LLM analytics). Without clarification that Cami is LLM-based, it is unclear if this meets the LLM intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing instruction, and the study evaluates the impact of Cami AI-SAMR implementation on EFL students’ writing achievement, clearly focusing on writing competence within a pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that ‘Cami AI-SAMR implementation significantly impacted EFL students' writing achievement,’ indicating quantitative writing outcome measures, alongside qualitative perceptions.""
    }
}"
759,Efl Tertiary Teachers' and Students' Conceptualizations and Challenges of Using Ai Tools to Improve Writing Skills in Thailand and Vietnam during the Covid-19 Pandemic,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are clearly EFL tertiary teachers and students in Thailand and Vietnam, focusing on English as a foreign language writing skills.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to 'AI tools' and 'AITs' but does not specify that these are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems. They could include grammar checkers or other non-LLM tools.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates perceptions and challenges of using AI tools to improve writing, not a structured pedagogical intervention or experimental integration of a specific AI tool into writing instruction. It is attitudinal rather than an intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The quantitative data are descriptive of perceptions, not measures of changes in writing performance or related competencies following an intervention.""
    }
}"
760,"The Metaphor of Ai in Writing in English: a Reflection on Efl Learners' Motivation to Write, Enjoyment of Writing, Academic Buoyancy, and Academic Success in Writing",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 86 intermediate EFL students from China in an English as a foreign language context, clearly L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses an automated writing evaluation (AWE) system. The abstract does not indicate that this AWE is an LLM-based, transformer generative model (e.g., ChatGPT, GPT-4). AWE tools are typically rule-based or non-LLM scoring/feedback systems, which fall outside the review’s inclusion criteria for LLM-based interventions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on fostering learners’ writing skills and related affective variables (motivation to write, enjoyment of writing, academic buoyancy, academic success in writing) in an EFL writing context, aligning with a writing competence focus.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative outcomes (one-way MANOVA) comparing groups on motivation to write, enjoyment in writing, academic buoyancy, and academic success in writing, providing measurable writing-related outcomes.""
    }
}"
761,Writing Argumentative Essays: Jambi Efl Students' Challenges and Strategies,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students in the English Education Study Program at a public university in Jambi, Indonesia, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students report using “AI applications” as a technology utilization strategy, the abstract does not specify large language models (e.g., ChatGPT) nor describe any experimental or quasi-experimental LLM-based instructional intervention. The study is a qualitative case study of challenges and self-reported strategies, not an LLM-mediated intervention design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on difficulties in writing argumentative essays and strategies to address them, which is directly related to writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses qualitative methods (semi-structured interviews, document analysis, thematic analysis) and reports problems and strategies. It does not report quantifiable writing outcome metrics or evaluate the effectiveness of an AI/LLM-mediated intervention.""
    }
}"
762,L2 Students' Barriers in Engaging with Form and Content-focused Ai-generated Feedback in Revising Their Compositions,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described only as “L2 students in a computer science program.” The target L2 is not explicitly stated as English, nor is the context labeled ESL/EFL/ELL. It is plausible but not certain that the L2 is English, so this cannot be confirmed from the abstract alone.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used to provide corrective feedback, the study is observational/analytic: students were tasked with seeking feedback and their revisions and rationales were analyzed. There is no indication of an experimental or quasi-experimental design (e.g., control/comparison groups, pre–post measures, or structured intervention to test effectiveness). The focus is on barriers and uptake, not on testing an LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly L2 writing: students wrote argumentative essays and sought AI-generated corrective feedback on form (grammar) and content (evidence). The primary focus is on how they engage with feedback in revising their compositions, which is directly related to writing processes and competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports proportions of feedback accepted, argued, or ignored, and examines reasons for rejection using the Technology Acceptance Model. It does not report quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity) to assess the effectiveness of the LLM-mediated intervention. Outcomes are about feedback uptake and perceptions, not measured improvement in writing.""
    }
}"
763,Balancing Ai and Authenticity: Efl Students' Experiences with Chatgpt in Academic Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as EFL students, indicating they are learners of English as a foreign language and thus L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used by students, the study is a qualitative case study of students’ experiences and strategies. There is no indication of an experimental or quasi-experimental design, structured instructional intervention, or controlled integration of ChatGPT into teaching; it is exploratory and descriptive.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is academic writing, focusing on how EFL students incorporate ChatGPT into their writing process and its impact on essay quality, authenticity, and related writing practices.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract specifies a qualitative case study using semi-structured interviews and self-reported experiences. It notes that future research should include objective measures, implying that this study does not report quantifiable writing outcome metrics or experimental measures of writing performance.""
    }
}"
764,Investigating Students' Cognitive Processes in Generative Ai-assisted Digital Multimodal Composing and Traditional Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) writers, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study investigates generative AI-assisted composing processes using ChatGPT and Bing Chat, which are LLM-based tools, integrated into students’ multimodal and traditional writing tasks.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on composing processes in multimodal PPT projects and traditional argumentative essays, both of which are writing-related tasks, with attention to how generative AI supports these processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes a qualitative study using screen recordings, think-aloud protocols, final texts, and interviews to analyze cognitive and composing processes. It does not mention any experimental or quasi-experimental design, control/comparison of conditions, or quantifiable writing outcome metrics assessing effectiveness of the AI intervention.""
    }
}"
765,Ai Chatbot as a Companion in Writing Travel Notes1,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are Russian heritage language speakers and advanced Russian-as-a-foreign-language learners at a German university. The target language is Russian, not English, so the population does not match the review’s focus on L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a customized chatbot built on the ChatGPT model (an LLM) as an interactive interlocutor and writing assistant in a structured learning scenario, indicating an LLM-based intervention integrated into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on improving writing competency in the travel note genre, using a genre-based approach and a five-step genre cycle. The chatbot supports learners in crafting travel notes, clearly centering on writing instruction rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses potential benefits and observations (e.g., better understanding of genre specifics, development of reading and writing skills) but does not explicitly mention quantitative writing outcome measures or experimental comparisons. It is unclear whether structured, quantifiable writing outcomes were collected.""
    }
}"
766,English Paraphrasing Strategies and Levels of Proficiency of an Ai-generated Quillbot and Paraphrasing Tool: Case Study of Scientific Research Abstracts,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study paraphrases 30 abstracts from the Journal of Second Language Writing using QuillBot and Paraphrasing Tool. No human participants or L2 English learners in ESL/EFL/ELL contexts are mentioned; it is a tool-focused text analysis, not learner-focused research.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study analyzes paraphrasing strategies and proficiency levels of QuillBot and Paraphrasing Tool. There is no experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or learner writing processes; it is a comparative evaluation of tools.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the paraphrasing behavior of AI tools applied to published abstracts, not on developing or assessing learners’ writing competence through an instructional context. Any pedagogical comments are incidental and not part of an intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes are reported. The study reports patterns of paraphrasing (e.g., synonym substitution, levels of revision) by the tools themselves, not changes in human learners’ writing performance following an LLM-mediated intervention.""
    }
}"
767,Eap Teacher Feedback in the Age of Ai: Supporting First-year Students in Efl Disciplinary Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly refers to “English as a foreign language (EFL) disciplinary writing” and “first-year EFL undergraduate students in their discipline-specific academic writing within EMI settings,” indicating L2 English learners in an EFL/EMI context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study discusses “the emergence of generative artificial intelligence (GenAI) as a feedback tool” and compares students’ perceptions of teacher vs. AI-generated feedback, there is no indication of an experimental or quasi-experimental LLM-based writing intervention. The focus is descriptive/analytical rather than implementing an LLM (e.g., ChatGPT) as an instructional treatment.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly disciplinary academic writing: the study analyzes EAP teacher feedback on EFL disciplinary writing and students’ perceptions of feedback, which is directly related to writing competence and writing support.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions analysis of interview themes and a coding scheme for feedback types, but does not report any quantitative writing outcome measures (e.g., changes in writing scores, quality, accuracy). Outcomes are qualitative (perceptions, nature of feedback), not experimental measures of LLM-mediated writing improvement.""
    }
}"
768,Reflections on Co-researching Ai Literacy: a Students-as-partners Approach with International Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The participants are described as international students in a UK pre-sessional English for Academic Purposes (EAP) course, which likely implies L2 English learners, but the abstract does not explicitly state that they are ESL/EFL/ELL learners or that the data focus specifically on English language learning outcomes.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a Students-as-Partners case study on AI literacy, focusing on learning about AI limitations and prompt writing. It does not describe an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT, GPT-4) into writing instruction or processes; rather, it is about co-researching AI literacy and partnership practices.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on AI literacy, SaP processes, and partnership reflections, not on writing competence or writing-related variables as outcomes. Prompt writing is mentioned as a skill, but the context is AI literacy rather than a structured writing pedagogy intervention targeting writing performance.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics. It discusses perceived benefits (learning about AI limitations, skills for prompt writing) and offers recommendations for SaP projects, but there is no indication of measured writing performance or experimental outcome data.""
    }
}"
769,Chatgpt-generated Corrective Feedback: Does It Do What It Says on the Tin?,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as students at CEFR B1 level attending an English for Academic Purposes (EAP) course at an international branch campus of a UK university, which fits an ESL/EAP L2 English learner context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares ChatGPT-generated corrective feedback with teacher-provided feedback on students’ essays, but the abstract does not indicate an experimental or quasi-experimental pedagogical intervention where L2 learners actually use ChatGPT within a structured writing instruction or process. It appears to be an evaluative comparison of feedback quality, not an LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the quantity and quality of corrective feedback produced by ChatGPT versus teachers, and on the adequacy of feedback strategy and polarity. There is no indication that the study examines changes in learners’ writing competence or writing-related performance; rather, it evaluates the feedback tool itself.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics (e.g., pre/post writing scores, improvement measures). Outcomes concern characteristics of feedback, not measurable changes in students’ writing performance following an LLM-mediated intervention.""
    }
}"
770,"Chatgpt, Plagiarism, and Multilingual Students' Learning to Write",2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions “multilingual students” and “writing instructors,” but does not specify that the participants are L2 English learners in ESL/EFL/ELL contexts or that the focus is specifically on English writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The piece is described as a “short piece” sharing “exploratory interactions with ChatGPT” to discuss plagiarism and academic integrity. There is no indication of an experimental or quasi-experimental design or a structured instructional intervention integrating ChatGPT into writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on plagiarism, academic integrity, and ethics in academic writing, not on developing writing competence or writing-related performance. ChatGPT is framed as a tool to teach ethics rather than to improve writing skills.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or assessment of writing performance. It appears to be conceptual/exploratory rather than an empirical study with measurable writing outcomes.""
    }
}"
771,Chatgpt in Language Writing Education: Reflections and a Research Agenda for a Chatgpt Feedback Engagement Framework,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses ESL writing education in general but does not specify any actual participant group or empirical data collection with L2 English learners. It appears to be a conceptual/personal reflection piece rather than a participant-based study.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is discussed conceptually and ethically, and a future research agenda/framework is proposed. However, there is no indication of an experimental or quasi-experimental intervention actually implemented with learners; it is a reflection and framework paper.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""While the context is ESL writing education and feedback, the paper is theoretical, focusing on ethical considerations and a proposed framework rather than an implemented pedagogical intervention or study of writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantitative writing outcomes or measures. It is a reflective/conceptual article calling for future research, not an empirical evaluation of LLM-mediated writing outcomes.""
    }
}"
772,The Reliability of Using Chatgpt in Rating Efl Writings,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses 82 compositions from the Written English Corpus of Chinese Learners, clearly indicating EFL learners writing in English as an L2.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used solely as an automated rater to evaluate existing EFL essays. There is no experimental or quasi-experimental instructional intervention integrating ChatGPT into learners’ writing instruction or writing process.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the reliability of ChatGPT as an essay scoring tool (intra- and inter-rater reliability), not on pedagogical use for improving writing competence or writing-related learning outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No learner writing outcomes are measured as a result of an LLM-mediated intervention. The only quantitative outcomes are reliability statistics comparing ChatGPT and human ratings, not changes in students’ writing performance.""
    }
}"
773,"Comparing Peer, Chatgpt, and Teacher Corrective Feedback in Efl Writing: Students' Perceptions and Preferences",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL students in English as a Foreign Language classrooms, so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention includes an AI tool (ChatGPT) providing written corrective feedback as one of three feedback modes. ChatGPT is a large language model integrated into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on written corrective feedback in EFL writing and subsequent revisions, directly related to writing competence and feedback practices in writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as using a qualitative approach via survey analysis to explore students’ perceptions and preferences. No quantifiable writing outcome metrics (e.g., scores, rubric-based gains, measurable text quality changes) are reported; revisions are mentioned but not as measured outcomes of effectiveness.""
    }
}"
774,Enhancing Usability and Learner Engagement: a Heuristic Evaluation of the Ai-enhanced Video Drama Maker App,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The app is designed for learners of English as a Foreign Language (EFL), clearly situating the population as L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the app includes GPT-generated sentences, the study itself is a heuristic evaluation of usability by UI/UX experts, not an experimental or quasi-experimental pedagogical intervention with learners integrating LLMs into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on usability, user experience, and HCI design (heuristic evaluation using Nielsen’s principles). Writing and speaking are mentioned as intended outcomes, but they are not the focus of the reported study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The quantitative data concern usability (e.g., Cronbach’s alpha, descriptive statistics on heuristic evaluation), not writing performance or related writing variables.""
    }
}"
775,Developing a Thai Grammatical Error Correction Tool for Deaf Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are deaf students writing in Thai. The focus is on Thai grammatical error correction, not on L2 English learners in ESL/EFL/ELL contexts or English-language data.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract describes a Thai grammatical error correction (GEC) system and mentions off-the-shelf vs. custom models, but does not specify that these are large language models (e.g., transformer-based generative LLMs like GPT). The nature of the models is not clearly LLM-based.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on developing and evaluating an automatic Thai GEC tool and corpus, not on a pedagogical writing intervention or instructional context aimed at improving learners’ writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are model performance metrics (detection and correction accuracy) rather than quantifiable writing outcomes for learners following an LLM-mediated writing intervention.""
    }
}"
776,Deep Learning Approaches to Predict Student Success in English Language Learning,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to 'English language learning' and 'student-written texts' but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts. They could be L1 or mixed populations; this is not explicit.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""GPT-3 is used to predict student success and assess texts, functioning as an analytic/predictive tool. There is no explicit experimental or quasi-experimental design integrating GPT-3 into writing instruction or the writing process as an intervention; it is primarily a prediction/assessment model.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on predicting student achievement and improving accuracy of success predictions, not on developing writing competence. Writing is used as input data for prediction, and the study centers on evaluation/analytics rather than a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported concern prediction accuracy of student success and the quality of feedback, not quantifiable changes in learners’ writing performance following an LLM-mediated writing intervention. No pre/post or comparative writing outcome measures are described.""
    }
}"
777,Xducation of Things (xot): Harnessing Ai and Edge Computing to Educate All Things,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states that a quasi-experimental study involved 26 EFL learners, indicating that the participants are L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is the smartXoT environment with a Smart Question Answer Forwarding Mechanism (SQA-Forwarding) within an edge-computing/XoT framework. The abstract does not indicate that this system is based on large language models (e.g., ChatGPT, GPT-4, transformer-based generative models); it appears to be a knowledge-base/QA forwarding mechanism rather than an LLM-mediated writing tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports that interaction between EFL learners and smartthings with SQA-Forwarding significantly improved learners’ writing skills and that revisions enhanced writing quality, indicating a primary focus on writing competence as a learning outcome.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract mentions a quasi-experimental design with experimental and control groups and reports significant improvement in writing skills and writing quality, implying quantifiable writing outcome metrics were used to assess the intervention’s effectiveness.""
    }
}"
778,Automated English Language Learning Using Bert-lstm Model,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers generally to “automatic English learning” and “students,” but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor does it clearly describe an empirical learner population at all.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a BERT-LSTM model as an NLP engine for automated English learning. BERT is a transformer-based encoder, but the abstract does not indicate use of a generative large language model (e.g., ChatGPT/GPT-4) integrated into writing instruction. It appears to be an automated system for tasks like comprehension, interpretation, and grammar correction, not an LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions “accuracy of written responses” and “grammar correction,” but the primary focus seems to be general language learning and multiple linguistic tasks, not specifically writing competence or a writing-focused pedagogical intervention. The instructional context and focus on writing are not clearly described.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""It states that “experimental findings affirm the usefulness” of the model, but provides no indication that quantifiable writing outcome metrics (e.g., writing scores, text quality measures) were collected as part of a structured writing intervention. The nature of the reported outcomes is not clear from the abstract.""
    }
}"
779,"The Effects of a Quillbot-based Intervention on English Language Majors' Efl Writing Performance, Apprehension, and Self-efficacy",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 18 fourth-year English Language majors in an EFL context at Matrouh University. The study explicitly concerns EFL writing performance, indicating L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is based on QuillBot, described as an AI-powered writing assistant. QuillBot is not clearly identified as an LLM-based, transformer generative model in the abstract, and in this review’s criteria, tools like QuillBot are explicitly listed as examples to exclude when they are not LLM-based writing interventions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL writing performance and related affective variables (writing apprehension and self-efficacy). The intervention involves drafting, receiving AI-generated feedback, revising, and producing final drafts, which is clearly a writing-focused pedagogical context rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a pre/post test and two scales to measure writing performance, apprehension, and self-efficacy, and reports significant positive effects. These constitute quantifiable outcome measures of writing-related performance and affective variables.""
    }
}"
780,Revolutionizing Efl Learning through Chatgpt: a Qualitative Study,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students at the University of Hail in Saudi Arabia, clearly positioning them as L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is the focus, the study is exploratory and qualitative, using interviews to examine perceptions of using ChatGPT. There is no indication of an experimental or quasi-experimental intervention design integrating ChatGPT into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing is mentioned as one of several skills (reading, writing, grammar, spelling, research skills, self-directed learning). The primary focus appears to be general English learning with ChatGPT, not specifically writing competence or writing-related variables as the main context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly described as qualitative, based on individual and focus group interviews. It reports perceived enhancements but does not mention any quantifiable writing outcome metrics or measured changes in writing performance.""
    }
}"
781,Efl Students' Perception in Indonesia and Taiwan on Using Artificial Intelligence to Enhance Writing Skills,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students in Indonesia and Taiwan, described as second-year students specializing in English. The focus is clearly on English as a Foreign Language learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students ‘actively use AI tools in their writing processes,’ the abstract does not specify that these are LLM-based tools (e.g., ChatGPT, GPT-4) nor does it describe an experimental or quasi-experimental intervention design. It is a perception study using qualitative interviews, not an instructional intervention trial.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly academic writing in EFL, focusing on how AI is used to enhance writing skills (grammar, sentence structure, paraphrasing, vocabulary, topic generation). Thus, the primary focus is on writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses qualitative methods (semi-structured interviews, thematic analysis) to explore perceptions. No quantifiable writing outcome metrics or experimental measures of writing performance are reported.""
    }
}"
782,From Virtual Assistant to Writing Mentor: Exploring the Impact of a Chatgpt-based Writing Instruction Protocol on Efl Teachers' Self-efficacy and Learners' Writing Skill,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Iranian English language teachers and learners in an L2 writing context, explicitly described as EFL. The focus is on English language learning and writing skills, satisfying the population criterion.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is a ChatGPT-based writing instruction protocol (CGWIP). ChatGPT is a large language model, and it is integrated systematically into planning, instruction, and assessment phases. The study uses an experimental design with control and treatment groups and pre/post testing.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly an L2 writing context. ChatGPT is used for brainstorming, engaging learners in the writing process, analyzing and reflecting on drafts, and simulating IELTS writing exams with feedback. The primary focus is on writing instruction and writing skills, not on automated scoring alone.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative outcomes: Independent Samples t-test and One Way ANCOVA results showing that CGWIP significantly improved learners’ writing skills and teachers’ self-efficacy. Writing skills are measured pre- and post-intervention, providing quantifiable writing outcome metrics.""
    }
}"
783,The Influence of Chatgpt on Thinking Skills and Creativity of Efl Student Teachers: a Narrative Inquiry,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are described as “EFL student teachers” and “English student teachers” in a teacher education programme. The focus is on their practicum and use of ChatGPT in teaching practices, not on their own L2 English learning or development as EFL learners. Thus, they are better characterized as pre-service teachers rather than L2 learner participants in an ESL/EFL/ELL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""ChatGPT (an LLM) is used, but the abstract frames it as part of teaching practices and teacher education, not as a structured experimental or quasi-experimental writing intervention. The design is narrative inquiry, not clearly an intervention study with controlled conditions.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on “thinking skills and creativity” of student teachers and their experiences using ChatGPT in teaching. Writing is only mentioned as “weekly written narratives” used as data, not as a target of instruction or competence development. The study does not focus on writing competence or writing-related variables as outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a narrative inquiry approach with qualitative interviews and written narratives, examining experiences, perceptions, and reflections. No quantifiable writing outcome metrics or experimental measures of writing performance are reported; outcomes are qualitative insights into thinking skills, creativity, and AI integration.""
    }
}"
784,Generative Ai and Essay Writing: Impacts of Automated Feedback on Revision Performance and Engagement,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are described only as 'first-year university students in Hong Kong.' Their L2 English learner status is not specified, nor is an ESL/EFL/ELL context explicitly mentioned. They could be native or L2 users, so the population criterion is not clearly met.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses 'feedback generated by large language models (LLMs)' as an intervention in a randomized controlled trial, with one group receiving AI-generated feedback on essay drafts and a control group not receiving it. This is an experimental design integrating LLMs into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on 'essay-writing skills,' 'revising their essays,' and 'essay revision performance,' which are clearly writing-related variables in an educational context, not just automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports 'statistical analysis of essay grades' and notes that students receiving AI feedback 'achieved significant improvements in essay quality.' These are quantifiable writing outcome metrics assessing the effectiveness of the LLM-mediated intervention.""
    }
}"
785,Impacts of Chatgpt-assisted Writing for Efl English Majors: Feasibility and Challenges,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL English college majors, clearly L2 English learners in an EFL context: “English as a foreign language (EFL) English college majors.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used to assist students in revising essays, but there is no instructional or pedagogical intervention design (e.g., teaching sequence, integration into writing instruction). The study is framed as a prospective, double-blinded, paired-comparison to test score changes and fairness, not as an instructional experiment on LLM-mediated teaching or learning processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on how ChatGPT-assisted revisions affect essay scores and fairness in evaluation, not on developing writing competence. It evaluates the impact of using ChatGPT on graded products and distribution of scores, similar to a tool-effect/fairness study rather than a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantifiable writing outcomes are reported: before–after comparison of original vs. ChatGPT-assisted revised essays, with scores in four dimensions (vocabulary, grammar, organization, content) and distributional changes in grades.""
    }
}"
786,Examining the Impact of Ai-powered Writing Tools on Independent Writing Skills of Health Science Graduates,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as ESL health science graduates from a South Indian private medical university, indicating English is a second language and the context is ESL with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates ‘AI-powered writing tools’ in general and contrasts ‘independent writing with AI editing assistance’ vs. ‘generative writing with AI assistance,’ but it is framed as a survey of familiarity, attitudes, and usage. There is no indication of an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT, GPT-4) into instruction; the tools are not clearly identified as LLM-based.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on knowledge, attitudes, and usage patterns of AI-powered writing tools, and concerns about reliance affecting independent writing. It does not describe a pedagogical writing intervention or instructional design; rather, it is a descriptive survey of practices and perceptions.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are frequency distributions of knowledge, familiarity, and perspectives toward AI-PWT use. There are no quantifiable pre/post or comparative writing performance measures assessing the effectiveness of an AI/LLM-mediated writing intervention on writing quality or related performance variables.""
    }
}"
787,"Chatgpt, the End of L2 Academic Writing or a Blessing in Disguise?",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on academic writing in English as a second language and discusses opportunities and challenges for L2 students and teachers, indicating an L2 English learner population in ESL/EFL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the paper is described as an overview and a descriptive account of an interview with ChatGPT, plus suggested activities. There is no indication of an experimental or quasi-experimental design integrating ChatGPT into instruction with participants.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 academic writing skills and how ChatGPT and AI-based technologies relate to the L2 writing process, clearly centering on writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any empirical intervention, data collection with learners, or quantifiable writing outcome metrics. It appears to be conceptual/descriptive, discussing opportunities, challenges, and proposed activities without measured outcomes.""
    }
}"
788,Exploring the Educational Potential of Chatgpt: Ai-assisted Narrative Writing for Efl College Students,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 44 university students in South Korea engaged in college-level L2 (EFL) writing. The context is explicitly EFL and focuses on English as the target language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study investigates “ChatGPT-assisted narrative writing” and analyzes “effects of the narrative writing intervention assisted by ChatGPT.” ChatGPT is a large language model, and the design includes pre/post testing, indicating an experimental/quasi-experimental intervention using an LLM in writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on narrative writing in L2 and the impact of ChatGPT on writing skills, including fluency, syntactic complexity, and overall performance. This is a pedagogical writing intervention, not an automated scoring or purely functional evaluation of the tool.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports quantitative writing outcomes: pre/post-test scores in writing fluency, overall performance, syntactic complexity, and clause complexity, with statistical tests (paired t-test, Wilcoxon signed rank test) and significance reported. These are clear, quantifiable writing outcome metrics.""
    }
}"
789,Zone of Proximal Creativity: an Empirical Study on Efl Teachers' Use of Chatgpt for Enhanced Practice,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are EFL teachers enrolled in a post-graduate program, not L2 English learners in ESL/EFL/ELL contexts. The focus is on teacher creativity, not learner language development.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, it is employed as a tool to support teachers’ creative ideation (e.g., lesson planning, seeking perspectives), not as part of an experimental or quasi-experimental writing instruction intervention for L2 learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on teacher creativity and use of ChatGPT for lesson planning and idea generation. There is no indication that the study targets writing competence or writing-related variables as the main outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses inductive content analysis of inquiry threads, lesson plans, reflections, and open-ended survey responses to explore creativity. It does not report quantifiable writing outcome metrics related to L2 learner writing performance.""
    }
}"
790,Patterns of Utilizing Ai-assisted Tools among Efl Students: Need Surveys for Assessment Model Development,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Indonesian EFL university students, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a survey of AI-tool utilization patterns and technology acceptance. It does not describe an experimental or quasi-experimental intervention integrating LLMs into writing instruction. The main tools mentioned are Grammarly and Google Translate, which are not specified as LLM-based in this context.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on general AI-tool use, knowledge, and technology acceptance, not specifically on writing competence or writing-related instructional interventions. Writing outcomes or writing-focused pedagogy are not central to the study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study reports survey data on knowledge, frequency of use, perceived ease of use, and perceived usefulness of AI tools, without measuring changes in writing performance.""
    }
}"
791,Chain-of-thought in Neural Code Generation: from and for Lightweight Language Models,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study concerns large and lightweight language models for code generation in software engineering. There is no mention of human participants, learners, or L2 English learning contexts (ESL/EFL/ELL).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although LLMs are used, they are applied to code generation and Chain-of-Thought reasoning, not as an instructional intervention for L2 English writing. No educational or pedagogical design is described.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is software engineering and code generation performance, not writing competence in an L2, nor any writing-related educational variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are automated and human evaluation metrics for code generation quality, not quantifiable outcomes of L2 English writing performance or related writing skills.""
    }
}"
792,The Impact of Using Interactive Chatbots on Self- Directed Learning,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'fifty Omani EFL students', clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses an 'interactive chatbot' implemented via WhatsApp, but there is no indication that it is based on a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model). It appears to be a delivery platform for instructions and tests rather than an LLM-integrated writing tool.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing tasks are mentioned among several activities (grammar, reading comprehension), but the primary focus of the study is on self-directed learning abilities, not specifically on writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported center on self-directed learning questionnaire scores (awareness, strategies, activities, evaluation, interpersonal skills). While writing tasks were assigned, no specific, quantifiable writing outcome metrics are reported in the abstract.""
    }
}"
793,Ai Tools for Enhanced English Learning: Leveraging Machine Learning for Improved Outcomes,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to 'English as a foreign language' and 'diverse groups of learners' but does not clearly specify that the participants are L2 English learners in ESL/EFL/ELL contexts, nor does it describe an actual participant sample.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper describes a proposed AI/ML-based system using NLP, adaptive learning, speech and text recognition, and gamification. It does not explicitly mention large language models (e.g., ChatGPT, GPT-4) or transformer-based generative models, and appears to be a conceptual/system design rather than an experimental or quasi-experimental LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing is mentioned only briefly as one of several skills (writing and speaking feedback) within a broader English learning platform. The primary focus seems to be general English learning, pronunciation, and gamified engagement, not specifically writing competence or writing-related variables as the main outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract outlines a methodology and system architecture but does not report any experimental or quasi-experimental results, nor any quantifiable writing outcome metrics. It appears to be a proposal or conceptual framework without measured intervention outcomes.""
    }
}"
794,Role of Artificial Intelligence in Ict Based Teaching and Learning,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions language learning and ELT applications but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor does it describe any concrete participant group.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a general discussion of AI technologies in ICT-based teaching and learning, listing tools like Google Translate, Duolingo, chatbots, etc. There is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT, GPT-4) into writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Writing is mentioned only briefly as one of several practical skills. The focus is broad (role of AI in teaching and learning, language proficiency, ELT applications) rather than a primary focus on writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics or structured intervention outcomes. It appears to be descriptive or conceptual rather than an empirical intervention study measuring writing performance.""
    }
}"
795,How Llms Support Efl Writing:a Case Study of K-12 English Learning Based on the Edipt Model,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on K-12 English as a Foreign Language (EFL) learners in Chinese English education, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the paper discusses LLMs conceptually and proposes a response strategy framework (EDIPT model) for future use, it is described as a case study and an initial effort to explore potential contributions. There is no indication of an experimental or quasi-experimental design implementing an LLM-based writing intervention; it appears more conceptual/theoretical than an actual tested intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on how LLMs can support EFL writing and K-12 English learning, and it mentions enhancing writing abilities and providing feedback on students’ writing. However, the abstract does not clearly describe a concrete pedagogical intervention or structured writing-instruction context being empirically evaluated.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantitative writing outcome measures or experimental results. It discusses potential benefits (improving learning efficiency, reducing teacher burden) and challenges, and offers recommendations, but no measurable writing performance data or intervention outcomes are mentioned.""
    }
}"
796,Predictive Feedback Loops: Harnessing Ai for Continuous Assessment and Personalized Growth in English Language Learners,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “English language learners” and “English language learning” but does not specify whether participants are L2 English learners in ESL/EFL/ELL contexts or provide any concrete participant description. It is unclear if this is an empirical learner study or a conceptual/technical proposal.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is based on an LSTM model for predictive feedback loops, not on a large language model (e.g., ChatGPT, GPT-4, Gemini). LSTM is a recurrent neural network architecture, not a transformer-based generative LLM. Therefore, it does not meet the criterion of integrating LLMs into instruction.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study targets overall English language proficiency and mentions comprehension, grammar, vocabulary, and fluency. Writing is only one of several skills and is not the primary or clearly isolated focus. The abstract does not indicate that writing competence or writing-related variables are the central outcome of the intervention.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that the research “investigates the model's efficacy in enhancing language proficiency” but does not specify any quantifiable writing outcome metrics or experimental design details. It is unclear whether structured, measurable writing outcomes are reported, and the focus appears to be general proficiency and learner traits (self-regulation, motivation, autonomy).""
    }
}"
797,Ai in Foreign Language Learning in Engineering Education: the Benefits and Challenges of Using Chatgpt,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are first-year engineering students learning a foreign language (English) in a non-linguistic department, indicating an L2 English learning context (EFL in engineering education).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used and practical ways of use are described, but the abstract does not indicate an experimental or quasi-experimental design. It appears descriptive, outlining benefits, challenges, and suggested practices rather than a controlled intervention study.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing is one of several skills mentioned (vocabulary, grammar, written practice, learning writing styles, dialogue). The primary focus seems to be general foreign language learning with multiple skills, not specifically writing competence or writing-related variables as the main outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports students’ attitudes via an after-practice questionnaire and tips for ChatGPT use. There is no mention of quantifiable writing outcome metrics or measured changes in writing performance; outcomes are attitudinal and descriptive.""
    }
}"
798,Exploring Chatgpt's Ability to Classify the Structure of Literature Reviews in Engineering Research Articles,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any participants, learners, or educational context (ESL/EFL/ELL). It is a systems-focused evaluation of ChatGPT’s classification ability on literature review structures in engineering research articles, not a study involving L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used to classify paragraphs in literature reviews and its performance is compared to manual coding. There is no experimental or quasi-experimental pedagogical intervention integrating ChatGPT into writing instruction or learners’ writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on ChatGPT’s functionality in identifying literature review structure, not on developing or assessing learners’ writing competence. Any pedagogical implications are speculative and not part of an implemented instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes are reported. The numerical results concern ChatGPT’s classification accuracy, not changes in students’ writing performance following an LLM-mediated intervention.""
    }
}"
799,Using Ai-text Editing Tools to Enhance Writing Skills: an Attitudinal Case Study of Egyptian Undergraduates,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Egyptian undergraduates in a TEFL context, explicitly aiming to improve their EFL writing abilities. This fits L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “AI-text editing tools” and “different AI tools” without specifying whether they are LLM-based (e.g., ChatGPT, GPT-4) or non-LLM tools (e.g., traditional grammar checkers). However, the study is framed as a case study of tool use rather than an experimental or quasi-experimental intervention design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on using AI-text editing tools to refine translated manuscripts and improve EFL writing abilities, i.e., writing quality and writing skills in an EFL context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as an attitudinal case study based on students’ self-reported observations and perceptions. The abstract reports favorable attitudes and perceived enhancement of writing skills but does not mention any quantitative writing outcome measures or experimental comparison to assess effectiveness.""
    }
}"
800,Investigating Chinese Learners ‘ Use and Perceptions of Chatgpt in Eap,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese learners in an English for Academic Purposes (EAP) context at a Chinese university, which fits L2 English learners in an EFL/ESL/ELL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the study investigates learners’ use and perceptions via questionnaire and interviews. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating ChatGPT into instruction; it is observational/descriptive.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context includes academic writing and EAP, and students use ChatGPT for academic vocabulary and academic writing, which aligns with writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports perceptions, attitudes, and self-reported uses only. It does not mention any quantifiable writing outcome measures (e.g., writing scores, text quality metrics) or an evaluated intervention effect.""
    }
}"
801,Argumentative Writing Software: Perceptions of Undergraduate Students Toward Artist Prototype,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are 30 undergraduate students at a Thai university. Their L1 is likely not English, but the abstract does not explicitly state that they are L2 English learners or that the writing is in English, so it is unclear whether this is an L2 English context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines perceptions of an argumentative writing support tool (Artist) using NLP and AI. ChatGPT is mentioned as providing recommendations, but the design is described as prototype/interface testing with focus group interviews, not as an experimental or quasi-experimental LLM-based instructional intervention. The primary focus is usability/feasibility and perceptions, not a structured LLM-mediated teaching intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The tool is explicitly an argumentative writing support software, and the study focuses on argumentative writing and how students benefit from graphical representation in their argumentative writing. Thus, the primary focus is on writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are based on focus group interviews and perceptions of feasibility and usability. The abstract does not report any quantifiable writing outcome metrics (e.g., scores, rubric-based improvements, measurable changes in writing quality). The effectiveness discussed appears to be qualitative and design-oriented rather than experimental measures of writing performance.""
    }
}"
802,Mcaimem: a Mixed Sram and Edram Cell for Area and Energy-efficient On-chip Ai Memory,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article focuses on AI chip memory design and benchmarking. There are no human participants, no mention of L2 English learners, ESL/EFL/ELL contexts, or any language learning population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is a mixed SRAM/eDRAM on-chip memory architecture (MCAIMem) for AI hardware. It does not involve integrating large language models (e.g., ChatGPT, GPT-4) into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is hardware performance (area, energy efficiency) for AI memory in deep neural networks, not writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No writing outcomes or educational measures are reported; the outcomes are chip area, energy consumption, and accuracy of AI models, unrelated to L2 writing performance.""
    }
}"
803,Identifying Language Anxiety among Foreign Language Learners Using Gru,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The participants are described as foreign language learners writing English essays, suggesting they may be L2 English learners, but the specific ESL/EFL/ELL context and focus on English as the target language are not clearly detailed.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study develops machine learning classifiers (Decision Tree, LSTM, GRU) to categorize student-produced texts as anxious vs. non-anxious. These are not large language models used as pedagogical tools in writing instruction; they are text classifiers for anxiety detection, not LLM-based writing interventions.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on identifying language anxiety via automated text classification, not on improving writing competence or writing-related instructional processes. Writing is only a source of data for anxiety detection, not the target of an instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are model performance metrics (F1-score, accuracy, ROC-AUC) for anxiety classification. There are no quantifiable writing outcome measures assessing changes in learners’ writing performance due to an LLM-mediated intervention.""
    }
}"
804,Fluent Futures: Cutting-edge Ai Techniques for Mastering English,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses the ELLIPSE Corpus, described as a dataset of English Language Learner (ELL) writing samples with proficiency scores and comments, indicating an L2 English learner population in an ELL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is based on BERT and a sequence-to-sequence fine-tuning mechanism to generate feedback. BERT is a bidirectional encoder model, not a generative large language model like ChatGPT/GPT-4, and the abstract does not indicate use of an LLM-based generative system in instruction. Thus it does not meet the LLM intervention criterion.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on generating individualized feedback on learner writing (grammar, vocabulary, syntax) using AI, which is writing-related. However, it is not clearly framed as a pedagogical classroom intervention versus a technical NLP system for feedback generation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions potential measures such as student satisfaction and gains in writing skill, the reported experimental findings are only ROUGE-1, ROUGE-2, and ROUGE-L scores, which evaluate system output quality against reference feedback, not learners’ writing outcomes. No quantifiable learner writing improvement is reported.""
    }
}"
805,Synergizing Generative Pre-trained Transformer (gpt) Chatbots in a Process-based Writing Paradigm to Enhance University Students' Writing Skill,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 'university EFL students,' indicating learners of English as a foreign language. The focus of the study is on their English writing skills (organization, content, coherence-cohesion, logical connection, argumentation), satisfying the requirement that the target language is English in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is the integration of 'GPT-based chatbots' within a process-based writing framework. GPT-based chatbots are large language models (Generative Pre-trained Transformers). The study uses a pre- and post-test design with 10 instructional sessions, indicating an experimental/quasi-experimental pedagogical intervention using LLMs in writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on enhancing 'students' writing skills' within a 'process-based writing framework,' covering components such as organization, content, coherence-cohesion, logical connection, and argumentation. The LLM is used as part of the writing process (planning, drafting, revising, editing), not merely for automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative writing outcomes: pre- and post-writing test scores (mean scores increasing from 9.13 to 17.03) and performance across four writing quizzes, with detailed component-wise improvements. These constitute measurable writing outcome metrics assessing the effectiveness of the GPT-based chatbot intervention.""
    }
}"
806,Examining Writing Feedback Dynamics from Chatgpt Ai and Human Educators: a Comparative Study,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as English Language Learners and third-year undergraduate students in English Language Education, indicating an EFL/ELL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used as an AI automated writing feedback tool, the study employs a phenomenological design and focuses on comparing AI vs. human feedback qualitatively, not as an experimental or quasi-experimental pedagogical intervention with controlled conditions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is writing instruction and feedback, explicitly aiming to examine the effectiveness of AI and human feedback in enhancing writing skills of English Language Learners.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract states that the study used a phenomenological design and collected qualitative data; it reports perceptions of feedback (detail, comprehensiveness, emotional intelligence) but does not mention any quantifiable writing outcome measures or experimental effectiveness metrics.""
    }
}"
807,Chatbot-based Learning of Logical Fallacies in Efl Writing: Perceived Effectiveness in Improving Target Knowledge and Learner Motivation,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 30 Chinese EFL learners, clearly an L2 English population in an EFL context, and the focus is on EFL writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers generically to a ‘chatbot’ used for learning logical fallacies, with no indication that it is an LLM-based tool (e.g., ChatGPT, GPT-4, transformer-based generative model). It could be a rule-based or scripted chatbot. Without explicit mention of LLM or generative AI, its status as an LLM intervention is unclear.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary instructional focus is on learning logical fallacies and motivation, not on writing competence or writing performance. While framed in relation to EFL writing, the measured outcomes are fallacy knowledge and motivation, not writing quality or writing-related performance variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantitative outcomes are pre–post tests of fallacy knowledge and motivation questionnaires. No quantifiable writing outcome metrics (e.g., writing scores, text quality, complexity, accuracy, fluency) are reported to assess changes in writing performance.""
    }
}"
808,Co-creating Stories with Generative Ai,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as students in an undergraduate language-related subject at a Hong Kong tertiary institution, and the paper explicitly refers to them as ESL learners, indicating L2 English learners in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions use of ‘publicly available Generative Artificial Intelligence (GenAI) tools’ in co-creating digital stories, but does not specify whether these are LLM-based tools (e.g., ChatGPT) or other generative systems. However, even if they are LLMs, the study design is not clearly experimental or quasi-experimental; it is framed as a service-learning subject with qualitative analysis.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on digital storytelling, creative potential, and promoting linguistic, digital, and cultural awareness, with GenAI playing a ‘peripheral role’. There is no indication of a structured writing instruction intervention aimed at improving writing competence; rather, it is a service-learning experience and exploration of critical use of GenAI.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is based on qualitative content analysis of semi-structured interviews and reports perceived expansion of creative potential and awareness. It does not mention any quantifiable writing outcome metrics or experimental measures of writing performance.""
    }
}"
809,Aes Model with Logic Rule Reasoning and Self-explanation Based on Amr and Llm,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions 'second-language learners' only as a potential user group needing explanations, but does not describe any actual participant population, learner context (ESL/EFL/ELL), or empirical study with L2 English learners. It appears to be a technical AES model paper without human learner participants.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""LLMs are used to generate explanations within an Automated Essay Scoring system, not as part of an instructional or quasi-experimental intervention in writing instruction or writing processes. The focus is on model development and comparison with ChatGPT-4, not on pedagogical integration.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is AES model interpretability and performance, not writing competence or writing-related learning outcomes. LLMs are evaluated as components of an automated scoring/explanation system, which falls under excluded AES functionality studies rather than pedagogical interventions.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are model performance metrics (e.g., surpassing prompt-tuned ChatGPT-4, cost reduction) and explanation quality, not quantifiable writing outcomes for learners. There is no experimental measure of changes in learners’ writing ability following an LLM-mediated intervention.""
    }
}"
810,Morpho-phraseological Based Classification of Cefr Italian L2 Learner Writing Proficiency,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are L2 learners of Italian, not L2 English learners. The study focuses on Italian as a second language and CEFR classification for Italian, which does not meet the population requirement centered on English L2 learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study presents an automatic classification model using lexical, morphosyntactic, and phraseological features, and compares it with machine learning models. There is no indication that large language models (e.g., ChatGPT, GPT-4) are used, nor that there is any instructional or intervention component.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on automated proficiency classification (assessment) of written texts, not on writing instruction, intervention, or support for writing processes. This aligns with automated scoring/classification research rather than pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are model performance metrics (accuracy and prediction metrics) for CEFR level classification, not quantifiable writing development outcomes resulting from an LLM-mediated intervention. No experimental writing instruction or improvement measures are described.""
    }
}"
811,Enhancing Writing Skills with Ai: Personalized Feedback Mechanisms for English Learners,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to 'English learners' and 'diverse learning contexts' but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor does it describe any concrete learner population or setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study introduces a feedback system based on the T5 Transformer model and evaluates it using BLEU, ROUGE, and METEOR. There is no indication of an experimental or quasi-experimental pedagogical intervention where L2 learners actually use the system in writing instruction; it appears to be a system-development and NLP evaluation study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""While the context is writing feedback, the focus is on model performance and automatic feedback quality, not on an instructional intervention or integration into a teaching/learning process aimed at improving learner writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Reported outcomes are NLP metrics (BLEU, ROUGE, METEOR) assessing alignment with reference texts, not quantifiable learner writing outcomes (e.g., pre/post writing scores, rubric-based writing quality measures) from an educational intervention.""
    }
}"
812,The Impact of Using Chatgpt on Efl Students’ Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) learners, and the focus is on English writing, satisfying the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines learners’ outlines written without ChatGPT and revised outlines with ChatGPT assistance, indicating an intervention integrating an LLM (ChatGPT) into the writing process in a comparative design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on the impact of ChatGPT on EFL students’ writing, including logical structure, content enrichment, vocabulary, and grammar, which are all writing-related variables rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports discourse analysis results and qualitative improvements (logical structure, content, vocabulary, grammar) and student reflections, but does not indicate any quantifiable writing outcome metrics (e.g., scores, counts, statistical tests). Outcomes appear qualitative only.""
    }
}"
813,Visual Analysis of Mobile-assisted Language Education and Discussion on the Role of Mobile Llm Applications in Tcsol,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article focuses on mobile-assisted language education broadly and specifically discusses mobile LLM applications in TCSOL (Teaching Chinese to Speakers of Other Languages), i.e., L2 Chinese learners. The target language is Chinese, not English, so it does not match the required L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a visual analysis/bibliometric study using Citespace and a conceptual discussion of the role of mobile LLM applications. There is no experimental or quasi-experimental design integrating LLMs into instruction; it is not an intervention study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper is a bibliometric overview of mobile-assisted language education and a conceptual discussion of potential roles of mobile LLMs. It does not implement or evaluate a writing-focused pedagogical intervention; writing competence is not the primary empirical focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study is descriptive/analytical and forward-looking, discussing potential future research and roles of LLMs, without experimental measures of writing performance.""
    }
}"
814,Exploring Efl Learners’ Integration and Perceptions of Chatgpt's Text Revisions: a Three-stage Writing Task Study,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states the context is an English as a foreign language (EFL) classroom, so participants are L2 English learners and the target language is English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used to provide reformulations as feedback, the design is observational/descriptive rather than experimental or quasi-experimental. The study investigates how learners notice, integrate, and perceive ChatGPT’s reformulations; there is no indication of controlled intervention conditions, comparison groups, or pre/post testing to evaluate instructional effectiveness.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL writing: a three-stage writing task (composing–comparison–rewriting) and how ChatGPT’s reformulations function as feedback in the revision stage. This directly concerns writing processes and writing-related variables in a pedagogical context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported concern noticing (type and depth), number of reformulations integrated, and learners’ perceptions via questionnaire. The abstract does not report quantifiable writing performance outcomes (e.g., scores, quality ratings, accuracy measures) to assess effectiveness of the LLM-mediated intervention on writing competence.""
    }
}"
815,Efl Learners' Perceptions of Written Corrective Feedback in Online Learning,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 113 EFL students (English as a Foreign Language) in English preparation classes at a private university in Vietnam, clearly L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates perceptions of written corrective feedback (WCF) in online writing classes. There is no mention of large language models, ChatGPT, or any transformer-based generative AI being used as part of the intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is English writing classes and written corrective feedback, which is directly related to writing competence and writing instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on students’ perceptions of WCF using questionnaires and interviews. It does not report quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy) resulting from an intervention; it is attitudinal rather than outcome-based.""
    }
}"
816,Uses and Misuses of Chatgpt as an Ai-language Model in Academic Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not specify any participant group, let alone L2 English learners in ESL/EFL/ELL contexts. It appears to be a conceptual or discussion paper about academic writing in general, not an empirical study with a defined L2 population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is discussed, there is no indication of an experimental or quasi-experimental intervention design. The paper examines uses, misuses, advantages, and limitations conceptually rather than implementing ChatGPT in a structured instructional intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on academic writing broadly, including idea generation, grammar, and research assistance. However, it is not framed as a pedagogical intervention targeting writing competence in a specific learner group; instead, it is a general discussion of tool use and ethics.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental measures are reported. The abstract mentions ‘findings’ in a general sense but does not describe any measured changes in writing performance or related variables.""
    }
}"
817,"Chatgpt, a Helpful Scaffold or a Debilitating Crutch for Academic Writing?",2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes a general review of ChatGPT in academic writing without specifying any participant population, let alone L2 English learners in ESL/EFL/ELL contexts. It appears to address academic writers broadly (educators, researchers, students), not a defined L2 English learner group.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is explicitly a review paper that ‘draws on existing literature, empirical studies, and expert opinions’ and ‘assesses the advantages and constraints’ of ChatGPT. It does not report an experimental or quasi-experimental intervention integrating ChatGPT into instruction; it is conceptual/analytical.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on academic writing processes and quality in general, but because it is a review, it does not describe a specific pedagogical context or intervention targeting writing competence. The primary aim is critical examination, not an implemented instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The paper synthesizes advantages, constraints, and ethical implications from prior work, but does not present its own experimental measures or structured intervention outcomes.""
    }
}"
818,Exploring the Young Learners' Interactions with Ai-enerated Multimodal Feedback in Collaborative Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are young learners in Chinese language learning activities. The abstract repeatedly specifies a focus on Chinese language, not English, and there is no indication that they are L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses an AI-enabled automated feedback learning system with AI-generated image feedback, AI-enabled audio feedback, and automatic scoring. However, it is not specified whether this system is based on large language models (e.g., ChatGPT/GPT-4) or other AI techniques.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on vocabulary learning and collaborative Chinese language learning activities. While the title mentions collaborative writing, the abstract emphasizes vocabulary learning outcomes, learning process, and enjoyment, not writing competence or writing-related variables as the main outcome.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study will examine students’ learning outcomes and uses automatic scoring, but the abstract frames these outcomes in terms of vocabulary learning rather than writing performance. It is not clear that quantifiable writing outcome metrics are reported.""
    }
}"
819,To Use or Not to Use? a Mixed-methods Study on the Determinants of Efl College Learners' Behavioral Intention to Use Ai in the Distributed Learning Context,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 464 Chinese EFL college learners, clearly an English-as-a-foreign-language population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines determinants of behavioral intention to use AI based on the Technology Acceptance Model. It does not describe an experimental or quasi-experimental LLM-based writing intervention, nor specify use of tools like ChatGPT or other LLMs in instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on behavioral intention to use AI in distributed EFL learning contexts, not specifically on writing competence or writing-related variables. No mention is made of writing instruction or writing processes as the primary context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are TAM constructs (perceived ease of use, perceived usefulness, attitude, behavioral intention). The study does not report quantifiable writing performance outcomes or writing-related measures.""
    }
}"
820,Opening the Black Box: Interpretable Machine Learning Reveals the Relationship between Lexical Diversity and Writing Quality,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract references CET-4 writing, which typically involves Chinese EFL learners, but it does not explicitly state that the participants are L2 English learners or provide participant details. Thus, the L2 English learner population is not clearly confirmed from the abstract alone.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses interpretable machine learning to explore the relationship between lexical diversity and writing quality and to verify the validity of automatic essay scoring. There is no indication that large language models (e.g., ChatGPT, GPT-4) are integrated into instruction or writing processes as an intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on modeling the relationship between lexical diversity and writing quality and on validating automatic essay scoring, not on a pedagogical writing intervention. It is an assessment/construct validity study rather than an instructional context aimed at improving writing competence through LLM use.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing quality is analyzed, the study does not describe an experimental or quasi-experimental intervention using LLMs with pre/post or comparative outcome measures. It focuses on construct exploration and scoring validity, not on quantifying the effectiveness of an LLM-mediated writing intervention.""
    }
}"
821,Feeding Two Birds with One Scone: Using Awe to Enhance Writing and Creativity among Pre-university Students,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as “eleven CEFR B1 second language learners” in “English language writing instructions,” indicating L2 English learners in an EFL/ESL-type context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses an Automated Writing Evaluation (AWE) tool based on NLP to generate feedback. There is no indication that this is a large language model (e.g., ChatGPT/GPT-4 or similar transformer-based generative model); it is framed as standard AWE, which falls outside the LLM-focused scope.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly focuses on “English language writing instructions” and aims “to improve writing proficiency and creative performance,” aligning with writing competence as a primary focus.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pre- and post-tests for writing and creativity, reporting “improvements in writing and creativity scores,” which are quantifiable outcome measures of the intervention.""
    }
}"
822,The Combination of Recognition Technology and Artificial Intelligence for Questioning and Clarification Mechanisms to Facilitate Meaningful Efl Writing in Authentic Contexts,2023,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL learners, indicating L2 English learners in an EFL context. The focus is on EFL writing, so the target language is English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses an app (UEnglish) with Image-to-Text Recognition and “generative-AI that can generate meaningful questions and clarifications.” However, the abstract does not specify whether this generative AI is a large language model (e.g., transformer-based LLM like ChatGPT/GPT-4) or another type of AI. Without this detail, it is unclear if it meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is a Smart Questioning-Answering-Clarification mechanism designed “to help EFL writing” and to enable learners to “write more meaningful words in the assignments.” The primary focus is on facilitating EFL writing in authentic contexts, not on automated scoring or system evaluation alone.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is a five-week quasi-experiment with experimental and control groups, reporting significant differences in learning behaviors, post-test results, and that the experimental group “could write more meaningful words in the assignments.” These indicate quantifiable writing-related outcome measures.""
    }
}"
823,Rating Short L2 Essays on the Cefr Scale with Gpt-4,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract specifies that the essays are written by L2 English learners on a high-stakes language assessment, so the population clearly consists of L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""GPT-3.5 and GPT-4 are used as automated raters of essays, not as part of an instructional or intervention design for writing. There is no experimental or quasi-experimental integration of LLMs into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automated essay scoring reliability (inter-rater agreement with human ratings) and comparison with AWE methods. This is an assessment/measurement study, not a pedagogical writing intervention targeting writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports agreement between GPT ratings and human ratings, but not outcomes of an LLM-mediated writing intervention (no pre/post writing performance or instructional effect). It evaluates scoring performance, not changes in learners’ writing.""
    }
}"
824,The Impact of Automated Writing Evaluation on Second Language Writing Skills of Chinese Efl Learners: a Randomized Controlled Trial,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 190 Chinese EFL students, clearly identifying them as L2 English learners in an EFL context, with outcomes measured via an IELTS writing test in English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is Automated Writing Evaluation (AWE) using Grammarly. Grammarly is described as an AI-driven AWE program, but it is not a large language model-based generative tool like ChatGPT, GPT-4, or similar LLMs. The focus is on AWE feedback, not LLM-mediated writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on improving L2 writing competence (task achievement, coherence and cohesion, lexicon, grammatical accuracy) through AWE training, which is directly related to writing skills rather than essay scoring research alone.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The randomized controlled trial reports quantifiable writing outcomes, including performance on IELTS writing tasks across multiple dimensions (task achievement, coherence and cohesion, lexicon, grammatical accuracy), comparing experimental and control groups.""
    }
}"
825,Sentence-level Feedback Generation for English Language Learners: Does Data Augmentation Help?,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions ‘English language learners’ as the target of feedback comments, but it does not specify whether any human L2 English learners participated in an instructional study or whether this is purely a system-development task using existing corpora.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on building and evaluating LLM-based systems for feedback comment generation and data augmentation, not on an experimental or quasi-experimental pedagogical intervention where L2 learners use LLMs in their writing process.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the NLP task of feedback comment generation and system performance, not on learners’ writing competence or a teaching/learning context. There is no indication of an instructional setting or writing intervention with learners.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports system performance and analysis of generated comments, but does not mention any quantifiable writing outcomes for L2 learners (e.g., changes in writing quality, accuracy, or complexity) resulting from an LLM-mediated intervention.""
    }
}"
826,Exploring the Capabilities of Chatgpt for Lexicographical Purposes: a Comparison with Oxford Advanced Learner’s Dictionary within the Microstructural Framework,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any participants or learners being studied. It is a tool-focused comparison between ChatGPT and the Oxford Advanced Learner’s Dictionary, not an empirical study with L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is examined, it is not integrated into an instructional intervention or experimental/quasi-experimental design involving learners. The study compares lexicographical data between ChatGPT and a dictionary, not an LLM-mediated teaching or writing process.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on lexicographical microstructure and dictionary content quality, not on writing competence or writing-related variables. There is no mention of writing instruction, writing tasks, or writing performance.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcomes are reported. The metrics used (BLEU, ROUGE, percentage presence of lexicographical items) assess similarity of lexicographical content, not changes in learners’ writing performance or related outcomes.""
    }
}"
827,An Impact of Artificial Intelligence Tools on Technical Students’ Esl Oral Communication Skills-a Study,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are technical engineering students in India learning English as a Second Language (ESL), which fits the target population of L2 English learners in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses unspecified ‘Artificial Intelligence based mobile applications.’ There is no indication these are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative tools; they could be generic AI language-learning apps. Thus it does not clearly meet the LLM requirement.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on oral communication skills (speaking accuracy and fluency), not writing competence or writing-related variables. Writing is only mentioned in the conclusion as a future recommendation, not as the focus of the intervention or outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports quantifiable outcomes (pre-post speaking test scores) but these are for oral communication, not writing outcomes. No writing-related metrics are reported.""
    }
}"
828,The Impact of Ai Writing Tools on the Content and Organization of Students’ Writing: Efl Teachers’ Perspective,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students in Indonesian universities, as reported via their EFL teachers’ perspectives. The context is clearly English as a Foreign Language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although several AI writing tools are mentioned (Quillbot, WordTune, Jenni, ChatGPT, Paperpal, Copy.ai, Essay Writer), the study is purely descriptive/qualitative and does not implement an experimental or quasi-experimental LLM-based writing intervention. It explores tools in use but does not test a structured LLM-mediated instructional treatment.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on the impact of AI writing tools on students’ writing, specifically content and organization, which are core writing competence variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a qualitative case study design with semi-structured interviews and reports teachers’ perceptions. It does not report quantifiable writing outcome metrics or experimental measures of writing performance; outcomes are purely perceptual/qualitative.""
    }
}"
829,The Use of Artificial Intelligence to Improve the Scientific Writing of Non-native English Speakers,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The population is described broadly as “non-native English-speaking scientists,” not as L2 English learners in ESL/EFL/ELL instructional contexts. The focus is on researchers’ scientific writing, not on language learners in educational settings.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a non-systematic narrative review of AI tools (Elicit, ResearchRabbit, Scispace Copilot, Grammarly, Paperpal, ChatGPT). It does not report an experimental or quasi-experimental intervention integrating LLMs into instruction; it only describes potential uses.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the topic is scientific writing, the paper is a narrative review of tools and their possible functions, not an empirical pedagogical intervention or study focused on writing competence outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental results are reported. The article discusses potential benefits qualitatively as a narrative review, without structured intervention outcomes.""
    }
}"
830,"17th Linguistic Annotation Workshop, Law 2023 @ Acl 2023 - Proceedings of the Workshop",2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a proceedings volume from the 17th Linguistic Annotation Workshop containing 26 papers on various annotation and NLP topics. The abstract does not indicate any focus on L2 English learners in ESL/EFL/ELL contexts; instead, it covers diverse linguistic and computational annotation issues (e.g., Byzantine Greek marginal writing, German narratives, Italian case law, hate speech labelling).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although one paper mentions ‘fine-tuned LLMs suggestions’ for extending an event-type ontology, this is in the context of ontology extension and annotation, not an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or writing processes for learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus of the proceedings is linguistic annotation and NLP (e.g., event annotation, error detection in conversational agents, privacy-preserving text rewriting), not writing competence or writing-related pedagogy. There is no indication of an educational writing context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or structured LLM-mediated writing interventions are described. The work concerns datasets, annotation procedures, and NLP methods rather than measuring changes in learners’ writing performance.""
    }
}"
831,Chatback: Investigating Strategies of Providing Synchronous Grammatical Error Feedback in a Gui-based Language Learning Social Chatbot,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “second-language learners” and “language-learning tools” but does not specify that the target language is English or that the context is ESL/EFL/ELL. The target L2 and context remain unspecified.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates a GUI-based language-learning social chatbot providing synchronous grammatical error feedback. It is not identified as an LLM-based system (e.g., ChatGPT, GPT-4) and appears to be a feedback-delivery chatbot rather than a transformer-based generative LLM intervention in writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on synchronous grammatical corrective feedback in conversational chatbot interactions and learners’ “learning experiences and intention to use the system.” While online writing tasks are mentioned in background, the primary context is not clearly an L2 writing competence intervention but rather general language learning and feedback delivery.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported concern learning experience and intention to use the system. The abstract does not indicate any quantifiable writing performance metrics or writing-related outcome measures; it focuses on user experience rather than measured changes in writing ability.""
    }
}"
832,Using Ai-based Detectors to Control Ai-assisted Plagiarism in Esl Writing: the Terminator Versus the Machines,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is ESL composition and AI-assisted plagiarism in ESL writing, implying participants or data are from ESL writers (L2 English learners).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines RoBERTa-based AI detectors used to identify ChatGPT-generated texts. These are classifiers, not LLMs integrated into writing instruction or writing processes as an intervention. There is no experimental or quasi-experimental pedagogical use of LLMs.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on detecting AI-assisted plagiarism and evaluating detector performance, not on improving writing competence or writing-related learning outcomes through instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports detection accuracy of classifiers on human vs. AI-generated essays, not quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) resulting from an LLM-mediated writing intervention.""
    }
}"
833,Analyzing Bias in Large Language Model Solutions for Assisted Writing Feedback Tools: Lessons from the Feedback Prize Competition Series,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions English Language Learner status as a demographic factor, the study does not focus on L2 English learners as participants in an instructional context; instead, it analyzes model performance across demographic groups within an existing dataset.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study analyzes winning LLM-based solutions used for evaluating student writing in a competition. There is no experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or writing processes; it is an evaluation of model bias and performance.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on bias and performance of LLM-based Assisted Writing Feedback Tools as evaluators (identifying discourse elements and predicting discourse effectiveness), not on improving learners’ writing competence through instructional use of LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are model performance accuracy and bias across demographic groups, not quantifiable writing outcomes for learners following an LLM-mediated writing intervention.""
    }
}"
834,Investigating Efl Students' Writing Skills through Artificial Intelligence: Wordtune Application as a Tool,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Saudi English as a Foreign Language (EFL) students, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Wordtune (and mentions Grammarly) as AI-powered writing technologies. The abstract does not indicate that these tools are large language model–based (e.g., ChatGPT/GPT-4-type transformer generative models). Wordtune is primarily a rewriting/augmentation tool and is not clearly framed here as an LLM-based generative system, so it does not meet the specified LLM intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly investigates whether and to what extent Wordtune facilitates Saudi students' writing, focusing on writing quality, lexical gains, and syntactic gains—clearly a writing competence intervention context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental design with control and experimental groups, pretests and post-tests, and reports quantitative outcomes (students in the experimental group outperformed the control group in the final writing exam) as well as rated writing samples, providing quantifiable writing outcome metrics.""
    }
}"
835,Engaging Efl Students’ Critical Thinking Tendency and In-depth Reflection in Technology-based Writing Contexts: a Peer Assessment-incorporated Automatic Evaluation Approach,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are clearly described as university EFL (English as a Foreign Language) writing students, so the population consists of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is an automatic writing evaluation (AWE) system combined with peer assessment. The abstract does not indicate that the AWE tool is a large language model (e.g., ChatGPT, GPT-4) or transformer-based generative model; it appears to be a conventional AWE system. Therefore, it does not meet the requirement of integrating LLMs into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on EFL writing instruction and writing performance, as well as related variables such as motivation, critical thinking, and writing anxiety, within a technology-based writing context. The primary context is writing competence and writing-related outcomes.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The quasi-experiment compares an experimental PA-AWE group with a control C-AWE group and reports quantifiable outcomes: EFL writing performance, learning motivation, critical thinking, and writing anxiety. Thus, it includes measurable writing-related outcome metrics.""
    }
}"
836,Artificial Intelligence in Global World: a Case Study of Grammarly as E-tool on Esl Learners’ Writing of Darul Uloom Nadwa,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Madrasa ESL learners in India (Alimiyat grade), explicitly described as English as a Second Language (ESL) students, with outcomes focused on English writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Grammarly as an electronic tool. Grammarly is a grammar-checking and writing support tool that is not based on a large language model in the sense required (e.g., ChatGPT, GPT-4, Gemini). The abstract does not indicate use of an LLM-based generative model, but rather a conventional error-correction tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on improving ESL learners’ writing, specifically minimizing inflectional morpheme errors, and compares Grammarly-based instruction with communicative language teaching. This is clearly a writing competence intervention.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quantitative design with pre- and post-tests and reports results from a repeated-measures two-way ANOVA showing Grammarly enhanced writing accuracy in inflectional morphemes, providing quantifiable writing outcome metrics.""
    }
}"
837,Understanding English as a Foreign Language Students’ Idea Generation Strategies for Creative Writing with Natural Language Generation Tools,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as English as a foreign language (EFL) students in Hong Kong secondary schools, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “natural language generation (NLG) tools” but does not specify whether these are large language model–based systems (e.g., ChatGPT, GPT-4) or other AI/NLG tools. However, even if they were LLMs, the study design focuses on workshops and reflections rather than an experimental or quasi-experimental intervention measuring effects.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is creative writing: students attend workshops to learn to write stories using their own words and words generated by NLG tools. The focus is on writing processes (idea generation for creative writing), which aligns with writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are based on thematic analysis of students’ written reflections about their experience and strategies. The abstract does not report any quantifiable writing outcome metrics (e.g., writing scores, quality ratings, measurable gains). It is a qualitative exploration of strategies and concerns, not an experimental measure of intervention effectiveness.""
    }
}"
838,Exploring the Role of Artificial Intelligence in Facilitating Assessment of Writing Performance in Second Language Learning,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are students in a Chinese language learning program in the US, and the LLMs assess writing accuracy in Chinese. The focus is on Chinese as the target language, not English L2 learners or English writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses GPT-4, GPT-3.5, iFLYTEK, and Baidu Cloud as automated raters to assess writing accuracy, not as part of an instructional or quasi-experimental writing intervention. There is no integration of LLMs into teaching or learners’ writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the functionality and robustness of LLMs for automated assessment of writing accuracy, comparing them to human ratings. There is no pedagogical context or intervention aimed at improving writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports performance metrics of LLMs (e.g., accuracy, precision) as raters, not quantifiable outcomes of learners’ writing development following an LLM-mediated intervention. No experimental learning outcomes are described.""
    }
}"
839,Interaction Patterns between Learners and Ai Tools for English Writing,2023,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL (English as a foreign language) learners, specifically 29 EFL undergraduates, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to an unspecified 'AI tool for English writing' but does not indicate whether it is a large language model (e.g., ChatGPT/GPT-based) or a non-LLM tool (e.g., grammar checker). Without identifying the AI as LLM-based, it is unclear if it meets the LLM intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly English writing: the study examines how EFL learners interact with an AI tool for English writing and how interaction patterns affect writing performance, which aligns with a focus on writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract notes that the study 'explores the effects of different interaction patterns on their writing performance' and that comparisons among clusters show varied benefits, implying quantitative writing performance outcomes were measured.""
    }
}"
840,Empowering Language Learners: Harnessing Computer-based Writing for Enhanced Chinese Language Proficiency,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are Chinese Language (CL) learners in Singapore, focusing on Chinese language proficiency and Chinese writing, not L2 English learners or English writing outcomes. The abstract explicitly centers on CL classes and CBW for Chinese, so the population/target language does not match the review’s focus on English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention is computer-based writing (CBW) versus paper-and-pen writing, not clearly an LLM-based tool. Generative AI is only mentioned in a proposed future platform (WeeWrite), not as part of the implemented and evaluated intervention. It is unclear whether any LLM was actually integrated into the studied intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence (writing quality, performance) in Chinese, comparing CBW and PPBW and examining factors like typing and handwriting speed and writing strategies. This aligns with a writing-focused context, though not in English.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes, comparing post-CBW and post-PPBW scores and analyzing effects across achievement levels using mixed-effects modeling. Thus, it includes measurable writing outcome metrics, albeit for Chinese rather than English.""
    }
}"
841,Exploring the Potential of Chatgpt in Assessing L2 Writing Accuracy for Research Purposes,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions '100 L2 essays across five proficiency levels' but does not specify that these are L2 English learners or the language of the essays. It is therefore unclear whether the population is L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT-4 is used to measure linguistic accuracy and detect errors in existing L2 essays. There is no experimental or quasi-experimental design integrating ChatGPT into writing instruction or learners’ writing processes; it is an evaluation of ChatGPT as an assessment tool.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on ChatGPT’s performance in error detection (assessment/measurement) rather than on improving writing competence through pedagogical intervention. It evaluates ChatGPT as an automated error-detection system, not as part of a teaching or learning activity.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports precision, recall, and correlations between ChatGPT and human coding for error detection, but does not report any writing outcome metrics resulting from an LLM-mediated intervention. There is no pre/post or comparative measure of learners’ writing development.""
    }
}"
842,Using Ai-based Detectors to Control Ai-assisted Plagiarism in Esl Writing: “the Terminator Versus the Machines”,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is ESL composition and AI-assisted plagiarism in ESL writing, implying involvement of L2 English learners in ESL settings.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a descriptive evaluation of RoBERTa-based AI detectors on a dataset of human-written and ChatGPT-generated essays. There is no experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or processes; ChatGPT is only a text source, not an instructional tool.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on controlling AI-assisted plagiarism and assessing the performance of AI-based detectors, not on improving writing competence or writing-related learning outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) are reported. Outcomes relate to detection accuracy of classifiers, not to learners’ writing development under an LLM-mediated intervention.""
    }
}"
843,"A Triple Challenge: Students' Identification, Interpretation, and Use of Individualized Automated Feedback in Learning to Write English as a Foreign Language.",2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are eighth-grade students learning English as a foreign language, which fits the L2 English EFL context: “eighth-grade students' … writing skills in English as a foreign language.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses an “AI-based automated essay assessment tool (EAT)” that provides automatic feedback. The abstract does not indicate that this tool is a large language model (e.g., ChatGPT/GPT-style generative transformer). It is framed as an automated essay assessment system, which typically relies on scoring/feedback algorithms rather than LLM-based generative models.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on developing “writing skills in English as a foreign language” using automated feedback on essays, with analysis of revisions and writing trajectories. This is clearly a writing competence intervention rather than pure scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines “improvements made on the essay based on the feedback logs … and the different versions of the essay … using frequency analyses,” indicating quantifiable writing outcome measures related to revisions and skill development.""
    }
}"
844,From Process to Product: Writing Engagement and Performance of Efl Learners under Computer-generated Feedback Instruction,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 42 English as a foreign language (EFL) learners, clearly indicating L2 English learners in an EFL context, with outcomes focused on English writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Pigai, described as a Chinese automated writing evaluation (AWE) system. Pigai is a traditional AWE tool, not specified as a large language model (e.g., ChatGPT, GPT-4, Gemini) or transformer-based generative model. Thus it does not meet the LLM-based intervention requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on revision processes and writing products, analyzing feedback uptake and text quality in complexity, accuracy, and fluency (CAF), which are core writing-related variables in an instructional context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantifiable writing outcome metrics are reported, including CAF measures (complexity, accuracy, fluency) and effects of automated feedback on accuracy and lexical complexity, along with engagement dimensions.""
    }
}"
845,"Artificial Intelligence in Language Instruction: Impact on English Learning Achievement, L2 Motivation, and Self-regulated Learning",2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as English as a Foreign Language (EFL) university students, and outcomes are explicitly English learning achievement (grammar, vocabulary, reading, writing), so the population is L2 English learners.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers only to an unspecified “AI-mediated instruction” and “AI-powered platforms/AI-driven educational technologies.” It does not indicate that a large language model (e.g., ChatGPT, GPT-4, Gemini) or any transformer-based generative model was used, nor does it describe generative interaction with an LLM. The AI could be any form of educational technology.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is overall English learning achievement (grammar, vocabulary, reading comprehension, and writing skills) plus L2 motivation and self-regulated learning. Writing is only one subcomponent among several skills, and there is no indication that the intervention specifically targets writing instruction or writing processes as the main focus.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study reports pre/post English learning achievement including writing skills, but it is not clear whether distinct, quantifiable writing outcome metrics (e.g., writing quality scores, organization, accuracy) are analyzed separately, or whether writing is just part of a composite achievement test. Moreover, without confirmation that an LLM-based writing intervention is involved, this criterion cannot be confidently applied.""
    }
}"
846,Local Similarity and Global Variability Characterize the Semantic Space of Human Languages,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study uses TOEFL essays written by 38,500 speakers from various native languages, the focus is on semantic space and cross-linguistic meaning variability, not on L2 English learners in an instructional ESL/EFL/ELL context. Participants are data sources for semantic analysis rather than learners in an educational intervention.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Large language models are used as analytical tools to characterize semantic variability across languages, not as an instructional intervention integrated into writing instruction or writing processes. There is no experimental or quasi-experimental design involving LLM-mediated pedagogy.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on semantic space, meaning variability, and cross-linguistic comparisons, not on writing competence or writing-related pedagogical variables. TOEFL essays are used to model semantics, not to improve or assess writing through an intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study does not report quantifiable writing outcome metrics related to an LLM-mediated writing intervention. Outcomes concern variability in semantic representations, not changes in writing performance or related skills following an instructional treatment.""
    }
}"
847,Bibliometrically and Systematically Analyzing Automated Writing Evaluation for English Learning,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract concerns automated writing evaluation for learning English as a second language, implying L2 English learners, but it does not specify participant characteristics or contexts, as it is a secondary study (bibliometric + systematic review).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a bibliometric analysis and systematic review of automated writing evaluation tools, not an experimental or quasi-experimental primary study integrating a specific LLM (e.g., ChatGPT, GPT-4) into instruction. It is a secondary review article, which is excluded by the protocol.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the topic is writing-related (automated writing evaluation), the paper is not a primary pedagogical intervention study but a bibliometric and systematic overview of prior work, which falls under excluded article types (review/overview).""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study does not report original, quantifiable writing outcome metrics from an intervention; instead, it synthesizes findings from 56 peer-reviewed articles. As a review, it lacks its own experimental outcome measures.""
    }
}"
848,Enhancing Academic Writing Skills and Motivation: Assessing the Efficacy of Chatgpt in Ai-assisted Language Learning for Efl Students,2023,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese English as a Foreign Language (EFL) students. The abstract explicitly states the focus is on their English writing skills and motivation, fitting ESL/EFL/ELL L2 English learner contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is AI-assisted instruction via ChatGPT, a large language model. The design is experimental: 50 EFL students are randomly assigned to an experimental (ChatGPT) or control (traditional instruction) group, satisfying the requirement for an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence and writing-related variables: the study evaluates the impact on students’ writing skills (organization, coherence, grammar, vocabulary) and writing motivation. ChatGPT is used pedagogically, not merely as an automated scoring tool.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a pre-test/post-test design with writing samples evaluated using established scoring rubrics, and reports significant improvements in writing skills and motivation in the experimental group. These are quantifiable writing outcome metrics aligned with the review’s criteria.""
    }
}"
849,"A Triple Challenge: Students’ Identification, Interpretation, and Use of Individualized Automated Feedback in Learning to Write English as a Foreign Language",2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are eighth-grade students learning English as a foreign language, which fits L2 English learners in an EFL context: “eighth-grade students’ … writing skills in English as a foreign language.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses an “AI-based automated essay assessment tool (EAT)” that provides automatic feedback. There is no indication that this tool is a large language model (e.g., ChatGPT/GPT-style transformer-based generative model); it is framed as automated essay assessment, which typically predates LLMs. Thus it does not clearly meet the requirement of integrating LLMs into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on writing competence: “assessment literacy and writing skills in English as a foreign language,” with students writing essays, receiving feedback, and revising. This aligns with a writing-focused pedagogical context rather than pure scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines “improvements made on the essay based on the feedback logs… and the different versions of the essay… using frequency analyses,” indicating quantifiable writing outcome metrics related to revisions and improvements.""
    }
}"
850,Second Language Learners’ Post-editing Strategies for Machine Translation Errors,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract refers to 'second language (L2) learners' but does not specify that they are L2 English learners or that the writing is in English. The context (University of Hawaii at Manoa) suggests a possible English context, but the target language is not explicitly stated, so it does not clearly meet the requirement of focusing on English as the L2.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses Google Translate, described as a neural machine translator, as the AI tool. This is a machine translation system, not an LLM-based generative model like ChatGPT or GPT-4, and the focus is on post-editing MT output rather than integrating an LLM into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is L2 writing: learners use machine translation to address lexical and grammatical problems during L2 writing, and the study analyzes MT errors and post-editing strategies, which are clearly writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes: the 'successfulness of PE was gauged by comparing sentence adequacy scores of the MT output and PEd texts,' providing measurable writing-related performance data.""
    }
}"
851,Engineering Chatgpt Prompts for Efl Writing Classes,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers generally to 'EFL education' and 'student writing' but does not specify that the study involves actual L2 English learners as participants with collected data, or whether it is a conceptual/practical article without participants.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is described as demonstrating 'effective prompts for writing classes' and discussing ChatGPT as a feedback tool. There is no indication of an experimental or quasi-experimental design, nor of a structured intervention study; it appears to be a practical or conceptual piece on prompt engineering.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""While the focus is on EFL writing classes and feedback on student writing, the abstract does not clearly state that the paper empirically investigates writing competence or related variables; it seems more oriented toward illustrating prompt design.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or assessment of effectiveness. It only states that the article will demonstrate effective prompts, with no reference to measured changes in writing performance.""
    }
}"
852,Exploring the Effects of Grammarly on Efl Students’ Foreign Language Anxiety and Learner Autonomy,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students in academic writing courses at a Japanese university, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Grammarly, described as an automated writing evaluation (AWE) tool. Grammarly is not an LLM-based, transformer generative model like ChatGPT or GPT-4; it is explicitly listed as an exclusionary tool in the review criteria.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is English academic writing courses, and Grammarly is used while editing English writing. The study is situated in L2 writing instruction, even though the primary outcomes are affective (anxiety, autonomy).""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study measures foreign language anxiety and learner autonomy via pre- and post-surveys. It does not report quantifiable writing performance outcomes; writing is the context, not the measured outcome variable.""
    }
}"
853,"2023 Ieee 15th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management, Hnicem 2023",2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The record is for a conference proceedings volume (HNICEM 2023) containing 263 papers. One listed paper mentions “utilization of artificial intelligence in academic writing class: L2 learners perspective,” but no details are provided about participants or whether they are L2 English learners. The proceedings-level abstract does not specify language, learner type, or context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The proceedings abstract only notes a paper on “utilization of artificial intelligence in academic writing class” without specifying that the AI is an LLM (e.g., ChatGPT, GPT-4). It could involve non-LLM tools. At the proceedings level, there is no clear evidence of an LLM-based experimental or quasi-experimental writing intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""One paper title suggests a focus on academic writing and L2 learners, but the proceedings abstract does not clarify whether the primary focus is on writing competence or writing-related variables, nor does it describe any pedagogical intervention. The volume overall covers many unrelated technical topics.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported in the proceedings abstract. It only lists paper titles, including one about AI in academic writing, without indicating whether that study includes experimental measures of writing performance.""
    }
}"
854,Fusion Weighted Features and Bilstm-attention Model for Argument Mining of Efl Writing,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions a corpus of 180 argumentative essays, but does not specify that the writers are L2 English learners (ESL/EFL/ELL). The context could be EFL, but this is not stated explicitly.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses BERT and a BiLSTM-attention model for argument mining. These are NLP models for automated annotation, not LLMs integrated into writing instruction or learners’ writing processes. There is no pedagogical intervention involving tools like ChatGPT or GPT-4.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on developing an argument mining model and improving automatic annotation for potential use in automated scoring. It does not describe an instructional context or intervention aimed at improving learners’ writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are model performance metrics (e.g., 69% precision in automatic annotation), not quantifiable changes in learners’ writing performance following an LLM-mediated intervention.""
    }
}"
855,"Navigating the Impact of Chatgpt/gpt4 on Legal Academic Examinations: Challenges, Opportunities and Recommendations",2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract refers broadly to “students and researchers” and “non-native English speakers in academic research” in higher education, without specifying L2 English learners in ESL/EFL/ELL contexts or focusing on English as the target language in a language-learning sense. The population is general higher education, not clearly L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper is a conceptual/discussion piece about the impact of ChatGPT/GPT-4 on academic paper writing, plagiarism, and ethics. It does not describe an experimental or quasi-experimental intervention integrating LLMs into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on academic integrity, plagiarism detection, ethical use, and institutional guidelines, not on a pedagogical intervention targeting writing competence or writing-related learning outcomes. It is a policy/ethics discussion rather than a writing instruction study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantitative writing outcome measures or experimental results are reported. The article proposes strategies and discusses challenges and opportunities but does not present empirical data on writing performance or related variables.""
    }
}"
856,Teachers’ Reflections on Academic Dishonesty in Efl Students’ Writings in the Era of Artificial Intelligence,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The participants in the study are 67 teachers, not L2 English learners. Although the context involves EFL students’ writings, the data and analysis focus on teachers’ perceptions rather than on L2 learners as the primary participants.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study explores teachers’ perceptions of academic dishonesty in the era of AI and mentions AI technologies generally, but it does not describe an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is academic dishonesty, ethical implications, and teachers’ roles in detecting AI-generated assignments, not on improving writing competence or writing-related pedagogical interventions using LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study relies on questionnaires and interviews about perceptions and ethics, without measuring changes in students’ writing performance following an LLM-mediated intervention.""
    }
}"
857,Chatgpt's Capabilities in Spotting and Analyzing Writing Errors Experienced by Efl Learners,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states that the study investigates ChatGPT in detecting English as a foreign language (EFL) learners' writing errors, indicating an EFL (L2 English) population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares ChatGPT’s error detection with human instructors to evaluate its capabilities. There is no indication of an experimental or quasi-experimental pedagogical intervention where ChatGPT is integrated into writing instruction or learners’ writing processes; it is a tool evaluation, not an instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on ChatGPT’s ability to spot and analyze writing errors (i.e., error detection performance and reliability), akin to evaluating an automated feedback/grading system. There is no description of a teaching/learning context or structured writing intervention aimed at improving learners’ writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are metrics like F-score and p-value assessing ChatGPT’s error detection accuracy, not quantifiable changes in learners’ writing performance following an LLM-mediated intervention. No pre/post or comparative writing outcome measures for learners are mentioned.""
    }
}"
858,Improving Logical Flow in English-as-a-foreign-language Learner Essays by Reordering Sentences,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The corpus ICNALE-AS2R consists of essays written by English-as-a-foreign-language learners from various Asian countries, clearly indicating an EFL (L2 English) population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study proposes a computational sentence reordering system trained on an EFL learner corpus, but it is presented as an NLP/AI method for automatic reordering, not as an LLM-based (e.g., ChatGPT, GPT-4) pedagogical intervention or classroom tool. There is no indication that a large language model is used, nor that learners interact with the system in an instructional experiment.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on developing and evaluating an automatic sentence reordering system (discourse-level text processing) using metrics like longest common subsequence ratio and Kendall’s Tau. It does not describe an instructional context or writing intervention aimed at improving learners’ writing competence; rather, it is a text-processing/algorithmic study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are system performance metrics (LCS ratio, Kendall’s Tau) on reconstructing reordered essays, not quantifiable changes in learner writing performance following an intervention. No experimental or quasi-experimental measures of learner writing outcomes are described.""
    }
}"
859,Second Language Learners' Post-editing Strategies for Machine Translation Errors,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study involves 57 second language (L2) learners using Google Translate during L2 writing. Although the target language is not explicitly stated as English, the general L2 context and focus on L2 writing fit the broad L2 learner population criterion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention centers on Google Translate, a neural machine translation (NMT) system, not on a large language model (LLM) such as ChatGPT, GPT-4, or similar transformer-based generative models used interactively for writing instruction. The study analyzes post-editing of MT output rather than an LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly L2 writing: learners use MT to address lexical and grammatical problems during L2 writing, and the study examines post-editing strategies and writing-related competence in the ‘AI era’.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes: sentence adequacy scores comparing MT output and post-edited texts, and examines how proficiency affects successful post-editing. These are measurable writing-related outcomes.""
    }
}"
860,The Impact of Artificial Intelligence in Foreign Language Learning Using Learning Management Systems: a Systematic Literature Review,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract focuses on English as a foreign language and discusses students and teachers in EFL contexts using AI via learning management systems. Thus, the population is L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a systematic literature review of AI in foreign language learning via LMSs over 2011–2021. It does not describe a primary experimental or quasi-experimental intervention using a specific LLM (e.g., ChatGPT, GPT-4). It is a secondary review article, which is explicitly excluded.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The review addresses multiple language skills (reading, writing, speaking, listening) broadly. Writing is only one of several skills and not the primary focus of a specific pedagogical intervention; the context is general language learning with AI in LMSs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic literature review, it does not report original, quantifiable writing outcome metrics from an LLM-mediated intervention conducted by the authors. It synthesizes prior work and focuses on perceived benefits rather than presenting new experimental writing outcomes.""
    }
}"
861,The Application of Chatbot as an L2 Writing Practice Tool,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 75 Korean elementary school students engaged in English L2 writing practice, clearly an EFL/ESL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention used a chatbot developed with Google’s Dialogflow by encoding expressions from an elementary school English textbook. This is a rule/intent-based chatbot platform, not a transformer-based large language model such as ChatGPT, GPT-4, Gemini, etc. Thus, it does not meet the requirement of integrating an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly focuses on chatbot-based L2 writing practice and compares it with traditional teacher-led writing instruction, with the primary outcome being writing performance.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports pretest and posttest writing performance scores and compares experimental and control groups, providing quantifiable writing outcome metrics. It also includes a survey, but the quantitative writing scores satisfy C4.""
    }
}"
862,Academic Integrity Considerations of Ai Large Language Models in the Post-pandemic Era: Chatgpt and beyond,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions 'supporting EFL learners' as one of several potential uses of LLMs, but the paper is framed broadly around students and higher education institutions, not a defined population of L2 English learners in ESL/EFL/ELL contexts. No specific participant group is described.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a conceptual/position paper on academic integrity issues related to student use of LLMs such as ChatGPT. It discusses potential ways LLMs can support education and writing, but does not describe an experimental or quasi-experimental intervention integrating LLMs into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""While writing and composition are mentioned, the primary focus is academic integrity, plagiarism detection, and institutional policy, not a pedagogical context aimed at improving writing competence or writing-related variables through an intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantitative writing outcome measures or structured intervention results. It is an analytical discussion of issues and implications, not an empirical evaluation of LLM-mediated writing outcomes.""
    }
}"
863,A Systematic Review on Artificial Intelligence Dialogue Systems for Enhancing English as Foreign Language Students’ Interactional Competence in the University,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The population of interest throughout the article is English as a Foreign Language (EFL) university students, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a systematic review of various AI dialogue systems rather than an experimental or quasi-experimental primary study integrating a specific LLM (e.g., ChatGPT, GPT-4) into writing instruction. It does not report on a concrete LLM-based intervention designed and tested by the authors.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on interactional competence and broader EFL learning (including reading, writing, listening) using AI dialogue systems. Writing is mentioned only generally; the review centers on interactional competence dimensions, not specifically on writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic review, it does not itself report original, quantifiable writing outcome metrics from an LLM-mediated writing intervention. It synthesizes prior work on interactional competence and AI dialogue systems without presenting new experimental writing outcome data.""
    }
}"
864,Utilizing Artificial Intelligence Technologies in Saudi Efl Tertiary Level Classrooms,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are in Saudi EFL tertiary-level classrooms, i.e., English as a Foreign Language learners in Saudi Arabia. The abstract explicitly refers to EFL and English language learning (ELT), indicating L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines general AI technologies (Google Translate, Bing Translator, Wordtune, MT, AESs) and CALL tools. These are not clearly described as transformer-based large language models, and there is no indication of an experimental or quasi-experimental LLM-integrated writing intervention. The design is exploratory and survey-based (questionnaires), not an LLM-mediated instructional experiment.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing is mentioned (e.g., Wordtune as a writing assistant, subjects of writing with AI technologies), but the primary focus appears to be broad AI use in EFL classrooms and ELT processes rather than a targeted writing competence intervention. The abstract does not clearly describe a structured writing-focused pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Data were collected via questionnaires and analyzed with SPSS, suggesting attitudinal or perception measures. The abstract does not report any quantifiable writing outcome metrics (e.g., writing scores, text quality measures) assessing the effectiveness of AI tools on writing performance.""
    }
}"
865,A Corpus-based Study of the Usage of Chinese Core Separable Words in the Use of Language,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are Chinese L2 learners and native Chinese speakers; the focus is on Chinese as a second language and International Chinese Language Education, not on L2 English learners or English language contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a corpus-based analysis using BCC, CCL, and HSK learner corpora. There is no mention of large language models, ChatGPT-like systems, or any AI-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on usage of Chinese core separable words and learner errors, not on writing competence in English or any L2 writing intervention context. It is descriptive corpus research, not a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No experimental or quasi-experimental intervention is described, and no quantifiable writing outcome metrics related to an LLM-mediated writing intervention are reported. The study analyzes corpus usage patterns and error types only.""
    }
}"
866,A Deep Fusion Model for Human Vs. Machine-generated Essay Classification,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract states that the datasets contain short essays in English and Spanish written by L2 learners. Thus, there is an L2 population and English is one of the target languages.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study proposes a deep neural network-based model for classifying essays as human vs. machine-generated. It does not describe an instructional intervention using LLMs (e.g., ChatGPT) in writing instruction or processes; LLMs are only the source of machine-generated texts to be classified.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is essay classification (human vs. machine-generated) for integrity and detection purposes, not on improving writing competence or writing-related pedagogical outcomes. This aligns more with automated detection than with writing instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) are reported. The outcomes are classification performance metrics, not measures of L2 writing development or intervention effectiveness.""
    }
}"
867,Efl Paraphrasing Skills with Quillbot: Unveiling Students' Enthusiasm and Insights,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as EFL (English as a foreign language) preparatory year students, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention tool is QuillBot. Based on the review’s criteria, tools like QuillBot are treated as AI writing aids that are not clearly positioned as transformer-based generative LLMs for instructional integration. The abstract does not indicate use of an LLM such as ChatGPT, GPT-4, Gemini, etc., but rather a paraphrasing tool, which falls under the exclusion note for non-LLM AI tools.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on paraphrasing skills within writing, including performance in synonyms, sentence structure, and word choice, and the context is a writing class. This aligns with a primary focus on writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports that students ‘improved their performance in synonyms, sentence structure, and word choice,’ implying quantifiable writing outcome measures in a quasi-experimental design, alongside attitudinal data.""
    }
}"
868,Comparing Measures of Syntactic and Lexical Complexity in Artificial Intelligence and L2 Human-generated Argumentative Essays,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are first-year Tswana L2 learners of English at a South African university, clearly an L2 English learner population in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT-3.5 is used only to generate comparison essays; there is no experimental or quasi-experimental instructional intervention integrating the LLM into learners’ writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on comparing syntactic and lexical complexity between AI- and human-generated essays, not on a pedagogical writing intervention or development of learners’ writing competence using LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported for an LLM-mediated intervention. The measures are used for corpus comparison, not to assess the effectiveness of an instructional treatment involving LLMs.""
    }
}"
869,The Use and Abuse of Artificial Intelligence-enabled Machine Translation in the Efl Classroom: an Exploratory Study,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners in higher education where English is not their first language, clearly fitting an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention centers on Google Translate as an AI-enabled machine translation tool. The abstract does not indicate that a large language model (LLM) or transformer-based generative model (e.g., ChatGPT, GPT-4) is used; it focuses on MT use, practices, and beliefs, not an LLM-based writing assistant.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study compares the quality of writing drafts created with and without Google Translate, indicating a primary focus on writing performance in an EFL classroom context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pre- and post-tests to compare the quality of writing drafts with and without MT, implying quantifiable writing outcome metrics are collected to assess the impact of the intervention.""
    }
}"
870,Work in Progress: Chatgpt as an Assistant in Paper Writing,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions “non-native English speakers,” which suggests L2 English users, but it does not specify ESL/EFL/ELL instructional contexts or participant characteristics. It is unclear whether there is a defined learner population or just a general discussion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as a discussion of the potential of ChatGPT as an assistant in paper writing. There is no indication of an experimental or quasi-experimental design, structured intervention, or empirical implementation of ChatGPT in instruction.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on “paper writing” in natural English, which is writing-related, but the abstract frames this as a conceptual discussion of ChatGPT’s potential and ethical use, not a pedagogical intervention study targeting writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or empirical assessment. It appears to be a conceptual or opinion piece about potential uses and ethical considerations, without reported intervention outcomes.""
    }
}"
871,A Deep Fusion Model for Human $vs$. Machine-generated Essay Classification,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract states that the datasets contain short essays in English and Spanish written by L2 learners. Thus, the population includes L2 English learners and English essay data.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study proposes a deep neural network-based model for classifying essays as human vs. machine-generated. It does not describe an instructional intervention using LLMs (e.g., ChatGPT) for teaching or supporting writing; instead, LLM-related content is only the target of classification.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on essay classification (human vs. machine-generated) and model performance, not on improving writing competence or writing-related pedagogical outcomes. There is no writing instruction or intervention context described.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) are reported. Outcomes are classification accuracy and model competitiveness, not learner writing gains or changes.""
    }
}"
872,A Syntactic Complexity Analysis of Revised Composition through Artificial Intelligence-based Question-answering Systems,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are college English learners taking the TEM-4 test, which is an English proficiency test for Chinese EFL learners. The focus is clearly on L2 English argumentative essay writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used to revise students’ essays, the design is a comparison between original student texts and ChatGPT-revised versions, not an experimental or quasi-experimental pedagogical intervention where learners interact with the LLM as part of instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on syntactic complexity differences between human-written and ChatGPT-revised texts. There is no described instructional context or structured writing intervention; rather, it is an analysis of AI-revised output as a potential reference, similar to a functionality or text-quality evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports syntactic complexity metrics comparing student essays and ChatGPT revisions, but there is no measurement of changes in learners’ own writing performance following an LLM-mediated intervention. No experimental outcome on learner writing development is reported.""
    }
}"
873,Intertextuality in Pre-service Teachers' Argumentative Essay in Raising Ai: Practices and Beliefs,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Indonesian EFL pre-service teachers, which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions essays 'assisted by AI' and 'in a rising AI era' but does not specify the use of large language models (e.g., ChatGPT, GPT-4) or any particular transformer-based generative system, nor does it describe an experimental or quasi-experimental intervention integrating such tools into instruction. It is framed as a case study of existing practices and beliefs rather than a structured LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on argumentative essay writing, specifically intertextuality practices in EFL pre-service teachers’ academic writing, which is clearly a writing-related construct.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a case study design with content analysis of essays and interviews to explore practices and beliefs. There is no indication of an experimental or quasi-experimental design with quantifiable writing outcome metrics to assess the effectiveness of an AI/LLM-mediated intervention; rather, it is descriptive/qualitative.""
    }
}"
874,Utilization of Artificial Intelligence in Academic Writing Class: L2 Learners Perspective,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on second language (L2) learners in the Philippines in academic writing classes, which fits ESL/EFL/ELL-type contexts with English as the implied target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a descriptive survey of perceptions and experiences regarding AI tools; there is no experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into instruction or writing processes. The type of AI (LLM vs other) is not specified, and no intervention is implemented.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is academic writing, the focus is on awareness, preferences, and concerns about AI use, not on a pedagogical intervention aimed at improving writing competence. It is attitudinal rather than an instructional or intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports survey-based perceptions only and does not provide quantifiable writing outcome metrics (e.g., writing scores, text quality measures) to assess the effectiveness of AI- or LLM-mediated writing interventions.""
    }
}"
875,Looks like Google to Me: Instructor Ability to Detect Machine Translation in L2 Spanish Writing,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are L2 learners of Spanish, not L2 English learners. The context is an intermediate-level Spanish writing course, so the target language is Spanish rather than English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on instructors’ ability to detect machine translation in student writing. It does not describe an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction; rather, it examines detection accuracy of MT use.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on detection of MT vs. non-MT texts and related instructor factors, not on a writing intervention aimed at improving writing competence through LLM use.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., changes in writing quality due to an LLM-mediated intervention) are reported. Outcomes concern detection accuracy and related variables, not intervention effects on writing.""
    }
}"
876,Impact of Chatgpt on Learners in a L2 Writing Practicum: an Exploratory Investigation,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract clearly states the context is an L2 writing practicum and refers to L2 writing learners, implying participants are second language learners. While the target language is not explicitly named as English, the L2 writing practicum context suggests L2 learners consistent with ESL/EFL/ELL-type settings.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study applies ChatGPT’s text generation feature in a one-week L2 writing practicum, indicating an intervention where an LLM (ChatGPT) is integrated into writing classrooms as part of instruction or practice.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly a ‘one-week L2 writing practicum’ and ‘writing classrooms,’ focusing on the impact of ChatGPT on L2 writing pedagogy and composing workflows, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as adopting a qualitative approach to investigate students’ behaviors and reflections, triangulating learning activities and reflective perceptions. There is no mention of quantitative or otherwise structured, quantifiable writing outcome metrics; the focus is on affordances, perceptions, and concerns rather than measured changes in writing performance.""
    }
}"
877,Roles and Research Foci of Artificial Intelligence in Language Education: an Integrated Bibliographic Analysis and Systematic Review Approach,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a broad review of Artificial Intelligence in Language Education (AILEd) from 1990–2020 and does not specify that it focuses on L2 English learners in ESL/EFL/ELL contexts. It aggregates diverse language education studies without restricting to English L2 populations.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is an integrated bibliographic analysis and systematic review, not an experimental or quasi-experimental study implementing an LLM-based intervention. It surveys technologies such as ITS and NLP and AI algorithms (Statistical Learning, Data Mining, Machine Learning) rather than reporting on a specific LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the review notes that writing is one of the main application domains, its primary purpose is to map roles and research foci of AI in language education generally, not to implement or evaluate a concrete writing intervention. It is a secondary study, not a pedagogical trial focused on writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a review and does not report original, quantifiable writing outcome metrics from an LLM-mediated intervention. It synthesizes prior work and discusses learning outcomes in general terms, offering suggestions rather than presenting experimental measures of writing performance.""
    }
}"
878,Recipe: How to Integrate Chatgpt into Eflwriting Education,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 213 undergraduate and graduate students enrolled in EFL writing courses, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study presents RECIPE, a learning platform that integrates ChatGPT (a large language model) into EFL writing education, with ChatGPT taking an EFL teacher role and engaging in dialogue based on students’ self-written summaries.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL writing education, with a platform designed for revising essays and supporting EFL writing courses, so the primary focus is on writing-related learning.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports collection of interaction data, students’ perceptions and usage, user scenarios, and qualitative interviews. It does not mention any experimental or quasi-experimental design with quantifiable writing outcome measures (e.g., writing scores, quality ratings, accuracy gains). Outcomes are primarily perceptions and design opportunities, not measured writing improvement.""
    }
}"
879,Who Wrote This Essay? Detecting Ai-generated Writing in Second Language Education in Higher Education,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The participants are ESL lecturers, not L2 English learners. The study focuses on teachers’ ability to detect AI-generated texts, not on L2 learners’ development or performance.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT and AI detectors are mentioned, they are used as objects of detection and comparison, not as an instructional intervention or integrated tool in learners’ writing processes. There is no experimental or quasi-experimental LLM-based teaching intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is academic integrity and detection of AI-generated writing, along with lecturers’ assessment practices and policy implications. It does not examine writing competence or writing-related learning outcomes for L2 learners.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is qualitative and centers on lecturers’ evaluations and perceptions. It does not report quantifiable writing outcome metrics for L2 learners or measure the effectiveness of any LLM-mediated writing intervention.""
    }
}"
880,Assessing Second-language Academic Writing: Ai Vs. Human Raters,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are first-year college students producing L2 academic writing; the context is clearly second-language (L2) writing assessment, implying L2 English learners in an academic setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT-3.5 is used as an automated rater to score student paragraphs, not as part of an instructional or intervention design to support writing development. There is no experimental or quasi-experimental LLM-based teaching or feedback intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the assessment function of LLMs (ChatGPT vs. human raters) for rating L2 writing quality, not on improving writing competence or integrating LLMs into writing instruction or processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing scores are reported, they are used solely to compare rating reliability between ChatGPT and human raters. There is no LLM-mediated writing intervention whose effect on writing outcomes is evaluated.""
    }
}"
881,Large Language Model-based Artificial Intelligence in the Language Classroom: Practical Ideas for Teaching,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses language learning and language classrooms in general but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor does it indicate any empirical participant sample at all.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper is described as aiming to provide examples of how LLMs can be used for materials development, classroom activities, and feedback. There is no indication of an experimental or quasi-experimental study design or an implemented intervention with participants; it appears to be a conceptual/practical ideas paper.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""While writing-related uses (e.g., feedback, materials) may be included, the abstract frames the paper broadly around language learning and teaching, not specifically around writing competence or writing-related variables as the primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantitative outcome measures or assessment of writing performance. It focuses on providing examples and discussion, with no indication of measured intervention outcomes.""
    }
}"
882,"Perceptions of High School Students on Ai Chatbots Use in English Learning: Benefits, Concerns, and Ethical Consideration",2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are high school students using AI chatbots in English learning, which fits an EFL/ESL/ELL-type context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a perception survey about AI chatbot use; there is no experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into instruction as an intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on general English learning and perceptions of benefits, concerns, and ethics, not specifically on writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are students’ perceptions (frequency, means, t-test on attitudes). No quantifiable writing performance or writing-related outcome measures are reported.""
    }
}"
883,Analyzing Composition Complexity in Revised Versions through Artificial Intelligence-based Writing Assistants,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract refers to 'English learners’ writing practice' and 'university-level English essays', indicating L2 English learners in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is Grammarly, described as an 'AI-powered essay revision software'. Grammarly is not a large language model-based generative tool in the sense required (e.g., ChatGPT, GPT-4). The study examines automated corrections by Grammarly, not an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on writing complexity (lexical and syntactic) in essays before and after correction, which is directly related to writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcome metrics, including three lexical complexity indicators and ten syntactic complexity indicators, and compares these before and after Grammarly correction.""
    }
}"
884,Work in Progress: Safeguarding Authenticity: Strategies for Combating Ai-generated Plagiarism in Academia,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions students in STEM and use of common English language sentence patterns, but does not clearly state that participants are L2 English learners in ESL/EFL/ELL contexts. Their L2 status and language learning context are not specified.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used only to generate a comparison paragraph for plagiarism-detection purposes. There is no experimental or quasi-experimental design integrating an LLM into writing instruction or students’ writing processes as an intervention; instead, the focus is on assessment and detection of AI-generated plagiarism.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is safeguarding authenticity and differentiating human vs. AI-generated text using a rubric, not improving writing competence or writing-related pedagogical outcomes. It is essentially an assessment/detection study rather than a writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although rubric scores and thresholds are reported, they are used to distinguish human vs. AI text and to detect plagiarism, not to evaluate the effectiveness of an LLM-mediated writing intervention on learners’ writing outcomes. No quantifiable writing improvement attributable to LLM use is assessed.""
    }
}"
885,Teaching Chatbot Prompt Strategies in Efl Essay Writing Instruction,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are EFL students in an essay writing unit, which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “AI chatbots” and “chatbot outputs” but does not specify that these are large language model-based tools (e.g., ChatGPT, GPT-4). It could involve LLMs, but this is not explicit from the title or abstract alone.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly EFL essay writing instruction, focusing on AI chatbot prompt-based learning within an essay writing unit, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on students’ perceptions and reflections, with content analysis of opportunities and challenges. There is no mention of quantitative or experimental writing outcome measures (e.g., writing scores, quality ratings) to assess effectiveness of the intervention.""
    }
}"
886,"The Challenges of Developing Technological, Pedagogical, and Content Knowledge in Aviation English Field",2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are seven Indonesian aviation English teachers working in an ESP/EFL context, so the population is clearly related to L2 English teaching/learning, with a focus on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a qualitative investigation of teachers’ perceptions of their TPACK development. It does not describe any experimental or quasi-experimental intervention integrating LLMs (e.g., ChatGPT, GPT-4) into writing instruction. Technology is discussed generically (e.g., technologies to teach writing and listening), with no mention of LLM-based tools.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing is mentioned as a macro skill, the primary focus is on teachers’ TPACK (technological, pedagogical, and content knowledge) and challenges in using technology, not on writing competence or a specific writing intervention. There is no structured pedagogical writing intervention being evaluated.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses qualitative interview data to explore perceptions. It does not report quantifiable writing outcome metrics or any measured change in learners’ writing performance resulting from an LLM-mediated intervention.""
    }
}"
887,Integration of Big Data and Artificial Intelligence in Constructing Learners' Individualized Feedback System,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are described as “65 intermediate Chinese second language learners.” The population appears to be learners of Chinese as an L2, not L2 English learners in ESL/EFL/ELL contexts. The abstract does not indicate that English is the target language.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses an “AI-based feedback system” for L2 writing, but there is no indication that it is a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model). It could be any AI feedback tool; the underlying architecture is not specified.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on L2 writing feedback and its impact on “writing quality,” “writing proficiency,” and “overall writing gains” through multi-draft essay writing. This aligns with writing competence and writing-related variables in an instructional context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an experimental vs. control group design and reports that the AI-based feedback system “significantly improve[s] learners' overall writing gains,” implying quantifiable writing outcome metrics, even though specific measures are not detailed in the abstract.""
    }
}"
888,An Investigation into the Use of Educational Apps in Efl Courses,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are 43 English teachers, not L2 English learners. The study focuses on teachers’ use of apps in EFL courses rather than on data from L2 learners themselves.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates general educational apps (Quizizz, Blooket, Kahoot) used in English teaching. These are not described as LLM-based tools (e.g., ChatGPT, GPT-4), and there is no LLM-mediated intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on overall use of apps across multiple skills (vocabulary, grammar, speaking, listening, writing, reading) and teacher perceptions, not specifically on writing competence or a writing-focused intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The article discusses app usage patterns and engagement, not experimental measures of writing performance or related variables.""
    }
}"
889,Incorporating a Reflective Thinking Promoting Mechanism into Artificial Intelligence-supported English Writing Environments,2023,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are clearly described as EFL university students in two EFL writing classes, and the focus is on English writing quality, satisfying the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses an “AI-supported English writing” environment and compares a reflective-thinking mechanism-based AI-supported approach with “conventional AI-supported EFL writing.” However, the abstract does not specify whether the AI system is a large language model (e.g., ChatGPT/GPT-like transformer-based generative model) or another type of automated feedback tool. Without this detail, it is unclear if the intervention is LLM-based.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL writing quality and related constructs (self-efficacy, self-regulated learning, cognitive load) within an AI-supported English writing environment. This aligns with writing competence and writing-related variables rather than essay scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that the proposed approach ‘significantly improved the experimental group students' English writing performance’ and also measured self-efficacy, self-regulated learning, and cognitive load, indicating quantifiable outcome metrics from a quasi-experimental design.""
    }
}"
890,Leveraging Artificial Intelligence (ai) Technology for English Writing: Introducing Wordtune as a Digital Writing Assistant for Efl Writers,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly targets English as a Foreign Language (EFL) writers and discusses English writing, so the population and language focus align with L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is described as a 'tech review' that provides an overview of Wordtune and its affordances. There is no indication of an experimental or quasi-experimental design, nor of a structured pedagogical intervention integrating the AI tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on English writing support for EFL writers, including assistance in formulating and rewriting ideas, which is clearly writing-related.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any empirical study, experimental measures, or quantifiable writing outcomes. It is a descriptive review of the tool’s features, benefits, and limitations.""
    }
}"
891,Engaging Efl Students' Critical Thinking Tendency and In-depth Reflection in Technology-based Writing Contexts: a Peer Assessment-incorporated Automatic Evaluation Approach,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are clearly described as university EFL (English as a Foreign Language) writing students, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses an Automatic Writing Evaluation (AWE) system, but there is no indication that it is based on a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model). AWE here appears as a conventional automated feedback tool, not an LLM-integrated writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on EFL writing instruction and writing performance in technology-based writing contexts, integrating AWE and peer assessment to improve writing-related outcomes.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The quasi-experiment reports quantifiable outcomes such as EFL writing performance, learning motivation, critical thinking, and writing anxiety, comparing an experimental PA-AWE group with a conventional AWE control group.""
    }
}"
892,Ai and Recognition Technologies to Facilitate English as Foreign Language Writing for Supporting Personalization and Contextualization in Authentic Contexts,2023,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 104 undergraduate English as a Foreign Language (EFL) students, clearly L2 English learners in an EFL context, and the focus is on English writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses an app (Smart RoamLingo) with ‘AI-Sample Sentences’ and ‘AI-Writing Feedback’ based on ‘recognition technologies’. The abstract does not specify whether these AI components are large language models/transformer-based generative models (e.g., ChatGPT-like) or more traditional NLP/ASR/MT/grammar-checking tools. Thus, it is unclear if an LLM is involved.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly targets EFL writing, aiming to improve meaningful content, cohesion, consistency, and writing quality via AI-generated sample sentences and AI-based feedback. The primary focus is on writing competence, not on automated scoring or system evaluation alone.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an experimental design with an experimental group and two control groups, reports that the experimental group significantly outperformed others in a post-test, and mentions assignment scores and number of revisions predicting post-test performance. These are quantifiable writing outcome measures.""
    }
}"
893,Exploring the Potential and Limitations of Chatgpt for Academic Peer-reviewed Writing: Addressing Linguistic Injustice and Ethical Concerns,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract discusses “non-native English speakers in academic publishing” in general, not a defined population of L2 English learners in ESL/EFL/ELL instructional contexts. It focuses on researchers using English for publication, not language learners in a pedagogical setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a commentary exploring the potential and limitations of ChatGPT. There is no indication of an experimental or quasi-experimental design, nor a structured instructional intervention integrating ChatGPT into writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""While it addresses academic writing and linguistic injustice, the focus is conceptual and ethical (potential, limitations, injustice, ethics), not on a concrete pedagogical context or intervention aimed at developing writing competence in an L2 learning environment.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or empirical evaluation are reported. The piece is a commentary without experimental measures, structured intervention outcomes, or assessment of writing performance changes.""
    }
}"
894,Validity Arguments for Automated Essay Scoring of Young Students' Writing Traits,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions K-12 students in grades 3–6 and refers to language backgrounds, but does not specify that the participants are L2 English learners in ESL/EFL/ELL contexts or that the focus is specifically on English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates machine learning models for automated essay scoring and human–machine score alignment. It does not describe an instructional or quasi-experimental intervention integrating large language models (e.g., ChatGPT, GPT-4) into writing instruction or writing processes; rather, it focuses on assessment validity.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the validity of automated essay scoring models (evaluation and explanation inferences, human–machine score alignment, detection of off-topic/gibberish). This is an assessment/measurement study, not a pedagogical intervention targeting writing competence or writing-related learning outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing trait scores are analyzed, they are used to evaluate the performance of ML scoring models, not to measure the effectiveness of an LLM-mediated writing intervention. There is no experimental or quasi-experimental design assessing changes in learners’ writing outcomes due to an instructional use of LLMs.""
    }
}"
895,Using Ai-based Detectors to Control Ai-assisted Plagiarism in Esl Writing: 'the Terminator Versus the Machines',2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is ESL composition, implying participants or focal texts are from L2 English learners in ESL settings: “disrupts traditional assessment practices in ESL composition… in ESL contexts.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates RoBERTa-based AI detectors for identifying ChatGPT-generated texts. It does not describe an instructional or experimental intervention integrating LLMs into writing instruction or processes; ChatGPT is only a source of machine-generated essays for detection testing.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on plagiarism detection and classifier performance, not on developing or assessing writing competence or writing-related pedagogical interventions. It is an assessment/detection study rather than a writing intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) are reported. Outcomes concern detection accuracy of classifiers, not learners’ writing performance following an LLM-mediated intervention.""
    }
}"
896,Ai-generated Feedback on Writing: Insights into Efficacy and Enl Student Preference,2023,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'university English as a new language (ENL) learners,' which aligns with L2 English learners in an ELL/ESL-type context. The focus is clearly on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""Study 1 uses a six-week repeated-measures quasi-experimental design where the experimental group receives writing feedback generated from ChatGPT (GPT-4) and the control group receives human tutor feedback. This is an LLM-based intervention integrated into writing instruction/feedback.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly writing-focused: AI-generated feedback on student writing, ENL essay evaluation, and development of students' writing skills. The study compares AI vs human feedback as part of a pedagogical intervention, not just as an automated scoring benchmark.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Study 1 'examined learning outcomes' and reports 'no difference in learning outcomes between the two groups,' implying quantifiable writing outcome metrics were used to assess the effect of ChatGPT-mediated feedback on writing performance over six weeks.""
    }
}"
897,An Assistive Environment for Eal Academic Writing Using Formulaic Sequences Classification,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as novice English as an additional language (EAL) writers, which likely corresponds to L2 English learners, but the abstract does not clearly specify ESL/EFL/ELL instructional contexts or learner status (e.g., students vs. researchers).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is an assistive environment based on formulaic sequences extracted and classified with a machine learning technique. There is no indication that a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model) is used; it appears to be corpus-based FS extraction and classification, not an LLM-mediated writing tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on academic writing improvement for EAL writers through use of domain-specific formulaic sequences, clearly targeting writing competence in research article writing rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports a ‘positive impact’ and ‘significantly higher degree of perceived usefulness’ but does not clearly state whether objective, quantifiable writing outcome measures (e.g., writing scores, text quality metrics) were collected, or only perceptions and usefulness ratings.""
    }
}"
898,"Trends, Research Issues and Applications of Artificial Intelligence in Language Education",2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The article is a bibliometric review of 516 papers on AI in language education. The abstract does not specify that its own data are drawn specifically from L2 English learners in ESL/EFL/ELL contexts; it aggregates across many AI-in-language-education studies without detailing participant populations.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a bibliometric review, not an experimental or quasi-experimental study implementing an LLM-based intervention. It surveys trends and applications of AI (e.g., automated writing evaluation, ITS) but does not itself integrate an LLM (such as ChatGPT or GPT-4) into writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing-related topics (e.g., automated writing evaluation, ITS for writing) are mentioned among the reviewed themes, the paper’s primary focus is mapping research trends and applications across multiple skills, not conducting a specific pedagogical writing intervention or study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a bibliometric review, the study does not report original, quantifiable writing outcome metrics from an LLM-mediated intervention. It summarizes existing literature rather than measuring writing performance changes in an experimental design.""
    }
}"
899,The Impact of Ai Writing Tools on the Content and Organization of Students' Writing: Efl Teachers' Perspective,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students in Indonesian universities, as reported via interviews with four EFL teachers. The focus is clearly on English as a foreign language learners’ writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although several AI tools are mentioned (Quillbot, WordTune, Jenni, ChatGPT, Paperpal, Copy.ai, Essay Writer), the study is a qualitative case study based on teacher perceptions and does not describe an experimental or quasi-experimental LLM-based writing intervention. It surveys tools in use rather than implementing and testing a specific LLM-mediated instructional design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on the impact of AI writing tools on students’ writing, specifically content and organization, which are core writing competence variables in an EFL context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a qualitative case study design with semi-structured interviews and reports teachers’ perceptions of improvement. It does not report quantifiable writing outcome metrics or experimental measures of writing performance.""
    }
}"
900,Chatbot-based Training on Logical Fallacy in Efl Argumentative Writing,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'Chinese EFL undergraduate and graduate students,' clearly indicating L2 English learners in an EFL context, with outcomes focused on EFL argumentative writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses an 'educational chatbot' for training on logical fallacies, but the abstract does not indicate that this chatbot is a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model). It could be a rule-based or non-LLM system, so it does not clearly meet the LLM intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL argumentative writing, with the chatbot-based intervention designed to address logical fallacies that affect argumentative writing quality. The primary focus is on writing proficiency and related variables (self-efficacy).""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: pre-post argumentative writings analyzed using the Illinois Critical Thinking Essay Scoring Rubric, and pre-post questionnaires on writing self-efficacy. These provide measurable effects of the chatbot-based training on writing-related outcomes.""
    }
}"
901,Understanding English as a Foreign Language Students' Idea Generation Strategies for Creative Writing with Natural Language Generation Tools,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) students in Hong Kong secondary schools, focusing on English creative writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses ‘natural language generation (NLG) tools’ for idea generation. It is not specified whether these are large language models (e.g., ChatGPT/GPT-4) or other, non-LLM NLG systems. However, the tools are used mainly for idea generation, not as a structured, experimental LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on students’ idea generation strategies and interactions with NLG tools, explored via thematic analysis of reflections. There is no explicit focus on measuring writing competence or writing-related performance outcomes; instead, it examines perceptions and strategies around idea generation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports a qualitative thematic analysis of written reflections and does not mention any quantifiable writing outcome metrics (e.g., writing scores, text quality measures, pre/post tests). The outcomes are students’ concerns and strategies, not measured changes in writing performance.""
    }
}"
902,"Artificial Intelligence in English Language Teaching: the Good, the Bad and the Ugly",2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses English language teaching (ELT) broadly and mentions learners, teachers, and institutions, but does not specify that the focus is on L2 English learners in ESL/EFL/ELL contexts or provide participant details, as it appears to be a conceptual/overview article.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a descriptive overview of how AI is used in ELT, mentioning chatbots, machine translation, intelligent tutoring systems, and automated writing evaluation. It does not describe an experimental or quasi-experimental intervention integrating LLMs (e.g., ChatGPT, GPT-4) into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on AI in ELT generally, including ethical issues, learner wellbeing, and digital literacies. Writing is only briefly referenced via automated writing evaluation as one of many AI tools, and there is no indication that writing competence or writing-related variables are the primary focus of the study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any empirical data, experimental measures, or quantifiable writing outcomes. It is an exploratory/overview article discussing opportunities, challenges, and ethical issues rather than reporting intervention outcomes.""
    }
}"
903,Recipe: How to Integrate Chatgpt into Efl Writing Education,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 213 undergraduate and graduate students enrolled in EFL writing courses, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study presents RECIPE, a platform that integrates ChatGPT (a large language model) into EFL writing education, with ChatGPT taking an EFL teacher role and interacting with students about their self-written summaries.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL writing courses, and the platform is designed for revising an essay with ChatGPT, focusing on writing-related learning activities.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports collection of interaction data, students’ perceptions, usage, user scenarios, and qualitative interviews. It does not mention any experimental or quasi-experimental design with quantifiable writing outcome measures (e.g., writing scores, quality ratings, or pre/post tests). The focus is exploratory and design-oriented rather than on measured writing gains.""
    }
}"
904,Chatgpt and the Efl Classroom: Supplement or Substitute in Saudi Arabia’s Eastern Region,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 64 EFL learners at a language learning institution in Saudi Arabia’s Eastern Region, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT is used in writing opportunities, the design focuses on comparing satisfaction with teacher-mediated vs. ChatGPT-assisted writing, not on an experimental or quasi-experimental pedagogical intervention aimed at improving writing performance. The emphasis is on perceptions rather than structured instructional treatment effects.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing: the study compares teacher-mediated versus ChatGPT-assisted writing opportunities, which is directly related to writing instruction and writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are learners’ satisfaction components (learning content, learning progress, ease of use, interactive opportunities) derived from factor analysis of open-ended responses. No quantifiable writing performance metrics (e.g., scores, quality ratings, accuracy, complexity) are reported to assess writing improvement.""
    }
}"
905,Using Chatgpt for Second Language Writing: Pitfalls and Potentials,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses 'second language (L2) writing' in general but does not specify that the focus is on L2 English learners (ESL/EFL/ELL) or that the target language is English. The population and language context remain unspecified.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a 'tech review' that explores potential benefits and challenges of using ChatGPT for L2 writing. It does not indicate any experimental or quasi-experimental design, nor an implemented LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on L2 writing and pedagogy, suggesting relevance to writing competence, but as a review rather than an empirical intervention study. The primary aim is conceptual/analytical, not an implemented pedagogical context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a review article, it does not report quantifiable writing outcome metrics or empirical measures of intervention effectiveness. It offers recommendations and discusses potentials and pitfalls without experimental outcome data.""
    }
}"
906,Assessing the Effectiveness of Quillbot-mediated Instruction in Enhancing Efl Students’ Paraphrasing Skills,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL university students enrolled in a Technical Writing course, so they are L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses QuillBot, described as an online paraphrasing tool. QuillBot is not clearly an LLM-based pedagogical writing intervention in the sense required (e.g., ChatGPT/GPT-4-style generative transformer used instructionally), and is listed in the protocol as an example of tools to exclude if not LLM-based.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on improving paraphrasing skills within Technical Writing, which is a writing-related competence. The intervention is framed as instruction to enhance writing (paraphrasing) performance.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""A test was used to measure students’ paraphrasing skills, and the abstract reports that the QuillBot-mediated instructional program ‘highly benefited students’ paraphrasing skills,’ indicating quantifiable outcome measures.""
    }
}"
907,X-education: Education of All Things with Ai and Edge Computing-one Case Study for Efl Learning,2022,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly mentions EFL learners and EFL writing. Participants are described as EFL learners (22 learners), indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses “on-device AI” and an X-Education framework with Q&A forwarding mechanisms, but it is not specified whether this AI is a large language model (e.g., ChatGPT/GPT-like transformer-based generative model) or another type of AI. Without clarification, it is unclear if an LLM is integrated into the writing instruction or process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context includes an EFL writing preliminary study and mentions that learners felt X-Education could help them learn EFL writing better through Q&A. This indicates a focus on writing-related learning, not just general language or assessment.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports significant increases in the ‘knowledge of all things’ and that the experimental group received better EFL answers from the AI and perceived benefits for EFL writing. However, it does not clearly state whether quantifiable writing outcome metrics (e.g., writing scores, text quality measures) were collected, as opposed to general knowledge gains and perceptions.""
    }
}"
908,Impact on Second Language Writing Via an Intelligent Writing Assistant and Metacognitive Training,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL (English as a foreign language) university-level learners completing TOEFL iBT-style independent writing tasks, so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is an internally developed online writing aid with next-word prediction and reverse translation support. The abstract does not indicate that this tool is based on a large language model (e.g., transformer-based generative model like GPT). It appears to be a predictive text/assistive tool rather than an LLM-based system, so it does not meet the LLM intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on second language writing output and writing quality, using TOEFL iBT-style writing tasks and a writing assistant. The primary context is clearly writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing outputs were assessed by machine and human raters using several measures for writing quality, and the study reports that the treatment group performed better than the control group. This indicates quantifiable writing outcome metrics are reported.""
    }
}"
909,Determinants Affecting Teachers' Adoption of Ai-based Applications in Efl Context: an Analysis of Analytic Hierarchy Process,2022,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context is EFL, but the abstract does not specify whether the focus is on learners’ English writing or even on learners at all; it centers on teachers’ adoption of AI applications. The target language is English, but the participant population relevant to L2 writing outcomes is not clearly defined.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study analyzes determinants of teachers’ adoption of AI-based applications using an Analytic Hierarchy Process model. It does not describe an experimental or quasi-experimental pedagogical intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on technology adoption factors (effectiveness, efficiency, complexity, fees, etc.) for AI applications in EFL, not on writing competence or writing-related variables. No writing instruction or writing process intervention is described.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports weighted factors influencing adoption decisions, not quantifiable writing outcome metrics. There is no measurement of learners’ writing performance or related writing outcomes following an LLM-mediated intervention.""
    }
}"
910,The Role of Psycholinguistics for Language Learning in Teaching Based on Formulaic Sequence Use and Oral Fluency,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are Chinese EFL learners (“Learners of English as a foreign language… Chinese EFL learners”), so the population clearly consists of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study mentions being “combined with artificial intelligence techniques,” there is no indication that a large language model (e.g., ChatGPT, GPT-4) is integrated into instruction or the writing process. AI appears to be used as an analytic tool, not as an LLM-based pedagogical intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is explicitly on oral fluency and spoken narratives (“oral fluency,” “spoken narratives,” “speed fluency,” “breakdown fluency,” “repair fluency”). Writing competence or writing-related variables are not the primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes measured are oral fluency metrics (speed, breakdown, repair fluency) and formulaic sequence use in spoken narratives. No writing outcomes or writing-related measures are reported.""
    }
}"
911,Automated Feedback and Teacher Feedback: Writing Achievement in Learning English as a Foreign Language at a Distance,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are open education faculty students in Turkey learning English as a foreign language, which fits an EFL L2 English learner context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention compares teacher feedback with ‘automated feedback software’ but the abstract does not indicate that this software is an LLM or transformer-based generative model (e.g., ChatGPT, GPT-4). It appears to be generic automated feedback, not an LLM-based tool, so it does not meet the LLM intervention requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly focuses on academic writing achievement in EFL and examines the effect of feedback (teacher vs automated) on writing performance, which is a writing competence outcome in an instructional context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses diagnostic and post-test writing scores and statistically analyzes grades to determine effects on academic writing achievement, providing quantifiable writing outcome metrics.""
    }
}"
912,An Analysis and Research on Chinese College Students' Psychological Barriers in Oral English Output from a Cross-cultural Perspective,2022,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are Chinese college students learning English, but the study frames English as China’s second language in a general sense, not clearly as an ESL/EFL/ELL research context focused on L2 English learners as a defined population. The emphasis is on psychological barriers in oral English output rather than L2 writing learners per se.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions an ‘artificial-intelligence-based oral English teaching assistance system’ but provides no indication that it is a large language model (e.g., ChatGPT, GPT-4) or any transformer-based generative model. It appears to be an AI pronunciation correction tool, not an LLM-mediated intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is oral English output, pronunciation, and psychological barriers in speaking. Writing competence or writing-related variables are not mentioned; the intervention is clearly about oral English teaching, not writing instruction or writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported or implied. Outcomes relate to oral English, pronunciation improvement, and psychological barriers in speaking, with no experimental measures of writing performance or writing-related constructs.""
    }
}"
913,"Proceedings - 2022 International Conference on Artificial Intelligence of Things and Crowdsensing, Aiotcs 2022",2022,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract is for a proceedings volume listing multiple papers. One listed paper mentions 'computerized dynamic ESL writing', suggesting ESL learners may be involved, but no specific participant information is provided for that study.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The proceedings description does not indicate that any paper uses large language models (e.g., ChatGPT, GPT-4) in an experimental or quasi-experimental writing intervention. The mentioned ESL writing paper concerns Rasch measurement of peer evaluation, not LLM-based tools.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The volume covers diverse AI and engineering topics. The only writing-related item is 'a multi-facet Rasch measurement of peer evaluation in computerized dynamic ESL writing', which focuses on measurement of peer evaluation rather than a pedagogical LLM-mediated writing intervention.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract does not provide details on outcome measures for any individual study. Even if the ESL writing paper includes quantitative outcomes, there is no indication these relate to an LLM-mediated intervention.""
    }
}"
914,Icall Offering Individually Adaptive Input: Effects of Complex Input on L2 Development,2022,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “language learners” and “L2 development” but does not specify that the target language is English or that the context is ESL/EFL/ELL. The venue (University of Hawaii at Manoa) suggests a possible English focus, but this is not explicit in the title or abstract.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses an ICALL system that adaptively selects texts of varying complexity (“Complex Input Primed Writing task”). There is no indication that the system is based on large language models (e.g., transformer-based generative models like ChatGPT/GPT-4). It appears to be an adaptive input-selection system rather than an LLM-mediated writing tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on how different challenge levels of adaptive input affect learners’ written output complexity. Writing production and complexity alignment are central outcomes, fitting the focus on writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports quantifiable outcomes: learners in low- and medium-challenge conditions produced “more complex writings” after the intervention, while the high-challenge group did so less. This implies measured writing complexity as an outcome metric in an experimental design.""
    }
}"
915,"Proceedings of the 19th International Conference on Cognition and Exploratory Learning in the Digital Age, Celda 2022",2022,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a proceedings volume containing 55 papers across diverse topics. The abstract does not specify that any included study focuses on L2 English learners in ESL/EFL/ELL contexts with analyzable data; it only lists titles, one of which is a literature review on EFL online learning and another on student perceptions of AI-powered writing tools, without specifying L2 English learners as the population for an empirical intervention study.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The proceedings as a whole are not an experimental or quasi-experimental study. The only relevant-sounding item, “student perceptions of AI-powered writing tools,” appears to be a perception-focused study and does not clearly indicate integration of LLMs (e.g., ChatGPT, GPT-4) in an intervention design. No specific LLM-based writing intervention is described.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The volume covers many topics (mathematics, programming, driving, gamification, etc.). Writing is only tangentially mentioned in one paper title about AI-powered writing tools and is framed around perceptions, not a focused pedagogical intervention on writing competence. The proceedings themselves are not centered on writing instruction or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported in the abstract. The mentioned paper on AI-powered writing tools focuses on student perceptions, suggesting qualitative or attitudinal data rather than measured changes in writing performance following an LLM-mediated intervention.""
    }
}"
916,Exploring the Interaction between L2 Learners and Ai Translator in English Writing,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as L2 learners writing an essay in English, and Korean is mentioned, indicating an EFL/ESL-type context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The tool is an unspecified 'AI translator' used during English writing. There is no indication it is a large language model (e.g., ChatGPT/GPT-4) or a transformer-based generative model; it appears to be a translation tool rather than an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is English essay writing, and the study examines interaction patterns while using an AI translator for English writing, which is directly writing-focused.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study explores interaction patterns and clusters of use (English writing, Korean writing, Interactive writing) and notes differences according to expression scores, but it does not describe an experimental or quasi-experimental intervention to improve writing or report pre/post or comparative writing outcome measures attributable to the AI tool.""
    }
}"
917,An Integrated Automatic Writing Evaluation and Svvr Approach to Improve Students’ Efl Writing Performance,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are clearly described as EFL (English as a Foreign Language) university students in an EFL writing course, so the population consists of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention integrates Automatic Writing Evaluation (AWE) and spherical video-based virtual reality (SVVR). The abstract does not indicate that the AWE system is based on a large language model or transformer-based generative model (e.g., ChatGPT, GPT-4). AWE here is used for feedback on vocabulary and grammar, which is typical of non-LLM AWE systems. No LLM is mentioned.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on improving EFL writing performance and related affective variables (motivation, self-efficacy, anxiety) through an instructional intervention in a writing course, aligning with writing competence as the central context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that the integrated SVVR–AWE approach ‘considerably enhanced the students’ EFL writing performance’ compared to a control group, implying quantitative writing outcome measures were collected and analyzed in a quasi-experimental design.""
    }
}"
918,"Investigating English as a Foreign Language Learners’ Perceptions, Emotions, and Performance during Online Collaborative Writing",2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners: 58 male students enrolled in writing courses in the Department of English Language and Translation at Qassim University. The context is clearly English as a Foreign Language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Blackboard and Blackboard Chatbox for online collaborative writing. These are not large language models (e.g., ChatGPT, GPT-4) but standard learning management and chat tools. No LLM-based generative system is mentioned.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on collaborative writing in EFL classes and examines learners’ perceptions, emotions, and performance in writing tasks using technology (Blackboard Chatbox). Writing competence and related variables are central.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports learners’ overall performance and compares performance between face-to-face and Blackboard Chatbox instruction, including a significance test (Sig. = 0.287), indicating quantifiable writing outcomes.""
    }
}"
919,Using Chatbots to Scaffold Efl Students’ Argumentative Writing,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The population is explicitly English as a foreign language (EFL) students, and the focus is on their English argumentative writing, satisfying the L2 English learner requirement.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes a custom chatbot system (Argumate) but does not indicate that it is a large language model (e.g., ChatGPT/GPT-like transformer-based generative model). It is framed generically as a chatbot/AI system, and given the 2022 date and lack of LLM terminology, it is unlikely to be an LLM-based intervention as defined in the review.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly argumentative writing instruction: a chatbot-assisted approach to teaching and learning argumentative writing and scaffolding argument construction, which aligns with writing competence as the primary focus.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions discussing advantages and limitations of using the system to assist students in producing high-quality argumentative writing but does not state that any experimental or quasi-experimental study with quantifiable writing outcome metrics was conducted.""
    }
}"
920,Proactive Learner Empowerment: towards a Transformative Academic Integrity Approach for English Language Learners,2022,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as undergraduate students in diverse global locations engaged in a program called 'Reading and Writing Excellence' and as English language learners in the title, but the abstract does not clearly specify that they are L2 English learners in ESL/EFL/ELL contexts, nor that English is the target L2 for all participants.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention involves a curated set of academic integrity (AI) online resources and an instructor-facilitated, learner-driven approach. There is no mention of large language models (e.g., ChatGPT, GPT-4) or any transformer-based generative tools being integrated into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The program focuses on academic writing-related skills (paraphrasing, summarizing, organization of ideas, critical thinking, logic/argument) and written journal entries with instructor feedback, indicating a primary focus on writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative outcomes are reported: average written output per student (6064 words over 4 weeks), comparison of output across proficiency levels using nonparametric ANOVA, and survey-based self-perceptions of readiness in specific writing-related skills (paraphrasing, summarizing, organization, critical thinking, logic/argument).""
    }
}"
921,Automated Scoring of Speaking and Writing: Starting to Hit Its Stride,2022,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses automated scoring of speaking and writing in general and mentions different groups, but does not specify that the population is L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a literature review on automated scoring (AS) and does not describe an experimental or quasi-experimental intervention integrating LLMs into writing instruction or writing processes. It focuses on AS systems and their design, role of AI, and accuracy, not on LLM-mediated pedagogical interventions.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automated scoring for assessment (writing and speaking) and its implications, not on writing instruction or development of writing competence through an intervention. It aligns with evaluation of AS functionality rather than a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a review article, it does not report original experimental outcome measures of a specific LLM-mediated writing intervention. It synthesizes existing literature rather than providing quantifiable writing outcomes from a new study.""
    }
}"
922,Assessing Readability of Learning Materials on Artificial Intelligence in English for Second Language Learners,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on English-as-a-second-language (ESL) learners engaging with English AI learning materials, which fits the target population of L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study uses deep-learning-based NLP to build automatic readability assessors, there is no indication that large language models (e.g., ChatGPT, GPT-4) are integrated into writing instruction or learners’ writing processes. The tools are used for text readability assessment, not as pedagogical LLM interventions.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on assessing the readability of AI learning materials, not on writing competence or writing-related instruction. There is no mention of writing tasks, writing instruction, or writing performance as a central outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports readability levels and the proportion of texts that intermediate ESL learners can read, but it does not report quantifiable writing outcomes or effects of an LLM-mediated writing intervention.""
    }
}"
923,A Multi-facet Rasch Measurement of Peer Evaluation in Computerized Dynamic Esl Writing,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly refers to ESL (English as a Second Language) writing and mentions 41 students in an ESL context, indicating L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention involves Computerized Dynamic Assessment and a peer assessment system (Peerceptiv). There is no mention of large language models, transformer-based generative AI, or tools like ChatGPT/GPT-4. The focus is on peer evaluation reliability, not LLM integration.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on second language writing and peer assessment within computerized dynamic assessment, which is clearly writing-related.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses reliability and consistency of peer assessment using Multi-facet Rasch measurement but does not clearly report quantifiable writing outcome metrics (e.g., changes in writing quality). However, this criterion is moot because C2 already fails.""
    }
}"
924,Design of Interactive System for Autonomous Learning of Business English Majors Based on Deep Learning Algorithms,2022,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The population is described as 'business English majors', which likely implies L2 English learners, but this is not explicitly stated and could also include native speakers in an English-medium context. The abstract does not clearly specify ESL/EFL/ELL status.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study mentions integrating 'deep learning into the recommendation system' but does not indicate the use of large language models (e.g., ChatGPT, GPT-4) or any transformer-based generative model. It appears to be about a recommendation system and autonomous learning, not an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on 'self-service learning ability' and 'deep learning goals' for business English majors, with evaluation via written tests and work evaluations. There is no clear indication that the primary focus is on writing competence or writing-related variables; it seems more about general learning or performance.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although written tests and work evaluations are mentioned, the abstract does not specify that these are writing outcome measures within an LLM-mediated writing intervention. There is no indication of quantifiable writing outcomes tied to an LLM-based writing intervention.""
    }
}"
925,The Integration of Multiple Recognition Technologies and Artificial Intelligence to Facilitate Efl Writing in Authentic Contexts,2022,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 71 undergraduate EFL learners (“English as Foreign Language (EFL) learners”), and the focus is explicitly on English writing. This matches the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is a mobile app (Smart UEnglish) that integrates “generative-AI” to provide AI-generated sample sentences (AI-GS). Students are assigned to experimental and control groups, with the experimental group using the generative-AI component. This is an experimental design integrating generative AI into writing instruction. While the specific LLM is not named, the description of ‘generative-AI’ producing sample sentences is consistent with an LLM-based tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on facilitating EFL learners’ English writing: the app is designed “to help learners practice meaningful English writing in authentic contexts,” and the outcome discussed is performance on a writing posttest and essay writing inspired by AI-generated sample sentences. This aligns with writing competence as the central context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports that “the EG outperformed the CG in the posttest” and identifies ITR use as a predictive variable in the post-test. This indicates quantifiable writing outcome metrics (pre/post or at least posttest comparison between groups) to assess the effectiveness of the AI-mediated writing intervention.""
    }
}"
926,Using Chatbots to Scaffold Efl Students? Argumentative Writing,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly refers to English as a foreign language (EFL) students and focuses on their argumentative writing in English, matching the target L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a custom chatbot system (Argumate). The abstract does not indicate that it is based on large language models (e.g., GPT-style transformer generative models); it is presented generically as a chatbot/AI system. Given the publication context and lack of LLM mention, it is unlikely to be an LLM-based intervention as defined in the review.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The paper proposes a chatbot-assisted approach to teaching and learning argumentative writing and discusses using the system to assist students in producing high-quality argumentative writing. The primary focus is clearly on writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes a proposed approach and a system (Argumate) and discusses advantages and limitations, but does not mention any experimental or quasi-experimental design, nor any quantitative writing outcome measures. It appears to be more of a design/description paper than an intervention study with measurable outcomes.""
    }
}"
927,To Err Is Human: Comparing Human and Automated Corrective Feedback,2022,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions a corpus of 115 texts written by college students, but does not specify whether these are L2 English learners (ESL/EFL/ELL) or native speakers. The learner status and L2 context are not clearly indicated.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares corrective feedback from human teachers with Grammarly, described as a ‘well-known writing assistant’ and ‘Automated Written Evaluation (AWE)’ tool. Grammarly is not an LLM-based generative model in the sense required (e.g., ChatGPT, GPT-4, Gemini); it is a non-LLM AWE/grammar checker. No LLM integration into instruction or writing processes is reported.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on comparing error detection and types of corrective feedback between human raters and Grammarly on existing texts. There is no pedagogical intervention or instructional context where learners use the tool as part of a writing intervention; it is essentially a comparative CF/assessment study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports statistics on number and types of errors detected by humans vs Grammarly, not on changes in learners’ writing performance over time or pre/post intervention outcomes. No quantifiable writing outcome metrics assessing the effectiveness of an LLM-mediated writing intervention are presented.""
    }
}"
928,A Review of Artificial Intelligence in Foreign Language Learning,2022,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses foreign/second language learning in general and does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor that the focus is on English specifically.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a brief review of AI implementation in second language learning, not an experimental or quasi-experimental study. No specific LLM-based intervention (e.g., ChatGPT, GPT-4) is described.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is broadly on foreign language learning and AI, with no indication that writing competence or writing-related variables are the primary focus; skills are not specified in the abstract.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a review article, it does not report original, quantifiable writing outcome metrics from an intervention; it summarizes ‘latest attempts’ rather than presenting experimental measures.""
    }
}"
929,The Effects of an Augmented-reality Ubiquitous Writing Application: a Comparative Pilot Project for Enhancing Efl Writing Instruction,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL undergraduates in an English as a foreign language writing context, so the population is L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is an augmented-reality context-aware ubiquitous writing (ARCAUW) application. There is no indication that it is based on large language models (e.g., ChatGPT, GPT-4, transformer-based generative models). It is framed as AR and context-aware ubiquitous technology, not an LLM-mediated tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on EFL writing instruction, comparing an ARCAUW writing mode with a mobile-assisted classroom-based writing mode, and examines writing development, task schema, and related writing processes.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports pre- and post-test results on writing outcomes (process analysis essay performance) and compares writing performance between conditions, indicating quantifiable writing outcome metrics.""
    }
}"
930,Partnering with Al: Intelligent Writing Assistance and Instructed Language Learning,2022,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses ‘learners’ and ‘instructional language learning’ but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor that the focus is specifically on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The piece is explicitly described as a ‘column’ that examines AI-enabled writing tools, reviews findings from research studies, and discusses their use. It does not describe an experimental or quasi-experimental study conducted by the authors, nor a specific LLM-based intervention (e.g., ChatGPT, GPT-4).""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus is on writing tools and their instructional use, the article is a conceptual/review-style column rather than an empirical study implementing a concrete writing intervention with measured outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental results are reported; the abstract only mentions that tools ‘have been found to offer significant benefits’ in prior work and focuses on discussion and review.""
    }
}"
931,Exploring Artificial Intelligence Using Automated Writing Evaluation for Writing Skills,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Malaysian public university students in ESL writing classrooms, indicating L2 English learners in an ESL/EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is described as AI software for Automated Writing Evaluation (AWE). There is no indication that this is an LLM-based, transformer generative model (e.g., ChatGPT, GPT-4). AWE tools are typically rule-based or non-LLM systems, so it does not meet the LLM requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is ESL writing classrooms and improving writing skills, with focus on grammatical error detection and writing skills, which is directly writing-related.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions investigating the effectiveness of AWE in improving writing skills and students’ perceptions, but only reports positive perceptions. It does not clearly state any quantitative writing outcome measures (e.g., scores, error rates).""
    }
}"
932,Clustering Students' Writing Behaviors Using Keystroke Logging: a Learning Analytic Approach in Efl Writing,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The title and abstract indicate an EFL writing context, implying participants are English as a foreign language learners engaged in English writing tasks.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses machine learning and clustering on keystroke logging data to identify writing behavior profiles. There is no mention of large language models (e.g., ChatGPT, GPT-4) or any LLM-based writing intervention; the focus is on analytics, not LLM-mediated instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly EFL writing, focusing on writing processes and writing quality, and how students interact with writing tasks. This aligns with a primary focus on writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports analysis of writing quality and compares clusters with respect to students’ writing quality, indicating quantifiable writing outcome metrics are used, even though no LLM intervention is present.""
    }
}"
933,An Integrated Automatic Writing Evaluation and Svvr Approach to Improve Students' Efl Writing Performance,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are clearly described as EFL (English as a Foreign Language) university students in an EFL writing course, so the population consists of L2 English learners and the focus is on English writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention integrates Automatic Writing Evaluation (AWE) and Spherical Video-based Virtual Reality (SVVR). The abstract does not indicate that the AWE system is based on a large language model (e.g., ChatGPT, GPT-4) or any transformer-based generative model; it is a generic AWE tool. Therefore, it does not meet the requirement of an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on improving EFL writing performance and related affective variables (motivation, self-efficacy, anxiety) through an instructional intervention in a writing course, which aligns with a writing competence context rather than automated scoring or system evaluation alone.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that the integrated SVVR-AWE approach ‘considerably enhanced the students’ EFL writing performance’ compared to a control group, implying quantifiable writing outcome measures were collected and analyzed in a quasi-experimental design.""
    }
}"
934,Automatic Scoring of Arabic Essays over Three Linguistic Levels,2022,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are learners of Arabic as a second language; the focus is on Arabic essays, not L2 English learners in ESL/EFL/ELL contexts. Therefore, the population does not match the review’s scope.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study presents an automatic scoring system using feature extraction at lexical, syntactic, and semantic levels, with linear and non-linear combination methods. There is no indication that a large language model (e.g., transformer-based generative model like ChatGPT/GPT-4) is used, nor that it is integrated into instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automated essay scoring reliability (accuracy and quadratic weighted kappa vs. human raters), not on pedagogical writing intervention or development of writing competence. It is an assessment tool evaluation, not a teaching/learning context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports system performance metrics (accuracy, quadratic weighted kappa) relative to human raters, not quantifiable outcomes of a writing intervention on learners’ writing performance. There is no experimental or quasi-experimental design assessing LLM-mediated writing improvement.""
    }
}"
935,Analysis of Syntactic Complexity and Semantic Coherence of Academic English Writing Based on Particle Swarm Optimization,2022,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses ‘academic English writing’ and ‘second language writing’ but does not specify the participant population (e.g., EFL/ESL learners, their level, or whether they are L2 English learners). It could be corpus-based or system-focused rather than learner-focused.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is an ‘intelligent evaluation method’ using particle swarm optimization (PSO) and other algorithms. PSO is an optimization technique, not a large language model or transformer-based generative model (e.g., ChatGPT, GPT-4). No LLM-based writing instruction or process support is described.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on automated evaluation of syntactic complexity and semantic coherence using PSO and other algorithms, not on a pedagogical writing intervention. It appears to be an assessment/algorithmic study rather than an instructional context aimed at improving writing competence through an intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although quantitative measures (e.g., significance values) are reported, they relate to comparing algorithms (data mining, AI, decision tree, PSO) for evaluation performance, not to measuring changes in learners’ writing outcomes following an LLM-mediated intervention.""
    }
}"
936,Writing Issues in Esl and Their Potential Solutions: Case Study Imco's Foundation Students,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are IMCO foundation students (A1–B1) who are non-native English speakers in an ESL/EFL context, focusing on English writing mistakes. This matches the target L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study records common writing mistakes and uses bibliometric analysis tools (VOSviewer, Yale DHlab Raw Graph 2.0). There is no indication that large language models (e.g., ChatGPT, GPT-4) were integrated into instruction or writing processes; AI is only mentioned as a future need.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing issues (spelling, punctuation, thesis statements, structure, etc.) among ESL learners, clearly centering on writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports identification and categorization of common errors but does not clearly describe a structured intervention with pre/post or comparative quantitative writing outcome measures to assess an instructional treatment. It appears more diagnostic/descriptive than evaluative of an intervention.""
    }
}"
937,X-education: Education of All Things with Ai and Edge Computing—one Case Study for Efl Learning,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly mentions a preliminary study for EFL writing with 22 learners, indicating participants are EFL (L2 English) learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses “on-device AI” and Q&A forwarding mechanisms within an X-Education framework, but there is no indication that the AI is a large language model (e.g., ChatGPT/GPT-like transformer-based generative model). The nature of the AI is unspecified and cannot be assumed to be an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context includes EFL writing and learners’ perceptions that X-Education could help them learn EFL writing better through Q&A, indicating a focus on writing-related learning.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports that knowledge of all things in the experimental group increased significantly and that learners received better EFL answers, but it does not clearly state that quantifiable writing performance outcomes (e.g., writing scores, text quality measures) were measured. The only explicit outcome is knowledge gain and perceived help for EFL writing.""
    }
}"
938,Computer-assisted Efl Writing and Evaluations Based on Artificial Intelligence: a Case from a College Reading and Writing Course,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students in a college reading and writing course, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses three online automated essay evaluation (AEE) systems and discusses computer-assisted review tools and automatic evaluation. There is no indication these are large language model–based tools (e.g., ChatGPT, GPT-4); they are framed as traditional AEE/ICALL systems, not transformer-based generative LLMs.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on English writing ability, computer-assisted evaluation tools, and their impact on students’ writing and independent learning, which aligns with a writing competence context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that students’ English writing ability was significantly improved and that teacher and AEE scores were compared using descriptive statistics, indicating quantifiable writing outcome measures.""
    }
}"
939,"Investigating English as a Foreign Language Learners' Perceptions, Emotions, and Performance during Online Collaborative Writing",2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners (male students enrolled in writing courses in the Department of English Language and Translation, Qassim University), so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Blackboard and Blackboard Chatbox for online collaborative writing. These are general learning management and chat tools, not large language models (e.g., ChatGPT, GPT-4). No LLM-based generative system is mentioned.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on collaborative writing, learners’ emotions, and performance in writing courses, so the primary focus is on writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports learners’ overall performance and compares performance between face-to-face and Blackboard Chatbox instruction, indicating quantifiable writing-related outcome measures (e.g., significance value Sig. = 0.287).""
    }
}"
940,Partnering with Ai: Intelligent Writing Assistance and Instructed Language Learning,2022,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses ‘learners’ and ‘instructional language learning’ in general but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor that the focus is specifically on English writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The piece is explicitly described as a ‘column’ that examines AI-enabled writing tools and reviews findings from research studies. It does not report an experimental or quasi-experimental study of its own, nor a specific LLM-based intervention; it is a narrative/overview of tools such as AWE, MT, Grammarly, and generative systems.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus is on writing tools and their instructional use, the article is a conceptual/review-style column rather than an empirical study implementing a concrete writing intervention with measured outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental results are reported. The abstract mentions that tools ‘have been found to offer significant benefits’ but only in the context of reviewing prior research, without presenting new, structured intervention outcomes.""
    }
}"
941,Investigating Connections between Teacher Identity and Pedagogy in a Content-based Classroom,2021,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are L2 English learners in an L2 English legal education (LLM) program, learning to write a legal genre (office memorandum), which fits ESL/EAP-type contexts focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a classroom-based ethnography of a content-based legal research and writing course. There is no mention of large language models, AI tools, or any experimental/quasi-experimental integration of LLMs into instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context involves teaching legal writing, the primary focus is on connections between teacher identity and pedagogy in a CBI classroom, not on writing competence or writing-related variables as outcomes of a specific intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is qualitative (ethnography) and does not report quantifiable writing outcome metrics. Data sources include observations, fieldnotes, artifacts, and interviews, with no experimental measures of writing performance.""
    }
}"
942,Application of Artificial Intelligence Powered Digital Writing Assistant in Higher Education: Randomized Controlled Trial,2021,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as \""English second postgraduate students\"" and \""non-native postgraduate students in English academic writing,\"" indicating L2 English learners in an English academic writing context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention is an \""Artificial Intelligence (AI) powered writing tool\"" but the abstract does not specify that it is a large language model (e.g., ChatGPT/GPT-based or transformer generative model). It could be a non-LLM tool (e.g., traditional NLP, grammar checker). Without explicit indication of LLM use, this does not clearly meet the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is English academic writing, but the primary outcomes reported are behavioral, emotional, and cognitive engagement, self-efficacy for writing, and emotions. There is no indication that writing competence or text quality itself was measured; the focus is on engagement and attitudes rather than writing performance.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports quantitative outcomes only for engagement, self-efficacy, and emotions. No quantifiable writing outcome metrics (e.g., writing scores, text quality measures, accuracy, complexity) are mentioned, so it does not meet the requirement for writing performance outcomes.""
    }
}"
943,Ensemble Multi-channel Neural Networks for Scientific Language Editing Evaluation,2021,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract discusses scientific papers authored by non-native English speakers in general and an AESW shared task dataset, but does not describe any participant group of L2 English learners in an ESL/EFL/ELL instructional context. It is a system paper, not a learner study.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study proposes an Ensemble Multi-Channel Neural Networks (EMC-NN) model for sentence-level language editing evaluation. It is not an LLM-based (e.g., ChatGPT/GPT-4) pedagogical intervention; it is a classification model for detecting whether a sentence needs editing.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on automated scientific writing evaluation (predicting if a sentence needs editing) and model performance (F1-score), not on writing instruction, learner use of tools, or writing competence development in an educational context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are model performance metrics (F1-score) on a test set, not quantifiable writing outcomes for learners following an LLM-mediated writing intervention. No experimental measures of learner writing improvement are described.""
    }
}"
944,Automated L2 Writing Performance Assessment: a Literature Review,2021,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses ESL/EFL writing instruction contexts in general but does not specify participant populations, as this is a literature review rather than an empirical study with its own sample.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a literature review on Automated Writing Evaluation (AWE) systems over the last two decades. It does not report an experimental or quasi-experimental intervention using LLMs; instead, it synthesizes prior work.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the topic is writing assessment and feedback, the paper is a literature review, not a primary study implementing a pedagogical intervention or writing process integration with LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a literature review, the study does not report its own quantifiable writing outcome metrics from an intervention; it summarizes previous research instead.""
    }
}"
945,A Hierarchical Bert-based Transfer Learning Approach for Multi-dimensional Essay Scoring,2021,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract mentions a self-collected dataset of Chinese EFL learners’ argumentation (CELA), indicating that participants are English as a Foreign Language learners writing in English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses BERT, a pre-trained transformer model, for automated essay scoring, but there is no experimental or quasi-experimental pedagogical intervention integrating an LLM into writing instruction or learners’ writing processes. It is a modeling study, not an instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on developing and evaluating an automated essay scoring system (multi-dimensional AES) and improving QWK scores compared to baselines. There is no teaching/learning context or writing instruction intervention; it is an assessment/algorithmic performance study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are model performance metrics (quadratic weighted kappa) for scoring essays, not changes in learners’ writing competence or writing-related variables following an LLM-mediated intervention. No experimental measures of instructional effectiveness are described.""
    }
}"
946,A Literature Review of Foreign Studies on the Impact of Call on Second Language Acquisition from 2015,2021,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses second language acquisition and CALL in general but does not specify that the reviewed studies focus on L2 English learners in ESL/EFL/ELL contexts or that English is the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a literature review of empirical studies on computer-assisted language learning (CALL) from 2015. It is not an experimental or quasi-experimental primary study, and it does not specifically focus on LLM-based tools such as ChatGPT or GPT-4.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is broadly on computer-assisted language teaching and second language acquisition, not specifically on writing competence or writing-related variables. The abstract does not indicate that writing is the primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a literature review, the paper does not report its own experimental writing outcome metrics; it synthesizes prior studies instead. This does not meet the requirement for quantifiable writing outcomes from an LLM-mediated intervention.""
    }
}"
947,Digital Storytelling with Chatbots: Mapping L2 Participation and Perception Patterns,2021,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context is an L2 class at a university in South Korea, which strongly suggests EFL learners, but the abstract does not explicitly state that the target language is English. It only refers to “L2” and “L2 goals,” so the specific language cannot be confirmed from the abstract alone.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses a “digital storytelling chatbot system (storybot).” The abstract does not indicate that this chatbot is a large language model or transformer-based generative model (e.g., ChatGPT, GPT-4). It appears to be a rule-based or pre-scripted chatbot focused on narrative interaction, not an LLM-based tool.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on increasing L2 output and reading comprehension via storybot interactions. While students do write messages, the primary reported benefit is reading comprehension and participation, not writing competence or writing-related variables as a central outcome. Writing is not clearly framed as the main instructional focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports participation analytics (amount read vs. written) and survey-based perceptions. It does not report quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity) to assess effectiveness of a writing intervention. Outcomes are mainly participation and perception, with some reading comprehension indication, not structured writing measures.""
    }
}"
948,The Intervention of Internet Technology on Students' English Learning in the Intelligent Era,2021,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese medicine undergraduates learning English as a second language in China (ESL/EFL context). The study explicitly concerns second language learning (SLL) and English learning ability, including English writing ability.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is described as an 'Internet learning system' and 'Internet technology' with AI resources and intelligent learning system, but there is no indication that a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model) is used. It appears to be a general AI/Internet-based learning platform, not an LLM-based writing tool.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing is one of several skills measured (listening, reading, writing, translation), and the primary focus seems to be overall English learning performance, motivation, and anxiety rather than writing competence specifically. Writing-related variables are included but not clearly the primary focus.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes, including English learning performance and subskills such as writing, with statistical comparisons between experimental and control groups (e.g., p<0.01 for writing performance differences).""
    }
}"
949,Research on the Design of Lexical-chunks Centered Mode of Writing under Artificial Intelligence in College English Course,2021,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is situated in a college English course with EFL learners (“college English writing teaching model… for EFL, especially for students with a relatively low language proficiency”), indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions “big data technology” and “artificial intelligence” in general but does not specify the use of large language models (e.g., ChatGPT, GPT-4) or any transformer-based generative model. It appears to be a data-driven monitoring/feedback system rather than an LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on a “college English writing teaching model” and how lexical-chunk-centered instruction affects students’ writing input and output, clearly centering on writing competence in an instructional context.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract notes that big data technology “effectively monitors the learning process” and that lexical chunk teaching “promotes students’ writing input and triggers output,” but it does not report specific quantitative writing outcome measures or experimental results. It is unclear whether structured, quantifiable writing outcomes were collected.""
    }
}"
950,The Listening Strategies of Non English Majors in Colleges and Universities Based on Artificial Intelligence,2021,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are non-English majors in colleges and universities studying English listening, which implies they are L2 English learners in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the title mentions 'based on artificial intelligence', the abstract describes a questionnaire study on listening strategies and metacognitive strategies. There is no indication of an experimental or quasi-experimental design integrating an LLM (e.g., ChatGPT, GPT-4) into instruction or learning processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on listening strategies and listening proficiency, not on writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports questionnaire scores related to listening strategies and performance; there are no quantifiable writing outcome metrics or writing intervention effects.""
    }
}"
951,L2 Learner Cognitive Psychological Factors about Artificial Intelligence Writing Corrective Feedback,2021,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 1,952 undergraduate L2 learners in China, focusing on English writings, which fits ESL/EFL/ELL L2 English learner contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Pigai, described as an AI evaluating system for English writings. Pigai is a traditional automated writing evaluation tool and is not identified as an LLM or transformer-based generative model (e.g., ChatGPT, GPT-4, Gemini). Thus it does not meet the LLM-based intervention requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is AI writing corrective feedback (WCF) and its relation to L2 learner cognitive psychology, clearly centered on writing and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses Likert-scale questionnaires and interviews to examine perceptions, noticing, uptake, initiative, retention, and emotion. It does not report quantifiable writing performance outcomes (e.g., writing scores, quality measures) to assess effectiveness of the AI intervention on writing competence.""
    }
}"
952,Examining the Impact of Grammarly on the Quality of Mobile L2 Writing,2021,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were Japanese L2 English university EFL students, clearly an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Grammarly, described as an intelligent writing assistant with predictive text and real-time corrective feedback. Grammarly is not an LLM-based generative tool like ChatGPT/GPT-4; it is an automated writing evaluation tool and is explicitly listed as an exclusion in the review criteria.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on mobile L2 writing quality and examines grammatical accuracy, lexical richness, writing fluency, and syntactic complexity, all of which are writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative outcomes (descriptive statistics and t-tests) on grammatical errors, lexical variation, fluency, and syntactic complexity, providing measurable writing outcome metrics.""
    }
}"
953,Automated Writing Evaluation (awe) in Higher Education: Indonesian Efl Students' Perceptions about Grammarly Use across Student Cohorts,2021,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Indonesian undergraduate EFL students majoring in English education, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is Grammarly, an Automated Writing Evaluation (AWE) tool. Grammarly is not described as an LLM-based, transformer generative model in this study and is treated as a conventional AWE tool. The focus is on perceptions of Grammarly use, not on integrating an LLM such as ChatGPT, GPT-4, etc.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing classes and the use of Grammarly to assist students’ writing processes (compose and revise their writing), which is directly writing-focused.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines students’ perceptions via questionnaires and interviews. There is no indication of quantifiable writing outcome metrics (e.g., writing scores, text quality measures) assessing effectiveness of the intervention; only perceptions of usefulness and drawbacks are reported.""
    }
}"
954,Going beyond Computer-assisted Vocabulary Learning: Research Synthesis and Frameworks,2020,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to 'foreign language learner' and 'foreign vocabulary' but does not specify English as the target language or identify ESL/EFL/ELL contexts. The population and language focus cannot be confirmed as L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study presents computer-assisted vocabulary learning applications (image recommendation, context representation, location-based word recommendation) within the AIVAS platform. There is no indication that these tools are based on large language models or transformer-based generative models such as ChatGPT, GPT-4, or similar.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on vocabulary learning in informal settings, not on writing competence or writing-related variables. The applications support vocabulary acquisition, image selection, and context representation, with no mention of writing instruction or writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The reported evaluations involve human and data-driven assessments of the vocabulary learning systems, but there is no indication of quantifiable writing outcome metrics or any writing intervention outcomes.""
    }
}"
955,Future Prediction of L2 Writing Performance: a Machine Learning Approach,2020,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 102 students of English Language Teaching in Turkey, clearly L2 English learners in an EFL/ESL-related higher education context, with outcomes explicitly about L2 writing performance.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study trains a machine learning model (Instance-Based Learning with Parameter K) using demographic and psychometric data to predict end-of-term L2 writing performance. There is no indication that a large language model (e.g., ChatGPT, GPT-4) is integrated into writing instruction or writing processes; it is a predictive analytics application, not an LLM-based pedagogical intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on predicting L2 writing performance using machine learning, not on an instructional or intervention context to improve writing competence. The model is used for early detection of potential failure, not as part of a writing pedagogy or feedback process.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although L2 writing performance is measured, the outcomes relate to prediction accuracy of the machine learning model (Pass/Fail prediction), not to the effectiveness of an LLM-mediated writing intervention. There is no experimental manipulation of a writing intervention and no comparison of writing outcomes due to an LLM-based tool.""
    }
}"
956,Efl Writing Tasks and the Application of the Concept of Situatedness: Evaluating the Theoretical and Practical Aspects of the Saudi Efl Context,2020,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Saudi EFL students learning English at Qassim and Bisha Universities, clearly an EFL/ELL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention contrasts conventional written lectures with a virtual online learning environment framed by a Situated Learning approach and a training-technology design framework. There is no indication that large language models (e.g., ChatGPT, GPT-4) or transformer-based generative AI tools are used; technology appears to be a virtual/online environment and e-portfolios, not LLMs.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on improving EFL students’ practical English writing skills through writing tasks in virtual versus conventional settings, aligning with writing competence as the main outcome.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an experimental design with control and experimental groups and reports that the virtual language experience improved participants’ practical English writing skills, implying quantifiable outcome measures (e.g., testing, e-portfolio evaluation).""
    }
}"
957,Detecting Preposition Errors to Target Interlingual Errors in Second Language Writing,2020,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers generally to 'second language learners' and 'second language writing' but does not specify that the target language is English or that participants are ESL/EFL/ELL learners. It may be about other languages with diverse preposition systems.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on developing classifiers and fine-tuned BERT models for preposition error detection as part of a prospective digital writing assistant. There is no indication of an experimental or quasi-experimental pedagogical intervention using an LLM with learners; it is a computational NLP error-detection study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the technical task of preposition error detection and model performance, not on writing instruction or improving learners’ writing competence through an implemented intervention. The envisioned assistant is not empirically tested as a teaching tool.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes or measures of writing improvement are reported. The outcomes concern classifier performance on error detection, not changes in learners’ writing quality following an LLM-mediated intervention.""
    }
}"
958,Bert-based Contextual Semantic Analysis for English Preposition Error Correction,2020,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ESL learners are mentioned, they are only the source of error data (preposition errors). There is no indication of actual participants in an instructional or intervention study; this is a computational error-correction model paper.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study presents a BERT-based preposition error correction model. BERT is a bidirectional encoder model, not a generative large language model used as an instructional tool in writing intervention. There is no experimental or quasi-experimental integration of an LLM into teaching or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on developing an automatic preposition error correction system, not on pedagogical writing instruction or learner-facing writing processes. It is essentially an NLP error-correction/assessment tool, not a writing competence intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No learner writing outcomes or educational effectiveness metrics are reported. The paper evaluates model performance (e.g., matching scores) rather than changes in learners’ writing ability following an intervention.""
    }
}"
959,Research on the Cultivation of Non-english Majors' English Reading Interest: Poa Teaching Mode in the Internet + Era,2020,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are non-English majors engaged in college English reading instruction in China, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is the POA (Production-Oriented Approach) teaching model in an 'Internet +' environment. There is no mention of large language models (e.g., ChatGPT, GPT-4) or any transformer-based generative AI being integrated into instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on English reading interest and reading instruction, not on writing competence or writing-related variables. Writing is only mentioned as one of several skills supported by reading, not as the target of the intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports effects on reading interest, not on quantifiable writing outcomes. No writing performance metrics or writing-related measures are described.""
    }
}"
960,"Exploring the Development of Writing Complexity, Accuracy, and Fluency in Relation to the Motivational Trajectories: a Dynamically-oriented Case Study; 探討與動機軌跡相關的寫作複雜度,正確性和流暢度的發展:一個動態性的個案研究",2020,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participant is described as a 'successful highly motivated EFL learner,' indicating an English-as-a-foreign-language context and thus an L2 English learner.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""In this study, 'LLM' refers to language learning motivation, not large language models. There is no mention of ChatGPT, GPT-4, or any transformer-based generative model, nor any AI-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on the development of writing complexity, accuracy, and fluency (CAF) in L2 writing, clearly centering on writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study quantitatively assesses CAF measures across ten stages of monthly writing assignments, providing quantifiable writing outcome metrics, even though these are not linked to any LLM-based intervention.""
    }
}"
961,Is the Simplest Chatbot Effective in English Writing Learning Assistance?,2020,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract refers to “non-native learners” who have difficulty writing English, indicating an L2 English learner population in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses “the simplest chatbot (such as ELIZA).” ELIZA is a rule-based chatbot and not a transformer-based large language model. Therefore, the study does not integrate an LLM (e.g., ChatGPT, GPT-4, Gemini) into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on English writing learning assistance, examining effects on word usage, self-revision, and amount of writing, which are writing-related variables in a pedagogical context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study empirically compares the number of words produced with a standard editor versus a chatbot-based system and analyzes writing results (word usage and self-revision), indicating quantifiable writing outcome metrics.""
    }
}"
962,A Critical Deconstruction of Computer-based Test Application in Turkish State University,2020,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Turkish EFL university students and their instructors, clearly situated in an English as a foreign language context, with data focused on English proficiency testing (Versant English Test).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates conceptions of the Versant English Test, an automated test using AI software, but there is no indication that it is an LLM-based tool (e.g., ChatGPT, GPT-4) or that it is integrated into writing instruction or writing processes as an intervention. It is an assessment tool, not an LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on perceptions of an automated English test’s reliability, validity, and washback, not on developing writing competence or writing-related pedagogical interventions. Writing is only one component of a broader language test, and the study is not about writing instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a qualitative phenomenological design with interviews and focus groups to explore attitudes and conceptions. It does not report quantifiable writing outcome metrics or evaluate the effectiveness of any LLM-mediated writing intervention.""
    }
}"
963,A Machine Learning Approach to Persian Text Readability Assessment Using a Crowdsourced Dataset,2020,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on Persian text readability assessment and dataset creation. There is no mention of participants, learners, or L2 English learning contexts (ESL/EFL/ELL). The target language is Persian, not English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is a machine learning model for Persian text readability assessment. It is not described as a large language model (e.g., ChatGPT, GPT-4) integrated into instruction; rather, it is a traditional ML readability classifier.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is automated readability assessment of Persian texts, not writing competence, writing instruction, or writing-related pedagogical variables for learners.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No writing outcomes or measures of learners’ writing performance are reported. The study evaluates model accuracy for readability classification, not the effect of an intervention on writing.""
    }
}"
964,Digital Storytelling with Chatbots: Mapping L2 Participation and Perception Patterns,2020,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states the context is an L2 class at a university in South Korea, which strongly suggests EFL learners, but it does not explicitly specify that the target language is English. The focus is on L2 generally, not clearly on English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses a ‘digital storytelling chatbot system’ (storybot). The abstract does not indicate that this chatbot is a large language model or transformer-based generative model (e.g., ChatGPT/GPT-4). Given the 2020 date and lack of technical description, it is unclear whether it is LLM-based.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on L2 output and reading comprehension within narrative chatbot interactions, not specifically on writing competence or writing-related instruction. Students read much more than they wrote, and the study is framed around participation and perceptions, with reading comprehension as the main measured outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports participation analytics (reading vs. writing amounts) and reading comprehension (cohesion between questions and responses), but it does not report quantifiable writing outcome metrics or a structured writing intervention aimed at improving writing quality. Writing is incidental and minimal, and no writing performance measures are described.""
    }
}"
965,"Exploring the Development of Writing Complexity, Accuracy, and Fluency in Relation to the Motivational Trajectories: a Dynamically-oriented Case Study",2020,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participant is described as a 'successful highly motivated EFL learner,' indicating an English-as-a-foreign-language learner and thus an L2 English population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The term 'LLM' in this abstract refers to 'language learning motivation,' not large language models. There is no mention of ChatGPT, GPT-4, or any LLM-based tool, nor any AI-mediated instructional intervention. The study is a CDST-oriented case study of motivation and CAF development, not an LLM-integrated intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on writing-related variables—complexity, accuracy, and fluency (CAF)—in monthly writing assignments, aligning with a primary focus on writing competence and development.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study quantitatively assesses the development of CAF measures over ten stages using descriptive and statistical analyses, providing quantifiable writing outcome metrics (complexity, accuracy, fluency) across time.""
    }
}"
966,Foreign Language Learners’ Preference of E-leaming Methods: an Empirical Study,2020,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are foreign language learners taking English courses (listening, reading, writing, translating, speaking) at Xinhua Colleges, indicating an EFL/ESL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares four e-learning delivery methods (video conferencing, self-recorded videos, MOOC courses, electronic materials by native speakers). There is no mention of large language models or tools like ChatGPT, GPT-4, etc., nor any AI-based generative intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on learners’ preference for different e-learning methods across several skills, not specifically on writing competence or writing-related variables. Writing is only one of several course types considered, and no writing-focused pedagogical intervention is described.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes concern preferences and influencing factors (time, place, network quality, emotional attachment, proficiency, interaction). No quantifiable writing performance or writing outcome metrics are reported.""
    }
}"
967,Research on College English Teaching Strategies and Applications Based on Big Data,2019,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions 'college English teaching in China', which likely involves EFL learners, but it does not explicitly state that participants are L2 English learners or provide details on the learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on 'big data' and a 'new model of college English teaching.' There is no mention of large language models (e.g., ChatGPT, GPT-4) or any transformer-based generative AI being integrated into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on general college English teaching strategies in the era of big data. Writing competence or writing-related variables are not specified as the primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not indicate any quantifiable writing outcome metrics or experimental evaluation of a writing intervention. It appears to be an empirical analysis leading to proposed measures, without specific writing outcome assessment.""
    }
}"
968,Chinese Grammatical Error Correction Based on Convolutional Sequence to Sequence Model,2019,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on Chinese grammatical error correction for learners of Chinese as a second language. The target language is Chinese, not English, so it does not involve L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study introduces a convolutional sequence-to-sequence model (a CNN-based neural model), not a large language model such as ChatGPT, GPT-4, or similar transformer-based generative LLMs. It is a model-development paper, not an LLM-based pedagogical intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""While the task (grammatical error correction) is related to writing, the abstract frames it as an NLP system development and evaluation task, not as an instructional or classroom intervention targeting learners’ writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are system performance improvements over a baseline neural machine translation model, not quantifiable writing outcomes for learners following an LLM-mediated writing intervention.""
    }
}"
969,Application of Artificial Intelligence to the Small Open Online English Abstract Writing Course,2019,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 79 graduate students learning English abstract writing in a SMOOC context, indicating L2 English academic writing as the focus (enhancing graduate students’ English abstract writing skill).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses an AI-assisted writing, grading, and feedback system called Quick Research Papers (QRP). The abstract does not indicate that QRP is a large language model or transformer-based generative model (e.g., ChatGPT/GPT-like). It appears to be an analytics/feedback system rather than an LLM-based generative tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on English abstract writing skills, tracking writing errors, and using AI analytics to guide teaching and consultation, which is clearly centered on writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative writing outcomes are reported: total words written, total errors, and distribution of error types (e.g., noun, spelling, subject-verb agreement). These are measurable writing-related outcome metrics.""
    }
}"
970,"5th Eai International Conference on E-learning, E-education, and Online Training, Eleot 2019",2019,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The proceedings volume includes multiple studies, one of which mentions EFL writing and another college English education, but the abstract is a table-of-contents style summary. It is not clear which specific participant populations are involved or whether they are L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract lists various topics related to MOOCs, online learning, AI, and web-based platforms. None are described as using large language models (e.g., ChatGPT, GPT-4) in an experimental or quasi-experimental writing intervention. The mention of a web-based automatic writing evaluation platform does not indicate an LLM-based tool.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""One paper title mentions “Self-correction’s Effects on EFL Writing on Web-Based Automatic Writing Evaluation Platform,” which is writing-related, but the nature of the intervention and its primary focus (pedagogical vs. system evaluation) are not specified in the proceedings abstract.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The proceedings abstract does not provide methodological details or confirm that any included study reports quantifiable writing outcome metrics. It only lists paper titles without describing outcome measures.""
    }
}"
971,Detection of Non-standard English Expressions by Language Sense,2019,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly mentions Chinese students’ English essays and second language acquisition, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study proposes an algorithm (N-LanSen based on an N-model) for detecting non-standard English expressions. There is no indication that this is a large language model (e.g., transformer-based generative model like ChatGPT/GPT-4). It appears to be a detection algorithm, not an LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on developing and evaluating an algorithm to detect non-standard expressions with high accuracy, not on a pedagogical writing intervention or instructional context. Feedback is mentioned, but only as part of system functionality, not as an implemented teaching intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported concern algorithmic detection accuracy, not quantifiable changes in learners’ writing performance following an LLM-mediated intervention. No experimental writing outcome measures for students are described.""
    }
}"
972,Native Language Identification in Very Short Utterances Using Bidirectional Long Short-term Memory Network,2019,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are Urdu speakers whose native language is being identified from short English L2 speech, but the study is framed as a native language identification (NLI) task, not as L2 English learners in an ESL/EFL/ELL instructional context. There is no indication of an educational or language-learning setting focused on L2 English development.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is a bidirectional long short-term memory (BLSTM) neural network for classification, not a large language model (e.g., ChatGPT, GPT-4) integrated into writing instruction or writing processes. It is a speech-based classification system, not an LLM-mediated pedagogical tool.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on native language identification from very short speech utterances, not on writing competence or any writing-related variables. There is no mention of writing tasks, instruction, or assessment.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No writing outcomes or writing performance metrics are reported. The only quantitative outcomes are classification accuracies for NLI based on speech features, which are unrelated to L2 writing intervention effectiveness.""
    }
}"
973,A Framework of Computer-based Learning System Based on Self-regulated Model in English Writing,2019,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states the system is for English writing in Thai EFL learners, which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper describes a computer-based learning system using components of linguistics and machine translation. There is no indication that the system is based on large language models (e.g., ChatGPT, GPT-4) or transformer-based generative models; it appears to be a general computer-assisted system with machine translation, not an LLM-mediated intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on English writing, with the system designed as an assisting tool for self-regulated learning in English writing and guiding target sentence writing. This aligns with a writing-focused context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as presenting the design phase of a system and aims to collect learners’ behavior and find behavioral patterns. There is no mention of experimental or quasi-experimental evaluation, nor of quantifiable writing outcome metrics assessing the effectiveness of the intervention on writing performance.""
    }
}"
974,An Associativity-agnostic In-cache Computing Architecture Optimized for Multiplication,2019,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper is a hardware/architecture study on in-cache computing for multiplication in machine learning workloads. There are no human participants, no mention of L2 English learners, ESL/EFL/ELL contexts, or any language learning population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention concerns an in-cache computing architecture (BLADE) and its optimization for multiplication. It does not involve large language models (e.g., ChatGPT, GPT-4) or any pedagogical integration of LLMs into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is computer architecture and energy-efficient computation for data-intensive algorithms, not writing competence or writing-related variables. There is no educational or writing-focused setting.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are hardware metrics (performance, area, energy, cycle count) for multiplication operations. No writing outcomes or measures of writing performance are presented.""
    }
}"
975,Automated Writing Evaluation System: Tapping Its Potential for Learner Engagement,2018,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions second language acquisition and L2 generally, but does not specify that the participants are L2 English learners in ESL/EFL/ELL contexts or that the focus is on English rather than other languages.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The title and abstract refer broadly to an automated writing evaluation system and AI technologies, but do not indicate the use of large language models (e.g., ChatGPT, GPT-4) or transformer-based generative models, nor do they describe an experimental or quasi-experimental intervention integrating LLMs into writing instruction.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus appears to be on an automated writing evaluation system and learner engagement, which may relate to writing, but the abstract does not clearly state that the primary focus is on writing competence or writing-related variables within a pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental measures are described in the abstract; it appears to be a conceptual or descriptive discussion rather than a study reporting intervention outcomes.""
    }
}"
976,Application of Sentiment Analysis to Language Learning,2018,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “language learners” and “second or foreign language learning” but does not specify that the target language is English or that participants are ESL/EFL/ELL learners. The target language could be any L2.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is RESOLVE, a context-aware emotion synonym suggestion system using sentiment analysis and machine-learning techniques. There is no indication that it is based on a large language model or transformer-based generative model (e.g., ChatGPT, GPT-4). It appears to be a traditional NLP/sentiment analysis tool rather than an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a writing task and focuses on learners’ use of emotion vocabulary in their writings, aiming to improve vocabulary knowledge and word use in written production. Thus, the primary focus is on writing-related competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""A pedagogical evaluation was conducted using a writing task, and results indicate participants achieved “substantial progress on emotion word use,” implying quantifiable outcome measures of writing performance (emotion word use) were collected.""
    }
}"
977,Supporting Esl Writing by Prompting Crowdsourced Structural Feedback,2017,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly targets support for English as a Second Language (ESL) writing and focuses on non-native speakers, indicating an L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention (StructFeed) relies on crowdsourced annotations and compares them with three naïve machine learning methods for identifying topic and irrelevant sentences. There is no indication that large language models (e.g., ChatGPT, GPT-4, transformer-based generative models) are used; the ML methods appear to be traditional, not LLM-based.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is ESL writing support, focusing on paragraph structure (topic sentence, irrelevant sentence) and writing hints, which are directly related to writing competence and revision outcomes.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that people who received feedback via StructFeed showed the highest improvement after revision, implying quantifiable writing outcome measures (improvement scores) were used to assess effectiveness.""
    }
}"
978,A Tutorial Proposal On: Advanced Technical Communications for Esl Engineers and Ooi,2017,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The course is explicitly designed for English-as-a-Second-Language (ESL) engineers and others of interest, indicating an L2 English learner population in an ESL/EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes an IEEE course on advanced technical writing and presentation skills, with demonstrations of grammatical subtlety, cultural difference, cognitive style, and logical thinking. There is no mention of large language models (e.g., ChatGPT, GPT-4) or any AI-based intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on advanced technical writing and presentation skills for ESL engineers, which is directly related to writing competence and communication skills.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The only outcome reported is a 97% satisfaction rating from participants, which reflects course satisfaction rather than quantifiable writing performance metrics. No experimental measures of writing outcomes are described.""
    }
}"
979,Integrating an Adjusted Conversational Agent into a Mobile-assisted Language Learning Application,2017,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions a mobile-assisted English language learning application and students learning vocabulary in English, implying L2 English learners, but it does not explicitly state that participants are ESL/EFL/ELL learners or provide participant details.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses the chatterbot ALICE, a rule-based conversational agent, not a transformer-based large language model such as ChatGPT, GPT-4, or similar. Therefore, it does not meet the requirement that the intervention integrate an LLM.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is vocabulary learning and general language learning outcomes (motivation, engagement, cognitive skills). Writing is only mentioned as one modality for chatting with the agent, not as a targeted writing competence or writing-focused intervention.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract notes that students can be evaluated by the chatterbot and that the system supports vocabulary practice, but it does not specify any quantifiable writing outcome metrics or structured assessment of writing performance.""
    }
}"
