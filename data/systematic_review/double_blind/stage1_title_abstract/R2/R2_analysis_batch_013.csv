Title,Year,Decision,Notes
Engagements with Gpt Responses and Learner Prompts in Chatgpt-based Learning of English Argumentative Writing Logic and Their Impacts,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 42 Chinese university students learning English as a foreign language (EFL). The focus is explicitly on English argumentative writing logic, so the population is L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study developed a discipline-specific GPT-4-powered chatbot for learning English argumentative writing logic. Learners used this ChatGPT-based tool as the core of the instructional intervention, indicating an experimental design integrating an LLM into writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on learning English argumentative writing logic, a key component of writing competence. The intervention is a ChatGPT-based learning environment for argumentative writing, not an automated scoring or purely functional evaluation of the model.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Learning outcomes were assessed via pre-post-delayed tests and pre-post writing tasks, providing quantifiable measures of writing-related performance (logic knowledge and writing logic). Thus, the study reports experimental outcome metrics for the LLM-mediated writing intervention.""}}"
Enhancing Writing Skills through Ai-powered Tools: Perceived Benefits and Challenges among Vietnamese Efl Students,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Vietnamese EFL students: \u201cEnglish-majored students at a university in Vietnam\u2026 in enhancing their writing skills in EFL classes,\u201d which fits L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although students use AI tools such as ChatGPT, QuillBot, and Claude, the study is observational and perception-based. There is no experimental or quasi-experimental design integrating LLMs as a structured writing intervention; it only surveys existing usage and perceptions.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on writing: \u201cusing AI-powered tools in enhancing their writing skills in EFL classes\u2026 complex academic writing tasks\u2026 across nearly all stages of the writing process,\u201d so the primary context is writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are perceptions and correlations about perceived benefits, not objective or experimental writing performance measures. The abstract reports \u201cperceived writing benefits\u201d and a correlation between frequency of AI use and perceived benefits, but no quantifiable writing outcome metrics (e.g., scores, rubric-based writing gains) from an intervention.""}}"
Academic Socialization with Generative Ai: a Longitudinal Case Study of an L2 Graduate Student's Academic Literacies Development,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participant is described as an international, English as a Second Language graduate student. The context is clearly L2 English academic discourse socialization, so the population criterion is met.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study involves the learner leveraging ChatGPT (an LLM) for academic literacy development. However, it is framed as a longitudinal case study of naturally occurring use rather than an experimental or quasi-experimental intervention. There is no mention of a designed instructional treatment, control/comparison, or structured pedagogical integration beyond the learner\u2019s own use.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although writing support is mentioned, the primary focus is broader academic socialization and academic literacies (reading, exploring genres, navigating disciplinary expectations, generating research ideas, identity, confidence). Writing competence is only one of several aspects and not the central evaluative focus of the study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports qualitative outcomes such as research interest, genre knowledge, disciplinary identity, and confidence. There is no indication of quantifiable writing outcome metrics or experimental measures of writing performance; data sources are interviews, surveys, and ChatGPT records, used qualitatively.""}}"
Evaluating the Potential of Chatgpt-reformulated Essays as Written Feedback in L2 Writing,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study uses 1,200 argumentative essays written for the TOEFL iBT independent writing task, which are produced by L2 English learners preparing for or taking an English proficiency test. The focus is clearly on L2 English writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study evaluates ChatGPT\u2019s ability to reformulate existing L2 essays and compares different prompts, but there is no indication of an experimental or quasi-experimental pedagogical intervention where learners use LLMs as part of instruction or writing processes. It is a tool-performance study, not an instructional intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the context is L2 writing and written corrective feedback, the study focuses on assessing ChatGPT-generated reformulations (meaning retention and linguistic development) rather than implementing and evaluating a teaching/learning intervention that targets learners\u2019 writing competence over time.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported (ROUGE-L, syntactic complexity, lexical sophistication/diversity, cohesion) are applied to ChatGPT\u2019s reformulations versus original essays, not to learners\u2019 post-intervention writing performance. There is no quantifiable measure of learner writing gains resulting from an LLM-mediated intervention.""}}"
"The Role of Techno-competence in Ai-based Assessments: Exploring Its Influence on Students’ Boredom, Self-esteem, and Writing Development",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were 66 Saudi Arabian male EFL learners, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cAI-driven evaluations\u201d and \u201cAI-enhanced assessments\u201d but does not specify the AI technology (e.g., ChatGPT, GPT-4, or any LLM-based system). It could be non-LLM automated assessment. Without explicit mention of LLMs or transformer-based generative models, it is unclear whether the intervention uses an LLM.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""Writing skills/proficiency is one of the primary outcome variables, and the intervention is situated in language assessment with a focus on writing development, satisfying the writing-related context requirement.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although pre- and post-assessments of writing proficiency are mentioned, the AI component is described only as part of assessment, not as a writing instruction or process intervention mediated by an LLM. The study evaluates AI-based assessment effects on boredom, self-esteem, and writing, but not an LLM-mediated writing intervention as required. Given the unclear LLM use and assessment-focused design, it does not meet the specified outcome criterion for LLM-mediated writing intervention.""}}"
Predictors of Childhood Vaccination Uptake in England: an Explainable Machine Learning Analysis of Regional Data (2021–2024),2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The study analyzes district-level childhood vaccination coverage in England using NHS records and geographic, demographic, socioeconomic, and cultural variables. It does not involve L2 English learners in ESL/EFL/ELL contexts; English proficiency is only a predictor variable in a public health dataset.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is not educational and does not involve integrating large language models into writing instruction. The study uses CatBoost (a gradient boosting algorithm) and SHAP for explainable machine learning, not LLMs such as ChatGPT or GPT-4.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The context is public health and vaccination uptake, not writing competence or writing-related variables. There is no focus on writing instruction, writing processes, or language learning tasks.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No writing outcomes are reported. The outcomes concern vaccination coverage and predictors of disparities, with no assessment of writing performance or writing-related measures.""}}"
Tracking the Effects of Gemini as a Genai Tool on L2 Learners' Writing Proficiency and Anxiety: Latent Growth Curve Modeling Approach,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were 274 undergraduate English learners in Iran enrolled in academic writing classes. The context is clearly L2 English (EFL) learners, and the focus is on English writing proficiency and anxiety.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses Gemini, explicitly described as a generative AI (GenAI) tool, in a treatment group receiving GenAI-assisted instruction versus a control group with traditional instruction. Gemini is a large language model, and the design is experimental with random assignment.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on L2 writing competence and related affective variables: writing proficiency and writing anxiety in academic writing classes. Gemini is integrated into writing instruction, not just for scoring or evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcomes: writing proficiency measured via a standardized rubric-based assessment and writing anxiety via an L2 writing anxiety scale, with statistical results (MD, SE, CR, p-values) comparing treatment and control groups over time.""}}"
Exploring Factors Influencing L2 Learners' Use of Gai-assisted Writing Technology: Based on the Utaut Model,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 419 graduate students in China using GAI for second language writing, indicating L2 English learners in an EFL context, though the target language is implied rather than explicitly stated.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is framed with the UTAUT model and investigates factors influencing L2 learners\u2019 usage behavior of GAI. It is a technology acceptance/usage study, not an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction or writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on determinants of GAI usage (performance expectancy, effort expectancy, social influence, etc.), not on improving writing competence or writing-related performance through an instructional intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes are behavioral intention and actual usage behavior of GAI, not measures of writing quality, accuracy, complexity, or related writing performance indicators.""}}"
Exploring Second Language Writers' Engagement with Chatgpt Feedback: Revision Behaviors and Perceptions,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 25 B1-level English as a Foreign Language (EFL) university students in T\u00fcrkiye, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""ChatGPT (an LLM) is used as a feedback tool on students\u2019 opinion essays, but the abstract does not specify an experimental or quasi-experimental design (e.g., no control/comparison group, no pre-post intervention structure is mentioned). It appears more exploratory/descriptive than an intervention study.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on L2 writing, specifically how EFL writers engage with ChatGPT feedback when revising opinion essays. The context is clearly writing competence and revision behavior, not automated scoring.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study analyzes revision behaviors (acceptance/rejection of feedback, types of revision operations) and perceptions via questionnaires and interviews. There is no indication of quantifiable writing outcome metrics (e.g., changes in writing quality scores, accuracy, complexity) to assess effectiveness of the ChatGPT-mediated intervention.""}}"
Using Chatgpt to Bring Non-player Characters to Life: Effects on Students' Storyline-driven Game-based Writing Learning,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Chinese undergraduate students in English as a Foreign Language (EFL) writing classrooms, clearly indicating L2 English learners in an EFL context with a focus on English writing.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study integrates ChatGPT, an LLM, into a game-based learning environment via ChatGPT-powered NPCs. It uses a quasi-experimental design comparing a ChatGPT condition with a conventional NPC condition, constituting an LLM-mediated instructional intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is explicitly EFL writing classrooms, with the game designed to enhance argumentative writing skills. The primary focus is on writing learning and writing performance, not on automated scoring or system evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantitative writing outcomes: student essays were evaluated to compare writing performance, with findings that the ChatGPT group produced clearer, more elaborated, more persuasive essays that better addressed opposing viewpoints. These are measurable writing performance metrics.""}}"
Chinese Efl Learners' Genai Literacy in Digital Multimodal Composing and Self-regulated Writing: Chain Mediation Effects of Needs Satisfaction and Creative Self-concept,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as 634 Chinese EFL learners, which fits the target population of L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines students\u2019 \u2018GenAI literacy in digital multimodal composing\u2019 via questionnaires; there is no indication of an experimental or quasi-experimental intervention where an LLM (e.g., ChatGPT, GPT-4) is integrated into writing instruction or tasks. It is a correlational/structural equation modeling study of literacy and psychological variables, not an LLM-mediated instructional intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is EFL writing, focusing on digital multimodal composing and self-regulated writing, which are writing-related constructs and align with the review\u2019s focus on writing competence and related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are self-report measures (GenAI literacy, needs satisfaction, creative self-concept, self-regulated writing) analyzed via SEM. There are no quantifiable writing performance outcomes (e.g., text quality, accuracy, complexity) from an LLM-mediated writing intervention; the study is about psychological mediation, not measured changes in writing performance.""}}"
Exploring the Effectiveness of a Ddl-genai Teaching Mode in Students' Efl Writing Classroom,2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 75 second-year Chinese university students in an EFL writing classroom, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract describes an intervention integrating Data-Driven Learning with Generative Artificial Intelligence (GenAI) and mentions a separate GenAI class. However, it does not specify whether the GenAI tools are large language models (e.g., ChatGPT/GPT-based) or other non-LLM generative tools. Without explicit mention of LLM-based systems, it is unclear if the intervention meets the LLM criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on EFL expository writing performance and related variables (structure, content quality, efficiency, engagement) within a writing classroom, indicating a writing-focused pedagogical context rather than automated scoring or non-instructional evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses a quasi-experimental design with three instructional modes and reports that the DDL-GenAI mode significantly improved students\u2019 writing performance, including specific aspects such as structure and content quality, implying quantifiable writing outcome measures.""}}"
Students' Perceptions of Multiliteracies Development Using Ai-assisted Portfolio Assessment,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 50 freshmen students in an EFL classroom, indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract states that the classroom is 'GenAI-supported' and mentions 'AI-generated feedback', but does not specify that the AI is an LLM (e.g., ChatGPT, GPT-4) or provide details about the underlying technology. It could be any GenAI tool.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on multiliteracies, multimodal competence, and portfolio-based multiliteracies development, not specifically on writing competence or writing-related variables. Writing is one component of multimodal artefacts, but the outcomes and discussion center on multiliteracies, metacognition, and professional growth rather than writing performance.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study employs a qualitative design using reflective journals, focus group interviews, and narrative inquiries, analyzed thematically. No quantifiable writing outcome metrics or experimental/quasi-experimental measures of writing performance are reported.""}}"
"Impacts of Genai-assisted Collaborative Prewriting on University Efl Students' Interactions with Genai, Outline Quality, and Task Motivation",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 69 Chinese undergraduates in an EFL context, and the study explicitly concerns English as a foreign language (EFL) writing instruction, so the population is L2 English learners.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study integrates a GenAI tool (a generative AI, i.e., LLM-type system) into prewriting instruction via GenAI-assisted collaborative prewriting (GACP) and GenAI-assisted individual prewriting (GAIP) in a within-subjects comparative design.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on prewriting/outline generation, students\u2019 interactions with GenAI, outline quality, and task motivation. It does not examine actual writing competence or written text performance as an outcome, but rather planning artifacts (outlines) and motivational variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Quantitative outcomes are reported for outline quality (content, organization, language) and task motivation, but not for writing performance or writing-related competence measures. The review requires quantifiable writing outcome metrics; here, only prewriting outline quality and motivation are assessed, not the quality of produced texts.""}}"
"The Role of Generative Ai in Writing Doctoral Dissertation: Perceived Opportunities, Challenges, and Facilitating Strategies to Promote Human Agency",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly situates the work in ESL and EFL academic writing contexts and involves doctoral scholars and thesis supervisors, implying participants are L2 English users in higher education.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study explores perceived usefulness and use of \u2018GenAI-assisted dissertation writing\u2019 but does not describe an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into instruction. It is framed as a perception study using survey and test data, not as a structured pedagogical intervention with controlled use of an LLM.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on perceived opportunities, challenges, and strategies related to GenAI in dissertation writing, framed through the Technology Acceptance Model and human agency. It does not describe a targeted writing competence intervention or instructional design; rather, it discusses attitudes and institutional implications.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports qualitative perceptions (perceived usefulness, challenges, technological singularity syndrome) and does not mention quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity) resulting from an LLM-mediated intervention.""}}"
Evaluating Chatgpt's Effectiveness in Enhancing Argumentative Writing: a Quasi-experimental Study of Efl Learners in Pakistan,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Pakistani secondary school students in an English as a Foreign Language (EFL) environment, explicitly focusing on English argumentative writing skills for SSC students.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses ChatGPT, explicitly identified as an artificial intelligence tool, as an intervention over three months. It is described as a quasi-experimental study with ChatGPT interaction integrated into learning, satisfying the LLM-based instructional intervention requirement.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on improving argumentative writing skills, including key components of argumentative writing and error types, clearly situating the study in writing competence rather than automated scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study employs a quasi-experimental pre-test/post-test design to measure changes in argumentative writing abilities and error types, reporting significant progress and decreased errors as quantifiable writing outcomes.""}}"
Assessing the Reliability and Relevance of Deepseek in Efl Writing Evaluation: a Generalizability Theory Approach,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL learners: 92 CET-4 essays written by non-English majors in China, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""DeepSeek-V3 and R1 are used as automated raters to score and provide feedback on existing essays. There is no experimental or quasi-experimental instructional intervention integrating the LLM into learners\u2019 writing processes or teaching; the focus is on assessment reliability and feedback characteristics.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on writing assessment reliability and feedback relevance (G-theory analysis of scores and feedback) rather than on a pedagogical writing intervention or development of writing competence. It evaluates DeepSeek as an assessment tool, not as part of a teaching/learning intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable learner writing outcomes or pre/post measures are reported. The study analyzes reliability coefficients and feedback relevance, not changes in students\u2019 writing performance resulting from an LLM-mediated intervention.""}}"
Ai Partner Versus Human Partner: Comparing Ai-based Peer Assessment with Human-generated Peer Assessment in Examining Writing Skills,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as EFL college students from the University of Diyala (Iraq) and the University of Hradec Kralove (Czech Republic), indicating L2 English learners in EFL/ESL contexts with a focus on English writing skills.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention contrasts traditional peer assessment (group A) with AI-based assessment using ChatGPT (group B). ChatGPT is a large language model integrated into the peer assessment process, constituting an LLM-mediated writing intervention with a quasi-experimental comparison between groups.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on improving and examining EFL students\u2019 writing skills through peer assessment. The study compares human versus AI-based feedback mechanisms specifically in relation to writing performance, not for automated scoring alone or non-pedagogical evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Quantifiable writing outcomes are reported: final writing scores for group A range from 7 to 14 out of 15, and for group B from 6 to 12 out of 15. The abstract notes improvement in writing skills in both groups and significant differences between conditions, indicating measurable writing outcomes.""}}"
"Integrating Flipped Learning in Ai-enhanced Language Learning: Mapping the Effects on Metacognitive Awareness, Writing Development, and Foreign Language Learning Boredom",2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were 70 intermediate Iranian EFL learners, clearly indicating L2 English learners in an EFL context, with outcomes including writing development in English.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract repeatedly refers to an \u201cAI-enhanced\u201d flipped learning environment and \u201cAI-enhanced instruction,\u201d but does not specify the AI tool or whether it is an LLM (e.g., ChatGPT, GPT-4) versus other AI (e.g., grammar checkers, analytics). Without explicit mention of an LLM or transformer-based generative model, it is impossible to confirm that the intervention meets the LLM criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""One of the primary variables is \u201cwriting development,\u201d and pre- and post-intervention writing tasks were used, indicating that writing competence is a central focus of the intervention, not just assessment or non-pedagogical use.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses a quasi-experimental design with pre- and post-intervention writing tasks and analyzes inter-group differences via ANCOVA. This implies quantifiable writing outcome metrics were collected to evaluate the effect of the AI-enhanced flipped learning intervention on writing development.""}}"
Exploring Teacher Perspectives on Gpt in L2 Disciplinary Academic Writing through the Lens of Feedback Literacy: a Q-methodology Approach,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The participants are 27 L2 university instructors, not L2 English learners. The study focuses on teacher perspectives and teacher feedback literacy rather than on data from L2 learners themselves.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although GPT/LLMs are the topic, the study is a Q-methodology investigation of teacher perspectives and does not describe an experimental or quasi-experimental design where LLMs are integrated as an intervention in learners\u2019 writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The context is L2 disciplinary academic writing education, but the primary focus is on teacher feedback literacy, ethical considerations, and policy, not on implementing a concrete LLM-mediated writing pedagogy with learners.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported. The study analyzes teacher perspectives via Q-sorts and interviews, without measuring changes in learners\u2019 writing performance or related quantitative outcomes.""}}"
