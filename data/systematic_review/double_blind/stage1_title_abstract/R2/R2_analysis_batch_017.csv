Title,Year,Decision,Notes
Investigating a Customized Generative Ai Chatbot for Automated Essay Scoring in a Disciplinary Writing Task,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are engineering students in a disciplinary English course at a university in Hong Kong, which implies L2 English learners in an EFL/ESL academic context. The writing is in English and assessed by English teachers.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses a customized GenAI chatbot for automated essay scoring (AES) and examines correlations between chatbot scores and teacher scores. There is no experimental or quasi-experimental instructional intervention integrating the LLM into writing instruction or writing processes; it is an assessment/validation study.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on the functionality and validity of GenAI for automated essay scoring (correlations between chatbot and teacher scores), not on improving writing competence or implementing a pedagogical writing intervention. This fits the excluded category of studies evaluating LLMs as AES systems.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although quantitative writing scores are reported, they are used solely to evaluate the chatbot\u2019s scoring performance, not as outcomes of an LLM-mediated writing intervention. There is no pre/post or comparative design assessing changes in learners\u2019 writing due to LLM use.""}}"
Attitudes of Pakistani Undergraduate Esl Students Toward Artificial Intelligence in Improving English Writing Skills,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Pakistani undergraduate ESL students, clearly identified as English as a Second Language learners, and the focus is on English writing skills.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines attitudes toward AI in general and AI adoption, not a specific LLM-based tool (e.g., ChatGPT, GPT-4) within an experimental or quasi-experimental instructional design. No particular LLM intervention is described.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is explicitly English writing skills and how AI might improve them, so the primary focus is on writing competence and related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports attitudes, perceived usefulness, ease of use, motivation, and engagement, but does not report quantifiable writing outcome measures or evaluate the effectiveness of an AI/LLM-mediated writing intervention.""}}"
Exploring the Efficacy of Chatgpt-4 Feedback in Second Language Spanish Writing,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are described as advanced Spanish learners in an L2 Spanish writing context. The focus is on Spanish as the target language, not English (ESL/EFL/ELL). Therefore, the population does not meet the review\u2019s requirement of L2 English learners.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study integrates ChatGPT-4, a large language model, into a writing intervention: students receive AI-generated, rubric-aligned feedback on their drafts and then revise. This constitutes an LLM-mediated instructional intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on writing development in L2 Spanish, with AI-generated feedback on argumentation, linguistic concepts, research and analysis, grammar and language, and structure and formality. This is clearly a writing-focused pedagogical context.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract labels the study as qualitative and emphasizes thematic analysis of questionnaires, revisions, and reflections. While participants completed pre- and post-treatment questionnaires and a formal writing task, the abstract does not clearly state that quantifiable writing outcome metrics (e.g., scores, rubric ratings) were analyzed to assess effectiveness, so it is unclear whether C4 is met.""}}"
Efl Learners’ Perceptual Perezhivaniya and Actual Writing Revision Behaviors Mediated by Genai: a Sociocultural Theory Perspective,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are nineteen EFL learners at a university in Southern China, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract states that learners revised L2 continuation writing tasks \""using GenAI\"" but does not specify that the GenAI tool is an LLM (e.g., ChatGPT/GPT-based) rather than another form of generative AI. The specific technology and model type are not identified.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on L2 writing revision processes (word choice, content, discourse, syntax, errors, alignment, typographic elements) mediated by GenAI, clearly centering on writing competence and writing-related behaviors rather than automated scoring.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses interviews, Q-methodology, and Translog screen recordings to explore revision processes and the alignment between perceived experiences and actual revision behaviors. The abstract does not report any quantifiable writing outcome metrics (e.g., writing quality scores, accuracy gains) assessing the effectiveness of the GenAI-mediated intervention; it focuses on process and perceptions, not outcome measures.""}}"
Automated Scoring in the Era of Artificial Intelligence: an Empirical Study with Turkish Essays,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are learners of Turkish as a second language; the target language is Turkish, not English. The review focuses on L2 English learners in ESL/EFL/ELL contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""GPT-4o is used as an automated scoring engine via a custom interface. There is no indication of an instructional or quasi-experimental pedagogical intervention integrating the LLM into writing instruction or writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on automated essay scoring reliability and validity (alignment between human and AI scores), not on improving writing competence or writing-related learning outcomes through an intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports scoring agreement metrics (Quadratic Weighted Kappa, Pearson correlation, overlap) but does not report quantifiable writing outcome measures resulting from an LLM-mediated writing intervention.""}}"
Can Chatgpt Serve as a Writing Collaborator? Insights from Chinese Efl Learners,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Chinese EFL learners at a tier-one university in China with over ten years of English learning experience and upper-intermediate English proficiency. The context is clearly L2 English learning (EFL).""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study explicitly investigates how Chinese EFL learners interact with ChatGPT, a large language model, in an argumentative writing task. ChatGPT is integrated into the writing process as a collaborator, satisfying the LLM-based intervention criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on L2 argumentative writing: how student\u2013chatbot collaboration affects the writing process and the quality of the final writing products, as well as perceptions of ChatGPT as a writing collaborator. This is clearly about writing competence and writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although the abstract mentions examining the influence of collaboration on the \u2018quality of writing\u2019 and analyzing final writing texts, it specifies that data were \u2018qualitatively analysed\u2019 and emphasizes interaction modes and perceptions. There is no indication of experimental or quasi-experimental design, control/comparison conditions, or reported quantitative writing outcome metrics. The study appears to be qualitative and exploratory rather than an intervention study with measurable writing gains.""}}"
Large Language Models Fall Short in Classifying Learners’ Open-ended Responses,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 143 Japanese university students studying English as a foreign language (EFL), which fits the target population of L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""LLMs are used to classify learners\u2019 open-ended responses about their essay-writing process, not as part of an instructional or experimental writing intervention. There is no integration of LLMs into writing instruction or learners\u2019 writing processes as a pedagogical tool.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on the methodological accuracy of LLMs in qualitative data classification (self-regulated learning categories), not on improving writing competence or writing-related performance through an intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports Cohen\u2019s kappa for agreement between LLMs and human coders, but does not report any quantifiable writing outcome metrics (e.g., writing quality scores, complexity, accuracy) resulting from an LLM-mediated writing intervention.""}}"
"Enhancing Efl Writing with Visualised Genai Feedback: a Cognitive Affective Theory of Learning Perspective on Revision Quality, Emotional Response, and Human-computer Interaction",2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as EFL learners, indicating second language English learners in an EFL context. The focus is on their English writing and revision performance.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses a self-developed GenAI-powered writing chatbot based on large language models to provide feedback during revision. A 2\u00d72 quasi-experimental design compares visualised vs. non-visualised GenAI feedback, integrating LLMs into writing instruction/processes.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on EFL writing performance, specifically revision quality (coherence and cohesion) and related variables (emotional response, cognitive load) within GenAI-assisted writing instruction.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcomes via pre- and post-tests, showing that visualised feedback significantly improved coherence and cohesion in learners\u2019 writing, alongside measured emotional and cognitive load outcomes.""}}"
Examining Longitudinal Development of Writing Motivation in the Genai Context: a Self-determination Theory Perspective,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as '261 Chinese EFL student writers,' clearly indicating L2 English learners in an EFL context with a focus on English writing.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to 'GenAI-supported writing contexts' and 'GenAI scaffolds psychological needs,' but does not specify that the GenAI is a large language model (e.g., ChatGPT, GPT-4) or detail the nature of the tool. It is unclear whether the intervention is explicitly LLM-based.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on 'development of motivation' and four SDT constructs (autonomy, competence, relatedness, identified regulation) in GenAI-supported writing contexts. There is no indication that writing competence or writing performance is a main outcome; the emphasis is motivational, not on writing ability.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports 'motivational gains over time' and curvilinear trajectories of motivation, but does not mention any quantifiable writing outcome metrics (e.g., writing scores, text quality measures). Outcomes are psychological (motivation), not writing performance.""}}"
"Mastering Efl Writing with Chatgpt: a Systematic Review of Benefits, Challenges, and Best Practices",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly focuses on EFL students and their English writing skills, which fits the target population of L2 English learners in EFL contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The article is described as a systematic review drawing on 21 studies about ChatGPT in EFL writing, not as an experimental or quasi-experimental primary study implementing an LLM-based intervention itself. Review articles are to be excluded.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The review\u2019s primary focus is on EFL writing instruction and writing-related outcomes (accuracy, vocabulary, fluency, coherence) when using ChatGPT, aligning with the writing competence context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although the review summarizes effects on writing outcomes, it does not itself report original experimental or quasi-experimental outcome data; as a secondary synthesis, it falls under review articles, which are excluded by the protocol.""}}"
Exploring High School Students’ Preferences for English Writing Feedback: Non-native English Teacher Vs. Native English Teacher Vs. Chatgpt,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are high school students in Korea in an English newspaper club, clearly an EFL context with English as the target language.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used to provide feedback, the design focuses on comparing feedback preferences (non-native teacher vs native teacher vs ChatGPT) rather than an instructional or quasi-experimental intervention aimed at improving writing performance. It is essentially a preference/comparison study, not a structured LLM-mediated writing intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on students\u2019 preferences and perceptions of different feedback sources, not on developing or evaluating a pedagogical writing intervention. Writing competence or related skills are not the central outcome; instead, attitudes toward feedback providers are.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The quantitative data consist of Likert-scale ratings of feedback sources and statistical comparisons of these ratings. There is no report of quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity) following LLM-mediated intervention.""}}"
An Ai-assisted Critical Thinking Intervention to Enhance Undergraduate Efl Learners’ Writing Proficiency,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 250 undergraduate EFL learners from three public universities. The context is explicitly EFL, and the abstract focuses on English as the target language in writing proficiency and CT-oriented writing practices.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses an AI-assisted critical thinking-oriented writing intervention supported with ChatGPT. ChatGPT is a large language model, and the design is experimental (pretest-posttest single-group), integrating the LLM into writing instruction/practice.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on writing proficiency and CT as reflected in writing. ChatGPT is used as a scaffolding tool for CT-oriented writing training in EFL contexts, clearly centering on writing pedagogy rather than automated scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study employs pre-post writing tests evaluated across nine dimensions (clarity, accuracy, precision, relevance, depth, breadth, logic, significance, fairness) and reports that the intervention significantly enhanced students\u2019 CT reflected in writing, providing quantifiable writing outcome metrics.""}}"
"Generative Ai Is Useful for Second Language Writing, but When, Why, and for How Long Do Learners Use It?",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly states that the participants are L2 learners of English, indicating an L2 English learner population in a second language writing context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study investigates how L2 learners utilize ChatGPT, a large language model, during a writing task, indicating integration of an LLM into the writing process. However, it is observational rather than experimental in design.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on L2 writing processes and how ChatGPT is used for idea generation, grammar/word search, polishing, and example generation, which are all writing-related activities.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports frequency and time-series analyses of ChatGPT use and semantic network analyses of perceptions, but it does not mention any quantifiable writing outcome metrics (e.g., writing quality scores, accuracy, complexity) or an intervention effect. The study is descriptive/observational rather than assessing effectiveness of an LLM-mediated writing intervention.""}}"
From Feedback to Artificial Intelligence: a Bibliometric Mapping Analysis of the Thematic Evolution of Efl Writing Assessment Research Trends (2014–2024),2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The article is a bibliometric mapping analysis of published research on EFL writing assessment, not an empirical study with a defined participant population of L2 English learners. It aggregates literature from Scopus rather than reporting on specific learners in ESL/EFL/ELL contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""This is a review/bibliometric study and does not implement any experimental or quasi-experimental intervention using LLMs in writing instruction. AI and automated writing evaluation are mentioned only as emerging themes in the literature, not as an intervention in the study itself.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on mapping research trends in EFL writing assessment, not on conducting a pedagogical intervention targeting writing competence. It is a meta-level analysis of topics such as feedback and assessment, not a study of an instructional context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported. The study analyzes publication patterns, themes, and networks, rather than measuring changes in learners\u2019 writing performance following an LLM-mediated intervention.""}}"
"Integrating Ai in Pakistani Esl Classrooms: Teachers’ Practices, Perspectives, and Impact on Student Performance",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 100 undergraduate students in Pakistani ESL classrooms, clearly English L2 learners in an ESL context. The study focuses on English vocabulary and writing skills.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses AI tools such as Grammarly and QuillBot. These are not described as large language model\u2013based tools (e.g., ChatGPT, GPT-4, Gemini) and are typically categorized as non-LLM writing assistants in this review\u2019s criteria, so the study does not meet the requirement of integrating LLMs into instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is ESL instruction with a focus on vocabulary and writing skills. Writing performance is a primary outcome, aligning with writing competence as a central focus rather than automated scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcomes: pre- and post-tests on writing skills, with a reported +46% gain and effect size (d=1.03) for the experimental group, satisfying the requirement for measurable writing outcomes.""}}"
Investigating the Role of Ai Tool Interactions in Enhancing English Language Acquisition among Saudi College Students,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Saudi college students learning English as a second language in an EFL context, and the focus is explicitly on English language acquisition.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is mentioned, the study is a qualitative investigation using semi-structured interviews about how students use AI tools. There is no experimental or quasi-experimental design integrating ChatGPT into instruction; it is an exploratory, interview-based study of existing practices and perceptions.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""Students reportedly use ChatGPT primarily for writing assistance, brainstorming, and translation, but the study\u2019s primary focus is on general language acquisition, AI literacy, attitudes, and institutional support, not on a structured writing intervention or writing competence as the main outcome.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study employs a qualitative design with thematic analysis of interviews and does not report any quantifiable writing outcome metrics or measured changes in writing performance following an LLM-mediated intervention.""}}"
A Comparative Study of Human and Ai-assisted Assessment Using Chatgpt: the Case of Moroccan Efl Learners,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study uses writing assignments from EFL classes in Moroccan higher education, indicating participants are L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT-4 is used solely as an AI-assisted grader to compare AI and human assessment. There is no experimental or quasi-experimental instructional intervention integrating the LLM into writing instruction or the writing process.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on summative e-assessment and the comparability of AI vs. human grading. It evaluates ChatGPT-4 as an automated essay scoring system, not as part of a pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports grading score differences between AI and human raters, but not as outcomes of an LLM-mediated writing intervention. No writing development or change in writing performance due to LLM use is measured.""}}"
Preserving Authorial Voice in Academic Texts in the Age of Generative Ai: a Thematic Literature Review,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract notes that the review is particularly relevant in ESL university settings and that most synthesized studies were conducted there, implying a focus on L2 English learners. However, as a literature review, it aggregates various studies and does not itself report primary data on a specific L2 learner population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""This is explicitly described as a thematic literature review synthesizing 18 scholarly papers. It does not report an experimental or quasi-experimental intervention integrating LLMs into writing instruction; instead, it summarizes existing work and pedagogical implications.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the topic concerns academic writing, authorial voice, and AI writing tools, the article is a review, not a primary study implementing a writing-focused LLM intervention in an instructional context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not report any original quantitative writing outcome measures. It synthesizes empirical findings from other studies and discusses stylistic differences and pedagogical implications, which falls outside the requirement for primary, quantifiable writing outcomes from an LLM-mediated intervention.""}}"
"A Q Method Study on Turkish Efl Learners’ Perspectives on the Use of Ai Tools for Writing: Benefits, Concerns, and Ethics",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Turkish English language learners enrolled in an EFL preparatory program at a state university in Istanbul, clearly fitting an L2 English EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a Q methodological investigation of learners\u2019 perspectives on AI tools. It does not describe an experimental or quasi-experimental pedagogical intervention integrating a specific LLM (e.g., ChatGPT) into instruction; rather, it surveys existing usage and attitudes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on perceptions of benefits, concerns, and ethics regarding AI tools in writing, not on a structured writing intervention or instructional design aimed at improving writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported. The study uses Q methodology and qualitative interviews to explore perspectives, without measuring changes in writing performance or related quantitative outcomes.""}}"
From Struggle to Mastery: Ai-powered Writing Skills in Esl Education,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 10th grade ESL learners in a bilingual secondary school in Colombia, explicitly described as ESL students working on academic writing in English.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study integrates AI-powered tools, specifically Grammarly and ChatGPT, within the Writing Workshop Instructional Model. ChatGPT is an LLM, but Grammarly is not. The abstract does not specify whether the experimental evaluation isolates or quantifies the effect of the LLM component (ChatGPT) as opposed to the combined AI package, nor does it clearly describe an experimental or quasi-experimental design (it is framed as design-based research). It is unclear whether there is a structured LLM-mediated intervention with measurable, attributable effects.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on improving academic writing skills, including grammar accuracy, textual coherence, and organizational structure, within a writing instructional model. The context is clearly writing instruction rather than automated scoring or system evaluation.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although the abstract states that combining WWIM with AI feedback 'significantly improved students\u2019 academic writing performance' and mentions improved grammar accuracy, coherence, and organization, it does not report or clearly indicate the use of quantifiable writing outcome metrics (e.g., test scores, rubric-based ratings, statistical results). The description is general and could reflect qualitative or mixed findings without explicit experimental measures. Based on the abstract alone, the presence of structured, quantifiable outcome metrics is not sufficiently clear.""}}"
