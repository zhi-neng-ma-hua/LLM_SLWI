Title,Year,Decision,Notes
The Impact of Automated Writing Evaluation on Writing Gains,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 105 first-year university students in Belgium described as English as a foreign language (EFL) students, indicating L2 English learners in an EFL context with focus on English writing skills.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study examines the effectiveness of ChatGPT, explicitly a large language model, in improving English writing skills. It uses an experimental design comparing a teacher-feedback-only group with a group using ChatGPT alongside teacher feedback over a nine-week intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on writing competence, specifically syntactic and lexical complexity as key dimensions of writing development, and overall English writing skills. ChatGPT is integrated as part of writing instruction, not merely as an assessment tool.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcomes, including text length and measures of syntactic and lexical complexity, and compares gains between groups to assess ChatGPT\u2019s impact on writing development over nine weeks.""}}"
Exploring the Impact of Ai Technologies on Efl Writing Proficiency,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The participants are Saudi EFL teachers at King Saud University, not L2 English learners. The study focuses on teachers\u2019 perspectives rather than learner data or learner outcomes.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is mentioned, the study uses a descriptive survey design to explore teachers\u2019 perceptions. There is no experimental or quasi-experimental intervention integrating ChatGPT into learners\u2019 writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on teachers\u2019 views of using ChatGPT in writing classes, not on implementing and evaluating a pedagogical writing intervention. It is a perception study rather than an instructional context with measured impact on writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports perceived merits and challenges but does not provide quantifiable writing outcome metrics for learners. No experimental measures of writing performance or related variables are described.""}}"
Cognitive Offload Instruction with Generative Ai: a Quasi-experimental Study on Critical Thinking Gains in English Writing,2025,unsure,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions \u201cfirst-year university students\u201d and refers to \u201cEnglish essay writing\u201d and \u201csecond-language writing contexts,\u201d but it does not explicitly state that the participants are L2 English learners (ESL/EFL/ELL). They could be native or mixed-proficiency students. Thus, it is unclear whether the population is specifically L2 English learners.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses \u201cgenerative AI-enabled cognitive offload instruction\u201d and \u201cgenerative AI tools\u201d for brainstorming and co-revision. However, the abstract does not specify that these tools are LLM-based (e.g., ChatGPT, GPT-4) as opposed to other generative or assistive AI. Without explicit indication that transformer-based LLMs are used, this criterion remains unclear.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is English essay writing, with structured writing cycles including AI brainstorming, critique, and co-revision. Outcomes include essay quality (logical coherence, evidence use, originality) and critical thinking in writing. The focus is clearly on writing competence and writing-related variables within an instructional intervention, not on automated scoring or purely technical evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable outcomes: standardized critical thinking assessment scores and measures of essay quality (logical coherence, evidence use, originality), with significant improvements for the AI group and mediation analysis. These constitute measurable writing-related outcomes within an experimental/quasi-experimental design.""}}"
Revising with Intelligence: Chatgpt Feedback and Its Impact on Efl Students’ Revision and Self-efficacy,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as 82 university-level EFL students, i.e., learners of English as a foreign language. The focus is clearly on English writing development in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses ChatGPT-supported feedback as the core intervention in a quasi-experimental design, comparing a ChatGPT-supported writing group with a teacher-supported writing group over ten weeks. ChatGPT is a large language model integrated into the writing process.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on writing development and revision in process-based writing instruction. Outcomes include revision productivity, macro-level and content-based revisions, and writing self-efficacy related to substantive revision, discourse organization, and writing conventions.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantitative outcomes: significant increases in revision productivity, more macro-level and content-based revisions, and higher self-efficacy gains across three measured dimensions. These are structured, quantifiable writing-related outcome measures.""}}"
Traditional Strategies and Ai-integrated Strategies in Learning English among Efl Omani Students,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL Omani students at a public Omani university, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a survey using SILL plus AI-related questionnaire items to measure use of AI-integrated learning strategies. It does not describe an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into instruction; AI tools are referenced generically as strategies, not as a controlled LLM-based pedagogical treatment.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on general English learning strategies (listening, speaking, pronunciation, grammar, writing) and gender/academic level differences in their use. It is not a writing-focused instructional intervention; writing is only one of several skills and is not the primary context of a pedagogical treatment.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are self-reported strategy-use frequencies on Likert scales, not objective or quantifiable writing performance measures. The study does not assess changes in writing competence or related performance metrics following an LLM-mediated intervention.""}}"
Design Opportunities for Explainable Ai Paraphrasing Tools: a User Study with Non-native English Speakers,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""Participants are described as non-native English speakers (NNESs), but the abstract does not specify whether they are in ESL/EFL/ELL instructional contexts or simply general NNES users. The focus is on interaction with an AI paraphrasing assistant rather than a defined L2 learning context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses ParaScope, an AI paraphrasing assistant, but the abstract does not state that it is based on a large language model (e.g., ChatGPT/GPT-4 or similar transformer-based generative model). It could be any AI paraphrasing system, so LLM use cannot be confirmed from the abstract alone.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on user interaction with explainable AI paraphrasing tools, information aids, and design implications. Outcomes emphasized are confidence, autonomy, and writing efficiency, not writing competence or instructional intervention in writing. It is more a usability/design study than a pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not report quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity). It mentions confidence, autonomy, and efficiency, but without indication of experimental measures of writing performance or structured intervention outcomes.""}}"
The Role of Ai in Improving Writing Skills of Indian Undergraduate Efl Learners: a Research Review,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The population is clearly Indian undergraduate EFL learners (\u201cIndian undergraduates studying English as a foreign language\u201d), which fits the L2 English learner criterion.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The article is explicitly described as a \u201cresearch review\u201d examining the potential of AI writing tools. It does not describe an experimental or quasi-experimental intervention using a specific LLM (e.g., ChatGPT, GPT-4); instead, it conceptually reviews potential benefits and challenges.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on improving EFL learners\u2019 writing skills, including feedback, vocabulary expansion, and writing structure, which are writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a review article, it does not report original quantitative writing outcome metrics or results from a structured intervention; it only discusses potential benefits and calls for further investigation.""}}"
Coachgpt: a Scaffolding-based Academic Writing Assistant,2025,unsure,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions supporting academic writing, including when writing in a second language, but does not specify that study participants are L2 English learners in ESL/EFL/ELL contexts, nor that the focus is specifically on English writing.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study develops CoachGPT, an AI agent-based web application that uses large language models to provide real-time feedback and suggestions for academic writing. This is an LLM-based writing assistant integrated into the writing process, and the paper reports user studies, suggesting an intervention-like use.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on academic writing assistance, with CoachGPT providing scaffolding, feedback, and suggestions during writing. The context is clearly writing competence and writing-related support, not automated essay scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract states that \u201cuser studies prove the usefulness of CoachGPT,\u201d but does not specify whether these studies include quantifiable writing outcome metrics (e.g., writing quality scores, accuracy, complexity) versus only usability, perceptions, or engagement measures.""}}"
Chatgpt for English Writing: a Qualitative Inquiry among English Major Students at Thai Higher Education,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are seven fourth-year English majors in Thailand, explicitly described as Thai English as a Foreign Language (EFL) students, so the population is L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a qualitative inquiry into attitudes and perceptions about ChatGPT. There is no indication of an experimental or quasi-experimental design, nor a structured instructional intervention integrating ChatGPT into writing instruction or processes.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on ChatGPT\u2019s roles in English writing, including vocabulary, grammar, and content organization, which are writing-related variables in an L2 context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses semi-structured interviews and thematic analysis to explore perceptions and attitudes. It does not report quantifiable writing outcome metrics or measure changes in writing performance; outcomes are purely qualitative.""}}"
The Collaboration of Ai and Teacher in Feedback Provision and Its Impact on Efl Learner’s Argumentative Writing,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 28 tenth-grade EFL learners focusing on English argumentative writing, which fits ESL/EFL/ELL L2 English learner contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses DeepL Write as the AI tool. DeepL Write is primarily a machine translation/AI writing assistance system and is not clearly identified as an LLM-based (transformer generative) model like ChatGPT, GPT-4, Gemini, etc. The abstract does not specify use of a large language model; thus it does not meet the explicit LLM requirement.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study explicitly targets English argumentative writing and examines the impact of AI and teacher feedback on writing quality (lexical, grammatical, content, coherence, cohesion), which are core writing-related variables.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Writing outcomes are quantitatively analyzed using Coh-Metrix across three drafts to assess changes in writing quality, providing measurable writing outcome metrics.""}}"
Assigning Cefr-j Levels to English Learners’ Writing: an Approach Using Lexical Metrics and Generative Ai,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The system is designed for assessing English learners\u2019 writing proficiency in an EFL context (CEFR-J, particularly in Japan), so the population is L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study presents CWLA as an automated assessment system using lexical metrics and AI-based analytical scores. It focuses on developing and validating an automated scoring tool, not on an experimental or quasi-experimental pedagogical intervention integrating an LLM into writing instruction or writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on automated writing proficiency assessment (alignment with CEFR-J, correlation with human ratings, entropy analysis), i.e., functionality as an automated essay scoring system. There is no described instructional or intervention context targeting writing competence development.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are tool validation metrics (correlation with human ratings, entropy analysis, expert agreement). There is no experimental or quasi-experimental writing intervention and no quantifiable pre/post or comparative writing outcome measures for learners.""}}"
Modeling Chinese Efl Learners’ Intention to Use Generative Ai for L2 Writing through an Integrated Model of the Tam and Ttf,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Chinese EFL learners (304 university students in China) using generative AI for L2 English writing, which fits the ESL/EFL/ELL English-focused population criterion.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses a survey and structural equation modeling (TAM + TTF) to examine intention to use generative AI. There is no experimental or quasi-experimental pedagogical intervention integrating an LLM into actual writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is technology acceptance and behavioral intention, not an implemented writing intervention or measured impact on writing competence. It is about attitudes toward using generative AI as an assistant, not a writing-focused instructional context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes are psychological constructs (perceived usefulness, ease of use, attitude, behavioral intention), not measures of writing performance or related skills.""}}"
"A Mixed-methods Study on the Use of Chatgpt in the Pre-writing Stage: Efl Learners’ Utilization Patterns, Affective Engagement, and Writing Performance",2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as English as a Foreign Language (EFL) learners: 56 first-year university students performing argumentative writing tasks in an EFL context, with outcomes focused on English writing performance.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention uses ChatGPT, a large language model, as support in the pre-writing stage. The design is quasi-experimental: each learner completes two argumentative writing tasks, one with and one without ChatGPT support, enabling comparison of conditions.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on writing competence and related variables: pre-writing strategy use, affective engagement during planning, and subsequent text quality in argumentative writing. ChatGPT is integrated pedagogically into the writing process rather than used solely for scoring.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcomes: it compares text quality between ChatGPT and non-ChatGPT conditions and examines correlations between affective engagement and overall writing performance, indicating measurable writing performance metrics.""}}"
Predicting Kazakhstani Tefl Students’ Continuance Intention towards Using Chatgpt in Academic Writing,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are TEFL (Teaching English as a Foreign Language) students at two Kazakhstani universities, i.e., L2 English learners in an EFL context, and the focus is on academic writing in English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is the focal tool, the study is not an experimental or quasi-experimental intervention in writing instruction. It examines perceptions and continuance intention via a survey model, not a structured pedagogical writing intervention using ChatGPT.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on technology acceptance variables (perceived usefulness, ease of use, satisfaction, continuance intention) rather than on developing or assessing writing competence through an instructional intervention. Writing is the context, but not the main outcome of an educational treatment.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, text quality measures) are reported. Outcomes are psychological/behavioral (perceptions and intention to continue using ChatGPT) and qualitative comments, not measured changes in writing performance.""}}"
Exploring the Potential of Genai for Personalised English Teaching: Learners' Experiences and Perceptions,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are first-year English for Academic Purposes students, i.e., L2 learners in an EAP/ESL-type context, and the focus is on English language competencies.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines learners\u2019 use of GenAI tools such as Grammarly and Quillbot. These are not clearly specified as LLM-based tools in an experimental or quasi-experimental instructional design; rather, they are general-purpose support tools whose underlying models may not be transformer-based generative LLMs as required. The focus is on existing tool use, not a structured LLM-mediated intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on learners\u2019 experiences and perceptions of GenAI tools across multiple skills (grammar, writing, vocabulary, reading), not on a defined writing instruction intervention or writing process design. It is more a perception/usage study than a pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although the study uses surveys and interviews, the abstract reports usage rates and perceived helpfulness, not quantifiable writing outcome metrics (e.g., changes in writing scores, text quality measures) resulting from a structured intervention. Outcomes are attitudinal and self-reported rather than experimental writing performance measures.""}}"
The Impact of Integrating Chatgpt with Teachers’ Feedback on Efl Writing Skills,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were 68 intermediate Iranian EFL learners, clearly indicating L2 English learners in an EFL context, with outcomes focused on English IELTS Task 2 argumentative essays.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention explicitly integrates ChatGPT, a large language model chatbot, with teacher feedback to provide individualized writing feedback. Learners were randomly assigned to ChatGPT+teacher feedback vs teacher-only feedback, indicating an experimental design using an LLM in instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on EFL writing skills and improvement in IELTS Task 2 argumentative essays. ChatGPT is used pedagogically to support writing feedback, not merely for automated scoring or system evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Quantitative writing outcomes are reported: Paired Samples t-Test results show significantly greater improvement in the experimental group across specific writing criteria (task achievement, coherence, cohesion, vocabulary, grammar range and accuracy). These are clear, quantifiable writing outcome metrics.""}}"
Mobile Ai Tools in Language Learning: Efl Students’ Acceptance of Chatgpt for Writing Brainstorming,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 257 EFL students at a private Vietnamese university, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used for writing brainstorming, the study is described as inspecting students\u2019 acceptance using questionnaires and interviews. There is no indication of an experimental or quasi-experimental instructional intervention design; it is primarily an acceptance/perception study.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is writing, specifically brainstorming in a writing class and perceived support for enhancing writing quality and skills, which aligns with writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The methods mention a Likert-scale questionnaire and semi-structured interviews focusing on acceptance, perceptions, advantages, and disadvantages. The abstract does not report any quantifiable writing outcome metrics (e.g., writing scores, text quality measures) resulting from the ChatGPT use.""}}"
The Development and Validation of a Scale on Student Ai Literacy in L2 Writing: a Domain-specific Perspective,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 435 and 350 Chinese university students engaged in L2 writing, implying they are L2 English learners in an EFL context. The scale is explicitly for L2 writing, and in Chinese university contexts this typically refers to English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study develops and validates a self-report scale (L2W-SAILS) to measure student AI literacy in L2 writing. There is no experimental or quasi-experimental integration of a specific LLM (e.g., ChatGPT, GPT-4) into writing instruction or writing processes; AI tools are discussed conceptually, not implemented as an intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on constructing and validating a measurement instrument for AI literacy, not on an instructional or intervention context targeting writing competence. While situated in L2 writing, it does not describe an AI-mediated writing pedagogy or intervention being tested.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are psychometric properties of the AI literacy scale (factor structure, reliability). The study does not report quantifiable writing performance or writing-related outcome measures resulting from an LLM-mediated intervention; it only measures self-reported AI literacy.""}}"
Students' Perceptions and Usage Patterns of Chatgpt as an Automated Writing Evaluation (awe) Tool,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL graduate students at a university in Hong Kong, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used as an Automated Writing Evaluation tool, the study is not described as experimental or quasi-experimental. It focuses on existing usage and perceptions via a questionnaire, not on a structured LLM-mediated instructional intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is academic writing, with ChatGPT used for revision, grammar, and vocabulary enhancement, which are writing-related variables rather than pure scoring or grading.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports questionnaire-based perceptions (trustworthiness, usefulness, ease of use) and usage patterns, but does not mention any quantifiable writing outcome measures (e.g., writing scores, quality ratings, error counts) to assess effectiveness of the intervention.""}}"
A Pilot Study on Bridging Efl Writing and Speaking Skills through Ai-enhanced Authentic Short Video-making,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 20 first-year university students in an EFL context (public university in central Taiwan), so they are L2 English learners and the focus is on English proficiency.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cArtificial Intelligence-enhanced authentic short video-making (AI-eSV)\u201d but does not specify the type of AI or name any LLM tools (e.g., ChatGPT, GPT-4). It is unclear whether the AI component is an LLM-based generative model or another form of AI (e.g., video editing, recommendation, or non-LLM support).""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The intervention explicitly targets writing and speaking skills through collaborative scriptwriting and video recording. Writing competence (creativity, content organization) is a primary focus, not just assessment or non-pedagogical use.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although the study uses a pretest\u2013posttest design and reports \u201csignificant improvements in writing and speaking skills,\u201d the abstract does not indicate that the AI (possibly LLM) component itself is the focus of the experimental contrast. More importantly, the AI type is unspecified, and there is no clear evidence that an LLM-mediated writing intervention is being evaluated with quantifiable writing outcomes attributable to LLM use, as required by the review.""}}"
