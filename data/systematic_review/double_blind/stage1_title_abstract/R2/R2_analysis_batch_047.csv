Title,Year,Decision,Notes
Automated Scoring of Speaking and Writing: Starting to Hit Its Stride,2022,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses automated scoring of speaking and writing in general and mentions different groups, but does not specify that the population is L2 English learners in ESL/EFL/ELL contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The article is a literature review on automated scoring (AS) and does not describe an experimental or quasi-experimental intervention integrating LLMs into writing instruction or writing processes. It focuses on AS systems and their design, role of AI, and accuracy, not on LLM-mediated pedagogical interventions.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on automated scoring for assessment (writing and speaking) and its implications, not on writing instruction or development of writing competence through an intervention. It aligns with evaluation of AS functionality rather than a pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a review article, it does not report original experimental outcome measures of a specific LLM-mediated writing intervention. It synthesizes existing literature rather than providing quantifiable writing outcomes from a new study.""}}"
Assessing Readability of Learning Materials on Artificial Intelligence in English for Second Language Learners,2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly focuses on English-as-a-second-language (ESL) learners engaging with English AI learning materials, which fits the target population of L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the study uses deep-learning-based NLP to build automatic readability assessors, there is no indication that large language models (e.g., ChatGPT, GPT-4) are integrated into writing instruction or learners\u2019 writing processes. The tools are used for text readability assessment, not as pedagogical LLM interventions.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on assessing the readability of AI learning materials, not on writing competence or writing-related instruction. There is no mention of writing tasks, writing instruction, or writing performance as a central outcome.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports readability levels and the proportion of texts that intermediate ESL learners can read, but it does not report quantifiable writing outcomes or effects of an LLM-mediated writing intervention.""}}"
A Multi-facet Rasch Measurement of Peer Evaluation in Computerized Dynamic Esl Writing,2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly refers to ESL (English as a Second Language) writing and mentions 41 students in an ESL context, indicating L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention involves Computerized Dynamic Assessment and a peer assessment system (Peerceptiv). There is no mention of large language models, transformer-based generative AI, or tools like ChatGPT/GPT-4. The focus is on peer evaluation reliability, not LLM integration.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on second language writing and peer assessment within computerized dynamic assessment, which is clearly writing-related.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses reliability and consistency of peer assessment using Multi-facet Rasch measurement but does not clearly report quantifiable writing outcome metrics (e.g., changes in writing quality). However, this criterion is moot because C2 already fails.""}}"
Design of Interactive System for Autonomous Learning of Business English Majors Based on Deep Learning Algorithms,2022,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The population is described as 'business English majors', which likely implies L2 English learners, but this is not explicitly stated and could also include native speakers in an English-medium context. The abstract does not clearly specify ESL/EFL/ELL status.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study mentions integrating 'deep learning into the recommendation system' but does not indicate the use of large language models (e.g., ChatGPT, GPT-4) or any transformer-based generative model. It appears to be about a recommendation system and autonomous learning, not an LLM-based writing intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on 'self-service learning ability' and 'deep learning goals' for business English majors, with evaluation via written tests and work evaluations. There is no clear indication that the primary focus is on writing competence or writing-related variables; it seems more about general learning or performance.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although written tests and work evaluations are mentioned, the abstract does not specify that these are writing outcome measures within an LLM-mediated writing intervention. There is no indication of quantifiable writing outcomes tied to an LLM-based writing intervention.""}}"
The Integration of Multiple Recognition Technologies and Artificial Intelligence to Facilitate Efl Writing in Authentic Contexts,2022,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 71 undergraduate EFL learners (\u201cEnglish as Foreign Language (EFL) learners\u201d), and the focus is explicitly on English writing. This matches the target population of L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention is a mobile app (Smart UEnglish) that integrates \u201cgenerative-AI\u201d to provide AI-generated sample sentences (AI-GS). Students are assigned to experimental and control groups, with the experimental group using the generative-AI component. This is an experimental design integrating generative AI into writing instruction. While the specific LLM is not named, the description of \u2018generative-AI\u2019 producing sample sentences is consistent with an LLM-based tool.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on facilitating EFL learners\u2019 English writing: the app is designed \u201cto help learners practice meaningful English writing in authentic contexts,\u201d and the outcome discussed is performance on a writing posttest and essay writing inspired by AI-generated sample sentences. This aligns with writing competence as the central context.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports that \u201cthe EG outperformed the CG in the posttest\u201d and identifies ITR use as a predictive variable in the post-test. This indicates quantifiable writing outcome metrics (pre/post or at least posttest comparison between groups) to assess the effectiveness of the AI-mediated writing intervention.""}}"
Using Chatbots to Scaffold Efl Students? Argumentative Writing,2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly refers to English as a foreign language (EFL) students and focuses on their argumentative writing in English, matching the target L2 English learner population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses a custom chatbot system (Argumate). The abstract does not indicate that it is based on large language models (e.g., GPT-style transformer generative models); it is presented generically as a chatbot/AI system. Given the publication context and lack of LLM mention, it is unlikely to be an LLM-based intervention as defined in the review.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The paper proposes a chatbot-assisted approach to teaching and learning argumentative writing and discusses using the system to assist students in producing high-quality argumentative writing. The primary focus is clearly on writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract describes a proposed approach and a system (Argumate) and discusses advantages and limitations, but does not mention any experimental or quasi-experimental design, nor any quantitative writing outcome measures. It appears to be more of a design/description paper than an intervention study with measurable outcomes.""}}"
To Err Is Human: Comparing Human and Automated Corrective Feedback,2022,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions a corpus of 115 texts written by college students, but does not specify whether these are L2 English learners (ESL/EFL/ELL) or native speakers. The learner status and L2 context are not clearly indicated.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study compares corrective feedback from human teachers with Grammarly, described as a \u2018well-known writing assistant\u2019 and \u2018Automated Written Evaluation (AWE)\u2019 tool. Grammarly is not an LLM-based generative model in the sense required (e.g., ChatGPT, GPT-4, Gemini); it is a non-LLM AWE/grammar checker. No LLM integration into instruction or writing processes is reported.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on comparing error detection and types of corrective feedback between human raters and Grammarly on existing texts. There is no pedagogical intervention or instructional context where learners use the tool as part of a writing intervention; it is essentially a comparative CF/assessment study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports statistics on number and types of errors detected by humans vs Grammarly, not on changes in learners\u2019 writing performance over time or pre/post intervention outcomes. No quantifiable writing outcome metrics assessing the effectiveness of an LLM-mediated writing intervention are presented.""}}"
A Review of Artificial Intelligence in Foreign Language Learning,2022,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses foreign/second language learning in general and does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor that the focus is on English specifically.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The article is explicitly described as a brief review of AI implementation in second language learning, not an experimental or quasi-experimental study. No specific LLM-based intervention (e.g., ChatGPT, GPT-4) is described.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The focus is broadly on foreign language learning and AI, with no indication that writing competence or writing-related variables are the primary focus; skills are not specified in the abstract.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a review article, it does not report original, quantifiable writing outcome metrics from an intervention; it summarizes \u2018latest attempts\u2019 rather than presenting experimental measures.""}}"
The Effects of an Augmented-reality Ubiquitous Writing Application: a Comparative Pilot Project for Enhancing Efl Writing Instruction,2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as EFL undergraduates in an English as a foreign language writing context, so the population is L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is an augmented-reality context-aware ubiquitous writing (ARCAUW) application. There is no indication that it is based on large language models (e.g., ChatGPT, GPT-4, transformer-based generative models). It is framed as AR and context-aware ubiquitous technology, not an LLM-mediated tool.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on EFL writing instruction, comparing an ARCAUW writing mode with a mobile-assisted classroom-based writing mode, and examines writing development, task schema, and related writing processes.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract reports pre- and post-test results on writing outcomes (process analysis essay performance) and compares writing performance between conditions, indicating quantifiable writing outcome metrics.""}}"
Partnering with Al: Intelligent Writing Assistance and Instructed Language Learning,2022,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses \u2018learners\u2019 and \u2018instructional language learning\u2019 but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor that the focus is specifically on English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The piece is explicitly described as a \u2018column\u2019 that examines AI-enabled writing tools, reviews findings from research studies, and discusses their use. It does not describe an experimental or quasi-experimental study conducted by the authors, nor a specific LLM-based intervention (e.g., ChatGPT, GPT-4).""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the focus is on writing tools and their instructional use, the article is a conceptual/review-style column rather than an empirical study implementing a concrete writing intervention with measured outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics or experimental results are reported; the abstract only mentions that tools \u2018have been found to offer significant benefits\u2019 in prior work and focuses on discussion and review.""}}"
Exploring Artificial Intelligence Using Automated Writing Evaluation for Writing Skills,2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Malaysian public university students in ESL writing classrooms, indicating L2 English learners in an ESL/EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is described as AI software for Automated Writing Evaluation (AWE). There is no indication that this is an LLM-based, transformer generative model (e.g., ChatGPT, GPT-4). AWE tools are typically rule-based or non-LLM systems, so it does not meet the LLM requirement.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is ESL writing classrooms and improving writing skills, with focus on grammatical error detection and writing skills, which is directly writing-related.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions investigating the effectiveness of AWE in improving writing skills and students\u2019 perceptions, but only reports positive perceptions. It does not clearly state any quantitative writing outcome measures (e.g., scores, error rates).""}}"
Clustering Students' Writing Behaviors Using Keystroke Logging: a Learning Analytic Approach in Efl Writing,2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The title and abstract indicate an EFL writing context, implying participants are English as a foreign language learners engaged in English writing tasks.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses machine learning and clustering on keystroke logging data to identify writing behavior profiles. There is no mention of large language models (e.g., ChatGPT, GPT-4) or any LLM-based writing intervention; the focus is on analytics, not LLM-mediated instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly EFL writing, focusing on writing processes and writing quality, and how students interact with writing tasks. This aligns with a primary focus on writing competence and related variables.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports analysis of writing quality and compares clusters with respect to students\u2019 writing quality, indicating quantifiable writing outcome metrics are used, even though no LLM intervention is present.""}}"
An Integrated Automatic Writing Evaluation and Svvr Approach to Improve Students' Efl Writing Performance,2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are clearly described as EFL (English as a Foreign Language) university students in an EFL writing course, so the population consists of L2 English learners and the focus is on English writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention integrates Automatic Writing Evaluation (AWE) and Spherical Video-based Virtual Reality (SVVR). The abstract does not indicate that the AWE system is based on a large language model (e.g., ChatGPT, GPT-4) or any transformer-based generative model; it is a generic AWE tool. Therefore, it does not meet the requirement of an LLM-based writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study\u2019s primary focus is on improving EFL writing performance and related affective variables (motivation, self-efficacy, anxiety) through an instructional intervention in a writing course, which aligns with a writing competence context rather than automated scoring or system evaluation alone.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract reports that the integrated SVVR-AWE approach \u2018considerably enhanced the students\u2019 EFL writing performance\u2019 compared to a control group, implying quantifiable writing outcome measures were collected and analyzed in a quasi-experimental design.""}}"
Automatic Scoring of Arabic Essays over Three Linguistic Levels,2022,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are learners of Arabic as a second language; the focus is on Arabic essays, not L2 English learners in ESL/EFL/ELL contexts. Therefore, the population does not match the review\u2019s scope.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study presents an automatic scoring system using feature extraction at lexical, syntactic, and semantic levels, with linear and non-linear combination methods. There is no indication that a large language model (e.g., transformer-based generative model like ChatGPT/GPT-4) is used, nor that it is integrated into instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on automated essay scoring reliability (accuracy and quadratic weighted kappa vs. human raters), not on pedagogical writing intervention or development of writing competence. It is an assessment tool evaluation, not a teaching/learning context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports system performance metrics (accuracy, quadratic weighted kappa) relative to human raters, not quantifiable outcomes of a writing intervention on learners\u2019 writing performance. There is no experimental or quasi-experimental design assessing LLM-mediated writing improvement.""}}"
Analysis of Syntactic Complexity and Semantic Coherence of Academic English Writing Based on Particle Swarm Optimization,2022,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses \u2018academic English writing\u2019 and \u2018second language writing\u2019 but does not specify the participant population (e.g., EFL/ESL learners, their level, or whether they are L2 English learners). It could be corpus-based or system-focused rather than learner-focused.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is an \u2018intelligent evaluation method\u2019 using particle swarm optimization (PSO) and other algorithms. PSO is an optimization technique, not a large language model or transformer-based generative model (e.g., ChatGPT, GPT-4). No LLM-based writing instruction or process support is described.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on automated evaluation of syntactic complexity and semantic coherence using PSO and other algorithms, not on a pedagogical writing intervention. It appears to be an assessment/algorithmic study rather than an instructional context aimed at improving writing competence through an intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although quantitative measures (e.g., significance values) are reported, they relate to comparing algorithms (data mining, AI, decision tree, PSO) for evaluation performance, not to measuring changes in learners\u2019 writing outcomes following an LLM-mediated intervention.""}}"
Writing Issues in Esl and Their Potential Solutions: Case Study Imco's Foundation Students,2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are IMCO foundation students (A1\u2013B1) who are non-native English speakers in an ESL/EFL context, focusing on English writing mistakes. This matches the target L2 English learner population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study records common writing mistakes and uses bibliometric analysis tools (VOSviewer, Yale DHlab Raw Graph 2.0). There is no indication that large language models (e.g., ChatGPT, GPT-4) were integrated into instruction or writing processes; AI is only mentioned as a future need.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on writing issues (spelling, punctuation, thesis statements, structure, etc.) among ESL learners, clearly centering on writing competence and related variables.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract reports identification and categorization of common errors but does not clearly describe a structured intervention with pre/post or comparative quantitative writing outcome measures to assess an instructional treatment. It appears more diagnostic/descriptive than evaluative of an intervention.""}}"
X-education: Education of All Things with Ai and Edge Computing—one Case Study for Efl Learning,2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly mentions a preliminary study for EFL writing with 22 learners, indicating participants are EFL (L2 English) learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses \u201con-device AI\u201d and Q&A forwarding mechanisms within an X-Education framework, but there is no indication that the AI is a large language model (e.g., ChatGPT/GPT-like transformer-based generative model). The nature of the AI is unspecified and cannot be assumed to be an LLM.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context includes EFL writing and learners\u2019 perceptions that X-Education could help them learn EFL writing better through Q&A, indicating a focus on writing-related learning.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract reports that knowledge of all things in the experimental group increased significantly and that learners received better EFL answers, but it does not clearly state that quantifiable writing performance outcomes (e.g., writing scores, text quality measures) were measured. The only explicit outcome is knowledge gain and perceived help for EFL writing.""}}"
Computer-assisted Efl Writing and Evaluations Based on Artificial Intelligence: a Case from a College Reading and Writing Course,2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL students in a college reading and writing course, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses three online automated essay evaluation (AEE) systems and discusses computer-assisted review tools and automatic evaluation. There is no indication these are large language model\u2013based tools (e.g., ChatGPT, GPT-4); they are framed as traditional AEE/ICALL systems, not transformer-based generative LLMs.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on English writing ability, computer-assisted evaluation tools, and their impact on students\u2019 writing and independent learning, which aligns with a writing competence context.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract reports that students\u2019 English writing ability was significantly improved and that teacher and AEE scores were compared using descriptive statistics, indicating quantifiable writing outcome measures.""}}"
"Investigating English as a Foreign Language Learners' Perceptions, Emotions, and Performance during Online Collaborative Writing",2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL learners (male students enrolled in writing courses in the Department of English Language and Translation, Qassim University), so the population is L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses Blackboard and Blackboard Chatbox for online collaborative writing. These are general learning management and chat tools, not large language models (e.g., ChatGPT, GPT-4). No LLM-based generative system is mentioned.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on collaborative writing, learners\u2019 emotions, and performance in writing courses, so the primary focus is on writing competence and writing-related variables.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports learners\u2019 overall performance and compares performance between face-to-face and Blackboard Chatbox instruction, indicating quantifiable writing-related outcome measures (e.g., significance value Sig. = 0.287).""}}"
Partnering with Ai: Intelligent Writing Assistance and Instructed Language Learning,2022,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses \u2018learners\u2019 and \u2018instructional language learning\u2019 in general but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor that the focus is specifically on English writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The piece is explicitly described as a \u2018column\u2019 that examines AI-enabled writing tools and reviews findings from research studies. It does not report an experimental or quasi-experimental study of its own, nor a specific LLM-based intervention; it is a narrative/overview of tools such as AWE, MT, Grammarly, and generative systems.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the focus is on writing tools and their instructional use, the article is a conceptual/review-style column rather than an empirical study implementing a concrete writing intervention with measured outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics or experimental results are reported. The abstract mentions that tools \u2018have been found to offer significant benefits\u2019 but only in the context of reviewing prior research, without presenting new, structured intervention outcomes.""}}"
