Title,Year,Decision,Notes
Chatwell: an Ai-enabled Adaptive Tutoring System for Improving Mandarin Composition Skills in L2 Students with Learning Difficulties,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are HSK4 learners studying Mandarin Chinese: \u201c100 HSK4 learners\u2026 for Chinese language learners.\u201d The target language is Mandarin, not English, so the population does not match the review\u2019s focus on L2 English learners in ESL/EFL/ELL contexts.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study develops CHATWELL, \u201can intelligent tutoring platform that incorporates optimised large language models to deliver\u2026 writing assistance.\u201d It uses a 12-week quasi-experiment comparing this LLM-based system to a Bi-LSTM AES, satisfying the requirement for an LLM-mediated experimental/quasi-experimental intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on writing competence in Mandarin composition: \u201cfor Improving Mandarin Composition Skills\u2026 assessing improvements in writing scores, error reduction, and accessibility metrics.\u201d This is a pedagogical writing intervention, not just automated scoring.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Quantifiable writing outcomes are reported: \u201cscore gains (14.2 vs. 6.8 points, t(98) = 7.85, p < 0.001), with marked reductions in grammatical (72.1%) and logical (75.3%) errors.\u201d These are clear experimental measures of writing improvement.""}}"
A Duoethnographic Study of Writing-with as a Mode of Efl Teacher Professional Development Practice in the Age of Ai,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The abstract focuses on EFL teacher professional development and teacher reflection. Participants are teachers, not L2 English learners in ESL/EFL/ELL contexts, and there is no indication of learner writing data or learner-focused outcomes.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT is mentioned, it appears as an object of teacher reflection within a duoethnographic inquiry, not as an experimental or quasi-experimental pedagogical intervention integrating an LLM into learners\u2019 writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on teacher professional development, reflection, and ethical inquiry around digital tools, not on writing competence or writing-related variables for L2 learners. Writing is framed as a reflective practice for teachers, not as L2 writing instruction or intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is duoethnographic and qualitative, surfacing themes such as emotional labor and pedagogical ambivalence. It does not report quantifiable writing outcome metrics or experimental measures of LLM-mediated writing interventions.""}}"
Algorithmic Feedback and Multilingual Identity: Translanguaging Practices in Jordanian Efl Academic Writing,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as multilingual EFL students and instructors in a Jordanian university, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cAI-mediated writing support\u201d and \u201calgorithmic feedback systems\u201d but does not specify that these are large language models (e.g., ChatGPT, GPT-4) as opposed to other AI tools (e.g., grammar checkers). The underlying technology is not identified.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is academic writing in EFL, focusing on how students respond to AI-mediated writing support and algorithmic feedback in their texts, which is directly related to writing practices and pedagogy.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is explicitly qualitative (multi-case design using interviews, observations, samples, and journals) and focuses on identity, translanguaging, and critical responses to AI feedback. No quantifiable writing outcome metrics or experimental/quasi-experimental evaluation of intervention effectiveness are reported.""}}"
Optimizing Self-regulated Learning: a Mixed-methods Study on Gai's Impact on Undergraduate Task Strategies and Metacognition,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study focuses on self-regulated learning in second language (L2) writing among 40 undergraduate students in Eastern China. The context is explicitly L2 writing, which in China typically refers to English; no other target language is mentioned, and the abstract frames it as L2 writing in general, aligning with ESL/EFL/ELL-type contexts focused on English.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention uses a generative AI (GAI) chatbot platform, Tongyi.ai, over an 8-week intervention. This is a GAI chatbot (i.e., LLM-based) integrated into students\u2019 L2 writing-related learning processes, with an experimental group using the chatbot and a control group using traditional resources, indicating an experimental design with an LLM-mediated writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on L2 writing and self-regulated learning variables (task strategy diversity, metacognitive awareness) and writing performance. The abstract explicitly mentions \u2018writing performance assessments\u2019 and discusses how GAI tools support task planning and writing processes in L2 writing instruction, not just automated scoring or system evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Quantitative analysis includes \u2018writing performance assessments\u2019 and reports that the experimental group showed greater improvements in writing performance than the control group. Thus, the study provides quantifiable writing outcome metrics alongside other SRL measures, satisfying the requirement for measurable writing outcomes.""}}"
Is Generative Ai Ready to Replace Human Raters in Scoring Efl Writing? Comparison of Human and Automated Essay Evaluation,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are English as a Foreign Language (EFL) learners: 35 undergraduate students producing essays in English. The population clearly consists of L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses Generative AI as an Automated Essay Scoring (AES) system to compare its scores with human raters. There is no experimental or quasi-experimental instructional intervention integrating LLMs into writing instruction or writing processes; GenAI is only used for scoring.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on rating reliability and comparison between human and GenAI scoring of EFL essays, not on improving writing competence or implementing a pedagogical writing intervention. It is an assessment/measurement study rather than a writing instruction context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports score differences and correlations between human and GenAI ratings, but does not report any writing outcome changes resulting from an LLM-mediated intervention. There is no pre/post or controlled measure of writing improvement attributable to LLM use.""}}"
Formally Integrating Generative Ai into Secondary Education: Application of Chatgpt in Efl Writing Instruction,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 99 Grade-10 students in a Hong Kong secondary school enrolled in an English as a foreign language (EFL) writing course. The focus is explicitly on EFL (English) learners in a school context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study is a quasi-experiment integrating ChatGPT, a generative AI large language model, into a compulsory EFL writing course. The treatment group used ChatGPT as the tool for EFL writing instruction, compared with conventional media in the control group.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is an EFL writing course, and the intervention is described as ChatGPT-supported EFL writing instruction. The primary focus is on writing instruction and performance, not on automated scoring or non-pedagogical evaluation of the model.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract reports analysis of participants\u2019 EFL writing performance at the end of the experiment, showing the treatment group outperformed the control group and reporting interaction effects with baseline proficiency. These are quantifiable writing outcome measures.""}}"
Efl Lecturers’ Experiences and Perceptions towards Using Chatgpt in Teaching Writing: a Case Study in Vietnam,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The population involves EFL lecturers in Vietnam discussing their use of ChatGPT in EFL writing classes, clearly situated in an EFL/ESL context focused on English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used in writing instruction, the study is a qualitative case study of lecturers\u2019 experiences and perceptions, not an experimental or quasi-experimental intervention study. There is no structured LLM-mediated intervention being tested with outcome measures.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is explicitly EFL writing instruction, with ChatGPT used at pre-, while-, and post-writing stages for brainstorming, grammar checks, proofreading, and feedback\u2014clearly focused on writing competence and related processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses semi-structured interviews and a qualitative case study design, reporting perceptions of benefits and concerns. It does not report quantifiable writing outcome metrics or experimental measures of writing improvement.""}}"
Tame the Beast of Chatgpt: Developing Design Principles to Strategically Integrate Chatgpt into Efl Writing through an Activity Theory Perspective,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as four Chinese EFL writers, i.e., English as a Foreign Language learners, and the focus is on English writing.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study develops and iteratively revises an intervention with design principles to guide ChatGPT-assisted writing, clearly integrating an LLM (ChatGPT) into EFL writing processes within a design-based research framework.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is EFL writing; the study focuses on how to strategically integrate ChatGPT into EFL writing, with implications for EFL writing instruction, self-regulated learning, and AI literacy. This aligns with writing competence and writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports qualitative data sources (screen recordings, semi-structured interviews, stimulated-recall interviews) and thematic analysis to derive contradictions and design principles. It does not mention any quantitative or otherwise explicit, measurable writing outcome metrics (e.g., writing scores, text quality measures, error rates) assessing the effectiveness of the intervention.""}}"
Artificial Intelligence-supported Procedural Scaffolding for Promoting Efl Learners’ Writing Performance in Flipped Peer Assessment Activities,2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL learners: 74 university students in English writing classes in Taiwan. The focus is explicitly on English as a Foreign Language (EFL) learners\u2019 writing performance.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The intervention is described as an \u201cAI-based Procedural Scaffolding Peer Assessment (AI-PSPA) approach,\u201d but the abstract does not specify that the AI is a large language model (e.g., ChatGPT, GPT-4) or transformer-based generative model. It could be another form of AI (e.g., rule-based, analytics), so it is unclear whether it meets the LLM criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on writing competence: the study aims to enhance EFL learners\u2019 writing performance and reports outcomes such as writing accuracy within a peer assessment and flipped learning context.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses a quasi-experimental design with pre- and posttests of writing performance and reports that the AI-PSPA group outperformed others in writing accuracy. These are quantifiable writing outcome metrics.""}}"
University Students' Acceptance of Chatgpt as a Writing Assistance Tool in Esl and Esp Studies,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are ESL and ESP students at two universities, clearly indicating L2 English learners in ESL/ESP contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines students\u2019 perceptions and acceptance of ChatGPT using a TAM-based questionnaire in a non-mandatory use context. There is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is technology acceptance (perceptions and willingness to use ChatGPT) rather than writing competence or writing-related performance variables. It is not a pedagogical writing intervention study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports only questionnaire-based acceptance measures and does not mention any quantifiable writing outcome metrics (e.g., writing scores, quality measures, revisions) to assess the effectiveness of ChatGPT-mediated writing intervention.""}}"
Ai Vs. Teacher Feedback on Efl Argumentative Writing: a Quantitative Study,2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL learners: \u201cEnglish as a Foreign Language (EFL) learners at different proficiency levels\u201d in a \u201cwriting-focused EFL course in Jordan.\u201d The focus is clearly on English.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cAI-generated feedback\u201d and later explicitly mentions \u201clarge language models (LLMs), when carefully scaffolded and ethically deployed.\u201d However, it does not specify which AI system was used or confirm that the feedback tool is indeed an LLM-based system (e.g., ChatGPT, GPT-4). Without explicit identification of an LLM tool or architecture, it is uncertain whether the AI feedback is LLM-based rather than another AI technology.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on argumentative writing performance: \u201ceffectiveness of AI-generated feedback compared to teacher-generated feedback on the argumentative writing performance of EFL learners.\u201d The intervention is feedback on writing and subsequent revision, clearly a writing-instruction context rather than automated scoring only.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Quantifiable writing outcomes are reported: \u201cAn analytic rubric was used to assess writing performance\u2026 pre- and post-test scores analyzed for gains.\u201d Results include significance tests, effect size (Cohen\u2019s d = 0.10), and group comparisons, satisfying the requirement for measurable writing outcomes.""}}"
Ai-driven Corrective Feedback for Low-proficiency Learners: a Study on Writing Skill Development,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract refers to 'second language (L2) acquisition' and 'second language writing instruction' with low-proficiency learners. While it does not explicitly say ESL/EFL or English, the context of L2 writing and typical Springer L2 writing research strongly suggests L2 English learners; no other target language is mentioned.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention is 'AI-driven corrective feedback, specifically utilizing ChatGPT' over a 10-week intervention. ChatGPT is a large language model, and the design is quasi-experimental with an explicit instructional intervention in writing.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on 'writing skill development' and 'improving the writing skills of low-proficiency learners,' addressing grammar, vocabulary, sentence structure, coherence, and task achievement. This is clearly a pedagogical writing intervention, not an automated scoring or purely functional evaluation of the LLM.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports 'statistically significant improvements across all five assessed components of writing: grammar, vocabulary, sentence structure, coherence, and task achievement.' These are quantifiable outcome measures of writing performance following the LLM-mediated intervention.""}}"
Assessing Ai Literacy in Second Language Writing: a Scale Development and Validation Study,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are university-level English as a Foreign Language (EFL) learners in China, clearly an L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study focuses on developing and validating the AI Literacy in L2 Writing Scale (AIL-L2WS). It does not describe an experimental or quasi-experimental pedagogical intervention integrating a specific LLM (e.g., ChatGPT, GPT-4) into writing instruction or processes; rather, it measures literacy regarding AI tools in general.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the context is L2 writing, the primary focus is on constructing a scale of AI literacy (understanding, ethics, attitudes, self-efficacy), not on implementing or evaluating a writing intervention or instructional use of LLMs to improve writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports psychometric properties (EFA, CFA, reliability, validity) of an AI literacy scale. It does not report quantifiable writing outcome metrics (e.g., writing quality scores, complexity, accuracy, fluency) resulting from an LLM-mediated writing intervention.""}}"
On the Role of Engagement in Automated Feedback Effectiveness: Insights from Keystroke Logging,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were N = 453 English-as-a-foreign-language (EFL) learners (mean age 16.11). The abstract explicitly states an EFL context and the writing tasks are in English, satisfying the L2 English learner population requirement.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention is automated feedback generated by a large language model (GPT-3.5 Turbo). Learners were assigned to receive LLM-generated feedback or no feedback in a classroom experiment, which is an experimental design integrating an LLM into the writing process.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study centers on a writing task, revision of drafts, and a second writing (transfer) task. The focus is on feedback effectiveness for revision and transfer performance in writing, not on LLM evaluation per se, thus directly targeting writing competence and writing-related variables.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Writing outcomes are quantitatively assessed: all texts were scored automatically to assess performance, and the study reports effects of automated feedback on learners\u2019 revision and transfer performance, including mediation analyses via engagement measures. This provides quantifiable writing outcome metrics.""}}"
Using Chatgpt to Bring Non-player Characters to Life: Effects on Students’ Storyline-driven Game-based Writing Learning,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Chinese undergraduate students in English as a Foreign Language (EFL) writing classrooms. The focus is on English argumentative writing skills, clearly situating the population as L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study integrates ChatGPT, a large language model, into a game-based learning environment by using ChatGPT-powered NPCs. It employs a quasi-experimental design comparing a ChatGPT condition with a conventional NPC condition, constituting an LLM-mediated writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The intervention is implemented in EFL writing classrooms with the explicit goal of enhancing argumentative writing skills. The primary learning focus is on writing competence and writing-related variables (motivation, cognitive load, effort regulation) within a pedagogical context, not on automated scoring.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantitative writing outcomes: student essays were evaluated to compare writing performance across conditions. Results indicate superior writing performance (clarity, elaboration, persuasiveness, addressing opposing viewpoints) for the ChatGPT group, satisfying the requirement for measurable writing outcomes.""}}"
Tracking Progress to Foster Motivation: Implementing a Rubric-based P-score Model in Japanese University Efl Courses,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are in Japanese university EFL courses, i.e., learners of English as a foreign language. The context is clearly English-focused (EFL).""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Generative AI is used for rubric-based writing assessments and feedback generation to support consistency, but the study centers on implementing a rubric-based P-score assessment model, not on an LLM-mediated instructional or writing-process intervention. The AI functions primarily as an automated scoring/feedback tool within testing.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on assessment (P-score model) and student perceptions of this assessment system. While writing tests are involved, the AI is used for rubric-based assessment and feedback in testing, aligning more with automated essay scoring/assessment functionality than with a pedagogical writing intervention aimed at improving writing competence.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""Timed writing tests are administered and assessed with the P-score rubric, but the abstract reports survey-based perceptions and feasibility rather than quantifiable changes in writing performance attributable to the AI-supported intervention. It is unclear whether any experimental or quasi-experimental outcome measures of writing improvement are analyzed.""}}"
Do Ai Chatbot-integrated Writing Tasks Influence Writing Self-efficacy and Critical Thinking Ability? an Exploratory Study,2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract refers to \u201csecond language (L2) writing self-efficacy\u201d and \u201cvocational college students with limited language proficiency\u201d in an L2 context. Although the target language is not explicitly stated as English, the framing as L2 writing in a vocational college context suggests L2 learners; however, the specific target language (English vs. another language) is not clearly identified.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses \u201cAI chatbot-integrated writing tasks\u201d and \u201cgenerative AI chatbots,\u201d but it does not specify whether the chatbot is an LLM-based system (e.g., ChatGPT, GPT-4) or a different, possibly rule-based or non-transformer tool. Without explicit mention of an LLM or a clearly generative transformer-based model, it is unclear whether it meets the LLM criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is L2 writing: the intervention is \u2018AI chatbot-integrated writing tasks,\u2019 and outcomes include writing self-efficacy and aspects of critical thinking related to language construction and organization in students\u2019 writings. The focus is pedagogical, not automated scoring or system evaluation.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports quantitative outcomes only for writing self-efficacy and critical thinking ability via questionnaires. There is no explicit mention of quantifiable writing performance metrics (e.g., writing scores, text quality measures). The only writing-related outcome is self-efficacy, which is an affective/psychological construct rather than a direct writing performance measure.""}}"
Harnessing Ai in Academic Writing: the Complex Interplay of Ai Literacy and Self-directed Learning among University L2 Learners,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Chinese university students engaged in academic English writing, i.e., L2 English learners in an EFL context: \u201cacademic English writing among Chinese university students.\u201d""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines AI literacy and self-directed learning, not an experimental or quasi-experimental LLM-based writing intervention. AI tools are mentioned generically (summarization, translation, feedback), but there is no indication of a structured LLM-mediated instructional treatment or comparison group design.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on AI literacy and its relationship with self-directed learning, not on writing competence as an outcome. Writing is the context (academic English writing tasks), but the constructs measured are AI literacy dimensions and SDL, not writing performance or writing-related skill development through an intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Quantitative outcomes are about SDL and AI literacy components (awareness, ethics, usage, evaluation). The abstract does not report any quantifiable writing outcome metrics (e.g., writing scores, quality ratings, accuracy, complexity) to assess effectiveness of AI/LLM-mediated writing intervention.""}}"
"Impacts of Genai-assisted Collaborative Prewriting on University Efl Students’ Interactions with Genai, Outline Quality, and Task Motivation",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were 69 Chinese undergraduates in an EFL context, and the study explicitly concerns English as a foreign language (EFL) writing instruction, so the population is L2 English learners.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study integrates a generative AI (GenAI) tool\u2014described as supporting outline creation\u2014into EFL writing instruction, comparing GenAI-assisted collaborative prewriting (GACP) and GenAI-assisted individual prewriting (GAIP) in a within-subjects design. This aligns with an LLM-based writing intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on prewriting (outline creation), interactions with GenAI, and task motivation. While related to writing, the measured outcomes are outline quality and motivation, not actual writing competence or performance. The abstract does not indicate that full written texts or writing proficiency were assessed.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Quantitative outcomes are reported for outline quality (content, organization, language) and task motivation, but there is no indication of quantifiable outcomes for full L2 writing performance or competence. As the review requires writing outcome metrics, this study does not meet that criterion based on the abstract.""}}"
Understanding Efl Student Writers’ Metacognitive Awareness in Utilizing Chatgpt,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 452 EFL undergraduate students in a semester-long writing course, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although students use ChatGPT for academic writing feedback, the study is described as a mixed-method investigation of metacognitive awareness, not as an experimental or quasi-experimental intervention testing the effects of an LLM-based instructional treatment on writing.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The context involves using ChatGPT for EFL academic writing feedback, which is writing-related, but the primary focus is on metacognitive awareness and practices rather than a structured pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports validation of a metacognitive awareness scale and qualitative insights into metacognitive practices. It does not mention any quantifiable writing outcome metrics (e.g., writing scores, text quality measures) assessing the effectiveness of ChatGPT-mediated writing intervention.""}}"
