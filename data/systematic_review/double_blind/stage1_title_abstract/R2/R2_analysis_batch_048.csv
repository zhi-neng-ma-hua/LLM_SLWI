Title,Year,Decision,Notes
Investigating Connections between Teacher Identity and Pedagogy in a Content-based Classroom,2021,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are L2 English learners in an L2 English legal education (LLM) program, learning to write a legal genre (office memorandum), which fits ESL/EAP-type contexts focused on English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a classroom-based ethnography of a content-based legal research and writing course. There is no mention of large language models, AI tools, or any experimental/quasi-experimental integration of LLMs into instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the context involves teaching legal writing, the primary focus is on connections between teacher identity and pedagogy in a CBI classroom, not on writing competence or writing-related variables as outcomes of a specific intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is qualitative (ethnography) and does not report quantifiable writing outcome metrics. Data sources include observations, fieldnotes, artifacts, and interviews, with no experimental measures of writing performance.""}}"
Application of Artificial Intelligence Powered Digital Writing Assistant in Higher Education: Randomized Controlled Trial,2021,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as \""English second postgraduate students\"" and \""non-native postgraduate students in English academic writing,\"" indicating L2 English learners in an English academic writing context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The intervention is an \""Artificial Intelligence (AI) powered writing tool\"" but the abstract does not specify that it is a large language model (e.g., ChatGPT/GPT-based or transformer generative model). It could be a non-LLM tool (e.g., traditional NLP, grammar checker). Without explicit indication of LLM use, this does not clearly meet the LLM criterion.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The context is English academic writing, but the primary outcomes reported are behavioral, emotional, and cognitive engagement, self-efficacy for writing, and emotions. There is no indication that writing competence or text quality itself was measured; the focus is on engagement and attitudes rather than writing performance.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports quantitative outcomes only for engagement, self-efficacy, and emotions. No quantifiable writing outcome metrics (e.g., writing scores, text quality measures, accuracy, complexity) are mentioned, so it does not meet the requirement for writing performance outcomes.""}}"
Ensemble Multi-channel Neural Networks for Scientific Language Editing Evaluation,2021,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The abstract discusses scientific papers authored by non-native English speakers in general and an AESW shared task dataset, but does not describe any participant group of L2 English learners in an ESL/EFL/ELL instructional context. It is a system paper, not a learner study.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study proposes an Ensemble Multi-Channel Neural Networks (EMC-NN) model for sentence-level language editing evaluation. It is not an LLM-based (e.g., ChatGPT/GPT-4) pedagogical intervention; it is a classification model for detecting whether a sentence needs editing.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on automated scientific writing evaluation (predicting if a sentence needs editing) and model performance (F1-score), not on writing instruction, learner use of tools, or writing competence development in an educational context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are model performance metrics (F1-score) on a test set, not quantifiable writing outcomes for learners following an LLM-mediated writing intervention. No experimental measures of learner writing improvement are described.""}}"
Automated L2 Writing Performance Assessment: a Literature Review,2021,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses ESL/EFL writing instruction contexts in general but does not specify participant populations, as this is a literature review rather than an empirical study with its own sample.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The article is explicitly described as a literature review on Automated Writing Evaluation (AWE) systems over the last two decades. It does not report an experimental or quasi-experimental intervention using LLMs; instead, it synthesizes prior work.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the topic is writing assessment and feedback, the paper is a literature review, not a primary study implementing a pedagogical intervention or writing process integration with LLMs.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a literature review, the study does not report its own quantifiable writing outcome metrics from an intervention; it summarizes previous research instead.""}}"
A Hierarchical Bert-based Transfer Learning Approach for Multi-dimensional Essay Scoring,2021,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract mentions a self-collected dataset of Chinese EFL learners\u2019 argumentation (CELA), indicating that participants are English as a Foreign Language learners writing in English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses BERT, a pre-trained transformer model, for automated essay scoring, but there is no experimental or quasi-experimental pedagogical intervention integrating an LLM into writing instruction or learners\u2019 writing processes. It is a modeling study, not an instructional intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on developing and evaluating an automated essay scoring system (multi-dimensional AES) and improving QWK scores compared to baselines. There is no teaching/learning context or writing instruction intervention; it is an assessment/algorithmic performance study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are model performance metrics (quadratic weighted kappa) for scoring essays, not changes in learners\u2019 writing competence or writing-related variables following an LLM-mediated intervention. No experimental measures of instructional effectiveness are described.""}}"
A Literature Review of Foreign Studies on the Impact of Call on Second Language Acquisition from 2015,2021,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses second language acquisition and CALL in general but does not specify that the reviewed studies focus on L2 English learners in ESL/EFL/ELL contexts or that English is the target language.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The article is explicitly described as a literature review of empirical studies on computer-assisted language learning (CALL) from 2015. It is not an experimental or quasi-experimental primary study, and it does not specifically focus on LLM-based tools such as ChatGPT or GPT-4.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The focus is broadly on computer-assisted language teaching and second language acquisition, not specifically on writing competence or writing-related variables. The abstract does not indicate that writing is the primary focus.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a literature review, the paper does not report its own experimental writing outcome metrics; it synthesizes prior studies instead. This does not meet the requirement for quantifiable writing outcomes from an LLM-mediated intervention.""}}"
Digital Storytelling with Chatbots: Mapping L2 Participation and Perception Patterns,2021,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The context is an L2 class at a university in South Korea, which strongly suggests EFL learners, but the abstract does not explicitly state that the target language is English. It only refers to \u201cL2\u201d and \u201cL2 goals,\u201d so the specific language cannot be confirmed from the abstract alone.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses a \u201cdigital storytelling chatbot system (storybot).\u201d The abstract does not indicate that this chatbot is a large language model or transformer-based generative model (e.g., ChatGPT, GPT-4). It appears to be a rule-based or pre-scripted chatbot focused on narrative interaction, not an LLM-based tool.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The focus is on increasing L2 output and reading comprehension via storybot interactions. While students do write messages, the primary reported benefit is reading comprehension and participation, not writing competence or writing-related variables as a central outcome. Writing is not clearly framed as the main instructional focus.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports participation analytics (amount read vs. written) and survey-based perceptions. It does not report quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity) to assess effectiveness of a writing intervention. Outcomes are mainly participation and perception, with some reading comprehension indication, not structured writing measures.""}}"
The Intervention of Internet Technology on Students' English Learning in the Intelligent Era,2021,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Chinese medicine undergraduates learning English as a second language in China (ESL/EFL context). The study explicitly concerns second language learning (SLL) and English learning ability, including English writing ability.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is described as an 'Internet learning system' and 'Internet technology' with AI resources and intelligent learning system, but there is no indication that a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model) is used. It appears to be a general AI/Internet-based learning platform, not an LLM-based writing tool.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""Writing is one of several skills measured (listening, reading, writing, translation), and the primary focus seems to be overall English learning performance, motivation, and anxiety rather than writing competence specifically. Writing-related variables are included but not clearly the primary focus.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable outcomes, including English learning performance and subskills such as writing, with statistical comparisons between experimental and control groups (e.g., p<0.01 for writing performance differences).""}}"
Research on the Design of Lexical-chunks Centered Mode of Writing under Artificial Intelligence in College English Course,2021,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study is situated in a college English course with EFL learners (\u201ccollege English writing teaching model\u2026 for EFL, especially for students with a relatively low language proficiency\u201d), indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The abstract mentions \u201cbig data technology\u201d and \u201cartificial intelligence\u201d in general but does not specify the use of large language models (e.g., ChatGPT, GPT-4) or any transformer-based generative model. It appears to be a data-driven monitoring/feedback system rather than an LLM-mediated writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on a \u201ccollege English writing teaching model\u201d and how lexical-chunk-centered instruction affects students\u2019 writing input and output, clearly centering on writing competence in an instructional context.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract notes that big data technology \u201ceffectively monitors the learning process\u201d and that lexical chunk teaching \u201cpromotes students\u2019 writing input and triggers output,\u201d but it does not report specific quantitative writing outcome measures or experimental results. It is unclear whether structured, quantifiable writing outcomes were collected.""}}"
The Listening Strategies of Non English Majors in Colleges and Universities Based on Artificial Intelligence,2021,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are non-English majors in colleges and universities studying English listening, which implies they are L2 English learners in an EFL/ESL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the title mentions 'based on artificial intelligence', the abstract describes a questionnaire study on listening strategies and metacognitive strategies. There is no indication of an experimental or quasi-experimental design integrating an LLM (e.g., ChatGPT, GPT-4) into instruction or learning processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on listening strategies and listening proficiency, not on writing competence or writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports questionnaire scores related to listening strategies and performance; there are no quantifiable writing outcome metrics or writing intervention effects.""}}"
L2 Learner Cognitive Psychological Factors about Artificial Intelligence Writing Corrective Feedback,2021,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 1,952 undergraduate L2 learners in China, focusing on English writings, which fits ESL/EFL/ELL L2 English learner contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses Pigai, described as an AI evaluating system for English writings. Pigai is a traditional automated writing evaluation tool and is not identified as an LLM or transformer-based generative model (e.g., ChatGPT, GPT-4, Gemini). Thus it does not meet the LLM-based intervention requirement.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is AI writing corrective feedback (WCF) and its relation to L2 learner cognitive psychology, clearly centered on writing and writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses Likert-scale questionnaires and interviews to examine perceptions, noticing, uptake, initiative, retention, and emotion. It does not report quantifiable writing performance outcomes (e.g., writing scores, quality measures) to assess effectiveness of the AI intervention on writing competence.""}}"
Examining the Impact of Grammarly on the Quality of Mobile L2 Writing,2021,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were Japanese L2 English university EFL students, clearly an L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses Grammarly, described as an intelligent writing assistant with predictive text and real-time corrective feedback. Grammarly is not an LLM-based generative tool like ChatGPT/GPT-4; it is an automated writing evaluation tool and is explicitly listed as an exclusion in the review criteria.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on mobile L2 writing quality and examines grammatical accuracy, lexical richness, writing fluency, and syntactic complexity, all of which are writing-related variables.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantitative outcomes (descriptive statistics and t-tests) on grammatical errors, lexical variation, fluency, and syntactic complexity, providing measurable writing outcome metrics.""}}"
Automated Writing Evaluation (awe) in Higher Education: Indonesian Efl Students' Perceptions about Grammarly Use across Student Cohorts,2021,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Indonesian undergraduate EFL students majoring in English education, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is Grammarly, an Automated Writing Evaluation (AWE) tool. Grammarly is not described as an LLM-based, transformer generative model in this study and is treated as a conventional AWE tool. The focus is on perceptions of Grammarly use, not on integrating an LLM such as ChatGPT, GPT-4, etc.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is EFL writing classes and the use of Grammarly to assist students\u2019 writing processes (compose and revise their writing), which is directly writing-focused.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study examines students\u2019 perceptions via questionnaires and interviews. There is no indication of quantifiable writing outcome metrics (e.g., writing scores, text quality measures) assessing effectiveness of the intervention; only perceptions of usefulness and drawbacks are reported.""}}"
Going beyond Computer-assisted Vocabulary Learning: Research Synthesis and Frameworks,2020,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to 'foreign language learner' and 'foreign vocabulary' but does not specify English as the target language or identify ESL/EFL/ELL contexts. The population and language focus cannot be confirmed as L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study presents computer-assisted vocabulary learning applications (image recommendation, context representation, location-based word recommendation) within the AIVAS platform. There is no indication that these tools are based on large language models or transformer-based generative models such as ChatGPT, GPT-4, or similar.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on vocabulary learning in informal settings, not on writing competence or writing-related variables. The applications support vocabulary acquisition, image selection, and context representation, with no mention of writing instruction or writing processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The reported evaluations involve human and data-driven assessments of the vocabulary learning systems, but there is no indication of quantifiable writing outcome metrics or any writing intervention outcomes.""}}"
Future Prediction of L2 Writing Performance: a Machine Learning Approach,2020,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 102 students of English Language Teaching in Turkey, clearly L2 English learners in an EFL/ESL-related higher education context, with outcomes explicitly about L2 writing performance.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study trains a machine learning model (Instance-Based Learning with Parameter K) using demographic and psychometric data to predict end-of-term L2 writing performance. There is no indication that a large language model (e.g., ChatGPT, GPT-4) is integrated into writing instruction or writing processes; it is a predictive analytics application, not an LLM-based pedagogical intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on predicting L2 writing performance using machine learning, not on an instructional or intervention context to improve writing competence. The model is used for early detection of potential failure, not as part of a writing pedagogy or feedback process.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although L2 writing performance is measured, the outcomes relate to prediction accuracy of the machine learning model (Pass/Fail prediction), not to the effectiveness of an LLM-mediated writing intervention. There is no experimental manipulation of a writing intervention and no comparison of writing outcomes due to an LLM-based tool.""}}"
Efl Writing Tasks and the Application of the Concept of Situatedness: Evaluating the Theoretical and Practical Aspects of the Saudi Efl Context,2020,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Saudi EFL students learning English at Qassim and Bisha Universities, clearly an EFL/ELL context with English as the target language.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention contrasts conventional written lectures with a virtual online learning environment framed by a Situated Learning approach and a training-technology design framework. There is no indication that large language models (e.g., ChatGPT, GPT-4) or transformer-based generative AI tools are used; technology appears to be a virtual/online environment and e-portfolios, not LLMs.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on improving EFL students\u2019 practical English writing skills through writing tasks in virtual versus conventional settings, aligning with writing competence as the main outcome.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses an experimental design with control and experimental groups and reports that the virtual language experience improved participants\u2019 practical English writing skills, implying quantifiable outcome measures (e.g., testing, e-portfolio evaluation).""}}"
Detecting Preposition Errors to Target Interlingual Errors in Second Language Writing,2020,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers generally to 'second language learners' and 'second language writing' but does not specify that the target language is English or that participants are ESL/EFL/ELL learners. It may be about other languages with diverse preposition systems.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study focuses on developing classifiers and fine-tuned BERT models for preposition error detection as part of a prospective digital writing assistant. There is no indication of an experimental or quasi-experimental pedagogical intervention using an LLM with learners; it is a computational NLP error-detection study.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on the technical task of preposition error detection and model performance, not on writing instruction or improving learners\u2019 writing competence through an implemented intervention. The envisioned assistant is not empirically tested as a teaching tool.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable learner writing outcomes or measures of writing improvement are reported. The outcomes concern classifier performance on error detection, not changes in learners\u2019 writing quality following an LLM-mediated intervention.""}}"
Bert-based Contextual Semantic Analysis for English Preposition Error Correction,2020,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Although ESL learners are mentioned, they are only the source of error data (preposition errors). There is no indication of actual participants in an instructional or intervention study; this is a computational error-correction model paper.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study presents a BERT-based preposition error correction model. BERT is a bidirectional encoder model, not a generative large language model used as an instructional tool in writing intervention. There is no experimental or quasi-experimental integration of an LLM into teaching or writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on developing an automatic preposition error correction system, not on pedagogical writing instruction or learner-facing writing processes. It is essentially an NLP error-correction/assessment tool, not a writing competence intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No learner writing outcomes or educational effectiveness metrics are reported. The paper evaluates model performance (e.g., matching scores) rather than changes in learners\u2019 writing ability following an intervention.""}}"
Research on the Cultivation of Non-english Majors' English Reading Interest: Poa Teaching Mode in the Internet + Era,2020,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are non-English majors engaged in college English reading instruction in China, i.e., L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is the POA (Production-Oriented Approach) teaching model in an 'Internet +' environment. There is no mention of large language models (e.g., ChatGPT, GPT-4) or any transformer-based generative AI being integrated into instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on English reading interest and reading instruction, not on writing competence or writing-related variables. Writing is only mentioned as one of several skills supported by reading, not as the target of the intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports effects on reading interest, not on quantifiable writing outcomes. No writing performance metrics or writing-related measures are described.""}}"
"Exploring the Development of Writing Complexity, Accuracy, and Fluency in Relation to the Motivational Trajectories: a Dynamically-oriented Case Study; 探討與動機軌跡相關的寫作複雜度,正確性和流暢度的發展:一個動態性的個案研究",2020,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participant is described as a 'successful highly motivated EFL learner,' indicating an English-as-a-foreign-language context and thus an L2 English learner.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""In this study, 'LLM' refers to language learning motivation, not large language models. There is no mention of ChatGPT, GPT-4, or any transformer-based generative model, nor any AI-mediated instructional intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on the development of writing complexity, accuracy, and fluency (CAF) in L2 writing, clearly centering on writing competence and related variables.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study quantitatively assesses CAF measures across ten stages of monthly writing assignments, providing quantifiable writing outcome metrics, even though these are not linked to any LLM-based intervention.""}}"
