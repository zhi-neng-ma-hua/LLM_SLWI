Title,Year,Decision,Notes
"Learner Interaction With, and Response To, Ai-programmed Automated Writing Evaluation Feedback in Efl Writing: an Exploratory Study",2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are five Chinese university-level English as a foreign language (EFL) students, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses Pigai, described as an AI-programmed automated writing evaluation (AWE) system. Pigai is a traditional AWE tool, not identified as a large language model (e.g., ChatGPT, GPT-4, Gemini). The study focuses on interaction with AWE feedback, not an LLM-based generative system.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is EFL writing and student interaction with automated writing evaluation feedback, clearly centered on writing processes and responses to feedback in writing tasks.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is described as an exploratory analysis of how students interact with Pigai feedback and their response patterns. There is no indication of experimental or quasi-experimental design with quantifiable pre/post or comparative writing outcome measures; it focuses on interaction patterns and take-up rates, not on measured changes in writing competence.""}}"
Efl Teachers' Perceptions of the Use of an Ai Grading Tool (cograder) in English Writing Assessment at Saudi Universities: an Activity Theory Perspective,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are EFL teachers, not L2 English learners. The focus is on teachers' beliefs about an AI grading tool, not on learner outcomes or learner participants.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines perceptions of an AI grading tool (CoGrader) used for essay scoring and feedback. There is no indication that it is an LLM-based generative model integrated into instruction; it is positioned as scoring software, not as a transformer-based LLM writing assistant in an experimental or quasi-experimental intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is assessment (AI grading of essays) and teachers\u2019 beliefs, not a pedagogical writing intervention aimed at improving writing competence. It evaluates CoGrader as a scoring and feedback tool rather than as part of a structured instructional context for writing development.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports teachers\u2019 perceptions and beliefs; it does not report quantifiable writing outcome metrics for learners or measure the effectiveness of an LLM-mediated writing intervention. No experimental writing performance data are mentioned.""}}"
Indonesian University Students' Perspectives on Integrating Aied into English Language Learning,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Indonesian university students in English language learning contexts, which fits L2 English learners (EFL/ESL/ELL).""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a quantitative survey of perceptions of AIEd tools. It lists various AI-related writing features (translation, grammar checkers, paraphrasers, idea generators, citation management) but does not specify that these are LLM-based tools (e.g., ChatGPT, GPT-4) nor implement an experimental or quasi-experimental LLM-mediated intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although writing skills and related tools are mentioned as questionnaire items, the primary focus is on technology acceptance and perceptions of AIEd in general, not on a structured writing instruction or intervention targeting writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports perception indices (Likert-scale scores) but no quantifiable writing performance outcomes or writing-related achievement measures resulting from an intervention.""}}"
"Chatgpt Is Powerful, but Does It Have Power Distance? a Study of Culturally Imbued Discourse in Ai-generated Essays",2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are L1-English university learners and ChatGPT-generated texts. There is no mention of L2 English learners in ESL/EFL/ELL contexts; the comparison is between AI output and native-speaker essays.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is used as a text generator for comparison, not as part of an experimental or quasi-experimental pedagogical intervention in writing instruction. No instructional design integrating LLMs into learners\u2019 writing processes is described.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on culturally imbued discourse (power distance) in AI-generated vs. human essays, not on improving learners\u2019 writing competence through an intervention. It is essentially a discourse/linguistic analysis of texts, not a teaching/learning context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics for learners are reported. The study reports statistical differences in linguistic features between ChatGPT and L1 essays, but not outcomes of an LLM-mediated writing intervention on learner performance.""}}"
Investigating the Accuracy of Chatgpt as a Writing Error Correction Tool,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly refers to ESL learners and their writing errors, indicating the population is L2 English learners in an ESL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study investigates ChatGPT\u2019s accuracy as an error correction tool using pre-created data sets and content analysis. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating ChatGPT into instruction or learners\u2019 writing processes; it is a tool-evaluation study.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on ChatGPT\u2019s error detection and correction performance across error categories, not on developing or assessing learners\u2019 writing competence through an instructional intervention. This aligns more with system performance evaluation than with a writing pedagogy context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported are accuracy levels of ChatGPT across error categories (high, moderate, low), not quantifiable changes in learners\u2019 writing performance following an LLM-mediated intervention. No pre/post or comparative learner writing outcomes are mentioned.""}}"
Enhancing L2 Writing Skills: Chatgpt as an Automated Feedback Tool,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Turkish pre-service teachers of English in an academic writing course, clearly functioning as L2 English learners in an EFL/ESL higher education context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study explicitly uses ChatGPT, an AI-powered large language model, as an automated feedback tool for L2 writing in a course context, integrated alongside peer and instructor feedback.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on L2 writing, specifically on using ChatGPT as a feedback tool in an academic writing course, i.e., writing instruction and the writing process.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The methodology relies on focus-group interviews and thematic analysis of perceptions about ChatGPT as a feedback tool. The abstract does not report any quantitative or experimental writing outcome measures (e.g., changes in writing scores, accuracy, complexity), and future research is suggested to examine long-term influence on L2 writing, implying such outcomes were not measured here.""}}"
The Differential Role of Ai-operated Wcf in L2 Students' Noticing of Errors and Its Impact on Writing Scores,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 75 university undergraduate EFL students, clearly indicating L2 English learners in an EFL context. Writing tasks are IELTS Task 2 argumentative prompts, which are in English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The AI tools used are Grammarly and E-rater. These are automated writing evaluation/correction systems and are not described as large language models (e.g., ChatGPT, GPT-4, Gemini). The study focuses on AI-operated WCF via these tools, which do not qualify as LLM-based generative models under the review\u2019s criteria.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on written corrective feedback (WCF), noticing of errors, and writing scores in argumentative writing tasks, which are core writing-related variables in L2 instruction.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The quasi-experimental design compares four feedback conditions and explicitly examines their impact on writing scores and noticing, providing quantifiable outcome measures related to writing performance.""}}"
"Which One? Ai-assisted Language Assessment or Paper Format: an Exploration of the Impacts on Foreign Language Anxiety, Learning Attitudes, Motivation, and Writing Performance",2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were 70 intermediate English learners at Bangladeshi universities, clearly L2 English learners in an EFL/ESL context, with outcomes focused on English writing (TOEFL iBT writing section).""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is described only as \u201cAI-assisted language assessment\u201d versus \u201cpaper-format assessment.\u201d The abstract does not specify that the AI tool is a large language model (e.g., ChatGPT, GPT-4) or a transformer-based generative model integrated into writing instruction or processes. It appears to be an assessment modality rather than an LLM-mediated writing intervention.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""Writing skills are one of several outcomes (along with foreign language anxiety, attitudes, and motivation), and the AI is used in assessment rather than clearly in instruction or process-oriented writing support. The primary focus seems broader than writing competence alone, and the pedagogical use of AI for writing is not clearly described.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcomes: TOEFL iBT writing scores were used as pretest and posttest measures, with comparisons between experimental and control groups, even though posttest differences were not statistically significant.""}}"
Examining Ai-based Accuracy Assessment in L2 Learners' Writing,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract refers to L2 learners\u2019 academic writings and mentions EFL learners, indicating a population of English L2 learners in an EFL/ESL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is used solely as an evaluator of writing accuracy, compared to human raters. There is no experimental or quasi-experimental instructional intervention integrating ChatGPT into the writing process or teaching; it is a rater-functionality study.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on the reliability/validity of AI-based accuracy assessment (ChatGPT as an evaluator) rather than on improving writing competence through a pedagogical intervention. This aligns with automated essay scoring/assessment research, which is excluded by the review criteria.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although writing scores and error counts are reported, they are used to compare human vs. AI ratings, not as outcomes of an LLM-mediated instructional or writing intervention. No pre/post or controlled intervention effects on learners\u2019 writing are examined.""}}"
Strategic Use of Machine Translation: a Case Study of Japanese Efl University Students,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Japanese EFL university students at CEFR A2 level, clearly L2 English learners in an EFL context: \u201cJapanese EFL university students\u2026 CEFR A2 university students.\u201d""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention focuses on the use of machine translation (MT) in L2 writing. The abstract does not indicate that the MT system is an LLM-based generative model (e.g., ChatGPT, GPT-4). It is framed as conventional MT use, not as an LLM-integrated writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study explicitly targets L2 writing processes and strategies with MT: \u201cresearch on MT use in L2 writing\u2026 explore how\u2026 students employ strategies for L2 writing with MT and how their strategies change after strategy instruction.\u201d The primary focus is on writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are qualitative changes in strategy use and cognitive engagement, not quantifiable writing performance metrics. The abstract reports increased and more elaborate strategy use, but no measured writing quality scores or other quantitative writing outcomes.""}}"
Incorporating Ai in Foreign Language Education: an Investigation into Chatgpt's Effect on Foreign Language Learners,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""Participants are described as \u2018preparatory class students studying at the School of Foreign Languages at a university in Turkey.\u2019 The target language is not explicitly stated as English, only \u2018foreign language education.\u2019 It is therefore unclear whether they are L2 English learners or learners of another language.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study \u2018aimed to utilize ChatGPT in foreign language education\u2019 and students \u2018were introduced to ChatGPT through learning experiences over a span of four weeks.\u2019 ChatGPT is an LLM and is integrated into instruction, satisfying the LLM-based intervention requirement.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The abstract notes that ChatGPT \u2018positively affects students' learning experiences, especially in writing, grammar, and vocabulary acquisition,\u2019 and that it is used \u2018in various learning activities.\u2019 Writing is explicitly mentioned as a focus area within the language learning context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is described as a \u2018qualitative case study\u2019 with data from interviews analyzed via thematic analysis. No mention is made of quantitative or experimental writing outcome measures; findings are reported in terms of perceived effects and experiences, not measurable writing performance.""}}"
Leveraging Chatgpt in the Writing Classrooms: Theoretical and Practical Insights,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers broadly to \u201csecond language (L2) writing pedagogy\u201d and \u201cL2 writing teachers and students,\u201d but does not specify that the target language is English or that participants are ESL/EFL/ELL learners. It appears conceptual rather than reporting on a specific participant population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The paper is described as exploring the potential of integrating ChatGPT and providing theoretical and practical insights, challenges, and recommendations. There is no indication of an experimental or quasi-experimental design, nor of an implemented LLM-based intervention with participants.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the focus is on L2 writing pedagogy and integrating ChatGPT into stages of the writing process, the article is conceptual and pedagogical rather than an empirical study of a specific instructional context or intervention with measured outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or empirical assessment of effectiveness. It offers theoretical discussion, challenges, and research recommendations, but no reported intervention results or metrics.""}}"
"Teacher- Versus Ai-generated (poe Application) Corrective Feedback and Language Learners' Writing Anxiety, Complexity, Fluency, and Accuracy",2024,unsure,"{""c1"": {""status"": ""unclear"", ""evidence"": ""Participants are described only as \u201clanguage learners\u201d and \u201cundergraduate language learners at East China University of Political Science and Law.\u201d The abstract does not explicitly state that they are L2 English learners, nor that the target language is English. The mention of \u2018primary school settings\u2019 at the end further confuses the context. Thus, it is unclear whether the population is L2 English learners in ESL/EFL/ELL contexts.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The intervention uses an \u201cAI-driven application called Poe\u201d that provides corrective feedback. However, the abstract does not specify whether Poe is using a large language model (e.g., GPT-based, transformer generative model) or some other AI technology. Without confirmation that Poe is LLM-based, it is unclear whether this meets the LLM criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on writing-related variables: writing anxiety, writing complexity, fluency, and accuracy. The intervention is corrective feedback on learners\u2019 writing, not automated essay scoring or purely functional evaluation of an AI system. Thus, the primary focus aligns with writing competence and related variables.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses a quasi-experimental pretest\u2013posttest design with three groups and reports quantitative outcomes on writing complexity, fluency, accuracy, and writing anxiety, analyzed via one-way ANOVA. These are quantifiable writing outcome metrics assessing the effectiveness of the AI-mediated writing intervention.""}}"
Exploratory Study on the Potential of Chatgpt as a Rater of Second Language Writing,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Korean secondary-level EFL students writing English essays, clearly fitting an L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT (GPT-4) is used as an automated writing evaluation (AWE) scoring tool, not as part of an instructional or experimental/quasi-experimental pedagogical intervention in writing. The focus is on rating reliability, not on integrating LLMs into writing instruction or processes for learning.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on assessment\u2014comparing ChatGPT\u2019s essay scores with human raters\u2014rather than on improving writing competence or writing-related learning outcomes. This aligns with automated essay scoring functionality, which the criteria specify should be excluded.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports reliability metrics (intraclass correlation, Rasch model deviations) for scoring, not quantifiable outcomes of an LLM-mediated writing intervention (e.g., changes in learners\u2019 writing performance after using ChatGPT). There is no structured instructional intervention with pre/post writing measures.""}}"
Facilitating Learners' Self-assessment during Formative Writing Tasks Using Writing Analytics Toolkit,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers only to \u201clearners\u201d and does not specify that they are L2 English learners in ESL/EFL/ELL contexts, nor that the target language is English. Their language background and instructional context are not described.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is a \u201cwriting analytics toolkit\u201d using \u201cdata visualisation and cutting-edge machine learning technology\u201d to provide feedback. There is no indication that it is based on large language models (e.g., ChatGPT, GPT-4, transformer-based generative models). It appears to be an analytics/ML feedback tool rather than an LLM-integrated writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on formative writing tasks, revision, and self-assessment of writing products and processes. The primary context is writing competence and writing-related processes (self-assessment during writing).""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantitative outcomes: differences in self-assessment accuracy between experimental and control groups, and analysis of self-assessment processes. These are structured, measurable outcomes related to the writing process.""}}"
The Effect of Chatgpt-integrated English Teaching on High School Efl Learners' Writing Skills and Vocabulary Development,2024,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 10th grade Turkish EFL learners in English lessons. The focus is explicitly on English as a foreign language, satisfying the requirement for L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study examines \u201cChatGPT-integrated English lessons\u201d and compares an experimental group receiving ChatGPT-integrated vocabulary and writing instruction with a control group receiving traditional instruction, indicating an experimental/quasi-experimental LLM-based intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary outcomes are \u201cwriting skill and vocabulary development,\u201d and the intervention is explicitly described as vocabulary and writing instruction. The focus is pedagogical, not on automated scoring or system evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses pre- and post-tests for writing and vocabulary, analyzed statistically with SPSS, and reports comparative effects of traditional vs. ChatGPT-integrated instruction. This provides quantifiable writing outcome metrics.""}}"
Potentials and Implications of Chatgpt for Esl Writing Instruction,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The article is a systematic review and meta-analysis of prior research on ChatGPT for L2 writing instruction. It does not report on a specific primary study with its own participant sample of L2 English learners; instead, it synthesizes other studies.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""As a systematic review, the paper does not itself implement an experimental or quasi-experimental LLM-based writing intervention; it only summarizes existing research on ChatGPT\u2019s educational potentials.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the focus is on L2 writing instruction, the article is a secondary study (systematic review/meta-analysis) rather than a primary pedagogical intervention study, which the inclusion criteria explicitly exclude.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports synthesized findings (e.g., boosting motivation, automating tasks, providing feedback) but does not present original, quantifiable writing outcome metrics from a primary intervention; as a review/meta-analysis, it falls under excluded publication types.""}}"
Enhancing English as a Foreign Language (efl) Learners' Writing with Chatgpt: a University-level Course Design,2024,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as university-level English as a Foreign Language (EFL) learners, which fits the target population of L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study clearly integrates OpenAI\u2019s GPT-3.5 (an LLM) into a writing course and discusses course design (ADDIE, TPACK). However, the abstract does not specify whether there is an experimental or quasi-experimental design (e.g., control group, pre/post comparison, or structured intervention study) versus a purely design-oriented or descriptive implementation.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on an EFL writing course and on improving aspects of writing such as efficiency, organization, and feedback, indicating that the primary context is writing competence and writing-related variables.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract reports that GPT-3.5 \u2018enhances efficiency,\u2019 \u2018ensures cohesive organization,\u2019 and \u2018promotes writing proficiency,\u2019 but it does not indicate whether these findings are based on quantifiable writing outcome metrics (e.g., scores, rubric-based assessments, statistical comparisons) or are derived from qualitative/descriptive evaluation only.""}}"
Generating Genre-based Automatic Feedback on English for Research Publication Purposes,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers broadly to L2 writers and multilingual classrooms and to English for research publication purposes, but does not specify that the participants are L2 English learners in ESL/EFL/ELL contexts, nor does it clearly describe an empirical learner sample.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study focuses on the development of an AI-mediated L2 writing technology leveraging large language models and reports on the accuracy, precision, and recall of its network classification. It appears to be a system-development and evaluation study, not an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction with learners.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on generating genre-based automatic feedback and evaluating the performance of the classification network (accuracy, precision, recall). It is framed as tool development and automated feedback provision, not as an implemented writing intervention with measured effects on learners\u2019 writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Reported outcomes are technical metrics of the system (accuracy, precision, recall of classification). There is no indication of quantifiable writing outcome measures (e.g., changes in writing quality, complexity, accuracy) for L2 learners following an LLM-mediated writing intervention.""}}"
A Study on Chatgpt-4 as an Innovative Approach to Enhancing English as a Foreign Language Writing Learning,2024,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 76 undergraduate students in Algeria learning English as a Foreign Language (EFL). The abstract explicitly focuses on EFL writing, indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention is the use of ChatGPT-4, explicitly named as the tool used by the experimental group to support EFL writing. ChatGPT-4 is a large language model, and the study uses an experimental design with experimental and control groups.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on EFL writing learning and how ChatGPT-4 is used to address challenges in EFL writing. The outcome discussed is improvement in EFL writing skills, not automated scoring or system evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports that the experimental group outperformed the control group and that post-test scores exceeded pre-test scores, indicating quantifiable writing outcome measures. Additional quantitative measures include perceived usefulness, ease of use, attitudes, and behavioral intention.""}}"
