Title,Year,Decision,Notes
"A Systematic Review of Chatgpt for English as a Foreign Language Writing: Opportunities, Challenges, and Recommendations",2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The article explicitly focuses on English as a Foreign Language (EFL) writing, indicating that the population of interest across the reviewed studies is EFL learners working with English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""This is a systematic review of prior studies on ChatGPT in EFL writing, not an experimental or quasi-experimental primary study implementing an LLM-based intervention itself. Review articles are to be excluded.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on EFL writing, discussing how ChatGPT is adopted for EFL writing, including opportunities and challenges in writing instruction and curricula.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a systematic review, it synthesizes literature and provides recommendations but does not itself report original, quantifiable writing outcome metrics from an intervention it conducts. Review-type studies are excluded by design.""}}"
Chatgpt over My Friends: Japanese English-as-a-foreign-language Learners’ Preferences for Editing and Proofreading Strategies,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 33 Japanese English-as-a-foreign-language learners, clearly an EFL context with English as the target language.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT-3.5 (an LLM) is used, the design is not experimental or quasi-experimental regarding learning outcomes. The study contrasts experiences and preferences between writing groups and ChatGPT use, but there is no indication of an intervention aimed at measuring effectiveness on writing performance.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is academic writing in an EFL classroom, focusing on editing and proofreading to improve clarity and cohesion in writing, which is directly writing-related.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are students\u2019 preferences and perceptions gathered via questionnaires. The abstract does not mention any quantifiable writing performance metrics (e.g., scores, error rates, rubric-based improvements) to assess the effectiveness of the LLM-mediated intervention.""}}"
Uncovering Students’ Processing Tactics towards Chatgpt’s Feedback in Efl Education Using Learning Analytics,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as EFL students, i.e., English as a Foreign Language learners, which fits the target population of L2 English learners.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study examines students\u2019 interaction with ChatGPT, a generative AI large language model, during reading and writing tasks, and analyzes their processing tactics toward ChatGPT\u2019s feedback. This constitutes an LLM-based intervention embedded in learning activities.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although reading and writing tasks are mentioned, the primary analytic focus is on Processing Tactics towards ChatGPT\u2019s Feedback and learning modes, with reported outcomes being \u2018learning gains\u2019 and \u2018improvement of domain knowledge.\u2019 The abstract does not indicate that writing competence or writing-related performance measures are the main focus; instead, domain knowledge gains are emphasized.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports differences in learning gains and improvement of domain knowledge among groups, but it does not specify any quantifiable writing outcome metrics (e.g., writing quality scores, accuracy, complexity, organization). Thus, it lacks explicit quantitative writing performance outcomes required for inclusion.""}}"
Towards Fair Detection of Ai-generated Essays in Large-scale Writing Assessments,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The population is described only as native and non-native English speakers in a large-scale writing assessment. There is no indication that the focus is on L2 English learners in ESL/EFL/ELL instructional contexts; rather, the concern is test security and detector bias across demographic groups.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study focuses on strategies for detecting AI-generated essays and mitigating detector bias. It does not describe an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or processes for learners.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on AI-generated text detection and fairness (bias across native vs. non-native speakers) in assessment security, not on improving writing competence or writing-related learning outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) are reported. Outcomes relate to detection accuracy and bias, not to the effectiveness of an LLM-mediated writing intervention.""}}"
Advancing Sustainable Learning by Boosting Student Self-regulated Learning and Feedback through Ai-driven Personalized in Efl Education,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are junior high school EFL students (L2 English learners) in an Asian context: \u201cEnglish as a Foreign Language (EFL) students\u2026 The population in this study is junior high school class VIII\u2026\u201d. The focus is clearly on English language learning.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers broadly to \u201cAI-mediated language teaching\u201d and \u201cAI-powered platforms\u201d but does not specify that these are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems. The type of AI (LLM vs. other forms such as adaptive or analytic tools) is not identified, so it is unclear whether an LLM is integrated into instruction.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The study examines self-regulated learning, feedback-response, and overall English proficiency (vocabulary, reading, writing, grammar). While writing ability is one of several skills tested, the primary focus appears to be broader AI-mediated language teaching and self-regulation, not specifically writing competence or writing-related variables as the central context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although pre- and post-tests include \u201cwriting ability\u201d among other skills, the abstract does not report any specific, quantifiable writing outcome metrics or analyses focused on writing performance. Outcomes are described in aggregate as \u201clearning English\u201d and \u201clanguage learning outcomes,\u201d with no clear writing-focused experimental measure reported, which does not meet the requirement for explicit quantifiable writing outcomes.""}}"
Ai in Subconscious Language Learning for Error Remediation,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses second language acquisition in general and classroom contexts (e.g., a class of 25 pupils) but does not specify that the learners are L2 English learners or that English is the target language. It also mentions language learning apps (LingQ, Rosetta Stone) in a general multilingual sense.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""AI is discussed broadly (e.g., Siri, Alexa, AI-powered platforms) with no indication that large language models (ChatGPT, GPT-4, etc.) are used. The focus is conceptual/theoretical on AI and individualized learning, not on an experimental or quasi-experimental LLM-based intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The abstract addresses language acquisition and AI-supported language learning in general, not writing competence or writing-related variables. There is no mention of writing instruction, writing tasks, or writing performance as a primary focus.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No experimental or quasi-experimental design is described, and no quantifiable writing outcome metrics are reported. The piece appears to be conceptual or descriptive rather than an intervention study with measured outcomes.""}}"
"Integrating Large Language Models into Efl Writing Instruction: Effects on Performance, Self-regulated Learning Strategies, and Motivation",2024,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are elementary school students in an English as a Foreign Language (EFL) context. The focus is explicitly on EFL writing, i.e., English as the target L2.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study develops and implements an 'LLM-supported Cognitive Academic Language Learning Model (CALLA-LLM)' and compares it to traditional CALLA in a randomized controlled trial. LLMs are integrated into the writing instruction as part of the experimental intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is EFL writing instruction and related variables: 'EFL writing performance, SRL strategy use, and writing motivation.' The LLM is used pedagogically within writing instruction, not merely for automated scoring or system evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract reports 'significant improvements in writing performance' and describes a randomized controlled trial with pre-, post-, and follow-up measures, indicating quantifiable writing outcome metrics were collected and analyzed.""}}"
Balancing Ai and Authenticity: Efl Students’ Experiences with Chatgpt in Academic Writing,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are explicitly described as EFL students, indicating L2 English learners in an EFL context, and the focus is on their academic writing in English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is central, the study is a qualitative case study of students\u2019 experiences and strategies. There is no indication of an experimental or quasi-experimental design, structured instructional intervention, or controlled integration of ChatGPT into teaching.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly academic writing: the study examines how EFL students incorporate ChatGPT into their academic writing process and its impact on essay quality and authenticity.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is based on semi-structured interviews and self-reported experiences. The abstract does not mention any quantifiable writing outcome metrics or experimental measures; findings are qualitative (perceptions, concerns, strategies).""}}"
The Impact of Chatgpt on Students’ Writing Proficiency in Second Language Acquisition: Students’ Perception and Experiences: a Qualitative Analysis,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cstudents\u2019 writing proficiency in second language acquisition\u201d but does not specify that the target L2 is English, nor that the context is ESL/EFL/ELL. The specific language is not identified.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""ChatGPT, an LLM, is used \u201cas a tool for language learning,\u201d but the abstract does not clearly describe an experimental or quasi-experimental instructional intervention (e.g., treatment vs. control, pre/post design). It focuses on experiences and perceptions rather than a structured intervention design.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study explicitly focuses on \u201cstudents\u2019 writing proficiency\u201d and \u201cwriting skills in the realm of second language acquisition,\u201d indicating that the primary focus is on writing competence in an L2 context rather than on automated scoring or system evaluation.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is described as \u201ca qualitative analysis\u201d using interviews and questionnaires to explore \u201csubjective experiences and perceptions.\u201d There is no indication of quantitative writing outcome measures or experimental assessment of writing performance.""}}"
"Using Artificial Intelligence to Foster Students’ Writing Feedback Literacy, Engagement, and Outcome: a Case of Wordtune Application",2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly states the context is second language (L2) learning and L2 writing. Participants are upper-intermediate L2 students, implying an ESL/EFL context focused on English, though the language is not named. This fits the target L2 English learner population more likely than not.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses Wordtune, described only as an \u201cAI-based application.\u201d Wordtune is primarily a rewriting/paraphrasing tool and is not clearly identified as an LLM-based, transformer generative model in the abstract. Under the review\u2019s criteria, tools like Grammarly/QuillBot-style systems that are not explicitly LLM-based should be excluded. There is no explicit mention of ChatGPT, GPT-4, or other LLMs, nor of a transformer-based generative model.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study\u2019s primary focus is on L2 writing: it examines writing feedback literacy, writing engagement, and writing outcomes. The AI tool is integrated into the writing process as an instructional aid, not as an automated scoring system. Thus, the context aligns with writing competence and related variables.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract reports that the experimental group using Wordtune \u201csignificantly improve[d] their writing outcomes, engagement, and feedback literacy when compared to the control group,\u201d indicating quantifiable outcome measures in a mixed-method, experimental design.""}}"
Understanding Efl Students’ Chatbot-assisted Argumentative Writing: an Activity Theory Perspective,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are five Chinese undergraduate EFL students (\u201cEnglish as a foreign language students\u201d), so they are L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses a chatbot called Argumate to assist argumentative writing, but the abstract does not specify whether Argumate is an LLM-based, transformer-style generative model (e.g., ChatGPT-like) or a rule-based/chatbot of another type.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on chatbot-assisted argumentative writing, examining how students engage with the chatbot while composing essays. The context is clearly writing pedagogy and writing processes, not automated scoring.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is described as qualitative, using activity theory to analyze processes. Data include screen recordings, chat logs, essays, and questionnaire responses, but the abstract does not indicate any experimental or quasi-experimental design or report quantifiable writing outcome metrics to assess effectiveness of the chatbot intervention.""}}"
Enhancing Efl Vocabulary Acquisition through Computational Thinking,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Chinese non-English majors in foreign language education, clearly functioning as EFL learners focusing on English vocabulary and short essay writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT and AI are mentioned in the introduction, the described intervention is based on computational thinking (CT) skills (data analysis, pattern recognition, abstraction, decomposition, parallelization) applied to vocabulary acquisition. There is no indication that an LLM (e.g., ChatGPT) was actually integrated as part of the instructional or writing intervention; CT itself is the intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on improving vocabulary richness in English short essay writing and measures vocabulary-related indices in students\u2019 writing, which is directly related to writing competence.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses QUITA software to measure vocabulary-related quantitative indices in short essay writing before and after the CT intervention, providing quantifiable writing outcome metrics.""}}"
Examining Efl Students' Motivation Level in Using Quillbot to Improve Paraphrasing Skills,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL students at Najran University enrolled in a Technical Writing course, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention tool is QuillBot. The abstract describes it as an online AI tool but does not indicate that it is an LLM-based, transformer generative model in the sense required (e.g., ChatGPT, GPT-4). Moreover, the design is descriptive-diagnostic (survey and interviews), not experimental or quasi-experimental writing instruction integrating an LLM.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on students\u2019 motivation to use QuillBot for paraphrasing, not on a structured writing intervention or instruction. The study is framed around motivational factors and perceptions rather than a pedagogical writing intervention with measured impact on writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are motivational levels and gender differences in responses, gathered via questionnaire and interviews. There are no quantifiable writing outcome metrics (e.g., changes in paraphrasing quality, writing scores) assessing the effectiveness of the tool on writing performance.""}}"
The Intersection of Ai and Language Assessment: a Study on the Reliability of Chatgpt in Grading Ielts Writing Task 2,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions IELTS Task 2 writing, which typically involves L2 English learners, but it does not explicitly state that the participants are ESL/EFL/ELL learners or provide details about their language learning context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT-4 is used solely as an automated grader to compare its scores with official human raters. There is no experimental or quasi-experimental pedagogical intervention integrating the LLM into writing instruction or learners\u2019 writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on the reliability of ChatGPT as an essay scoring system, not on improving writing competence or writing-related learning outcomes. It is an assessment-functionality study rather than a teaching/learning intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No writing outcome metrics for learners are reported; the outcomes are reliability statistics (e.g., Cohen\u2019s kappa, ICC) comparing AI and human scores. There is no structured LLM-mediated writing intervention whose effectiveness on learner writing is measured.""}}"
University Students’ Perceptions of Artificial Intelligence-based Tools for English Writing Courses,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Korean university students who have taken English writing courses and are explicitly described as English language learners (ELLs), fitting an EFL/ELL L2 English context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines perceptions of AI-based tools (Google Translate, Naver Papago, Grammarly). These are not clearly LLM-based writing interventions in an experimental or quasi-experimental design; rather, they are existing tools used by students, with no structured LLM-mediated instructional intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on students\u2019 perceptions of AI-based tools in English writing courses, not on a designed pedagogical intervention targeting writing competence. It is exploratory/perceptual rather than an instructional study integrating LLMs into writing processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although the study uses mixed methods, it reports perceptions of usefulness and concerns. There is no indication of quantifiable writing outcome metrics (e.g., pre/post writing scores) assessing the effectiveness of an AI-mediated intervention.""}}"
From Virtual Assistant to Writing Mentor: Exploring the Impact of a Chatgpt-based Writing Instruction Protocol on Efl Teachers’ Self-efficacy and Learners’ Writing Skill,2024,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Iranian English language teachers (n=12) and learners (n=48) in an L2 writing context, explicitly described as EFL. The focus is on English writing skills, satisfying the requirement for L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention is a ChatGPT-based writing instruction protocol (CGWIP). ChatGPT is a large language model, and it is integrated systematically into planning, instruction, and assessment phases of writing instruction. The study uses an experimental design with control and treatment groups and pre/post testing.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is explicitly L2 writing instruction. ChatGPT is used for brainstorming, engaging learners in the writing process, analyzing drafts, and simulating IELTS writing exams with feedback. The primary focus is on writing competence and related instructional processes, not on automated scoring alone.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantitative writing outcomes: learners\u2019 writing skills were measured before and after a 10-week program, analyzed via One Way ANCOVA, showing significant improvement and persistence over time. Thus, it provides quantifiable writing outcome metrics for the LLM-mediated intervention.""}}"
Utilizing Artificial Intelligence Tools for Improving Writing Skills: Exploring Omani Efl Learners’ Perspectives,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Omani EFL learners from the General Requirements Unit at the Preparatory Studies Centre, clearly an EFL context focused on English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study investigates learners\u2019 perceptions and practices in using unspecified \u2018artificial intelligence tools\u2019 (e.g., for translation, spelling, grammar). There is no indication that these are LLM-based tools (e.g., ChatGPT) nor that there is an experimental or quasi-experimental intervention integrating a specific LLM into instruction; it is a survey of existing practices.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the context is writing skills, the study focuses on perceptions and self-reported use of AI tools, not on a structured pedagogical writing intervention using LLMs.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses a Likert-scale questionnaire to measure perceptions and practices; it does not report quantifiable writing outcome measures (e.g., changes in writing quality, scores, or performance) resulting from an AI/LLM-mediated intervention.""}}"
Paraphrasing Prowess: Unveiling the Insights of Efl Students and Teachers on Quillbot Mastery,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as English as a Foreign Language (EFL) students and teachers, indicating an L2 English learning context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention tool is QuillBot, which is not clearly identified as an LLM-based transformer generative model in the abstract and is treated as a generic AI paraphrasing tool. Moreover, the design is a descriptive survey of perceptions, not an experimental or quasi-experimental integration of an LLM into instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on perceptions of using QuillBot for paraphrasing skills, not on a structured pedagogical writing intervention or instructional design aimed at improving writing competence. It is an attitudinal/perception study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports perceptions and the influence of demographic variables on responses. There is no mention of quantifiable writing outcome measures (e.g., pre/post writing scores, rubric-based writing quality, accuracy) to assess effectiveness of the tool on writing performance.""}}"
Chatgpt as an Automated Writing Evaluation (awe) Tool: Feedback Literacy Development and Awe Tools’ Integration Framework,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 18 English as a Foreign Language (EFL) students in Indonesia, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study examines the use of ChatGPT (an LLM-based tool) along with Grammarly and Quillbot as automated writing evaluation tools in a writing course, indicating an instructional integration of an LLM.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on learners\u2019 feedback literacy and the development of an AWE Tools Integration Framework, not on writing competence or writing-related performance variables. Writing is the context, but the outcome of interest is feedback literacy rather than writing ability.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses a single qualitative case study design with interviews, reflective journals, and artifacts, and reports thematic findings about feedback literacy. There is no mention of quantifiable writing outcome metrics or experimental measures of writing performance.""}}"
Evaluating Prompting Strategies for Grammatical Error Correction Based on Language Proficiency,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly mentions \u201clearners of English as a foreign language\u201d and analyzes grammatical error correction on \u201cwriting examples of English language learners\u201d across proficiency levels A\u2013C.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study evaluates prompting strategies (zero-shot, few-shot, fine-tuning) for LLM-based grammatical error correction, but there is no indication of an experimental or quasi-experimental pedagogical intervention in writing instruction. It is a system/performance evaluation, not an instructional intervention with learners.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on GEC system performance (overcorrection, precision/recall) across proficiency levels, not on developing or assessing learners\u2019 writing competence through an instructional context. It treats learner texts as test data for GEC, not as part of a teaching/learning intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are GEC evaluation metrics (precision, recall, overcorrection) of LLMs, not quantifiable changes in learners\u2019 writing performance following an LLM-mediated intervention. No learner outcome measures or pre/post comparisons are described.""}}"
