Title,Year,Decision,Notes
Feeding Two Birds with One Scone: Using Awe to Enhance Writing and Creativity among Pre-university Students,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as \u201celeven CEFR B1 second language learners\u201d in \u201cEnglish language writing instructions,\u201d indicating L2 English learners in an EFL/ESL-type context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses an Automated Writing Evaluation (AWE) tool based on NLP to generate feedback. There is no indication that this is a large language model (e.g., ChatGPT/GPT-4 or similar transformer-based generative model); it is framed as standard AWE, which falls outside the LLM-focused scope.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study explicitly focuses on \u201cEnglish language writing instructions\u201d and aims \u201cto improve writing proficiency and creative performance,\u201d aligning with writing competence as a primary focus.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses pre- and post-tests for writing and creativity, reporting \u201cimprovements in writing and creativity scores,\u201d which are quantifiable outcome measures of the intervention.""}}"
The Combination of Recognition Technology and Artificial Intelligence for Questioning and Clarification Mechanisms to Facilitate Meaningful Efl Writing in Authentic Contexts,2023,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as EFL learners, indicating L2 English learners in an EFL context. The focus is on EFL writing, so the target language is English.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses an app (UEnglish) with Image-to-Text Recognition and \u201cgenerative-AI that can generate meaningful questions and clarifications.\u201d However, the abstract does not specify whether this generative AI is a large language model (e.g., transformer-based LLM like ChatGPT/GPT-4) or another type of AI. Without this detail, it is unclear if it meets the LLM criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The intervention is a Smart Questioning-Answering-Clarification mechanism designed \u201cto help EFL writing\u201d and to enable learners to \u201cwrite more meaningful words in the assignments.\u201d The primary focus is on facilitating EFL writing in authentic contexts, not on automated scoring or system evaluation alone.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study is a five-week quasi-experiment with experimental and control groups, reporting significant differences in learning behaviors, post-test results, and that the experimental group \u201ccould write more meaningful words in the assignments.\u201d These indicate quantifiable writing-related outcome measures.""}}"
Rating Short L2 Essays on the Cefr Scale with Gpt-4,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract specifies that the essays are written by L2 English learners on a high-stakes language assessment, so the population clearly consists of L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""GPT-3.5 and GPT-4 are used as automated raters of essays, not as part of an instructional or intervention design for writing. There is no experimental or quasi-experimental integration of LLMs into writing instruction or writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on automated essay scoring reliability (inter-rater agreement with human ratings) and comparison with AWE methods. This is an assessment/measurement study, not a pedagogical writing intervention targeting writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports agreement between GPT ratings and human ratings, but not outcomes of an LLM-mediated writing intervention (no pre/post writing performance or instructional effect). It evaluates scoring performance, not changes in learners\u2019 writing.""}}"
The Impact of Automated Writing Evaluation on Second Language Writing Skills of Chinese Efl Learners: a Randomized Controlled Trial,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 190 Chinese EFL students, clearly identifying them as L2 English learners in an EFL context, with outcomes measured via an IELTS writing test in English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is Automated Writing Evaluation (AWE) using Grammarly. Grammarly is described as an AI-driven AWE program, but it is not a large language model-based generative tool like ChatGPT, GPT-4, or similar LLMs. The focus is on AWE feedback, not LLM-mediated writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study\u2019s primary focus is on improving L2 writing competence (task achievement, coherence and cohesion, lexicon, grammatical accuracy) through AWE training, which is directly related to writing skills rather than essay scoring research alone.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The randomized controlled trial reports quantifiable writing outcomes, including performance on IELTS writing tasks across multiple dimensions (task achievement, coherence and cohesion, lexicon, grammatical accuracy), comparing experimental and control groups.""}}"
Sentence-level Feedback Generation for English Language Learners: Does Data Augmentation Help?,2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions \u2018English language learners\u2019 as the target of feedback comments, but it does not specify whether any human L2 English learners participated in an instructional study or whether this is purely a system-development task using existing corpora.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study focuses on building and evaluating LLM-based systems for feedback comment generation and data augmentation, not on an experimental or quasi-experimental pedagogical intervention where L2 learners use LLMs in their writing process.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on the NLP task of feedback comment generation and system performance, not on learners\u2019 writing competence or a teaching/learning context. There is no indication of an instructional setting or writing intervention with learners.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports system performance and analysis of generated comments, but does not mention any quantifiable writing outcomes for L2 learners (e.g., changes in writing quality, accuracy, or complexity) resulting from an LLM-mediated intervention.""}}"
Exploring the Capabilities of Chatgpt for Lexicographical Purposes: a Comparison with Oxford Advanced Learner’s Dictionary within the Microstructural Framework,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The abstract does not mention any participants or learners being studied. It is a tool-focused comparison between ChatGPT and the Oxford Advanced Learner\u2019s Dictionary, not an empirical study with L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is examined, it is not integrated into an instructional intervention or experimental/quasi-experimental design involving learners. The study compares lexicographical data between ChatGPT and a dictionary, not an LLM-mediated teaching or writing process.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on lexicographical microstructure and dictionary content quality, not on writing competence or writing-related variables. There is no mention of writing instruction, writing tasks, or writing performance.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcomes are reported. The metrics used (BLEU, ROUGE, percentage presence of lexicographical items) assess similarity of lexicographical content, not changes in learners\u2019 writing performance or related outcomes.""}}"
An Impact of Artificial Intelligence Tools on Technical Students’ Esl Oral Communication Skills-a Study,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are technical engineering students in India learning English as a Second Language (ESL), which fits the target population of L2 English learners in an EFL/ESL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses unspecified \u2018Artificial Intelligence based mobile applications.\u2019 There is no indication these are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative tools; they could be generic AI language-learning apps. Thus it does not clearly meet the LLM requirement.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on oral communication skills (speaking accuracy and fluency), not writing competence or writing-related variables. Writing is only mentioned in the conclusion as a future recommendation, not as the focus of the intervention or outcome.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports quantifiable outcomes (pre-post speaking test scores) but these are for oral communication, not writing outcomes. No writing-related metrics are reported.""}}"
The Impact of Ai Writing Tools on the Content and Organization of Students’ Writing: Efl Teachers’ Perspective,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL students in Indonesian universities, as reported via their EFL teachers\u2019 perspectives. The context is clearly English as a Foreign Language.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although several AI writing tools are mentioned (Quillbot, WordTune, Jenni, ChatGPT, Paperpal, Copy.ai, Essay Writer), the study is purely descriptive/qualitative and does not implement an experimental or quasi-experimental LLM-based writing intervention. It explores tools in use but does not test a structured LLM-mediated instructional treatment.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on the impact of AI writing tools on students\u2019 writing, specifically content and organization, which are core writing competence variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses a qualitative case study design with semi-structured interviews and reports teachers\u2019 perceptions. It does not report quantifiable writing outcome metrics or experimental measures of writing performance; outcomes are purely perceptual/qualitative.""}}"
The Use of Artificial Intelligence to Improve the Scientific Writing of Non-native English Speakers,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The population is described broadly as \u201cnon-native English-speaking scientists,\u201d not as L2 English learners in ESL/EFL/ELL instructional contexts. The focus is on researchers\u2019 scientific writing, not on language learners in educational settings.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The article is a non-systematic narrative review of AI tools (Elicit, ResearchRabbit, Scispace Copilot, Grammarly, Paperpal, ChatGPT). It does not report an experimental or quasi-experimental intervention integrating LLMs into instruction; it only describes potential uses.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the topic is scientific writing, the paper is a narrative review of tools and their possible functions, not an empirical pedagogical intervention or study focused on writing competence outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics or experimental results are reported. The article discusses potential benefits qualitatively as a narrative review, without structured intervention outcomes.""}}"
"17th Linguistic Annotation Workshop, Law 2023 @ Acl 2023 - Proceedings of the Workshop",2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""This is a proceedings volume from the 17th Linguistic Annotation Workshop containing 26 papers on various annotation and NLP topics. The abstract does not indicate any focus on L2 English learners in ESL/EFL/ELL contexts; instead, it covers diverse linguistic and computational annotation issues (e.g., Byzantine Greek marginal writing, German narratives, Italian case law, hate speech labelling).""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although one paper mentions \u2018fine-tuned LLMs suggestions\u2019 for extending an event-type ontology, this is in the context of ontology extension and annotation, not an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or writing processes for learners.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus of the proceedings is linguistic annotation and NLP (e.g., event annotation, error detection in conversational agents, privacy-preserving text rewriting), not writing competence or writing-related pedagogy. There is no indication of an educational writing context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics or structured LLM-mediated writing interventions are described. The work concerns datasets, annotation procedures, and NLP methods rather than measuring changes in learners\u2019 writing performance.""}}"
Chatback: Investigating Strategies of Providing Synchronous Grammatical Error Feedback in a Gui-based Language Learning Social Chatbot,2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201csecond-language learners\u201d and \u201clanguage-learning tools\u201d but does not specify that the target language is English or that the context is ESL/EFL/ELL. The target L2 and context remain unspecified.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study investigates a GUI-based language-learning social chatbot providing synchronous grammatical error feedback. It is not identified as an LLM-based system (e.g., ChatGPT, GPT-4) and appears to be a feedback-delivery chatbot rather than a transformer-based generative LLM intervention in writing instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on synchronous grammatical corrective feedback in conversational chatbot interactions and learners\u2019 \u201clearning experiences and intention to use the system.\u201d While online writing tasks are mentioned in background, the primary context is not clearly an L2 writing competence intervention but rather general language learning and feedback delivery.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported concern learning experience and intention to use the system. The abstract does not indicate any quantifiable writing performance metrics or writing-related outcome measures; it focuses on user experience rather than measured changes in writing ability.""}}"
Using Ai-based Detectors to Control Ai-assisted Plagiarism in Esl Writing: the Terminator Versus the Machines,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The context is ESL composition and AI-assisted plagiarism in ESL writing, implying participants or data are from ESL writers (L2 English learners).""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines RoBERTa-based AI detectors used to identify ChatGPT-generated texts. These are classifiers, not LLMs integrated into writing instruction or writing processes as an intervention. There is no experimental or quasi-experimental pedagogical use of LLMs.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on detecting AI-assisted plagiarism and evaluating detector performance, not on improving writing competence or writing-related learning outcomes through instruction.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports detection accuracy of classifiers on human vs. AI-generated essays, not quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) resulting from an LLM-mediated writing intervention.""}}"
Analyzing Bias in Large Language Model Solutions for Assisted Writing Feedback Tools: Lessons from the Feedback Prize Competition Series,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Although the abstract mentions English Language Learner status as a demographic factor, the study does not focus on L2 English learners as participants in an instructional context; instead, it analyzes model performance across demographic groups within an existing dataset.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study analyzes winning LLM-based solutions used for evaluating student writing in a competition. There is no experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or writing processes; it is an evaluation of model bias and performance.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on bias and performance of LLM-based Assisted Writing Feedback Tools as evaluators (identifying discourse elements and predicting discourse effectiveness), not on improving learners\u2019 writing competence through instructional use of LLMs.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported are model performance accuracy and bias across demographic groups, not quantifiable writing outcomes for learners following an LLM-mediated writing intervention.""}}"
Investigating Efl Students' Writing Skills through Artificial Intelligence: Wordtune Application as a Tool,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Saudi English as a Foreign Language (EFL) students, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses Wordtune (and mentions Grammarly) as AI-powered writing technologies. The abstract does not indicate that these tools are large language model\u2013based (e.g., ChatGPT/GPT-4-type transformer generative models). Wordtune is primarily a rewriting/augmentation tool and is not clearly framed here as an LLM-based generative system, so it does not meet the specified LLM intervention criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study explicitly investigates whether and to what extent Wordtune facilitates Saudi students' writing, focusing on writing quality, lexical gains, and syntactic gains\u2014clearly a writing competence intervention context.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses a quasi-experimental design with control and experimental groups, pretests and post-tests, and reports quantitative outcomes (students in the experimental group outperformed the control group in the final writing exam) as well as rated writing samples, providing quantifiable writing outcome metrics.""}}"
Engaging Efl Students’ Critical Thinking Tendency and In-depth Reflection in Technology-based Writing Contexts: a Peer Assessment-incorporated Automatic Evaluation Approach,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are clearly described as university EFL (English as a Foreign Language) writing students, so the population consists of L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is an automatic writing evaluation (AWE) system combined with peer assessment. The abstract does not indicate that the AWE tool is a large language model (e.g., ChatGPT, GPT-4) or transformer-based generative model; it appears to be a conventional AWE system. Therefore, it does not meet the requirement of integrating LLMs into writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on EFL writing instruction and writing performance, as well as related variables such as motivation, critical thinking, and writing anxiety, within a technology-based writing context. The primary context is writing competence and writing-related outcomes.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The quasi-experiment compares an experimental PA-AWE group with a control C-AWE group and reports quantifiable outcomes: EFL writing performance, learning motivation, critical thinking, and writing anxiety. Thus, it includes measurable writing-related outcome metrics.""}}"
Artificial Intelligence in Global World: a Case Study of Grammarly as E-tool on Esl Learners’ Writing of Darul Uloom Nadwa,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Madrasa ESL learners in India (Alimiyat grade), explicitly described as English as a Second Language (ESL) students, with outcomes focused on English writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses Grammarly as an electronic tool. Grammarly is a grammar-checking and writing support tool that is not based on a large language model in the sense required (e.g., ChatGPT, GPT-4, Gemini). The abstract does not indicate use of an LLM-based generative model, but rather a conventional error-correction tool.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study\u2019s primary focus is on improving ESL learners\u2019 writing, specifically minimizing inflectional morpheme errors, and compares Grammarly-based instruction with communicative language teaching. This is clearly a writing competence intervention.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses a quantitative design with pre- and post-tests and reports results from a repeated-measures two-way ANOVA showing Grammarly enhanced writing accuracy in inflectional morphemes, providing quantifiable writing outcome metrics.""}}"
Understanding English as a Foreign Language Students’ Idea Generation Strategies for Creative Writing with Natural Language Generation Tools,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as English as a foreign language (EFL) students in Hong Kong secondary schools, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cnatural language generation (NLG) tools\u201d but does not specify whether these are large language model\u2013based systems (e.g., ChatGPT, GPT-4) or other AI/NLG tools. However, even if they were LLMs, the study design focuses on workshops and reflections rather than an experimental or quasi-experimental intervention measuring effects.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is creative writing: students attend workshops to learn to write stories using their own words and words generated by NLG tools. The focus is on writing processes (idea generation for creative writing), which aligns with writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are based on thematic analysis of students\u2019 written reflections about their experience and strategies. The abstract does not report any quantifiable writing outcome metrics (e.g., writing scores, quality ratings, measurable gains). It is a qualitative exploration of strategies and concerns, not an experimental measure of intervention effectiveness.""}}"
Exploring the Role of Artificial Intelligence in Facilitating Assessment of Writing Performance in Second Language Learning,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are students in a Chinese language learning program in the US, and the LLMs assess writing accuracy in Chinese. The focus is on Chinese as the target language, not English L2 learners or English writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses GPT-4, GPT-3.5, iFLYTEK, and Baidu Cloud as automated raters to assess writing accuracy, not as part of an instructional or quasi-experimental writing intervention. There is no integration of LLMs into teaching or learners\u2019 writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on the functionality and robustness of LLMs for automated assessment of writing accuracy, comparing them to human ratings. There is no pedagogical context or intervention aimed at improving writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports performance metrics of LLMs (e.g., accuracy, precision) as raters, not quantifiable outcomes of learners\u2019 writing development following an LLM-mediated intervention. No experimental learning outcomes are described.""}}"
Interaction Patterns between Learners and Ai Tools for English Writing,2023,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as EFL (English as a foreign language) learners, specifically 29 EFL undergraduates, indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to an unspecified 'AI tool for English writing' but does not indicate whether it is a large language model (e.g., ChatGPT/GPT-based) or a non-LLM tool (e.g., grammar checker). Without identifying the AI as LLM-based, it is unclear if it meets the LLM intervention criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly English writing: the study examines how EFL learners interact with an AI tool for English writing and how interaction patterns affect writing performance, which aligns with a focus on writing competence.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract notes that the study 'explores the effects of different interaction patterns on their writing performance' and that comparisons among clusters show varied benefits, implying quantitative writing performance outcomes were measured.""}}"
Empowering Language Learners: Harnessing Computer-based Writing for Enhanced Chinese Language Proficiency,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are Chinese Language (CL) learners in Singapore, focusing on Chinese language proficiency and Chinese writing, not L2 English learners or English writing outcomes. The abstract explicitly centers on CL classes and CBW for Chinese, so the population/target language does not match the review\u2019s focus on English.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The intervention is computer-based writing (CBW) versus paper-and-pen writing, not clearly an LLM-based tool. Generative AI is only mentioned in a proposed future platform (WeeWrite), not as part of the implemented and evaluated intervention. It is unclear whether any LLM was actually integrated into the studied intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on writing competence (writing quality, performance) in Chinese, comparing CBW and PPBW and examining factors like typing and handwriting speed and writing strategies. This aligns with a writing-focused context, though not in English.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcomes, comparing post-CBW and post-PPBW scores and analyzing effects across achievement levels using mixed-effects modeling. Thus, it includes measurable writing outcome metrics, albeit for Chinese rather than English.""}}"
