Title,Year,Decision,Notes
Exploring the Potential of Chatgpt in Assessing L2 Writing Accuracy for Research Purposes,2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions '100 L2 essays across five proficiency levels' but does not specify that these are L2 English learners or the language of the essays. It is therefore unclear whether the population is L2 English learners in ESL/EFL/ELL contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT-4 is used to measure linguistic accuracy and detect errors in existing L2 essays. There is no experimental or quasi-experimental design integrating ChatGPT into writing instruction or learners\u2019 writing processes; it is an evaluation of ChatGPT as an assessment tool.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on ChatGPT\u2019s performance in error detection (assessment/measurement) rather than on improving writing competence through pedagogical intervention. It evaluates ChatGPT as an automated error-detection system, not as part of a teaching or learning activity.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports precision, recall, and correlations between ChatGPT and human coding for error detection, but does not report any writing outcome metrics resulting from an LLM-mediated intervention. There is no pre/post or comparative measure of learners\u2019 writing development.""}}"
Using Ai-based Detectors to Control Ai-assisted Plagiarism in Esl Writing: “the Terminator Versus the Machines”,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The context is ESL composition and AI-assisted plagiarism in ESL writing, implying involvement of L2 English learners in ESL settings.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a descriptive evaluation of RoBERTa-based AI detectors on a dataset of human-written and ChatGPT-generated essays. There is no experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or processes; ChatGPT is only a text source, not an instructional tool.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on controlling AI-assisted plagiarism and assessing the performance of AI-based detectors, not on improving writing competence or writing-related learning outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) are reported. Outcomes relate to detection accuracy of classifiers, not to learners\u2019 writing development under an LLM-mediated intervention.""}}"
"A Triple Challenge: Students' Identification, Interpretation, and Use of Individualized Automated Feedback in Learning to Write English as a Foreign Language.",2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are eighth-grade students learning English as a foreign language, which fits the L2 English EFL context: \u201ceighth-grade students' \u2026 writing skills in English as a foreign language.\u201d""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses an \u201cAI-based automated essay assessment tool (EAT)\u201d that provides automatic feedback. The abstract does not indicate that this tool is a large language model (e.g., ChatGPT/GPT-style generative transformer). It is framed as an automated essay assessment system, which typically relies on scoring/feedback algorithms rather than LLM-based generative models.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on developing \u201cwriting skills in English as a foreign language\u201d using automated feedback on essays, with analysis of revisions and writing trajectories. This is clearly a writing competence intervention rather than pure scoring or system evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study examines \u201cimprovements made on the essay based on the feedback logs \u2026 and the different versions of the essay \u2026 using frequency analyses,\u201d indicating quantifiable writing outcome measures related to revisions and skill development.""}}"
From Process to Product: Writing Engagement and Performance of Efl Learners under Computer-generated Feedback Instruction,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 42 English as a foreign language (EFL) learners, clearly indicating L2 English learners in an EFL context, with outcomes focused on English writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses Pigai, described as a Chinese automated writing evaluation (AWE) system. Pigai is a traditional AWE tool, not specified as a large language model (e.g., ChatGPT, GPT-4, Gemini) or transformer-based generative model. Thus it does not meet the LLM-based intervention requirement.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on revision processes and writing products, analyzing feedback uptake and text quality in complexity, accuracy, and fluency (CAF), which are core writing-related variables in an instructional context.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Quantifiable writing outcome metrics are reported, including CAF measures (complexity, accuracy, fluency) and effects of automated feedback on accuracy and lexical complexity, along with engagement dimensions.""}}"
"Artificial Intelligence in Language Instruction: Impact on English Learning Achievement, L2 Motivation, and Self-regulated Learning",2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as English as a Foreign Language (EFL) university students, and outcomes are explicitly English learning achievement (grammar, vocabulary, reading, writing), so the population is L2 English learners.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers only to an unspecified \u201cAI-mediated instruction\u201d and \u201cAI-powered platforms/AI-driven educational technologies.\u201d It does not indicate that a large language model (e.g., ChatGPT, GPT-4, Gemini) or any transformer-based generative model was used, nor does it describe generative interaction with an LLM. The AI could be any form of educational technology.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is overall English learning achievement (grammar, vocabulary, reading comprehension, and writing skills) plus L2 motivation and self-regulated learning. Writing is only one subcomponent among several skills, and there is no indication that the intervention specifically targets writing instruction or writing processes as the main focus.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The study reports pre/post English learning achievement including writing skills, but it is not clear whether distinct, quantifiable writing outcome metrics (e.g., writing quality scores, organization, accuracy) are analyzed separately, or whether writing is just part of a composite achievement test. Moreover, without confirmation that an LLM-based writing intervention is involved, this criterion cannot be confidently applied.""}}"
Local Similarity and Global Variability Characterize the Semantic Space of Human Languages,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Although the study uses TOEFL essays written by 38,500 speakers from various native languages, the focus is on semantic space and cross-linguistic meaning variability, not on L2 English learners in an instructional ESL/EFL/ELL context. Participants are data sources for semantic analysis rather than learners in an educational intervention.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Large language models are used as analytical tools to characterize semantic variability across languages, not as an instructional intervention integrated into writing instruction or writing processes. There is no experimental or quasi-experimental design involving LLM-mediated pedagogy.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on semantic space, meaning variability, and cross-linguistic comparisons, not on writing competence or writing-related pedagogical variables. TOEFL essays are used to model semantics, not to improve or assess writing through an intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study does not report quantifiable writing outcome metrics related to an LLM-mediated writing intervention. Outcomes concern variability in semantic representations, not changes in writing performance or related skills following an instructional treatment.""}}"
Bibliometrically and Systematically Analyzing Automated Writing Evaluation for English Learning,2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract concerns automated writing evaluation for learning English as a second language, implying L2 English learners, but it does not specify participant characteristics or contexts, as it is a secondary study (bibliometric + systematic review).""}, ""c2"": {""status"": ""fail"", ""evidence"": ""This is a bibliometric analysis and systematic review of automated writing evaluation tools, not an experimental or quasi-experimental primary study integrating a specific LLM (e.g., ChatGPT, GPT-4) into instruction. It is a secondary review article, which is excluded by the protocol.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the topic is writing-related (automated writing evaluation), the paper is not a primary pedagogical intervention study but a bibliometric and systematic overview of prior work, which falls under excluded article types (review/overview).""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study does not report original, quantifiable writing outcome metrics from an intervention; instead, it synthesizes findings from 56 peer-reviewed articles. As a review, it lacks its own experimental outcome measures.""}}"
Enhancing Academic Writing Skills and Motivation: Assessing the Efficacy of Chatgpt in Ai-assisted Language Learning for Efl Students,2023,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Chinese English as a Foreign Language (EFL) students. The abstract explicitly states the focus is on their English writing skills and motivation, fitting ESL/EFL/ELL L2 English learner contexts.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention is AI-assisted instruction via ChatGPT, a large language model. The design is experimental: 50 EFL students are randomly assigned to an experimental (ChatGPT) or control (traditional instruction) group, satisfying the requirement for an LLM-based writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on writing competence and writing-related variables: the study evaluates the impact on students\u2019 writing skills (organization, coherence, grammar, vocabulary) and writing motivation. ChatGPT is used pedagogically, not merely as an automated scoring tool.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses a pre-test/post-test design with writing samples evaluated using established scoring rubrics, and reports significant improvements in writing skills and motivation in the experimental group. These are quantifiable writing outcome metrics aligned with the review\u2019s criteria.""}}"
"A Triple Challenge: Students’ Identification, Interpretation, and Use of Individualized Automated Feedback in Learning to Write English as a Foreign Language",2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are eighth-grade students learning English as a foreign language, which fits L2 English learners in an EFL context: \u201ceighth-grade students\u2019 \u2026 writing skills in English as a foreign language.\u201d""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses an \u201cAI-based automated essay assessment tool (EAT)\u201d that provides automatic feedback. There is no indication that this tool is a large language model (e.g., ChatGPT/GPT-style transformer-based generative model); it is framed as automated essay assessment, which typically predates LLMs. Thus it does not clearly meet the requirement of integrating LLMs into writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on writing competence: \u201cassessment literacy and writing skills in English as a foreign language,\u201d with students writing essays, receiving feedback, and revising. This aligns with a writing-focused pedagogical context rather than pure scoring or system evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study examines \u201cimprovements made on the essay based on the feedback logs\u2026 and the different versions of the essay\u2026 using frequency analyses,\u201d indicating quantifiable writing outcome metrics related to revisions and improvements.""}}"
Second Language Learners’ Post-editing Strategies for Machine Translation Errors,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The abstract refers to 'second language (L2) learners' but does not specify that they are L2 English learners or that the writing is in English. The context (University of Hawaii at Manoa) suggests a possible English context, but the target language is not explicitly stated, so it does not clearly meet the requirement of focusing on English as the L2.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses Google Translate, described as a neural machine translator, as the AI tool. This is a machine translation system, not an LLM-based generative model like ChatGPT or GPT-4, and the focus is on post-editing MT output rather than integrating an LLM into writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is L2 writing: learners use machine translation to address lexical and grammatical problems during L2 writing, and the study analyzes MT errors and post-editing strategies, which are clearly writing-related variables.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable outcomes: the 'successfulness of PE was gauged by comparing sentence adequacy scores of the MT output and PEd texts,' providing measurable writing-related performance data.""}}"
Engineering Chatgpt Prompts for Efl Writing Classes,2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers generally to 'EFL education' and 'student writing' but does not specify that the study involves actual L2 English learners as participants with collected data, or whether it is a conceptual/practical article without participants.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The article is described as demonstrating 'effective prompts for writing classes' and discussing ChatGPT as a feedback tool. There is no indication of an experimental or quasi-experimental design, nor of a structured intervention study; it appears to be a practical or conceptual piece on prompt engineering.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""While the focus is on EFL writing classes and feedback on student writing, the abstract does not clearly state that the paper empirically investigates writing competence or related variables; it seems more oriented toward illustrating prompt design.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or assessment of effectiveness. It only states that the article will demonstrate effective prompts, with no reference to measured changes in writing performance.""}}"
Exploring the Effects of Grammarly on Efl Students’ Foreign Language Anxiety and Learner Autonomy,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL students in academic writing courses at a Japanese university, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses Grammarly, described as an automated writing evaluation (AWE) tool. Grammarly is not an LLM-based, transformer generative model like ChatGPT or GPT-4; it is explicitly listed as an exclusionary tool in the review criteria.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is English academic writing courses, and Grammarly is used while editing English writing. The study is situated in L2 writing instruction, even though the primary outcomes are affective (anxiety, autonomy).""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study measures foreign language anxiety and learner autonomy via pre- and post-surveys. It does not report quantifiable writing performance outcomes; writing is the context, not the measured outcome variable.""}}"
"2023 Ieee 15th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management, Hnicem 2023",2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The record is for a conference proceedings volume (HNICEM 2023) containing 263 papers. One listed paper mentions \u201cutilization of artificial intelligence in academic writing class: L2 learners perspective,\u201d but no details are provided about participants or whether they are L2 English learners. The proceedings-level abstract does not specify language, learner type, or context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The proceedings abstract only notes a paper on \u201cutilization of artificial intelligence in academic writing class\u201d without specifying that the AI is an LLM (e.g., ChatGPT, GPT-4). It could involve non-LLM tools. At the proceedings level, there is no clear evidence of an LLM-based experimental or quasi-experimental writing intervention.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""One paper title suggests a focus on academic writing and L2 learners, but the proceedings abstract does not clarify whether the primary focus is on writing competence or writing-related variables, nor does it describe any pedagogical intervention. The volume overall covers many unrelated technical topics.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""No quantifiable writing outcome metrics are reported in the proceedings abstract. It only lists paper titles, including one about AI in academic writing, without indicating whether that study includes experimental measures of writing performance.""}}"
Fusion Weighted Features and Bilstm-attention Model for Argument Mining of Efl Writing,2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions a corpus of 180 argumentative essays, but does not specify that the writers are L2 English learners (ESL/EFL/ELL). The context could be EFL, but this is not stated explicitly.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses BERT and a BiLSTM-attention model for argument mining. These are NLP models for automated annotation, not LLMs integrated into writing instruction or learners\u2019 writing processes. There is no pedagogical intervention involving tools like ChatGPT or GPT-4.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on developing an argument mining model and improving automatic annotation for potential use in automated scoring. It does not describe an instructional context or intervention aimed at improving learners\u2019 writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported are model performance metrics (e.g., 69% precision in automatic annotation), not quantifiable changes in learners\u2019 writing performance following an LLM-mediated intervention.""}}"
"Navigating the Impact of Chatgpt/gpt4 on Legal Academic Examinations: Challenges, Opportunities and Recommendations",2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The abstract refers broadly to \u201cstudents and researchers\u201d and \u201cnon-native English speakers in academic research\u201d in higher education, without specifying L2 English learners in ESL/EFL/ELL contexts or focusing on English as the target language in a language-learning sense. The population is general higher education, not clearly L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The paper is a conceptual/discussion piece about the impact of ChatGPT/GPT-4 on academic paper writing, plagiarism, and ethics. It does not describe an experimental or quasi-experimental intervention integrating LLMs into instruction or writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on academic integrity, plagiarism detection, ethical use, and institutional guidelines, not on a pedagogical intervention targeting writing competence or writing-related learning outcomes. It is a policy/ethics discussion rather than a writing instruction study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantitative writing outcome measures or experimental results are reported. The article proposes strategies and discusses challenges and opportunities but does not present empirical data on writing performance or related variables.""}}"
Teachers’ Reflections on Academic Dishonesty in Efl Students’ Writings in the Era of Artificial Intelligence,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The participants in the study are 67 teachers, not L2 English learners. Although the context involves EFL students\u2019 writings, the data and analysis focus on teachers\u2019 perceptions rather than on L2 learners as the primary participants.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study explores teachers\u2019 perceptions of academic dishonesty in the era of AI and mentions AI technologies generally, but it does not describe an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is academic dishonesty, ethical implications, and teachers\u2019 roles in detecting AI-generated assignments, not on improving writing competence or writing-related pedagogical interventions using LLMs.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported. The study relies on questionnaires and interviews about perceptions and ethics, without measuring changes in students\u2019 writing performance following an LLM-mediated intervention.""}}"
Chatgpt's Capabilities in Spotting and Analyzing Writing Errors Experienced by Efl Learners,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly states that the study investigates ChatGPT in detecting English as a foreign language (EFL) learners' writing errors, indicating an EFL (L2 English) population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study compares ChatGPT\u2019s error detection with human instructors to evaluate its capabilities. There is no indication of an experimental or quasi-experimental pedagogical intervention where ChatGPT is integrated into writing instruction or learners\u2019 writing processes; it is a tool evaluation, not an instructional intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on ChatGPT\u2019s ability to spot and analyze writing errors (i.e., error detection performance and reliability), akin to evaluating an automated feedback/grading system. There is no description of a teaching/learning context or structured writing intervention aimed at improving learners\u2019 writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported are metrics like F-score and p-value assessing ChatGPT\u2019s error detection accuracy, not quantifiable changes in learners\u2019 writing performance following an LLM-mediated intervention. No pre/post or comparative writing outcome measures for learners are mentioned.""}}"
Improving Logical Flow in English-as-a-foreign-language Learner Essays by Reordering Sentences,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The corpus ICNALE-AS2R consists of essays written by English-as-a-foreign-language learners from various Asian countries, clearly indicating an EFL (L2 English) population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study proposes a computational sentence reordering system trained on an EFL learner corpus, but it is presented as an NLP/AI method for automatic reordering, not as an LLM-based (e.g., ChatGPT, GPT-4) pedagogical intervention or classroom tool. There is no indication that a large language model is used, nor that learners interact with the system in an instructional experiment.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on developing and evaluating an automatic sentence reordering system (discourse-level text processing) using metrics like longest common subsequence ratio and Kendall\u2019s Tau. It does not describe an instructional context or writing intervention aimed at improving learners\u2019 writing competence; rather, it is a text-processing/algorithmic study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are system performance metrics (LCS ratio, Kendall\u2019s Tau) on reconstructing reordered essays, not quantifiable changes in learner writing performance following an intervention. No experimental or quasi-experimental measures of learner writing outcomes are described.""}}"
Second Language Learners' Post-editing Strategies for Machine Translation Errors,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study involves 57 second language (L2) learners using Google Translate during L2 writing. Although the target language is not explicitly stated as English, the general L2 context and focus on L2 writing fit the broad L2 learner population criterion.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention centers on Google Translate, a neural machine translation (NMT) system, not on a large language model (LLM) such as ChatGPT, GPT-4, or similar transformer-based generative models used interactively for writing instruction. The study analyzes post-editing of MT output rather than an LLM-mediated writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly L2 writing: learners use MT to address lexical and grammatical problems during L2 writing, and the study examines post-editing strategies and writing-related competence in the \u2018AI era\u2019.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable outcomes: sentence adequacy scores comparing MT output and post-edited texts, and examines how proficiency affects successful post-editing. These are measurable writing-related outcomes.""}}"
The Impact of Artificial Intelligence in Foreign Language Learning Using Learning Management Systems: a Systematic Literature Review,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract focuses on English as a foreign language and discusses students and teachers in EFL contexts using AI via learning management systems. Thus, the population is L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""This is a systematic literature review of AI in foreign language learning via LMSs over 2011\u20132021. It does not describe a primary experimental or quasi-experimental intervention using a specific LLM (e.g., ChatGPT, GPT-4). It is a secondary review article, which is explicitly excluded.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The review addresses multiple language skills (reading, writing, speaking, listening) broadly. Writing is only one of several skills and not the primary focus of a specific pedagogical intervention; the context is general language learning with AI in LMSs.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a systematic literature review, it does not report original, quantifiable writing outcome metrics from an LLM-mediated intervention conducted by the authors. It synthesizes prior work and focuses on perceived benefits rather than presenting new experimental writing outcomes.""}}"
