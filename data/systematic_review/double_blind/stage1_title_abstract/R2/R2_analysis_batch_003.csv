Title,Year,Decision,Notes
Chatgpt-supported Collaborative Argumentation: Integrating Collaboration Script and Argument Mapping to Enhance Efl Students' Argumentation Skills,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are clearly identified as EFL (English as a Foreign Language) university freshmen, and the focus is on their English argumentation skills in speaking and writing contexts.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study is a quasi-experimental design using ChatGPT, explicitly described as a large language model, to support collaborative argumentation through a structured collaboration script (preparation, interaction, reflection).""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary measured outcomes are argumentative speaking performance, critical thinking awareness, and collaboration tendency. While argumentation is relevant to writing, the abstract emphasizes speaking performance rather than writing competence or writing-related performance measures as the main focus.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract reports quantitative outcomes (e.g., effect sizes) for argumentative speaking performance, critical thinking awareness, and collaboration tendency. It does not specify any quantifiable writing outcome metrics (e.g., written argument quality scores), so it is unclear whether writing performance was measured at all.""}}"
Teachers' Perceptions and Students' Strategies in Using Ai-mediated Informal Digital Learning for Career Esl Writing,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are university students in an English writing course in an ESL context (\u201ccareer ESL writing instruction\u201d), so they are L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although students use AI tools including ChatGPT (an LLM) and other tools (Grammarly, Canva with Magic Write, Invideo), the design is described as a case study focusing on teachers\u2019 perceptions and students\u2019 strategies. There is no indication of an experimental or quasi-experimental intervention design testing LLM integration; it is exploratory/qualitative rather than an intervention study.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly writing-focused: \u201ccareer ESL writing instruction,\u201d \u201cEnglish writing course,\u201d and exploration of how AI-mediated informal digital learning tools are used in writing projects and rhetorical accessibility.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses demographic questionnaires, think-aloud protocols, and semi-structured interviews, and reports strategies and perceptions. There is no mention of quantitative writing outcome measures (e.g., scores, rubric-based gains, accuracy measures) assessing effectiveness of the LLM-mediated intervention.""}}"
"Using Ai to Enhance Digital Multimodal Composing: Efl Learners' Semiotic Decision-making, Self-efficacy, Enjoyment, and Continuance Intention",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL learners in an academic English course, clearly fitting the L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses an unspecified AI-powered text-to-video technology for digital multimodal composing. There is no indication that this is an LLM-based tool (e.g., ChatGPT, GPT-4) or that transformer-based generative language models are integrated into writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on digital multimodal composing (text-to-video) and learners\u2019 semiotic decision-making, self-efficacy, enjoyment, and continuance intention, not on writing competence or writing-related variables as primary outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports reflections, questionnaire responses, and evaluations of AI-generated videos, focusing on perceptions and intentions. It does not report quantifiable writing outcome metrics assessing changes in writing performance due to the AI intervention.""}}"
Exploring High School Students' Preferences for English Writing Feedback: Non-native English Teacher Vs. Native English Teacher Vs. Chatgpt,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 20 high school students from an English newspaper club in Korea, clearly an EFL context with English as the target language.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is used as one of several feedback providers, but the study is observational/comparative, focusing on students\u2019 preferences for different feedback sources. There is no experimental or quasi-experimental LLM-based instructional intervention aimed at improving writing performance.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on preferences and perceptions of feedback sources (non-native teacher, native teacher, ChatGPT, and collaborative feedback), not on writing competence or development as an outcome of a pedagogical intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are Likert-scale ratings of feedback preference and qualitative themes. No quantifiable writing performance metrics (e.g., scores, quality measures, accuracy) are reported to assess the effectiveness of ChatGPT-mediated writing intervention.""}}"
"I, Too, Shall Have to Prompt? a Study of Efl Students and Their Unmonitored Use of Genai in the Completion of an Imitation Task in Poetry",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL students in a university English as a Foreign Language Literature course, so they are L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to a \u2018GenAI model\u2019 and \u2018GenAI-assisted creative writing exercise\u2019 but does not specify whether the tool is a large language model (e.g., ChatGPT/GPT-4) or another type of generative AI. The specific technology and architecture are not identified.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on a literature course and on how the GenAI-assisted imitation task supports application of literary analysis elements, prompt characteristics, and pedagogical implications. Writing competence or writing-related performance is not the central outcome; rather, it is use of literary terms and analysis.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is based on qualitative data from surveys and observational studies. The abstract does not report any quantifiable writing outcome metrics (e.g., writing scores, rubric-based assessments) to evaluate the effectiveness of the GenAI intervention on writing performance.""}}"
Investigating Efl Teachers' Lesson Planning for Chatbot-assisted Learning of Argumentative Writing: a Tpack Perspective,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The context is clearly English as a foreign language (EFL), and the focus is on teaching argumentative writing in English, implying L2 English learners.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses a chatbot named Argumate, but the abstract does not specify whether it is an LLM-based, transformer generative model (e.g., ChatGPT-like) or a rule-based/other type of chatbot. Thus it is unclear if it meets the LLM requirement.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The study focuses on teachers\u2019 lesson planning and professional knowledge (TPACK) for chatbot-assisted argumentative writing. It analyzes lesson plans and interviews, not an implemented pedagogical intervention with learners\u2019 writing performance as the primary focus.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No experimental or quasi-experimental design with learners is reported, and no quantifiable writing outcome metrics are mentioned. The study is conceptual/qualitative about planning and integration, not about measured writing gains.""}}"
Comparing Hong Kong Secondary School Students' Perceptions of Chatgpt-assisted Efl Writing,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 107 Hong Kong secondary school students in an EFL context, and the focus is explicitly on EFL (English as a foreign language) writing.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study examines ChatGPT-assisted EFL writing and compares three teaching approaches (process-based, genre-based, and prompt-engineering-only) in a quantitative design, indicating an LLM-based instructional intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary outcomes are motivation, cognitive load, and satisfaction. While situated in a writing context, the abstract does not indicate that writing competence or writing performance measures are a focus; instead, it centers on affective and cognitive variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, quality ratings, accuracy, complexity) are reported. The measured variables are motivation, cognitive load, and satisfaction, which do not meet the requirement for writing outcome measures.""}}"
Does Metalinguistic Explanation of Teacher and Chatgpt Feedback Improve Efl Learners' Writing Quality and Engagement? Findings from an Intervention Study,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as EFL learners (foreign language writing instruction, EFL learners), indicating L2 English learners in an EFL context with focus on English writing.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study is a quasi-experimental intervention examining scaffolded metalinguistic explanations of teacher and ChatGPT feedback. ChatGPT is a large language model integrated into the writing feedback process, satisfying the LLM-based intervention requirement.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is foreign language writing instruction, focusing on how feedback (including ChatGPT feedback) affects EFL learners\u2019 writing quality and engagement. The primary pedagogical target is writing competence, not automated scoring or system evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses pre-tests and post-tests, written drafts, and reports significant improvements in writing performance (grammatical accuracy, vocabulary use, mechanical control) and incorporation of feedback, indicating quantifiable writing outcome measures within an intervention design.""}}"
Assigning Cefr-j Levels to English Learners' Writing: an Approach Using Lexical Metrics and Generative Ai,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The system is designed for assessing English learners\u2019 writing proficiency in an EFL context (CEFR-J, tailored to EFL in Japan). The ICNALE GRA dataset consists of English learner writing, so the population focus is on L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study presents CWLA as an automated scoring system that combines lexical metrics with AI-based analytical scores. It is an assessment tool, not an experimental or quasi-experimental pedagogical intervention integrating an LLM into writing instruction or writing processes. No LLM-mediated instructional treatment is described.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on automated writing proficiency assessment (CEFR-J level assignment) and validation against human ratings, not on improving writing competence through instructional use. This aligns with automated essay scoring functionality, which is explicitly excluded.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported are correlations between CWLA scores and human ratings, entropy analysis, and expert agreement rates. These are validation metrics for an assessment tool, not quantifiable writing outcome measures from an LLM-mediated writing intervention or instructional experiment.""}}"
Rnn Hybrid Model for Evaluating Efl Teachers' Classroom Performance in Higher Education,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The abstract focuses on evaluating EFL teachers\u2019 classroom performance in higher education using an RNN-based model. There is no indication that the participants are L2 English learners or that learner data in an ESL/EFL/ELL context is the focus; instead, the target of evaluation is teachers.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses an Elman RNN combined with a Dolphin Echolocation Algorithm (DEA-RNN) as a predictive/evaluation model. This is a traditional recurrent neural network approach, not a large language model (e.g., ChatGPT, GPT-4, Gemini), and it is not integrated into writing instruction or writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The context is teacher performance evaluation in higher education, not writing competence or writing-related variables. There is no mention of writing instruction, writing tasks, or writing development as a primary focus.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported are model performance metrics (accuracy, precision, recall, F1-score, specificity) for evaluating teachers, not quantifiable writing outcomes or measures of L2 writing performance following an intervention.""}}"
Exploring Ai to Automate Efl Corrective Written Feedback in the First Language,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The title and abstract indicate an EFL context with students whose L1 is Japanese, implying they are L2 English learners receiving corrective written feedback on English writing.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses a ChatGPT-powered plugin (a large language model) within Moodle to provide automated written corrective feedback as part of a classroom intervention, satisfying the LLM-based intervention criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The intervention centers on a free-writing activity and subsequent written corrective feedback on students\u2019 writing, clearly focusing on writing competence and writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports analysis of survey data and ChatGPT-generated feedback, focusing on perceptions of accuracy, comprehensibility, and appreciation. It does not mention any quantitative writing outcome measures (e.g., changes in writing quality, accuracy, complexity) or pre/post comparisons of learners\u2019 writing performance.""}}"
"Exploring Efl Students' Ai Literacy in Academic Writing: Insights into Familiarity, Knowledge and Ethical Perceptions",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Turkish English as a Foreign Language (EFL) students, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses a descriptive exploratory survey to examine AI literacy, familiarity, and perceptions. There is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on AI literacy, familiarity, usage patterns (translation, grammar proofreading), and ethical perceptions, not on a structured pedagogical writing intervention or systematic use of LLMs to develop writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports survey-based perceptions and literacy levels; it does not report quantifiable writing outcome metrics (e.g., changes in writing quality, scores) resulting from an LLM-mediated intervention.""}}"
"A Q Method Study on Turkish Efl Learners' Perspectives on the Use of Ai Tools for Writing: Benefits, Concerns, and Ethics",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Turkish English language learners enrolled in a preparatory program at a state university in Istanbul, clearly an EFL/ELL context focused on English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study explores learners\u2019 perspectives on the use of unspecified AI tools for writing via a Q methodological approach. There is no indication of an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into instruction or writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on perceptions of benefits, concerns, and ethics regarding AI tools in writing, not on a structured pedagogical writing intervention or instructional design using LLMs.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports qualitative perspectives and Q-sort results but does not mention any quantifiable writing outcome measures (e.g., writing scores, text quality metrics) resulting from an AI-mediated intervention.""}}"
"The Role of Techno-competence in Ai-based Assessments: Exploring Its Influence on Students' Boredom, Self-esteem, and Writing Development",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 66 Saudi Arabian male EFL learners, clearly L2 English learners in an EFL context: \u201cEFL learners\u2026 66 Saudi Arabian male students\u2026\u201d.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The abstract refers only to \u201cAI-driven evaluations\u201d and \u201cAI-enhanced assessments\u201d without specifying the technology. There is no indication that a large language model (e.g., ChatGPT, GPT-4) or transformer-based generative model was used; it could be any AI-based assessment tool. Thus it does not clearly meet the LLM requirement.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""Writing development is one of the main outcome variables: the study examines how AI-based assessments affect \u201cwriting skills,\u201d \u201cwriting proficiency,\u201d and \u201cwriting abilities,\u201d which aligns with a primary focus on writing competence.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses an experimental design with EG vs. CG and \u201cpre- and post-assessments\u2026 to gauge\u2026 writing proficiency,\u201d indicating quantifiable writing outcome metrics are reported alongside boredom and self-esteem.""}}"
Interactive Eassessment of Writing Competency in French as a Foreign Language: Development and Implementation of an Ai-enhanced Progress Monitoring System,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are learners of French as a Foreign Language in Moroccan primary schools. The focus is on writing competency in French, not on L2 English learners in ESL/EFL/ELL contexts, and the target language is French rather than English.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions an 'AI-enhanced progress monitoring system' and 'automated analysis,' but does not specify that the AI is a large language model (e.g., ChatGPT, GPT-4) or a transformer-based generative model, nor that it is integrated into writing instruction rather than assessment.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on formative e-assessment and progress monitoring of writing competency via an AI-enhanced system, not on writing instruction or intervention. It is essentially an assessment/monitoring tool, aligning more with writing assessment functionality than with pedagogical writing intervention.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The study reports qualitative teacher responses, system interaction statistics, and feedback analysis. It does not clearly report quantifiable writing outcome metrics (e.g., pre/post writing scores) demonstrating changes in learners\u2019 writing performance attributable to the AI system.""}}"
Leveraging Ai for Writing Instruction in Efl Classrooms: Opportunities and Challenges,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 150 fourth-year English major students in an EFL context (a university in the Mekong Delta), clearly L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The abstract refers generically to \u201cAI writing tools\u201d without specifying large language models (e.g., ChatGPT, GPT-4). It appears to be a broad exploration of AI tools rather than a defined LLM-based intervention, and no particular LLM is identified.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on EFL writing instruction and how AI tools support writing skills, including feedback and learner independence in writing.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although the study is mixed methods, the abstract only reports perceptions and self-reported improvement (e.g., \u2018help\u2026 achieve better writing skills\u2019) without mentioning any experimental or quasi-experimental design or quantifiable writing outcome measures (e.g., scores, rubric-based gains).""}}"
"Generative Ai-assisted Feedback and Efl Writing: a Study on Proficiency, Revision Frequency and Writing Quality",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are sixty postgraduate English as a Foreign Language (EFL) students, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses Grammarly as the AI-enhanced feedback system. Grammarly is generally not an LLM-based, transformer-style generative model like ChatGPT, GPT-4, or Gemini; it is typically categorized as an AI writing assistant outside the scope of LLM-focused interventions specified in the review criteria.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on writing proficiency, revision practices, and writing quality, with Grammarly used as feedback during the writing process. The primary focus is on writing competence and related variables, not on automated essay scoring.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantitative outcomes: pre- and post-test writing proficiency scores, correlations between AI feature use and revision frequency, and improvements in content, organization, and cohesion, providing measurable writing outcome metrics.""}}"
"Generative Ai Vs. Teachers: Feedback Quality, Feedback Uptake, and Revision",2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were 60 EFL secondary students from a high school in China. The context is explicitly EFL, and the task involves writing in English, satisfying the L2 English learner population requirement.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses a generative AI bot (ChatGPT), a large language model, to provide feedback on students\u2019 writing. It employs a 2x2 counter-balanced experimental design comparing AI-generated and teacher feedback, thus integrating an LLM into the writing process in an experimental framework.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on written samples, feedback quality, feedback uptake, and revision. The intervention directly targets writing (students write on two topics, receive feedback, and resubmit revised work), aligning with writing competence and writing-related variables rather than mere automated scoring.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantitative analyses of feedback quality and uptake (e.g., AI outperformed a teacher in meaning-level feedback; teacher feedback had higher uptake rates). It also involves revision outcomes after feedback, indicating measurable writing-related outcomes within an experimental design.""}}"
"Bridging Ai and Pedagogy: How Ai-adaptive Feedback Shapes Chinese Efl Students' Writing Engagement, Metacognitive Writing Strategies, and Writing Performance",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as Chinese university EFL learners in EFL writing contexts, so they are L2 English learners in an EFL setting.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The abstract refers to \u201cAI-adaptive feedback\u201d and \u201cAI-enhanced adaptive feedback\u201d but does not specify that the system is based on large language models (e.g., ChatGPT, GPT-4). It appears to be an adaptive feedback system rather than an LLM-integrated writing intervention, and no LLM is named or implied.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly EFL writing pedagogy, focusing on writing engagement, metacognitive writing strategies, and writing performance, which are writing-related variables.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcomes, including writing performance and its relationships with AI-adaptive feedback, engagement, and metacognition, analyzed via structural equation modeling with reported beta coefficients.""}}"
Enhancing Students' L2 Writing by Integrating Artificial Intelligence with Corpus-based Language Pedagogy,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 50 English as a Foreign Language (EFL) learners majoring in English at an English-Medium Instruction university in China, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers only to generic 'AI tools' and does not specify that they are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems. They could be non-LLM tools (e.g., grammar checkers). Without explicit indication of LLM use, it cannot be confirmed that the intervention integrates LLMs.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on L2 students\u2019 writing revision, integrating AI and corpus-based language pedagogy to support writing development, with attention to lexico-grammatical patterns, collocations, and sentence revision\u2014clearly a writing-focused pedagogical context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although drafts and revisions were collected and changes analyzed, the abstract does not report or clearly indicate quantifiable writing outcome metrics (e.g., scores, error rates, quality ratings) to assess effectiveness. The emphasis is on types of changes, tool preferences, and attitudes, not on experimental outcome measures of writing performance.""}}"
