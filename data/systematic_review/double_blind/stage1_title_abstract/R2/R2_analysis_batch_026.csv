Title,Year,Decision,Notes
Is This Really Your Work?: a Qualitative Study of Teacher-led Interviews and Student Accountability in the Age of Generative Ai,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 24 Master's-level English as a Foreign Language (EFL) students, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the study concerns student engagement with generative AI in writing, the intervention is teacher-led interviews as an assessment practice, not an LLM-mediated writing instruction or process. There is no indication that a specific LLM (e.g., ChatGPT) is systematically integrated as an instructional tool in an experimental or quasi-experimental design.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on authorship, integrity, accountability, and ethical engagement with GenAI via teacher-led interviews, not on improving writing competence or writing-related performance variables. The emphasis is on assessment and ethical orientation rather than writing skill development.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is explicitly described as qualitative, using thematic analysis of reflection data. Reported outcomes are cognitive, emotional, and agentive developments, with no mention of quantifiable writing outcome metrics (e.g., writing scores, text quality measures) to assess effectiveness of an LLM-mediated writing intervention.""}}"
Integrating Iwrite Tools into English Writing Instruction,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract describes English writing instruction in Chinese universities, implying learners are EFL students (L2 English learners). The focus is clearly on English writing proficiency.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The tool mentioned is \u2018iWrite\u2019, described as an AI tool for grammar correction, vocabulary enhancement, and structural analysis. The abstract does not specify that it is an LLM or transformer-based generative model (e.g., ChatGPT, GPT-4). It could be a traditional NLP/automated feedback system. Without explicit indication of LLM use, its eligibility as an LLM-based intervention is unclear.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is English writing instruction, focusing on improving writing proficiency, academic writing conventions, and related instructional challenges. The primary focus is clearly on writing competence and pedagogy, not on automated scoring or system evaluation alone.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract states that the paper \u2018examines the implementation\u2019 and \u2018focuses on methods, outcomes, and challenges\u2019 but does not indicate any experimental or quasi-experimental design with quantifiable writing outcome metrics. It appears descriptive/practice-oriented rather than reporting measured intervention effects (e.g., pre/post test scores, rubric-based gains).""}}"
A Literature Review on Generative Artificial Intelligence Applications in Foreign Language Education,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The article is explicitly described as a literature review of generative AI in foreign language education, not a primary empirical study with a defined participant population of L2 English learners. It synthesizes 30 empirical studies rather than reporting original participant data.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""As a literature review, the paper does not itself implement an experimental or quasi-experimental LLM-based writing intervention. It only summarizes existing studies on GenAI tools in foreign language education.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although it notes that many included studies focus on writing instruction, the review\u2019s own primary focus is not a specific writing intervention or context but a broad overview of GenAI applications across multiple domains (user perceptions, assessment, teacher preparation, etc.).""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study does not report original quantitative writing outcome measures. It is a qualitative synthesis of prior work and thus does not provide direct experimental outcome data on LLM-mediated writing interventions.""}}"
"Effects of Speech-enabled Corrective Feedback Technology on Efl Speaking Skills, Anxiety and Confidence",2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are clearly described as learners of English as a foreign language (EFL) from China and Kazakhstan, so they are L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is a speech-enabled corrective feedback (SECF) system combining speech-to-text recognition with automated corrective feedback. There is no indication that this system is based on a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model); it appears to be an STR + rule-based/ACF tool rather than an LLM-mediated intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on speaking skills (pronunciation, discourse length, confidence to speak, anxiety) in EFL speaking practice. Writing is only involved as an intermediate representation of speech (speech-to-text), not as a target competence or writing instruction context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The reported outcomes are EFL speaking ability, foreign language anxiety, and confidence. No quantifiable writing outcomes or writing-related performance measures are reported.""}}"
Chatgpt in Foreign Language Teaching and Assessment: Exploring Efl Instructors' Experience,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study involves English language teachers of EFL and ESP courses in Ukraine, the EU, and the USA. While the participants are instructors rather than learners, the context is clearly EFL/ESL with English as the target language.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a survey of teachers\u2019 perceptions and familiarity with ChatGPT for teaching and assessment. It does not describe an experimental or quasi-experimental intervention integrating ChatGPT into learners\u2019 writing instruction or processes; it focuses on instructors\u2019 experiences and intentions.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although writing is mentioned as one of several skills (along with vocabulary and grammar), the primary focus is on general foreign language teaching and assessment development, not specifically on writing competence or writing-related variables as the main outcome of an intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The paper reports survey findings about perceptions, confidence, hesitancy, and satisfaction. It does not report any quantifiable learner writing outcomes or measured changes in writing performance resulting from an LLM-mediated writing intervention.""}}"
Evaluating Automated Grammar Corrective Feedback Tools: a Comparative Study of Grammarly and Quillbot in Esl Expository Essays,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study uses expository essays authored by Malaysian ESL students, clearly identifying the population as L2 English learners in an ESL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The tools investigated are Grammarly and Quillbot as automated grammar feedback applications. These are not described as LLM-based generative models integrated into instruction, but as error-detection tools. The focus is on their error-identification performance, not on an LLM-mediated pedagogical intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on comparing the tools\u2019 ability to detect and classify errors in existing writing samples, not on a writing instruction or intervention aimed at improving learners\u2019 writing competence. It is essentially a tool evaluation study, not a pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., pre/post writing scores, improvement measures) are reported. The study analyzes frequencies of errors flagged by the tools, not changes in learners\u2019 writing performance following an intervention.""}}"
Engage Learn: an Ai-based English Proficiency Improviser,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract describes an English learning and teaching platform but does not specify the target population (e.g., EFL/ESL/ELL learners) or provide details about participants. It is unclear whether the study involves L2 English learners in ESL/EFL/ELL contexts or a general user base.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The platform uses generative models including ChatGPT 3.5 Turbo and Gemini 1.5 Flash, enhanced via RAG, to provide targeted feedback on users\u2019 English. These are clearly LLM-based tools integrated into language learning, satisfying the LLM intervention criterion.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The system aims to improve users\u2019 ability to write and speak English and includes feedback on grammar, vocabulary, and fluency. However, the abstract emphasizes system architecture and speech-based interaction; it does not clearly state that the primary focus of the evaluation is writing competence or writing-related variables, as opposed to general language proficiency or speaking.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract mentions only \u2018planned evaluation methods\u2019 and \u2018user testing and data analysis\u2019 but does not describe any experimental or quasi-experimental design, nor any quantifiable writing outcome metrics. It appears to be a system description with prospective evaluation rather than a reported intervention study with measurable writing outcomes.""}}"
Personalized Recommendation Design of English Writing Marking System Based on Corpus,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract discusses college English writing teaching and higher vocational English teaching, implying learners of English in an EFL/ESL context. The focus is on English composition and college English writing, consistent with L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study focuses on a corpus-based automatic scoring and computer-aided composition marking system. There is no indication that the system is an LLM (e.g., ChatGPT, GPT-4) or transformer-based generative model; it appears to be a traditional automated scoring/evaluation system rather than an LLM-mediated writing intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on an automatic scoring/marking system and corpus-based teaching integration, not on an LLM-based pedagogical writing intervention. It describes computer-aided composition marking and online automatic evaluation, which aligns more with automated essay scoring functionality than with LLM-supported instructional processes.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract does not report or clearly indicate quantifiable writing outcome metrics (e.g., pre/post writing scores, accuracy, complexity). It mainly describes the teaching approach and context without specifying experimental measures or results.""}}"
University Students' Perceptions of Artificial Intelligence-based Tools for English Writing Courses,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Korean university students who have taken English writing courses and are explicitly described as English language learners (ELLs), fitting an EFL/ESL context focused on English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines perceptions of various AI-based tools (Google Translate, Naver Papago, Grammarly). These are not clearly LLM-based writing interventions, and the design is not experimental or quasi-experimental; it is a survey plus focus group on tool perceptions, not an instructional intervention using LLMs.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the context is English writing courses, the primary focus is on students\u2019 perceptions, strengths/weaknesses, and potential interference with writing processes, rather than a structured pedagogical intervention aimed at improving writing competence via LLMs.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports no quantifiable writing outcome measures (e.g., pre/post writing scores, rubric-based gains). Data are survey responses and interview findings about perceptions and experiences, not measured changes in writing performance following an LLM-mediated intervention.""}}"
Investigating Efl Faculty Members' Perceptions of Integrating Artificial Intelligence Applications to Improve the Research Writing Process: a Case Study at Majmaah University,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are EFL faculty members/teachers, not L2 English learners in ESL/EFL/ELL contexts. The focus is on teachers\u2019 own research writing, not on student L2 learning.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers broadly to \u201cAI applications and tools\u201d without specifying whether they are large language models (e.g., ChatGPT, GPT-4) or other types of AI. No particular LLM-based intervention is described.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The context is faculty research writing processes and their perceptions of AI tools, not pedagogical writing instruction or student writing development. It is not an instructional intervention in L2 writing.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports attitudes and perceptions via questionnaires and interviews. It does not report quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity) resulting from an AI-mediated intervention.""}}"
The Effects of Generative Ai Usage in Efl Classrooms on the L2 Motivational Self System,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Japanese university students in an EFL writing class, i.e., L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention integrates the generative pre-trained AI chatbot ChatGPT into an instructor-led writing class, with a control and treatment group, fitting an experimental/quasi-experimental LLM-based intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""ChatGPT is used in writing workshops where students collaborate and receive feedback from the chatbot; the context is clearly writing instruction and writing-related activities.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The reported outcomes are changes in motivational constructs (Ideal L2 Self, Ought-to L2 Self, L2 Learning Experience) measured via questionnaires. While the abstract mentions potential enhancement of writing skills, it does not report any quantifiable writing performance metrics or writing quality measures; the focus is on motivation, not writing outcomes.""}}"
Investigating the Impact of Chatgpt as an Ai Tool on Esl Writing : Prospects and Challenges in Saudi Arabian Higher Education,2024,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly states the participants are ESL students at a Saudi Arabian university, indicating L2 English learners in an EFL/ESL context with focus on English writing proficiency.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""ChatGPT is clearly an LLM, and the study examines its impact on ESL writing. However, the abstract does not specify whether there was an experimental or quasi-experimental design (e.g., control group, pre-post intervention) or how ChatGPT was systematically integrated into instruction versus being used in an unstructured way.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on ESL students\u2019 writing proficiency and how ChatGPT affects writing-related aspects such as feedback, language skill development, vocabulary, autonomy, and creativity. This aligns with a writing competence context rather than automated scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract reports that data from 130 students showed a \u2018significant positive effect\u2019 on writing, implying quantitative outcomes, but it does not specify the nature of the measures (e.g., rubric scores, test scores) or whether these are structured writing outcome metrics versus self-reported perceptions. Thus, it is unclear if quantifiable writing outcomes were actually measured.""}}"
Beyond Syntax: Exploring Moroccan Undergraduate Efl Learners' Engagement with Ai-assisted Writing,2024,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Moroccan undergraduate EFL learners in a general English course, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cAI-supported writing tools\u201d and \u201cAI assistance\u201d but does not specify whether these are large language model-based tools (e.g., ChatGPT, GPT-4) or other forms of AI (e.g., grammar checkers). Without explicit mention of LLMs or transformer-based generative models, it is unclear if the intervention meets the LLM criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on \u201cAI-assisted writing,\u201d examining the impact of AI tools on the writing process and writing quality, including organization, vocabulary, and creativity, within a pedagogical context.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""It is described as a quasi-experimental study with a control group and reports \u201cpositive outcomes in language proficiency, creativity, organizational skills, and vocabulary use,\u201d implying quantifiable writing-related outcome measures to assess the AI-assisted intervention.""}}"
Chatgpt for Language Learning: Assessing Teacher Candidates' Skills and Perceptions Using the Technology Acceptance Model (tam),2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL teacher candidates performing tasks in Spanish (L1) and English (L2), so they are L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT-4 is used only to generate comparison texts; there is no experimental or quasi-experimental instructional intervention where learners use the LLM as part of their writing instruction or process. The focus is on evaluating critical skills and perceptions, not on an LLM-mediated writing intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although participants complete writing tasks, the primary focus is on critical skills in distinguishing human vs. machine texts and perceptions of ChatGPT, not on improving writing competence or writing-related pedagogical outcomes through LLM use.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Text analysis metrics (SC, ASL, VOCD) are used to compare human and machine texts, but not as outcome measures of an LLM-based instructional intervention. The study does not report changes in learners\u2019 writing performance attributable to using ChatGPT; instead it reports perceptions and discrimination skills.""}}"
"Graduate Students' Use of Chatgpt for Academic Text Revision: Behavioral, Cognitive, and Affective Engagement",2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as six Iranian graduate ESL students from STEM fields, indicating L2 English learners in an ESL context with a focus on English academic writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used for academic text revision, the study is observational/qualitative: it examines how students engage with ChatGPT via screencasts, stimulated recall, interviews, and surveys. There is no experimental or quasi-experimental instructional intervention or comparison condition designed to test the effect of an LLM-based writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly L2 academic writing: students revise research proposals, focus on lower-order concerns, paraphrasing, and professionalism in writing. The study centers on writing processes and engagement with ChatGPT for text revision.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports behavioral, cognitive, and affective engagement and satisfaction, but does not mention any quantifiable writing outcome metrics (e.g., scores, quality ratings, error counts) to assess effectiveness. Outcomes are qualitative/engagement-focused rather than experimental measures of writing improvement.""}}"
Understanding Efl Students ' Use of Self-made Ai Chatbots as Personalized Writing Assistance Tools: a Mixed Methods Study,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 69 Chinese undergraduate EFL students, clearly L2 English learners in an EFL context, and the focus is on English writing (\u2018learning to write\u2019 in English).""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention involves students creating and using self-made RAG chatbots via Poe to assist with their writing processes. These are LLM-based chatbots integrated into writing support, fitting the LLM intervention criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is explicitly EFL writing: chatbots are used for idea generation, outlines, and error identification in writing. The study examines chatbots as pedagogical tools for personalized writing assistance, so the primary focus is writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports outcomes on writing motivation, confidence, beliefs, and attitudes, but does not mention any quantitative writing performance metrics (e.g., scores, quality ratings, accuracy measures). Data sources include essays, but no experimental or quasi-experimental writing outcome measures are described; the reported effects are affective, not performance-based.""}}"
Identifying Chatgpt-generated Texts in Efl Students' Writing: through Comparative Analysis of Linguistic Fingerprints,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Japanese EFL learners (140 first-year university students), clearly fitting an L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is present but not as a structured instructional or experimental writing intervention. The study focuses on distinguishability of human vs. ChatGPT-generated texts and uses ChatGPT mainly to generate comparison essays, not as a pedagogical tool in a designed intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on detecting ChatGPT-generated texts via linguistic fingerprints and machine learning classification, not on improving writing competence or implementing a writing pedagogy using LLMs.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., gains in writing quality, accuracy, complexity) are reported. Outcomes concern distinguishability and classification performance, not effectiveness of an LLM-mediated writing intervention.""}}"
Generative Ai's Recolonization of Efl Classrooms,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The context is Chinese English as a Foreign Language (EFL) classrooms and EFL assessment, clearly involving L2 English learners in an EFL setting.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study discusses the potential use of generative AI to provide sample writings and illustrates risks using data generated via AI chatbots, but it does not describe an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction. It is a critical/analytical piece rather than an intervention study.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The focus is on continuation writing and AI-generated sample texts, but the primary aim is to critique cultural and ideological implications (recolonization, native-speakerism), not to evaluate writing competence or a structured writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics or experimental measures are reported. The study uses SFL to analyze AI-generated texts and discusses risks, without assessing effects on learners\u2019 writing performance.""}}"
Korean-as-a-foreign-language Learners' Engagement with Machine Translation Output,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are US university students learning Korean as a foreign language. The target language is Korean, not English, and the context is KFL rather than ESL/EFL/ELL. The abstract explicitly frames the study around Korean writing, not L2 English writing.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses 'machine translators and other artificial intelligence-assisted programs' and a Guided Use of Machine Translation model. It does not specify whether the machine translator is an LLM-based system (e.g., GPT-based) or a traditional MT system (e.g., phrase-based or NMT without LLM interaction).""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on how learners use machine translators to revise their writing in Korean, examining engagement with MT output as feedback in the writing process. This aligns with a primary focus on writing competence and writing-related processes.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract describes an exploratory case study analyzing cognitive and behavioral engagement and reporting that students could identify and correct errors and used various revision strategies. It does not clearly state that quantifiable writing outcome metrics (e.g., pre/post writing scores, error rates) were collected to assess intervention effectiveness.""}}"
Automatic Scoring of Arabic Essays: a Parameter-efficient Approach for Grammatical Assessment,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The study focuses on automatic scoring of Arabic essays and uses Arabic datasets (QALB-2014, QALB-2015, ZAEBUC). There is no indication that the participants are L2 English learners or that the target language is English; the focus is on Arabic grammatical assessment.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The paper leverages a pre-trained AraBART model, which is a transformer-based large language model, fine-tuned with parameter-efficient methods for essay scoring. This satisfies the requirement of using an LLM-based system, though not in a pedagogical intervention context.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on automated essay scoring (AES) for grammaticality and other criteria, not on writing instruction or intervention to improve learners\u2019 writing competence. It is a scoring/assessment tool, not a pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports system performance on AES tasks (e.g., error-based grammatical scoring) rather than quantifiable outcomes of an LLM-mediated writing intervention on learners\u2019 writing. There is no experimental design measuring changes in learner writing performance.""}}"
