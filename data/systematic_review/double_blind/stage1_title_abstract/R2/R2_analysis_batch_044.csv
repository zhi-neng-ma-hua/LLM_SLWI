Title,Year,Decision,Notes
The Application of Chatbot as an L2 Writing Practice Tool,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were 75 Korean elementary school students engaged in English L2 writing practice, clearly an EFL/ESL context with English as the target language.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention used a chatbot developed with Google\u2019s Dialogflow by encoding expressions from an elementary school English textbook. This is a rule/intent-based chatbot platform, not a transformer-based large language model such as ChatGPT, GPT-4, Gemini, etc. Thus, it does not meet the requirement of integrating an LLM.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study explicitly focuses on chatbot-based L2 writing practice and compares it with traditional teacher-led writing instruction, with the primary outcome being writing performance.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports pretest and posttest writing performance scores and compares experimental and control groups, providing quantifiable writing outcome metrics. It also includes a survey, but the quantitative writing scores satisfy C4.""}}"
Academic Integrity Considerations of Ai Large Language Models in the Post-pandemic Era: Chatgpt and beyond,2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions 'supporting EFL learners' as one of several potential uses of LLMs, but the paper is framed broadly around students and higher education institutions, not a defined population of L2 English learners in ESL/EFL/ELL contexts. No specific participant group is described.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a conceptual/position paper on academic integrity issues related to student use of LLMs such as ChatGPT. It discusses potential ways LLMs can support education and writing, but does not describe an experimental or quasi-experimental intervention integrating LLMs into writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""While writing and composition are mentioned, the primary focus is academic integrity, plagiarism detection, and institutional policy, not a pedagogical context aimed at improving writing competence or writing-related variables through an intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not report any quantitative writing outcome measures or structured intervention results. It is an analytical discussion of issues and implications, not an empirical evaluation of LLM-mediated writing outcomes.""}}"
A Systematic Review on Artificial Intelligence Dialogue Systems for Enhancing English as Foreign Language Students’ Interactional Competence in the University,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The population of interest throughout the article is English as a Foreign Language (EFL) university students, i.e., L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""This is a systematic review of various AI dialogue systems rather than an experimental or quasi-experimental primary study integrating a specific LLM (e.g., ChatGPT, GPT-4) into writing instruction. It does not report on a concrete LLM-based intervention designed and tested by the authors.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on interactional competence and broader EFL learning (including reading, writing, listening) using AI dialogue systems. Writing is mentioned only generally; the review centers on interactional competence dimensions, not specifically on writing competence or writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a systematic review, it does not itself report original, quantifiable writing outcome metrics from an LLM-mediated writing intervention. It synthesizes prior work on interactional competence and AI dialogue systems without presenting new experimental writing outcome data.""}}"
Utilizing Artificial Intelligence Technologies in Saudi Efl Tertiary Level Classrooms,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are in Saudi EFL tertiary-level classrooms, i.e., English as a Foreign Language learners in Saudi Arabia. The abstract explicitly refers to EFL and English language learning (ELT), indicating L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines general AI technologies (Google Translate, Bing Translator, Wordtune, MT, AESs) and CALL tools. These are not clearly described as transformer-based large language models, and there is no indication of an experimental or quasi-experimental LLM-integrated writing intervention. The design is exploratory and survey-based (questionnaires), not an LLM-mediated instructional experiment.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""Writing is mentioned (e.g., Wordtune as a writing assistant, subjects of writing with AI technologies), but the primary focus appears to be broad AI use in EFL classrooms and ELT processes rather than a targeted writing competence intervention. The abstract does not clearly describe a structured writing-focused pedagogical intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Data were collected via questionnaires and analyzed with SPSS, suggesting attitudinal or perception measures. The abstract does not report any quantifiable writing outcome metrics (e.g., writing scores, text quality measures) assessing the effectiveness of AI tools on writing performance.""}}"
A Corpus-based Study of the Usage of Chinese Core Separable Words in the Use of Language,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are Chinese L2 learners and native Chinese speakers; the focus is on Chinese as a second language and International Chinese Language Education, not on L2 English learners or English language contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a corpus-based analysis using BCC, CCL, and HSK learner corpora. There is no mention of large language models, ChatGPT-like systems, or any AI-based instructional intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on usage of Chinese core separable words and learner errors, not on writing competence in English or any L2 writing intervention context. It is descriptive corpus research, not a pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No experimental or quasi-experimental intervention is described, and no quantifiable writing outcome metrics related to an LLM-mediated writing intervention are reported. The study analyzes corpus usage patterns and error types only.""}}"
A Deep Fusion Model for Human Vs. Machine-generated Essay Classification,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract states that the datasets contain short essays in English and Spanish written by L2 learners. Thus, there is an L2 population and English is one of the target languages.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study proposes a deep neural network-based model for classifying essays as human vs. machine-generated. It does not describe an instructional intervention using LLMs (e.g., ChatGPT) in writing instruction or processes; LLMs are only the source of machine-generated texts to be classified.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is essay classification (human vs. machine-generated) for integrity and detection purposes, not on improving writing competence or writing-related pedagogical outcomes. This aligns more with automated detection than with writing instruction.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) are reported. The outcomes are classification performance metrics, not measures of L2 writing development or intervention effectiveness.""}}"
Efl Paraphrasing Skills with Quillbot: Unveiling Students' Enthusiasm and Insights,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are explicitly described as EFL (English as a foreign language) preparatory year students, indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention tool is QuillBot. Based on the review\u2019s criteria, tools like QuillBot are treated as AI writing aids that are not clearly positioned as transformer-based generative LLMs for instructional integration. The abstract does not indicate use of an LLM such as ChatGPT, GPT-4, Gemini, etc., but rather a paraphrasing tool, which falls under the exclusion note for non-LLM AI tools.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on paraphrasing skills within writing, including performance in synonyms, sentence structure, and word choice, and the context is a writing class. This aligns with a primary focus on writing competence.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports that students \u2018improved their performance in synonyms, sentence structure, and word choice,\u2019 implying quantifiable writing outcome measures in a quasi-experimental design, alongside attitudinal data.""}}"
Comparing Measures of Syntactic and Lexical Complexity in Artificial Intelligence and L2 Human-generated Argumentative Essays,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are first-year Tswana L2 learners of English at a South African university, clearly an L2 English learner population in an EFL/ESL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT-3.5 is used only to generate comparison essays; there is no experimental or quasi-experimental instructional intervention integrating the LLM into learners\u2019 writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on comparing syntactic and lexical complexity between AI- and human-generated essays, not on a pedagogical writing intervention or development of learners\u2019 writing competence using LLMs.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported for an LLM-mediated intervention. The measures are used for corpus comparison, not to assess the effectiveness of an instructional treatment involving LLMs.""}}"
The Use and Abuse of Artificial Intelligence-enabled Machine Translation in the Efl Classroom: an Exploratory Study,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL learners in higher education where English is not their first language, clearly fitting an L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention centers on Google Translate as an AI-enabled machine translation tool. The abstract does not indicate that a large language model (LLM) or transformer-based generative model (e.g., ChatGPT, GPT-4) is used; it focuses on MT use, practices, and beliefs, not an LLM-based writing assistant.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study compares the quality of writing drafts created with and without Google Translate, indicating a primary focus on writing performance in an EFL classroom context.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses pre- and post-tests to compare the quality of writing drafts with and without MT, implying quantifiable writing outcome metrics are collected to assess the impact of the intervention.""}}"
Work in Progress: Chatgpt as an Assistant in Paper Writing,2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions \u201cnon-native English speakers,\u201d which suggests L2 English users, but it does not specify ESL/EFL/ELL instructional contexts or participant characteristics. It is unclear whether there is a defined learner population or just a general discussion.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is described as a discussion of the potential of ChatGPT as an assistant in paper writing. There is no indication of an experimental or quasi-experimental design, structured intervention, or empirical implementation of ChatGPT in instruction.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The focus is on \u201cpaper writing\u201d in natural English, which is writing-related, but the abstract frames this as a conceptual discussion of ChatGPT\u2019s potential and ethical use, not a pedagogical intervention study targeting writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or empirical assessment. It appears to be a conceptual or opinion piece about potential uses and ethical considerations, without reported intervention outcomes.""}}"
A Deep Fusion Model for Human $vs$. Machine-generated Essay Classification,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract states that the datasets contain short essays in English and Spanish written by L2 learners. Thus, the population includes L2 English learners and English essay data.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study proposes a deep neural network-based model for classifying essays as human vs. machine-generated. It does not describe an instructional intervention using LLMs (e.g., ChatGPT) for teaching or supporting writing; instead, LLM-related content is only the target of classification.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on essay classification (human vs. machine-generated) and model performance, not on improving writing competence or writing-related pedagogical outcomes. There is no writing instruction or intervention context described.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) are reported. Outcomes are classification accuracy and model competitiveness, not learner writing gains or changes.""}}"
A Syntactic Complexity Analysis of Revised Composition through Artificial Intelligence-based Question-answering Systems,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are college English learners taking the TEM-4 test, which is an English proficiency test for Chinese EFL learners. The focus is clearly on L2 English argumentative essay writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used to revise students\u2019 essays, the design is a comparison between original student texts and ChatGPT-revised versions, not an experimental or quasi-experimental pedagogical intervention where learners interact with the LLM as part of instruction or writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on syntactic complexity differences between human-written and ChatGPT-revised texts. There is no described instructional context or structured writing intervention; rather, it is an analysis of AI-revised output as a potential reference, similar to a functionality or text-quality evaluation.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports syntactic complexity metrics comparing student essays and ChatGPT revisions, but there is no measurement of changes in learners\u2019 own writing performance following an LLM-mediated intervention. No experimental outcome on learner writing development is reported.""}}"
Intertextuality in Pre-service Teachers' Argumentative Essay in Raising Ai: Practices and Beliefs,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as Indonesian EFL pre-service teachers, which fits the target population of L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The abstract mentions essays 'assisted by AI' and 'in a rising AI era' but does not specify the use of large language models (e.g., ChatGPT, GPT-4) or any particular transformer-based generative system, nor does it describe an experimental or quasi-experimental intervention integrating such tools into instruction. It is framed as a case study of existing practices and beliefs rather than a structured LLM-based intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on argumentative essay writing, specifically intertextuality practices in EFL pre-service teachers\u2019 academic writing, which is clearly a writing-related construct.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses a case study design with content analysis of essays and interviews to explore practices and beliefs. There is no indication of an experimental or quasi-experimental design with quantifiable writing outcome metrics to assess the effectiveness of an AI/LLM-mediated intervention; rather, it is descriptive/qualitative.""}}"
Utilization of Artificial Intelligence in Academic Writing Class: L2 Learners Perspective,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study focuses on second language (L2) learners in the Philippines in academic writing classes, which fits ESL/EFL/ELL-type contexts with English as the implied target language.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a descriptive survey of perceptions and experiences regarding AI tools; there is no experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into instruction or writing processes. The type of AI (LLM vs other) is not specified, and no intervention is implemented.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the context is academic writing, the focus is on awareness, preferences, and concerns about AI use, not on a pedagogical intervention aimed at improving writing competence. It is attitudinal rather than an instructional or intervention study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports survey-based perceptions only and does not provide quantifiable writing outcome metrics (e.g., writing scores, text quality measures) to assess the effectiveness of AI- or LLM-mediated writing interventions.""}}"
Looks like Google to Me: Instructor Ability to Detect Machine Translation in L2 Spanish Writing,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are L2 learners of Spanish, not L2 English learners. The context is an intermediate-level Spanish writing course, so the target language is Spanish rather than English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study focuses on instructors\u2019 ability to detect machine translation in student writing. It does not describe an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction; rather, it examines detection accuracy of MT use.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on detection of MT vs. non-MT texts and related instructor factors, not on a writing intervention aimed at improving writing competence through LLM use.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., changes in writing quality due to an LLM-mediated intervention) are reported. Outcomes concern detection accuracy and related variables, not intervention effects on writing.""}}"
Impact of Chatgpt on Learners in a L2 Writing Practicum: an Exploratory Investigation,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract clearly states the context is an L2 writing practicum and refers to L2 writing learners, implying participants are second language learners. While the target language is not explicitly named as English, the L2 writing practicum context suggests L2 learners consistent with ESL/EFL/ELL-type settings.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study applies ChatGPT\u2019s text generation feature in a one-week L2 writing practicum, indicating an intervention where an LLM (ChatGPT) is integrated into writing classrooms as part of instruction or practice.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is explicitly a \u2018one-week L2 writing practicum\u2019 and \u2018writing classrooms,\u2019 focusing on the impact of ChatGPT on L2 writing pedagogy and composing workflows, which aligns with writing competence and writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is described as adopting a qualitative approach to investigate students\u2019 behaviors and reflections, triangulating learning activities and reflective perceptions. There is no mention of quantitative or otherwise structured, quantifiable writing outcome metrics; the focus is on affordances, perceptions, and concerns rather than measured changes in writing performance.""}}"
Roles and Research Foci of Artificial Intelligence in Language Education: an Integrated Bibliographic Analysis and Systematic Review Approach,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The article is a broad review of Artificial Intelligence in Language Education (AILEd) from 1990\u20132020 and does not specify that it focuses on L2 English learners in ESL/EFL/ELL contexts. It aggregates diverse language education studies without restricting to English L2 populations.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""This is an integrated bibliographic analysis and systematic review, not an experimental or quasi-experimental study implementing an LLM-based intervention. It surveys technologies such as ITS and NLP and AI algorithms (Statistical Learning, Data Mining, Machine Learning) rather than reporting on a specific LLM-mediated writing intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the review notes that writing is one of the main application domains, its primary purpose is to map roles and research foci of AI in language education generally, not to implement or evaluate a concrete writing intervention. It is a secondary study, not a pedagogical trial focused on writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is a review and does not report original, quantifiable writing outcome metrics from an LLM-mediated intervention. It synthesizes prior work and discusses learning outcomes in general terms, offering suggestions rather than presenting experimental measures of writing performance.""}}"
Recipe: How to Integrate Chatgpt into Eflwriting Education,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 213 undergraduate and graduate students enrolled in EFL writing courses, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study presents RECIPE, a learning platform that integrates ChatGPT (a large language model) into EFL writing education, with ChatGPT taking an EFL teacher role and engaging in dialogue based on students\u2019 self-written summaries.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is explicitly EFL writing education, with a platform designed for revising essays and supporting EFL writing courses, so the primary focus is on writing-related learning.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports collection of interaction data, students\u2019 perceptions and usage, user scenarios, and qualitative interviews. It does not mention any experimental or quasi-experimental design with quantifiable writing outcome measures (e.g., writing scores, quality ratings, accuracy gains). Outcomes are primarily perceptions and design opportunities, not measured writing improvement.""}}"
Who Wrote This Essay? Detecting Ai-generated Writing in Second Language Education in Higher Education,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The participants are ESL lecturers, not L2 English learners. The study focuses on teachers\u2019 ability to detect AI-generated texts, not on L2 learners\u2019 development or performance.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT and AI detectors are mentioned, they are used as objects of detection and comparison, not as an instructional intervention or integrated tool in learners\u2019 writing processes. There is no experimental or quasi-experimental LLM-based teaching intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is academic integrity and detection of AI-generated writing, along with lecturers\u2019 assessment practices and policy implications. It does not examine writing competence or writing-related learning outcomes for L2 learners.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is qualitative and centers on lecturers\u2019 evaluations and perceptions. It does not report quantifiable writing outcome metrics for L2 learners or measure the effectiveness of any LLM-mediated writing intervention.""}}"
Assessing Second-language Academic Writing: Ai Vs. Human Raters,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are first-year college students producing L2 academic writing; the context is clearly second-language (L2) writing assessment, implying L2 English learners in an academic setting.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT-3.5 is used as an automated rater to score student paragraphs, not as part of an instructional or intervention design to support writing development. There is no experimental or quasi-experimental LLM-based teaching or feedback intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on the assessment function of LLMs (ChatGPT vs. human raters) for rating L2 writing quality, not on improving writing competence or integrating LLMs into writing instruction or processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although writing scores are reported, they are used solely to compare rating reliability between ChatGPT and human raters. There is no LLM-mediated writing intervention whose effect on writing outcomes is evaluated.""}}"
