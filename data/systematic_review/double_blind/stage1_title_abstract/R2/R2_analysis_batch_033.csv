Title,Year,Decision,Notes
A Case Study of Implementing Generative Ai in University’s General English Courses,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL learners in Korean university-level general English courses, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions a 'generative AI-based instruction model' but does not specify whether this is an LLM (e.g., ChatGPT/GPT-like) or another form of generative AI. The specific tool or model type is not identified.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The abstract notes that the AI-based instruction is for 'writing and speaking' and mentions 'linguistic proficiency,' but the primary stated focus of the study is on affective factors (motivation, interest, confidence), not explicitly on writing competence or writing-related variables as the main outcome.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is described as investigating effects on affective factors (motivation, interest, confidence). While it mentions potential effectiveness for writing and speaking proficiency, it does not indicate that quantifiable writing outcome metrics were collected or reported; outcomes appear to be affective rather than writing-performance measures.""}}"
Detecting and Assessing Ai-generated and Human-produced Texts: the Case of Second Language Writing Teachers,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The participants in focus are second language writing teachers, not L2 English learners. The abstract does not indicate that data are collected on L2 learners\u2019 own writing development or performance as participants; instead, it examines teachers\u2019 assessment of AI- vs. human-produced texts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT-generated text is involved, the study does not describe an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or learners\u2019 writing processes. It focuses on teachers\u2019 ability to detect AI-generated texts, not on LLM-mediated instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on assessment and detection of AI-generated versus human-produced essays by teachers, not on improving writing competence or writing-related learning outcomes through an instructional intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study analyzes teachers\u2019 scores and comments and their strategies for identifying AI-generated texts. It does not report quantifiable writing outcome metrics for L2 learners following an LLM-based writing intervention.""}}"
The Impact of Chatgpt on English Language Learners’ Writing Skills: an Assessment of Ai Feedback on Mobile,2024,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as English as a second language (ESL) learners in a senior secondary public school in India. The focus is explicitly on English writing skills and common English grammatical errors.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses ChatGPT\u2019s mobile application to provide feedback on students\u2019 writing error corrections in a quasi-experimental design, comparing it to traditional teacher feedback. ChatGPT is a large language model integrated into the writing instruction process.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on ESL writing skills, including grammar and composition proficiency, and the impact of AI feedback on common writing errors. ChatGPT is used pedagogically to support writing development, not merely for scoring.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Quantitative outcomes are reported via pre- and post-tests involving story writing based on pictures, with measured reductions in specific error types and improved writing proficiency in the experimental group compared to the control group.""}}"
Large Language Models and Automated Essay Scoring of English Language Learner Writing: Insights into Validity and Reliability,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study uses 119 essays from an English language placement test written by English language learners, indicating an ELL/L2 English population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although multiple LLMs (PaLM 2, Claude 2, GPT-3.5, GPT-4) are used, they are employed solely as automated essay scoring tools, not as part of an instructional or quasi-experimental writing intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on the validity and reliability of LLM-based automated essay scoring, not on improving learners\u2019 writing competence or integrating LLMs into writing instruction or processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No pedagogical intervention or LLM-mediated writing support is tested; the outcomes are psychometric properties of scoring (validity, reliability), not quantifiable changes in learners\u2019 writing performance due to an intervention.""}}"
Evaluating Cami Ai across Samr Stages: Students’ Achievement and Perceptions in Efl Writing Instruction,2024,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly states that participants are 126 EFL (English as a Foreign Language) university students, indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses \u201cCami, an AI-powered tool\u201d and refers to \u201cCami AI technology,\u201d but it does not specify whether Cami is a large language model (e.g., ChatGPT-like, transformer-based generative model) or another type of AI (e.g., annotation, feedback, or grading tool). Without clarification that it is LLM-based, it is unclear if it meets the LLM intervention criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is explicitly EFL writing instruction, and the study examines the impact of Cami AI-SAMR implementation on EFL students\u2019 writing achievement, indicating a primary focus on writing competence within a pedagogical intervention.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract reports that Cami AI-SAMR implementation \u201csignificantly impacted EFL students\u2019 writing achievement,\u201d implying quantitative measures of writing performance as outcomes, alongside qualitative perceptions.""}}"
Advancing Efl Writing Proficiency in Jordan: Addressing Challenges and Embedding Progressive Strategies,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 150 Jordanian EFL students majoring in English across three public universities, clearly an EFL (L2 English) context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the abstract mentions the integration of advanced technologies such as AI as a potential strategy, there is no indication that an LLM-based tool (e.g., ChatGPT) was actually implemented as an experimental or quasi-experimental intervention. The study is descriptive/exploratory, not an LLM-mediated instructional intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on identifying challenges in EFL writing and proposing general strategies, including AI, rather than empirically examining a specific LLM-integrated writing intervention or process.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics related to an LLM-mediated intervention are reported. The study uses surveys and interviews to explore challenges and suggested strategies, without experimental measures of writing improvement due to LLM use.""}}"
Can Chatgpt Reliably and Accurately Apply a Rubric to L2 Writing Assessments? the Devil Is in the Prompt(s),2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to 'second language (L2) writing' and is published in the Journal of Technology and Chinese Language Teaching. It is unclear whether the target language is English or Chinese, and no explicit mention of English L2 learners (ESL/EFL/ELL) is made.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is used as an assessment tool to score L2 writing and compare its scores with human raters. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating ChatGPT into writing instruction or writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on the accuracy and reliability of ChatGPT as an automated writing assessment tool, not on improving learners\u2019 writing competence or implementing a teaching/learning intervention. This aligns with excluded contexts (automated essay scoring functionality).""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports on the reliability and accuracy of AI-generated scores compared to human raters, not on quantifiable changes in learners\u2019 writing performance following an LLM-mediated intervention. No writing outcome metrics related to instructional impact are described.""}}"
Paraphrase or Plagiarism? Exploring Eap Students’ Use of Source Material in a Transnational University Context,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly states that the study investigates English as a Second Language (ESL) student writers in an English for Academic Purposes (EAP) context, which fits the target L2 English learner population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the abstract mentions Generative AI and students\u2019 confidence in technological tools, there is no indication that an LLM-based tool (e.g., ChatGPT) is actually integrated as an experimental or quasi-experimental intervention in the writing process. The study is exploratory, using text-based interviews and a custom writing task, not an LLM-mediated instructional intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on academic writing practices\u2014specifically paraphrasing, plagiarism, and use of source material in EAP writing\u2014so the primary context is writing competence and writing-related behaviors.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is described as exploratory, using interviews and a writing task to examine how students make decisions about source use. The abstract does not report any quantifiable writing outcome metrics assessing the effectiveness of an LLM-mediated intervention; instead, it focuses on qualitative insights and perceptions, including views on technological tools.""}}"
Improving Writing Feedback for Struggling Writers: Generative Ai to the Rescue?,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions students with and without disabilities who struggled with writing and notes that AI feedback did not reflect student characteristics such as ELL status. However, it does not specify that the target population is L2 English learners in ESL/EFL/ELL contexts, nor that the data focus specifically on English as an L2.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study imports existing student essays into two versions of ChatGPT and analyzes the feedback and instructional suggestions generated, comparing them with teachers\u2019 feedback. There is no experimental or quasi-experimental pedagogical intervention where LLMs are integrated into writing instruction or writing processes for learners; rather, it is an evaluation/comparison of AI-generated feedback.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the context is writing instruction and feedback, the focus is on comparing AI and teacher feedback quality and characteristics, not on implementing an LLM-mediated instructional intervention aimed at improving learners\u2019 writing competence. It functions more as an evaluation of AI feedback than a pedagogical intervention study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics (e.g., pre/post writing scores, rubric-based gains) resulting from an LLM-based intervention. Analyses are qualitative (inductive thematic analysis of AI and teacher feedback), with no experimental measures of changes in student writing performance.""}}"
Efl Learners’ Attitudes towards Utilizing Chatgpt for Acquiring Writing Skills in Higher Education: a Case Study of Computing Students,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as EFL learners taking an English language course at a private university in Sharjah, focusing on acquisition of English writing skills.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT is an LLM and is used for essay writing, the study is framed as exploring students\u2019 attitudes toward utilizing ChatGPT rather than implementing an experimental or quasi-experimental instructional intervention. No controlled or structured LLM-mediated teaching design is described.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly writing-focused: acquisition of writing skills in English, higher-order thinking skills related to effective writing, and comparison of ChatGPT-based essay writing versus self-dependent essay writing.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses a questionnaire and semi-structured interviews to measure attitudes, advantages, and drawbacks. There is no indication of quantifiable writing performance outcomes (e.g., scores, rubric-based writing measures) resulting from an intervention; reported findings concern perceived effectiveness, not measured writing gains.""}}"
Detecting Chatgpt-generated Essays in a Large-scale Writing Assessment: Is There a Bias Against Non-native English Speakers?,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Although the study involves GRE writing assessment data that likely includes non-native English speakers, the focus is not on L2 learners\u2019 development or instruction but on detector bias. The abstract does not specify an L2 learner population in ESL/EFL/ELL instructional contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study develops detectors of ChatGPT-generated essays using linguistic and perplexity features. ChatGPT is only the source of generated texts; there is no experimental or quasi-experimental integration of an LLM into writing instruction or writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on AI-generated text detection and bias in large-scale assessment, not on improving writing competence or writing-related pedagogical interventions. It is essentially an assessment/detector performance study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics related to learners\u2019 writing performance or development are reported. Outcomes concern detection accuracy and bias, not changes in writing quality or related variables following an LLM-mediated intervention.""}}"
Testing the Viability of Chatgpt as a Companion in L2 Writing Accuracy Assessment,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study uses the Cambridge Learner Corpus First Certificate in English (CLC FCE), which consists of L2 English learner writing. The focus is clearly on L2 English writing accuracy.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is used as an automated evaluator of linguistic accuracy, not as part of an instructional or experimental intervention in learners\u2019 writing processes. The design compares ChatGPT, Grammarly, and human raters on an existing corpus; there is no LLM-mediated teaching or practice component.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on the viability of ChatGPT for automated accuracy assessment within the CAF framework, not on improving writing competence through pedagogical use. It evaluates tool performance as an assessment system rather than implementing a writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although writing accuracy scores are analyzed, they are used to validate ChatGPT as an assessment tool, not as outcome measures of an LLM-based instructional intervention. No experimental or quasi-experimental teaching treatment or pre/post writing outcomes are reported.""}}"
"A Meta-analysis of Effects of Automated Writing Evaluation on Anxiety, Motivation, and Second Language Writing Skills",2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers broadly to second language (L2) writing skills but does not specify that the population is L2 English learners in ESL/EFL/ELL contexts, nor that the focus is specifically on English rather than other L2s.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a PRISMA-based meta-analysis of automated writing evaluation (AWE) technologies in general. It does not focus on large language models (e.g., ChatGPT, GPT-4) but on AWE systems as a category, many of which are not LLM-based. It is also a secondary study, not an experimental or quasi-experimental primary intervention study.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the meta-analysis concerns writing skills and related affective variables, it is not a primary pedagogical intervention study but a synthesis of prior work on AWE. The review\u2019s focus is not on implementing an LLM-mediated writing intervention in a specific instructional context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a meta-analysis, it aggregates effect sizes from prior studies rather than reporting original experimental outcomes of an LLM-based writing intervention. The review protocol excludes secondary research such as meta-analyses.""}}"
Understanding Efl Students’ Use of Self-made Ai Chatbots as Personalized Writing Assistance Tools: a Mixed Methods Study,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 69 Chinese undergraduate EFL students, clearly L2 English learners in an EFL context: \u201cEnglish as a foreign language (EFL) students\u2026 69 Chinese undergraduate students.\u201d""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention involves students creating and using self-made retrieval augmented generation (RAG) chatbots via Poe to assist with their writing processes. RAG chatbots are LLM-based tools, and the study integrates them into writing instruction/workshop activities.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on writing processes and support: chatbots assist with idea generation, outlines, and error identification, and students write essays using their chatbots. The context is clearly writing competence and writing-related variables (motivation, goals, confidence).""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports outcomes on writing motivation, goals, confidence, beliefs, and attitudes, but does not mention any quantitative writing performance metrics (e.g., scores, quality ratings, accuracy measures). The mixed methods design appears to focus on motivational and attitudinal outcomes rather than measurable changes in writing quality, so it does not meet the requirement for quantifiable writing outcome metrics.""}}"
Chatgpt for L2 Learning: Current Status and Implications,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The article is a review of 44 studies on ChatGPT for L2 learning, not a primary empirical study with its own participant sample. Thus, it does not itself involve a defined population of L2 English learners as participants in an intervention.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""This is described as a systematic review of existing studies on ChatGPT for L2 learning, not an experimental or quasi-experimental study implementing an LLM-based writing intervention. It synthesizes others\u2019 interventions rather than conducting one.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the abstract notes that many included studies target writing skills, this article\u2019s primary focus is mapping the literature (roles of ChatGPT, participants, objectives, theories, methods, outcomes), not implementing or evaluating a specific writing-focused pedagogical intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a review article, it does not report original, quantifiable writing outcome metrics from a new intervention. It summarizes benefits and challenges from prior studies instead of presenting its own experimental outcome data.""}}"
"The Metaphor of Ai in Writing in English: a Reflection on Efl Learners’ Motivation to Write, Enjoyment of Writing, Academic Buoyancy, and Academic Success in Writing",2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 86 intermediate EFL students from China in an English as a foreign language context, clearly L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses an automated writing evaluation (AWE) system. The abstract does not indicate that this AWE is an LLM-based, transformer generative model (e.g., ChatGPT, GPT-4). AWE tools are typically rule-based or non-LLM machine learning systems, which fall outside the review\u2019s inclusion criteria.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on fostering learners\u2019 writing skills and related variables (motivation to write, enjoyment of writing, academic buoyancy, and academic success in writing) in an EFL writing context, aligning with a writing-focused intervention.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantitative outcomes, including academic success in writing and measures of motivation, enjoyment, and academic buoyancy, analyzed via one-way MANOVA, satisfying the requirement for quantifiable writing-related outcomes.""}}"
Effect of Editgpt on the Learners` Autonomy and Learning Anxiety,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were thirty Omani EFL learners, clearly indicating L2 English learners in an EFL context, with English as the target language in writing instruction.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention used an automated writing evaluation system called EditGPT, described as an AI application. Given the name and context, it is reasonably inferred to be based on GPT (a large language model), and it was integrated into instruction for the experimental group.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the tool is used in English writing instruction, the study\u2019s primary focus and measured outcomes are learning anxiety and learner autonomy, not writing competence or writing-related performance variables. No writing performance or writing quality measures are mentioned.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports quantitative outcomes only for foreign language anxiety and autonomy scales. It does not report any quantifiable writing outcome metrics (e.g., writing scores, accuracy, complexity, fluency), so it does not assess the effectiveness of the LLM-mediated intervention on writing performance.""}}"
"Chatgpt-empowered Writing Strategies in Efl Students’ Academic Writing: Calibre, Challenges and Chances",2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 60 Chinese university juniors majoring in English (EFL context), and the focus is on English academic writing. This matches the target population of L2 English learners in an EFL setting.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses a CSE-based questionnaire and focus group interviews to investigate current usage, perceptions, and potential applications of ChatGPT. There is no indication of an experimental or quasi-experimental instructional intervention where ChatGPT is systematically integrated into writing instruction or processes with controlled conditions.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on English academic writing strategies (planning, composing, revising) and how ChatGPT can empower these writing strategies for EFL students, which aligns with writing competence and writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although mixed methods are used, the quantitative component is based on a questionnaire (CSE-based) and analyzed with descriptive statistics and regression. The abstract does not report objective, quantifiable writing performance outcomes (e.g., writing scores, text quality measures) resulting from an LLM-mediated intervention; it focuses on perceived assistance and usage patterns.""}}"
Exploring the Use of Chatgpt as a Tool for Written Corrective Feedback in an Efl Classroom,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are five Form Four students in a Band 2 secondary school in Hong Kong, clearly an EFL context with English as the target language.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention explicitly uses ChatGPT, a large language model, as a writing feedback tool. Students write tasks and revise based on ChatGPT feedback, indicating an LLM-mediated writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on written corrective feedback (WCF) in an EFL classroom, with students writing and revising texts. The study examines the effectiveness of ChatGPT feedback in relation to writing improvement, so the primary focus is on writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract describes exploration of cognitive factors via stimulated recall interviews and students\u2019 perceptions. It does not mention any quantitative or otherwise explicit writing outcome measures (e.g., scores, error rates, rubric-based gains) to assess effectiveness. Outcomes are reported qualitatively (valuing feedback, difficulties understanding/attending to feedback), so it fails the requirement for quantifiable writing outcome metrics.""}}"
Tapping into the Pedagogical Potential of Infinigochatic: Evidence from Iwrite Scoring and Comments and Lu & Ai’s Linguistic Complexity Analyzer,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are postgraduate students taking an English reading and writing course in Southwest China, clearly functioning as L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although infinigoChatIC (a ChatGPT-based LLM) is used to polish learner texts, the design is not an experimental or quasi-experimental pedagogical intervention with learners. The teacher inputs existing homework into the LLM and compares LLM-polished texts to original learner texts; learners do not interact with the LLM as part of instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on comparing LLM-polished texts with learner texts using automated scoring and linguistic complexity analysis, not on a teaching/learning intervention targeting writing competence. It functions more as an evaluation of LLM output quality than a structured writing pedagogy study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""While quantitative measures (iWrite scores, lexical and syntactic complexity) are reported, they assess differences between LLM output and learner writing, not changes in learners\u2019 writing performance following an LLM-mediated intervention. No learner outcome over time or treatment effect is measured.""}}"
