Title,Year,Decision,Notes
Towards a Taxonomy of Artificial Intelligence in Teaching Writing in a Foreign Language,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers broadly to 'foreign language teaching' and 'teaching writing in a foreign language' without specifying English or L2 English learners (ESL/EFL/ELL). The target language and learner population are not clearly identified.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The article aims to identify characteristics and capacities of AI sites and proposes a taxonomy, describing advantages, disadvantages, and potential applications. There is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into instruction; it appears to be a conceptual/overview piece.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the focus is on AI in teaching writing in a foreign language, the work is described as proposing a taxonomy, describing tools, and suggesting applications, rather than implementing and evaluating a concrete pedagogical intervention in writing.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not mention any empirical data collection or quantifiable writing outcome measures. It focuses on taxonomy, description, and evaluation of benefits/drawbacks at a conceptual level, without reporting experimental outcomes.""}}"
Using Ai-generative Tools in Tertiary Education: Reflections on Their Effectiveness in Improving Tertiary Students' English Writing Abilities,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The population is \u2018tertiary students\u2019 in Hong Kong, and the study focuses on their English writing abilities, implying L2 English learners in an EFL/ESL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions \u2018AI-generative tools, such as ChatGPT\u2019 and \u2018their experience using AI in learning and writing,\u2019 but does not clearly describe an experimental or quasi-experimental instructional intervention; it appears more exploratory/reflective.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The stated aim is to find out whether AI-generative tools can help improve students\u2019 English writing skills, and the context is explicitly about using AI in writing and learning writing skills.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Methods are described as interviews to gather opinions from students and teachers. No mention is made of quantitative writing outcome measures or experimental evaluation of writing performance; the focus is on perceptions and reflections.""}}"
An Investigation of Artificial Intelligence Tools in Editorial Tasks among Arab Researchers Publishing in English,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are described as 'Arab researchers who publish in English,' i.e., academic researchers using English for publication, not L2 English learners in ESL/EFL/ELL instructional contexts. The focus is on scholarly publishing practices, not language learners in educational settings.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study surveys use of AI tools such as Grammarly, Endnote, and QuillBot. These are not clearly LLM-based writing-intervention tools in an experimental or quasi-experimental design; rather, they are general-purpose editorial aids, and no structured pedagogical intervention is implemented.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The context is editorial tasks in scholarly publishing, not an instructional setting focused on developing writing competence. The study examines adoption, challenges, and ethics of AI tools, not a pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports survey-based perceptions of usage, challenges, and ethical considerations. It does not report quantifiable writing outcome metrics (e.g., changes in writing quality, scores, or performance) resulting from an AI-mediated writing intervention.""}}"
Analyzing the Use of Ai Writing Assistants in Generating Texts with Standard American English Conventions: a Case Study of Chatgpt and Bard,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The abstract does not mention any human participants, learners, or educational setting (ESL/EFL/ELL). It analyzes AI-generated texts using corpus methods, not data from L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT and Bard are examined as text generators, but there is no experimental or quasi-experimental pedagogical intervention integrating these LLMs into writing instruction or learner writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on linguistic conventions and collocational patterns in AI-generated texts and their implications, not on an instructional context aimed at improving learner writing competence through LLM use.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics for learners are reported. The study is a corpus-based analysis of AI output, with only general pedagogical implications, not measured intervention outcomes.""}}"
Network Algorithms for Intelligent Evaluation of Composition in Middle School English Cloud Classrooms,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions 'English compositions for middle school students' but does not specify whether these are L2 English learners (ESL/EFL/ELL) or native speakers. The learner population and L2 status are not clearly identified.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study proposes a method combining a link grammar detector with an N-grammar model and compares it to Grammarly. This is an automated scoring/evaluation algorithm, not an LLM-based (e.g., ChatGPT, GPT-4) intervention integrated into writing instruction or processes. No large language model is mentioned.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on automated evaluation and scoring of compositions (accuracy, recall, mean square error, runtime) rather than on a pedagogical writing intervention or development of writing competence. It is essentially an automated essay scoring system.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although quantitative metrics are reported, they concern system performance (recall, accuracy, error vs. manual scoring, MSE, runtime), not learner writing outcomes following an LLM-mediated instructional intervention. No experimental measures of changes in students\u2019 writing performance are provided.""}}"
Can My Writing Be Polished Further? When Chatgpt Meets Human Touch,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as EFL learners (\u201c19 EFL learners\u201d), indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study investigates the use of ChatGPT, a large language model, in EFL writing classrooms and describes a collaborative writing process with ChatGPT, indicating an LLM-based writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on EFL writing processes and refinement (grammar correction, vocabulary enrichment, sentence structuring) within a classroom context, aligning with writing competence and writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports think-aloud sessions, interviews, and qualitative findings about collaborative work, emotional reassurance, and metacognitive awareness. It does not mention any experimental or quasi-experimental design with quantifiable writing outcome metrics (e.g., scores, rubric-based gains, pre-post tests).""}}"
To Resist It or to Embrace It? Examining Chatgpt's Potential to Support Teacher Feedback in Efl Writing,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study uses 50 English argumentative essays composed by Chinese undergraduate students in an EFL context, clearly involving L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is exploratory and examines ChatGPT\u2019s potential to support teacher feedback by comparing ChatGPT- and teacher-generated feedback and surveying teacher perceptions. There is no described experimental or quasi-experimental pedagogical intervention where learners use ChatGPT within a structured writing instruction or process.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on evaluating ChatGPT\u2019s feedback characteristics and teachers\u2019 perceptions, not on an implemented writing intervention. It does not describe an instructional context where ChatGPT is integrated into teaching to improve writing competence; rather, it analyzes feedback quantity/type and attitudes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable learner writing outcome metrics (e.g., pre/post writing scores, quality ratings) are reported. The study compares feedback features and gathers teacher perceptions, but does not measure changes in students\u2019 writing performance resulting from an LLM-mediated intervention.""}}"
"Automated Writing Evaluation Systems: a Systematic Review of Grammarly, Pigai, and Criterion with a Perspective on Future Directions in the Age of Generative Artificial Intelligence",2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The article is a systematic review of studies on Grammarly, Pigai, and Criterion. While many included primary studies involve non-native English-speaking students, this paper itself is not an empirical study with a defined participant population; it is a secondary review article, which falls under the exclusion criteria.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The focus is on automated writing evaluation systems (Grammarly, Pigai, Criterion), which are not described as large language model-based generative tools. Moreover, the article is a review, not an experimental or quasi-experimental intervention study integrating LLMs into writing instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the context is writing and AWE systems, the paper is a systematic review of existing tools and studies, not a primary pedagogical intervention study. The review nature places it outside the scope of the targeted intervention-focused systematic review.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The article synthesizes findings from 39 studies but does not itself report original, quantifiable writing outcome metrics from an LLM-mediated intervention. As a review article, it is excluded by the protocol.""}}"
Adopting Chatgpt as a Writing Buddy in the Advanced L2 Writing Class,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are advanced L2 writers of German producing summaries in L2 German. The focus is on German as the target language, not English (ESL/EFL/ELL), so the population does not meet the review\u2019s requirement of L2 English learners.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study integrates ChatGPT-3.5 (an LLM) into a classroom-based writing intervention. Students compare their drafts with ChatGPT-produced texts and then revise their own writing, which constitutes an LLM-mediated writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is explicitly the L2 writing and revision process. ChatGPT is used as a writing buddy/model to support revision, and the study examines how this affects students\u2019 revision behavior and writing processes, not automated scoring.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions rubric-based ratings of ChatGPT models and coded revision processes (focus, source, success), and notes that students improved their texts. However, it does not clearly state that quantifiable writing outcome metrics (e.g., pre/post writing quality scores) for students\u2019 own writing were reported, so it is unclear if formal writing outcome measures are included.""}}"
“chatgpt Seems Too Good to Be True”: College Students’ Use and Perceptions of Generative Ai,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are U.S. college students in general; while some are non-native English speakers, the study is not situated in an ESL/EFL/ELL instructional context nor focused specifically on L2 English learners as the target population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is examined as a tool students choose to use, but there is no experimental or quasi-experimental instructional intervention integrating LLMs into writing instruction or structured writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on perceptions and patterns of ChatGPT use across general, writing, and programming tasks, not on a pedagogical writing intervention or systematic development of writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics or pre/post measures of writing performance are reported; the study centers on usage frequency, demographics, and attitudes.""}}"
Identifying Chatgpt-generated Texts in Efl Students’ Writing: through Comparative Analysis of Linguistic Fingerprints,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Japanese EFL learners (140 first-year university students), clearly fitting an L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is present but not as a structured instructional intervention. The study focuses on distinguishability of human vs. ChatGPT-generated texts and students\u2019 incidental use (proofreading or full generation), not on an experimental or quasi-experimental LLM-based writing pedagogy or designed writing support process.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on detecting ChatGPT-generated texts via linguistic fingerprints and machine learning classification, not on improving writing competence or evaluating a pedagogical writing intervention. It is essentially a detection/forensics study, not a writing instruction study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality gains, accuracy, complexity) are reported to assess the effectiveness of an LLM-mediated intervention. Outcomes concern distinguishability and classification performance, not changes in learners\u2019 writing performance.""}}"
Using Chatgpt for Second Language Writing: Experiences and Perceptions of Efl Learners in Thailand and Vietnam,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as Thai and Vietnamese EFL learners using ChatGPT for second language (L2) writing, clearly indicating L2 English learners in EFL contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the study concerns ChatGPT use, it is an exploratory survey/interview study of learners\u2019 experiences and perceptions. There is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction or processes; rather, it documents existing practices and attitudes.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on using ChatGPT for L2 writing (brainstorming, organizing ideas, refining outlines, editing drafts), which is directly related to writing competence and writing-related practices.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are perceptions and experiences (e.g., perceived usefulness, engagement, differences in perceptions between Thai and Vietnamese learners). The abstract does not mention any quantifiable writing performance metrics or measured changes in writing quality resulting from ChatGPT use.""}}"
Evaluating the Role of Chatgpt in Enhancing Efl Writing Assessments in Classroom Settings: a Preliminary Investigation,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL learners: 30 CET-4 essays written by non-English majors at a university in Beijing, China. The context is clearly English-as-a-foreign-language writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT 3.5 and 4 are used as raters to assign holistic scores and provide feedback on existing essays. There is no experimental or quasi-experimental instructional intervention integrating LLMs into the writing process; the focus is on assessment reliability and feedback relevance, not on a teaching/learning intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on writing assessment\u2014reliability of holistic scores and relevance of feedback\u2014rather than on improving learners\u2019 writing competence through a pedagogical intervention. It functions as an evaluation of LLMs as automated raters/feedback providers, not as a structured instructional context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable learner writing outcome measures (e.g., pre/post writing quality, accuracy, complexity) are reported. Outcomes concern reliability coefficients of ChatGPT vs. teachers and relevance of feedback, not changes in students\u2019 writing performance following an LLM-mediated intervention.""}}"
The Grass Is Not Always Greener: Teacher Vs. Gpt-assisted Written Corrective Feedback,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to student writing and L2 writing practice but does not specify that participants are L2 English learners or that the target language is English. The learner population and language are not explicitly identified.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study compares written corrective feedback (WCF) produced by teachers and ChatGPT, focusing on their characteristics. There is no indication of an experimental or quasi-experimental pedagogical intervention where LLMs are integrated into instruction or writing processes; rather, it is an analytic comparison of feedback types.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the topic is WCF in L2 writing, the primary focus is on describing and contrasting teacher vs. ChatGPT feedback practices, not on an instructional intervention aimed at improving writing competence. It does not describe an implemented teaching/learning context using LLMs with learners.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports qualitative findings about the nature, accuracy, and variability of teacher vs. ChatGPT WCF. It does not mention any quantitative writing outcome measures (e.g., pre/post writing scores, error rates, rubric-based gains) assessing the effectiveness of LLM-mediated intervention.""}}"
"Brave New World or Not?: a Mixed-methods Study of the Relationship between Second Language Writing Learners' Perceptions of Chatgpt, Behaviors of Using Chatgpt, and Writing Proficiency",2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as 'second or foreign language (L2) writing learners' at university level, and the outcomes are L2 writing proficiency measures (complexity, accuracy, fluency), which in this context strongly implies L2 English learners in an ESL/EFL setting.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines learners\u2019 perceptions of ChatGPT and their self-reported usage behaviors. There is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction; rather, it is a correlational/mixed-methods study of existing usage.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on L2 writing proficiency (complexity, accuracy, fluency) and how these relate to ChatGPT usage, clearly centering on writing competence rather than automated scoring or system evaluation.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although the study reports quantitative writing proficiency measures, these are not outcomes of a structured LLM-mediated writing intervention. The design does not manipulate or implement ChatGPT as an instructional treatment; it only examines associations between existing usage and proficiency, which falls outside the required intervention-outcome framework.""}}"
Using Generative Ai to Provide High-quality Lexicographic Assistance to Chinese Learners of English,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study explicitly targets \u201cChinese learners of English,\u201d which fits the L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The paper explores how generative AI (ChatGPT, Ernie Bot) can be used to produce explanations and argues for their integration into writing assistants, but it does not describe an experimental or quasi-experimental pedagogical intervention where LLMs are actually integrated into learners\u2019 writing instruction or processes.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The focus is on lexicographic assistance and error explanations (subject-verb disagreement) for potential use in writing assistants. While related to writing, the abstract centers on tool development and comparison of chatbots, not on an implemented writing intervention or measured writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported. The study discusses identification of error subcategories and the quality of AI-generated explanations, but does not measure changes in learners\u2019 writing performance or related variables.""}}"
Instructors' and Learners' Perspectives on Using Chatgpt in English as a Foreign Language Courses and Its Effect on Academic Integrity,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are university learners of English as a foreign language (EFL), which fits the target population of L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) was used and integrated into teaching for one trimester, the study focuses on perspectives and academic integrity rather than an experimental or quasi-experimental evaluation of a structured LLM-based writing intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on attitudes toward ChatGPT use in EFL learning and its implications for academic integrity. While written work is mentioned, the study does not center on writing competence or writing-related instructional interventions as the main outcome.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses questionnaires, open-ended responses, and interviews to gather opinions and attitudes. It does not report quantifiable writing outcome metrics (e.g., writing scores, quality measures) to assess the effectiveness of ChatGPT-mediated writing interventions.""}}"
A Case Study of Implementing Generative Ai in University's General English Courses,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as English as a foreign language (EFL) learners in Korean university-level general English courses, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract states that learners were exposed to a \""generative AI-based instruction model\"" but does not specify whether this is an LLM (e.g., ChatGPT/GPT-4) or another type of generative AI. However, it is at least plausible that LLMs are involved.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The abstract notes that the AI-based instruction is for \""writing and speaking\"" and mentions supporting linguistic proficiency, but the primary stated research focus is on affective factors (motivation, interest, confidence). It is not clear that writing competence or writing-related variables are the primary focus of the study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is described as investigating effects on affective factors (motivation, interest, confidence). There is no indication that quantifiable writing outcome metrics (e.g., writing scores, text quality measures) were collected or reported; writing is only mentioned generally as a skill area, not as an assessed outcome.""}}"
Investigating Students' Uptake of Teacher- and Chatgpt-generated Feedback in Efl Writing: a Comparison Study,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as EFL students: \u201cTwenty Chinese undergraduate students participated in the study\u2026 in the context of argumentative writing.\u201d This fits L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used to generate feedback, the design is not an experimental or quasi-experimental intervention assessing the effectiveness of an LLM-mediated writing instruction. It is a comparison of uptake of teacher vs. ChatGPT feedback without a structured pedagogical intervention aimed at testing LLM-based instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on EFL writing: students compose argumentative essays, receive feedback, and revise. The study examines engagement with feedback and revision quality, which are writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are engagement with feedback and appropriateness/accuracy of revisions, not quantifiable writing competence measures (e.g., holistic/analytic writing scores, complexity/accuracy/fluency metrics) used to assess the effectiveness of an LLM-mediated intervention. The study is primarily about feedback uptake and perceptions rather than experimental writing outcome metrics.""}}"
Uncovering Students' Processing Tactics towards Chatgpt's Feedback in Efl Education Using Learning Analytics,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as EFL students (\u201cpotential use in English as a Foreign Language (EFL) education\u201d), indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study examines students\u2019 interaction with ChatGPT, a generative AI chatbot based on LLMs, during reading and writing tasks. It analyzes their processing tactics toward ChatGPT\u2019s feedback, implying an LLM-mediated learning activity, though the design is observational/analytic rather than a controlled intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although reading and writing tasks are mentioned, the primary focus is on processing tactics toward ChatGPT\u2019s feedback and learning modes, with outcomes framed as \u2018improvement of domain knowledge\u2019 rather than writing competence or writing-related variables. Writing development is not the central measured construct.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Quantitative outcomes reported concern \u2018differences in learning gains\u2026 specifically in the improvement of domain knowledge.\u2019 There is no indication of quantifiable writing outcome metrics (e.g., writing quality scores, accuracy, complexity) to assess effectiveness of LLM-mediated writing intervention.""}}"
