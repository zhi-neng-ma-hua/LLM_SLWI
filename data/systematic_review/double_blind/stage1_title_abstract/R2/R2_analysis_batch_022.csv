Title,Year,Decision,Notes
Integrating Automated Writing Evaluation into Saudi Efl Students’ Writing Practice,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 154 Arabic-speaking undergraduate EFL students at a Saudi university, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses generic 'AWE systems' (Automated Writing Evaluation). There is no indication these are LLM-based tools such as ChatGPT/GPT-4 or other transformer-based generative models; AWE typically refers to scoring/feedback systems like e-rater or Criterion, which are not LLM interventions as defined in the review.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on integrating AWE into EFL writing practice and its effects on writing skills, critical thinking, autonomy, and motivation to write in English\u2014clearly a writing-focused pedagogical context.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions collecting 'samples of EFL writing assignments before and after utilising the AWE system' and claims effectiveness in enhancing lower-level writing skills, but it does not explicitly state that quantifiable writing outcome metrics were analyzed; emphasis is on experiences, evaluations, challenges, satisfaction.""}}"
The Impact of Ai-generated Feedback Explicitness (generic Vs. Specific) on Efl Students' Use of Automated Written Corrective Feedback,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL university students in Saudi Arabia (Arab schools and universities), clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is described as AI-driven Automated Written Corrective Feedback and Automated Essay Scoring systems/AWE systems. There is no indication that these tools are LLM-based (e.g., ChatGPT, GPT-4); they are framed as generic AWE/AES systems, which are typically not transformer-based generative models.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on EFL writing, corrective feedback, and writing proficiency in L2 writing instruction, which aligns with writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although the main research question mentions writing proficiency, the abstract reports only perceptions (ease of use, clarity, usefulness, preferences for specific vs. generic feedback). The analysis centers on perceptions via questionnaires and factor analysis; no explicit quantifiable writing outcome measures (e.g., changes in writing scores, accuracy) are reported.""}}"
Saudi Efl Learners’ Perceptions of Using Artificial Intelligence and Its Impact on Their Writing Skills,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are female Saudi learners of English as a Foreign Language at the University of Jeddah, clearly an EFL context with English as the target language.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT and other AI tools are mentioned, the abstract frames the study as examining learners\u2019 perceptions and experiences, not as an experimental or quasi-experimental intervention integrating LLMs into instruction. No controlled or structured LLM-based instructional treatment is described.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The focus is broadly on writing skills and writing development, but the study centers on perceptions and experiences rather than a defined pedagogical writing intervention. It is not clear that there is a specific instructional design around writing competence being tested.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports attitudes, perceived benefits, and drawbacks, but does not mention any quantifiable writing outcome measures (e.g., pre/post writing scores, rubric-based assessments). The impact on writing competency is discussed in terms of perceptions, not measured outcomes.""}}"
Evaluating the Quality of Ai Feedback: a Comparative Study of Ai and Human Essay Grading,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL students: \u201c30 essays written by English as a foreign language (EFL) students,\u201d so the population is L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""AI tools are used as essay graders/feedback providers and compared to human evaluators. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction or writing processes; the focus is on evaluation quality.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on the quality and comparability of AI vs. human essay grading and feedback, not on improving writing competence through an instructional intervention. This aligns with automated essay scoring research rather than a writing intervention context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study does not report changes in learners\u2019 writing performance or other outcome measures following an AI-mediated intervention. It only analyzes AI vs. human scoring and feedback on existing essays, with no pre/post or comparative learning outcomes.""}}"
The Integration of Chatgpt in English for Foreign Language Course: Elevating Ai Writing Assistant Acceptance,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 95 English as a Foreign Language (EFL) students in Indonesia, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study integrates ChatGPT, an LLM, into students\u2019 writing process over a four-week assignment, constituting an LLM-based writing aid intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on technology acceptance (perceived ease of use, usefulness, attitude toward change, behavioral intention) using the Technology Acceptance Model, not on writing competence or writing-related performance variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, quality measures, accuracy, complexity) are reported. Outcomes are limited to acceptance and behavioral intention constructs, not writing performance.""}}"
Investigating Students’ Uptake of Teacher- and Chatgpt-generated Feedback in Efl Writing: a Comparison Study,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are twenty Chinese undergraduate EFL students writing argumentative essays in English, clearly fitting an EFL/ESL L2 English learner population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is used as a feedback provider, but the design is a comparison of teacher- vs ChatGPT-generated feedback uptake, not an experimental or quasi-experimental LLM-mediated instructional intervention aimed at improving writing performance (e.g., no pre/post or controlled treatment vs control conditions).""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on EFL argumentative writing, specifically on how students use feedback from teachers and ChatGPT in revising their essays, which is directly related to writing competence and writing processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are engagement with feedback, appropriateness of revisions, and questionnaire-based perceptions and preferences. There is no indication of quantifiable writing outcome metrics (e.g., overall writing quality scores, rubric-based gains) assessing the effectiveness of an LLM-mediated intervention over time.""}}"
"Beyond Policing: Ai Writing Detection Tools, Trust, Academic Integrity, and Their Implications for College Writing",2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions bias against non-native English speakers and focuses on college writing, but it does not specify that the participants are L2 English learners in ESL/EFL/ELL contexts, nor that data are specifically about L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The article discusses AI writing detection tools, trust, and academic integrity, and argues for collaborative AI integration in writing. However, it does not describe an experimental or quasi-experimental study using a specific LLM (e.g., ChatGPT, GPT-4) as an instructional intervention; it appears to be conceptual/perspective-based.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""While the context is college writing and AI, the focus is on detection tools, institutional guidelines, and academic integrity rather than a concrete pedagogical intervention targeting writing competence or writing-related variables using LLMs.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics or experimental results are reported. The abstract discusses implications, frameworks, and recommendations, but not measured changes in writing performance following an LLM-mediated intervention.""}}"
Unpacking the Rejection of L2 Students Toward Chatgpt-generated Feedback: an Explanatory Research,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are L2 learners (L2 students in a university Computer Science program) working on an argumentative writing report in an AI-assisted educational environment, indicating an L2 English writing context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study involves students being encouraged to seek corrective feedback from ChatGPT, a large language model, on their argumentative writing report. This constitutes an LLM-based writing-related intervention, even though it is not strictly experimental in the sense of comparing conditions.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on learners\u2019 challenges and rejection of ChatGPT-generated feedback (technology acceptance and use), not on improving writing competence or systematically evaluating writing performance. Outcomes center on feedback acceptance/rejection and reasons, rather than writing development.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although the study reports quantitative data (e.g., 45.9% of AI-generated feedback rejected), it does not report quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity). The measures relate to feedback uptake and perceptions, not to writing performance gains.""}}"
Collaborative Writing Based on Generative Ai Models: Revision and Deliberation Processes in German as a Foreign Language,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The population consists of learners of German as a foreign language. The title and abstract explicitly state the context is German as a Foreign Language, not English (ESL/EFL/ELL). Therefore, it does not meet the requirement that the target language be English.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study integrates generative AI models (e.g., ChatGPT) into a classroom-based collaborative writing intervention, where students compare their own writing with GenAI models. This constitutes an LLM-based writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on L2 writing and revision processes in collaborative writing, including how GenAI influences revision and deliberation, clearly centering on writing competence and writing-related variables rather than automated scoring.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports changes in text quality and evaluates texts for functional adequacy, which are quantifiable writing outcome metrics linked to the GenAI-mediated intervention.""}}"
Exploring Chatgpt as a Tool for Thesis Writing: Perspectives of Efl Supervisors in Jordanian Universities,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The participants are 47 Jordanian EFL supervisors, not L2 English learners. The study reports supervisors\u2019 perceptions of ChatGPT\u2019s use in students\u2019 thesis writing, but the data are not collected from learners themselves, nor are learner outcomes directly measured.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is the focal tool, the study is not an experimental or quasi-experimental intervention integrating ChatGPT into writing instruction. It is a perception study using a questionnaire to gauge supervisors\u2019 views, without a structured LLM-mediated instructional treatment.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The context is thesis writing in EFL, which is writing-focused, but the study centers on supervisors\u2019 opinions about ChatGPT\u2019s usefulness rather than on an implemented pedagogical intervention or writing process design. The abstract does not describe an actual instructional context where ChatGPT is systematically integrated.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study quantifies supervisors\u2019 perceptions (Likert-scale responses) about ChatGPT\u2019s effects, not students\u2019 writing performance. No quantifiable learner writing outcome metrics (e.g., scores, text quality measures, revisions) are reported to assess the effectiveness of an LLM-mediated writing intervention.""}}"
More Human Than Human? Differences in Lexis and Collocation within Academic Essays Produced by Chatgpt-3.5 and Human L2 Writers,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study explicitly involves human L2 writers producing academic essays, indicating a population of second language learners writing in English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT-3.5 is used to generate essays, there is no experimental or quasi-experimental pedagogical intervention integrating the LLM into L2 writing instruction or learners\u2019 writing processes. The design is a comparative corpus analysis of AI vs. human texts, not an instructional intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on linguistic differences (lexis and collocation) between AI-generated and human L2 essays and implications for academic integrity and AI detection, rather than on improving writing competence through an instructional context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study does not report quantifiable writing outcome measures assessing the effectiveness of an LLM-mediated writing intervention. It analyzes textual features but does not evaluate changes in learners\u2019 writing performance following LLM use.""}}"
Chatgpt and L2 Chinese Writing: Evaluating the Impact of Model Version and Prompt Language on Automated Corrective Feedback,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are not L2 English learners; the focus is on L2 Chinese writing. The dataset consists of erroneous Chinese sentences from a textbook, and the study explicitly addresses the need for Chinese grammar checking and L2 Chinese writing, not English.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses ChatGPT-3.5 and ChatGPT-4.0 (LLMs) to generate automated corrective feedback for L2 Chinese writing, comparing model versions and prompt languages. This is an LLM-based intervention in writing-related tasks, albeit not with human learners directly involved.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is writing-focused: automated corrective feedback for L2 Chinese writing, with evaluation of grammaticality, fluency, and feedback quality. The primary concern is writing error correction, not general language skills or pure system evaluation unrelated to writing.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable outcome metrics such as grammaticality, fluency, minimal alterations, over-correction, correctness, understandability, and detail of feedback, rated by teachers. These are measurable outcomes of the LLM-generated corrective feedback.""}}"
Using an Ai-powered Chatbot for Improving L2 Korean Grammar: a Comparison between Proficiency Levels and Task Types,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are L2 Korean learners, not L2 English learners. The abstract explicitly states the study is about using an AI chatbot (Iruda) in L2 Korean teaching to improve Korean lexico-grammar, and it is framed as work on a less commonly taught language, not English.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The tool is described as an AI-powered chatbot (Iruda), but the abstract does not specify whether it is based on a large language model or transformer-based generative model. It could be rule-based or another AI architecture; this cannot be determined from the abstract alone.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on improving Korean lexico-grammar and grammar test performance (selected-response and constructed-response tasks), not on writing competence in English. While constructed-response tasks include sentence composition, the context is grammar instruction in Korean, not L2 English writing intervention.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The study reports quantifiable outcomes (item mean differences on grammar test items) and uses t-tests, regression, and ANOVAs. However, these outcomes relate to Korean grammar performance, not English writing outcomes, so they do not meet the review\u2019s required focus on L2 English writing metrics.""}}"
Interacting with Chatgpt in Essay Writing: a Study of L2 Learners’ Task Motivation,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are L2 learners writing English argumentative essays at a public university in a non-English-speaking country, which fits an EFL/ESL/ELL context focused on English.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study involves interacting with ChatGPT 4.0 (an LLM) as part of an experimental design to support L2 essay writing, which qualifies as an LLM-based writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is explicitly L2 English essay (argumentative) writing, and ChatGPT is used as a tutor/support tool in the writing process, aligning with a focus on writing competence and related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract states the study explored effects on learners\u2019 motivation and reports positive lasting effects on motivation, with no mention of quantitative writing performance or other objective writing outcome measures. The primary measured outcome is task motivation, not writing quality or competence.""}}"
Empowering Dialogic Feedback in Flw with Llm,2025,unsure,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers broadly to foreign/second language (L2) writing and L2 learners but does not specify that the target language is English or that the context is ESL/EFL/ELL. The population could involve any L2, so it is unclear whether it fits the English-focused inclusion criterion.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study explicitly proposes leveraging large-language models (LLMs) to facilitate dialogic feedback in L2 writing, including creating an AI-writing tool and testing its effectiveness through experimental sessions. This indicates an LLM-based intervention with an experimental component.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on L2 writing instruction and feedback, aiming to enhance editing, rewriting, and overall writing development. The intervention is pedagogical, centered on feedback practices in writing, not on automated scoring or non-instructional evaluation.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract states that the study will test the effectiveness of the AI-writing tool and understand its impact on L2 learners' writing progress, as well as perceptions and interaction patterns. However, it does not explicitly state that quantifiable writing outcome metrics will be reported, leaving uncertainty about whether measurable writing gains are assessed.""}}"
Exploring Efl Students’ Prompt Engineering in Human–ai Story Writing: an Activity Theory Perspective,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as 'English as a foreign language (EFL) students' who are Hong Kong secondary school students, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""Students 'created their own generative-AI tools using open-source language models and wrote short stories with them.' These are generative LLM-based tools integrated into the writing process, satisfying the LLM intervention criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is 'short story writing' and the study focuses on how students prompt generative AI during story writing, which is directly related to writing processes and competence rather than automated scoring.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports thematic findings about purposes for prompting and characteristics of activity systems (e.g., sophistication of tools, quality of stories, school achievement level) but does not indicate any experimental or quasi-experimental design, control/comparison, or quantifiable writing outcome metrics assessing effectiveness of the LLM-mediated intervention. It appears exploratory/qualitative rather than an outcome-focused intervention study.""}}"
Ai-assisted Feedback in Clil Courses as a Self-regulated Language Learning Mechanism: Students’ Perceptions and Experiences; Retroalimentación Asistida Por Ia En Cursos Clil Como Mecanismo De Aprendizaje Autorregulado De Idiomas: Percepciones Y Experiencias De Estudiantes,2025,unsure,"{""c1"": {""status"": ""unclear"", ""evidence"": ""Participants are university students in a business CLIL (Content and Language Integrated Learning) course, which strongly suggests they are L2 learners, but the abstract does not explicitly state that they are L2 English learners or that English is the target language. The title and abstract are bilingual (English/Spanish), adding ambiguity about the target language.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses ChatGPT, explicitly named, as an AI tool to provide criteria-based feedback on weekly writing compositions in a 15-week course. This is an instructional intervention integrating an LLM into the writing process.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is a Data Description writing course where students write weekly compositions and receive AI-assisted feedback on writing (content clarity, grammar, vocabulary). The primary focus is on improving writing skills and linguistic proficiency, not on automated scoring or system evaluation alone.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study analyzes a coded sample of 336 compositions to evaluate linguistic enhancement and reports \u2018significant improvement in content accuracy and linguistic proficiency,\u2019 indicating quantifiable writing outcome measures beyond perceptions.""}}"
Empowering Efl Learners: Assessing the Ai Brainstorming Tools' Impact on Essay Writing Proficiency,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are thirty Saudi EFL learners enrolled in English departments, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses an AI brainstorming tool (AYOA). The abstract does not indicate that AYOA is a large language model or transformer-based generative model (e.g., ChatGPT, GPT-4). It appears to be a general AI/brainstorming tool rather than an LLM-based writing assistant, so it does not meet the LLM-specific intervention criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on essay writing proficiency: learners brainstorm ideas (with or without AI) and then write essays based on those ideas. The primary outcome is writing performance, fitting the writing competence context.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses an experimental design with control and experimental groups and reports that the experimental group showed better performance in essay writing, indicating quantifiable writing outcome metrics were used.""}}"
Efl Teachers and Feedback Fatigue: Ai to the Rescue?,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses L2 writing and feedback in general but does not specify the learner population, target language (English), or context (ESL/EFL/ELL). It appears to be a conceptual or discussion paper rather than an empirical study with a defined participant group.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The paper \""looks at the contribution of Automated Writing Evaluation (AWE) programmes and Generative Artificial Intelligence (GenAI) to feedback\"" in a general, discursive way. There is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT, GPT-4) into instruction; it appears to be a conceptual or reflective piece.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the focus is on feedback in L2 writing, the article is framed as a discussion of potential benefits, teacher roles, and claims about automation, not as a pedagogical intervention study with implemented LLM-based writing activities.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or empirical evaluation. It raises questions about whether AI can improve writers and not just texts, but does not report data or structured intervention outcomes.""}}"
Cognitive Load Scale for Ai-assisted L2 Writing: Scale Development and Validation,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers broadly to 'L2 writing' and 'second language (L2) composition' but does not specify that participants are L2 English learners (ESL/EFL/ELL) or that the target language is English. The specific language context is not stated.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study focuses on developing and validating the Cognitive Load Scale for AI-assisted L2 Writing. It does not describe an experimental or quasi-experimental pedagogical intervention integrating a specific LLM (e.g., ChatGPT, GPT-4) into instruction; rather, it is a measurement instrument development study about cognitive load in human-AI collaborative writing.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the context is AI-assisted L2 writing, the primary focus is on cognitive load measurement and scale validation, not on improving writing competence or writing-related performance through an instructional intervention. The study advances theory and measurement, not a writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported are psychometric properties of the scale (factor structure, internal consistency, criterion-related validity via correlations with anxiety, self-efficacy, and mental effort). No quantifiable writing performance outcomes (e.g., writing quality scores, accuracy, complexity) are reported to assess effectiveness of an LLM-mediated writing intervention.""}}"
