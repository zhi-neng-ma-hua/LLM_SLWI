Title,Year,Decision,Notes
Non-academic Learner Socialisation with Chatgpt and Its Influences on Learning English Argumentative Writing Logic,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as 40 EFL university students learning English argumentative writing. The context is clearly English as a foreign language, with outcomes tied to English argumentative writing logic.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study developed a GPT-4-powered bot (an LLM-based tool) for learning English argumentative writing logic. Learners used it in a structured session (45\u201375 minutes), indicating an experimental instructional intervention integrating an LLM into the writing learning process.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on English argumentative writing, specifically on learning outcomes such as logical knowledge and logical quality in English argumentative writing. The LLM is used pedagogically, not merely for automated scoring or system evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports pre\u2013post tests, writing tasks, and questionnaires to assess learning outcomes, including logical knowledge, logical quality, and self-efficacy in English argumentative writing. These constitute quantifiable writing-related outcome measures within an intervention framework.""}}"
Genai-assisted Critical Reading Report Revision: a Mixed-methods Study,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""Participants are described only as 22 postgraduate students and L2 learners engaged in critical reading and writing. The abstract does not explicitly state that they are L2 English learners in ESL/EFL/ELL contexts or that the target language is English, though it is likely. This cannot be confirmed from the abstract alone.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses \u201cGenAI tools\u201d and mentions \u201cinteractions with the chatbot\u201d and \u201cGenAI-generated critical reading reports,\u201d which suggests but does not explicitly confirm the use of LLM-based tools (e.g., ChatGPT). The specific technology (LLM vs. other AI) is not identified in the abstract.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on critical reading and writing dimensions and student engagement patterns during revision, not on writing competence as an outcome. The study examines which dimensions receive engagement and the factors influencing selective engagement, emphasizing critical thinking and agency rather than a pedagogical writing intervention aimed at improving writing performance.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports engagement patterns across dimensions (e.g., research aims, contributions, quality of evidence) using lag sequential and thematic analysis, but does not indicate any quantifiable writing outcome metrics (e.g., writing scores, quality ratings, accuracy, complexity) to assess effectiveness of the GenAI-supported revision. It focuses on process/engagement, not measured writing gains.""}}"
"Ai-generated, L2 Learner, and Native German Writing: a Comparative Analysis of Linguistic Complexity",2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The study focuses on German argumentative essays and compares texts by ChatGPT, DeepSeek, L1 speakers, and L2 learners of German. The target language is German, not English, so it does not meet the population/language focus requirement on L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the study analyzes texts generated by LLMs (ChatGPT, DeepSeek), there is no indication of an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or learner writing processes. It is a comparative linguistic analysis, not an instructional intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on linguistic complexity and formality of AI-generated vs. human-authored German essays. While pedagogical implications are discussed, there is no actual writing instruction context or intervention being implemented or evaluated.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study does not report quantifiable writing outcome measures for learners following an LLM-mediated intervention. It compares linguistic features of existing texts rather than assessing changes in learner writing performance due to an LLM-based instructional treatment.""}}"
Experiences of Esl Students and Instructors Using Grammarly in Academic Writing,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are English as a second language (ESL) graduate students at a Malaysian public university, clearly fitting an L2 English learner population in an ESL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention tool is Grammarly, described as an AI writing assistant. Grammarly is not an LLM-based, transformer generative model like ChatGPT or GPT-4; it is a separate class of AI tool and is explicitly listed in the exclusion examples. Therefore, it does not meet the LLM-based intervention requirement.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on academic writing, formative assessment, and feedback for ESL students\u2019 writing, which aligns with writing competence and writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Data were collected through semi-structured interviews and focus groups, and the abstract reports perceived improvements (motivation, engagement, proficiency) but does not indicate any experimental or quasi-experimental design with quantifiable writing outcome metrics. The outcomes are qualitative perceptions rather than measured writing performance.""}}"
Tracking the Effects of Gemini as a Genai Tool on L2 Learners’ Writing Proficiency and Anxiety: Latent Growth Curve Modeling Approach,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were 274 undergraduate English learners in Iran enrolled in academic writing classes. The context is clearly L2 English (EFL) learners, and the focus is on English writing proficiency and anxiety.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention is GenAI-assisted instruction using Gemini, a large language model, compared to traditional instruction. Learners in the treatment group received Gemini-mediated support during a 16-week course, indicating an experimental design integrating an LLM into instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on L2 writing competence and writing-related affective variables (writing proficiency and writing anxiety) within academic writing classes. Gemini is used pedagogically to provide tailored, immediate feedback in writing instruction, not merely for automated scoring.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcomes: writing proficiency measured via a standardized rubric-based assessment and writing anxiety via an L2 writing anxiety scale. Results include specific statistics (MD, SE, CR, p-values), demonstrating measured intervention effects.""}}"
"Comparing the Effects of Teacher- and Ai-mediated Corrective Feedback on Accuracy, Complexity, and Quality in L2 Written Narratives",2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were 166 upper-intermediate ESL undergraduates in international writing classes at a U.S. university. The context is clearly L2 English (ESL).""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract states that 86 students received 'AI-mediated WCF' and refers to 'generative artificial intelligence (AI)', but it does not specify whether the AI system is a large language model (e.g., ChatGPT/GPT-4 or another transformer-based generative model) versus another type of AI feedback tool. Without the tool being named or its architecture described, it is unclear if an LLM is used.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on written corrective feedback in L2 narrative writing and examines effects on complexity, accuracy, and quality of L2 written narratives. This is clearly a writing-focused pedagogical intervention, not just automated scoring.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcomes: changes in accuracy (error reduction), lexical and syntactic complexity (e.g., T-unit length, subordination, coordination, nominalization), and writing quality (conventions and overall scores) between pre- and post-revision drafts across teacher vs. AI feedback groups.""}}"
"Artificial Intelligence in Language Education: a Systematic Review of Multilingual Applications, Large Language Models, and Emerging Challenges",2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The article is a broad systematic review of AI in language education across multilingual settings. It does not focus specifically on L2 English learners in ESL/EFL/ELL contexts; instead, it covers multiple languages, including low-resourced and marginal languages in general.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""This is a review article synthesizing 161 studies and discussing various AI tools (conversational agents, speech recognition, writing assistants, LLMs like Aya and LLaMA). It does not itself implement an experimental or quasi-experimental LLM-based writing intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is broad AI use in language education (anxiety reduction, pronunciation support, real-time feedback, mobile learning, gamification, ethics, infrastructure). Writing is only one of several skills mentioned and not the central focus of the review.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a systematic review, it does not report original experimental writing outcome metrics from an LLM-mediated intervention; instead, it summarizes prior work and discusses gaps and implications at a high level.""}}"
Efl Teachers’ Inquisitive Agency in Ai-enhanced Writing Instruction,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The participants are twelve Indonesian EFL teachers. The abstract does not specify that data are collected from L2 English learners or that learner outcomes are analyzed; the focus is on teachers\u2019 practices, not learners as participants.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the study concerns integration of AI tools in EFL writing instruction, it does not specify that these are large language models (e.g., ChatGPT, GPT-4). It focuses on teachers\u2019 agency in exploring and adapting unspecified AI technologies, with no clear indication of LLM-based intervention or experimental/quasi-experimental design.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on teacher inquisitive agency, resource exploration, and professional development in AI-enhanced writing instruction, not on learners\u2019 writing competence or writing-related variables as outcome measures. It is a pedagogical/teacher practice study rather than a writing competence intervention study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses qualitative methods and reports thematic categories about teacher practices. There is no mention of quantifiable writing outcome metrics or experimental measures of students\u2019 writing performance resulting from AI/LLM-mediated interventions.""}}"
Evaluating the Performance of Chatgpt and Claude in Automated Writing Scoring: Insights from the Many-facet Rasch Model,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 117 English as a Foreign Language (EFL) students in China, clearly an L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT and Claude are used as automated writing scorers (LLM-based raters). There is no indication of an instructional or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or writing processes; the focus is on scoring performance.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is automated writing scoring (AWS) and comparison of LLM raters with human raters using Many-Facet Rasch Model. It evaluates rater severity, consistency, and bias, not writing competence or writing-related learning outcomes, and there is no pedagogical intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports metrics on scoring behavior (severity, consensus, consistency, gender bias) of LLMs versus human raters. It does not report quantifiable writing outcome measures assessing the effectiveness of an LLM-mediated writing intervention on learners\u2019 writing performance.""}}"
Genai Image Creation in Efl: Prompt Writing as an Emerging Writing Activity for Sustainability-focused Artivism,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 21 preparatory-year students in an EFL setting at a university in Northern Cyprus, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses GenAI image generation with English prompt writing, but the abstract does not specify that the GenAI system is a large language model (e.g., ChatGPT, GPT-4). It focuses on AI image generation, not an LLM-based writing assistant or transformer-based generative text model.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is sustainability awareness and artivism via image creation; writing is limited to prompt writing and descriptive texts as language practice. The study emphasizes qualitative experiences, confidence, and sustainability awareness rather than systematic development of writing competence as the main outcome.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is described as a qualitative descriptive study with thematic analysis. Reported outcomes include perceived gains in writing confidence and strategy use, but there is no mention of quantifiable writing outcome metrics (e.g., pre/post writing scores, rubric-based assessments).""}}"
"Lexical Diversity, Syntactic Complexity, and Readability: a Corpus-based Analysis of Chatgpt and L2 Student Essays",2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions a corpus of 50 student essays and notes implications for L2 learners, but it does not explicitly state that the 50 student essays are written by L2 English learners in ESL/EFL/ELL contexts. The learner population is therefore not clearly defined as L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study compares AI-generated texts via ChatGPT with student-written essays using corpus-based measures. There is no indication of an experimental or quasi-experimental pedagogical intervention where LLMs are integrated into writing instruction or writing processes; ChatGPT is only a source of comparison texts.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on textual features (lexical diversity, syntactic complexity, readability) of ChatGPT vs. student essays, not on an instructional context or intervention aimed at improving writing competence. It is an analytic comparison, not a pedagogical study of writing development.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although quantitative measures (TTR, MLT, readability indices) are reported, they are used to compare ChatGPT output and student essays, not to evaluate the effectiveness of an LLM-mediated writing intervention on learners\u2019 writing outcomes over time or across conditions.""}}"
Factors Affecting Efl Students’ Behavioral Intention to Use Ai in Efl Writing Development,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 415 Chinese university students using AI for English as a Foreign Language (EFL) writing development, clearly an L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses a cross-sectional survey to investigate behavioral intention to adopt AI; there is no experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into actual writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is technology acceptance (behavioral intention, attitudes) toward AI in EFL writing, not on implementing a writing intervention or instructional use of LLMs to develop writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes are psychological/behavioral (e.g., performance expectancy, attitude, intention), not measures of writing performance or related skills after an AI-mediated intervention.""}}"
A Case Study of Applying Grammarly for Mastering Pre-service Teachers' Writing Skills,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are university students majoring in English at Pavlo Tychyna Uman State Pedagogical University (Ukraine), i.e., L2 English learners in an EFL/ESL context. The focus is on mastering English academic writing skills.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention tool is Grammarly. While described as AI-based, Grammarly is not an LLM-based, transformer-style generative model like ChatGPT, GPT-4, or Gemini. The review explicitly excludes tools such as Grammarly that do not utilize LLMs as the core intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study\u2019s primary focus is on improving English academic writing skills, including pragmatic components of writing and language accuracy (grammar, vocabulary, spelling). Grammarly is integrated into the writing process to support these aspects.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions pre- and post-interviews to collect data on writing problems and refers to criteria for pragmatic components and language accuracy, but it does not clearly state that quantifiable writing outcome metrics (e.g., scores, error rates) were measured and analyzed. The outcomes are described in general terms (e.g., Grammarly enhances writing skills) without explicit quantitative results.""}}"
Leveraging Chatgpt for L2 Writing: Teacher Cognition and the Impact of Professional Development,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are 11 EFL teachers working in L2 writing contexts, and the abstract mentions student writing with ChatGPT feedback, implying an English-as-a-foreign-language setting.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study focuses on teacher cognition and a professional development (PD) program about using ChatGPT. There is no indication of an experimental or quasi-experimental LLM-based writing intervention implemented with learners; ChatGPT is used as an object of teacher learning, not as a structured instructional treatment for students.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""While the context is L2 writing and feedback, the primary focus is on teacher beliefs and professional development, not on a pedagogical intervention aimed at improving learners\u2019 writing competence. The study is conceptual/teacher-focused rather than an instructional trial of LLM-mediated writing support.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics for students (e.g., writing scores, complexity, accuracy, fluency). Outcomes are changes in teacher cognition and feedback literacy, not measured changes in learner writing performance.""}}"
"Comparing Peer Feedback and Generative Artificial Intelligence Feedback in Japanese English as a Foreign Language Speaking Context: Impacts on Motivation, Engagement, and Writing Self-efficacy",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Japanese university students learning English as a Foreign Language (EFL), clearly an L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study contrasts peer feedback with generative AI feedback using ChatGPT, a large language model, as part of an instructional intervention across semesters.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary context is speaking preparation; writing is limited to script-writing for speaking tasks. The main outcomes are motivation, engagement, and self-efficacy in a speaking context, not writing competence or writing-related performance variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports changes in motivation, engagement, ideal L2 self, and writing self-efficacy, but does not report quantifiable writing performance outcomes (e.g., writing quality, accuracy, complexity). Thus, it lacks measurable writing outcome metrics required for inclusion.""}}"
Artificial Intelligence in Efl Writing Enhancement: a Study on Chatbot Feedback and Learner Autonomy,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly focuses on English as a Foreign Language (EFL) learners and their writing, which fits the target population of L2 English learners in EFL contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the tool is described as an online AI chatbot using a transformer-based NLP system, it appears to be a feedback generator trained on ICLE essays, not a general-purpose large language model like ChatGPT/GPT-4. The description suggests a specialized NLP feedback system rather than an LLM-based generative model integrated as an instructional partner in the sense defined for this review.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study\u2019s primary focus is on writing enhancement, with the chatbot providing feedback on grammar, vocabulary, and discourse-level characteristics, and on learner autonomy in writing. This aligns with a focus on writing competence and writing-related variables.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Quantifiable writing outcomes are reported: changes in lexical diversity (MTLD), syntactic complexity (C/T), and cohesion in a simulated revision task, with findings of significant language gains among high-level learners.""}}"
Guided or Guiding: Contradictions and Conflicts in Ai-assisted Second Language Writing for Efl Learners from the Activity Theory Perspective,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as English as a Foreign Language (EFL) learners engaged in second language writing, so the population is L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract states that learners are \u201cengaging with artificial intelligence (AI) in second language writing\u201d and discusses \u201cAI-assisted writing practices,\u201d but it does not specify that the AI is a large language model (e.g., ChatGPT, GPT-4) or describe the AI tool\u2019s nature. It could be any AI-based support, not necessarily an LLM.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is clearly on second language writing practices and human\u2013AI collaboration in writing, examining tensions between learning, assessment, and AI-assisted writing. Thus, the primary context is writing competence and writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is described as a qualitative analysis of three EFL learners, focusing on contradictions, tensions, and resolution strategies. There is no mention of experimental or quasi-experimental design, nor of quantifiable writing outcome metrics; the outcomes are theoretical and qualitative (e.g., learner agency, resolution strategies).""}}"
"Descriptive Writing Using Generative Ai as a Cognitive Scaffold in the Metaverse Environment: University Students’ Perceptions, Learning Engagement, and Performance",2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were two undergraduate English as a foreign language (EFL) writing classes, clearly indicating L2 English learners in an EFL context, with a focus on English descriptive writing.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The intervention uses a tool termed a \u201cgenerative AI tool called \u2018GAIscaffold\u2019\u201d as a cognitive scaffold. However, the abstract does not specify whether GAIscaffold is an LLM/transformer-based generative model (e.g., ChatGPT-like) or another form of generative AI. Without this detail, it is unclear if it meets the LLM criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on EFL descriptive writing performance in a metaverse environment, using generative AI as a scaffold in the writing task. Outcomes include engagement and writing performance, aligning with writing competence\u2013related variables rather than automated scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantitative writing outcomes: final writing performance compared between experimental and control groups using MANCOVA, with statistically significant improvements in writing performance for the experimental group.""}}"
Overview of the Clef 2025 Joker Task 1: Humour-aware Information Retrieval,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The abstract describes an information retrieval task (JOKER-2025 Track) with English and Portuguese text collections. There is no mention of participants, learners, or L2 English learning contexts (ESL/EFL/ELL). It is a dataset/task overview, not a learner study.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study focuses on humour-aware information retrieval and dataset creation. It does not describe any experimental or quasi-experimental pedagogical intervention using LLMs (e.g., ChatGPT, GPT-4) in writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is humour-aware information retrieval and cross-linguistic humour detection, not writing competence or writing-related instructional variables. Any mention of potential use in writing or translation is speculative and not part of an educational intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No writing outcomes or metrics are reported. The paper reports dataset statistics and system runs for an IR task, without assessing effects on learners\u2019 writing performance.""}}"
Personalized L2 Argumentative Writing Instruction through Genai-enhanced Corpus-based Language Pedagogy: an Intervention Study,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are L2 learners engaged in IELTS Task 2 argumentative writing, which is an English proficiency exam context. The study explicitly focuses on L2 argumentative writing, implying L2 English learners in an EFL/ESL-type setting.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention uses GPT-4o (a large language model) to analyze learners\u2019 essay corpus and generate individualized linguistic profiles, tailored writing tips, coherence/cohesion checks, vocabulary lists, and grammar exercises. This is an experimental design integrating an LLM into writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on L2 argumentative writing instruction and improvement. GenAI is used pedagogically to personalize writing instruction (tips, feedback, exercises) rather than for automated scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantitative results from IELTS writing tasks, showing significant differences between control and experimental groups in short- and long-term outcomes. These are clear, quantifiable writing outcome measures assessing the effectiveness of the LLM-mediated intervention.""}}"
