Title,Year,Decision,Notes
Argumentative Writing Software: Perceptions of Undergraduate Students Toward Artist Prototype,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""Participants are 30 undergraduate students at a Thai university. Their L1 is likely not English, but the abstract does not explicitly state that they are L2 English learners or that the writing is in English, so it is unclear whether this is an L2 English context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines perceptions of an argumentative writing support tool (Artist) using NLP and AI. ChatGPT is mentioned as providing recommendations, but the design is described as prototype/interface testing with focus group interviews, not as an experimental or quasi-experimental LLM-based instructional intervention. The primary focus is usability/feasibility and perceptions, not a structured LLM-mediated teaching intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The tool is explicitly an argumentative writing support software, and the study focuses on argumentative writing and how students benefit from graphical representation in their argumentative writing. Thus, the primary focus is on writing competence and writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are based on focus group interviews and perceptions of feasibility and usability. The abstract does not report any quantifiable writing outcome metrics (e.g., scores, rubric-based improvements, measurable changes in writing quality). The effectiveness discussed appears to be qualitative and design-oriented rather than experimental measures of writing performance.""}}"
Mcaimem: a Mixed Sram and Edram Cell for Area and Energy-efficient On-chip Ai Memory,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The article focuses on AI chip memory design and benchmarking. There are no human participants, no mention of L2 English learners, ESL/EFL/ELL contexts, or any language learning population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is a mixed SRAM/eDRAM on-chip memory architecture (MCAIMem) for AI hardware. It does not involve integrating large language models (e.g., ChatGPT, GPT-4) into instruction or writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The context is hardware performance (area, energy efficiency) for AI memory in deep neural networks, not writing competence or writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No writing outcomes or educational measures are reported; the outcomes are chip area, energy consumption, and accuracy of AI models, unrelated to L2 writing performance.""}}"
Identifying Language Anxiety among Foreign Language Learners Using Gru,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The participants are described as foreign language learners writing English essays, suggesting they may be L2 English learners, but the specific ESL/EFL/ELL context and focus on English as the target language are not clearly detailed.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study develops machine learning classifiers (Decision Tree, LSTM, GRU) to categorize student-produced texts as anxious vs. non-anxious. These are not large language models used as pedagogical tools in writing instruction; they are text classifiers for anxiety detection, not LLM-based writing interventions.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on identifying language anxiety via automated text classification, not on improving writing competence or writing-related instructional processes. Writing is only a source of data for anxiety detection, not the target of an instructional intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported are model performance metrics (F1-score, accuracy, ROC-AUC) for anxiety classification. There are no quantifiable writing outcome measures assessing changes in learners\u2019 writing performance due to an LLM-mediated intervention.""}}"
Fluent Futures: Cutting-edge Ai Techniques for Mastering English,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study uses the ELLIPSE Corpus, described as a dataset of English Language Learner (ELL) writing samples with proficiency scores and comments, indicating an L2 English learner population in an ELL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is based on BERT and a sequence-to-sequence fine-tuning mechanism to generate feedback. BERT is a bidirectional encoder model, not a generative large language model like ChatGPT/GPT-4, and the abstract does not indicate use of an LLM-based generative system in instruction. Thus it does not meet the LLM intervention criterion.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The focus is on generating individualized feedback on learner writing (grammar, vocabulary, syntax) using AI, which is writing-related. However, it is not clearly framed as a pedagogical classroom intervention versus a technical NLP system for feedback generation.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although the abstract mentions potential measures such as student satisfaction and gains in writing skill, the reported experimental findings are only ROUGE-1, ROUGE-2, and ROUGE-L scores, which evaluate system output quality against reference feedback, not learners\u2019 writing outcomes. No quantifiable learner writing improvement is reported.""}}"
Synergizing Generative Pre-trained Transformer (gpt) Chatbots in a Process-based Writing Paradigm to Enhance University Students' Writing Skill,2024,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as 'university EFL students,' indicating learners of English as a foreign language. The focus of the study is on their English writing skills (organization, content, coherence-cohesion, logical connection, argumentation), satisfying the requirement that the target language is English in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention is the integration of 'GPT-based chatbots' within a process-based writing framework. GPT-based chatbots are large language models (Generative Pre-trained Transformers). The study uses a pre- and post-test design with 10 instructional sessions, indicating an experimental/quasi-experimental pedagogical intervention using LLMs in writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on enhancing 'students' writing skills' within a 'process-based writing framework,' covering components such as organization, content, coherence-cohesion, logical connection, and argumentation. The LLM is used as part of the writing process (planning, drafting, revising, editing), not merely for automated scoring or system evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantitative writing outcomes: pre- and post-writing test scores (mean scores increasing from 9.13 to 17.03) and performance across four writing quizzes, with detailed component-wise improvements. These constitute measurable writing outcome metrics assessing the effectiveness of the GPT-based chatbot intervention.""}}"
Examining Writing Feedback Dynamics from Chatgpt Ai and Human Educators: a Comparative Study,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as English Language Learners and third-year undergraduate students in English Language Education, indicating an EFL/ELL context focused on English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used as an AI automated writing feedback tool, the study employs a phenomenological design and focuses on comparing AI vs. human feedback qualitatively, not as an experimental or quasi-experimental pedagogical intervention with controlled conditions.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is writing instruction and feedback, explicitly aiming to examine the effectiveness of AI and human feedback in enhancing writing skills of English Language Learners.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract states that the study used a phenomenological design and collected qualitative data; it reports perceptions of feedback (detail, comprehensiveness, emotional intelligence) but does not mention any quantifiable writing outcome measures or experimental effectiveness metrics.""}}"
Chatbot-based Learning of Logical Fallacies in Efl Writing: Perceived Effectiveness in Improving Target Knowledge and Learner Motivation,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were 30 Chinese EFL learners, clearly an L2 English population in an EFL context, and the focus is on EFL writing.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers generically to a \u2018chatbot\u2019 used for learning logical fallacies, with no indication that it is an LLM-based tool (e.g., ChatGPT, GPT-4, transformer-based generative model). It could be a rule-based or scripted chatbot. Without explicit mention of LLM or generative AI, its status as an LLM intervention is unclear.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary instructional focus is on learning logical fallacies and motivation, not on writing competence or writing performance. While framed in relation to EFL writing, the measured outcomes are fallacy knowledge and motivation, not writing quality or writing-related performance variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Quantitative outcomes are pre\u2013post tests of fallacy knowledge and motivation questionnaires. No quantifiable writing outcome metrics (e.g., writing scores, text quality, complexity, accuracy, fluency) are reported to assess changes in writing performance.""}}"
Co-creating Stories with Generative Ai,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as students in an undergraduate language-related subject at a Hong Kong tertiary institution, and the paper explicitly refers to them as ESL learners, indicating L2 English learners in an EFL/ESL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions use of \u2018publicly available Generative Artificial Intelligence (GenAI) tools\u2019 in co-creating digital stories, but does not specify whether these are LLM-based tools (e.g., ChatGPT) or other generative systems. However, even if they are LLMs, the study design is not clearly experimental or quasi-experimental; it is framed as a service-learning subject with qualitative analysis.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on digital storytelling, creative potential, and promoting linguistic, digital, and cultural awareness, with GenAI playing a \u2018peripheral role\u2019. There is no indication of a structured writing instruction intervention aimed at improving writing competence; rather, it is a service-learning experience and exploration of critical use of GenAI.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is based on qualitative content analysis of semi-structured interviews and reports perceived expansion of creative potential and awareness. It does not mention any quantifiable writing outcome metrics or experimental measures of writing performance.""}}"
Aes Model with Logic Rule Reasoning and Self-explanation Based on Amr and Llm,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The abstract mentions 'second-language learners' only as a potential user group needing explanations, but does not describe any actual participant population, learner context (ESL/EFL/ELL), or empirical study with L2 English learners. It appears to be a technical AES model paper without human learner participants.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""LLMs are used to generate explanations within an Automated Essay Scoring system, not as part of an instructional or quasi-experimental intervention in writing instruction or writing processes. The focus is on model development and comparison with ChatGPT-4, not on pedagogical integration.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is AES model interpretability and performance, not writing competence or writing-related learning outcomes. LLMs are evaluated as components of an automated scoring/explanation system, which falls under excluded AES functionality studies rather than pedagogical interventions.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported are model performance metrics (e.g., surpassing prompt-tuned ChatGPT-4, cost reduction) and explanation quality, not quantifiable writing outcomes for learners. There is no experimental measure of changes in learners\u2019 writing ability following an LLM-mediated intervention.""}}"
Morpho-phraseological Based Classification of Cefr Italian L2 Learner Writing Proficiency,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are L2 learners of Italian, not L2 English learners. The study focuses on Italian as a second language and CEFR classification for Italian, which does not meet the population requirement centered on English L2 learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study presents an automatic classification model using lexical, morphosyntactic, and phraseological features, and compares it with machine learning models. There is no indication that large language models (e.g., ChatGPT, GPT-4) are used, nor that there is any instructional or intervention component.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on automated proficiency classification (assessment) of written texts, not on writing instruction, intervention, or support for writing processes. This aligns with automated scoring/classification research rather than pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported are model performance metrics (accuracy and prediction metrics) for CEFR level classification, not quantifiable writing development outcomes resulting from an LLM-mediated intervention. No experimental writing instruction or improvement measures are described.""}}"
Enhancing Writing Skills with Ai: Personalized Feedback Mechanisms for English Learners,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers broadly to 'English learners' and 'diverse learning contexts' but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor does it describe any concrete learner population or setting.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study introduces a feedback system based on the T5 Transformer model and evaluates it using BLEU, ROUGE, and METEOR. There is no indication of an experimental or quasi-experimental pedagogical intervention where L2 learners actually use the system in writing instruction; it appears to be a system-development and NLP evaluation study.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""While the context is writing feedback, the focus is on model performance and automatic feedback quality, not on an instructional intervention or integration into a teaching/learning process aimed at improving learner writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Reported outcomes are NLP metrics (BLEU, ROUGE, METEOR) assessing alignment with reference texts, not quantifiable learner writing outcomes (e.g., pre/post writing scores, rubric-based writing quality measures) from an educational intervention.""}}"
The Impact of Using Chatgpt on Efl Students’ Writing,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) learners, and the focus is on English writing, satisfying the L2 English learner population criterion.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study examines learners\u2019 outlines written without ChatGPT and revised outlines with ChatGPT assistance, indicating an intervention integrating an LLM (ChatGPT) into the writing process in a comparative design.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on the impact of ChatGPT on EFL students\u2019 writing, including logical structure, content enrichment, vocabulary, and grammar, which are all writing-related variables rather than automated scoring.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports discourse analysis results and qualitative improvements (logical structure, content, vocabulary, grammar) and student reflections, but does not indicate any quantifiable writing outcome metrics (e.g., scores, counts, statistical tests). Outcomes appear qualitative only.""}}"
Visual Analysis of Mobile-assisted Language Education and Discussion on the Role of Mobile Llm Applications in Tcsol,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The article focuses on mobile-assisted language education broadly and specifically discusses mobile LLM applications in TCSOL (Teaching Chinese to Speakers of Other Languages), i.e., L2 Chinese learners. The target language is Chinese, not English, so it does not match the required L2 English learner population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""This is a visual analysis/bibliometric study using Citespace and a conceptual discussion of the role of mobile LLM applications. There is no experimental or quasi-experimental design integrating LLMs into instruction; it is not an intervention study.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The paper is a bibliometric overview of mobile-assisted language education and a conceptual discussion of potential roles of mobile LLMs. It does not implement or evaluate a writing-focused pedagogical intervention; writing competence is not the primary empirical focus.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported. The study is descriptive/analytical and forward-looking, discussing potential future research and roles of LLMs, without experimental measures of writing performance.""}}"
Exploring Efl Learners’ Integration and Perceptions of Chatgpt's Text Revisions: a Three-stage Writing Task Study,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly states the context is an English as a foreign language (EFL) classroom, so participants are L2 English learners and the target language is English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used to provide reformulations as feedback, the design is observational/descriptive rather than experimental or quasi-experimental. The study investigates how learners notice, integrate, and perceive ChatGPT\u2019s reformulations; there is no indication of controlled intervention conditions, comparison groups, or pre/post testing to evaluate instructional effectiveness.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on EFL writing: a three-stage writing task (composing\u2013comparison\u2013rewriting) and how ChatGPT\u2019s reformulations function as feedback in the revision stage. This directly concerns writing processes and writing-related variables in a pedagogical context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported concern noticing (type and depth), number of reformulations integrated, and learners\u2019 perceptions via questionnaire. The abstract does not report quantifiable writing performance outcomes (e.g., scores, quality ratings, accuracy measures) to assess effectiveness of the LLM-mediated intervention on writing competence.""}}"
Efl Learners' Perceptions of Written Corrective Feedback in Online Learning,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 113 EFL students (English as a Foreign Language) in English preparation classes at a private university in Vietnam, clearly L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study investigates perceptions of written corrective feedback (WCF) in online writing classes. There is no mention of large language models, ChatGPT, or any transformer-based generative AI being used as part of the intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is English writing classes and written corrective feedback, which is directly related to writing competence and writing instruction.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study focuses on students\u2019 perceptions of WCF using questionnaires and interviews. It does not report quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy) resulting from an intervention; it is attitudinal rather than outcome-based.""}}"
Uses and Misuses of Chatgpt as an Ai-language Model in Academic Writing,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The abstract does not specify any participant group, let alone L2 English learners in ESL/EFL/ELL contexts. It appears to be a conceptual or discussion paper about academic writing in general, not an empirical study with a defined L2 population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is discussed, there is no indication of an experimental or quasi-experimental intervention design. The paper examines uses, misuses, advantages, and limitations conceptually rather than implementing ChatGPT in a structured instructional intervention.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The focus is on academic writing broadly, including idea generation, grammar, and research assistance. However, it is not framed as a pedagogical intervention targeting writing competence in a specific learner group; instead, it is a general discussion of tool use and ethics.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics or experimental measures are reported. The abstract mentions \u2018findings\u2019 in a general sense but does not describe any measured changes in writing performance or related variables.""}}"
"Chatgpt, a Helpful Scaffold or a Debilitating Crutch for Academic Writing?",2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The abstract describes a general review of ChatGPT in academic writing without specifying any participant population, let alone L2 English learners in ESL/EFL/ELL contexts. It appears to address academic writers broadly (educators, researchers, students), not a defined L2 English learner group.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""This is explicitly a review paper that \u2018draws on existing literature, empirical studies, and expert opinions\u2019 and \u2018assesses the advantages and constraints\u2019 of ChatGPT. It does not report an experimental or quasi-experimental intervention integrating ChatGPT into instruction; it is conceptual/analytical.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The focus is on academic writing processes and quality in general, but because it is a review, it does not describe a specific pedagogical context or intervention targeting writing competence. The primary aim is critical examination, not an implemented instructional context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported. The paper synthesizes advantages, constraints, and ethical implications from prior work, but does not present its own experimental measures or structured intervention outcomes.""}}"
Exploring the Young Learners' Interactions with Ai-enerated Multimodal Feedback in Collaborative Writing,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are young learners in Chinese language learning activities. The abstract repeatedly specifies a focus on Chinese language, not English, and there is no indication that they are L2 English learners in ESL/EFL/ELL contexts.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses an AI-enabled automated feedback learning system with AI-generated image feedback, AI-enabled audio feedback, and automatic scoring. However, it is not specified whether this system is based on large language models (e.g., ChatGPT/GPT-4) or other AI techniques.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on vocabulary learning and collaborative Chinese language learning activities. While the title mentions collaborative writing, the abstract emphasizes vocabulary learning outcomes, learning process, and enjoyment, not writing competence or writing-related variables as the main outcome.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The study will examine students\u2019 learning outcomes and uses automatic scoring, but the abstract frames these outcomes in terms of vocabulary learning rather than writing performance. It is not clear that quantifiable writing outcome metrics are reported.""}}"
To Use or Not to Use? a Mixed-methods Study on the Determinants of Efl College Learners' Behavioral Intention to Use Ai in the Distributed Learning Context,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 464 Chinese EFL college learners, clearly an English-as-a-foreign-language population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines determinants of behavioral intention to use AI based on the Technology Acceptance Model. It does not describe an experimental or quasi-experimental LLM-based writing intervention, nor specify use of tools like ChatGPT or other LLMs in instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on behavioral intention to use AI in distributed EFL learning contexts, not specifically on writing competence or writing-related variables. No mention is made of writing instruction or writing processes as the primary context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are TAM constructs (perceived ease of use, perceived usefulness, attitude, behavioral intention). The study does not report quantifiable writing performance outcomes or writing-related measures.""}}"
Opening the Black Box: Interpretable Machine Learning Reveals the Relationship between Lexical Diversity and Writing Quality,2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract references CET-4 writing, which typically involves Chinese EFL learners, but it does not explicitly state that the participants are L2 English learners or provide participant details. Thus, the L2 English learner population is not clearly confirmed from the abstract alone.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses interpretable machine learning to explore the relationship between lexical diversity and writing quality and to verify the validity of automatic essay scoring. There is no indication that large language models (e.g., ChatGPT, GPT-4) are integrated into instruction or writing processes as an intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on modeling the relationship between lexical diversity and writing quality and on validating automatic essay scoring, not on a pedagogical writing intervention. It is an assessment/construct validity study rather than an instructional context aimed at improving writing competence through LLM use.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although writing quality is analyzed, the study does not describe an experimental or quasi-experimental intervention using LLMs with pre/post or comparative outcome measures. It focuses on construct exploration and scoring validity, not on quantifying the effectiveness of an LLM-mediated writing intervention.""}}"
