Title,Year,Decision,Notes
Feeding Two Birds with One Scone: Using Awe to Enhance Writing and Creativity among Pre-university Students,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as \u201celeven CEFR B1 second language learners\u201d in \u201cEnglish language writing instructions,\u201d indicating L2 English learners in an EFL/ESL-type context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses an Automated Writing Evaluation (AWE) tool based on NLP to generate feedback. The abstract does not indicate that this is a large language model (e.g., ChatGPT/GPT-4 or similar transformer-based generative model); it appears to be a conventional AWE system, which falls outside the LLM-focused scope.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study explicitly focuses on \u201cEnglish language writing instructions to improve writing proficiency and creative performance,\u201d using AWE as formative assessment in writing lessons. The primary context is writing competence and related creativity.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports pre- and post-test scores for writing and creativity, noting \u201cimprovements in writing and creativity scores.\u201d These are quantifiable outcome measures of the writing intervention.""}}"
The Combination of Recognition Technology and Artificial Intelligence for Questioning and Clarification Mechanisms to Facilitate Meaningful Efl Writing in Authentic Contexts,2023,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as EFL learners, indicating L2 English learners in an EFL context. The focus is on EFL writing, so the target language is English.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses an app with \u201cgenerative-AI that can generate meaningful questions and clarifications.\u201d However, the abstract does not specify whether this generative AI is a large language model (e.g., transformer-based LLM such as ChatGPT/GPT-4) or another type of AI. Without explicit indication that an LLM is used, it is unclear if it meets the LLM-based intervention criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The intervention is designed to facilitate EFL writing in authentic contexts via a Smart Questioning-Answering-Clarification mechanism. Outcomes include writing more meaningful words and enhancing EFL writing, so the primary focus is on writing competence and related variables, not on automated scoring.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study is a five-week quasi-experiment with experimental and control groups, reporting significant differences in learning behaviors, post-test results, and the amount of meaningful words written in assignments. These are quantifiable writing-related outcome measures.""}}"
Rating Short L2 Essays on the Cefr Scale with Gpt-4,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract specifies that the essays are written by L2 English learners on a high-stakes language assessment, clearly matching the target population of L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""GPT-3.5 and GPT-4 are used as automated raters of essays, not as part of an instructional or intervention design for writing. There is no experimental or quasi-experimental integration of LLMs into writing instruction or writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on automated essay scoring performance and inter-rater agreement with human ratings, not on improving writing competence or implementing a pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports agreement between LLM and human scores as an evaluation of scoring reliability, not as outcome measures of a writing intervention. There is no LLM-mediated instructional treatment whose impact on writing performance is measured.""}}"
The Impact of Automated Writing Evaluation on Second Language Writing Skills of Chinese Efl Learners: a Randomized Controlled Trial,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 190 Chinese EFL students, clearly L2 English learners in an EFL context. The writing test is an IELTS writing sample, confirming the target language is English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is Automated Writing Evaluation (AWE) training using Grammarly. Grammarly is described as an AI-driven AWE platform, but it is not a large language model-based generative tool like ChatGPT, GPT-4, or similar transformer-based LLMs. The study focuses on AWE, not LLM-mediated writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on L2 writing competence, assessing task achievement, coherence and cohesion, lexicon, and grammatical accuracy in IELTS writing tasks. The intervention is pedagogical, not just automated scoring.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The randomized controlled trial reports quantifiable writing outcomes: performance differences between experimental and control groups across multiple writing skill dimensions, with pre- and post-test measures.""}}"
Sentence-level Feedback Generation for English Language Learners: Does Data Augmentation Help?,2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions \u2018English language learners\u2019 as the target of feedback comments, but it does not specify whether any actual L2 English learners participated as subjects, nor whether data come from ESL/EFL/ELL learners versus synthetic or existing corpora.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses LLMs to generate feedback comments and explores data augmentation for a feedback generation system. There is no indication of an experimental or quasi-experimental pedagogical intervention where L2 learners use LLMs within writing instruction or writing processes; it is a system-development/evaluation paper.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on the NLP task of feedback comment generation and system performance, not on learners\u2019 writing competence or writing-related learning outcomes. It aims to aid future studies but does not itself implement a teaching/learning context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable learner writing outcomes are reported. The results concern performance of feedback generation models and analysis of generated comments, not changes in learners\u2019 writing quality or related measurable educational outcomes.""}}"
Exploring the Capabilities of Chatgpt for Lexicographical Purposes: a Comparison with Oxford Advanced Learner’s Dictionary within the Microstructural Framework,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The abstract focuses on comparing ChatGPT\u2019s lexicographical output with the Oxford Advanced Learner\u2019s Dictionary. It does not mention any participant group, learners, or empirical data from L2 English learners in ESL/EFL/ELL contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is evaluated as a lexicographical resource, not implemented as an instructional intervention or within an experimental/quasi-experimental design involving learners\u2019 writing processes. The study is a tool comparison, not a pedagogical intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on lexicographical microstructure and dictionary content quality, not on writing competence or writing-related variables. There is no indication of writing instruction or writing performance being targeted.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported are similarity metrics (BLEU, ROUGE) and percentage presence of lexicographical items, not quantifiable writing outcomes from learners. No writing performance measures or intervention effects on writing are described.""}}"
An Impact of Artificial Intelligence Tools on Technical Students’ Esl Oral Communication Skills-a Study,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are technical engineering students in India learning English as a second language (ESL), which fits the target population of L2 English learners in an EFL/ESL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses unspecified \u2018Artificial Intelligence based mobile applications.\u2019 There is no indication these are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative tools; they could be generic AI language-learning apps. Thus it does not clearly meet the LLM requirement.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on oral communication skills (speaking accuracy and fluency). Writing is only mentioned in the conclusion as a future recommendation, not as the focus of the intervention or measured outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Quantitative outcomes are reported only for speaking (oral communication) via pre-post tests and speaking rubrics. No writing-related outcome measures are reported.""}}"
The Impact of Ai Writing Tools on the Content and Organization of Students’ Writing: Efl Teachers’ Perspective,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL students as reported via their teachers\u2019 perspectives in Indonesian universities, clearly within an EFL/ELL context focused on English writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although several AI tools are mentioned (Quillbot, WordTune, Jenni, ChatGPT, etc.), the study is not an experimental or quasi-experimental intervention integrating LLMs into instruction. It is a qualitative case study exploring teachers\u2019 perceptions of various AI tools, without a structured LLM-based pedagogical intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on the impact of AI writing tools on students\u2019 writing, specifically content and organization, which are core writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses a qualitative case study design with semi-structured interviews and reports teachers\u2019 perceptions. It does not report quantifiable writing outcome metrics or experimental measures of writing performance.""}}"
The Use of Artificial Intelligence to Improve the Scientific Writing of Non-native English Speakers,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The population is described broadly as 'non-native English-speaking scientists,' not as L2 English learners in ESL/EFL/ELL instructional contexts. The focus is on researchers\u2019 scientific writing, not language learners in educational settings.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The article is a narrative, non-systematic review of AI tools (Elicit, ResearchRabbit, Scispace Copilot, Grammarly, Paperpal, ChatGPT). It does not report an experimental or quasi-experimental intervention integrating LLMs into instruction; it only describes potential uses.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the topic is scientific writing, the paper is conceptual/descriptive, not an empirical study of a writing intervention. There is no implemented pedagogical context or structured writing program being evaluated.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported. The article is a narrative review discussing how AI might improve clarity, style, and coherence, without experimental measures or assessed intervention outcomes.""}}"
"17th Linguistic Annotation Workshop, Law 2023 @ Acl 2023 - Proceedings of the Workshop",2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""This is a proceedings volume from the 17th Linguistic Annotation Workshop, covering multiple NLP/annotation topics (e.g., Byzantine Greek marginal writing, mythological events, mathematical expressions, hate speech labelling). There is no indication that any paper focuses on L2 English learners in ESL/EFL/ELL contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""While one paper mentions using fine-tuned LLM suggestions to extend an event-type ontology, this is in the context of annotation and ontology extension, not an experimental or quasi-experimental LLM-based writing instruction intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus of the proceedings is linguistic annotation and related NLP tasks, not writing competence or writing-related pedagogical interventions. No writing instruction or writing process support is described.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""There is no mention of quantifiable writing outcome metrics or any structured LLM-mediated writing intervention. The described works concern annotation, datasets, and NLP pipelines rather than L2 writing outcomes.""}}"
Chatback: Investigating Strategies of Providing Synchronous Grammatical Error Feedback in a Gui-based Language Learning Social Chatbot,2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201csecond-language learners\u201d and \u201clanguage-learning AI chatbots\u201d but does not specify that the target language is English or that participants are ESL/EFL/ELL learners. The L2 and context are not explicitly identified.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study investigates a GUI-based language-learning social chatbot providing synchronous grammatical error feedback. There is no indication that the chatbot is powered by a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model). It appears to be a feedback-delivery interface rather than an LLM-integrated writing intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on synchronous grammatical corrective feedback in conversational chatbot interactions, including spoken language skills and general language learning experience and intention to use. Writing competence or writing-related variables are not the primary focus; online writing tasks are only mentioned as background, not as the main outcome context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported concern \u201clearning experiences\u201d and \u201cintention to use the system.\u201d The abstract does not mention quantifiable writing performance metrics or other objective writing outcomes; it centers on user experience and feedback presentation methods.""}}"
Using Ai-based Detectors to Control Ai-assisted Plagiarism in Esl Writing: the Terminator Versus the Machines,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The context is ESL composition, implying participants or texts from ESL learners. The focus is on ESL writing and AI-assisted plagiarism in ESL contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study investigates RoBERTa-based AI detectors and their ability to identify ChatGPT-generated texts. There is no experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or processes; instead, it evaluates detection tools.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on controlling AI-assisted plagiarism and evaluating AI-based detectors\u2019 accuracy, not on improving writing competence or writing-related learning outcomes. It is an assessment/detection study rather than a writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported concern detection accuracy of RoBERTa-based classifiers on human vs. ChatGPT-generated essays. No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) for learners are reported.""}}"
Analyzing Bias in Large Language Model Solutions for Assisted Writing Feedback Tools: Lessons from the Feedback Prize Competition Series,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Although the abstract mentions English Language Learner status as a demographic factor, the study does not focus on L2 English learners as participants in an instructional context; rather, it analyzes model performance across demographic groups within an existing dataset.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study analyzes winning LLM-based solutions used for evaluating student writing in competitions. There is no experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on bias and performance of LLM-based evaluation models (automated feedback/assessment), not on improving learners\u2019 writing competence through instructional use of LLMs.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported are model performance accuracy and bias across demographic groups, not quantifiable writing outcomes for learners following an LLM-mediated writing intervention.""}}"
Investigating Efl Students' Writing Skills through Artificial Intelligence: Wordtune Application as a Tool,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Saudi English as a Foreign Language (EFL) students, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses Wordtune (and mentions Grammarly) as AI-powered writing tools. The abstract does not indicate that these are large language model (LLM)-based tools (e.g., ChatGPT/GPT-4-style transformer generative models), and Wordtune/Grammarly are typically not framed as LLM-based pedagogical agents in this context. Thus it does not meet the requirement of integrating LLMs into writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study explicitly focuses on EFL students\u2019 writing skills and examines how Wordtune facilitates their writing, including lexical and syntactic gains and overall writing quality. The primary focus is writing competence, not automated scoring.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses a quasi-experimental design with control and experimental groups, pretests and post-tests, and final writing exam scores analyzed quantitatively, along with rated writing samples. These provide quantifiable writing outcome metrics.""}}"
Engaging Efl Students’ Critical Thinking Tendency and In-depth Reflection in Technology-based Writing Contexts: a Peer Assessment-incorporated Automatic Evaluation Approach,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are clearly described as university EFL (English as a Foreign Language) writing students, so the population consists of L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses an automatic writing evaluation (AWE) system integrated with peer assessment. The abstract does not indicate that the AWE tool is an LLM-based, transformer generative model (e.g., ChatGPT, GPT-4). AWE in this context typically refers to non-LLM scoring/feedback systems, which fall outside the review\u2019s scope.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on EFL writing instruction and performance in technology-based writing contexts, examining how AWE and peer assessment affect writing performance, motivation, critical thinking, and anxiety. Writing competence is a primary focus.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable outcomes: the PA-AWE group \u2018outperformed\u2019 the control group in EFL writing performance, learning motivation, critical thinking, and writing anxiety, implying measured, comparative writing-related outcomes from a quasi-experiment.""}}"
Artificial Intelligence in Global World: a Case Study of Grammarly as E-tool on Esl Learners’ Writing of Darul Uloom Nadwa,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Madrasa ESL learners in India (Alimiyat grade), explicitly described as English as a Second Language (ESL) students, with focus on English writing and inflectional morpheme errors.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses Grammarly as an electronic tool. Grammarly is a grammar-checking/writing support tool and is not described as an LLM-based, transformer generative model (e.g., ChatGPT, GPT-4). The study does not involve integration of large language models into instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on improving ESL learners\u2019 writing, specifically reducing inflectional morpheme errors. The intervention is pedagogical, comparing Grammarly-supported writing with communicative language teaching, not automated essay scoring research.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantitative writing outcomes: pre- and post-treatment measures of inflectional morpheme-related errors analyzed via repeated-measures two-way ANOVA, showing Grammarly enhanced ESL learners\u2019 writing relative to a control group.""}}"
Understanding English as a Foreign Language Students’ Idea Generation Strategies for Creative Writing with Natural Language Generation Tools,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as English as a foreign language (EFL) students in Hong Kong secondary schools, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses \u201cnatural language generation (NLG) tools\u201d for idea generation in creative writing, but the abstract does not specify whether these are large language model\u2013based tools (e.g., ChatGPT, GPT-4) or other, non-LLM NLG systems. Thus it is unclear if LLMs are involved.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is creative writing: students attend workshops to learn to write stories using their own words and words generated by NLG tools. The focus is on writing processes (idea generation) in an instructional setting.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is exploratory and uses thematic analysis of students\u2019 written reflections about their experience with NLG tools. The abstract does not report any quantitative or experimental writing outcome measures (e.g., writing quality scores, complexity, accuracy). It focuses on strategies and concerns, not measurable writing gains.""}}"
Exploring the Role of Artificial Intelligence in Facilitating Assessment of Writing Performance in Second Language Learning,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are students in a Chinese language learning program in the US, and the study focuses on assessing writing accuracy in Chinese, not English. Thus, the target language is not L2 English.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses four LLMs (GPT-4, GPT-3.5, iFLYTEK, Baidu Cloud) via official APIs to assess writing accuracy, indicating integration of LLMs in language-related assessment, though not as a pedagogical intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on using LLMs to assess writing accuracy and compare their ratings to human raters. This is an automated assessment/essay scoring context, not an instructional or intervention context aimed at improving writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports performance metrics of LLMs (e.g., precision, robustness, efficiency) in rating writing, not quantifiable outcomes of a writing intervention on learners\u2019 writing performance. There is no experimental or quasi-experimental pedagogical intervention with learner writing outcomes.""}}"
Interaction Patterns between Learners and Ai Tools for English Writing,2023,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as EFL (English as a foreign language) undergraduates, indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to an unspecified 'AI tool for English writing' but does not indicate whether it is a large language model (e.g., ChatGPT, GPT-4) or a non-LLM tool (e.g., grammar checker). Without the tool\u2019s nature or name, it is impossible to confirm that an LLM is integrated into the writing instruction or process.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on how EFL learners interact with an AI tool 'for English writing' and how different interaction patterns affect 'writing performance,' which aligns with a primary focus on writing competence and writing-related variables.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study 'explores the effects of different interaction patterns on their writing performance' and reports that different patterns lead to varied benefits, implying quantitative comparison of writing outcomes across clusters, even though specific metrics are not detailed in the abstract.""}}"
Empowering Language Learners: Harnessing Computer-based Writing for Enhanced Chinese Language Proficiency,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are Chinese Language (CL) learners in Singapore primary schools, focusing on Chinese language proficiency and Chinese writing, not L2 English learners or English writing outcomes.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is computer-based writing (CBW) versus paper-and-pen writing in Chinese. Generative AI is only mentioned in a proposed future platform (WeeWrite) and is not part of the implemented experimental or quasi-experimental intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on writing quality and related variables (typing speed, handwriting speed, writing strategies) in the context of computer-based writing, which is a writing competence context, albeit in Chinese.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcome metrics, comparing post-CBW and post-PPBW scores using mixed-effects modeling to assess the impact on writing quality.""}}"
