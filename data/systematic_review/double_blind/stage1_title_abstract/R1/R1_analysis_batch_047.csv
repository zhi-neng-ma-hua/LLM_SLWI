Title,Year,Decision,Notes
Automated Scoring of Speaking and Writing: Starting to Hit Its Stride,2022,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The abstract describes a review of automated scoring of writing and speaking, not an empirical study with a defined participant population of L2 English learners. It focuses on literature from 2011 onward and implications for assessment, teaching, and learning, but no specific learner group is identified.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The article is a literature review on automated scoring systems, not an experimental or quasi-experimental intervention integrating LLMs (e.g., ChatGPT, GPT-4) into writing instruction or processes. It surveys AS research rather than implementing an LLM-based pedagogical tool.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on automated scoring for assessment (design considerations, role of humans and AI, accuracy with different groups) rather than on writing competence development through instructional intervention. It discusses implications for teaching and learning but does not present a writing-focused pedagogical context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a review article, it does not report original, quantifiable writing outcome metrics from an LLM-mediated intervention. It synthesizes existing AS research and future directions, not experimental measures of writing improvement.""}}"
Assessing Readability of Learning Materials on Artificial Intelligence in English for Second Language Learners,2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly focuses on English-as-a-second-language (ESL) learners studying AI, so the population is L2 English learners in an ESL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study develops automatic readability assessors using deep-learning-based NLP and classic NLP to estimate text difficulty. There is no indication that an LLM (e.g., ChatGPT, GPT-4) is integrated into writing instruction or learners\u2019 writing processes; the tools are used for readability assessment of input texts, not as pedagogical LLM interventions.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on reading difficulty/readability of AI learning materials, not on writing competence or writing-related variables. No writing instruction or writing tasks are described.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported concern readability levels of texts and the proportion of materials accessible to intermediate ESL learners. There are no quantifiable writing outcome metrics or evaluation of a writing intervention.""}}"
A Multi-facet Rasch Measurement of Peer Evaluation in Computerized Dynamic Esl Writing,2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly states the context is ESL (English as a Second Language) writing with 41 students, indicating L2 English learners in an ESL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention involves Computerized Dynamic Assessment and a peer assessment system (Peerceptiv). There is no mention of large language models (e.g., ChatGPT, GPT-4) or transformer-based generative AI; the focus is on peer evaluation and Rasch measurement, not LLM-mediated instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on second language writing and peer assessment within computerized dynamic assessment, which is directly related to writing competence and writing assessment processes.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract reports on reliability and consistency of peer assessment using Multi-facet Rasch measurement but does not clearly state whether quantifiable writing outcome metrics (e.g., improvement in writing quality) are reported. The focus appears to be on assessment reliability rather than learner writing gains.""}}"
Design of Interactive System for Autonomous Learning of Business English Majors Based on Deep Learning Algorithms,2022,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The population is described as 'business English majors', which likely implies L2 English learners, but this is not explicitly stated and could also include native speakers studying Business English. The abstract does not clearly specify ESL/EFL/ELL status or that English is a foreign/second language for the participants.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study mentions 'deep learning algorithms' and an 'interactive system for autonomous learning' but does not indicate the use of large language models (e.g., ChatGPT, GPT-4) or transformer-based generative models integrated into writing instruction. It appears to be a recommendation/learning system based on heterogeneous data, not an LLM-mediated writing intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on 'self-service learning ability' and 'deep learning goals' for business English majors. While 'written tests and work evaluations' are mentioned, the abstract does not specify that the primary focus is writing competence or writing-related variables; it seems more about autonomous learning and reflection rather than writing instruction or writing processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although there is mention of 'written tests and work evaluations', these are used to verify a hypothesis about reflection and deep learning goals, not clearly as quantifiable writing outcome metrics within an LLM-mediated writing intervention. No explicit writing performance measures tied to an LLM-based writing intervention are reported.""}}"
The Integration of Multiple Recognition Technologies and Artificial Intelligence to Facilitate Efl Writing in Authentic Contexts,2022,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 71 undergraduate English as a Foreign Language (EFL) learners. The focus is explicitly on English writing, satisfying the requirement for L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention is a mobile app (Smart UEnglish) integrating multiple recognition technologies and generative-AI. The experimental group uses AI-generated sample sentences (AI-GS) as part of instruction, compared to a control group without AI-GS, indicating an experimental design with a generative AI (LLM-like) writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study\u2019s primary focus is on facilitating EFL writing, providing lexical resources and AI-generated sample sentences to support essay writing. Outcomes discussed include meaningful English writing and post-test writing performance, clearly centering on writing competence.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports that the experimental group outperformed the control group in the posttest and identifies ITR use as a predictive variable in the post-test. This indicates quantifiable writing outcome metrics (pre/post-test comparison) to assess the effectiveness of the AI-mediated writing intervention.""}}"
Using Chatbots to Scaffold Efl Students? Argumentative Writing,2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The population is explicitly EFL (English as a foreign language) students, and the focus is on English argumentative writing, satisfying the L2 English learner requirement.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to a \u2018chatbot\u2019 and \u2018Argumate, a novel chatbot system\u2019, but does not specify that it is a large language model (e.g., transformer-based generative model like GPT). It could be a rule-based or non-LLM chatbot, so its status as an LLM intervention is unclear.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly the teaching and learning of argumentative writing, with the chatbot used to scaffold students\u2019 argument construction and assist them in producing high-quality argumentative writing. The primary focus is on writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract describes a proposed chatbot-assisted approach and discusses advantages and limitations of the system, but does not indicate any experimental or quasi-experimental design, nor any reported quantitative writing outcome measures. It appears to be a design/description paper rather than an intervention study with measurable writing outcomes.""}}"
To Err Is Human: Comparing Human and Automated Corrective Feedback,2022,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions a corpus of 115 texts written by college students, but does not specify whether these are L2 English learners (ESL/EFL/ELL) or native speakers. The learner status and L2 context are not clearly indicated.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study compares corrective feedback from human teachers with Grammarly, described as a \u2018well-known writing assistant\u2019 and \u2018Automated Written Evaluation (AWE)\u2019 tool. Grammarly is not an LLM-based generative model in the sense required (e.g., ChatGPT, GPT-4, Gemini); it is a non-LLM AWE/grammar-checking tool. No LLM-based intervention is reported.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on comparing types and accuracy of corrective feedback (error detection by teachers vs Grammarly) on a corpus of texts, not on a pedagogical writing intervention or instructional integration of an LLM. It is essentially an evaluation of automated vs human CF, not an LLM-mediated writing instruction study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports statistics on number and types of errors detected by each feedback source, but does not report pre/post or comparative writing outcome measures for learners (e.g., improvement in writing quality or accuracy after intervention). It is descriptive and tool-comparative, not an outcome-based intervention study.""}}"
A Review of Artificial Intelligence in Foreign Language Learning,2022,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses foreign/second language learning in general and does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor that the focus is on English specifically.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The article is explicitly described as a brief review of AI implementation in second language learning, not an experimental or quasi-experimental study. No specific LLM-based intervention (e.g., ChatGPT, GPT-4) is reported.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The focus is broadly on foreign language learning and AI, with no indication that writing competence or writing-related variables are the primary focus; multiple aspects of language learning may be covered.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a review article, it does not report original quantitative writing outcome metrics from an intervention; it summarizes existing attempts instead.""}}"
The Effects of an Augmented-reality Ubiquitous Writing Application: a Comparative Pilot Project for Enhancing Efl Writing Instruction,2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as EFL undergraduates in an English as a foreign language writing context, so the population is L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is an augmented-reality context-aware ubiquitous writing (ARCAUW) application compared with a mobile-assisted classroom-based writing mode. There is no indication that the tool is a large language model or transformer-based generative system (e.g., ChatGPT, GPT-4). It is an AR ubiquitous learning application, not an LLM-based writing assistant.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on EFL writing instruction and compares two writing modes, examining writing development, task schema, and self-regulation in writing. Thus, the primary focus is on writing competence and related variables.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract reports pre- and post-test results showing significant improvement in writing process analysis essays and mixed results in writing performance, indicating quantifiable writing outcome measures were used.""}}"
Partnering with Al: Intelligent Writing Assistance and Instructed Language Learning,2022,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses \u201cinstructional language learning\u201d and \u201clearners,\u201d but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor that the focus is specifically on English rather than other languages.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The piece is explicitly described as a \u201ccolumn\u201d that examines tools, reviews findings, and discusses their use. It does not present an experimental or quasi-experimental study; rather, it is a narrative/overview of AI-enabled writing tools (AWE, MT, Grammarly, predictive text, generative tools). Thus, it does not meet the requirement for an LLM-based intervention study design.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The focus is broadly on \u201cintelligent writing tools\u201d and their use in writing instruction, which is writing-related, but because this is a column/review rather than an empirical intervention study, the context criterion cannot be properly applied.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics or experimental results. It states that the column will review findings and discuss use in instructional settings, which aligns with a narrative/review format rather than reporting original, measured writing outcomes.""}}"
Exploring Artificial Intelligence Using Automated Writing Evaluation for Writing Skills,2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Malaysian public university students in ESL writing classrooms, indicating L2 English learners in an ESL/EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is Automated Writing Evaluation (AWE) software. The abstract does not indicate that this AWE system is an LLM-based, transformer generative model (e.g., ChatGPT, GPT-4). AWE tools are typically rule-based or non-LLM NLP systems, which fall outside the review\u2019s scope.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on improving writing skills in ESL writing classrooms and on detecting grammatical errors, which are writing-related variables.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions investigating the effectiveness of AWE and students\u2019 perceptions, but only reports positive perceptions and implications. It does not clearly state that quantifiable writing outcome metrics (e.g., pre/post writing scores) were measured.""}}"
Clustering Students' Writing Behaviors Using Keystroke Logging: a Learning Analytic Approach in Efl Writing,2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The title specifies an EFL writing context, implying participants are English as a Foreign Language learners engaged in English writing tasks.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses keystroke logging and clustering (machine learning) to identify writing behavior profiles. There is no mention of large language models (e.g., ChatGPT, GPT-4) or any transformer-based generative model being integrated into instruction or writing processes.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on writing processes and writing quality in EFL writing, using process indicators and clustering to understand writing behaviors, which is clearly writing-related.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract notes that the clusters are validated by comparing them with students\u2019 writing quality, indicating quantifiable writing outcome measures are analyzed.""}}"
An Integrated Automatic Writing Evaluation and Svvr Approach to Improve Students' Efl Writing Performance,2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are clearly described as EFL (English as a Foreign Language) university students in an EFL writing course, so the population consists of L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention integrates Automatic Writing Evaluation (AWE) and spherical video-based virtual reality (SVVR). The abstract does not indicate that the AWE system is based on large language models (e.g., ChatGPT, GPT-4) or transformer-based generative models; it is presented as a conventional AWE tool. Therefore, it does not meet the requirement of an LLM-based writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on improving EFL writing performance and related affective variables (motivation, self-efficacy, anxiety) through an instructional intervention in a writing course, which aligns with a writing competence context rather than automated scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable outcomes: it states that the integrated SVVR-AWE method enhanced students\u2019 EFL writing performance and also measured motivation, self-efficacy, sense of presence, and writing anxiety, implying pre/post or comparative quantitative measures in a quasi-experimental design.""}}"
Automatic Scoring of Arabic Essays over Three Linguistic Levels,2022,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are learners of Arabic as a second language; the focus is on Arabic essays, not English. The review targets L2 English learners in ESL/EFL/ELL contexts with data related to English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study presents an automatic scoring system using feature extraction and experiments with linear and non-linear combination methods. There is no indication that large language models (e.g., ChatGPT, GPT-4) are used, nor that the system is transformer-based generative AI.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on automated essay scoring reliability and agreement with human raters, not on a pedagogical writing intervention or integration into writing instruction or processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports scoring accuracy and kappa values for the automated system versus human raters, but does not report quantifiable writing outcome metrics from an instructional or intervention context aimed at improving learners\u2019 writing.""}}"
Analysis of Syntactic Complexity and Semantic Coherence of Academic English Writing Based on Particle Swarm Optimization,2022,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers generally to \u2018language learners\u2019 and \u2018second language writing\u2019 but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor does it clearly describe a learner population (it may be corpus-based or system-focused).""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses particle swarm optimization (PSO) and compares it with data mining, AI, and decision tree algorithms as evaluation methods. PSO is an optimization algorithm, not a large language model or transformer-based generative model (e.g., ChatGPT, GPT-4). There is no LLM-based instructional or writing-process intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on developing an \u2018intelligent evaluation method\u2019 for syntactic complexity and semantic coherence in academic English writing, essentially an automated evaluation system. There is no indication of a pedagogical intervention in writing instruction or integration into learners\u2019 writing processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although quantitative metrics (e.g., significance values) are reported, they relate to algorithm performance in evaluating writing, not to changes in learners\u2019 writing outcomes following an LLM-mediated intervention. No experimental writing outcome measures for learners are described.""}}"
Writing Issues in Esl and Their Potential Solutions: Case Study Imco's Foundation Students,2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are IMCO foundation students who are described as non-native English speakers (ESL context, A1\u2013B1 levels). The focus is clearly on English writing issues of L2 learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is an experimental investigation of common writing mistakes and their causes. Although it mentions a need for apps, technology, and artificial intelligence, there is no indication that any LLM-based tool (e.g., ChatGPT, GPT-4) was actually integrated into instruction or the writing process.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on writing competence, specifically common writing mistakes (spelling, punctuation, thesis statements, structure, etc.) and factors contributing to these issues in ESL learners.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study records and analyzes common errors but does not describe an LLM-mediated intervention or report quantifiable outcomes of such an intervention. It is diagnostic/descriptive rather than an evaluation of an LLM-based writing intervention.""}}"
X-education: Education of All Things with Ai and Edge Computing—one Case Study for Efl Learning,2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly mentions a preliminary study for EFL writing with 22 learners, indicating participants are EFL (L2 English) learners.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses an 'on-device AI' and Q&A forwarding mechanisms within an X-Education framework. However, it is not specified that this AI is a large language model (e.g., transformer-based generative model like ChatGPT/GPT-4). The nature of the AI (LLM vs. other AI) is unclear from the abstract.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the context is EFL writing and Q&A for EFL answers, the primary focus appears to be on knowledge building for 'all things' and the X-Education framework, not specifically on writing competence or writing-related variables. The outcomes discussed are knowledge increase and perceived help for learning EFL writing, not targeted writing instruction or processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports that knowledge of all things in the experimental group increased more than the control group and that learners felt X-Education could help them learn EFL writing better. It does not report quantifiable writing outcome metrics (e.g., writing scores, text quality measures); the quantitative result pertains to 'knowledge,' not writing performance.""}}"
Computer-assisted Efl Writing and Evaluations Based on Artificial Intelligence: a Case from a College Reading and Writing Course,2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL students in a college reading and writing course, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses three online automated essay evaluation (AEE) systems and is framed under ICALL and deep learning theory, but there is no indication these are transformer-based large language models (e.g., ChatGPT, GPT-4). They are generic AEE tools, not explicitly LLM-based generative systems integrated into instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on English writing ability, independent learning ability in writing, and compares computer vs. teacher scoring feedback within a writing project, so the primary context is writing competence.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract reports that students\u2019 English writing ability and independent learning ability were \u2018significantly improved\u2019 and mentions descriptive statistics, implying quantifiable outcome measures of writing performance.""}}"
"Investigating English as a Foreign Language Learners' Perceptions, Emotions, and Performance during Online Collaborative Writing",2022,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL learners: 58 male students enrolled in writing courses in the Department of English Language and Translation at Qassim University. The focus is clearly on English as a foreign language.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses Blackboard and Blackboard Chatbox for online collaborative writing. These are not large language models or transformer-based generative tools (e.g., ChatGPT, GPT-4). No LLM integration is mentioned.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on collaborative writing, learners\u2019 emotions, and performance in writing courses, so the primary context is writing competence and writing-related variables.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports learners\u2019 overall performance and compares performance between face-to-face and Blackboard Chatbox instruction, including a significance test (Sig. = 0.287), indicating quantifiable writing outcomes.""}}"
Partnering with Ai: Intelligent Writing Assistance and Instructed Language Learning,2022,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses \u2018learners\u2019 and \u2018instructional language learning\u2019 but does not specify that participants are L2 English learners (ESL/EFL/ELL) or that the focus is specifically on English writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The piece is described as a \u2018column\u2019 that examines AI-enabled writing tools and reviews findings from research studies. It does not report an experimental or quasi-experimental study conducted by the authors, nor does it clearly focus on a specific LLM-based tool (e.g., ChatGPT, GPT-4). It is a narrative/overview rather than an intervention study.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""Writing assistance and instructional language learning are central themes, but because this is a column reviewing tools and research rather than reporting a specific empirical intervention, the context as a primary writing competence intervention study is not established.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not mention any quantifiable writing outcome metrics or experimental results. It focuses on reviewing tools and prior findings and discussing their use, which aligns with a conceptual/review piece rather than an empirical study with measured writing outcomes.""}}"
