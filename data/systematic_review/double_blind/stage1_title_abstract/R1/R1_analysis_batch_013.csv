Title,Year,Decision,Notes
Engagements with Gpt Responses and Learner Prompts in Chatgpt-based Learning of English Argumentative Writing Logic and Their Impacts,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 42 Chinese university students learning English as a foreign language (EFL). The focus is explicitly on English argumentative writing logic, so the target language is English in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study developed a discipline-specific GPT-4-powered chatbot (ChatGPT-based) for learning English argumentative writing logic. Learners used this LLM-based tool as part of an instructional intervention, indicating an experimental design integrating an LLM into writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on English argumentative writing logic, a core component of writing competence. The intervention is framed as ChatGPT-based learning of English argumentative writing logic, not as automated scoring or system evaluation, but as a pedagogical tool.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Learning outcomes were assessed via pre-post-delayed tests and pre-post writing tasks, providing quantifiable measures of changes in writing-related performance (logic knowledge and writing logic). Thus, the study reports experimental outcome metrics for the LLM-mediated writing intervention.""}}"
Enhancing Writing Skills through Ai-powered Tools: Perceived Benefits and Challenges among Vietnamese Efl Students,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are English-majored Vietnamese students in EFL classes at a university in Vietnam, clearly fitting an EFL/ESL/ELL L2 English learner population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although students use AI tools such as ChatGPT, QuillBot, and Claude, the study is observational and perception-based. There is no experimental or quasi-experimental design integrating LLMs as a structured writing intervention; AI use is self-initiated and surveyed, not manipulated as an instructional treatment.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on enhancing writing skills in EFL classes and on how AI tools are used across stages of the writing process, addressing writing-related variables rather than automated scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are students\u2019 perceived benefits and challenges and a correlation between frequency of AI use and perceived writing benefits. There are no objective or quantifiable writing performance measures (e.g., scores, text quality metrics) assessing the effectiveness of an LLM-mediated intervention.""}}"
Academic Socialization with Generative Ai: a Longitudinal Case Study of an L2 Graduate Student's Academic Literacies Development,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participant is described as an international, English as a Second Language (ESL) graduate student using English in an academic context, which fits the L2 English learner population criterion.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the study involves the use of ChatGPT (an LLM), it is a longitudinal case study of naturally occurring use, not an experimental or quasi-experimental intervention design integrating LLMs into instruction. There is no structured pedagogical treatment or controlled intervention.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""Writing is one of several foci (reading and writing support, exploring genres, navigating disciplinary expectations, generating research ideas). The primary framing is academic discourse socialization and academic literacies more broadly, not specifically a writing competence intervention, and no explicit instructional context is described.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports qualitative outcomes such as research interest, genre knowledge, disciplinary identity, and confidence. It does not mention any quantifiable writing outcome metrics or experimental measures of writing performance.""}}"
Evaluating the Potential of Chatgpt-reformulated Essays as Written Feedback in L2 Writing,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study uses 1,200 argumentative essays written for the TOEFL iBT independent writing task, which are produced by L2 English learners. The focus is clearly on second language (L2) English writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used to reformulate learner essays, the design is not an experimental or quasi-experimental pedagogical intervention with learners. It is a system-focused evaluation of ChatGPT\u2019s reformulations and prompt types, not an instructional treatment applied to participants\u2019 writing processes or instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on evaluating the properties of ChatGPT-generated reformulations (meaning retention, linguistic development, cohesion) and comparing prompt types. There is no implemented teaching/learning context or writing instruction intervention; the discussion of how reformulations could be used pedagogically is speculative rather than part of the study design.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports quantitative metrics (ROUGE-L, syntactic complexity, lexical sophistication, etc.) but these are applied to ChatGPT outputs versus original essays, not to measure changes in learners\u2019 writing following an LLM-mediated intervention. No learner outcome or pre\u2013post writing performance is assessed.""}}"
"The Role of Techno-competence in Ai-based Assessments: Exploring Its Influence on Students’ Boredom, Self-esteem, and Writing Development",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 66 Saudi Arabian male EFL learners, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cAI-driven evaluations\u201d and \u201cAI-enhanced assessments\u201d but does not specify that the AI is a large language model (e.g., ChatGPT, GPT-4) or a transformer-based generative model. It could be any AI-based assessment tool, not necessarily an LLM.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""Writing skills/proficiency is one of the primary outcome variables, and the intervention is situated in language assessment with a focus on writing development, which aligns with writing-related competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although pre- and post-assessments of writing proficiency are mentioned, the intervention is AI-based assessment in general, not clearly an LLM-mediated writing intervention. Because the nature of the AI tool (LLM vs. non-LLM) is unspecified, it does not meet the review\u2019s requirement for LLM-mediated writing outcomes.""}}"
Predictors of Childhood Vaccination Uptake in England: an Explainable Machine Learning Analysis of Regional Data (2021–2024),2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The study analyzes childhood vaccination coverage across districts in England using regional demographic and cultural variables. It does not involve L2 English learners in ESL/EFL/ELL educational contexts; English proficiency appears only as a population-level predictor, not as a learner population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is a public health data analysis using CatBoost and SHAP for explainable machine learning. There is no educational intervention, no language instruction, and no integration of large language models (e.g., ChatGPT, GPT-4) into any learning or writing process.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The context is public health and vaccination uptake, not writing competence or writing-related variables. No writing instruction, tasks, or assessment are mentioned.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes are vaccination coverage prediction accuracy and identification of predictors via SHAP. There are no writing outcome metrics or measures of writing performance or development.""}}"
Tracking the Effects of Gemini as a Genai Tool on L2 Learners' Writing Proficiency and Anxiety: Latent Growth Curve Modeling Approach,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were 274 undergraduate English learners in Iran enrolled in academic writing classes. The context is clearly L2 English (EFL) at a public university, and the focus is on English writing proficiency and anxiety.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses Gemini, explicitly described as a generative AI (GenAI) tool, in a treatment group receiving GenAI-assisted instruction versus a control group with traditional instruction. Gemini is a large language model, and the design is experimental with random assignment over a 16-week course.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on L2 writing competence and related affective variables: writing proficiency and writing anxiety in academic writing classes. Gemini is integrated into writing instruction, not just for scoring or system evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Quantifiable writing outcomes are reported: writing proficiency measured via a standardized rubric-based assessment, and writing anxiety via an L2 writing anxiety scale. The abstract reports statistical results (MD, SE, CR, p-values) for changes in these outcomes.""}}"
Exploring Factors Influencing L2 Learners' Use of Gai-assisted Writing Technology: Based on the Utaut Model,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The participants are 419 graduate students in China, described as L2 learners using GAI in second language writing. It is highly likely they are L2 English learners, but the target language is not explicitly stated in the title or abstract.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is framed with the UTAUT model and investigates factors influencing learners\u2019 usage behavior of GAI. It examines acceptance and use (behavioral intention, facilitating conditions) rather than implementing an experimental or quasi-experimental LLM-based writing intervention. No specific LLM tool or instructional treatment is described.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the context is L2 writing and GAI, the primary focus is on technology acceptance and usage behavior (PE, EE, SI, BI, FCs, AU), not on writing competence or writing-related performance variables. It is a technology adoption study rather than a pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported are behavioral intention and actual usage behavior, moderated by gender, experience, and proficiency. There are no quantifiable writing outcome metrics (e.g., writing quality scores, complexity, accuracy, fluency) assessing the effectiveness of GAI-mediated writing intervention.""}}"
Exploring Second Language Writers' Engagement with Chatgpt Feedback: Revision Behaviors and Perceptions,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 25 B1-level English as a Foreign Language (EFL) university students in T\u00fcrkiye, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""ChatGPT (an LLM) is used as a feedback tool on students\u2019 opinion essays, but the abstract does not specify an experimental or quasi-experimental design (e.g., control group, pre-post comparison, or structured intervention beyond a single use). It focuses on exploring engagement with feedback rather than testing an instructional intervention\u2019s effectiveness.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on L2 writing (opinion essays) and how students engage with ChatGPT-generated feedback on content, organization, and language use\u2014clearly centered on writing competence and writing-related processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Data sources include essay drafts, change tracker sheets, a questionnaire, and interviews. The analyses are described as descriptive and thematic, focusing on types of revisions, acceptance/rejection of feedback, and perceptions. There is no indication of quantifiable writing outcome metrics (e.g., pre-post writing scores, rubric-based gains) used to assess effectiveness of the LLM-mediated intervention.""}}"
Using Chatgpt to Bring Non-player Characters to Life: Effects on Students' Storyline-driven Game-based Writing Learning,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Chinese undergraduate students in English as a Foreign Language (EFL) writing classrooms, clearly indicating L2 English learners in an EFL context with a focus on English writing.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study integrates ChatGPT, an LLM, into a game-based learning environment via ChatGPT-powered NPCs. It uses a quasi-experimental design comparing a ChatGPT condition with a conventional NPC condition, constituting an LLM-mediated instructional intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is explicitly EFL writing classrooms, with the game designed to enhance argumentative writing skills. The primary focus is on writing learning and writing performance, not on automated scoring or system evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Student essays were evaluated to compare writing performance across conditions, and results report superior writing performance (clarity, elaboration, persuasiveness, addressing opposing viewpoints) in the ChatGPT condition, providing quantifiable writing outcome metrics.""}}"
Chinese Efl Learners' Genai Literacy in Digital Multimodal Composing and Self-regulated Writing: Chain Mediation Effects of Needs Satisfaction and Creative Self-concept,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as 634 Chinese EFL learners, which fits the target population of L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines students\u2019 GenAI literacy in digital multimodal composing via questionnaires and structural equation modeling. There is no indication of an experimental or quasi-experimental pedagogical intervention where LLMs (e.g., ChatGPT) are integrated into writing instruction or processes; rather, it is a correlational/mediation study of literacy and psychological variables.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on GenAI literacy, needs satisfaction, creative self-concept, and self-regulated writing, not on a concrete LLM-mediated writing intervention or instructional context. Writing competence is only indirectly referenced, and no specific LLM-based writing activity or instructional design is described.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are self-report questionnaire measures (GenAI literacy, needs satisfaction, creative self-concept, self-regulated writing). The abstract does not report any quantifiable writing performance metrics (e.g., text quality, accuracy, complexity) resulting from an LLM-mediated intervention.""}}"
Exploring the Effectiveness of a Ddl-genai Teaching Mode in Students' Efl Writing Classroom,2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 75 second-year Chinese university students in an EFL writing classroom, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract describes an innovative teaching mode integrating Data-Driven Learning with Generative Artificial Intelligence (GenAI), and mentions a separate GenAI class. However, it does not specify whether the GenAI tools are large language models (e.g., ChatGPT/GPT-like transformer-based generators) or other forms of AI. Without explicit mention of LLM-based tools, it is unclear if the intervention meets the LLM criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on EFL expository writing performance and related variables (structure, content quality, efficiency, classroom engagement) within a writing classroom, indicating a pedagogical writing intervention rather than automated scoring or non-instructional evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses a quasi-experimental design with three instructional modes and reports that the DDL-GenAI mode significantly improved students\u2019 writing performance, including specific aspects such as structure and content quality, indicating quantifiable writing outcome measures.""}}"
Students' Perceptions of Multiliteracies Development Using Ai-assisted Portfolio Assessment,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 50 freshmen students in an EFL classroom, indicating L2 English learners in an EFL context. The portfolios involve multimodal writing about touring route recommendations, implying English as the target language.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study is set in a \u201cGenAI-supported portfolio assessment classroom\u201d where students revise artefacts based on \u201cAI-generated feedback.\u201d Although the specific tool is not named, it is described as Generative AI, which reasonably implies an LLM-based system integrated into the writing/portfolio process.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on multiliteracies, multimodal competence, and portfolio-based formative assessment, not specifically on writing competence or writing-related variables as primary outcomes. The abstract emphasizes multiliteracies development, metacognitive development, and professional growth rather than writing proficiency.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study employs a qualitative design, collecting reflective journals, focus group interviews, and narrative inquiries, analyzed thematically. No quantifiable writing outcome metrics or experimental comparison are reported; outcomes are described qualitatively (e.g., stages of multiliteracies development, confidence, awareness).""}}"
"Impacts of Genai-assisted Collaborative Prewriting on University Efl Students' Interactions with Genai, Outline Quality, and Task Motivation",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were sixty-nine Chinese undergraduates in an English as a foreign language (EFL) writing context, clearly indicating L2 English learners.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study integrates a generative AI (GenAI) tool\u2014i.e., an LLM-based system\u2014into prewriting instruction via GenAI-assisted collaborative and individual prewriting, using a within-subjects comparative design.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary outcome is the quality of prewriting outlines (content, organization, language) and task motivation, not actual writing performance. The focus is on prewriting/planning and interaction with GenAI rather than on writing competence or writing-related performance measures (e.g., essay quality).""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Quantitative outcomes are reported for outline quality and task motivation, but no quantifiable metrics of written text (e.g., essays, compositions) are provided. The intervention outcomes do not include measurable L2 writing performance, which is required for inclusion.""}}"
"The Role of Generative Ai in Writing Doctoral Dissertation: Perceived Opportunities, Challenges, and Facilitating Strategies to Promote Human Agency",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly situates the work in ESL and EFL academic writing contexts and involves doctoral scholars and thesis supervisors, implying participants are L2 English users in higher education.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the study concerns GenAI-assisted dissertation writing, it is framed as an exploration of perceived usefulness and use, grounded in the Technology Acceptance Model. There is no indication of an experimental or quasi-experimental instructional intervention integrating a specific LLM into writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on perceived opportunities, challenges, and human agency in GenAI-assisted dissertation writing, not on a structured pedagogical intervention targeting writing competence. It is more about attitudes and conceptual discussion than a writing-focused instructional context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is described as qualitative, using survey and test data to explore perceptions. No quantifiable writing outcome metrics (e.g., writing scores, text quality measures) assessing the effectiveness of GenAI-mediated writing intervention are reported in the abstract.""}}"
Evaluating Chatgpt's Effectiveness in Enhancing Argumentative Writing: a Quasi-experimental Study of Efl Learners in Pakistan,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Pakistani students pursuing the Secondary School Certificate in an English as a Foreign Language (EFL) environment. The study explicitly focuses on English argumentative writing skills, satisfying the L2 English learner population requirement.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study evaluates the effectiveness of ChatGPT, explicitly identified as an artificial intelligence tool, in improving argumentative writing. It uses a quasi-experimental design with three months of ChatGPT interaction as the intervention, aligning with LLM-based writing instruction criteria.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on argumentative writing competence, including key components of argumentative writing and error types. ChatGPT is integrated as a pedagogical tool to enhance writing skills, not merely as an assessment engine.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses pre- and post-tests to measure changes in students' argumentative writing abilities and reports significant progress and decreased error types after the ChatGPT intervention, providing quantifiable writing outcome metrics.""}}"
Assessing the Reliability and Relevance of Deepseek in Efl Writing Evaluation: a Generalizability Theory Approach,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL learners: 92 CET-4 essays written by non-English majors at a Chinese university. The focus is clearly on English as a foreign language writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""DeepSeek-V3 and DeepSeek-R1 are used as automated raters to assess reliability of holistic scores and qualitative feedback, compared with teacher raters. There is no experimental or quasi-experimental instructional intervention integrating LLMs into writing instruction or writing processes; the focus is on assessment reliability.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on writing assessment reliability and feedback relevance (G-theory analysis of scores and feedback), not on a pedagogical intervention to improve writing competence. It functions as an automated essay scoring/feedback evaluation study, which falls under the exclusion criteria.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No writing outcome metrics for learners are reported. The study analyzes reliability coefficients and relevance of feedback, but does not measure changes in learners\u2019 writing performance following an LLM-mediated intervention.""}}"
Ai Partner Versus Human Partner: Comparing Ai-based Peer Assessment with Human-generated Peer Assessment in Examining Writing Skills,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL college students from the University of Diyala (Iraq) and the University of Hradec Kralove (Czech Republic). The abstract explicitly states the focus is on improving EFL college students\u2019 writing skills, indicating L2 English learners in EFL/ESL contexts.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention contrasts traditional peer assessment (group A) with AI-based assessment using ChatGPT (group B). ChatGPT is a large language model integrated into the peer assessment process, constituting an LLM-mediated instructional intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on writing skills and how different feedback mechanisms (human vs. AI-based via ChatGPT) affect EFL students\u2019 writing. The context is clearly pedagogical, centered on peer assessment to improve writing competence rather than automated scoring alone.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcomes: final writing scores for group A (7\u201314/15) and group B (6\u201312/15), and notes comparative improvement in writing skills. These numeric scores provide measurable writing outcome metrics for evaluating the LLM-mediated intervention.""}}"
"Integrating Flipped Learning in Ai-enhanced Language Learning: Mapping the Effects on Metacognitive Awareness, Writing Development, and Foreign Language Learning Boredom",2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as 70 intermediate Iranian EFL learners, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract repeatedly refers to an \u201cAI-enhanced\u201d flipped learning environment and \u201cAI-enhanced instruction,\u201d but does not specify the AI tool or whether it is an LLM (e.g., ChatGPT, GPT-4) versus other forms of AI (e.g., analytics, non-LLM feedback tools). Thus, it is not possible to confirm that an LLM is integrated into the writing instruction or process.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""Among the key variables examined is \u201cwriting development,\u201d and pre- and post-intervention writing tasks are used, indicating that writing competence is a primary focus alongside metacognitive awareness and boredom.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses pre- and post-intervention writing tasks and analyzes inter-group differences via ANCOVA, implying quantifiable writing outcome metrics to assess the impact of the AI-enhanced flipped learning intervention on writing development.""}}"
Exploring Teacher Perspectives on Gpt in L2 Disciplinary Academic Writing through the Lens of Feedback Literacy: a Q-methodology Approach,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The participants are 27 L2 university instructors, not L2 English learners. The focus is on teacher perspectives and feedback literacy, not on learner outcomes or learner data.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although GPT/LLMs are discussed, the study is not an experimental or quasi-experimental intervention integrating LLMs into learners\u2019 writing processes. It is a Q-methodology study of teacher perspectives, without an instructional treatment using LLMs.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The context is L2 disciplinary academic writing education and feedback practices, but the study examines perceptions and ethical/pedagogical considerations rather than a concrete writing intervention or measured changes in writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported. The study uses Q-sorts and interviews to capture subjective teacher perspectives, without assessing changes in student writing performance.""}}"
