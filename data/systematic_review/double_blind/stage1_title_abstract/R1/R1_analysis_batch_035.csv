Title,Year,Decision,Notes
Indocl: Benchmarking Indonesian Language Development Assessment,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are L2 learners of Indonesian: \u201cIndoCL corpus (Indonesian Corpus of L2 Learners), which comprises compositions written by undergraduate students majoring in Indonesian language.\u201d The target language is Indonesian, not English, so it does not match the review\u2019s focus on L2 English learners.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study explores \u201cthe feasibility of using existing large-scale language models (LLMs) for LDA tasks,\u201d but this is in the context of automated language development assessment, not an instructional or quasi-experimental pedagogical intervention in writing. It is unclear whether LLMs are integrated into teaching or writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is language development assessment (LDA) and benchmarking models for that task, not on writing instruction or improving writing competence. It is essentially an automated assessment/benchmarking study, not a pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported concern model performance on LDA tasks (\u201cremarkable performance on both our self-constructed corpus and publicly available corpora\u201d), not quantifiable effects of an LLM-mediated writing intervention on learners\u2019 writing quality. No experimental instructional outcomes are described.""}}"
Exploring the Influence of Ai and Chatgpt on University Efl Learners,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are clearly described as university-level English as a Foreign Language (EFL) learners, i.e., L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study explicitly investigates the use of ChatGPT (an LLM) and other AI tools in an experimental design with experimental and control groups, integrating AI-powered customized learning and feedback into instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary outcome is grammatical proficiency and grammatical accuracy, with a secondary focus on related language skills. Writing is only used as a vehicle for reflective essays to capture perceptions, not as the main instructional or assessment focus. The context is grammar learning, not writing competence or writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Quantitative outcomes reported concern grammatical competence and grammatical accuracy, not writing performance metrics. Reflective essays are used qualitatively to explore perceptions, not to measure changes in writing quality. Thus, no quantifiable writing outcome metrics are reported.""}}"
Students’ Engagement in Seeking and Accepting Chatgpt Feedback in Essay Writing: a Study of Second Language Learners at Varying Proficiency Levels,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The title and abstract indicate the participants are second language learners engaged in academic English writing, which aligns with L2 English learners in an ESL/EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used as a feedback tool, the study is described as a case study focusing on utilization patterns, human-computer interaction, and interviews. There is no indication of an experimental or quasi-experimental design testing an instructional intervention; it is exploratory/descriptive.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly L2 academic English essay writing and the use of ChatGPT feedback during the writing process, which is directly related to writing competence and writing processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports qualitative findings about metacognitive strategies and perceptions at different proficiency levels. It does not mention any quantifiable writing outcome measures (e.g., scores, accuracy, complexity) to assess the effectiveness of ChatGPT-mediated intervention.""}}"
"The Effects of a Quillbot-based Intervention on English Language Majors’ Efl Writing Performance, Apprehension, and Self-efficacy",2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 18 fourth-year students majoring in English in the English Language Department at Matrouh University, explicitly described as EFL learners. The focus is on EFL writing performance, so the population criterion is satisfied.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is explicitly described as a \u201cQuillBot-based intervention.\u201d QuillBot is an AI-powered writing assistant primarily known as a paraphrasing and grammar tool and is not clearly an LLM-based, transformer generative model in the sense required (e.g., ChatGPT, GPT-4, Gemini). The abstract does not indicate integration of a large language model; it only mentions AI-generated feedback via QuillBot, which falls under excluded tools per the guidelines.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on EFL writing performance and related affective variables (writing apprehension and self-efficacy). The intervention involves drafting, receiving AI-generated feedback, revising, and producing final drafts, which is clearly a writing instruction/writing process context rather than automated essay scoring.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses a pre/post design with \u201cone test and two scales\u201d administered before and after the intervention to measure writing performance, apprehension, and self-efficacy. It reports \u201csignificant positive effects\u201d on writing performance, indicating quantifiable outcome metrics for the writing intervention.""}}"
Developing an Ai-enhanced Video Drama-making Learning System to Support Efl Learners in Authentic Contexts,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL university students, clearly L2 English learners in an EFL context: \u201cimprove English as a Foreign Language (EFL) learning\u2026 involving sixty-three university students.\u201d""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The system uses \u201cGPT-generated sentences,\u201d which suggests an LLM-based component, but the abstract does not specify whether this is a large language model (e.g., GPT-3/4) or how it is integrated pedagogically into instruction versus as a background feature.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on an AI-enhanced video drama-making system and its evaluation via the Technology Acceptance Model (TAM), emphasizing usability, usefulness, and attitudes. Writing is mentioned only briefly (\u201cenhancing their speaking and writing skills\u201d) without clear indication that writing competence or writing-related variables are the main focus of the intervention or analysis.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are TAM constructs (usability, usefulness, attitudes). The abstract does not report any quantifiable writing outcome metrics (e.g., writing scores, text quality measures) to assess the effectiveness of the AI/LLM component on writing performance.""}}"
Exploring the Impact of Ai in Language Education: Vietnamese Efl Teachers’ Views on Using Chatgpt for Fairy Tale Retelling Tasks,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Vietnamese tertiary-level English as a Foreign Language (EFL) teachers discussing students\u2019 fairy tale retelling writing tasks in English, which fits an EFL/ESL/ELL context focused on English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is the focal technology, the study is purely qualitative and perception-based, using semi-structured interviews with teachers. There is no experimental or quasi-experimental design implementing ChatGPT as an actual classroom writing intervention with measured effects.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context explicitly involves students\u2019 fairy tale retelling writing tasks, which are writing-focused. The article examines how ChatGPT might be integrated into these writing activities, aligning with writing competence and writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports only qualitative perceptions (challenges and opportunities) from teachers. It does not report any quantifiable writing outcome metrics or measured changes in students\u2019 writing performance resulting from an LLM-mediated intervention.""}}"
Synergizing Generative Pre-trained Transformer (gpt) Chatbots in a Process-based Writing Paradigm to Enhance University Students’ Writing Skill,2024,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as 'university EFL students,' indicating learners of English as a foreign language. The focus of the study is on their English writing skills (organization, content, coherence-cohesion, logical connection, argumentation), satisfying the requirement that the target language is English in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention is 'a GPT-based chatbot within a process-based writing framework.' GPT-based chatbots are large language models (Generative Pre-trained Transformer). The study uses a pre- and post-test design with 10 instructional sessions integrating the GPT chatbot into the writing process, meeting the criterion of an experimental/quasi-experimental LLM-mediated writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on enhancing 'students\u2019 writing skills' within a 'process-based writing framework,' guiding learners through planning, drafting, revising, and editing. The outcomes and discussion center on writing performance and components of writing quality, not on automated scoring or system evaluation, aligning with a pedagogical writing intervention context.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantitative writing outcomes: pre- and post-writing test scores (mean scores 9.13 vs. 17.03) and progression across four writing quizzes for specific writing components (organization, content, coherence-cohesion, logical connection, argumentation). These provide measurable writing outcome metrics, in addition to qualitative data.""}}"
L2 Students’ Barriers in Engaging with Form and Content-focused Ai-generated Feedback in Revising Their Compositions,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are described as 'Forty-five L2 students in a computer science program' writing argumentative essays in English, fitting an L2 English learner population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used to provide corrective feedback, the study is observational/analytic: students were 'tasked with seeking corrective feedback from ChatGPT' and their revisions and rationales were analyzed. There is no experimental or quasi-experimental intervention design comparing conditions or measuring treatment effects.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is L2 writing revision: students used ChatGPT feedback on their argumentative essays, and the study focuses on engagement with form- and content-focused feedback in revising compositions, which is directly writing-related.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports proportions of feedback accepted, argued, or ignored and reasons for non-uptake, but does not mention any quantifiable writing outcome metrics (e.g., changes in writing scores, accuracy, complexity) to assess effectiveness of the LLM-mediated intervention.""}}"
Enhancing English Writing Courses in the Uae: the Potential of Generative Ai Tools,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 38 postgraduate students in the UAE who are described as non-native English speakers, indicating an L2 English learner population in an English writing course context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the study discusses generative AI tools such as ChatGPT, it is framed as an exploratory, qualitative investigation of potential challenges and possibilities. There is no indication of an experimental or quasi-experimental intervention design integrating LLMs into instruction or writing processes.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is explicitly English writing courses in the UAE, focusing on how generative AI might be incorporated into English writing classes and its implications for writing skills and student growth.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The methodology is qualitative, using open-ended questions and thematic analysis. The abstract does not report any quantifiable writing outcome metrics or experimental measures of writing performance; it focuses on perceptions, challenges, and recommendations.""}}"
Korean-as-a-foreign-language Learners’ Engagement with Machine Translation Output,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are US university students learning Korean as a foreign language. The target language is Korean, not English, and the context is not ESL/EFL/ELL focused on English.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to 'machine translators and other artificial intelligence-assisted programs' but does not specify that these are LLM-based (e.g., ChatGPT, GPT-4). It could be conventional MT systems like Google Translate, which are not necessarily LLMs.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study examines how learners use machine translators to revise their writing and analyzes their engagement and revision strategies, focusing on writing processes and incorporation of MT output as feedback.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""This is described as an exploratory case study focusing on cognitive and behavioral engagement and revision strategies. There is no indication of experimental or quasi-experimental design with quantifiable writing outcome metrics assessing intervention effectiveness.""}}"
Exploring Interrelationships among L2 Writing Subskills: Insights from Cognitive Diagnostic Models,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 500 English as a foreign language (EFL) students, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses cognitive diagnostic models (G-DINA, DINA, DINO, A-CDM, LLM, RRUM) to analyze writing subskills. Here, 'LLM' refers to a log-linear model within CDMs, not a transformer-based large language model used as an instructional tool. No LLM-based writing intervention is described.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on modeling interrelationships among L2 writing subskills using diagnostic psychometric models, not on a pedagogical intervention or instructional use of any LLM in writing processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although writing performance data are analyzed, there is no experimental or quasi-experimental intervention involving an LLM, and no comparison of writing outcomes across LLM-mediated conditions. The study is diagnostic/analytical rather than an intervention study.""}}"
Efl Teachers’ Perceptions of the Use of an Ai Grading Tool (cograder) in English Writing Assessment at Saudi Universities: an Activity Theory Perspective,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL teachers at Saudi universities, working with English as a Foreign Language learners. The context is clearly EFL with English as the target language.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines teachers\u2019 beliefs about an AI grading tool (CoGrader) used for essay scoring and feedback. There is no indication that CoGrader is an LLM-based tool (e.g., ChatGPT-like transformer-based generative model), nor that it is integrated as an instructional intervention; it is framed as scoring software.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on assessment\u2014teachers\u2019 perceptions of an AI grading tool for essay scoring and feedback. It does not describe a pedagogical writing intervention or instructional use aimed at improving writing competence; rather, it evaluates grading support.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports teachers\u2019 beliefs and perceptions via questionnaires and interviews. It does not report quantifiable student writing outcome measures or experimental effects of an AI-mediated writing intervention on learners\u2019 writing performance.""}}"
Crafting with Ai: Personalized Pathways to Boost Critical Language Awareness and Spark Creativity in Writing through Digital Adaptive Learning,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cL2 learners\u201d and \u201clanguage learning contexts\u201d but does not specify that the target language is English (ESL/EFL/ELL). The population could be English learners, but this is not explicit from the title or abstract.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is an \u201cautomated writing application equipped with adaptive learning (AL) strategy.\u201d There is no indication that this tool is a large language model (e.g., ChatGPT, GPT-4, Gemini) or transformer-based generative model. It is described in terms of adaptive learning, individualized instruction, and feedback, which are typical of non-LLM adaptive systems.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on enhancing writing skills and related constructs (critical language awareness and creativity) through an automated writing application. Writing proficiency and accuracy are central outcomes, indicating a writing-focused pedagogical context rather than automated scoring or system evaluation alone.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantitative outcomes: it compares writing outcomes between an experimental and control group and notes significant improvement in writing skills, accuracy, and language proficiency. These are quantifiable writing-related measures derived from writing tasks and questionnaires.""}}"
Understanding Chinese University Efl Learners’ Perceptions of Ai in English Writing,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 140 Chinese university EFL learners in a Chinese university setting, clearly an EFL context with English as the target language.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines perceptions of Grammarly, which is not described as an LLM-based tool and is treated broadly as \u2018AI\u2019. There is no indication of an experimental or quasi-experimental design integrating an LLM (e.g., ChatGPT, GPT-4) into writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on learners\u2019 perceptions and technology acceptance (TAM constructs) regarding Grammarly, not on a structured pedagogical writing intervention or development of writing competence. It is attitudinal rather than instructional in focus.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes are behavioral intention and perceptions (ease of use, usefulness, enjoyment, task relevance). No quantifiable writing performance or writing-related outcome measures are reported.""}}"
Ai-enhanced Video Drama-making for Improving Writing and Speaking Skills of Students Learning English as a Foreign Language,2024,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 77 university students learning English as a Foreign Language (EFL). The context is clearly EFL, and the outcomes discussed (writing and speaking skills) are in English.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention uses an AI-enhanced video drama (AI-EVD) application that incorporates GPT-generated sentences, explicitly referencing a generative pretrained transformer. The design is experimental with an experimental group using the AI features and two control groups (app without AI and conventional learning).""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus includes improving EFL writing (and speaking) skills. AI is used to provide lexical resources (vocabulary and sentence structures) to support students\u2019 writing in the drama-making process, aligning with writing instruction and writing processes rather than automated scoring.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports learning achievement outcomes and uses correlation and regression analyses to link specific AI-mediated behaviors (e.g., GPT-generated sentences) to improvements in writing and speaking skills. These constitute quantifiable writing outcome metrics within an experimental framework.""}}"
Investigating Generative Ai Models and Detection Techniques: Impacts of Tokenization and Dataset Size on Identification of Ai-generated Text,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Although the abstract mentions that detectors show reduced reliability for English as a Second Language learners, the study itself uses data from prompt 1 of the ASAP Kaggle competition and focuses on AI vs. human text detection. There is no indication that the participants are L2 English learners in ESL/EFL/ELL contexts, nor that the primary data are from such learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Generative AI models (ChatGPT, Claude, Gemini) are included only as sources of AI-generated text for detection experiments. The study does not describe an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or learners\u2019 writing processes; it is a detection/cheating-identification study.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on detecting AI-generated or AI-paraphrased text in high-stakes writing assessments using machine learning and LLM-based detectors. It does not investigate writing competence or writing-related pedagogical variables; instead, it evaluates detection techniques and model performance.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity) are reported. Outcomes concern detection accuracy and model performance, not the effectiveness of an LLM-mediated writing intervention on learners\u2019 writing.""}}"
Chatgpt for Language Learning: Assessing Teacher Candidates’ Skills and Perceptions Using the Technology Acceptance Model (tam),2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL teacher candidates performing tasks in Spanish (L1) and English (L2), so they are L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT-4 is used to generate machine-written samples that participants compare and evaluate. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating ChatGPT into their own writing instruction or writing process; it is used as material for critical evaluation, not as an instructional writing tool.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on critical skills in distinguishing human vs. machine-generated texts and perceptions of ChatGPT (TAM constructs), not on improving writing competence or writing-related performance through an LLM-mediated intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although text analysis metrics (SC, ASL, VOCD) are reported, they are used to compare human and machine texts, not as outcome measures of a writing intervention\u2019s effect on learners\u2019 writing. The main outcomes are critical discrimination skills and perceptions, not changes in learners\u2019 writing performance.""}}"
"Comparing Peer, Chatgpt, and Teacher Corrective Feedback in Efl Writing: Students’ Perceptions and Preferences",2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as EFL students, i.e., learners of English as a foreign language, so the population consists of L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention includes an AI tool identified as ChatGPT, a large language model, used to provide written corrective feedback on students\u2019 writing as part of the study design.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is EFL writing: students complete a short writing task, receive written corrective feedback (peer, ChatGPT, teacher), and revise their writing. The focus is on writing skills and feedback practices, not on automated scoring.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract states that a qualitative approach via survey analysis was used to explore students\u2019 perceptions and preferences. It does not report quantitative writing outcome measures (e.g., scores, accuracy gains) to assess effectiveness of the LLM-mediated intervention; revisions are mentioned but not as measured outcomes. Thus, it lacks quantifiable writing outcome metrics.""}}"
An Analysis on the Implementation of Artificial Intelligence (ai) to Improve Engineering Students in Writing an Essay,2024,unsure,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions \u2018formal EFL essay elements\u2019 and \u2018engineering students,\u2019 suggesting they may be English as a Foreign Language learners, but it does not explicitly state that participants are L2 English learners in ESL/EFL/ELL contexts. The institutional or linguistic context is not clearly described.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study refers broadly to \u2018Artificial Intelligence (AI) technologies, such as chatbots, Natural Language Processing (NLP), and Sentiment Analysis\u2019 and \u2018the use of artificial intelligence to improve writing skills.\u2019 It does not specify whether the intervention uses a large language model (e.g., ChatGPT/GPT-based chatbot) versus non-LLM NLP tools. The VAN framework is mentioned but not explained in terms of underlying AI architecture.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on \u2018improving student writing skills in engineering,\u2019 examining \u2018formal EFL essay elements, including content and language, in terms of comprehension and production,\u2019 and \u2018the flow of information among the participants in essay writing.\u2019 This aligns with writing competence and writing-related variables in an educational context.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses a mixed-method approach with a control group of essays (224 essays from 52 students) and compares essay elements (content and language). This implies quantifiable writing outcome metrics (e.g., evaluation of essay content/language) to assess the impact of AI-supported writing, even though specific metrics are not detailed in the abstract.""}}"
Utilizing an Adaptable Artificial Intelligence Writing Tool (chatgpt) to Enhance Academic Writing Skills among Yemeni University Efl Students,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Yemeni university EFL learners, clearly L2 English learners in an EFL context: \u201cYemeni EFL learners at the university level.\u201d""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is the focus, the study is not an experimental or quasi-experimental intervention. It is a perception survey about using ChatGPT, with no structured instructional treatment or controlled integration into writing instruction or processes.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is academic writing: \u201cAI-based writing tool in academic writing\u2026 improved their writing fluency, accuracy, and overall quality of their academic work.\u201d The primary focus is writing competence, not automated scoring.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses surveys and reports perceived improvements; there is no mention of quantifiable writing outcome metrics (e.g., pre/post writing scores, rubric-based assessments). Outcomes are self-reported perceptions, not measured writing performance.""}}"
