Title,Year,Decision,Notes
"Learner Interaction With, and Response To, Ai-programmed Automated Writing Evaluation Feedback in Efl Writing: an Exploratory Study",2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are five Chinese university-level English as a foreign language (EFL) students, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses Pigai, described as an AI-programmed automated writing evaluation (AWE) system. Pigai is a traditional AWE tool, not identified as a large language model (e.g., ChatGPT, GPT-4, Gemini). The study focuses on interaction with AWE feedback, not an LLM-based generative system.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is EFL writing and student interaction with automated writing evaluation feedback, which is directly related to writing processes and writing pedagogy.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is described as an exploratory analysis of how students interact with Pigai feedback and their response patterns. The abstract does not report quantifiable writing outcome metrics (e.g., pre/post writing scores, quality ratings); it focuses on interaction patterns and take-up rates of feedback types, not on measured changes in writing competence.""}}"
Efl Teachers' Perceptions of the Use of an Ai Grading Tool (cograder) in English Writing Assessment at Saudi Universities: an Activity Theory Perspective,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are EFL teachers (n=10) at Saudi universities, not L2 English learners. The focus is on teachers\u2019 beliefs, not learner outcomes.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines perceptions of an AI grading tool (CoGrader) for essay scoring and feedback. There is no indication that it is an LLM-based tool (e.g., ChatGPT/GPT-4) or that it is integrated as an instructional writing intervention in an experimental/quasi-experimental design.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on assessment (AI grading) and teachers\u2019 beliefs, not on a pedagogical writing intervention aimed at improving learners\u2019 writing competence. It evaluates CoGrader as a scoring/feedback tool rather than as part of a structured instructional context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable learner writing outcomes are reported. The study uses questionnaires and interviews about teacher perceptions; there is no experimental measure of changes in students\u2019 writing performance due to an LLM-mediated intervention.""}}"
Indonesian University Students' Perspectives on Integrating Aied into English Language Learning,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Indonesian university students using AIEd for English language learning, which fits an EFL/ELL context focused on English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a quantitative survey of perceptions of AIEd tools. It does not describe an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes, nor does it specify that the listed tools are LLM-based.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although writing-related features (translation, grammar checkers, paraphrasers, idea generators, citation management) are mentioned in the questionnaire, the study\u2019s primary focus is on general perceptions of AIEd in English learning, not on a writing-focused pedagogical intervention or writing competence outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are perception indices (e.g., positive/negative perceptions) based on TAM constructs. No quantifiable writing performance or writing-related competence measures are reported to assess effectiveness of an LLM-mediated writing intervention.""}}"
"Chatgpt Is Powerful, but Does It Have Power Distance? a Study of Culturally Imbued Discourse in Ai-generated Essays",2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The study compares 200 essays written by ChatGPT with 200 essays written by L1-English university learners. There is no mention of L2 English learners, ESL/EFL/ELL contexts, or second language writers; the human comparison group is explicitly L1-English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is used to generate essays for comparison with human texts, but there is no experimental or quasi-experimental pedagogical intervention integrating ChatGPT into writing instruction or learners\u2019 writing processes. It is a corpus/comparative study of discourse features, not an instructional intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on culturally imbued discourse (power distance) in AI-generated versus human essays, examining formulaic language (stances, modals, pronoun deixis). It does not study writing competence development or a teaching/learning context; rather, it evaluates linguistic characteristics of outputs.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although quantitative analyses (Wilcoxon tests) are reported, they concern linguistic feature frequencies in ChatGPT vs. L1 essays, not writing outcomes of an LLM-mediated intervention for learners. No learner performance or improvement metrics are provided.""}}"
Investigating the Accuracy of Chatgpt as a Writing Error Correction Tool,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions ESL learners in a general sense but does not clearly state that actual L2 English learners participated as subjects; it instead refers to pre-created data sets. It is unclear whether the data are authentic learner texts or constructed examples, and whether any learner participants are involved.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used, the study is framed as an evaluation of ChatGPT\u2019s accuracy as an error correction tool using pre-created data sets and computational processing. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating ChatGPT into writing instruction or learners\u2019 writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on ChatGPT\u2019s error detection and correction performance across error categories, not on developing or assessing learners\u2019 writing competence through an instructional context. This is a tool-functionality evaluation rather than a writing intervention study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported are accuracy levels of ChatGPT across error categories (high, moderate, low), not quantifiable changes in learners\u2019 writing performance following an LLM-mediated intervention. No experimental measures of learner writing outcomes are described.""}}"
Enhancing L2 Writing Skills: Chatgpt as an Automated Feedback Tool,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Turkish pre-service teachers of English in an academic writing course, clearly functioning as L2 English learners in an EFL/ESL higher education context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study explicitly investigates ChatGPT, an AI-powered large language model, used as an automated feedback tool for L2 writing in an academic writing course. This constitutes an LLM-based writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is L2 academic writing, focusing on ChatGPT as a feedback tool to support the L2 writing process. The primary emphasis is on writing and writing-related support, not on assessment-only or non-pedagogical use.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The methodology describes focus-group interviews and thematic analysis of perceptions regarding ChatGPT feedback. The abstract reports only qualitative findings about affordances and constraints, with no mention of quantitative or experimental writing outcome measures (e.g., changes in writing scores, accuracy, complexity).""}}"
The Differential Role of Ai-operated Wcf in L2 Students' Noticing of Errors and Its Impact on Writing Scores,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were 75 university undergraduate EFL students, clearly indicating L2 English learners in an EFL context. Writing tasks were IELTS Task 2 argumentative prompts, which are English writing tasks.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The AI tools used are Grammarly and E-rater. These are automated writing evaluation/correction systems and are not described as large language models or transformer-based generative models (e.g., ChatGPT, GPT-4). The intervention is AI-operated WCF but not LLM-based.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on written corrective feedback during and after writing, using argumentative IELTS prompts, and examines its impact on writing scores and noticing of errors. The primary context is writing competence and writing-related variables.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly mentions investigating the impact of feedback modes and timing on writing scores, implying quantifiable writing outcome measures in a quasi-experimental design with four feedback conditions.""}}"
"Which One? Ai-assisted Language Assessment or Paper Format: an Exploration of the Impacts on Foreign Language Anxiety, Learning Attitudes, Motivation, and Writing Performance",2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were 70 intermediate English learners at Bangladeshi universities, clearly an EFL/ESL context with English as the target language.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is described only as 'AI-assisted language assessment.' No indication is given that the AI is a large language model (e.g., ChatGPT, GPT-4) or that it involves transformer-based generative text. It appears to be an assessment tool rather than an LLM-based writing assistant.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""Writing skills are a primary outcome, measured via the TOEFL iBT writing section, and the study compares AI-assisted versus paper-format assessment in relation to writing performance and affective variables.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports pretest and posttest writing abilities using TOEFL iBT writing scores, providing quantifiable writing outcome metrics, even though posttest differences were not statistically significant.""}}"
Examining Ai-based Accuracy Assessment in L2 Learners' Writing,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract refers to 'L2 learners' writing' and 'EFL learners', indicating a population of English L2 learners in an EFL/ESL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is used solely as an evaluator of writing accuracy, compared to human raters. There is no experimental or quasi-experimental instructional intervention integrating the LLM into the writing process or teaching; it is a rater-functionality study.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on the performance of ChatGPT as an accuracy assessor (automated scoring/feedback function) and its correlation with human ratings, not on a pedagogical writing intervention or instruction aimed at improving writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports correlations between ChatGPT and human ratings but does not implement an LLM-mediated writing intervention or measure pre/post changes in learners\u2019 writing outcomes as a result of such an intervention.""}}"
Strategic Use of Machine Translation: a Case Study of Japanese Efl University Students,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Japanese EFL university students at CEFR A2 level, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention focuses on the use of machine translation (MT) in L2 writing. The abstract does not indicate that the MT system is an LLM-based generative model (e.g., ChatGPT, GPT-4). It is framed as generic MT use, not as an LLM-integrated writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study explicitly examines L2 writing with MT, focusing on learners\u2019 strategies and engagement in the L2 writing process, which is a writing-related context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is described as a qualitative case study exploring strategy use and changes after instruction. Outcomes reported are increases in strategy use and cognitive engagement, not quantifiable writing performance metrics (e.g., scores, accuracy, complexity).""}}"
Incorporating Ai in Foreign Language Education: an Investigation into Chatgpt's Effect on Foreign Language Learners,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""Participants are described as \u2018preparatory class students studying at the School of Foreign Languages at a university in Turkey.\u2019 The target language is not explicitly stated as English in the title or abstract; it is only referred to as \u2018foreign language education,\u2019 so it is unclear whether they are L2 English learners.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study \u2018aimed to utilize ChatGPT in foreign language education\u2019 and students were \u2018introduced to ChatGPT through learning experiences over a span of four weeks.\u2019 ChatGPT is an LLM and is integrated into instruction, satisfying the LLM-based intervention requirement, even though the design is qualitative case study rather than experimental.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The abstract notes that ChatGPT \u2018positively affects students' learning experiences, especially in writing, grammar, and vocabulary acquisition,\u2019 and mentions \u2018various learning activities.\u2019 Writing is a primary focus area among the reported effects, so the context includes writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is explicitly a \u2018qualitative case study\u2019 with data from interviews analyzed via thematic analysis. The abstract reports perceived effects (e.g., \u2018positively affects students' learning experiences\u2019) but does not indicate any quantitative or experimental writing outcome measures. Thus, it does not meet the requirement for quantifiable writing outcome metrics.""}}"
Leveraging Chatgpt in the Writing Classrooms: Theoretical and Practical Insights,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers broadly to 'second language (L2) writing pedagogy' but does not specify that the target L2 is English or that participants are ESL/EFL/ELL learners. It appears conceptual rather than reporting on a specific learner population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The paper is described as exploring the potential of integrating ChatGPT into L2 writing pedagogy and discussing integration across stages of the writing process. However, it is presented as theoretical and practical insights, not as an experimental or quasi-experimental study implementing an LLM-based intervention with participants.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the focus is on L2 writing pedagogy and the writing process, the article is conceptual (theoretical frameworks, challenges, recommendations) rather than an empirical pedagogical intervention study with implemented instructional context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or empirical assessment of writing performance. It offers recommendations and theoretical discussion without reporting measured effects of an LLM-mediated writing intervention.""}}"
"Teacher- Versus Ai-generated (poe Application) Corrective Feedback and Language Learners' Writing Anxiety, Complexity, Fluency, and Accuracy",2024,unsure,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201clanguage learners\u201d and \u201cundergraduate language learners at East China University of Political Science and Law,\u201d which strongly suggests EFL learners in China, but it never explicitly states that the target language is English. The mention of \u2018primary school settings\u2019 at the end further confuses the context. Thus, it is likely but not certain that these are L2 English learners.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The intervention uses an \u201cAI-driven application called Poe\u201d to provide corrective feedback. However, the abstract does not specify whether Poe is using a large language model (e.g., GPT-based, transformer generative model) or some other AI technology. Without confirmation that Poe is LLM-based, it is unclear whether this meets the LLM criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on writing-related variables: writing anxiety, complexity, fluency, and accuracy. The AI tool is integrated as corrective feedback within a writing task, and the primary outcomes are writing competence and related affective variables, not automated scoring or system evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""A quasi-experimental pretest\u2013posttest design with three groups (teacher CF, AI CF, no feedback) is used. Quantitative outcomes include writing complexity, fluency, accuracy, and writing anxiety, analyzed via one-way ANOVA. These are clear, quantifiable writing-related outcome measures of the AI-mediated intervention.""}}"
Exploratory Study on the Potential of Chatgpt as a Rater of Second Language Writing,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Korean secondary-level EFL students writing English essays, clearly fitting an L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT (GPT-4) is used as an automated writing evaluation (AWE) scoring tool, not as part of an instructional or experimental writing intervention. The focus is on rating reliability, not on integrating LLMs into writing instruction or processes for learning.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on assessment\u2014comparing ChatGPT\u2019s essay scores with human raters\u2014rather than on improving writing competence or implementing a pedagogical writing intervention. It is essentially an AWE/automated scoring validity study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No intervention or pre/post or comparative writing outcome measures are reported. The only quantitative outcomes are reliability/fit indices (intraclass correlation, Rasch model) for scoring, not measures of changes in learners\u2019 writing performance due to LLM-mediated instruction.""}}"
Facilitating Learners' Self-assessment during Formative Writing Tasks Using Writing Analytics Toolkit,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions \u201clearners\u201d but does not specify that they are L2 English learners in ESL/EFL/ELL contexts, nor that the target language is English. Their linguistic background and language of writing are not stated.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is a \u201cwriting analytics toolkit\u201d using \u201cdata visualisation and cutting-edge machine learning technology\u201d to provide feedback. There is no indication that it is based on large language models (e.g., ChatGPT, GPT-4, transformer-based generative models). It appears to be an analytics/ML feedback tool rather than an LLM-integrated writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on formative writing tasks, self-assessment of writing products, and monitoring writing processes. The toolkit is used during revision of written texts, so the primary focus is on writing-related competence and processes.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable outcomes: learners\u2019 self-assessment accuracy and processes of self-assessment were compared between experimental and control groups, and the toolkit\u2019s effect on self-assessment accuracy is reported. These are structured, measurable outcomes related to writing assessment processes.""}}"
The Effect of Chatgpt-integrated English Teaching on High School Efl Learners' Writing Skills and Vocabulary Development,2024,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 10th grade Turkish EFL learners in English lessons, clearly an EFL context with English as the target language: \u201c10th grade Turkish EFL learners' writing skill and vocabulary development.\u201d""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention explicitly integrates ChatGPT, a large language model, into English lessons: \u201cChatGPT-integrated English lessons\u2026 the experimental group took ChatGPT-integrated vocabulary and writing instruction whereas the control group took traditional instruction,\u201d indicating an experimental design using an LLM in instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on writing competence and related variables: \u201caims to explore the effect of ChatGPT-integrated English lessons on\u2026 writing skill and vocabulary development.\u201d ChatGPT is used pedagogically in writing instruction, not merely for automated scoring.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses pre- and post-tests and statistical analysis to measure outcomes: \u201cparticipated in the study by taking place in experimental phase and completing pre- and post-tests\u2026 The results of pre- and post-tests showed that the traditional instruction had more effect on writing and vocabulary development,\u201d indicating quantifiable writing outcome metrics.""}}"
Potentials and Implications of Chatgpt for Esl Writing Instruction,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The article is a systematic review/meta-analysis of prior research on ChatGPT for L2 writing, not an empirical study with its own participant sample of L2 English learners. Thus, it does not itself report primary data from a defined L2 English learner population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses a systematic review design to synthesize research on ChatGPT\u2019s educational potentials. It does not implement an experimental or quasi-experimental LLM-based writing intervention itself; it is a secondary study.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on implications of ChatGPT for L2 composition and writing instruction, discussing how ChatGPT can enhance L2 writing instruction and its practical applications in L2 writing classes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although it mentions a meta-analysis of 42 articles, the abstract does not report primary, study-level quantitative writing outcomes from an intervention conducted by the authors. As a review/meta-analysis, it falls under the exclusion criteria for non-primary research.""}}"
Enhancing English as a Foreign Language (efl) Learners' Writing with Chatgpt: a University-level Course Design,2024,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as university-level English as a Foreign Language (EFL) learners, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study integrates OpenAI\u2019s GPT-3.5 (an LLM) into a university-level EFL writing course, framed within ADDIE and TPACK. GPT-3.5 is used to provide feedback, generate ideas, and act as a peer reviewer, indicating an instructional intervention using an LLM.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is explicitly an EFL writing course, focusing on academic writing, organization, feedback, and writing proficiency. The emphasis is on writing instruction and writing-related variables, not on automated scoring.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract reports that GPT-3.5 enhances efficiency, cohesion, and serves as a substitute for peer reviewers, and that it promotes writing proficiency. However, it does not specify any experimental or quasi-experimental design, control/comparison, or quantifiable writing outcome metrics; it may be descriptive/course design rather than outcome-based. Without explicit mention of measured writing scores or other quantitative outcomes, eligibility is uncertain.""}}"
Generating Genre-based Automatic Feedback on English for Research Publication Purposes,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers broadly to \u201cL2 writers\u201d and \u201cmultilingual classrooms\u201d and to English for research publication purposes, but does not specify participant characteristics or whether any empirical learner data were collected. It is unclear if actual L2 English learners participated in a study or if this is purely a tool-development paper.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the paper describes developing an AI-mediated L2 writing technology that leverages large language models and genre-based instruction, the abstract focuses on system development and evaluation (accuracy, precision, recall of network classification). There is no indication of an experimental or quasi-experimental pedagogical intervention where LLMs are integrated into instruction with learners as participants.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on generating genre-based automatic feedback and evaluating the classification network\u2019s performance, not on an implemented writing intervention or instructional context. It is essentially an automated writing evaluation/tool-development study rather than a pedagogical study of writing competence outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Reported outcomes are technical metrics (accuracy, precision, recall) of the classification network. The abstract does not report any quantifiable learner writing outcomes (e.g., changes in writing quality, complexity, accuracy) resulting from LLM-mediated intervention with learners.""}}"
A Study on Chatgpt-4 as an Innovative Approach to Enhancing English as a Foreign Language Writing Learning,2024,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 76 undergraduate students in Algeria learning English as a Foreign Language (EFL). The abstract explicitly focuses on EFL writing, indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention is the use of ChatGPT-4, explicitly named, which is a large language model. An experiment with experimental and control groups was conducted to investigate its use in students\u2019 EFL writing, indicating an experimental design integrating an LLM into writing learning.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study\u2019s focus is on EFL writing learning and how ChatGPT-4 helps students address challenges in EFL writing and put what they learn about EFL writing into practice. The primary outcome is writing skills, not automated scoring or system evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract reports that the experimental group outperformed the control group and that post-test scores exceeded pre-test scores, indicating quantifiable writing outcome measures. Additional questionnaire data on perceptions is secondary to these measured writing outcomes.""}}"
