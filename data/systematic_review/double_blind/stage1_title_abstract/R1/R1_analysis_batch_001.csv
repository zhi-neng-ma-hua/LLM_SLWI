Title,Year,Decision,Notes
Same Assignment-two Different Feedback Contexts: Lower Secondary Students' Experiences with Feedback during a Three Draft Writing Process,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""Participants are described as lower secondary students in English as a foreign language (EFL) classes, which suggests they are L2 English learners. However, the abstract does not explicitly state their L1 or confirm that English is a second/foreign language for all participants, though this is strongly implied by the EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study contrasts AI-generated feedback with peer feedback, but the abstract does not specify what AI system is used, nor whether it is a large language model (e.g., ChatGPT, GPT-4). It could be a non-LLM feedback tool. Without explicit mention of an LLM or transformer-based generative model, it is unclear whether it meets the LLM criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is a three-draft writing process in EFL classes, with feedback (AI-generated vs. peer) integrated into the drafting process. The focus is on writing processes and feedback literacy in writing, which aligns with writing-related variables in an instructional context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study investigates students\u2019 conceptions, experiences, and engagement with feedback through observations and interviews, analyzed thematically. The abstract does not report any quantitative or experimental writing outcome measures (e.g., changes in writing quality, scores, accuracy). Outcomes are qualitative (experiences, feedback literacy), so it does not meet the requirement for quantifiable writing outcome metrics.""}}"
Efl Learners' Perceptual Perezhivaniya and Actual Writing Revision Behaviors Mediated by Genai: a Sociocultural Theory Perspective,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are nineteen EFL learners at a university in Southern China, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract states that learners revised L2 continuation writing tasks \""using GenAI\"" but does not specify that the GenAI tool is an LLM (e.g., ChatGPT, GPT-4) or provide details about the underlying technology. It could be any generative AI system, not necessarily an LLM-based intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on the revision stage of L2 writing processes, development of an L2 writing revision taxonomy, and analysis of revision behaviors, which are core writing-related variables rather than automated scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses interviews, Q-methodology, and Translog screen recordings to explore revision processes and the alignment between perceived experiences and actual revision behaviors. The abstract does not report any quantifiable writing outcome metrics (e.g., writing quality scores, accuracy gains) assessing the effectiveness of GenAI-mediated intervention; it focuses on process and perceptions rather than outcome measures.""}}"
Students' Perceptions of Generative Artificial Intelligence (genai) Use in Academic Writing in English as a Foreign Language,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 56 undergraduate university students in Ecuador studying English as a foreign language (EFL), clearly an L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a perception survey about GenAI/ChatGPT use and academic integrity. There is no indication of an experimental or quasi-experimental design integrating LLMs into writing instruction or writing processes as an intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the context is academic writing in EFL, the primary focus is on perceptions of academic integrity, cheating, and AI-giarism, not on improving writing competence or implementing a pedagogical writing intervention using LLMs.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports students\u2019 perceptions and worries, but does not mention any quantifiable writing outcome metrics or measured changes in writing performance resulting from an LLM-mediated intervention.""}}"
Chatbots or Cheatbots? University Students' Uses of Ai Literacy Tools across Four Nations,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are undergraduate and graduate students in English-medium programs across India, Indonesia, Morocco, and the US. Their L1s are not specified, and the focus is on general use of LLMs in English-medium instruction, not explicitly on L2 English learners in ESL/EFL/ELL contexts or on data specifically framed as L2 English learning.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a cross-case analysis of first-person accounts of how students use LLMs. There is no experimental or quasi-experimental design, nor a structured pedagogical intervention integrating LLMs into instruction; it is descriptive/qualitative.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""While writing is mentioned (brainstorming, sentence complexity, revising prompts), the primary focus is on general AI literacy and uses of LLMs for reading, writing, and learning, not on a defined writing instruction intervention or systematic development of writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports qualitative accounts of opportunities and challenges and discusses implications. It does not mention any quantitative or experimental writing outcome measures assessing the effectiveness of LLM-mediated writing interventions.""}}"
"A Comparative Study of the Human, Automated Scoring Model, and Gpt-4 Ratings of Young Efl Students' Writing",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as 'young English as a foreign language learners,' clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""GPT-4 is used as an automated writing evaluation (AWE) scoring model, not as part of an instructional or intervention design to support learners\u2019 writing processes or instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on comparing GPT-4, an operational AWE model, and human ratings for scoring TOEFL Junior Writing responses. This is an assessment/measurement study, not a pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports psychometric performance of scoring models (e.g., agreement with human ratings), not quantifiable changes in learners\u2019 writing outcomes resulting from an LLM-mediated instructional intervention.""}}"
Efl Learners' Motivation and Acceptance of Using Large Language Models in English Academic Writing: an Extension of the Utaut Model,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are explicitly described as EFL learners engaged in learning English academic writing, which fits the target population of L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the study involves LLMs (e.g., ChatGPT) and mentions that participants completed a semester of training in using LLMs for English academic writing, the research focus is not on experimentally evaluating an LLM-based writing intervention. Instead, it examines motivation and technology acceptance (UTAUT) via survey data, without an experimental or quasi-experimental instructional design centered on LLM integration.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on learners\u2019 motivation, behavioral intention, and acceptance of LLMs, modeled through L2 Motivational Self System and UTAUT constructs. Writing competence or writing-related performance variables are not the central outcome; the context is technology adoption rather than pedagogical writing intervention outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports structural relationships among motivational and acceptance variables (e.g., performance expectancy, social influence, behavioral intention, use behavior) using PLS-SEM. It does not report quantifiable writing outcome metrics (e.g., writing quality scores, accuracy, complexity) to assess the effectiveness of LLM-mediated writing interventions.""}}"
Edcew-llm: Error Detection and Correction in English Writing: a Large Language Model-based Approach,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cerror profiles of English language learners across CEFR proficiency levels (A, B, and C)\u201d but does not specify that these are actual study participants in an instructional context; they may simply be learner corpora used for benchmarking. No ESL/EFL/ELL classroom or learner-participant sample is clearly described.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study develops and benchmarks an LLM-based error detection and correction pipeline and uses GPT\u20113.5 to generate explanations. It is framed as a WEDC system evaluation, not as an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction with learners.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on model performance for error detection/correction and explanation generation, with benchmarks on BEA-2019 and JFLEG. There is no description of a teaching/learning context, instructional design, or writing instruction intervention; it is essentially an NLP system study, not a writing pedagogy study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are F1 scores and benchmark performance on WEDC datasets, plus human evaluations of correction and explanation quality. There are no quantifiable learner writing outcomes (e.g., pre/post writing scores, improvement measures) from an LLM-mediated writing intervention.""}}"
Investigating Efl Students' Perceptions of Feedback: a Comparative Study of Instructor and Chatgpt-generated Responses in Academic Writing,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Saudi English as a Foreign Language (EFL) learners in an advanced writing course, clearly fitting an L2 English EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is used to generate feedback on writing, but the study focuses on comparing perceptions of instructor vs. ChatGPT feedback. There is no indication of an experimental or quasi-experimental instructional intervention using LLMs to teach or support writing beyond feedback provision for perception comparison.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on students\u2019 perceptions of feedback sources (instructor vs. ChatGPT), not on writing competence or writing-related performance variables as outcomes of a pedagogical intervention. Writing is the context, but the study is perception-focused rather than intervention-focused.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports only survey-based perceptions and preferences. It does not report quantifiable writing outcome metrics (e.g., changes in writing scores, accuracy, complexity) attributable to ChatGPT-mediated intervention.""}}"
Large Language Models Fall Short in Classifying Learners' Open-ended Responses,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 143 Japanese university students studying English as a foreign language (EFL), which fits the L2 English learner population criterion.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""LLMs are used to classify learners\u2019 open-ended responses about their essay-writing process, not as part of an instructional or quasi-experimental writing intervention. The focus is on methodological evaluation of LLM-based classification, not on integrating LLMs into writing instruction or processes for learning outcomes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on LLM performance in qualitative data analysis (classification of responses) and methodological implications, not on improving writing competence or writing-related pedagogical variables. There is no described instructional context targeting writing development.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports Cohen\u2019s kappa for agreement between LLMs and human coders, not quantifiable writing outcome metrics. It does not assess changes in learners\u2019 writing performance or related measurable outcomes from an LLM-mediated intervention.""}}"
A Linguistic Comparison between Chatgpt-generated and Nonnative Student-generated Short Story Adaptations: a Stylometric Approach,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are nonnative ESL students at an Egyptian university, and the texts analyzed are in English, fitting the L2 English learner population criterion.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is used only to generate comparison texts; there is no experimental or quasi-experimental instructional intervention integrating the LLM into writing instruction or students\u2019 writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on stylometric comparison and authorship attribution (distinguishing AI vs. human text), not on improving writing competence through a pedagogical intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No writing outcome measures assessing the effectiveness of an LLM-mediated writing intervention are reported; the study analyzes linguistic features but does not evaluate changes in learners\u2019 writing performance after an intervention.""}}"
Artificial Intelligence Vs. Instructor Supported Ai: Teaching Second Language Writing Via Write&improve,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study focuses on second language writing and English writing success/self-efficacy, implying participants are L2 English learners in an ESL/EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses the Write&Improve system. While it is an AI-based feedback tool, the abstract does not indicate that it is based on large language models or transformer-based generative models (e.g., ChatGPT, GPT-4). Under the review\u2019s criteria, tools like Write&Improve that are not clearly LLM-based should be excluded.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on second language writing success and related variables (self-efficacy, emotions, responsibilities, teacher-student interaction) within a writing instruction context, not on automated scoring per se.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantitative pretest-posttest outcomes, including statistically significant increases in English writing success and other measurable constructs, satisfying the requirement for quantifiable writing outcome metrics.""}}"
Developing L2 Postgraduate Students' Strategic and Responsible Use of Genai through a Purposefully Designed Workshop in Academic Writing,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are explicitly described as L2 postgraduate students facing challenges in academic writing, indicating second language English learners in an academic writing context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The workshop uses \u201cdiverse GenAI tools\u201d and focuses on \u201cstrategic and responsible GenAI use,\u201d but the abstract does not specify whether these are large language models (e.g., ChatGPT, GPT-4) or other types of generative AI. However, even if LLMs are involved, the design is primarily a pedagogical workshop with pre/post questionnaires, not clearly an experimental or quasi-experimental comparison of LLM-integrated writing instruction versus control conditions.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is academic writing: the workshop targets stages of the writing process (brainstorming, literature searching, revising, ethical considerations) and is clearly centered on writing competence and writing-related processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are changes in \u201ctechnology proficiency, critical evaluation skills, ethical competence, and AI agency\u201d based on pre- and post-workshop questionnaires. There is no mention of quantifiable writing performance metrics (e.g., writing quality scores, complexity, accuracy, fluency). Thus, no direct writing outcome measures are reported.""}}"
Linguistic Analyses of Written Corrective Feedback for Chinese as a Second Language: Chatgpt Versus Human Teachers,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are learners of Chinese as a second language (CSL), specifically a Vietnamese CSL writing sample corpus. The focus is not on L2 English learners in ESL/EFL/ELL contexts, and the target language is Chinese, not English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is involved, the study compares written corrective feedback produced by ChatGPT and human teachers. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction; it is an analysis of feedback characteristics.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on linguistic analysis of written corrective feedback quality (language accuracy and content expressivity), not on writing competence development or a structured writing intervention. It is essentially a functionality/quality comparison of feedback providers.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports linguistic parameters of feedback (e.g., word order changes, vocabulary difficulty) but does not report quantifiable writing outcome metrics for learners (e.g., changes in writing scores or proficiency after intervention). No experimental learning outcomes are described.""}}"
A Translanguaging Perspective on Students' Use of Generative Artificial Intelligence in L2 Writing,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as 'Chinese multilingual undergraduates' engaged in 'L2 writing', which in this context strongly implies English as the target language in an EFL/ESL-type setting.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study focuses on 'Generative artificial intelligence (GAI)' and students' use of it in L2 writing. While this likely includes LLM-based tools (e.g., ChatGPT), the abstract does not explicitly specify that the tools are large language models or name any LLM platform. It also does not describe a structured instructional intervention; rather, it examines naturalistic use.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on how students use GAI in naturalistic L2 writing contexts from a translanguaging perspective, exploring usage patterns and underlying reasons. It is not an instructional or pedagogical intervention study aimed at improving writing competence, but a descriptive/qualitative exploration of practices and stances.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses screen recordings, reflective journals, and interviews, analyzed thematically. No mention is made of quantitative or experimental writing outcome measures; findings are qualitative (patterns of use, stances, and theorization of GAI-assisted writing). Thus, it does not report quantifiable writing outcome metrics.""}}"
Saudi Efl Learners' Perceptions of Using Artificial Intelligence and Its Impact on Their Writing Skills,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are female Saudi learners of English as a Foreign Language at the University of Jeddah, clearly an EFL context with English as the target language.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cArtificial Intelligence tools\u201d and explicitly mentions ChatGPT, which is an LLM. However, it does not clearly describe an experimental or quasi-experimental instructional intervention; it focuses on perceptions and experiences rather than a structured LLM-mediated teaching design.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on the impact of AI tools on students\u2019 English writing skills and writing competency, i.e., writing-related variables in an EFL context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses questionnaires and semi-structured interviews to explore perceptions, attitudes, and perceived impact. There is no indication of quantifiable writing outcome measures (e.g., pre/post writing scores, rubric-based performance) assessing effectiveness of an LLM-mediated intervention.""}}"
Enhancing Efl Writing through Ai-driven Video-to-text Recognition in Authentic Learning Contexts,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as English as a Foreign Language (EFL) learners: 22 first-year university students in an EFL context, with focus on English writing skills.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is an AI-driven video-to-text recognition (VTR) system that combines AI and cloud-based technologies. There is no indication that it is based on a large language model (e.g., ChatGPT/GPT-style generative transformer). It appears to be a recognition/transcription tool rather than an LLM-based generative writing assistant.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on enhancing EFL writing skills and supporting structured writing tasks in authentic learning environments, clearly centering on writing competence.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study is a two-week experimental study evaluating the impact of the VTR system on writing proficiency, reporting improvement in writing skills, which implies quantifiable writing outcome metrics.""}}"
Harnessing Generative Ai for English Curriculum Innovation in Higher Education: a Case Study at Al-zaytoonah University of Jordan,2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract specifies that the context is English as a Foreign Language (EFL) instruction at Al-Zaytoonah University of Jordan, indicating L2 English learners in an EFL setting.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study integrates Generative AI, particularly LLMs (ChatGPT), into English language curriculum design and introduces ChatGPT as a supplementary tool in classrooms. However, the abstract does not clearly state that there is an experimental or quasi-experimental design (e.g., control vs. treatment, pre/post intervention) focused specifically on writing instruction or processes; it may be broader curriculum innovation.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""Writing fluency is mentioned as one of several outcomes (along with linguistic autonomy and critical thinking), but the primary focus appears to be overall curriculum innovation and EFL instruction, not explicitly a writing-focused intervention. It is unclear whether writing competence is the central focus or just one of multiple skills examined.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract notes that a mixed-method approach with qualitative and quantitative data was used and that GenAI tools improved writing fluency, but it does not specify what quantifiable writing outcome metrics were used (e.g., scores, rubric-based assessments, pre/post writing tests). Without explicit mention of measured writing outcomes, it is unclear if this criterion is met.""}}"
Exploring the Use of Generative Ai on Students’ Academic Writing: an Exploratory Study,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) learners, and the context is academic writing in English.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u2018generative AI (GenAI)\u2019 but does not specify whether it is an LLM-based tool (e.g., ChatGPT/GPT-4) or another type of generative system. However, even if it were an LLM, the study is exploratory and focuses on question categories and adoption patterns rather than a structured instructional intervention with experimental or quasi-experimental design.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly academic writing, examining how EFL students use GenAI during a designed writing task. The primary focus is on writing-related behavior and perceptions.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study investigates questioning behaviors, adoption of GenAI responses, and perceptions of usefulness and ease of use. There is no mention of quantifiable writing outcome measures (e.g., writing scores, quality ratings, accuracy) to assess effectiveness of the GenAI-mediated writing process.""}}"
Understanding How Ai Chatbots Influence Efl Learners’ Oral English Learning Motivation and Outcomes: Evidence from Chinese Learners,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 351 EFL students in China learning spoken English with an AI chatbot, clearly fitting an EFL/ESL/ELL English-learning context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the study involves AI chatbots, the abstract does not specify that they are large language model\u2013based tools (e.g., ChatGPT, GPT-4). It generically refers to \u2018AI chatbots\u2019 and focuses on their \u2018human likeness\u2019 and social presence, without indicating transformer-based generative LLMs or a specific LLM platform.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on spoken/oral English learning, motivation, self-efficacy, and social presence. There is no indication that writing competence or writing-related variables are targeted; the context is oral English practice, not writing.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes concern learning motivation and spoken learning outcomes measured via questionnaire and SEM. No quantifiable writing outcomes or writing performance measures are reported.""}}"
Unveiling the Writing Self-efficacy and Its Relationship with Writing Engagement Based on Generative Ai Feedback,2025,unsure,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract does not specify the language background of the participants or whether they are L2 English learners in ESL/EFL/ELL contexts. It only refers to \u201cstudents,\u201d so their L1/L2 status and target language are unknown.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses \u201cgenerative AI feedback,\u201d which could involve LLMs, but no specific tools (e.g., ChatGPT, GPT-4) or model types are named. It is unclear whether the generative AI is an LLM-based system or another form of AI feedback.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on writing self-efficacy and writing engagement \u201cbased on generative AI feedback,\u201d indicating a writing-related intervention context rather than automated scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported concern writing self-efficacy (ideation, construction, self-regulation) and writing engagement. There is no indication of quantifiable writing performance or competence measures (e.g., text quality, accuracy, complexity), only affective/psychological variables.""}}"
