Title,Year,Decision,Notes
Is the Simplest Chatbot Effective in English Writing Learning Assistance?,2020,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cnon-native learners\u201d writing English, which suggests L2 English learners, but it does not explicitly specify ESL/EFL/ELL contexts or participant details. Population appears likely relevant but is not fully clear from the abstract alone.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses \u201cthe simplest chatbot (such as ELIZA).\u201d ELIZA-style chatbots are rule-based and predate transformer-based large language models. There is no indication that the system is an LLM (e.g., GPT-style, transformer-based generative model). Thus, it does not meet the requirement that the intervention integrate an LLM.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on English writing learning assistance, comparing a standard editor with a chatbot-based writing system and examining effects on word usage and self-revision. The primary focus is on writing behavior and writing-related variables, not on automated scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study empirically compares the number of words learners produce with a standard editor versus a chatbot-based system and analyzes writing results (word usage, self-revision). These are quantifiable writing outcome metrics assessing the effectiveness of the intervention.""}}"
A Critical Deconstruction of Computer-based Test Application in Turkish State University,2020,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Turkish EFL university students and their instructors, clearly situated in an English as a foreign language context, with data focused on English proficiency testing (Versant English Test).""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study investigates conceptions of the Versant English Test, an automated AI-based test of spoken and written language. It is not an experimental or quasi-experimental pedagogical intervention integrating an LLM into writing instruction or writing processes; it is an assessment tool evaluation, and the abstract does not indicate use of transformer-based generative LLMs.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on automated assessment (VET) and its validity, reliability, and washback, not on developing writing competence or writing-related instructional interventions. Writing is only one component of a broader language test, and there is no described writing pedagogy or intervention context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses a qualitative phenomenological design with semi-structured interviews and focus groups to explore attitudes and perceptions. It does not report quantifiable writing outcome metrics or experimental measures of writing performance following an AI/LLM-mediated writing intervention.""}}"
A Machine Learning Approach to Persian Text Readability Assessment Using a Crowdsourced Dataset,2020,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The study focuses on Persian text readability assessment and dataset creation. There is no mention of L2 English learners, ESL/EFL/ELL contexts, or English as the target language; instead, it concerns Persian language readability in general.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is a machine learning model for Persian text readability assessment, not an LLM-based tool (e.g., ChatGPT, GPT-4) integrated into writing instruction or writing processes. It is an NLP/readability system, not an LLM-mediated pedagogical intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on automated text readability assessment for Persian, not on writing competence, writing instruction, or writing-related pedagogical variables. It is a language technology development study rather than a writing intervention study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No writing outcome metrics for learners are reported. The study evaluates model accuracy in assessing readability, not changes in learners\u2019 writing performance or outcomes following an intervention.""}}"
Digital Storytelling with Chatbots: Mapping L2 Participation and Perception Patterns,2020,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""Participants are L2 learners in a university class in South Korea, which strongly suggests EFL learners, but the abstract never explicitly states that the target language is English. It only refers to \u201cL2\u201d and \u201cL2 class.\u201d""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses a \u201cdigital storytelling chatbot system (storybot)\u201d in 2020. There is no indication that this is a large language model or transformer-based generative model (e.g., ChatGPT, GPT-4). It is described as a narrative-focused chatbot, not as an LLM-based tool.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on participation rates, perceptions, and reading comprehension in interactions with a storybot. Writing is minimal and not the central instructional focus; the study is framed as increasing L2 output and reading comprehension, not specifically writing competence or writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports participation analytics and reading comprehension (cohesion between comprehension questions and responses) plus perception survey data. It does not report quantifiable writing outcome metrics or structured evaluation of writing performance attributable to the chatbot intervention.""}}"
"Exploring the Development of Writing Complexity, Accuracy, and Fluency in Relation to the Motivational Trajectories: a Dynamically-oriented Case Study",2020,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participant is described as a 'successful highly motivated EFL learner,' indicating an English-as-a-foreign-language context and thus an L2 English learner.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The term 'LLM' in the abstract refers to 'language learning motivation,' not large language models. There is no mention of ChatGPT, GPT-4, or any LLM-based tool, nor any AI-mediated instructional intervention. The study is a CDST-oriented case study of motivation and CAF development, not an LLM-integrated intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on writing-related variables\u2014complexity, accuracy, and fluency (CAF)\u2014in monthly writing assignments, aligning with a primary focus on writing competence and its development.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study quantitatively assesses the development of general measures of CAF over ten stages using descriptive and statistical analyses, providing quantifiable writing outcome metrics, even though these are not linked to any LLM-based intervention.""}}"
Foreign Language Learners’ Preference of E-leaming Methods: an Empirical Study,2020,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are foreign language learners taking English courses (listening, reading, writing, translating, speaking) at Xinhua Colleges, indicating an EFL/ESL context focused on English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study compares four e-learning delivery methods (video conferencing, self-recorded videos, MOOC courses, electronic materials by native speakers). There is no mention of large language models or tools like ChatGPT, GPT-4, etc., nor any AI-based generative intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on learners\u2019 preference for different e-learning methods across several skills, not specifically on writing competence or writing-related variables. Writing is only one of several course types considered, and no writing-focused pedagogical intervention is described.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes concern preferences and influencing factors (time, place, network quality, emotional attachment, proficiency, interaction). No quantifiable writing performance or writing outcome metrics are reported.""}}"
Research on College English Teaching Strategies and Applications Based on Big Data,2019,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions 'college English teaching in China', which likely involves EFL learners, but it does not explicitly specify that participants are L2 English learners or provide details about the learner population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study focuses on 'big data' as a basis for teaching strategies. There is no mention of large language models (e.g., ChatGPT, GPT-4) or any transformer-based generative AI being integrated into instruction or writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The abstract addresses general 'college English teaching strategies and applications' in the big data era. It does not indicate that the primary focus is on writing competence or writing-related variables; it appears to concern overall English teaching.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are mentioned. The paper is described as an empirical analysis of teaching and proposing measures, without reference to measured changes in writing performance or related variables.""}}"
Chinese Grammatical Error Correction Based on Convolutional Sequence to Sequence Model,2019,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The focus is on Chinese grammatical error correction for learners of Chinese as a second language. The target language is Chinese, not English, so it does not match the required L2 English learner population/context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study introduces a convolutional sequence-to-sequence model (a CNN-based neural MT/GEC system), not a large language model such as ChatGPT, GPT-4, or similar transformer-based generative LLM used pedagogically. It is a computational NLP model development paper, not an LLM-mediated instructional intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The context is automatic grammatical error correction system development and evaluation, not writing instruction or writing processes in an educational setting. There is no pedagogical intervention targeting learners\u2019 writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are model performance improvements over a baseline neural MT model, not quantifiable writing outcomes for human learners following an LLM-mediated writing intervention.""}}"
Application of Artificial Intelligence to the Small Open Online English Abstract Writing Course,2019,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 79 graduate students learning English abstract writing in a SMOOC context, indicating L2 English academic writing instruction (ESL/EFL/ELL-type context).""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses an AI-assisted system called Quick Research Papers (QRP) for writing, grading, feedback, and analytics. The abstract (2019) does not indicate that QRP is a large language model or transformer-based generative model; it appears to be an automated error-detection/analytics tool rather than an LLM like ChatGPT/GPT-4.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on improving English abstract writing skills, tracking writing errors, and using AI analytics to guide teaching and consultation\u2014clearly centered on writing competence.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing-related outcomes: number of words written, total errors (501), and distribution of error types (e.g., noun, spelling, subject-verb agreement), used to assess writing weaknesses.""}}"
"5th Eai International Conference on E-learning, E-education, and Online Training, Eleot 2019",2019,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The proceedings volume includes multiple studies, one of which mentions EFL writing and another mentions College English education, but the abstract is a table-of-contents style overview. It is not clear which specific participant populations are involved or whether they are L2 English learners in ESL/EFL/ELL contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The abstract lists various topics (MOOCs, blended learning, AI in wireless sensor networks, etc.). One paper mentions a web-based automatic writing evaluation platform, but there is no indication that any study uses large language models (e.g., ChatGPT, GPT-4) in writing instruction. The AI references appear unrelated to LLM-based writing intervention.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""One listed paper is titled \u201cSelf-correction\u2019s Effects on EFL Writing on Web-Based Automatic Writing Evaluation Platform,\u201d which suggests a focus on writing competence, but the nature of the intervention and tools is not specified. It may involve automated evaluation rather than an LLM-mediated pedagogical writing intervention.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The EFL writing paper title implies an empirical study of self-correction effects, which likely includes quantitative writing outcomes, but the abstract for the proceedings volume does not provide explicit information on outcome measures or designs for any individual paper.""}}"
Detection of Non-standard English Expressions by Language Sense,2019,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract refers to improving the ability of Chinese students\u2019 English writing and mentions second language acquisition, indicating L2 English learners (likely EFL in China).""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study proposes an algorithm (N-LanSen) for detecting non-standard English expressions. There is no indication that this is a large language model (LLM) or transformer-based generative model; it appears to be a detection/classification algorithm, not an LLM-based writing intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on developing and evaluating an algorithm to detect non-standard expressions in essays, not on a pedagogical intervention or integration into writing instruction. It is essentially a detection tool evaluation, not a teaching/learning context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The only reported outcome is algorithmic performance (high accuracy in detecting non-standard expressions). There are no quantifiable learner writing outcomes or measures of improvement in students\u2019 writing as a result of an intervention.""}}"
Native Language Identification in Very Short Utterances Using Bidirectional Long Short-term Memory Network,2019,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are Urdu speakers whose native language is being identified from very short English L2 utterances, but the study is framed as a speech/native language identification task, not as an ESL/EFL/ELL learning population in an instructional context. There is no indication of an educational or L2 learning setting.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses bidirectional long short-term memory (BLSTM) neural networks for native language identification. BLSTMs are not large language models (LLMs) such as ChatGPT, GPT-4, or similar transformer-based generative models, and there is no writing instruction or LLM-mediated intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on automatic native language identification from speech using acoustic features (MFCC, GFCC) and BLSTM classifiers. There is no focus on writing competence, writing instruction, or writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are classification accuracy for native language identification across different feature sets and utterance durations. No writing outcomes or measures of writing performance are reported.""}}"
A Framework of Computer-based Learning System Based on Self-regulated Model in English Writing,2019,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as Thai EFL learners, and the system is for English writing, so the population is L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The paper describes a computer-based learning system using components of linguistics and machine translation, but there is no indication that it uses large language models (e.g., ChatGPT, GPT-4) or any transformer-based generative model. It appears to be a design of a general computer-assisted system, not an LLM-based intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on a computer-based learning system for English writing, incorporating self-regulated learning phases to guide target sentence writing, which aligns with writing competence and writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract presents only the design phase of the system and its aim to collect learner behavior for future analysis. It does not report any experimental or quasi-experimental outcomes, nor any quantifiable writing performance metrics.""}}"
An Associativity-agnostic In-cache Computing Architecture Optimized for Multiplication,2019,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The paper is a hardware/architecture study on in-cache computing for multiplication operations. There is no mention of human participants, language learners, ESL/EFL/ELL contexts, or any educational population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention concerns an in-cache computing architecture (BLADE) and its optimization for multiplication in CMOS technology. It does not involve large language models, ChatGPT-like systems, or any LLM-based pedagogical tool.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The context is computer architecture and energy-efficient computation for machine learning workloads, not writing instruction, writing processes, or language education. No writing competence or writing-related variables are addressed.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported are hardware metrics (performance, area, energy, cycle count) for multiplication operations. There are no quantifiable writing outcomes or measures of L2 writing performance.""}}"
Automated Writing Evaluation System: Tapping Its Potential for Learner Engagement,2018,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions second language acquisition in general but does not specify that the participants are L2 English learners in ESL/EFL/ELL contexts, nor that the focus is specifically on English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The title and abstract refer broadly to an automated writing evaluation system and AI technologies but do not indicate the use of large language models (e.g., ChatGPT, GPT-4). It appears to be a conceptual or descriptive piece about AWE/AI rather than an LLM-based experimental or quasi-experimental intervention.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""While the title suggests a focus on writing evaluation and learner engagement, the abstract is too general to confirm that the primary focus is on writing competence or writing-related variables within a pedagogical intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""There is no indication of an experimental or quasi-experimental study design or of any reported quantitative writing outcome measures; the abstract reads as a general discussion of AI and AWE potential.""}}"
Application of Sentiment Analysis to Language Learning,2018,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201csecond or foreign language learning\u201d and \u201clanguage learners,\u201d but does not specify that the target language is English or that participants are ESL/EFL/ELL learners. The target language could be any L2.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is RESOLVE, a context-aware emotion synonym suggestion system using sentiment analysis and machine-learning techniques. There is no indication that it is based on a large language model or transformer-based generative model (e.g., ChatGPT, GPT-4). It appears to be a traditional NLP/sentiment analysis tool rather than an LLM.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study involves a writing task and aims to improve learners\u2019 use of emotion vocabulary in their writings, indicating a focus on writing-related competence (emotion word use in written production).""}, ""c4"": {""status"": ""pass"", ""evidence"": ""A pedagogical evaluation was conducted using a writing task, and the abstract reports that participants \u201cachieved substantial progress on emotion word use,\u201d with less proficient participants showing greater improvements. This implies quantifiable outcome measures of writing-related performance.""}}"
Supporting Esl Writing by Prompting Crowdsourced Structural Feedback,2017,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study explicitly targets support for English as a Second Language (ESL) writing and focuses on non-native speakers, indicating an L2 English learner population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention (StructFeed) relies on crowdsourced annotations from native speakers and compares this to three na\u00efve machine learning methods. There is no indication that a large language model (e.g., transformer-based generative model like ChatGPT/GPT-4) is used; the ML methods appear to be traditional, not LLM-based.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is ESL writing support, focusing on paragraph structure (topic sentence, irrelevant sentences) and writing hints, which are directly related to writing competence and revision outcomes.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract reports that people who received feedback via StructFeed showed the highest improvement after revision, implying quantifiable writing outcome measures were used to assess effectiveness.""}}"
A Tutorial Proposal On: Advanced Technical Communications for Esl Engineers and Ooi,2017,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The course is explicitly designed for English-as-a-Second-Language (ESL) engineers and others of interest, indicating an L2 English learner population in an ESL/EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The abstract describes an IEEE course on advanced technical writing and presentation skills, with demonstrations of grammatical subtlety, cultural differences, cognitive style, and logical thinking. There is no mention of large language models (e.g., ChatGPT, GPT-4) or any AI-based intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on technical writing and presentation skills for ESL engineers, which is directly related to writing competence and communication skills.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports participant satisfaction (97%) but does not mention any quantifiable writing outcome metrics or experimental evaluation of changes in writing performance.""}}"
Integrating an Adjusted Conversational Agent into a Mobile-assisted Language Learning Application,2017,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions a mobile-assisted English language learning application and students learning vocabulary in English, which suggests L2 learners, but it does not explicitly state that participants are ESL/EFL/ELL learners or that English is a second/foreign language for them.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses the chatterbot ALICE, a rule-based conversational agent, not a transformer-based large language model such as ChatGPT, GPT-4, or similar. Therefore, it does not meet the requirement of integrating an LLM into instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is vocabulary learning, motivation, engagement, and cognitive skills within a general English learning app. Writing is only mentioned as one modality for chatting with the agent, not as the central focus on writing competence or writing-related variables.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract notes that students can be evaluated by the chatterbot and that the system supports vocabulary practice, but it does not specify any quantifiable writing outcome metrics or structured assessment of writing performance.""}}"
