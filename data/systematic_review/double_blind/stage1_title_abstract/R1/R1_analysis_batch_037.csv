Title,Year,Decision,Notes
"A Systematic Review of Chatgpt for English as a Foreign Language Writing: Opportunities, Challenges, and Recommendations",2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly focuses on English as a Foreign Language (EFL) writing, indicating that the population of interest across the reviewed studies is EFL learners working with English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""This is a systematic review of existing literature on ChatGPT for EFL writing, not an experimental or quasi-experimental primary study implementing an LLM-based intervention. Review articles are to be excluded.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on EFL writing, discussing how ChatGPT is adopted for EFL writing, including opportunities and challenges in writing instruction and curricula.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a systematic review, it synthesizes prior work and provides recommendations but does not itself report original, quantifiable writing outcome metrics from an LLM-mediated intervention.""}}"
Chatgpt over My Friends: Japanese English-as-a-foreign-language Learners’ Preferences for Editing and Proofreading Strategies,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 33 Japanese English-as-a-foreign-language learners, clearly an EFL population learning English as L2.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT-3.5 (an LLM) is used, the design is not experimental or quasi-experimental in terms of learning outcomes. Learners simply use writing groups and ChatGPT for editing/proofreading and then complete questionnaires about their experiences and preferences; no controlled intervention to test effectiveness is described.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is academic writing in an EFL classroom, focusing on editing and proofreading to improve clarity and cohesion in writing, which is directly writing-related.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are preferences and perceptions from questionnaires. The abstract does not mention any quantifiable writing performance metrics (e.g., scores, error rates, rubric-based assessments) to evaluate the effectiveness of the LLM-mediated intervention.""}}"
Uncovering Students’ Processing Tactics towards Chatgpt’s Feedback in Efl Education Using Learning Analytics,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as being in EFL education, implying they are L2 English learners in an EFL context. The abstract explicitly mentions English as a Foreign Language (EFL) education and reading and writing tasks in that context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses ChatGPT, a generative AI chatbot based on LLMs, during students\u2019 reading and writing tasks. Students interact with ChatGPT\u2019s feedback, and their processing tactics toward this feedback are analyzed, indicating an LLM-based intervention embedded in learning activities.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The context includes reading and writing tasks and ChatGPT\u2019s feedback, but the primary measured outcome is described as \u2018improvement of domain knowledge\u2019 rather than writing competence or writing-related variables. It is unclear whether writing performance itself is a central focus or just a medium for content learning.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports differences in \u2018learning gains\u2019 and \u2018improvement of domain knowledge\u2019 among groups but does not indicate any quantifiable writing outcome metrics (e.g., writing quality scores, accuracy, complexity, organization). Outcomes appear to be content/knowledge gains rather than writing performance measures.""}}"
Towards Fair Detection of Ai-generated Essays in Large-scale Writing Assessments,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The population is described only as native and non-native English speakers in a large-scale writing assessment. There is no indication that the focus is on L2 English learners in ESL/EFL/ELL instructional contexts; rather, the concern is demographic bias in detection across broad test-taker groups.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study focuses on automated detection of AI-generated essays and compares strategies to mitigate detector bias. It does not describe an instructional intervention integrating LLMs into writing instruction or writing processes; LLMs are only the source of generated text to be detected.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on fairness and accuracy of AI-generated text detection in assessments, not on improving writing competence or writing-related pedagogical variables. There is no writing instruction or intervention context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) are reported. Outcomes relate to detection accuracy and bias, not to learners\u2019 writing performance following an LLM-mediated intervention.""}}"
Advancing Sustainable Learning by Boosting Student Self-regulated Learning and Feedback through Ai-driven Personalized in Efl Education,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are junior high school EFL students in Asia (English as a Foreign Language), clearly fitting the L2 English learner population criterion.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers broadly to \u201cAI-mediated language teaching\u201d and \u201cAI-powered platforms\u201d but does not specify that these are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative tools. They could be other types of AI tools. Without explicit mention of LLMs, it is unclear whether the intervention meets the LLM requirement.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is EFL instruction with outcomes including vocabulary, reading comprehension, writing ability, and grammar. Writing ability is explicitly listed as one of the assessed areas, so writing competence is part of the primary learning focus.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although pre- and post-tests evaluate multiple skills including writing ability, the abstract does not report any specific, quantifiable writing outcome metrics (e.g., writing scores, rubric-based writing gains) or isolate writing-related results. The reported findings are aggregated as general \u2018learning English\u2019 outcomes and self-regulation/feedback measures, without distinct experimental writing outcome data.""}}"
Ai in Subconscious Language Learning for Error Remediation,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses second language acquisition and language learning apps (LingQ, Rosetta Stone) but does not specify that the population is L2 English learners or that the focus is on English rather than other target languages.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The abstract refers broadly to AI-powered language learning platforms and intelligent assistants (Siri, Alexa) but does not mention large language models (e.g., ChatGPT, GPT-4) or any specific LLM-based intervention. It appears to be a conceptual or descriptive piece rather than an experimental or quasi-experimental LLM integration in instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on general language acquisition and personalized AI-based learning strategies, not specifically on writing competence or writing-related variables. Writing is not mentioned as a primary outcome or context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics or experimental measures are reported. The abstract describes potential benefits and capabilities of AI platforms without presenting structured intervention outcomes or data.""}}"
"Integrating Large Language Models into Efl Writing Instruction: Effects on Performance, Self-regulated Learning Strategies, and Motivation",2024,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are elementary school students in an English as a Foreign Language (EFL) context. The focus is explicitly on EFL writing, i.e., English as the target L2.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study develops and implements an 'LLM-supported Cognitive Academic Language Learning Model (CALLA-LLM)' and compares it to traditional CALLA in a randomized controlled trial. LLMs are integrated into the writing instruction as part of the experimental intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary instructional focus is EFL writing, with outcomes including 'EFL writing performance' and writing-related SRL strategies and motivation. The LLM is used pedagogically within writing instruction, not merely for automated scoring.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract reports 'significant improvements in writing performance' and describes a randomized controlled trial with pre-, post-, and follow-up measures, indicating quantifiable writing outcome metrics were collected and analyzed.""}}"
Balancing Ai and Authenticity: Efl Students’ Experiences with Chatgpt in Academic Writing,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as EFL students, indicating L2 English learners in an EFL context, with a focus on academic writing in English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used by students in their writing process, the study is a qualitative case study of existing student practices and experiences, not an experimental or quasi-experimental intervention integrating LLMs into instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly academic writing: the study examines how EFL students incorporate ChatGPT into their academic writing process and its perceived impact on essay quality.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract states that data were collected through semi-structured interviews and focuses on experiences, perceptions, and ethical concerns. It explicitly notes reliance on self-reported data and calls for future research with objective measures, indicating no quantifiable writing outcome metrics were reported.""}}"
The Impact of Chatgpt on Students’ Writing Proficiency in Second Language Acquisition: Students’ Perception and Experiences: a Qualitative Analysis,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201csecond language acquisition\u201d and \u201cstudents\u2019 writing proficiency\u201d but does not specify that the target L2 is English or that the context is ESL/EFL/ELL. Thus, it is unclear whether participants are L2 English learners.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""ChatGPT, an LLM, is clearly the tool under investigation. However, the abstract does not describe an experimental or quasi-experimental instructional design; it only notes that students use ChatGPT as a tool and that their experiences are explored qualitatively. The presence of a structured intervention cannot be confirmed.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on \u201cstudents\u2019 writing proficiency\u201d in second language acquisition and how ChatGPT influences language learning and writing skills, which aligns with a writing-related context rather than automated scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is described as \u201ca qualitative analysis\u201d using interviews and questionnaires to explore perceptions and experiences. There is no indication of quantitative or experimental writing outcome measures; it explicitly goes \u201cbeyond mere evaluation of outcomes,\u201d suggesting no reported quantifiable writing metrics.""}}"
"Using Artificial Intelligence to Foster Students’ Writing Feedback Literacy, Engagement, and Outcome: a Case of Wordtune Application",2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly states the context is second language (L2) learning and L2 writing. Participants are upper-intermediate L2 students, implying an ESL/EFL context focused on English, though the language is not named. This fits the target L2 English learner population more closely than other L2s.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses Wordtune, described only as an \u201cAI-based application.\u201d Wordtune is primarily a rewriting/paraphrasing tool and is not clearly identified as a large language model (e.g., ChatGPT, GPT-4, Gemini). The abstract provides no indication that a transformer-based generative LLM underpins the tool, and Wordtune is listed in the protocol as an example of tools to exclude if not LLM-based.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study\u2019s focus is on L2 writing skills, specifically writing feedback literacy, engagement, and writing outcomes. The intervention is clearly pedagogical, integrating AI into L2 writing practice rather than using AI solely for automated scoring or system evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract reports that the experimental group using Wordtune \u201csignificantly improve[d] their writing outcomes, engagement, and feedback literacy when compared to the control group,\u201d indicating quantitative outcome measures of writing performance within an experimental design.""}}"
Understanding Efl Students’ Chatbot-assisted Argumentative Writing: an Activity Theory Perspective,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are five Chinese undergraduate students described as English as a foreign language (EFL) students composing argumentative essays in English, which fits the L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The intervention involves a chatbot named Argumate used to assist argumentative writing. However, the abstract does not specify whether Argumate is an LLM-based chatbot (e.g., transformer-based generative model) or a rule-based/other AI system. Thus, it is unclear if it meets the LLM requirement.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on chatbot-assisted argumentative writing, examining how students engage with the chatbot while composing essays and the activity system of chatbot-assisted writing, which is clearly centered on writing processes and pedagogy.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is explicitly described as qualitative, using activity theory to understand engagement processes. Data include screen recordings, chat logs, essays, and a questionnaire, but the abstract reports no experimental or quasi-experimental design, no comparison groups, and no quantifiable writing outcome metrics assessing effectiveness of the intervention. The focus is on process understanding, not measured writing gains.""}}"
Enhancing Efl Vocabulary Acquisition through Computational Thinking,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Chinese non-English majors in foreign language education in China, working on English short essay writing and vocabulary acquisition. This fits an EFL context with English as the target L2.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT and AI are mentioned in the introduction, the described intervention is based on computational thinking (CT) skills (data analysis, pattern recognition, abstraction, decomposition, parallelization) applied to vocabulary acquisition. There is no indication that an LLM (e.g., ChatGPT) was actually integrated into the writing instruction or writing process as an experimental tool.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on improving vocabulary richness in English short essay writing and measures vocabulary-related indices in students\u2019 writing, which is directly related to writing competence.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantitative changes in vocabulary-related indices in short essay writing before and after the CT intervention, using QUITA software, thus providing measurable writing outcomes.""}}"
Examining Efl Students' Motivation Level in Using Quillbot to Improve Paraphrasing Skills,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL students at Najran University enrolled in a Technical Writing course, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention tool is QuillBot. As specified in the review criteria, tools like QuillBot that are not clearly framed as transformer-based generative LLMs for instructional intervention are to be excluded.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on students\u2019 motivation in using QuillBot to improve paraphrasing skills, not on a structured writing instruction intervention. The design is descriptive-diagnostic, not an experimental or quasi-experimental pedagogical intervention targeting writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports motivational outcomes and gender differences in perceptions, using questionnaires and interviews. It does not report quantifiable writing performance outcomes (e.g., pre/post paraphrasing or writing scores) to assess effectiveness of the AI tool on writing.""}}"
The Intersection of Ai and Language Assessment: a Study on the Reliability of Chatgpt in Grading Ielts Writing Task 2,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions IELTS Task 2 writing scripts but does not specify the learners\u2019 status as L2 English learners in ESL/EFL/ELL contexts. While IELTS candidates are typically L2 users, this is not explicitly stated in the abstract.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study evaluates ChatGPT-4 as an automated grader, comparing its scores with official human raters. There is no indication of an instructional or intervention design integrating ChatGPT into writing instruction or learners\u2019 writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on the reliability of ChatGPT as a grading tool for IELTS Task 2, not on improving writing competence or implementing a pedagogical writing intervention. It is an assessment-functionality study rather than a teaching/learning intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although quantitative measures (e.g., kappa, ICC) are reported, they relate to score agreement between ChatGPT and human raters, not to changes in learners\u2019 writing performance following an LLM-mediated intervention. No writing outcome metrics for an instructional treatment are presented.""}}"
University Students’ Perceptions of Artificial Intelligence-based Tools for English Writing Courses,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Korean university students who are English language learners (ELLs) in English writing courses, fitting an EFL/ESL context focused on English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study explores perceptions of AI-based tools (Google Translate, Naver Papago, Grammarly) but does not describe an experimental or quasi-experimental intervention integrating LLMs into instruction. Tools mentioned are primarily translation and error-checking systems, and Grammarly is not clearly framed as an LLM-based generative model in an instructional design.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on students\u2019 perceptions of AI-based tools in English writing courses, not on a structured writing intervention or instructional design aimed at improving writing competence. It is attitudinal rather than an intervention study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports perceptions that tools could improve writing skills but does not mention any quantifiable writing outcome measures or experimental comparison of writing performance. Data are survey and interview-based, focusing on strengths, weaknesses, and concerns, not measured writing gains.""}}"
From Virtual Assistant to Writing Mentor: Exploring the Impact of a Chatgpt-based Writing Instruction Protocol on Efl Teachers’ Self-efficacy and Learners’ Writing Skill,2024,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Iranian English language teachers (n=12) and learners (n=48) in an L2 writing context. The abstract explicitly refers to second language (L2) writing and IELTS writing, indicating English as the target language in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention is a ChatGPT-based writing instruction protocol (CGWIP). ChatGPT is a large language model, and it is integrated systematically into planning, instruction, and assessment phases of writing instruction, constituting an experimental pedagogical intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is explicitly L2 writing instruction. ChatGPT is used for brainstorming, engaging learners in the writing process, analyzing drafts, revising, feedback, and simulating IELTS writing exams. The primary focus is on writing competence and related instructional processes, not on automated scoring alone.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantitative writing outcomes: learners\u2019 writing skills were measured before and after a 10-week program, and One Way ANCOVA showed that CGWIP significantly improved learners\u2019 writing skills with effects persisting over time.""}}"
Utilizing Artificial Intelligence Tools for Improving Writing Skills: Exploring Omani Efl Learners’ Perspectives,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Omani EFL learners from the General Requirements Unit at a university in Oman, clearly an EFL context focused on English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study investigates learners\u2019 perceptions and self-reported practices in using unspecified \u2018artificial intelligence writing tools\u2019 (e.g., for translation, spelling, grammar, idea generation). There is no indication of an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into instruction; tools may include non-LLM AI such as grammar checkers or translators.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on perceptions and practices regarding AI tools, not on a structured pedagogical writing intervention. It is a survey study rather than an instructional context designed to improve writing competence via LLM integration.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are Likert-scale perceptions and reported usage patterns; no quantifiable writing performance metrics (e.g., scores, text quality measures) are reported to assess effectiveness of AI/LLM-mediated writing intervention.""}}"
Paraphrasing Prowess: Unveiling the Insights of Efl Students and Teachers on Quillbot Mastery,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are explicitly described as English as a Foreign Language (EFL) students and teachers, indicating an L2 English learning context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention tool is QuillBot, which is not clearly identified as an LLM-based, transformer generative model in the abstract and is treated as a generic AI paraphrasing tool. Moreover, the design is a descriptive survey of perceptions, not an experimental or quasi-experimental writing intervention integrating an LLM.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on perceptions of using QuillBot for paraphrasing skills, not on a structured pedagogical writing intervention or systematic integration into writing instruction. It is a perception study rather than an instructional intervention study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports perceptions and attitudinal data (e.g., students and teachers perceived QuillBot can enhance paraphrasing skills) and demographic effects on responses. There is no mention of quantifiable writing outcome measures or pre/post tests of writing performance.""}}"
Chatgpt as an Automated Writing Evaluation (awe) Tool: Feedback Literacy Development and Awe Tools’ Integration Framework,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 18 English as a Foreign Language (EFL) students in Indonesia, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""ChatGPT is explicitly used as an AWE tool alongside Grammarly and Quillbot in a writing course, indicating integration of an LLM (ChatGPT) into writing instruction, even though it is combined with non-LLM tools.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on feedback literacy development and an AWE tools integration framework, not on writing competence or writing-related performance variables. Writing is the context, but the outcome focus is literacy about feedback and tool use rather than writing ability.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses a single qualitative case study design with interviews, reflective journals, and artifacts, and reports thematic findings. There is no indication of quantifiable writing outcome metrics or experimental measures of writing performance; outcomes are qualitative (feedback literacy, framework).""}}"
Evaluating Prompting Strategies for Grammatical Error Correction Based on Language Proficiency,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly mentions \u201clearners of English as a foreign language\u201d and analyzes GEC performance on writing examples of English language learners across proficiency levels (A, B, C). Thus, the population is L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the study uses generative LLMs and explores zero-shot, few-shot prompting, and fine-tuning for grammatical error correction, it is framed as an evaluation of prompting strategies and model performance, not as an experimental or quasi-experimental pedagogical intervention integrated into writing instruction or learners\u2019 writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on grammatical error correction system performance (overcorrection, recall vs. precision) and how it varies by learner proficiency. There is no indication of a teaching/learning context or writing instruction intervention; rather, it is a GEC/LLM evaluation study, which falls outside the review\u2019s focus on writing competence interventions.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported are GEC evaluation metrics (recall, precision, overcorrection) of LLMs, not quantifiable changes in learners\u2019 writing performance following an LLM-mediated intervention. No experimental measures of learner writing development or instructional impact are described.""}}"
