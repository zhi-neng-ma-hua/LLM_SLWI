Title,Year,Decision,Notes
Chatgpt-supported Collaborative Argumentation: Integrating Collaboration Script and Argument Mapping to Enhance Efl Students' Argumentation Skills,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are clearly identified as EFL (English as a Foreign Language) students: \u201cA total of 67 freshmen university students participated\u2026 The findings showed that the ChatGPT-CA approach significantly enhanced EFL students' argumentative speaking performance\u2026\u201d. The target language is English.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study is quasi-experimental and explicitly uses ChatGPT, a large language model, as part of the intervention: \u201cwe proposed using ChatGPT, a large language model, to guide students through three stages of collaboration script\u2026 34 of them using ChatGPT-supported collaborative argumentation (ChatGPT-CA) and 33 using conventional-based collaborative argumentation (C-CA).\u201d""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary measured outcomes are \u201cargumentative speaking performance, critical thinking awareness, and collaboration tendency.\u201d The abstract frames argumentation as involving both writing and speaking, but the reported quantitative outcome is explicitly speaking-focused, not writing competence or writing-related performance. There is no clear indication that written argumentation or writing quality was an assessed outcome.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although the study reports quantifiable outcomes (e.g., argumentative speaking performance, critical thinking awareness, collaboration tendency, and quality of arguments), these are not specified as writing outcomes. The focus of the measured intervention effects is on speaking and general argument quality, not on written texts or writing performance metrics, which is required for inclusion.""}}"
Teachers' Perceptions and Students' Strategies in Using Ai-mediated Informal Digital Learning for Career Esl Writing,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are university students in an English writing course in an ESL context (\u201ccareer ESL writing instruction\u201d), so they are L2 English learners in an ESL setting.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is mentioned among tools (Grammarly, ChatGPT, Canva with Magic Write, Invideo), the study is described as a case study exploring perceptions and strategies, not an experimental or quasi-experimental intervention design specifically integrating LLMs into instruction. Multiple tools are used and there is no clear LLM-focused instructional intervention with controlled conditions.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is career ESL writing instruction and focuses on students\u2019 strategies for using AI-mediated tools to improve writing, so the primary focus is on writing competence and writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports qualitative data sources (demographic questionnaire, think-aloud protocols, semi-structured interviews) and discusses strategies and perceptions. It does not indicate any quantifiable writing outcome metrics or experimental measures of writing improvement attributable to LLM-mediated intervention.""}}"
"Using Ai to Enhance Digital Multimodal Composing: Efl Learners' Semiotic Decision-making, Self-efficacy, Enjoyment, and Continuance Intention",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL learners in an academic English course, clearly fitting the L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses an unspecified AI-powered text-to-video tool for digital multimodal composing. There is no indication that this is an LLM-based (transformer generative text) system such as ChatGPT/GPT-4; it is framed as text-to-video generation, not an LLM writing assistant.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on digital multimodal composing (video production) and related constructs (semiotic decision-making, self-efficacy, enjoyment, continuance intention), not on writing competence or writing-related variables as outcomes. Written reflections are data sources, not targeted writing outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports questionnaire-based perceptions (self-efficacy, enjoyment, continuance intention) and qualitative assessments of AI-generated videos. It does not report quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity) to evaluate an LLM-mediated writing intervention.""}}"
Exploring High School Students' Preferences for English Writing Feedback: Non-native English Teacher Vs. Native English Teacher Vs. Chatgpt,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 20 high school students from an English newspaper club in Korea, clearly an EFL context with English as the target language.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used to provide feedback, the study is not an experimental or quasi-experimental writing intervention aimed at improving writing performance. It is primarily a preference/comparison study of feedback sources (non-native teacher, native teacher, ChatGPT), not a structured pedagogical intervention assessing learning gains.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on students\u2019 preferences and perceptions of different feedback providers, not on writing competence or writing-related performance outcomes. The context is evaluative (which feedback source students prefer) rather than an instructional intervention to develop writing skills.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The quantitative data consist of Likert-scale ratings of feedback and preferences, analyzed with descriptive statistics and non-parametric tests. No quantifiable writing outcome metrics (e.g., changes in writing scores, accuracy, complexity) are reported to assess the effectiveness of ChatGPT-mediated writing intervention.""}}"
"I, Too, Shall Have to Prompt? a Study of Efl Students and Their Unmonitored Use of Genai in the Completion of an Imitation Task in Poetry",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL students in a university English as a Foreign Language Literature course, so they are L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to a 'GenAI model' and a 'GenAI-assisted creative writing exercise,' but does not specify whether the tool is a large language model (e.g., ChatGPT/GPT-4) or another type of generative AI. The specific technology and architecture are not identified.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on a literature course and on how the GenAI-assisted imitation task supports application of literary analysis elements, prompt characteristics, and pedagogical implications. Writing competence or writing-related performance is not the central outcome; rather, it is use of literary terms and analysis.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is based on qualitative data from surveys and observational studies. The abstract does not report any quantifiable writing outcome metrics (e.g., writing scores, rubric-based assessments) to evaluate the effectiveness of the GenAI intervention on writing performance.""}}"
Investigating Efl Teachers' Lesson Planning for Chatbot-assisted Learning of Argumentative Writing: a Tpack Perspective,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The context is clearly EFL (English as a foreign language) teaching and learning, with a focus on argumentative writing in English. Participants are EFL teachers planning for EFL learners.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses a chatbot named Argumate, but the abstract does not specify whether it is an LLM-based, transformer-based generative model (e.g., ChatGPT-like) or a different type of chatbot. However, the main focus is on teachers\u2019 lesson planning and professional knowledge, not on an implemented LLM-mediated intervention with learners.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the context is argumentative writing, the study investigates teachers\u2019 lesson planning and TPACK for chatbot integration, not an actual pedagogical intervention implemented with students. It does not evaluate writing competence or writing-related outcomes; it focuses on integration approaches and professional knowledge.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported. The study analyzes lesson plans and interview data about teachers\u2019 reasoning, without experimental measures of students\u2019 writing performance or structured intervention outcomes.""}}"
Comparing Hong Kong Secondary School Students' Perceptions of Chatgpt-assisted Efl Writing,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 107 Hong Kong secondary school students in an EFL context, and the study explicitly concerns ChatGPT-assisted EFL (English) writing.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study investigates ChatGPT-assisted EFL writing and compares three teaching approaches (process-based, genre-based, prompt engineering only), indicating an instructional intervention integrating an LLM (ChatGPT) into writing instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the context is ChatGPT-assisted EFL writing, the measured outcomes are motivation, cognitive load, and satisfaction. There is no indication that writing competence or writing performance variables are directly assessed; the focus is on affective and cognitive perceptions rather than writing outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports quantitative outcomes only for motivation, cognitive load, and satisfaction. It does not mention any quantifiable writing performance metrics (e.g., writing scores, accuracy, complexity, organization). Thus, it lacks the required writing outcome measures for inclusion.""}}"
Does Metalinguistic Explanation of Teacher and Chatgpt Feedback Improve Efl Learners' Writing Quality and Engagement? Findings from an Intervention Study,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are explicitly described as EFL learners (foreign language writing instruction, EFL learners), indicating L2 English learners in an EFL context with a focus on English writing.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study is a quasi-experimental intervention examining scaffolded metalinguistic explanations of teacher and ChatGPT feedback. ChatGPT is a large language model integrated into the writing feedback process, satisfying the LLM-based intervention requirement.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is foreign language writing instruction, focusing on how feedback (including ChatGPT feedback) affects writing quality and engagement. The primary focus is clearly on writing competence and writing-related variables, not on automated scoring or system evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses pre-tests and post-tests, written drafts, and reports significant improvements in writing performance (grammatical accuracy, vocabulary use, mechanical control) and incorporation of feedback. These are quantifiable writing outcome metrics within an intervention design.""}}"
Assigning Cefr-j Levels to English Learners' Writing: an Approach Using Lexical Metrics and Generative Ai,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The system is designed for assessing English learners\u2019 writing proficiency in an EFL context (CEFR-J, tailored to EFL in Japan). Thus, the population is L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study presents CWLA, an automated writing level analyzer that uses lexical metrics and AI-based analytical scores for assessment. There is no indication that a large language model (e.g., ChatGPT, GPT-4) is integrated into writing instruction or writing processes; instead, AI is used for automated scoring/assessment.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on developing and validating an automated system for assessing writing proficiency (alignment with CEFR-J, correlation with human ratings), not on pedagogical writing intervention or improving writing competence. This aligns with automated essay scoring functionality, which is excluded by the review criteria.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports quantitative metrics (correlation with human ratings, entropy analysis, expert agreement), but these are validation metrics for an assessment tool, not writing outcome measures from an instructional or intervention study involving learners\u2019 writing development.""}}"
Rnn Hybrid Model for Evaluating Efl Teachers' Classroom Performance in Higher Education,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The abstract focuses on evaluating EFL teachers' classroom performance in higher education using an RNN-based model. There is no indication that the participants are L2 English learners or that learner data in an ESL/EFL/ELL context is the focus; instead, the target of evaluation is teachers.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses an Elman RNN combined with a Dolphin Echolocation Algorithm (DEA-RNN) as a predictive/evaluation model. This is not a large language model (e.g., ChatGPT, GPT-4) and is not integrated into writing instruction or writing processes; it is a machine learning model for performance evaluation.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The context is teacher performance evaluation in higher education, not writing competence or writing-related variables. There is no mention of writing instruction, writing tasks, or writing development as a primary focus.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported are model performance metrics (accuracy, precision, recall, F1-score, specificity) for evaluating teachers, not quantifiable writing outcomes for L2 learners. No writing intervention or writing performance measures are described.""}}"
Exploring Ai to Automate Efl Corrective Written Feedback in the First Language,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The title and abstract indicate an EFL context with students whose L1 is Japanese, implying they are L2 English learners receiving corrective written feedback on English writing.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses a ChatGPT-powered plugin (a generative AI LLM) within Moodle to provide automated written corrective feedback as part of a classroom intervention, satisfying the LLM-based intervention criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The intervention centers on a free-writing activity and subsequent written corrective feedback on students\u2019 writing, clearly focusing on writing competence and writing-related processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract describes an exploratory study focusing on perceptions of grammatical feedback (accuracy, comprehensibility, appreciation) and survey data. It does not report any quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity) to assess effectiveness of the intervention on learners\u2019 writing performance.""}}"
"Exploring Efl Students' Ai Literacy in Academic Writing: Insights into Familiarity, Knowledge and Ethical Perceptions",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Turkish English as a Foreign Language (EFL) students, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a descriptive exploratory survey of AI literacy and usage (e.g., translation and grammar proofreading). It does not describe an experimental or quasi-experimental intervention integrating LLMs (such as ChatGPT) into writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on AI literacy, familiarity, and ethical perceptions related to AI in academic writing, not on a pedagogical writing intervention or structured use of LLMs to develop writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes concern levels of AI familiarity, usage, and ethical perceptions, without measured changes in writing performance following an intervention.""}}"
"A Q Method Study on Turkish Efl Learners' Perspectives on the Use of Ai Tools for Writing: Benefits, Concerns, and Ethics",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Turkish English language learners enrolled in a preparatory EFL program at a state university in Istanbul, clearly fitting an L2 English EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study investigates learners\u2019 perspectives on the use of unspecified AI tools for writing, not an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into instruction. It is attitudinal/usage-focused rather than an LLM-based pedagogical intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the context is writing, the focus is on perceived benefits, concerns, and ethics of AI tool use, not on a structured writing intervention or instructional design aimed at improving writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported. The study uses Q methodology and qualitative interviews to explore perspectives, without experimental measures of writing performance or related outcomes.""}}"
"The Role of Techno-competence in Ai-based Assessments: Exploring Its Influence on Students' Boredom, Self-esteem, and Writing Development",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 66 Saudi Arabian male EFL learners, clearly an L2 English context: \u201cEFL learners\u2026 66 Saudi Arabian male students\u2026 participated in the study.\u201d""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is described only as \u201cAI-driven evaluations\u201d and \u201cAI-enhanced assessments.\u201d There is no indication that a large language model (e.g., ChatGPT, GPT-4) or transformer-based generative model was used; it could be any AI-based assessment tool. Thus it does not clearly meet the LLM requirement.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""Writing development is one of the primary outcomes: the study examines how AI-based assessments affect \u201cwriting skills,\u201d \u201cwriting proficiency,\u201d and \u201cwriting abilities,\u201d which are central to writing competence.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses pre- and post-assessments to measure \u201cboredom, writing proficiency, and self-esteem,\u201d and reports that the experimental group outperformed the control group. This indicates quantifiable writing outcome metrics within an experimental design.""}}"
Interactive Eassessment of Writing Competency in French as a Foreign Language: Development and Implementation of an Ai-enhanced Progress Monitoring System,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are learners of French as a Foreign Language in Moroccan primary schools. The focus is on French writing competency, not English (ESL/EFL/ELL). Therefore, the population does not meet the review\u2019s requirement of L2 English learners.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions an 'AI-enhanced progress monitoring system' and 'automated analysis,' but does not specify that the AI is a large language model (e.g., ChatGPT, GPT-4) or any transformer-based generative model. The nature of the AI is not clearly described.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on formative e-assessment and progress monitoring of writing competency via an AI-enhanced system, not on writing instruction or intervention in the writing process. It is an assessment/monitoring tool rather than a pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are qualitative (teacher responses, feedback, perceived effectiveness) and system usage statistics. There is no indication of quantifiable student writing outcome metrics (e.g., pre/post writing scores) used to evaluate the impact of the AI system on learners\u2019 writing performance.""}}"
Leveraging Ai for Writing Instruction in Efl Classrooms: Opportunities and Challenges,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 150 fourth-year English major students in an EFL context (a university in the Mekong Delta). The focus is clearly on English as a foreign language writing instruction.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers generically to \u201cAI writing tools\u201d without specifying that they are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems. They could include non-LLM tools such as grammar checkers or other traditional AI, so it is not possible to confirm LLM use from the abstract alone.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is explicitly EFL writing instruction, and the study examines how AI tools are applied in writing classes and how they help improve writing skills. The primary focus is pedagogical use in writing, not automated scoring.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although the study is described as mixed methods and mentions that AI helps students \u2018achieve better writing skills,\u2019 the abstract only reports perceptions and self-reported improvements. It does not indicate any experimental or quasi-experimental design with quantifiable writing outcome measures (e.g., pre/post writing scores, rubric-based assessments). Thus, it does not meet the requirement for reported quantitative writing outcomes of an LLM-mediated intervention.""}}"
"Generative Ai-assisted Feedback and Efl Writing: a Study on Proficiency, Revision Frequency and Writing Quality",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are sixty postgraduate English as a Foreign Language (EFL) students, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses Grammarly as the AI-enhanced feedback system. Grammarly is generally not an LLM-based, transformer-style generative model in the sense required (e.g., ChatGPT, GPT-4, Gemini). The abstract does not indicate integration of a large language model; it frames Grammarly as an AI feedback tool, which falls under the excluded category of tools like Grammarly, Duolingo, QuillBot, Pigai that are not clearly LLM-based generative models.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on writing proficiency, revision practices, and writing quality (content, organization, cohesion) in EFL writing, which aligns with writing competence and writing-related variables.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcomes: pre- and post-test scores of overall writing proficiency, correlations between AI feature use and revision frequency, and improvements in content, organization, and cohesion.""}}"
"Generative Ai Vs. Teachers: Feedback Quality, Feedback Uptake, and Revision",2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were 60 EFL secondary students in a high school in China. The context is explicitly EFL, and the written samples are in English, satisfying the L2 English learner population requirement.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses a 2x2 counter-balanced experimental design where a Gen-AI bot (ChatGPT) and teachers both provide feedback on students\u2019 writing. ChatGPT is a large language model integrated into the writing feedback process, fulfilling the LLM-based intervention criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on written compositions, feedback quality, feedback uptake, and revision of EFL students\u2019 writing. ChatGPT is used pedagogically to provide feedback on student writing, not merely as an automated scoring tool, so the primary focus is on writing competence and revision behavior.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study analyzes 1200 records to compare feedback quality and student uptake rates between AI and teacher feedback, and examines revisions after feedback. These constitute quantifiable writing-related outcome measures (feedback uptake, revision behavior, and feedback quality metrics) within an experimental design.""}}"
"Bridging Ai and Pedagogy: How Ai-adaptive Feedback Shapes Chinese Efl Students' Writing Engagement, Metacognitive Writing Strategies, and Writing Performance",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Chinese university EFL learners in writing contexts, clearly L2 English learners in an EFL setting.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines \u201cAI-adaptive feedback\u201d in general, with no indication that the system is a large language model (e.g., ChatGPT, GPT-4) or transformer-based generative model. It appears to be an AI-enhanced adaptive feedback system, but its underlying technology is unspecified, so it cannot be confidently classified as an LLM-based intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is explicitly EFL writing pedagogy, focusing on writing engagement, metacognitive writing strategies, and writing performance, which are writing-related variables.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract reports quantifiable writing outcomes, including writing performance and structural equation modeling coefficients (e.g., beta = 0.32 for writing performance), indicating measurable effects of the intervention.""}}"
Enhancing Students' L2 Writing by Integrating Artificial Intelligence with Corpus-based Language Pedagogy,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 50 English as a Foreign Language (EFL) learners majoring in English at an English-Medium Instruction university in China, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract states that students used \u201ctheir preferred corpus and AI tools in writing revision\u201d but does not specify that these AI tools are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems. They could be non-LLM tools (e.g., grammar checkers). Without explicit indication of LLM use, eligibility on this criterion is unclear.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on L2 writing revision, integrating AI and corpus-based language pedagogy to support writing development. The primary context is writing competence and revision behavior, not automated scoring or system benchmarking.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract emphasizes attitudes (questionnaires, interviews) and descriptive analysis of types of changes (e.g., corpus for collocations, AI for sentences). It does not report quantifiable writing outcome metrics (e.g., pre/post writing scores, quality ratings) to assess effectiveness of the AI-mediated intervention, focusing instead on usage patterns and perceptions.""}}"
