Title,Year,Decision,Notes
The Application of Chatbot as an L2 Writing Practice Tool,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were 75 Korean elementary school students engaged in English L2 writing practice, clearly an EFL/ESL context with English as the target language.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention used a chatbot developed with Google Dialogflow by encoding textbook expressions. This is a rule/intent-based chatbot, not a transformer-based large language model such as ChatGPT, GPT-4, Gemini, etc. Thus, it does not meet the requirement that the intervention integrate an LLM.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study explicitly focuses on chatbot-based L2 writing practice and compares it with traditional teacher-led writing instruction, with the primary outcome being writing performance.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports pretest and posttest writing performance scores and compares experimental and control groups, providing quantifiable writing outcome metrics. It also includes a survey, but the quantitative writing scores satisfy C4.""}}"
Academic Integrity Considerations of Ai Large Language Models in the Post-pandemic Era: Chatgpt and beyond,2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions 'supporting EFL learners' as one of several potential uses of LLMs, but the paper is framed broadly around students and higher education institutions, not a defined population of L2 English learners. It is unclear whether any empirical data specifically involve EFL/ESL/ELL participants.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The paper is a conceptual/position piece on academic integrity and the potential uses and risks of LLMs such as ChatGPT. It does not describe an experimental or quasi-experimental design integrating LLMs into writing instruction or writing processes; rather, it discusses possibilities and policy implications.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""While writing and composition are mentioned, the primary focus is academic integrity, plagiarism detection, and institutional policy in the post-pandemic era. There is no structured pedagogical intervention targeting writing competence; writing is discussed mainly as the context in which integrity issues arise.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not report any quantitative writing outcome measures or assessment of intervention effectiveness. It analyzes issues and demonstrates that LLMs can generate undetectable text, but there is no experimental measure of changes in learners\u2019 writing performance.""}}"
A Systematic Review on Artificial Intelligence Dialogue Systems for Enhancing English as Foreign Language Students’ Interactional Competence in the University,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The population of interest in the reviewed studies is English as a Foreign Language (EFL) university students, i.e., L2 English learners in an EFL context. The abstract explicitly states the focus is on EFL university students\u2019 interactional competence and English language abilities.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The article itself is a systematic review of AI dialogue systems, not an experimental or quasi-experimental primary study integrating a specific LLM (e.g., ChatGPT, GPT-4) into writing instruction. As a review article, it does not present a distinct LLM-based intervention designed and tested by the authors.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on interactional competence and broader EFL learning (reading, writing, listening) via AI dialogue systems, not specifically on writing competence or writing-related variables. Writing is mentioned only generally as one of several skills previously improved, and the review centers on interactional competence, not writing-focused pedagogy.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a systematic review, the study does not report original, quantifiable writing outcome metrics from an LLM-mediated intervention conducted by the authors. It synthesizes prior work on AI dialogue systems and interactional competence, and the abstract does not indicate any experimental measures of writing outcomes.""}}"
Utilizing Artificial Intelligence Technologies in Saudi Efl Tertiary Level Classrooms,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The context is clearly Saudi EFL tertiary-level classrooms, i.e., learners of English as a foreign language in Saudi Arabia. The abstract explicitly refers to EFL and ELT settings, indicating L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study discusses a broad range of AI technologies (Google Translate, Bing Translator, machine translation, automatic evaluation systems, and Wordtune). These are not identified as large language model\u2013based tools, and the design is exploratory using questionnaires about use and perceptions, not an experimental or quasi-experimental LLM-based writing intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although writing with AI technologies is mentioned, the primary focus is on general AI use in EFL classrooms and communication training, not on a structured writing competence intervention. It is framed as an exploratory investigation of AI technologies in ELT rather than a targeted writing-instruction context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Data were collected via questionnaires and analyzed with SPSS, indicating attitudinal or usage measures. The abstract does not report any quantifiable writing performance outcomes or writing-related proficiency metrics; it only concludes that AI technologies can assist teaching and learning.""}}"
A Corpus-based Study of the Usage of Chinese Core Separable Words in the Use of Language,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are Chinese as a second language learners and native Chinese speakers. The focus is on learning and usage of Chinese core separable words, not on L2 English learners in ESL/EFL/ELL contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a corpus-based analysis using BCC, CCL, and HSK corpora. There is no mention of large language models, ChatGPT-like systems, or any AI-based instructional intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The context is lexical usage of Chinese separable words and their treatment in International Chinese Language Education, not writing competence in English or writing-related interventions with LLMs.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports corpus-based usage patterns and error types, not quantifiable outcomes of an LLM-mediated writing intervention. There is no experimental or quasi-experimental design assessing writing outcomes.""}}"
A Deep Fusion Model for Human Vs. Machine-generated Essay Classification,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Although the abstract mentions essays in English and Spanish written by L2 learners, it does not specify that these are L2 English learners in ESL/EFL/ELL contexts, and the focus is on classification of human vs. machine-generated essays rather than L2 English learning.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study proposes a deep neural network-based classifier for distinguishing human vs. machine-generated essays. There is no experimental or quasi-experimental pedagogical intervention integrating an LLM (e.g., ChatGPT) into writing instruction or processes; LLMs are only an implicit source of machine-generated text.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on essay classification for academic integrity (human vs. machine-generated), not on improving writing competence or writing-related learning outcomes. It is essentially a text classification/forensics task, not a writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) are reported. Outcomes are model performance metrics (classification accuracy, etc.), not learner writing development under an LLM-mediated intervention.""}}"
Efl Paraphrasing Skills with Quillbot: Unveiling Students' Enthusiasm and Insights,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are explicitly described as EFL (English as a foreign language) preparatory year students, indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention tool is QuillBot. Based on the review\u2019s criteria, tools like QuillBot are treated as AI writing aids that are not clearly positioned as transformer-based generative LLMs for instructional integration. The abstract does not indicate use of an LLM such as ChatGPT, GPT-4, Gemini, etc., but rather a paraphrasing tool, which falls under the exclusion note for non-LLM AI tools.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on paraphrasing skills within writing, including performance in synonyms, sentence structure, and word choice, and the context is a writing class. This aligns with writing competence as the primary focus.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses a quasi-experimental design and reports that students improved their performance in synonyms, sentence structure, and word choice, indicating quantifiable writing-related outcome measures alongside attitudinal data.""}}"
Comparing Measures of Syntactic and Lexical Complexity in Artificial Intelligence and L2 Human-generated Argumentative Essays,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are first-year Tswana L2 learners of English at a South African university, clearly an L2 English learner population in an EFL/ESL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT-3.5 is used only to generate comparison essays; there is no experimental or quasi-experimental pedagogical intervention integrating the LLM into writing instruction or learners\u2019 writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on comparing syntactic and lexical complexity between AI- and human-generated essays, not on improving learners\u2019 writing competence or implementing a writing intervention. It is an analytic comparison, not a teaching/learning context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics for an LLM-mediated intervention are reported. The study analyzes complexity features but does not assess changes in learners\u2019 writing due to an LLM-based instructional treatment.""}}"
The Use and Abuse of Artificial Intelligence-enabled Machine Translation in the Efl Classroom: an Exploratory Study,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL learners in higher education where English is not their first language, fitting the L2 English learner population criterion.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses AI-enabled machine translation, specifically Google Translate. GT is not described as an LLM-based, transformer generative model used as a writing assistant (e.g., ChatGPT, GPT-4); it is a machine translation tool, which falls outside the specified LLM-focused intervention scope.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study compares writing drafts created with and without Google Translate, focusing on how MT use affects writing quality and learners\u2019 practices in the EFL classroom, which is directly related to writing competence.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Pre- and post-tests are used to compare the quality of writing drafts with and without GT, indicating quantifiable writing outcome measures are reported.""}}"
Work in Progress: Chatgpt as an Assistant in Paper Writing,2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions \u201cnon-native English speakers,\u201d which suggests L2 English users, but it does not specify ESL/EFL/ELL instructional contexts or participant characteristics. It may be more conceptual than participant-based.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is described as a discussion of the potential of ChatGPT as an assistant in paper writing. There is no indication of an experimental or quasi-experimental design, structured intervention, or empirical implementation of ChatGPT in instruction.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The focus is on \u201cpaper writing\u201d in natural English, which is writing-related, but the abstract frames it as a conceptual discussion of ChatGPT\u2019s potential and ethical use rather than a pedagogical intervention study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics or empirical evaluation are mentioned. The abstract only states that the paper discusses potential and educational use, with no indication of measured effects on writing performance.""}}"
A Deep Fusion Model for Human $vs$. Machine-generated Essay Classification,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract states that the datasets contain short essays in English and Spanish written by L2 learners. Thus, the population includes L2 learners writing in English, which fits the ESL/EFL/ELL context requirement.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study proposes a deep neural network-based model for classifying essays as human vs. machine-generated. It does not describe an instructional intervention using an LLM (e.g., ChatGPT) in writing instruction or processes; instead, it is a text classification/modeling study.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on essay classification for academic integrity (human vs. machine-generated), not on improving writing competence or writing-related pedagogical variables. It is a computational classification task rather than a writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity) are reported. Outcomes relate to classification performance, not to the effectiveness of an LLM-mediated writing intervention.""}}"
A Syntactic Complexity Analysis of Revised Composition through Artificial Intelligence-based Question-answering Systems,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are college English learners taking the TEM-4 test, which is an English proficiency test for Chinese EFL learners. The focus is clearly on L2 English argumentative essay writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used to revise students\u2019 essays, the design is a comparison between original student texts and ChatGPT-revised versions, not an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction or learners\u2019 writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on syntactic complexity differences between human-written and AI-revised texts. There is no described instructional context, no learner interaction with the tool as part of a teaching/learning intervention, and no evaluation of writing competence development\u2014only text-level comparison.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports syntactic complexity metrics comparing student vs. ChatGPT-revised essays, but these are not outcomes of an LLM-mediated intervention on learners\u2019 writing performance over time. No experimental measures of learner improvement or structured intervention outcomes are reported.""}}"
Intertextuality in Pre-service Teachers' Argumentative Essay in Raising Ai: Practices and Beliefs,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Indonesian EFL pre-service teachers, clearly L2 English learners in an EFL context: \u201cIndonesian EFL pre-service teachers\u2026 were recruited as participants.\u201d""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions \u201cargumentative essays assisted by AI\u201d and \u201cassistance using AI while writing argumentative essays,\u201d but does not specify that the AI is an LLM (e.g., ChatGPT, GPT-4) or describe the AI tool or its generative/transformer-based nature. It could be any AI-based support, not necessarily an LLM, and there is no explicit experimental or quasi-experimental intervention design described.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on argumentative essay writing and intertextuality practices: \u201cinvestigate\u2026 intertextuality in argumentative essays assisted by AI.\u201d This is a writing-focused context, examining rhetorical moves and use of sources in EFL academic writing.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is described as a case study using content analysis of essays and interviews to portray practices and beliefs. There is no indication of an experimental or quasi-experimental design, no comparison groups, and no reported quantifiable writing outcome metrics assessing effectiveness of an AI/LLM-mediated intervention. The focus is descriptive/qualitative (practices and beliefs), not on measured writing gains.""}}"
Utilization of Artificial Intelligence in Academic Writing Class: L2 Learners Perspective,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as second language (L2) learners in the Philippines, implying English L2 learners in an EFL/ESL academic writing context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a descriptive survey of perceptions and experiences with AI tools; there is no experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into instruction or writing processes.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is explicitly academic writing, focusing on how AI tools are utilized to support various aspects of writing (idea generation, error detection, structural feedback, etc.).""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports awareness, preferences, and concerns, but does not mention any quantifiable writing outcome measures or effectiveness data from an AI-mediated writing intervention.""}}"
Looks like Google to Me: Instructor Ability to Detect Machine Translation in L2 Spanish Writing,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are L2 learners of Spanish in an intermediate-level writing course. The target language is Spanish, not English, so the population does not match the review\u2019s focus on L2 English learners in ESL/EFL/ELL contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study concerns detection of machine translation (MT) in L2 Spanish writing, not an instructional intervention using large language models such as ChatGPT or GPT-4. MT tools are not specified as LLM-based generative models, and there is no experimental or quasi-experimental LLM-mediated writing instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on instructors\u2019 ability to detect MT versus non-MT texts and related factors, not on a pedagogical intervention aimed at improving writing competence through LLM integration.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study does not report quantifiable writing outcome metrics assessing the effectiveness of an LLM-mediated writing intervention; it reports detection accuracy and related variables instead.""}}"
Impact of Chatgpt on Learners in a L2 Writing Practicum: an Exploratory Investigation,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract clearly states the context is a 'one-week L2 writing practicum' and refers to 'L2 writing learners,' indicating participants are second language learners engaged in English L2 writing.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""ChatGPT, an AI-powered chatbot capable of automatic text generation, was applied in a one-week L2 writing practicum. This is an LLM-based tool integrated into writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is explicitly L2 writing pedagogy and a writing practicum, focusing on the impact of ChatGPT on L2 writing learners and composing workflows, which aligns with writing competence and writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is described as adopting a qualitative approach to investigate students' behaviors, reflections, developmental features in learning activities, and perceptions. There is no mention of quantitative or experimental writing outcome measures (e.g., scores, rubric-based improvements), only exploratory qualitative evaluation.""}}"
Roles and Research Foci of Artificial Intelligence in Language Education: an Integrated Bibliographic Analysis and Systematic Review Approach,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The article is a broad review of AI in language education (AILEd) from 1990\u20132020 and does not focus specifically on L2 English learners in ESL/EFL/ELL contexts. It aggregates diverse studies across language skills and technologies without specifying an L2 English learner population as the primary focus.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""This is an integrated bibliographic analysis and systematic review, not an experimental or quasi-experimental study implementing an LLM-based intervention. It surveys prior work using ITS, NLP, and various AI algorithms, but does not itself integrate LLMs (e.g., ChatGPT, GPT-4) into writing instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the review notes that writing is one of the main application domains in AILEd research, the article\u2019s primary focus is mapping roles and research foci of AI across multiple skills and constructs, not conducting a specific writing competence intervention or study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a review article, it does not report original, quantifiable writing outcome metrics from an LLM-mediated intervention. It synthesizes existing literature and offers suggestions rather than testing and measuring the effectiveness of a particular AI/LLM writing intervention.""}}"
Recipe: How to Integrate Chatgpt into Eflwriting Education,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 213 undergraduate and graduate students enrolled in EFL writing courses, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study introduces RECIPE, a platform that integrates ChatGPT (a large language model) into EFL writing education, with ChatGPT taking an EFL teacher role and engaging in dialogue based on students\u2019 self-written summaries.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is explicitly EFL writing courses, and the platform is designed for revising an essay with ChatGPT, focusing on writing-related learning processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract states that the study collects interaction data, students\u2019 perceptions and usage, examines user scenarios, and conducts interviews to explore design opportunities. It does not mention any experimental or quasi-experimental design with quantifiable writing outcome measures (e.g., writing scores, quality ratings, accuracy gains). Outcomes are primarily perceptions and usage, so it does not meet the requirement for quantifiable writing outcomes.""}}"
Who Wrote This Essay? Detecting Ai-generated Writing in Second Language Education in Higher Education,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The context is English as a Second Language (ESL) in higher education, and the essays are C1-level L2 English texts. Although the participants are lecturers, the focus remains on L2 English writing in an ESL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study investigates lecturers\u2019 ability to detect AI-generated texts and compares their judgments with AI detectors. There is no experimental or quasi-experimental integration of an LLM (e.g., ChatGPT) into writing instruction or learners\u2019 writing processes as an intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is academic integrity and detection of AI-generated writing, not on improving learners\u2019 writing competence or implementing a pedagogical writing intervention. It examines assessment practices and detection challenges rather than writing instruction outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics for learners are reported. The study analyzes lecturers\u2019 evaluations and AI detectors\u2019 performance, not changes in students\u2019 writing quality or related measurable writing outcomes following an LLM-mediated intervention.""}}"
Assessing Second-language Academic Writing: Ai Vs. Human Raters,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are first-year college students producing L2 academic paragraph writing; the context is clearly second-language (L2) writing, likely English, used for departmental eligibility.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT-3.5 is used as an automated rater to score student writing, not as part of an instructional or intervention design to support writing development. There is no experimental or quasi-experimental LLM-based teaching or feedback intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on assessment\u2014comparing AI vs. human raters for evaluating L2 writing quality. This is an automated essay scoring/assessment study, not a pedagogical writing intervention or process-oriented support.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although writing scores are reported, they are used solely to examine rater agreement (AI vs. humans), not to evaluate the effectiveness of an LLM-mediated writing intervention on learners\u2019 writing outcomes over time.""}}"
