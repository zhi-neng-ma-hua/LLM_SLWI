Title,Year,Decision,Notes
Is This Really Your Work?: a Qualitative Study of Teacher-led Interviews and Student Accountability in the Age of Generative Ai,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 24 Master's-level English as a Foreign Language (EFL) students, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the study concerns student engagement with generative AI tools, it does not describe an experimental or quasi-experimental LLM-based writing instruction or intervention. The focal intervention is teacher-led interviews as an assessment practice, not structured LLM-mediated writing instruction or process support.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on authorship, integrity, accountability, and ethical orientation in academic work, not on writing competence or writing-related performance variables. Writing is the context, but the outcome focus is ethical and reflective engagement with GenAI, not writing development.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is explicitly qualitative, using thematic analysis of reflection data. It reports cognitive, emotional, and agentive developments but no quantifiable writing outcome metrics or experimental measures of writing performance.""}}"
Integrating Iwrite Tools into English Writing Instruction,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract describes English writing instruction in Chinese universities, implying that participants are Chinese learners of English in an EFL context, i.e., L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The tool mentioned is \u2018iWrite\u2019, described generically as an AI tool for grammar correction, vocabulary enhancement, and structural analysis. There is no indication that it is a large language model (e.g., ChatGPT/GPT-4-like transformer-based generative model). It appears more akin to traditional AI-assisted writing tools, which fall outside the LLM-focused scope.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on English writing instruction and improving writing proficiency, including grammar, vocabulary, and structure, which aligns with writing competence as the primary context.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions \u2018methods, outcomes, and challenges\u2019 and claims that iWrite \u2018improves writing proficiency\u2019 and \u2018enhance[s] writing skills\u2019, but it does not specify any experimental or quasi-experimental design or report quantifiable writing outcome metrics. It is unclear whether systematic, measurable outcomes are presented.""}}"
A Literature Review on Generative Artificial Intelligence Applications in Foreign Language Education,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The article is explicitly described as a literature review of generative AI in foreign language education, synthesizing 30 empirical studies. It is not an empirical study with its own participant population of L2 English learners; instead, it aggregates prior work.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""As a literature review, the paper does not itself implement an experimental or quasi-experimental LLM-based writing intervention. It only summarizes existing studies and their use of GenAI tools.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is broad\u2014foreign language education across multiple categories (user perceptions, language learning applications, assessment, teacher preparation, affective factors). It is not a primary study centered on a specific writing competence intervention context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The article does not report original, quantifiable writing outcome metrics. It is a qualitative synthesis of prior empirical studies and thus falls under review articles, which are excluded by the protocol.""}}"
"Effects of Speech-enabled Corrective Feedback Technology on Efl Speaking Skills, Anxiety and Confidence",2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are clearly described as learners of English as a foreign language (EFL) and university students from China and Kazakhstan engaged in EFL speaking practice, so the population fits L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is a speech-enabled corrective feedback (SECF) system combining speech-to-text recognition (STR) and automated corrective feedback (ACF). There is no indication that this system is based on large language models (e.g., ChatGPT, GPT-4, transformer-based generative models); it appears to be an STR plus rule-based or non-LLM ACF tool.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on speaking skills, foreign language anxiety, and confidence in speaking. Although STR converts speech to text, the intervention and outcomes target spoken English proficiency, not writing competence or writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Quantitative outcomes reported concern EFL speaking ability (pronunciation, grammar, vocabulary, discourse length) and affective variables (anxiety, confidence). No quantifiable writing outcome metrics are mentioned.""}}"
Chatgpt in Foreign Language Teaching and Assessment: Exploring Efl Instructors' Experience,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The participants are EFL/ESP instructors (teachers) from Ukraine, the EU, and the USA, not L2 English learners. The study focuses on teachers\u2019 perceptions and experiences, not learner outcomes.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is central, the study is a survey of instructors\u2019 perceptions about using ChatGPT for teaching and assessment. There is no experimental or quasi-experimental design integrating ChatGPT into actual learner writing instruction or processes.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""Writing is mentioned as one of several skills (along with vocabulary and grammar) for which ChatGPT can assist in task design and assessment, but the primary focus is broad foreign language teaching and assessment, not specifically writing competence or writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports survey-based perceptions (confidence, familiarity, satisfaction) of instructors. It does not report any quantifiable learner writing outcome metrics or results from an LLM-mediated writing intervention.""}}"
Evaluating Automated Grammar Corrective Feedback Tools: a Comparative Study of Grammarly and Quillbot in Esl Expository Essays,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Malaysian ESL students producing expository essays, clearly indicating L2 English learners in an ESL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The tools investigated are Grammarly and Quillbot, which are automated grammar feedback applications. The abstract frames this as a comparative analysis of their error detection capabilities, not as an LLM-based pedagogical intervention. Grammarly and Quillbot are not specified as transformer-based generative LLMs in this context, and the study design is tool-comparison rather than an instructional intervention using LLMs.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on how well the tools identify and classify errors in existing writing samples, not on improving learners\u2019 writing competence through an instructional intervention. It is essentially an evaluation of automated writing evaluation tools, not a writing pedagogy study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable learner writing outcomes or pre/post intervention measures are reported. The metrics are frequencies of errors flagged by the tools, not changes in students\u2019 writing performance following an intervention.""}}"
Engage Learn: an Ai-based English Proficiency Improviser,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract describes an English learning and teaching platform but does not specify the learner population (e.g., EFL/ESL/ELL, age, educational context) or confirm that participants are L2 English learners rather than general users.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The system integrates generative models (ChatGPT 3.5 Turbo and Gemini 1.5 Flash) with RAG into an English learning platform that provides targeted feedback on grammar, vocabulary, and fluency, indicating an LLM-based instructional intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The platform aims to help users write and speak English more effectively, with modules for grammar correction, vocabulary buildup, and feedback on user input. Writing competence and related variables are explicitly part of the focus, alongside speaking.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract only mentions that the paper presents planned evaluation methods and user testing to ensure the system promotes language learning. It does not report any experimental or quasi-experimental results, nor quantifiable writing outcome metrics; it appears to be a system description with prospective evaluation.""}}"
Personalized Recommendation Design of English Writing Marking System Based on Corpus,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract discusses college English writing teaching and higher vocational English teaching, implying learners of English in an EFL/ESL context. The population appears to be L2 English learners in tertiary education settings.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study focuses on a corpus-based automatic scoring and computer-aided composition marking system. There is no indication that large language models (e.g., ChatGPT, GPT-4) or transformer-based generative models are used; it appears to be a traditional automated scoring/AE system rather than an LLM-mediated intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly English writing instruction and assessment, with emphasis on composition marking and integrating an automatic evaluation system into classroom teaching, which is directly related to writing competence.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract describes a teaching method and system design but does not report any explicit quantitative writing outcome measures or experimental evaluation results. It is unclear whether the study includes measurable writing outcomes.""}}"
University Students' Perceptions of Artificial Intelligence-based Tools for English Writing Courses,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Korean university students who have taken English writing courses and are described as English language learners (ELLs), fitting an EFL/ELL L2 English context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study investigates perceptions of AI-based tools (Google Translate, Naver Papago, Grammarly). These are not clearly LLM-based interventions, and there is no experimental or quasi-experimental design integrating an LLM (e.g., ChatGPT, GPT-4) into instruction; it is a perception survey and focus group.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on students\u2019 perceptions of AI-based tools, their strengths/weaknesses, and potential interference with writing processes, not on a structured pedagogical writing intervention or measured changes in writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses mixed methods (survey and interviews) to explore perceptions. There is no indication of quantifiable writing outcome metrics (e.g., writing scores, text quality measures) resulting from an AI-mediated intervention.""}}"
Investigating Efl Faculty Members' Perceptions of Integrating Artificial Intelligence Applications to Improve the Research Writing Process: a Case Study at Majmaah University,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are EFL faculty members (teachers), not L2 English learners in ESL/EFL/ELL contexts. The focus is on their own research writing, not on student L2 learning.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers broadly to \u201cAI applications and tools\u201d without specifying large language models (e.g., ChatGPT, GPT-4). It also does not describe any experimental or quasi-experimental instructional intervention; it investigates perceptions via questionnaires and interviews.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The context is research writing by EFL educators and their perceptions of AI tools, not a pedagogical intervention targeting L2 writing competence of learners. It is not framed as writing instruction or an L2 writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports attitudes and perceptions, using descriptive and inferential statistics on questionnaire data, but does not report quantifiable writing outcome measures (e.g., changes in writing quality, accuracy, complexity) resulting from an AI-mediated intervention.""}}"
The Effects of Generative Ai Usage in Efl Classrooms on the L2 Motivational Self System,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Japanese university students in an EFL writing class, i.e., L2 English learners in an EFL context: \u201cJapanese university students\u2026 writing class.\u201d""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention integrates the LLM-based chatbot ChatGPT into an instructor-led writing class: \u201cincorporating the generative pre-trained AI chatbot, ChatGPT, into an instructor-led writing class\u2026 treatment group\u2026 received feedback from ChatGPT.\u201d""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on motivation (L2 Motivational Self System), not on writing competence or writing-related performance variables: \u201cThis study aimed to examine the effect\u2026 on the motivation of Japanese university students\u2026 examines changes in students\u2019 Ideal L2 Self, Ought-to L2 Self, and L2 Learning Experience.\u201d Writing is the context, but not the main outcome variable.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Quantitative outcomes reported are motivational constructs (Ideal L2 Self, Ought-to L2 Self, L2 Learning Experience). The abstract does not report any quantifiable writing performance metrics (e.g., scores, quality ratings, accuracy, complexity). References to \u201cenhancing\u2026 writing skills\u201d are not accompanied by measured writing outcomes.""}}"
Investigating the Impact of Chatgpt as an Ai Tool on Esl Writing : Prospects and Challenges in Saudi Arabian Higher Education,2024,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly states the population is ESL students at a Saudi Arabian university, indicating L2 English learners in an EFL/ESL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study clearly involves ChatGPT as an AI tool in writing, but the abstract does not specify whether there is an experimental or quasi-experimental design (e.g., control group, pre/post intervention) or describe the structured nature of the intervention. It only notes a mixed-methods approach and that data from 130 students showed a positive effect.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on ESL students\u2019 writing proficiency and how ChatGPT is integrated into writing instruction, with discussion of feedback, language skill development, vocabulary, and autonomy. This aligns with writing competence and writing-related variables rather than automated scoring.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract reports that data from 130 students showed a significant positive effect on writing, implying quantitative outcomes, but it does not specify what writing measures were used or how proficiency was quantified. It is unclear whether concrete, quantifiable writing outcome metrics were systematically assessed.""}}"
Beyond Syntax: Exploring Moroccan Undergraduate Efl Learners' Engagement with Ai-assisted Writing,2024,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Moroccan undergraduate EFL learners in a general English course, clearly indicating L2 English learners in an EFL context: \u201cundergraduate EFL learners\u2026 Business Law undergraduates enrolled in a general English course at the International University of Rabat, Morocco.\u201d""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cAI-supported writing tools\u201d and \u201cAI assistance\u201d but does not specify whether these are large language model tools (e.g., ChatGPT, GPT-4) or other AI tools (e.g., grammar checkers). Without explicit mention of LLM-based tools or transformer-based generative models, it is unclear if the intervention meets the LLM criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on writing: \u201cfocusing specifically on writing,\u201d examining \u201cstudent-written assignments,\u201d and reporting impacts on \u201clanguage proficiency, creativity, organizational skills, and vocabulary use with AI assistance,\u201d all within the context of AI-supported writing processes.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study is described as a quasi-experimental design with a control group and reports \u201cpositive outcomes in language proficiency, creativity, organizational skills, and vocabulary use with AI assistance,\u201d implying quantifiable outcome measures to compare groups, even though specific metrics are not detailed in the abstract.""}}"
Chatgpt for Language Learning: Assessing Teacher Candidates' Skills and Perceptions Using the Technology Acceptance Model (tam),2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL teacher candidates performing tasks in Spanish (L1) and English (L2), so they are L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT-4 is used only to generate comparison texts. There is no experimental or quasi-experimental instructional intervention where learners use the LLM as part of their writing instruction or process; instead, participants compare and evaluate human vs. machine texts.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on critical skills in distinguishing human vs. machine-generated texts and perceptions of ChatGPT (TAM variables), not on improving writing competence through an LLM-mediated pedagogical intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although text metrics (SC, ASL, VOCD) are used to compare human and machine texts, they are not reported as learning outcomes of an LLM-based writing intervention. The study does not assess changes in learners\u2019 writing performance due to using ChatGPT.""}}"
"Graduate Students' Use of Chatgpt for Academic Text Revision: Behavioral, Cognitive, and Affective Engagement",2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as six Iranian graduate ESL students from STEM fields, indicating L2 English learners in an ESL context with a focus on English academic writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is observational/qualitative, examining how students engaged with ChatGPT for revising their own academic research proposals. There is no indication of an experimental or quasi-experimental intervention design (e.g., treatment vs. control, pre/post measures) integrating ChatGPT into instruction; rather, it analyzes existing use and engagement.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly L2 academic writing and text revision, focusing on how students use ChatGPT for revising research proposals and paraphrasing to enhance professionalism in writing, which aligns with writing competence and writing-related processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are behavioral, cognitive, and affective engagement (e.g., satisfaction, doubts about accuracy). The abstract does not mention any quantifiable writing outcome metrics (such as scores, rubric-based writing quality measures, or error rates) to assess effectiveness of the ChatGPT-mediated revision.""}}"
Understanding Efl Students ' Use of Self-made Ai Chatbots as Personalized Writing Assistance Tools: a Mixed Methods Study,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 69 Chinese undergraduate EFL students, clearly L2 English learners in an EFL context: \u201cEnglish as a foreign language (EFL) students\u2026 69 Chinese undergraduate students.\u201d""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention involves students creating and using self-made RAG chatbots via Poe to assist with their writing processes. RAG chatbots are LLM-based tools, and the study integrates them into writing instruction/workshop activities.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on writing: chatbots assist with idea generation, outlines, and error identification, and students write essays using their chatbots. The workshop is about learning to write and using chatbots as personalized writing assistance tools.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Reported outcomes are motivational and attitudinal: \u201cpositive impact on students' writing motivation\u2026 clearer writing goals, increased writing confidence, reinforced writing beliefs, and a more positive attitude towards writing.\u201d The abstract does not indicate any quantitative writing performance metrics (e.g., scores, quality ratings, accuracy measures); essays are collected but no measured writing outcomes are reported.""}}"
Identifying Chatgpt-generated Texts in Efl Students' Writing: through Comparative Analysis of Linguistic Fingerprints,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Japanese EFL learners (140 first-year university students), clearly fitting an L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is present only as a source of comparison texts and as a tool some students used (proofreading or full generation), but there is no described experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or a structured writing process. The design focuses on distinguishability of texts, not an instructional treatment.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on identifying ChatGPT-generated texts via linguistic fingerprints and machine learning classification, not on improving writing competence or evaluating a writing intervention. It is essentially a detection/forensics study, not a pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., gains in writing quality, accuracy, complexity) are reported to assess the effectiveness of an LLM-mediated intervention. Outcomes concern distinguishability and classification performance, not learner writing development.""}}"
Generative Ai's Recolonization of Efl Classrooms,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The context is Chinese English as a Foreign Language (EFL) classrooms, clearly involving L2 English learners in an EFL setting.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the paper discusses generative AI and AI chatbots producing continuation writing samples, it is a critical/discursive analysis, not an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction. No structured intervention design is described.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on ideological, cultural, and linguistic risks (recolonization, native-speakerism) in AI-generated texts, not on developing or evaluating writing competence through an instructional intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or assessment of learners\u2019 writing performance. It illustrates arguments with AI-generated data and SFL analysis, not learner outcome metrics.""}}"
Korean-as-a-foreign-language Learners' Engagement with Machine Translation Output,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are US university students learning Korean as a foreign language. The target language is Korean, not English, and the context is not ESL/EFL/ELL focused on English, so it does not meet the population criterion.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses 'machine translators and other artificial intelligence-assisted programs' and a Guided Use of Machine Translation model. It is not specified whether the machine translator is an LLM-based system (e.g., GPT-based) or a traditional MT system, so its status as an LLM intervention is unclear.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study explicitly focuses on how learners use machine translators to revise their writing and analyzes their engagement and revision strategies, indicating a primary focus on writing processes and competence.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses cognitive and behavioral engagement, focus on word choice, and revision strategies, but does not report quantifiable writing outcome metrics (e.g., scores, accuracy rates pre/post). It is unclear whether such quantitative outcomes are measured.""}}"
Automatic Scoring of Arabic Essays: a Parameter-efficient Approach for Grammatical Assessment,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The study focuses on Arabic automated essay scoring using AraBART and evaluates essays in Arabic (datasets QALB-2014, QALB-2015, ZAEBUC). There is no indication that participants are L2 English learners or that the target language is English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although a transformer-based model (AraBART) is used, it is applied for automated essay scoring, not as an instructional or intervention tool integrated into learners\u2019 writing processes. There is no experimental or quasi-experimental pedagogical design involving LLM-mediated writing instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on developing and validating an automatic scoring system for grammaticality and other criteria in Arabic essays. This is an AES functionality study, not a pedagogical writing intervention aimed at improving learners\u2019 writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are model performance metrics (e.g., scoring accuracy, efficiency) rather than quantifiable changes in learners\u2019 writing performance following an LLM-mediated intervention. No experimental measures of learner writing improvement are described.""}}"
