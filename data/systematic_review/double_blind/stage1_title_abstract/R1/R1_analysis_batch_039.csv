Title,Year,Decision,Notes
Writing Argumentative Essays: Jambi Efl Students' Challenges and Strategies,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL students at the English Education Study Program of a public university in Jambi, Indonesia, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although students report using \u2018AI applications\u2019 as a technology utilization strategy, the study is a qualitative case study exploring challenges and self-reported strategies. There is no experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into instruction or writing processes as an intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on difficulties in writing argumentative essays and strategies to overcome them, which is directly related to writing competence and writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses qualitative methods (semi-structured interviews, document analysis, thematic analysis) and reports problems and strategies. It does not report quantifiable writing outcome metrics or evaluate the effectiveness of an LLM-mediated intervention.""}}"
L2 Students' Barriers in Engaging with Form and Content-focused Ai-generated Feedback in Revising Their Compositions,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are described as 'L2 students in a computer science program' writing argumentative essays in English, indicating L2 English learners in an academic EFL/ESL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""Students were 'tasked with seeking corrective feedback from ChatGPT for their argumentative essays,' which is an LLM-based tool integrated into their writing process in an experimental task.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on L2 writing, specifically revision behavior in response to AI-generated feedback on argumentative essays, clearly centering on writing processes and feedback use.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports proportions of feedback accepted/rejected and qualitative reasons for non-uptake, but does not mention any quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, or scores) to assess the effectiveness of the LLM-mediated intervention.""}}"
Balancing Ai and Authenticity: Efl Students' Experiences with Chatgpt in Academic Writing,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as EFL students, indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used, the study is a qualitative case study of students\u2019 experiences and strategies, not an experimental or quasi-experimental intervention design integrating LLMs into instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on academic writing processes and how ChatGPT is incorporated into students\u2019 writing, including effects on essay quality and authenticity, which aligns with writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study relies on semi-structured interviews and self-reported experiences; it does not report quantifiable writing outcome metrics or experimental measures of writing performance.""}}"
Investigating Students' Cognitive Processes in Generative Ai-assisted Digital Multimodal Composing and Traditional Writing,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) writers, indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although generative AI tools (ChatGPT, Bing Chat, Bing Image Creator) are used, the study is described as a qualitative exploration of composing processes over two weeks, not as an experimental or quasi-experimental intervention design testing the effectiveness of an LLM-based instructional treatment.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on generative AI-assisted composing processes in multimodal PPT projects and traditional argumentative essays, which are clearly writing-related tasks and processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports qualitative analyses of cognitive and composing patterns, use of AI-generated text and images, and pedagogical implications. It does not mention any quantifiable writing outcome metrics (e.g., scores, rubric-based ratings, measurable gains) to assess effectiveness of the AI-assisted writing intervention.""}}"
Ai Chatbot as a Companion in Writing Travel Notes1,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are Russian heritage language speakers and advanced Russian-as-a-foreign-language learners in a German university. The target language is Russian, not English, so the population does not consist of L2 English learners in ESL/EFL/ELL contexts.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses a customized chatbot built on the ChatGPT model (a large language model) as an interactive interlocutor and writing assistant within a structured learning scenario, indicating an LLM-based intervention in writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on improving writing competency in the travel note genre, using a genre-based approach and a five-step genre cycle. The chatbot is integrated specifically to support writing processes and genre awareness, not for automated scoring.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract reports observations about potential benefits and contributions to L2 reading and writing skills but does not clearly indicate experimental or quasi-experimental quantitative writing outcome measures. It appears more exploratory/observational, but this cannot be fully confirmed from the abstract alone.""}}"
English Paraphrasing Strategies and Levels of Proficiency of an Ai-generated Quillbot and Paraphrasing Tool: Case Study of Scientific Research Abstracts,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The study paraphrases 30 abstracts from the Journal of Second Language Writing using AI tools. There are no human participants, and thus no L2 English learners in ESL/EFL/ELL contexts are involved.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The tools examined are QuillBot and an unnamed Paraphrasing Tool. These are generic AI paraphrasers and the abstract does not indicate that they are LLM-based (e.g., ChatGPT/GPT-4-like transformer generative models) nor that they are integrated into an instructional intervention; they are only evaluated as tools.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on analyzing paraphrasing strategies and proficiency levels of the tools themselves, not on a pedagogical context or intervention aimed at improving learners\u2019 writing competence. It is a tool-focused case study, not a writing instruction study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics for learners are reported. The study evaluates outputs of AI tools qualitatively; there is no experimental or quasi-experimental intervention measuring changes in learner writing performance.""}}"
Eap Teacher Feedback in the Age of Ai: Supporting First-year Students in Efl Disciplinary Writing,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly refers to \u201cEnglish as a foreign language (EFL) disciplinary writing\u201d and \u201cfirst-year EFL undergraduate students in their discipline-specific academic writing within EMI settings,\u201d indicating L2 English learners in an EFL/EMI context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although generative AI is mentioned as a feedback tool, the study investigates the nature of EAP teacher feedback and compares it with students\u2019 perceptions of teacher vs. AI-generated feedback. There is no indication of an experimental or quasi-experimental LLM-based writing intervention; AI is a comparison point in perceptions, not an instructional treatment integrated into writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on \u201cEFL disciplinary writing,\u201d \u201cdiscipline-specific academic writing,\u201d and feedback on that writing, which aligns with writing competence and writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract describes qualitative analysis (three-layer coding scheme, interview themes) about the nature of feedback and perceptions. It does not report quantifiable writing outcome metrics or experimental measures of the effectiveness of AI-mediated writing interventions.""}}"
Reflections on Co-researching Ai Literacy: a Students-as-partners Approach with International Students,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The participants are described as international students in a UK pre-sessional English for Academic Purposes (EAP) course, which likely implies L2 English learners, but this is not explicitly stated in the abstract.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a Students-as-Partners case study on AI literacy, focusing on learning about AI limitations and prompt writing. There is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into writing instruction as an intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is AI literacy, SaP processes, and partnership reflections, not writing competence or writing-related variables. Writing is not presented as the central outcome domain.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics. It discusses perceived benefits (e.g., learning about AI limitations, prompt writing skills) and offers recommendations, but no experimental measures of writing performance are mentioned.""}}"
Chatgpt-generated Corrective Feedback: Does It Do What It Says on the Tin?,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as students at CEFR B1 level attending an English for Academic Purposes (EAP) course at an international branch campus of a UK university, which fits an ESL/EAP L2 English learner context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study compares ChatGPT-generated corrective feedback with teacher-provided feedback on students\u2019 essays, but it is framed as an evaluation of ChatGPT\u2019s feedback capabilities, not as an experimental or quasi-experimental pedagogical intervention integrating ChatGPT into instruction or the writing process with measured learning effects.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on the quantity and quality of corrective feedback produced by ChatGPT versus teachers, i.e., the adequacy of the feedback strategy and guidance. It does not describe an instructional intervention aimed at improving writing competence; rather, it assesses ChatGPT as a feedback tool, similar to functionality or tool-evaluation studies.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics (e.g., pre/post writing scores, revisions quality, accuracy gains). Outcomes concern the adequacy and characteristics of feedback, not measured changes in learners\u2019 writing performance following an LLM-mediated intervention.""}}"
"Chatgpt, Plagiarism, and Multilingual Students' Learning to Write",2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions \u201cmultilingual students\u201d and \u201cwriting instructors,\u201d but does not specify that the learners are L2 English learners in ESL/EFL/ELL contexts or that the focus is specifically on English writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is central, the piece is described as a \u201cshort piece\u201d sharing \u201cexploratory interactions\u201d and discussing how instructors can use the tool. There is no indication of an experimental or quasi-experimental design or a structured pedagogical intervention being implemented and studied.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on plagiarism, academic integrity, and ethics in academic writing, not on developing writing competence or writing-related performance. The aim is to facilitate teaching and learning of ethics rather than to improve writing skills per se.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or assessment of writing performance. It appears to be conceptual/practical guidance rather than an empirical study with measurable writing outcomes.""}}"
Chatgpt in Language Writing Education: Reflections and a Research Agenda for a Chatgpt Feedback Engagement Framework,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers generally to 'ESL writing education' and 'student writers' but does not specify any actual participant group or empirical data collection. It appears to be a conceptual/personal reflection rather than a study with defined L2 English learner participants.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The paper is described as a 'personal reflection' that reviews ethical considerations and proposes a research agenda and framework for ChatGPT feedback engagement. There is no indication of an experimental or quasi-experimental intervention actually integrating ChatGPT into writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the context is ESL writing education and feedback, the article is conceptual/theoretical. It discusses models and ethical dimensions rather than implementing or empirically evaluating a writing-focused pedagogical intervention with ChatGPT.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or empirical assessment. It focuses on reflections, framework development, and a call for future research, without reporting intervention outcomes.""}}"
The Reliability of Using Chatgpt in Rating Efl Writings,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL writers whose compositions were drawn from the Written English Corpus of Chinese Learners, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses ChatGPT solely as an automated rater to evaluate existing EFL compositions and compare its scores with human raters. There is no experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction or writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on the reliability of ChatGPT as an essay scoring tool (intra- and inter-rater reliability), not on improving writing competence or implementing a pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No writing outcome measures are reported as a result of an LLM-mediated intervention. The only quantitative outcomes are reliability statistics comparing ChatGPT and human ratings, not changes in learners\u2019 writing performance.""}}"
"Comparing Peer, Chatgpt, and Teacher Corrective Feedback in Efl Writing: Students' Perceptions and Preferences",2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as EFL students in English as a Foreign Language classrooms, and the focus is on English writing skills.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention includes an AI tool (ChatGPT) providing written corrective feedback on students\u2019 writing, alongside peer and teacher feedback, which constitutes integration of an LLM into the writing process.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is written corrective feedback on an EFL writing task, with revisions after each feedback mode; the focus is clearly on writing competence and feedback practices.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is described as using a qualitative approach via survey analysis to explore students\u2019 perceptions and preferences. No quantitative writing outcome metrics (e.g., scores, error rates, measurable improvement) are reported; revisions are mentioned but not as measured outcomes.""}}"
Enhancing Usability and Learner Engagement: a Heuristic Evaluation of the Ai-enhanced Video Drama Maker App,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The app is designed for learners of English as a Foreign Language (EFL), clearly indicating an L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the app includes GPT-generated sentences, the study itself is a heuristic evaluation of usability with UI/UX experts, not an experimental or quasi-experimental pedagogical intervention with learners integrating LLMs into writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on usability and user experience (heuristic evaluation based on Nielsen\u2019s principles) rather than on writing competence or writing-related learning outcomes. Writing is mentioned as an intended skill area, but not as the central evaluative focus.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported. The quantitative data concern usability (e.g., Cronbach\u2019s alpha, descriptive statistics on heuristic evaluation), not measures of learners\u2019 writing performance or development.""}}"
Developing a Thai Grammatical Error Correction Tool for Deaf Students,2024,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are deaf students writing in Thai; the focus is on Thai grammatical error correction, not on L2 English learners in ESL/EFL/ELL contexts or English-language data.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract describes a Thai grammatical error correction system and mentions comparing different detection and correction models, but does not specify that these are large language models (e.g., transformer-based generative LLMs like GPT). It may be traditional GEC models.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The study focuses on developing and evaluating an automated Thai GEC tool and corpus, not on a pedagogical writing intervention or instructional context aimed at improving learners\u2019 writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are model performance metrics (off-the-shelf vs corpus-trained models) rather than quantifiable writing outcomes for learners following an LLM-mediated writing intervention.""}}"
Deep Learning Approaches to Predict Student Success in English Language Learning,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to 'English language learning' and 'student-written texts' but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts. They could be L1 or mixed populations; the learner profile is not clearly defined.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""GPT-3 is used to predict student success and assess texts, functioning as an analytic/predictive model. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating GPT-3 into writing instruction or writing processes; it is primarily a prediction/assessment tool.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on predicting student achievement and improving accuracy of success predictions, not on developing writing competence. While GPT-3 analyzes writing and generates feedback, the study centers on prediction performance rather than a structured writing intervention or instructional context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported concern prediction accuracy of student success and the actionability of feedback, not quantifiable changes in learners\u2019 writing performance following an LLM-mediated intervention. No pre/post or comparative writing outcome measures are described.""}}"
Xducation of Things (xot): Harnessing Ai and Edge Computing to Educate All Things,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as 26 EFL learners, divided into experimental and control groups. The context is English as a foreign language, and the outcome mentioned is learners\u2019 writing skills, implying English writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is the smartXoT environment with a Smart Question Answer Forwarding Mechanism (SQA-Forwarding) built on edge computing and AI-Agents/smart things. The abstract does not indicate that this system is based on large language models (e.g., ChatGPT, GPT-4, transformer-based generative models). It appears to be an AI/edge-computing knowledge-base system rather than an LLM-mediated writing tool.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study explicitly reports that interaction with smartthings with SQA-Forwarding significantly improved learners\u2019 writing skills and that revisions enhanced writing quality. Thus, the primary measured educational focus includes writing competence.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""A quasi-experimental design with experimental and control groups is used to examine differences in learning achievement and writing skills. The abstract reports significant improvement in learners\u2019 writing skills, implying quantifiable outcome measures of writing quality.""}}"
Automated English Language Learning Using Bert-lstm Model,2024,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers broadly to \u201cautomatic English learning\u201d and \u201cstudents,\u201d but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor does it clearly describe any learner population or study sample.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is an automated BERT-LSTM model for English learning. While BERT is transformer-based, this is not an LLM-based pedagogical tool like ChatGPT/GPT-4; it is a feature-extraction/classification model. The study focuses on model design and performance, not on integrating an LLM into writing instruction in an experimental or quasi-experimental educational design.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions grammar correction, comprehension, and written responses, but the primary focus appears to be general \u2018automatic English learning\u2019 and linguistic feature handling, not a clearly defined writing-instruction context or writing competence intervention.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""It notes that \u201cexperimental findings affirm the usefulness\u201d of the model, but does not specify quantifiable writing outcome metrics (e.g., writing scores, complexity, accuracy, fluency) for learners. The nature of the reported outcomes (system performance vs. learner writing gains) is not clear.""}}"
"The Effects of a Quillbot-based Intervention on English Language Majors' Efl Writing Performance, Apprehension, and Self-efficacy",2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 18 fourth-year English Language majors in an EFL context at Matrouh University. The study explicitly concerns EFL writing performance, indicating L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is based on QuillBot, described as an AI-powered writing assistant. QuillBot is not specified as an LLM-based tool (e.g., ChatGPT, GPT-4, Gemini) in the abstract, and in the review\u2019s criteria, tools like QuillBot that are not clearly transformer-based generative LLMs are to be excluded.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on EFL writing performance and related affective variables (writing apprehension and self-efficacy). The intervention involves drafting, receiving AI-generated feedback, revising, and producing final drafts, clearly centering on writing competence.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses a pre/post test to measure writing performance and two scales to measure apprehension and self-efficacy, reporting significant positive effects. These are quantifiable outcome metrics of the writing intervention.""}}"
Revolutionizing Efl Learning through Chatgpt: a Qualitative Study,2024,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL students at the University of Hail in Saudi Arabia, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used, the study is exploratory and qualitative, based on interviews about general use of ChatGPT in learning English. There is no indication of an experimental or quasi-experimental design or a structured pedagogical intervention being tested.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""Writing is mentioned among several skills (reading, writing, grammar, spelling), but the focus is broad on overall English learning and experiences with ChatGPT, not specifically on writing competence or writing-related variables as the primary focus.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is explicitly described as qualitative, using interviews. It reports perceived enhancements and challenges but does not mention any quantifiable writing outcome metrics or experimental measures of writing performance.""}}"
