No.,Title,Year,Decision,Notes
1,Same Assignment-two Different Feedback Contexts: Lower Secondary Students' Experiences with Feedback during a Three Draft Writing Process,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as lower secondary students in English as a foreign language (EFL) classes, which suggests they are L2 English learners. However, the abstract does not explicitly state their L1 or confirm that English is a second/foreign language for all participants, though this is strongly implied by the EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study contrasts AI-generated feedback with peer feedback, but the abstract does not specify what AI system is used, nor whether it is a large language model (e.g., ChatGPT, GPT-4). It could be a non-LLM feedback tool. Without explicit mention of an LLM or transformer-based generative model, it is unclear whether it meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is a three-draft writing process in EFL classes, with feedback (AI-generated vs. peer) integrated into the drafting process. The focus is on writing processes and feedback literacy in writing, which aligns with writing-related variables in an instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates students’ conceptions, experiences, and engagement with feedback through observations and interviews, analyzed thematically. The abstract does not report any quantitative or experimental writing outcome measures (e.g., changes in writing quality, scores, accuracy). Outcomes are qualitative (experiences, feedback literacy), so it does not meet the requirement for quantifiable writing outcome metrics.""
    }
}"
2,Efl Learners' Perceptual Perezhivaniya and Actual Writing Revision Behaviors Mediated by Genai: a Sociocultural Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are nineteen EFL learners at a university in Southern China, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that learners revised L2 continuation writing tasks \""using GenAI\"" but does not specify that the GenAI tool is an LLM (e.g., ChatGPT, GPT-4) or provide details about the underlying technology. It could be any generative AI system, not necessarily an LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on the revision stage of L2 writing processes, development of an L2 writing revision taxonomy, and analysis of revision behaviors, which are core writing-related variables rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses interviews, Q-methodology, and Translog screen recordings to explore revision processes and the alignment between perceived experiences and actual revision behaviors. The abstract does not report any quantifiable writing outcome metrics (e.g., writing quality scores, accuracy gains) assessing the effectiveness of GenAI-mediated intervention; it focuses on process and perceptions rather than outcome measures.""
    }
}"
3,Students' Perceptions of Generative Artificial Intelligence (genai) Use in Academic Writing in English as a Foreign Language,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 56 undergraduate university students in Ecuador studying English as a foreign language (EFL), clearly an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a perception survey about GenAI/ChatGPT use and academic integrity. There is no indication of an experimental or quasi-experimental design integrating LLMs into writing instruction or writing processes as an intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is academic writing in EFL, the primary focus is on perceptions of academic integrity, cheating, and AI-giarism, not on improving writing competence or implementing a pedagogical writing intervention using LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports students’ perceptions and worries, but does not mention any quantifiable writing outcome metrics or measured changes in writing performance resulting from an LLM-mediated intervention.""
    }
}"
4,Chatbots or Cheatbots? University Students' Uses of Ai Literacy Tools across Four Nations,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are undergraduate and graduate students in English-medium programs across India, Indonesia, Morocco, and the US. Their L1s are not specified, and the focus is on general use of LLMs in English-medium instruction, not explicitly on L2 English learners in ESL/EFL/ELL contexts or on data specifically framed as L2 English learning.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a cross-case analysis of first-person accounts of how students use LLMs. There is no experimental or quasi-experimental design, nor a structured pedagogical intervention integrating LLMs into instruction; it is descriptive/qualitative.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""While writing is mentioned (brainstorming, sentence complexity, revising prompts), the primary focus is on general AI literacy and uses of LLMs for reading, writing, and learning, not on a defined writing instruction intervention or systematic development of writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative accounts of opportunities and challenges and discusses implications. It does not mention any quantitative or experimental writing outcome measures assessing the effectiveness of LLM-mediated writing interventions.""
    }
}"
5,"A Comparative Study of the Human, Automated Scoring Model, and Gpt-4 Ratings of Young Efl Students' Writing",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'young English as a foreign language learners,' clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""GPT-4 is used as an automated writing evaluation (AWE) scoring model, not as part of an instructional or intervention design to support learners’ writing processes or instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on comparing GPT-4, an operational AWE model, and human ratings for scoring TOEFL Junior Writing responses. This is an assessment/measurement study, not a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports psychometric performance of scoring models (e.g., agreement with human ratings), not quantifiable changes in learners’ writing outcomes resulting from an LLM-mediated instructional intervention.""
    }
}"
6,Efl Learners' Motivation and Acceptance of Using Large Language Models in English Academic Writing: an Extension of the Utaut Model,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as EFL learners engaged in learning English academic writing, which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study involves LLMs (e.g., ChatGPT) and mentions that participants completed a semester of training in using LLMs for English academic writing, the research focus is not on experimentally evaluating an LLM-based writing intervention. Instead, it examines motivation and technology acceptance (UTAUT) via survey data, without an experimental or quasi-experimental instructional design centered on LLM integration.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on learners’ motivation, behavioral intention, and acceptance of LLMs, modeled through L2 Motivational Self System and UTAUT constructs. Writing competence or writing-related performance variables are not the central outcome; the context is technology adoption rather than pedagogical writing intervention outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports structural relationships among motivational and acceptance variables (e.g., performance expectancy, social influence, behavioral intention, use behavior) using PLS-SEM. It does not report quantifiable writing outcome metrics (e.g., writing quality scores, accuracy, complexity) to assess the effectiveness of LLM-mediated writing interventions.""
    }
}"
7,Edcew-llm: Error Detection and Correction in English Writing: a Large Language Model-based Approach,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “error profiles of English language learners across CEFR proficiency levels (A, B, and C)” but does not specify that these are actual study participants in an instructional context; they may simply be learner corpora used for benchmarking. No ESL/EFL/ELL classroom or learner-participant sample is clearly described.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study develops and benchmarks an LLM-based error detection and correction pipeline and uses GPT‑3.5 to generate explanations. It is framed as a WEDC system evaluation, not as an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction with learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on model performance for error detection/correction and explanation generation, with benchmarks on BEA-2019 and JFLEG. There is no description of a teaching/learning context, instructional design, or writing instruction intervention; it is essentially an NLP system study, not a writing pedagogy study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are F1 scores and benchmark performance on WEDC datasets, plus human evaluations of correction and explanation quality. There are no quantifiable learner writing outcomes (e.g., pre/post writing scores, improvement measures) from an LLM-mediated writing intervention.""
    }
}"
8,Investigating Efl Students' Perceptions of Feedback: a Comparative Study of Instructor and Chatgpt-generated Responses in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Saudi English as a Foreign Language (EFL) learners in an advanced writing course, clearly fitting an L2 English EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used to generate feedback on writing, but the study focuses on comparing perceptions of instructor vs. ChatGPT feedback. There is no indication of an experimental or quasi-experimental instructional intervention using LLMs to teach or support writing beyond feedback provision for perception comparison.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on students’ perceptions of feedback sources (instructor vs. ChatGPT), not on writing competence or writing-related performance variables as outcomes of a pedagogical intervention. Writing is the context, but the study is perception-focused rather than intervention-focused.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports only survey-based perceptions and preferences. It does not report quantifiable writing outcome metrics (e.g., changes in writing scores, accuracy, complexity) attributable to ChatGPT-mediated intervention.""
    }
}"
9,Large Language Models Fall Short in Classifying Learners' Open-ended Responses,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 143 Japanese university students studying English as a foreign language (EFL), which fits the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""LLMs are used to classify learners’ open-ended responses about their essay-writing process, not as part of an instructional or quasi-experimental writing intervention. The focus is on methodological evaluation of LLM-based classification, not on integrating LLMs into writing instruction or processes for learning outcomes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on LLM performance in qualitative data analysis (classification of responses) and methodological implications, not on improving writing competence or writing-related pedagogical variables. There is no described instructional context targeting writing development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports Cohen’s kappa for agreement between LLMs and human coders, not quantifiable writing outcome metrics. It does not assess changes in learners’ writing performance or related measurable outcomes from an LLM-mediated intervention.""
    }
}"
10,A Linguistic Comparison between Chatgpt-generated and Nonnative Student-generated Short Story Adaptations: a Stylometric Approach,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are nonnative ESL students at an Egyptian university, and the texts analyzed are in English, fitting the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used only to generate comparison texts; there is no experimental or quasi-experimental instructional intervention integrating the LLM into writing instruction or students’ writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on stylometric comparison and authorship attribution (distinguishing AI vs. human text), not on improving writing competence through a pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No writing outcome measures assessing the effectiveness of an LLM-mediated writing intervention are reported; the study analyzes linguistic features but does not evaluate changes in learners’ writing performance after an intervention.""
    }
}"
11,Artificial Intelligence Vs. Instructor Supported Ai: Teaching Second Language Writing Via Write&improve,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on second language writing and English writing success/self-efficacy, implying participants are L2 English learners in an ESL/EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses the Write&Improve system. While it is an AI-based feedback tool, the abstract does not indicate that it is based on large language models or transformer-based generative models (e.g., ChatGPT, GPT-4). Under the review’s criteria, tools like Write&Improve that are not clearly LLM-based should be excluded.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on second language writing success and related variables (self-efficacy, emotions, responsibilities, teacher-student interaction) within a writing instruction context, not on automated scoring per se.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative pretest-posttest outcomes, including statistically significant increases in English writing success and other measurable constructs, satisfying the requirement for quantifiable writing outcome metrics.""
    }
}"
12,Developing L2 Postgraduate Students' Strategic and Responsible Use of Genai through a Purposefully Designed Workshop in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as L2 postgraduate students facing challenges in academic writing, indicating second language English learners in an academic writing context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The workshop uses “diverse GenAI tools” and focuses on “strategic and responsible GenAI use,” but the abstract does not specify whether these are large language models (e.g., ChatGPT, GPT-4) or other types of generative AI. However, even if LLMs are involved, the design is primarily a pedagogical workshop with pre/post questionnaires, not clearly an experimental or quasi-experimental comparison of LLM-integrated writing instruction versus control conditions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is academic writing: the workshop targets stages of the writing process (brainstorming, literature searching, revising, ethical considerations) and is clearly centered on writing competence and writing-related processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are changes in “technology proficiency, critical evaluation skills, ethical competence, and AI agency” based on pre- and post-workshop questionnaires. There is no mention of quantifiable writing performance metrics (e.g., writing quality scores, complexity, accuracy, fluency). Thus, no direct writing outcome measures are reported.""
    }
}"
13,Linguistic Analyses of Written Corrective Feedback for Chinese as a Second Language: Chatgpt Versus Human Teachers,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are learners of Chinese as a second language (CSL), specifically a Vietnamese CSL writing sample corpus. The focus is not on L2 English learners in ESL/EFL/ELL contexts, and the target language is Chinese, not English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is involved, the study compares written corrective feedback produced by ChatGPT and human teachers. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction; it is an analysis of feedback characteristics.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on linguistic analysis of written corrective feedback quality (language accuracy and content expressivity), not on writing competence development or a structured writing intervention. It is essentially a functionality/quality comparison of feedback providers.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports linguistic parameters of feedback (e.g., word order changes, vocabulary difficulty) but does not report quantifiable writing outcome metrics for learners (e.g., changes in writing scores or proficiency after intervention). No experimental learning outcomes are described.""
    }
}"
14,A Translanguaging Perspective on Students' Use of Generative Artificial Intelligence in L2 Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'Chinese multilingual undergraduates' engaged in 'L2 writing', which in this context strongly implies English as the target language in an EFL/ESL-type setting.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study focuses on 'Generative artificial intelligence (GAI)' and students' use of it in L2 writing. While this likely includes LLM-based tools (e.g., ChatGPT), the abstract does not explicitly specify that the tools are large language models or name any LLM platform. It also does not describe a structured instructional intervention; rather, it examines naturalistic use.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on how students use GAI in naturalistic L2 writing contexts from a translanguaging perspective, exploring usage patterns and underlying reasons. It is not an instructional or pedagogical intervention study aimed at improving writing competence, but a descriptive/qualitative exploration of practices and stances.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses screen recordings, reflective journals, and interviews, analyzed thematically. No mention is made of quantitative or experimental writing outcome measures; findings are qualitative (patterns of use, stances, and theorization of GAI-assisted writing). Thus, it does not report quantifiable writing outcome metrics.""
    }
}"
15,Saudi Efl Learners' Perceptions of Using Artificial Intelligence and Its Impact on Their Writing Skills,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are female Saudi learners of English as a Foreign Language at the University of Jeddah, clearly an EFL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “Artificial Intelligence tools” and explicitly mentions ChatGPT, which is an LLM. However, it does not clearly describe an experimental or quasi-experimental instructional intervention; it focuses on perceptions and experiences rather than a structured LLM-mediated teaching design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on the impact of AI tools on students’ English writing skills and writing competency, i.e., writing-related variables in an EFL context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses questionnaires and semi-structured interviews to explore perceptions, attitudes, and perceived impact. There is no indication of quantifiable writing outcome measures (e.g., pre/post writing scores, rubric-based performance) assessing effectiveness of an LLM-mediated intervention.""
    }
}"
16,Enhancing Efl Writing through Ai-driven Video-to-text Recognition in Authentic Learning Contexts,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a Foreign Language (EFL) learners: 22 first-year university students in an EFL context, with focus on English writing skills.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is an AI-driven video-to-text recognition (VTR) system that combines AI and cloud-based technologies. There is no indication that it is based on a large language model (e.g., ChatGPT/GPT-style generative transformer). It appears to be a recognition/transcription tool rather than an LLM-based generative writing assistant.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on enhancing EFL writing skills and supporting structured writing tasks in authentic learning environments, clearly centering on writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is a two-week experimental study evaluating the impact of the VTR system on writing proficiency, reporting improvement in writing skills, which implies quantifiable writing outcome metrics.""
    }
}"
17,Harnessing Generative Ai for English Curriculum Innovation in Higher Education: a Case Study at Al-zaytoonah University of Jordan,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract specifies that the context is English as a Foreign Language (EFL) instruction at Al-Zaytoonah University of Jordan, indicating L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study integrates Generative AI, particularly LLMs (ChatGPT), into English language curriculum design and introduces ChatGPT as a supplementary tool in classrooms. However, the abstract does not clearly state that there is an experimental or quasi-experimental design (e.g., control vs. treatment, pre/post intervention) focused specifically on writing instruction or processes; it may be broader curriculum innovation.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing fluency is mentioned as one of several outcomes (along with linguistic autonomy and critical thinking), but the primary focus appears to be overall curriculum innovation and EFL instruction, not explicitly a writing-focused intervention. It is unclear whether writing competence is the central focus or just one of multiple skills examined.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract notes that a mixed-method approach with qualitative and quantitative data was used and that GenAI tools improved writing fluency, but it does not specify what quantifiable writing outcome metrics were used (e.g., scores, rubric-based assessments, pre/post writing tests). Without explicit mention of measured writing outcomes, it is unclear if this criterion is met.""
    }
}"
18,Exploring the Use of Generative Ai on Students’ Academic Writing: an Exploratory Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) learners, and the context is academic writing in English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to ‘generative AI (GenAI)’ but does not specify whether it is an LLM-based tool (e.g., ChatGPT/GPT-4) or another type of generative system. However, even if it were an LLM, the study is exploratory and focuses on question categories and adoption patterns rather than a structured instructional intervention with experimental or quasi-experimental design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly academic writing, examining how EFL students use GenAI during a designed writing task. The primary focus is on writing-related behavior and perceptions.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates questioning behaviors, adoption of GenAI responses, and perceptions of usefulness and ease of use. There is no mention of quantifiable writing outcome measures (e.g., writing scores, quality ratings, accuracy) to assess effectiveness of the GenAI-mediated writing process.""
    }
}"
19,Understanding How Ai Chatbots Influence Efl Learners’ Oral English Learning Motivation and Outcomes: Evidence from Chinese Learners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 351 EFL students in China learning spoken English with an AI chatbot, clearly fitting an EFL/ESL/ELL English-learning context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study involves AI chatbots, the abstract does not specify that they are large language model–based tools (e.g., ChatGPT, GPT-4). It generically refers to ‘AI chatbots’ and focuses on their ‘human likeness’ and social presence, without indicating transformer-based generative LLMs or a specific LLM platform.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on spoken/oral English learning, motivation, self-efficacy, and social presence. There is no indication that writing competence or writing-related variables are targeted; the context is oral English practice, not writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes concern learning motivation and spoken learning outcomes measured via questionnaire and SEM. No quantifiable writing outcomes or writing performance measures are reported.""
    }
}"
20,Unveiling the Writing Self-efficacy and Its Relationship with Writing Engagement Based on Generative Ai Feedback,2025,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract does not specify the language background of the participants or whether they are L2 English learners in ESL/EFL/ELL contexts. It only refers to “students,” so their L1/L2 status and target language are unknown.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses “generative AI feedback,” which could involve LLMs, but no specific tools (e.g., ChatGPT, GPT-4) or model types are named. It is unclear whether the generative AI is an LLM-based system or another form of AI feedback.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on writing self-efficacy and writing engagement “based on generative AI feedback,” indicating a writing-related intervention context rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported concern writing self-efficacy (ideation, construction, self-regulation) and writing engagement. There is no indication of quantifiable writing performance or competence measures (e.g., text quality, accuracy, complexity), only affective/psychological variables.""
    }
}"
21,Investigating Efl Students' Attitudes towards Ai-powered Tools in English Language Learning,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 479 Vietnamese university students learning English as a Foreign Language (EFL), clearly an L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates attitudes toward various AI-powered tools (e.g., ChatGPT, Grammarly, Duolingo Max, Gemini) but does not describe an experimental or quasi-experimental intervention integrating LLMs into writing instruction or processes. It is an attitudinal/perception study, not a structured LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing skills are mentioned among several skills (grammar, vocabulary, pronunciation, motivation, autonomy), the primary focus is general English language learning and attitudes toward AI tools, not a targeted writing competence intervention or writing-focused context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports perceived improvements and attitudes but does not indicate any quantifiable writing outcome measures or experimental comparison. Data are surveys and interviews about perceptions, without measured writing performance outcomes.""
    }
}"
22,Developing an Ai-driven Contextualized Short Video Learning System for Efl Speaking and Writing,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as EFL learners (45 seventh graders), indicating second language English learners in an EFL context. The focus is on English speaking and writing proficiency.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is ClipTalk, an AI-driven system using GPT-enabled chatbots and intelligent contextual chatbots to provide feedback. The study is an eight-week experimental study integrating LLM-based tools into language learning tasks.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The system is explicitly designed to enhance EFL learners' speaking and writing proficiency, with real-world video production tasks and AI-driven feedback. Writing competence is a primary outcome, not just system evaluation or scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that the experimental study assessed the system's impact on writing and speaking proficiency and found significant improvements in EFL writing and speaking skills, indicating quantifiable outcome measures of writing performance.""
    }
}"
23,What Motivates Second Language Majors to Use Generative Ai for Informal Learning? Insights from the Theory of Planned Behavior,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described only as 'L2 majors at various Chinese universities.' The target L2 is not specified, and it is not clear that they are English L2 learners or that the focus is on English rather than other languages.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates factors influencing intention to use generative AI via a questionnaire and structural equation modeling. There is no experimental or quasi-experimental design integrating a specific LLM into instruction or writing processes; it is a correlational study of behavioral intention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on informal L2 learning intentions and psychological constructs (attitude, subjective norm, perceived behavioral control, GenAI literacy), not specifically on writing competence or writing-related variables. Writing is not mentioned in the abstract.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No writing outcome measures are reported. The outcomes are behavioral intention and related TPB constructs, not quantifiable writing performance or writing-related metrics following an LLM-mediated intervention.""
    }
}"
24,Enhancing Chinese Character Writing Learning: the Role of Mllm-based Intelligent Tutoring Systems,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are learners of Chinese as a foreign language, focusing on Chinese character learning. The target language is Chinese, not English, so the population does not match the review’s focus on L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an Intelligent Tutoring System grounded in a Multimodal Large Language Model with a feedback mechanism, and conducts a teaching experiment to validate its effectiveness, which fits an LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing Chinese characters and the impact of corrective feedback on character writing performance, which is a writing-related competence in the target language.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that students using the ITS 'perform better in writing Chinese characters than in the traditional teaching method,' indicating quantifiable writing outcome metrics comparing groups.""
    }
}"
25,Future Changes in Teachers' Professional Roles under the Impact of Artificial Intelligence: a Study in English as a Foreign Language Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states that the context is students learning English as a foreign language (EFL), which fits the target population of L2 English learners in EFL contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study involves GenAI (generative artificial intelligence) in an AIED system and compares human-centered teacher-student-GenAI collaboration with student-GenAI interactions, indicating an intervention using GenAI, which is likely LLM-based.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on affective and communicative variables—intrinsic motivation, classroom anxiety, and willingness to communicate in EFL classes—and on teachers’ changing roles under AIED. Writing competence or writing-related variables are not mentioned as a focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The measured outcomes are intrinsic motivation, classroom anxiety, and willingness to communicate. No quantifiable writing outcome metrics or writing performance measures are reported in the abstract.""
    }
}"
26,Optimizing English Learning with Ai: Machine Learning Techniques and Tools,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions the ELLIPSE corpus of essays by grade 8–12 learners, but does not clearly state that these are L2 English learners in ESL/EFL/ELL contexts. They could be native or mixed-proficiency learners; the L2 status is not explicit.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a TF-IDF-based Gated Recurrent Unit (GRU) model for text classification. This is a recurrent neural network, not a transformer-based large language model (e.g., ChatGPT, GPT-4). There is no indication of integrating an LLM into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on developing and evaluating an automated text classification framework to assess writing (coherence, syntax, vocabulary, etc.) using the ELLIPSE corpus. It is essentially an automated scoring/assessment tool, not a pedagogical writing intervention or instructional use of AI in learners’ writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are model performance metrics (accuracy, precision, recall, F1-score) for text classification. There is no experimental or quasi-experimental intervention with learners, nor quantifiable pre/post or comparative writing outcomes for students’ development.""
    }
}"
27,Enhancing Spelling Proficiency in Higher Education: Leveraging Ai for Improved Learning Outcomes,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 50 English department students at a Moroccan university. While not explicitly labeled as EFL/ESL, this context strongly implies L2 English learners in an EFL higher-education setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study ‘explores the opportunities and the challenges associated with AI-powered learning tools and examines students' attitudes.’ There is no indication of an experimental or quasi-experimental design integrating LLMs into instruction; it appears attitudinal/observational rather than an intervention study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on spelling proficiency and students’ attitudes toward AI tools versus traditional approaches, not on a structured writing instruction or writing process intervention. Writing competence as such is not the primary pedagogical focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantifiable outcome measures of writing or spelling performance resulting from an LLM-mediated intervention. It reports ‘insights’ into implications and attitudes, suggesting a primarily qualitative or descriptive study without measured intervention effects.""
    }
}"
28,Design and Evaluation of a Gamified Chat Generative Pre-trained Transformer-assisted English Course Learning System with Selfregulation Support,2025,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to \""English language learners\"" but does not specify whether they are L2 English learners in ESL/EFL/ELL contexts (e.g., country, educational setting, or whether English is a foreign/second language). Thus, it is unclear if the population matches the review’s target group.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly uses ChatGPT (a large language model) as the core of the learning system. It employs an experimental design with stratified random assignment to a control group (ChatGPT-assisted learning only) and an experimental group (ChatGPT plus gamification and self-regulation nudges), satisfying the requirement for an LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention covers weekly modules including reading, writing, speaking, and listening. The abstract does not indicate that writing competence or writing-related variables are the primary focus; writing appears as one of several skills. It is unclear whether the main outcome measures are specifically writing-related or more general language proficiency and motivation.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses pre- and post-tests and statistical analyses (independent-sample t-tests, effect sizes) to compare group performance, indicating quantitative outcomes. However, the abstract does not specify whether any of these outcome metrics are explicitly writing-related (e.g., writing scores, writing quality measures) as opposed to overall language proficiency or motivation. Thus, it is unclear if quantifiable writing outcomes are reported.""
    }
}"
29,Analysis of Personalized English Teaching Path Planning and Strategies under the Integration of Big Data and Artificial Intelligence,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to 200 students in an English teaching context but does not specify whether they are L2 English learners in ESL/EFL/ELL settings or native speakers. The learner population and context (e.g., EFL in a specific country) are not clearly identified.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is described broadly as an AI-supported, big-data-driven personalized learning model and ‘AI platforms’. There is no indication that the AI tools are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems, nor that they are used specifically for writing instruction. Thus it does not clearly meet the LLM-based intervention requirement.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The study targets overall English learning outcomes across the four skills (listening, speaking, reading, writing). Writing is only one of several skills and is not the primary or explicit focus of the intervention design; the emphasis is on general personalized English teaching path planning rather than writing competence or writing-related variables specifically.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports quantifiable post-test outcomes, including a mean improvement of 22% in writing and speaking skills and an 8-point increase in post-test scores, analyzed via t-tests and regression. Thus, measurable writing-related outcomes are present, even though they are combined with other skills.""
    }
}"
30,Balancing Technology with Pedagogy in Smart Classrooms for English Language,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are 200 secondary school students in English language instruction, but it is not specified whether they are L2 English learners in ESL/EFL/ELL contexts or native speakers. The abstract only mentions “English language acquisition” without clarifying L1/L2 status.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention involves “smart classroom technologies—such as interactive whiteboards, augmented reality (AR), and adaptive learning platforms.” There is no mention of large language models (e.g., ChatGPT, GPT-4) or transformer-based generative AI. Thus, it does not meet the LLM-based intervention requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing is one of the targeted skills: the study reports gains in “reading comprehension, writing skills, listening skills, and speaking abilities.” The context includes writing competence as a primary outcome among other language skills.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental design with pre- and post-tests and reports quantitative gains, including a 15% increase in writing skills. These are quantifiable writing outcome metrics aligned with the requirement for measurable intervention effects.""
    }
}"
31,Understanding Efl Student Writers' Metacognitive Awareness in Utilizing Chatgpt,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 452 EFL undergraduate students in a semester-long writing course, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used by students for academic writing feedback, the study is framed as an investigation of metacognitive awareness, not as an experimental or quasi-experimental intervention evaluating an LLM-based instructional treatment. There is no indication of controlled instructional conditions or treatment vs. comparison groups.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context is EFL academic writing and use of ChatGPT for writing feedback, which is writing-related. However, the primary focus is on metacognitive awareness and practices rather than on systematically improving writing competence through a pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports validation of a metacognitive awareness scale and qualitative insights into metacognitive practices. It does not mention any quantifiable writing outcome metrics (e.g., writing scores, text quality measures) to assess the effectiveness of ChatGPT-mediated writing intervention.""
    }
}"
32,Unlocking Efl Learners' Insights into Chatgpt Use for L2 Writing: the Impacts of Usage Frequency and Gender Variations,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 874 Turkish undergraduate English majors at a state university in Türkiye, clearly EFL/L2 English learners. The focus is on their use of ChatGPT for L2 (English) writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates learners’ perceptions of ChatGPT use and how gender and usage frequency affect these perceptions. There is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction; rather, it is an observational, perception-based study using a perception scale and interviews.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is L2 writing, the primary focus is on perceptions of ChatGPT use (Technology Acceptance Model) and usage patterns beyond the classroom, not on writing competence or writing-related performance variables within a pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports no quantifiable writing outcome metrics (e.g., writing scores, text quality measures). Outcomes are perceptions, gender differences, and correlations between usage frequency and perceptions, without measured changes in writing performance.""
    }
}"
33,A Comparative Study of the Efficacy of Llms in Generating Learning Resources for Non-english Major Postgraduates,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as “non-English major postgraduate students at a university,” but it is not specified whether they are L2 English learners (ESL/EFL/ELL) or native speakers using English-medium instruction. The language focus appears to be English, but learner status as L2 is not explicit.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares ERNIE Bot and ChatGPT in “producing pertinent language learning materials” and “supplementary learning resources.” There is no indication of an experimental or quasi-experimental pedagogical intervention where learners use LLMs within their writing process or instruction; instead, the focus is on evaluating LLM-generated materials.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Writing is only one of four dimensions (vocabulary, translation, reading, writing) used to assess generated materials. The primary focus is on the efficacy of LLMs in generating general language learning resources, not on writing competence or writing-related instructional interventions.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions evaluations from students and educators of LLM-generated materials but does not report any quantifiable writing outcome metrics for learners (e.g., changes in writing performance after an intervention). Outcomes relate to the quality of generated resources, not to learners’ writing development.""
    }
}"
34,Teaching Is Basically Feeling: Unpacking Efl Teachers' Perceived Emotions and Regulatory Strategies in Ai-powered L2 Speaking and Writing Skills Instruction,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 21 Iranian EFL teachers working in L2 speaking and writing instruction, clearly within an EFL/ESL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although AI tools are mentioned, the study is a qualitative exploration of teachers’ emotions and regulatory strategies. There is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) as a pedagogical intervention; the type of AI is unspecified and could include non-LLM tools.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on teacher emotionality and emotion regulation in AI-powered L2 speaking and writing instruction, not on learners’ writing competence or writing-related performance variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly qualitative, using semi-structured interviews and narrative frames, and reports thematic findings about emotions and strategies. It does not report quantifiable writing outcome metrics or measure the effectiveness of an LLM-mediated writing intervention.""
    }
}"
35,The Impact of Integrating Chatgpt with Teachers' Feedback on Efl Writing Skills,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 68 intermediate Iranian EFL learners working on IELTS Task 2 argumentative essays. This clearly indicates L2 English learners in an EFL context, with English as the target language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention explicitly integrates ChatGPT, described as a state-of-the-art AI chatbot, with teacher feedback to provide individualized writing feedback. Learners were randomly assigned to ChatGPT+teacher feedback vs teacher-only feedback, indicating an experimental design using an LLM in writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL essay writing (IELTS Task 2) and writing proficiency. ChatGPT is used to provide feedback on writing, and outcomes are reported for writing-related criteria (task achievement, coherence, cohesion, vocabulary, grammar range and accuracy). This is a pedagogical writing intervention, not an automated scoring study.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative writing outcome measures: improvement in IELTS Task 2 argumentative essays across specific scoring criteria (task achievement, coherence, cohesion, vocabulary, grammar range and accuracy), with statistical analysis via Paired Samples t-Test comparing groups.""
    }
}"
36,"Chinese College Students' Usage, Evaluation, Perception and Attitude Toward Generative Ai in English as a Foreign Language Writing",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese college students using generative AI tools in EFL (English as a Foreign Language) writing, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a two-stage survey (interviews and questionnaire) about students' usage, perceptions, and attitudes toward generative AI tools. There is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) as a structured writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is EFL writing, the focus is on usage patterns, benefits, concerns, and attitudes toward AI tools, not on a pedagogical intervention aimed at improving writing competence through LLM integration.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports survey-based perceptions and attitudes but does not mention any quantifiable writing outcome metrics (e.g., writing scores, text quality measures) resulting from an LLM-mediated intervention.""
    }
}"
37,Exploring Efl Students' Prompt Engineering in Human-ai Story Writing: an Activity Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) students: “Sixty-seven Hong Kong secondary school students… during short story writing” in an EFL context, with English as the target language.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""Students “created their own generative-AI tools using open-source language models and wrote short stories with them.” While this implies LLM-based tools, the abstract does not specify that these are transformer-based large language models (e.g., GPT-like) versus other generative architectures. However, they are generative AI tools integrated into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly writing-focused: students use generative AI tools “during short story writing” and the study examines prompting “for the three purposes during short story writing.” The primary focus is on writing processes and story development, not on automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is qualitative and exploratory, identifying themes about purposes for prompting and characteristics of activity systems. There is no mention of experimental or quasi-experimental design, control/comparison conditions, or quantifiable writing outcome metrics assessing effectiveness of the AI-mediated intervention. Outcomes are thematic (e.g., lack of awareness, overcoming writer’s block) rather than measured writing performance.""
    }
}"
38,Artificial Intelligence as an Equaliser: How Chatgpt Empowers Academics in the Global South,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract refers broadly to 'early-career scholars, non-native English speakers, and unaffiliated researchers' in the Global South, not specifically to L2 English learners in ESL/EFL/ELL instructional contexts. The focus is on academic researchers, not language learners in a pedagogical setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT is mentioned, the article is conceptual/argumentative, discussing how AI can empower academics. There is no indication of an experimental or quasi-experimental design, nor a structured instructional intervention integrating LLMs into writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on academic publishing, equity, and policy debates around AI-assisted writing, not on a pedagogical context targeting writing competence development. It does not describe a teaching/learning intervention in writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantitative writing outcome measures or empirical assessment of writing improvement. It is a discursive piece advocating for ethical AI use rather than an outcome-based study.""
    }
}"
39,"Negotiating Understanding, Control, and Authorship: L2 Learners' Experiences with Ai-assisted Paraphrasing in Academic Writing",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are twelve English-as-a-foreign-language (EFL) students at a university, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to unspecified 'AI tools' used for paraphrasing, translation, and synonym substitution. It does not identify them as large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems; they could be conventional paraphrasers or translators. No explicit LLM integration is described.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on learners’ experiences and interactions with AI-assisted paraphrasing in academic writing, explored through qualitative interviews. There is no structured pedagogical writing intervention or instructional design being experimentally tested; rather, it is an exploratory study of usage and perceptions.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is purely qualitative, based on interviews and thematic analysis. It does not report quantifiable writing outcome metrics or experimental measures of writing performance or paraphrasing quality.""
    }
}"
40,"Integrating Ai in Pakistani Esl Classrooms: Teachers' Practices, Perspectives, and Impact on Student Performance",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 100 undergraduate students in Pakistani ESL classrooms, clearly English L2 learners in an ESL context. The study focuses on vocabulary and writing skills in English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses AI tools such as Grammarly and QuillBot. These are not described as large language model-based instructional tools in the abstract and are typically categorized as non-LLM writing support tools (grammar checking/paraphrasing), not transformer-based generative LLMs like ChatGPT, GPT-4, or Gemini. No LLM integration is mentioned.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is ESL instruction with a focus on vocabulary and writing skills, and the study reports on writing performance outcomes, aligning with writing competence as a primary focus.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental design with pre- and post-tests and reports quantifiable gains in writing performance (+46%, d = 1.03), providing measurable writing outcome metrics.""
    }
}"
41,Chatgpt-supported Collaborative Argumentation: Integrating Collaboration Script and Argument Mapping to Enhance Efl Students' Argumentation Skills,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are clearly identified as EFL (English as a Foreign Language) students: “A total of 67 freshmen university students participated… The findings showed that the ChatGPT-CA approach significantly enhanced EFL students' argumentative speaking performance…”. The target language is English.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is quasi-experimental and explicitly uses ChatGPT, a large language model, as part of the intervention: “we proposed using ChatGPT, a large language model, to guide students through three stages of collaboration script… 34 of them using ChatGPT-supported collaborative argumentation (ChatGPT-CA) and 33 using conventional-based collaborative argumentation (C-CA).”""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary measured outcomes are “argumentative speaking performance, critical thinking awareness, and collaboration tendency.” The abstract frames argumentation as involving both writing and speaking, but the reported quantitative outcome is explicitly speaking-focused, not writing competence or writing-related performance. There is no clear indication that written argumentation or writing quality was an assessed outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study reports quantifiable outcomes (e.g., argumentative speaking performance, critical thinking awareness, collaboration tendency, and quality of arguments), these are not specified as writing outcomes. The focus of the measured intervention effects is on speaking and general argument quality, not on written texts or writing performance metrics, which is required for inclusion.""
    }
}"
42,Teachers' Perceptions and Students' Strategies in Using Ai-mediated Informal Digital Learning for Career Esl Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are university students in an English writing course in an ESL context (“career ESL writing instruction”), so they are L2 English learners in an ESL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is mentioned among tools (Grammarly, ChatGPT, Canva with Magic Write, Invideo), the study is described as a case study exploring perceptions and strategies, not an experimental or quasi-experimental intervention design specifically integrating LLMs into instruction. Multiple tools are used and there is no clear LLM-focused instructional intervention with controlled conditions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is career ESL writing instruction and focuses on students’ strategies for using AI-mediated tools to improve writing, so the primary focus is on writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative data sources (demographic questionnaire, think-aloud protocols, semi-structured interviews) and discusses strategies and perceptions. It does not indicate any quantifiable writing outcome metrics or experimental measures of writing improvement attributable to LLM-mediated intervention.""
    }
}"
43,"Using Ai to Enhance Digital Multimodal Composing: Efl Learners' Semiotic Decision-making, Self-efficacy, Enjoyment, and Continuance Intention",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners in an academic English course, clearly fitting the L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses an unspecified AI-powered text-to-video tool for digital multimodal composing. There is no indication that this is an LLM-based (transformer generative text) system such as ChatGPT/GPT-4; it is framed as text-to-video generation, not an LLM writing assistant.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on digital multimodal composing (video production) and related constructs (semiotic decision-making, self-efficacy, enjoyment, continuance intention), not on writing competence or writing-related variables as outcomes. Written reflections are data sources, not targeted writing outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports questionnaire-based perceptions (self-efficacy, enjoyment, continuance intention) and qualitative assessments of AI-generated videos. It does not report quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity) to evaluate an LLM-mediated writing intervention.""
    }
}"
44,Exploring High School Students' Preferences for English Writing Feedback: Non-native English Teacher Vs. Native English Teacher Vs. Chatgpt,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 20 high school students from an English newspaper club in Korea, clearly an EFL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used to provide feedback, the study is not an experimental or quasi-experimental writing intervention aimed at improving writing performance. It is primarily a preference/comparison study of feedback sources (non-native teacher, native teacher, ChatGPT), not a structured pedagogical intervention assessing learning gains.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on students’ preferences and perceptions of different feedback providers, not on writing competence or writing-related performance outcomes. The context is evaluative (which feedback source students prefer) rather than an instructional intervention to develop writing skills.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The quantitative data consist of Likert-scale ratings of feedback and preferences, analyzed with descriptive statistics and non-parametric tests. No quantifiable writing outcome metrics (e.g., changes in writing scores, accuracy, complexity) are reported to assess the effectiveness of ChatGPT-mediated writing intervention.""
    }
}"
45,"I, Too, Shall Have to Prompt? a Study of Efl Students and Their Unmonitored Use of Genai in the Completion of an Imitation Task in Poetry",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students in a university English as a Foreign Language Literature course, so they are L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to a 'GenAI model' and a 'GenAI-assisted creative writing exercise,' but does not specify whether the tool is a large language model (e.g., ChatGPT/GPT-4) or another type of generative AI. The specific technology and architecture are not identified.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on a literature course and on how the GenAI-assisted imitation task supports application of literary analysis elements, prompt characteristics, and pedagogical implications. Writing competence or writing-related performance is not the central outcome; rather, it is use of literary terms and analysis.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is based on qualitative data from surveys and observational studies. The abstract does not report any quantifiable writing outcome metrics (e.g., writing scores, rubric-based assessments) to evaluate the effectiveness of the GenAI intervention on writing performance.""
    }
}"
46,Investigating Efl Teachers' Lesson Planning for Chatbot-assisted Learning of Argumentative Writing: a Tpack Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly EFL (English as a foreign language) teaching and learning, with a focus on argumentative writing in English. Participants are EFL teachers planning for EFL learners.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses a chatbot named Argumate, but the abstract does not specify whether it is an LLM-based, transformer-based generative model (e.g., ChatGPT-like) or a different type of chatbot. However, the main focus is on teachers’ lesson planning and professional knowledge, not on an implemented LLM-mediated intervention with learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is argumentative writing, the study investigates teachers’ lesson planning and TPACK for chatbot integration, not an actual pedagogical intervention implemented with students. It does not evaluate writing competence or writing-related outcomes; it focuses on integration approaches and professional knowledge.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study analyzes lesson plans and interview data about teachers’ reasoning, without experimental measures of students’ writing performance or structured intervention outcomes.""
    }
}"
47,Comparing Hong Kong Secondary School Students' Perceptions of Chatgpt-assisted Efl Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 107 Hong Kong secondary school students in an EFL context, and the study explicitly concerns ChatGPT-assisted EFL (English) writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study investigates ChatGPT-assisted EFL writing and compares three teaching approaches (process-based, genre-based, prompt engineering only), indicating an instructional intervention integrating an LLM (ChatGPT) into writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is ChatGPT-assisted EFL writing, the measured outcomes are motivation, cognitive load, and satisfaction. There is no indication that writing competence or writing performance variables are directly assessed; the focus is on affective and cognitive perceptions rather than writing outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports quantitative outcomes only for motivation, cognitive load, and satisfaction. It does not mention any quantifiable writing performance metrics (e.g., writing scores, accuracy, complexity, organization). Thus, it lacks the required writing outcome measures for inclusion.""
    }
}"
48,Does Metalinguistic Explanation of Teacher and Chatgpt Feedback Improve Efl Learners' Writing Quality and Engagement? Findings from an Intervention Study,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as EFL learners (foreign language writing instruction, EFL learners), indicating L2 English learners in an EFL context with a focus on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is a quasi-experimental intervention examining scaffolded metalinguistic explanations of teacher and ChatGPT feedback. ChatGPT is a large language model integrated into the writing feedback process, satisfying the LLM-based intervention requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is foreign language writing instruction, focusing on how feedback (including ChatGPT feedback) affects writing quality and engagement. The primary focus is clearly on writing competence and writing-related variables, not on automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pre-tests and post-tests, written drafts, and reports significant improvements in writing performance (grammatical accuracy, vocabulary use, mechanical control) and incorporation of feedback. These are quantifiable writing outcome metrics within an intervention design.""
    }
}"
49,Assigning Cefr-j Levels to English Learners' Writing: an Approach Using Lexical Metrics and Generative Ai,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The system is designed for assessing English learners’ writing proficiency in an EFL context (CEFR-J, tailored to EFL in Japan). Thus, the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study presents CWLA, an automated writing level analyzer that uses lexical metrics and AI-based analytical scores for assessment. There is no indication that a large language model (e.g., ChatGPT, GPT-4) is integrated into writing instruction or writing processes; instead, AI is used for automated scoring/assessment.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on developing and validating an automated system for assessing writing proficiency (alignment with CEFR-J, correlation with human ratings), not on pedagogical writing intervention or improving writing competence. This aligns with automated essay scoring functionality, which is excluded by the review criteria.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports quantitative metrics (correlation with human ratings, entropy analysis, expert agreement), but these are validation metrics for an assessment tool, not writing outcome measures from an instructional or intervention study involving learners’ writing development.""
    }
}"
50,Rnn Hybrid Model for Evaluating Efl Teachers' Classroom Performance in Higher Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract focuses on evaluating EFL teachers' classroom performance in higher education using an RNN-based model. There is no indication that the participants are L2 English learners or that learner data in an ESL/EFL/ELL context is the focus; instead, the target of evaluation is teachers.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses an Elman RNN combined with a Dolphin Echolocation Algorithm (DEA-RNN) as a predictive/evaluation model. This is not a large language model (e.g., ChatGPT, GPT-4) and is not integrated into writing instruction or writing processes; it is a machine learning model for performance evaluation.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is teacher performance evaluation in higher education, not writing competence or writing-related variables. There is no mention of writing instruction, writing tasks, or writing development as a primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are model performance metrics (accuracy, precision, recall, F1-score, specificity) for evaluating teachers, not quantifiable writing outcomes for L2 learners. No writing intervention or writing performance measures are described.""
    }
}"
51,Exploring Ai to Automate Efl Corrective Written Feedback in the First Language,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The title and abstract indicate an EFL context with students whose L1 is Japanese, implying they are L2 English learners receiving corrective written feedback on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a ChatGPT-powered plugin (a generative AI LLM) within Moodle to provide automated written corrective feedback as part of a classroom intervention, satisfying the LLM-based intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention centers on a free-writing activity and subsequent written corrective feedback on students’ writing, clearly focusing on writing competence and writing-related processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes an exploratory study focusing on perceptions of grammatical feedback (accuracy, comprehensibility, appreciation) and survey data. It does not report any quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity) to assess effectiveness of the intervention on learners’ writing performance.""
    }
}"
52,"Exploring Efl Students' Ai Literacy in Academic Writing: Insights into Familiarity, Knowledge and Ethical Perceptions",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Turkish English as a Foreign Language (EFL) students, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a descriptive exploratory survey of AI literacy and usage (e.g., translation and grammar proofreading). It does not describe an experimental or quasi-experimental intervention integrating LLMs (such as ChatGPT) into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on AI literacy, familiarity, and ethical perceptions related to AI in academic writing, not on a pedagogical writing intervention or structured use of LLMs to develop writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes concern levels of AI familiarity, usage, and ethical perceptions, without measured changes in writing performance following an intervention.""
    }
}"
53,"A Q Method Study on Turkish Efl Learners' Perspectives on the Use of Ai Tools for Writing: Benefits, Concerns, and Ethics",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Turkish English language learners enrolled in a preparatory EFL program at a state university in Istanbul, clearly fitting an L2 English EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates learners’ perspectives on the use of unspecified AI tools for writing, not an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into instruction. It is attitudinal/usage-focused rather than an LLM-based pedagogical intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is writing, the focus is on perceived benefits, concerns, and ethics of AI tool use, not on a structured writing intervention or instructional design aimed at improving writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study uses Q methodology and qualitative interviews to explore perspectives, without experimental measures of writing performance or related outcomes.""
    }
}"
54,"The Role of Techno-competence in Ai-based Assessments: Exploring Its Influence on Students' Boredom, Self-esteem, and Writing Development",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 66 Saudi Arabian male EFL learners, clearly an L2 English context: “EFL learners… 66 Saudi Arabian male students… participated in the study.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is described only as “AI-driven evaluations” and “AI-enhanced assessments.” There is no indication that a large language model (e.g., ChatGPT, GPT-4) or transformer-based generative model was used; it could be any AI-based assessment tool. Thus it does not clearly meet the LLM requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing development is one of the primary outcomes: the study examines how AI-based assessments affect “writing skills,” “writing proficiency,” and “writing abilities,” which are central to writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pre- and post-assessments to measure “boredom, writing proficiency, and self-esteem,” and reports that the experimental group outperformed the control group. This indicates quantifiable writing outcome metrics within an experimental design.""
    }
}"
55,Interactive Eassessment of Writing Competency in French as a Foreign Language: Development and Implementation of an Ai-enhanced Progress Monitoring System,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are learners of French as a Foreign Language in Moroccan primary schools. The focus is on French writing competency, not English (ESL/EFL/ELL). Therefore, the population does not meet the review’s requirement of L2 English learners.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions an 'AI-enhanced progress monitoring system' and 'automated analysis,' but does not specify that the AI is a large language model (e.g., ChatGPT, GPT-4) or any transformer-based generative model. The nature of the AI is not clearly described.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on formative e-assessment and progress monitoring of writing competency via an AI-enhanced system, not on writing instruction or intervention in the writing process. It is an assessment/monitoring tool rather than a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are qualitative (teacher responses, feedback, perceived effectiveness) and system usage statistics. There is no indication of quantifiable student writing outcome metrics (e.g., pre/post writing scores) used to evaluate the impact of the AI system on learners’ writing performance.""
    }
}"
56,Leveraging Ai for Writing Instruction in Efl Classrooms: Opportunities and Challenges,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 150 fourth-year English major students in an EFL context (a university in the Mekong Delta). The focus is clearly on English as a foreign language writing instruction.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers generically to “AI writing tools” without specifying that they are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems. They could include non-LLM tools such as grammar checkers or other traditional AI, so it is not possible to confirm LLM use from the abstract alone.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL writing instruction, and the study examines how AI tools are applied in writing classes and how they help improve writing skills. The primary focus is pedagogical use in writing, not automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study is described as mixed methods and mentions that AI helps students ‘achieve better writing skills,’ the abstract only reports perceptions and self-reported improvements. It does not indicate any experimental or quasi-experimental design with quantifiable writing outcome measures (e.g., pre/post writing scores, rubric-based assessments). Thus, it does not meet the requirement for reported quantitative writing outcomes of an LLM-mediated intervention.""
    }
}"
57,"Generative Ai-assisted Feedback and Efl Writing: a Study on Proficiency, Revision Frequency and Writing Quality",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are sixty postgraduate English as a Foreign Language (EFL) students, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Grammarly as the AI-enhanced feedback system. Grammarly is generally not an LLM-based, transformer-style generative model in the sense required (e.g., ChatGPT, GPT-4, Gemini). The abstract does not indicate integration of a large language model; it frames Grammarly as an AI feedback tool, which falls under the excluded category of tools like Grammarly, Duolingo, QuillBot, Pigai that are not clearly LLM-based generative models.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing proficiency, revision practices, and writing quality (content, organization, cohesion) in EFL writing, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: pre- and post-test scores of overall writing proficiency, correlations between AI feature use and revision frequency, and improvements in content, organization, and cohesion.""
    }
}"
58,"Generative Ai Vs. Teachers: Feedback Quality, Feedback Uptake, and Revision",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 60 EFL secondary students in a high school in China. The context is explicitly EFL, and the written samples are in English, satisfying the L2 English learner population requirement.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a 2x2 counter-balanced experimental design where a Gen-AI bot (ChatGPT) and teachers both provide feedback on students’ writing. ChatGPT is a large language model integrated into the writing feedback process, fulfilling the LLM-based intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on written compositions, feedback quality, feedback uptake, and revision of EFL students’ writing. ChatGPT is used pedagogically to provide feedback on student writing, not merely as an automated scoring tool, so the primary focus is on writing competence and revision behavior.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study analyzes 1200 records to compare feedback quality and student uptake rates between AI and teacher feedback, and examines revisions after feedback. These constitute quantifiable writing-related outcome measures (feedback uptake, revision behavior, and feedback quality metrics) within an experimental design.""
    }
}"
59,"Bridging Ai and Pedagogy: How Ai-adaptive Feedback Shapes Chinese Efl Students' Writing Engagement, Metacognitive Writing Strategies, and Writing Performance",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese university EFL learners in writing contexts, clearly L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines “AI-adaptive feedback” in general, with no indication that the system is a large language model (e.g., ChatGPT, GPT-4) or transformer-based generative model. It appears to be an AI-enhanced adaptive feedback system, but its underlying technology is unspecified, so it cannot be confidently classified as an LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL writing pedagogy, focusing on writing engagement, metacognitive writing strategies, and writing performance, which are writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports quantifiable writing outcomes, including writing performance and structural equation modeling coefficients (e.g., beta = 0.32 for writing performance), indicating measurable effects of the intervention.""
    }
}"
60,Enhancing Students' L2 Writing by Integrating Artificial Intelligence with Corpus-based Language Pedagogy,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 50 English as a Foreign Language (EFL) learners majoring in English at an English-Medium Instruction university in China, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that students used “their preferred corpus and AI tools in writing revision” but does not specify that these AI tools are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems. They could be non-LLM tools (e.g., grammar checkers). Without explicit indication of LLM use, eligibility on this criterion is unclear.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on L2 writing revision, integrating AI and corpus-based language pedagogy to support writing development. The primary context is writing competence and revision behavior, not automated scoring or system benchmarking.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract emphasizes attitudes (questionnaires, interviews) and descriptive analysis of types of changes (e.g., corpus for collocations, AI for sentences). It does not report quantifiable writing outcome metrics (e.g., pre/post writing scores, quality ratings) to assess effectiveness of the AI-mediated intervention, focusing instead on usage patterns and perceptions.""
    }
}"
61,From Spicing up My Writing to Convincing My Supervisors: Efl Learners' Motivations for Using Promotional Language ('hypes') in Academic Texts,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Indonesian EFL learners writing theses and dissertations, so they are L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is qualitative, using in-depth semi-structured interviews to explore motivations for using promotional language. AI tools are mentioned only as one of several external motivational factors, not as an experimental or quasi-experimental LLM-based writing intervention. No specific LLM (e.g., ChatGPT) is integrated into instruction or writing processes as a treatment.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on rhetorical use of promotional language (hypes), identity construction, and power dynamics in academic discourse, not on improving writing competence through an LLM-mediated pedagogical intervention. AI tools are framed as influences, not as an instructional context for writing development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study relies on thematic analysis of interviews and functional analysis of hypes; it does not report quantitative writing outcome measures or assess the effectiveness of any LLM-mediated writing intervention.""
    }
}"
62,Probing into Efl Students' Perceptions about the Impact of Utilizing Ai-powered Tools on Their Academic Writing Practices,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 30 EFL students enrolled in an Academic Writing 2 course at a private university in Oman, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is among the tools used, the study is framed as an exploration of perceptions about AI-powered tools (Grammarly, Wordtune, ChatGPT, Quillbot) rather than an experimental or quasi-experimental design assessing an LLM-based writing intervention. There is no indication of controlled intervention conditions or comparison groups focused on LLM integration.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is academic writing practices and stages of the writing process in an Academic Writing course, with explicit focus on grammar, style, paraphrasing, summarizing, brainstorming, and overall academic writing performance.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a qualitative approach (learning journals, observations, focus-group interviews) to explore perceptions. While it claims that tools improved writing skills and performance, no quantifiable writing outcome metrics or experimental measures are reported in the abstract; outcomes are described qualitatively.""
    }
}"
63,Effects of Human-ai Collaborative Writing Strategy on Efl Students' Argumentative Writing Skills,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Indonesian EFL university freshmen, clearly L2 English learners in an EFL context: “Indonesian EFL students’ argumentative writing skills… Thirty university freshmen were involved as participants.”""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract repeatedly mentions “human-AI collaborative writing,” “AI-assisted tools,” and “intelligent technology-enhanced writing instruction,” but does not specify which AI tools were used or whether they are LLM-based (e.g., ChatGPT, GPT-4) versus non-LLM tools (e.g., grammar checkers). Without explicit identification of an LLM or transformer-based generative model, it is impossible to confirm that the intervention integrates an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on writing competence: “examined the effects of the human-AI collaborative writing strategy on … argumentative writing skills.” The intervention is a writing strategy and the outcomes are argumentative writing performance and critical thinking in written discourse, not automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantifiable writing outcomes are reported. Argumentative writing skills and critical thinking in writing are measured via pretest–posttest essay scores, analyzed with paired-sample t-tests and effect sizes (e.g., t = 54.87, p = 0.000, eta² = 0.99). Thus, structured, quantitative writing outcome metrics are present.""
    }
}"
64,Investigating L2 Learners' Text-to-video Resemiotisation in Ai-enhanced Digital Multimodal Composing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 75 undergraduates in an English writing course at a comprehensive university in China, i.e., EFL learners using English as an L2 in a writing classroom context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The AI tool is an AI-powered text-to-video platform (Pictory) used for digital multimodal composing. There is no indication that it is a large language model (LLM) such as ChatGPT/GPT-4 or a transformer-based generative text model integrated into writing instruction; it is primarily a text-to-video generator.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on digital multimodal composing and text-to-video resemiotisation, examining how students integrate linguistic, semiotic, and technological elements to create videos. The outcome emphasis is on DMC skills and multimodal video compositions rather than on writing competence or writing-related performance measures.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes qualitative content and comparative analyses of students’ query revisions and multimodal elements, aiming to understand processes and provide insights for curriculum development. It does not report quantifiable writing outcome metrics or experimental measures of writing performance attributable to the AI intervention.""
    }
}"
65,"Ai in Academic Writing: Assessing the Effectiveness, Grading Consistency, and Student Perspectives of Chatgpt and You.com for Efl Students",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 16 B1–B2 level students majoring in English Language and Literature or English Language Teaching at a School of Foreign Languages. The context is explicitly English as a Foreign Language (EFL) education, and the focus is on English academic writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses ChatGPT and You.com (both LLM-based tools) to provide AI-generated feedback and grading on students’ drafts, combined with targeted training sessions based on that feedback. This constitutes an experimental/mixed-methods design integrating LLMs into writing instruction and processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on academic writing skills in EFL, with AI-generated feedback used to improve paragraph writing across multiple types. The study is pedagogical, examining AI feedback and training sessions as part of writing instruction, not just automated scoring for evaluation purposes.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative analysis of draft scores (using a detailed rubric and statistical tests such as paired t-tests, independent t-tests, and ANOVA) shows significant improvements from first to final drafts. These are clear, quantifiable writing outcome measures assessing the effectiveness of the AI-mediated intervention.""
    }
}"
66,'critical Chatting' or 'casual Cheating': How Graduate Efl Students Utilize Chatgpt for Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as “graduate EFL students,” indicating L2 English learners in an EFL context, and the focus is on their academic writing in English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a qualitative case study exploring how four graduate EFL students utilize ChatGPT for academic writing. It does not describe an experimental or quasi-experimental instructional intervention; rather, it investigates existing student use, purposes, and rationales.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly academic writing: the study examines “ChatGPT-assisted academic writing,” including language editing, knowledge inquiry, and inspiration seeking, and how critical thinking is embedded in this writing process.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes a qualitative case study using thematic analysis, focusing on purposes, rationales, and critical thinking. It does not report any quantifiable writing outcome metrics or experimental measures of writing performance.""
    }
}"
67,English as a Foreign Language (efl) Secondary School Students' Use of Artificial Intelligent (ai) Tools for Developing Writing Skills: Unveiling Practices and Perceptions,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are EFL secondary school students using AI tools to develop English writing skills, which fits the L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is mentioned among tools students know, the study is descriptive/exploratory. It investigates existing practices and perceptions via questionnaire and interviews, not an experimental or quasi-experimental intervention integrating LLMs into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on developing writing skills and how AI writing tools mediate stages of the writing process, aligning with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports practices and perceptions; there is no indication of quantifiable writing outcome measures (e.g., pre/post writing scores, rubric-based performance) to assess the effectiveness of AI/LLM-mediated interventions.""
    }
}"
68,"The Impact of Self-revision, Machine Translation, and Chatgpt on L2 Writing: Raters' Assessments, Linguistic Complexity, and Error Correction",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are learners in a South Korean high school English as a Foreign Language (EFL) context, clearly indicating L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT-assisted proofreading (CAP) as one of three controlled interventions. ChatGPT is a large language model integrated into the writing process as part of an experimental design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on L2 writing outcomes: overall writing quality, text length, lexical diversity, sentence complexity, and error reduction. The interventions are pedagogical (self-revision, MT, ChatGPT) within writing instruction, not just automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcome metrics: improvements in overall writing quality, text length, lexical diversity, sentence complexity, verb cohesion, and grammatical/prepositional error rates, comparing SP, MAP, and CAP conditions.""
    }
}"
69,Chat Gpt a Project Based Professional Learning as an Alternative Learning to Traditional Writing : a Quick Response Generator to Improve Writing Skills,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are university students engaged in English language development and professional writing (business correspondence, reports, etc.). This indicates L2 English learners in an EFL/ESL academic context, with focus clearly on English writing skills.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention explicitly uses ChatGPT, described as an OpenAI tool, as a ‘techno-aided tool’ in a quasi-experimental design. Traditional writing instruction is compared with ChatGPT-supported project-based professional learning, satisfying the requirement for an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on improving writing skills, specifically professional/business writing (letters, emails, reports, notices, memorandums, etc.). ChatGPT is integrated into instruction to enhance these writing competencies, not merely for scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental pre-test/post-test design to examine the impact of ChatGPT on writing skills. It reports that technology-assisted ChatGPT use improves professional writing skills, implying quantifiable outcome measures beyond qualitative perceptions alone.""
    }
}"
70,"The Impact of Ai-enhanced Natural Language Processing Tools on Writing Proficiency: an Analysis of Language Precision, Content Summarization, and Creative Writing Facilitation",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly situates the study in the context of English as a Foreign Language (EFL) education, indicating that participants are L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses “AI-driven Natural Language Processing (NLP) tools” and specifically mentions tools for grammar checking, vocabulary enhancement, and sentence structure refinement. These are characteristic of traditional NLP/AI writing support tools (e.g., grammar checkers), and there is no indication that large language models (ChatGPT, GPT-4, etc.) or transformer-based generative models are used. Thus it does not clearly meet the requirement of an LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing proficiency and related aspects (language precision, content summarization, creative writing facilitation) within EFL education, aligning with writing competence as the central outcome rather than automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a pretest–posttest experimental design with random assignment and reports that the treatment group showed superior improvements in writing proficiency. This implies quantifiable writing outcome metrics (descriptive statistics and inferential tests) in addition to qualitative feedback.""
    }
}"
71,Human-ai Collaborative Feedback in Improving Efl Writing Performance: an Analysis Based on Natural Language Processing Technology,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL students from tertiary institutions, so they are L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to a “human-AI collaborative feedback mechanism” and “integrating AI into EFL feedback systems,” but does not specify that the AI is a large language model (e.g., ChatGPT, GPT-4) or transformer-based generative model. It could be another form of NLP-based feedback tool. Without explicit mention of LLMs or generative models, it is unclear whether this meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL writing proficiency and performance, with outcomes such as language accuracy, complexity, and fluency. The AI is used as part of a feedback system within writing instruction, not solely for automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses quantitative analyses (regression and mediation tests) to examine relationships between feedback and writing performance, and reports effects on writing performance and language features (accuracy, complexity, fluency), indicating quantifiable writing outcome metrics.""
    }
}"
72,Enhancing Learning Outcomes in Written Production by Implementing Writing Strategies and Using Ai Writing Tools,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are university students taking English for Specific Purposes and English for Academic Purposes courses at Slovak universities, indicating L2 English learners in an EFL/ESP context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions that student assignments were screened for AI use and that some students rely heavily on AI tools, but it does not specify that the intervention systematically integrates LLMs (e.g., ChatGPT) into instruction. AI use appears incidental and student-driven, not an experimental or quasi-experimental LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on written production and communicative language activities in ESP/EAP courses, with attention to writing performance and the role of AI tools in writing, aligning with a writing competence context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although pre-test and post-test writing results are compared using a t-test, the abstract does not report outcomes specifically attributable to an LLM-mediated intervention. AI tools are only observed/screened, not manipulated as a structured treatment whose effect on writing is measured.""
    }
}"
73,The Impact of Chatgpt on Academic Writing Skills and Knowledge: an Investigation of Its Use in Argumentative Essays,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as EFL students and third-year English majors, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The title and abstract state that the study investigates the impact of ChatGPT and AI-assisted writing, but they do not specify whether ChatGPT was integrated as a structured pedagogical intervention (e.g., guided use, experimental/quasi-experimental design) or merely observed as a tool students chose to use. The design is mixed-methods with pre/post drafts, but the exact nature of the ChatGPT-based instructional or experimental treatment is not detailed.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on EFL students’ argumentative writing development and academic writing skills, with essay evaluation across dimensions such as content, organization, language use, critical thinking, AI integration, and academic integrity. This aligns with writing competence as the primary focus.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative writing outcomes: essays were scored using an adapted AIAS framework, and the abstract notes significant enhancements in writing performance, including a quantified improvement in academic integrity (+3.0 points). This satisfies the requirement for quantifiable writing outcome metrics.""
    }
}"
74,Genai as a Learning Buddy for Non-english Majors: Effects on Listening and Writing Performance,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 93 undergraduates enrolled in mandatory English as a Foreign Language (EFL) courses at a public university. The focus is explicitly on English skills (listening and writing), fitting ESL/EFL L2 English learner criteria.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ‘GenAI-mediated’ activities and ‘guided chatbot interactions’ as the core intervention, with an experimental group completing 10 weekly GenAI-mediated listening and writing activities versus a comparison group with traditional curriculum and optional chatbot use. This is a quasi-experimental design integrating generative AI chatbots (LLM-based) into instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention explicitly targets listening and writing skills, and the abstract reports effects on ‘writing performance.’ The GenAI/chatbot is used pedagogically as a learning buddy within structured activities, not merely as an automated scoring tool.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative outcomes are reported: both groups improved over time, with the experimental group showing significantly greater gains in writing at the immediate post-test, though not maintained at follow-up. These are measurable writing performance outcomes from an LLM-mediated intervention.""
    }
}"
75,Leveraging Ai to Enhance Writing Skills of Senior Tfl Students in Kazakhstan: a Case Study Using 'write & Improve',2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are senior undergraduate students in a “two foreign language” (TFL) program in Kazakhstan, working on English writing tasks (task achievement, coherence and cohesion, lexical resource, grammar and accuracy), which fits an EFL/ESL-type L2 English learner context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses the Write & Improve platform. Write & Improve is an automated writing evaluation tool, not a large language model–based generative system like ChatGPT, GPT-4, or similar LLMs. The study compares teacher feedback with this AWE tool, so it does not meet the requirement of integrating an LLM in the writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on enhancing writing skills and evaluating feedback effects on multiple writing dimensions (task achievement, coherence and cohesion, lexical resource, grammar and accuracy, overall score). This is clearly a writing competence intervention, not just automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes via pre- and post-tests, using descriptive statistics, Mann-Whitney U tests, and MANCOVA to compare scores across writing dimensions and over time. Thus, it provides measurable writing outcome metrics.""
    }
}"
76,Chatgpt-assisted Language Learning: Effects on Vietnamese English Majors' Writing Skills and Motivation,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Vietnamese first-year English majors, clearly L2 English learners in an EFL context. The focus is on English writing skills, with outcomes measured via IELTS writing assessments.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly examines 'ChatGPT-assisted instruction' and compares an experimental group using ChatGPT-assisted writing instruction with a control group receiving traditional instruction, indicating an experimental design integrating an LLM into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence: 'writing skills' and 'writing performance across all domains' using IELTS writing assessments. ChatGPT is used pedagogically to support writing, not merely for automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantifiable writing outcomes are reported: pre- and post-tests using IELTS writing assessments, with ANCOVA results showing significant improvements in writing performance and effect sizes (e.g., task achievement, coherence). Thus, structured intervention outcomes on writing are clearly measured.""
    }
}"
77,"Artificial Intelligence in Efl Education in China: a Systematic Review of Trends, Gaps, and Future Directions (2015-2024)",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The article is a systematic review of AI in English as a Foreign Language (EFL) education in China, so the underlying population across included studies is EFL learners of English. However, this paper itself is not an empirical study with its own participants.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper is explicitly described as a systematic review of 56 articles on AI in EFL education. It does not itself implement an experimental or quasi-experimental LLM-based writing intervention; instead, it synthesizes prior work. Review articles are to be excluded.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract notes that speaking and writing are among the most discussed skills in the reviewed literature and mentions tools like ChatGPT and Pigai, the article’s primary focus is mapping trends and gaps in AI in EFL education broadly, not conducting a specific writing-focused pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic review, the study does not report its own experimental writing outcome metrics. It summarizes others’ findings rather than providing quantifiable outcomes from an LLM-mediated writing intervention conducted by the authors.""
    }
}"
78,Undergraduate Students' Perceptions on the Use of Chatgpt for English Learning at a Korean University,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Korean and international undergraduate students using ChatGPT for English language learning at a Korean university, fitting an EFL/ESL/ELL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates students’ perceptions of ChatGPT’s usefulness via surveys and qualitative comments. There is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction or processes; it is an attitudinal/perception study.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing is mentioned only as one of several skills (grammar, listening, vocabulary, reading, writing). The primary focus is general English learning and perceptions of ChatGPT, not a targeted writing competence intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are Likert-scale perceptions and qualitative views on usefulness. No quantifiable writing performance metrics or measured changes in writing ability are reported.""
    }
}"
79,Preparing Teachers for the Algorithmic Educational Landscape: a Critical Mapping of Generative Ai Integration in Language Teacher Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a bibliometric-based systematic literature review on generative AI in language teacher education. It does not report on a primary sample of L2 English learners in ESL/EFL/ELL contexts; instead, it maps existing research themes, including one cluster on EFL writing, at a meta-level.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic literature review, the article does not implement an experimental or quasi-experimental intervention integrating LLMs into writing instruction. It synthesizes prior work rather than conducting a primary LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on mapping research about generative AI in language teacher education, not on a specific writing competence intervention. Although one thematic cluster concerns EFL writing skills, this is at the level of reviewed studies, not a direct pedagogical intervention examined by this article.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a review and does not report original, quantifiable writing outcome metrics from an LLM-mediated intervention. It identifies thematic clusters in the literature rather than measuring writing performance changes.""
    }
}"
80,Comprehensive Review of Writing Assessments in Efl Contexts: a Meta-synthetic Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The article is a meta-synthesis of prior research on writing assessments in EFL contexts. While many included primary studies likely involve EFL learners (L2 English), this paper itself does not report on a specific participant population; it is a secondary review study.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a meta-synthetic review of various assessment practices (teacher feedback, self-assessment, peer-assessment, blended assessment, AWE, and AI). It does not implement an experimental or quasi-experimental LLM-based writing intervention itself; it only synthesizes existing literature.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is EFL writing assessment, the article is a review of assessment approaches rather than a primary study implementing an LLM in writing instruction or processes. It does not constitute a pedagogical intervention study with LLM integration.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a meta-synthesis, the paper does not report original, quantifiable writing outcome metrics from an LLM-mediated intervention. It synthesizes prior findings and offers recommendations, fitting the category of a review article, which is excluded by the protocol.""
    }
}"
81,Comparative Analysis of Human Graders and Ai in Assessing Secondary School Efl Journal Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are secondary school EFL students in a private school in Istanbul, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares grading and feedback by a GenAI platform and human graders. There is no indication of an experimental or quasi-experimental instructional intervention integrating the LLM into students’ writing processes; the GenAI is used as an assessor, not as part of a teaching intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on assessment—grading performance, consistency, and feedback quality of the GenAI platform—rather than on improving writing competence through a pedagogical intervention. This aligns with automated essay scoring/assessment evaluation, which is excluded by the review criteria.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports agreement between GenAI and human graders and discusses feedback quality, but does not report quantifiable writing outcome gains attributable to an LLM-mediated intervention (e.g., pre/post writing scores). It evaluates the tool’s grading, not its impact on learners’ writing development.""
    }
}"
82,Thai Efl University Students' Writing in the Digital Age: Error Analysis Revisited,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Thai EFL university students, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions Google Translate and ChatGPT and discusses digital tools, there is no indication of an experimental or quasi-experimental LLM-based writing intervention. The study is an error analysis plus a survey of attitudes and strategies, not an intervention integrating LLMs into instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on grammatical error analysis and writing strategies, with only general discussion of digital tools’ impact. There is no structured pedagogical intervention using LLMs to develop writing competence; LLMs are contextual background rather than the core instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports error types and survey results but does not evaluate the effectiveness of an LLM-mediated writing intervention with pre/post or comparative outcome measures. There are no quantifiable writing outcomes tied to an LLM-based treatment condition.""
    }
}"
83,Effects of Interaction with Ai-assisted Writing Evaluation on Efl Students' Writing Performance,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 30 Omani EFL learners, clearly indicating L2 English learners in an EFL context. The focus is on learning English as a foreign language and English writing performance.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses EditGPT, described as an automated written evaluation feedback instrument providing writing feedback. The name and description indicate an LLM-based tool (GPT) integrated into the writing feedback process in an experimental design with control and treatment groups.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing performance and feedback on students’ writing (narration and compare-and-contrast tasks). The study examines how AI-assisted writing evaluation affects writing performance, not just automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pretest and posttest writing tasks to measure students’ progress and reports comparative performance across control and experimental groups, providing quantifiable writing outcome metrics.""
    }
}"
84,The Effect of Ai-assisted Learning on Efl Writing Proficiency: Quasi-experimental and Cluster Analysis,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as EFL high school students in Dhahran at CEFR levels A2–B1. The context is explicitly English as a Foreign Language, and the focus is on English writing proficiency.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT as an AI tool providing real-time feedback on grammar, vocabulary, and coherence during writing practice. It is a quasi-experimental design with AI-assisted learning as the intervention, clearly involving an LLM (ChatGPT).""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing proficiency, assessing five core dimensions: content, organization, vocabulary, language use, and mechanics. ChatGPT is integrated into writing instruction as a supplementary aid, not merely as an assessment tool.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantifiable writing outcomes are reported via pre-test and post-test scores using Jacobs et al.’s (1981) analytical scoring rubric. Statistical analyses (Wilcoxon Signed Rank Test, cluster analysis) show significant gains in content, language use, vocabulary, and total scores.""
    }
}"
85,Imitating Mistakes in a Learning Companion Ai Agent for Online Peer Learning,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions a focus on English composition but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts. It could involve native speakers or mixed populations; this is not clarified.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study develops an AI Agent as a learning companion but does not indicate that it is based on a large language model (e.g., ChatGPT, GPT-4) or any transformer-based generative model. The nature of the AI is unspecified, so it cannot be assumed to be an LLM intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context involves English composition and peer learning, suggesting a writing-related focus, but the abstract does not clearly state that the primary focus is on writing competence or writing-related variables as learning outcomes, rather than on AI agent design or interaction patterns.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract does not report or clearly promise quantifiable writing outcome metrics. It mentions using English composition as an example to validate the approach, but no explicit experimental measures of writing performance are described.""
    }
}"
86,The Collaboration of Ai and Teacher in Feedback Provision and Its Impact on Efl Learner's Argumentative Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 28 tenth-grade EFL learners working on English argumentative writing, clearly fitting an EFL/ESL/ELL L2 English context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The AI tool used is DeepL Write. While it is an AI-based writing assistant, the abstract does not indicate that it is an LLM-based, transformer-style generative model like ChatGPT/GPT-4. Under the review’s criteria, tools such as Grammarly/other non-LLM writing assistants are to be excluded; DeepL Write appears to fall into this category rather than being an explicitly LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly focuses on English argumentative writing quality and examines the impact of AI and teacher feedback on multiple drafts, which is directly about writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing outcomes are quantitatively analyzed using Coh-Metrix across three drafts to assess changes in lexical, grammatical, and discourse-level features, providing measurable writing outcome metrics.""
    }
}"
87,Revisiting Trends in Genai-assisted Second Language Writing: Retrospect and Prospect,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract states that GenAI primarily assists learners of English as a second language (ESL) across various proficiency levels, indicating an L2 English learner population in ESL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a synthesis of findings from 73 empirical studies (a review), not an original experimental or quasi-experimental study implementing an LLM-based intervention itself. Review articles are to be excluded.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on GenAI-assisted L2 writing, including academic writing practices and writing metrics such as content, organization, grammar, and mechanics, which are clearly writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the review summarizes that included studies report effects and effect sizes, this paper does not itself report primary quantitative writing outcomes from an intervention it conducts; it is a secondary synthesis, which falls under excluded review-type articles.""
    }
}"
88,Enhancing Chatgpt-based Writing Research through Effective Prompt Use,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions “student essays” but does not specify that the students are L2 English learners in ESL/EFL/ELL contexts. Their language background and learning context are not described.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses ChatGPT to identify logical fallacies in student essays and examines prompt strategies. It is a methodological/case study on ChatGPT outputs, not an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or learners’ writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on ChatGPT’s analytical performance (precision, accuracy, validity) in detecting logical fallacies and on prompt design guidelines, not on developing learners’ writing competence or writing-related learning outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcome metrics are reported. Outcomes concern the reliability and validity of ChatGPT’s analyses and prompt strategies, not changes in students’ writing performance following an LLM-mediated intervention.""
    }
}"
89,"Including the Tech, Keeping the Human: Integrating Generative Ai in the Feedback Writing Process",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is UNSW College with reference to ‘the language learner’ and ‘EL/COS student’, which likely refers to English language / pathway college students. This suggests L2 English learners in an EAP/ESL-type setting.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to ‘generative AI’ and ‘AI-enhanced layered feedback’ but does not specify that the tools are large language models (e.g., ChatGPT, GPT-4). However, given current usage, it is plausible they are LLM-based. The design appears to be task trialling rather than a clearly stated experimental or quasi-experimental study.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on integrating generative AI into the feedback and editing stages of the writing process, aiming to support language development, feedback literacy, and writing-related skills. Thus, the primary focus is on writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions ‘observations from trialling these tasks’ and discusses potential benefits, but does not indicate any quantitative or experimental outcome measures of writing performance. It appears descriptive rather than reporting measurable writing outcomes.""
    }
}"
90,Implementing Ai Literacy Teaching in University-level L2 Writing Instruction: Exploring One Pedagogical Approach,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract specifies a first-year writing course for L2 writers at the university level, indicating L2 English learners in an academic writing context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study discusses GenAI tools and AI literacy in L2 writing instruction, it is described as a ‘classroom exploration piece’ and ‘one pedagogical approach’ without specifying an experimental or quasi-experimental design or systematic LLM-mediated intervention being tested.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on AI literacy, classroom culture, and the use of GenAI for written and multimodal communication. While writing is involved, the primary emphasis appears to be on literacy practices and pedagogy rather than systematically measuring writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantifiable writing outcome metrics or experimental measures. It presents a practitioner account of an approach, not an outcome-based evaluation of writing performance.""
    }
}"
91,Generative Ai for Learning Languages Other Than English: L2 Writers' Current Uses and Perceptions of Ethics,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are L2 learners of five languages other than English (LOTEs). The abstract explicitly focuses on writing in languages other than English, not on L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study concerns learners’ self-initiated uses of generative AI tools, but it does not clearly describe an experimental or quasi-experimental instructional intervention integrating a specific LLM into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is L2 writing: the study examines whether L2 learners use GenAI tools for L2 writing and in what ways, which is directly writing-related, though focused on usage and ethics rather than instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The design is a survey plus qualitative case study on uses and ethical perceptions. No quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity) assessing the effectiveness of GenAI-mediated writing interventions are reported.""
    }
}"
92,Structured or Semi-structured? the Use of Reflection Journals in Postgraduates' Generative Artificial Intelligence Literacy Development in an L2 Academic Writing Context,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are postgraduates in an L2 academic writing context, implying they are L2 English learners engaged in English academic writing. The abstract explicitly situates the study in an L2 academic writing context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study involves “GenAI-assisted writing tasks” and GenAI tools, which likely include LLMs, but no specific tools (e.g., ChatGPT, GPT-4) are named. However, the intervention being compared is the type of reflection journal (structured vs semi-structured), not different uses of LLMs themselves.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on GenAI literacy (operational competence, ethics and security, critical evaluation, reflection) in an L2 academic writing context, not on writing competence or writing-related performance variables. The outcomes concern literacy about GenAI use rather than measurable changes in writing quality or writing skills.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports quantifiable outcomes only for GenAI literacy dimensions, not for writing performance (e.g., text quality, accuracy, complexity, organization). There is no indication of measured writing outcomes; instead, the focus is on literacy gains and thematic analysis of reflections.""
    }
}"
93,Interacting with Chatgpt for Internal Feedback and Factors Affecting Feedback Quality,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 48 Chinese students in an English writing course, clearly indicating L2 English learners in an EFL context and a focus on L2 English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly involves interaction with ChatGPT (a Generative Pre-Trained Transformer LLM) to support students in generating internal feedback during an English writing course, which constitutes an LLM-based writing-related intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is an English writing course and the study focuses on using ChatGPT to support internal feedback in L2 writing, so the primary focus is on writing-related processes and competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes a qualitative case study exploring experiences, factors affecting feedback quality, and thematic analysis of qualitative data. It does not mention any experimental or quasi-experimental design with quantifiable writing outcome metrics (e.g., writing scores, measurable gains), focusing instead on perceptions and qualitative insights.""
    }
}"
94,Artificial Intelligence Tools for Research Writing: Practical Tips for Teachers,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract does not specify the learner population, language background, or whether students are L2 English learners in ESL/EFL/ELL contexts. It appears to be a general discussion of students and teachers without a defined L2 English population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper discusses “artificial intelligence (AI) tools” in general (content generation, literature review, data analysis, editing, citation management) and offers “practical instructional strategies.” It does not specify the use of large language models (e.g., ChatGPT, GPT-4) nor describe an experimental or quasi-experimental design; it appears to be conceptual/pedagogical guidance.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus is on research writing, the article is framed as an exploration of AI tools and instructional strategies rather than an empirical study of a writing intervention with measured outcomes. It is more of a practical/overview piece than a context where an intervention is systematically evaluated.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental results are mentioned. The abstract describes benefits and strategies but does not report any empirical measures of writing performance or related variables.""
    }
}"
95,Exploring the Use of Chatgpt-generated Model Texts as a Feedback Instrument: Efl Students' Text Quality and Perceptions,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 104 Chinese high school EFL students, clearly indicating L2 English learners in an EFL context. The focus is on English writing quality (content, organisation, vocabulary, grammar).""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses ChatGPT-generated model texts as a feedback instrument for writing. ChatGPT is a large language model, and the study employs a quasi-experimental design with control and experimental groups comparing human- vs ChatGPT-generated model texts.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL students’ writing quality (content, organisation, vocabulary, grammar) and the use of model texts as feedback in EFL writing classrooms. This is a pedagogical writing intervention, not an automated scoring or purely technical evaluation of the LLM.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a pretest–post-test quasi-experimental design and reports analytical measures of text quality (content, organisation, vocabulary, grammar) with descriptive and inferential statistics, providing quantifiable writing outcome metrics. Perception data are supplementary.""
    }
}"
96,Leveraging Chatgpt for Research Writing: an Exploration of Esl Graduate Students' Practices,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as two ESL graduate students, indicating L2 English learners in an ESL context, and the focus is on their English research writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the study is a case study of students’ self-directed use after a tutorial, not an experimental or quasi-experimental intervention design. There is no controlled instructional treatment or comparison condition to evaluate the effect of an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly research writing in English, focusing on how ChatGPT is used for genre, content, language use, documentation, coherence, and clarity—core writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative findings about practices, approaches, and academic integrity but does not mention any quantifiable writing outcome metrics (e.g., scores, rubric-based gains, pre-post measures) to assess effectiveness of the LLM-mediated writing support.""
    }
}"
97,Efl Students' Use of Ai Chatbots in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as students in a university-level English as a Foreign Language (EFL) class at a French university, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that students were trained to use AI chatbots for feedback on their writing. However, it does not specify that these chatbots are large language models (e.g., ChatGPT, GPT-4) as opposed to other AI feedback tools. The specific technology and model type are not identified.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is a unit focused on academic writing, and the intervention involves using AI chatbots to obtain feedback on student writing. The primary focus is clearly on writing competence and writing-related behavior.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study analyzes how students used chatbot feedback and what types of feedback they accepted or rejected, with responses coded to identify patterns. The abstract does not report any quantifiable writing outcome metrics (e.g., pre/post writing scores, rubric-based gains); it focuses on usage patterns and perceptions rather than measured effectiveness.""
    }
}"
98,Ai-powered Digital Tools for Vocabulary Retention in Foreign Language Learners: a Perception-based Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are students in the PINE program at UNESUM, Ecuador, where English is taught as a foreign language. Thus, they are EFL learners and fit the L2 English population criterion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students use AI-powered tools including ChatGPT, the study is described as a quantitative, descriptive, and relational survey of perceptions and usage. There is no experimental or quasi-experimental intervention design integrating LLMs into instruction; it is a perception-based survey.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is vocabulary retention and vocabulary learning, not writing competence or writing-related variables as a central outcome. Writing accuracy is mentioned only tangentially as a perceived benefit, not as the main focus of the study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are based on self-reported perceptions (e.g., perceived effectiveness, reported better retention, improved writing accuracy, increased motivation) collected via survey. There is no mention of quantifiable writing performance measures or an evaluated writing intervention.""
    }
}"
99,Translanguaging with Generative Ai in Efl Writing: Students' Practices and Perceptions,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students in China (six college students with lower to intermediate proficiency), clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study involves a generative AI tool (ERNIE Bot), it is described as a qualitative exploration of how students utilize it, with data from interviews and artefacts. There is no indication of an experimental or quasi-experimental design or a structured pedagogical intervention integrating the LLM into instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL writing and how students use generative AI in their writing process, framed through translanguaging practices. This aligns with writing competence and writing-related processes rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly qualitative, examining practices and perceptions. The abstract does not report any quantifiable writing outcome metrics or experimental measures of writing performance; it focuses on practices, emotions, and perceptions.""
    }
}"
100,"Descriptive Writing Using Generative Ai as a Cognitive Scaffold in the Metaverse Environment: University Students' Perceptions, Learning Engagement, and Performance",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as undergraduate EFL writing students, clearly indicating L2 English learners in an EFL context, with the task being English descriptive writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses a generative AI tool called 'GAIscaffold' as a cognitive scaffold. However, the abstract does not specify whether GAIscaffold is an LLM/transformer-based generative model (e.g., ChatGPT-like) or another form of generative AI. Without this detail, it is unclear if it meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on EFL descriptive writing performance in a metaverse environment, using generative AI as a scaffold in the writing process. The primary outcomes relate to writing competence and engagement, not automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative writing outcomes: final writing performance compared between experimental and control groups using MANCOVA, with statistically significant improvements in the experimental group.""
    }
}"
101,Impact of Chatgpt on English Academic Writing Ability and Engagement of Chinese Efl Undergraduates,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese undergraduates majoring in English as a foreign language (EFL) at a private university in China. The focus is explicitly on English academic writing, fitting ESL/EFL/ELL L2 English learner contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study investigates the impact of ChatGPT, explicitly identified as an AI tool, on students’ English academic writing. A quasi-experimental design with experimental and control classes is used, indicating an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on English academic writing ability and engagement in English academic writing. The intervention is pedagogical, not automated scoring or system evaluation, and centers on writing competence and related engagement variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes: English academic writing ability (content, structure and coherence, grammar, linguistic range, vocabulary, spelling, and form) analyzed via independent and paired sample t-tests, as well as survey-based engagement measures. These provide measurable writing-related outcomes of the LLM-mediated intervention.""
    }
}"
102,Understanding Efl Learners' Strategies in Ai-assisted English Writing: an Activity Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) learners, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates EFL learners’ strategies when using AI to assist writing, but there is no indication of an experimental or quasi-experimental design, nor explicit mention of a specific LLM (e.g., ChatGPT, GPT-4). It appears to be an exploratory, qualitative study of existing practices rather than an intervention study integrating LLMs.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on AI-assisted English writing processes and strategies during writing tasks, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Data sources are screenshots, chat logs, and semi-structured interviews, and the abstract reports strategies, usefulness, and concerns. There is no mention of quantifiable writing outcome metrics or measured changes in writing performance resulting from an AI-mediated intervention.""
    }
}"
103,Korean Efl Learners' Perceptions of Using Chatgpt for English Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Korean EFL (English as a foreign language) learners, so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, the design is exploratory and perception-focused. There is no indication of an experimental or quasi-experimental intervention design (e.g., no control/comparison group, no pre/post testing, no structured treatment conditions). The study centers on perceptions and types of feedback rather than testing an instructional intervention’s effectiveness.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly English writing: students compared their original writing with ChatGPT-edited versions and reflected on differences. The focus is on writing and feedback types, fitting the writing-competence context requirement.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports perceptions, engagement with feedback types, and questionnaire responses. It does not mention any quantifiable writing outcome metrics (e.g., scores, rubric-based improvements, accuracy measures) to assess effectiveness of the ChatGPT-mediated writing intervention.""
    }
}"
104,Assessing the Impact of Microsoft Copilot and Chatgpt on Efl Learners' Interactional Metadiscourse in Argumentative Writing,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Iranian English-as-a-foreign language (EFL) learners, i.e., L2 English learners in an EFL context. The focus is on English argumentative writing and interactional metadiscourse markers in that writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study compares ChatGPT-based instruction and Microsoft Copilot, both LLM-based chatbots, against a conventional control group. Learners received initial training on using these AI tools and then used them in practice sessions to identify and use IMMs in writing, indicating an experimental design integrating LLMs into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is argumentative writing, focusing on identifying and realizing interactional metadiscourse markers in learners’ writing. The intervention is pedagogical (instruction plus practice in writing with LLM support), not just system evaluation or automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative outcomes: posttest performance in identifying IMMs, analyzed via one-way ANCOVA, comparing ChatGPT, Copilot, and control groups. These are measurable writing-related outcomes tied to the intervention, alongside qualitative perceptions from interviews.""
    }
}"
105,The Role of Chatgpt in Enhancing Efl Students' Esp Writing Skills: an Experimental Study of Gender and Major Differences,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 117 university students learning ESP (English for Specific Purposes) writing, explicitly in an EFL context (EFL students in the title). The target language is English.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is an experimental study using ChatGPT as a self-directed learning tool. ChatGPT is a large language model integrated into the writing learning process, satisfying the LLM-based intervention requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on ESP writing skills. The intervention uses ChatGPT to enhance writing, and outcomes are writing-related (ESP writing skills and their dimensions), not just automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pre- and post-tests with statistical analyses (Wilcoxon signed-rank test and ANOVA) to measure improvements in writing skills across dimensions, providing quantifiable writing outcome metrics.""
    }
}"
106,Supporting 2e Bilingual Students with Motor Dysgraphia and Adhd in Writing: Efficacy and Acceptability of Human-ai Hybrid Tutoring,2025,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as “twice exceptional (2e) bilingual students,” but the abstract does not specify that they are L2 English learners in ESL/EFL/ELL contexts, nor that English is the target language being learned. Their bilingual status alone does not confirm they are L2 English learners in an English-learning context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention is “human-artificial intelligence (AI) hybrid tutoring,” but the abstract does not identify the AI system (e.g., ChatGPT, GPT-4) or clarify that it is an LLM-based, transformer generative model. It could involve other forms of AI or assistive technology not based on LLMs.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on improving writing skills, including handwriting fluency, orthographic coding, fine motor control, and composition skills. These are writing-related competencies within an instructional intervention, not automated essay scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative outcomes: post-tests showed significant improvements in handwriting fluency (speed and legibility), orthographic coding, fine motor control, and composition skills, providing measurable writing-related outcome metrics.""
    }
}"
107,Effectiveness of Generative Ai in Automated Written Corrective Feedback with Prompting,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions English writing instruction and an empirical study involving teachers and students, but it does not specify that the students are L2 English learners (ESL/EFL/ELL). Their language background and learner status are not described.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study evaluates GPT-4 and other GAI models as automated written corrective feedback (AWCF) tools and compares them to commercial tools. It focuses on model performance and system efficacy, not on an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or writing processes as a treatment condition.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the accuracy and consistency of GAI-based AWCF and user perceptions. While related to writing, it is essentially a tool performance and usability study rather than a structured writing competence intervention. It does not describe a designed instructional program or writing intervention using LLMs as part of teaching.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantitative results concern error detection and correction performance of models on datasets, not measured changes in learners’ writing outcomes after an LLM-mediated intervention. Qualitative feedback from participants is reported, but no experimental pre/post or comparative writing outcome metrics for learners are described.""
    }
}"
108,Artificial Intelligence as an Automated Essay Scoring Tool: a Focus on Chatgpt,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners at the B2 level writing essays in English, which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used solely as an Automated Essay Scoring (AES) tool to grade essays, not as part of an instructional or intervention design to support writing processes or instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the reliability and effectiveness of ChatGPT as an essay scoring system, comparing its scores with human raters. There is no pedagogical writing intervention or instructional context involving LLM use.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports scoring differences and correlations between human and ChatGPT ratings, but does not examine changes in learners’ writing performance or outcomes resulting from an LLM-mediated writing intervention.""
    }
}"
109,"Under the World of Ai-generated Feedback on Writing: Mirroring Motivation, Foreign Language Peace of Mind, Trait Emotional Intelligence, and Writing Development",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a Foreign Language (EFL) learners at the College of Languages, Nawroz University, in Iraq. The focus is on English writing proficiency, fitting ESL/EFL/ELL L2 English contexts.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract repeatedly refers to “AI-generated feedback” and “AI’s role in language education” but does not specify the AI system (e.g., ChatGPT, GPT-4) or whether it is an LLM-based, transformer generative model versus another type of AI feedback tool (e.g., rule-based, traditional NLP). Thus, it is unclear if an LLM is used.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is ‘online writing development with AI-generated feedback’ versus the same writing development without AI feedback. The primary pedagogical focus is on writing development and writing skills, with AI integrated into the writing instruction process.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pretest and posttest measures and reports that AI-generated feedback enhanced learners’ writing skills/writing proficiency, indicating quantifiable writing outcome metrics in a quasi-experimental design.""
    }
}"
110,Exploring Chatgpt as a Writing Assessment Tool,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are in an EFL context in Thailand, and the focus is on teaching English as a Foreign Language, so the population is L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study evaluates ChatGPT as an Automated Writing Evaluation (AWE) tool, comparing its ratings to human raters. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating ChatGPT into students’ writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on ChatGPT’s functionality and validity as an assessment/grading tool (AWE) rather than on a teaching or intervention context aimed at improving writing competence. It aligns with automated essay scoring research, which is excluded by the review criteria.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantitative analyses concern relationships between ChatGPT and human ratings, not pre/post or comparative writing performance outcomes from an LLM-mediated intervention. No experimental writing outcome metrics assessing effectiveness of ChatGPT-based instruction are reported.""
    }
}"
111,Exploring the Transformative Influence of Artificial Intelligence in Efl Context: a Comprehensive Bibliometric Analysis,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a bibliometric analysis of 3,300 documents on AI in EFL from 2013–2023. It does not report on a specific participant group of L2 English learners with primary data; instead, it synthesizes publication trends and contributors.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although it mentions AI tools such as ChatGPT, Grammarly, and Quillbot, the study itself is a bibliometric review and does not implement an experimental or quasi-experimental LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on mapping research trends in AI-enhanced language learning broadly, not on conducting or evaluating a specific pedagogical intervention targeting writing competence or related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study summarizes literature and trends rather than measuring the effectiveness of an LLM-mediated writing intervention.""
    }
}"
112,Chatgpt Affordances and Indonesian Efl Students' Perceptions in L2 Writing: a Collaborative Reflexive Thematic Analysis,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Indonesian EFL students, i.e., learners of English as a foreign language, so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study clearly involves ChatGPT, an LLM, in students’ EFL writing processes. However, the abstract does not specify an experimental or quasi-experimental design; it instead emphasizes exploration of affordances, prompts, and perceptions using qualitative methods (screen capture, interviews, thematic analysis). It is unclear whether there is a structured instructional intervention being tested versus purely observational use.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL writing: students’ use of ChatGPT in the writing process, essay quality (lexical resources, grammatical range and accuracy, coherence and cohesion), and writing-related affordances (brainstorming, outlining, idea development, feedback). This aligns with writing competence rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports that ChatGPT use ‘has the potential to improve their essay quality’ but does not mention any quantitative or experimental outcome measures (e.g., scores, pre/post tests, statistical comparisons). The methods are qualitative (screen capture, interviews, reflexive thematic analysis), focusing on perceptions and observed affordances rather than quantifiable writing outcomes.""
    }
}"
113,From Prompts to Plans: a Case Study of Pre-service Efl Teachers' Use of Generative Ai for Lesson Planning,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are pre-service EFL teachers in a South Korean university course, not L2 English learners in an ESL/EFL/ELL context whose own English writing development is being measured. The focus is on teacher education and lesson planning, not learner writing outcomes.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions “generative AI tools” but does not specify whether these are large language models such as ChatGPT or GPT-4. However, even if they are LLMs, they are used for lesson planning support, not as a writing intervention for L2 learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on lesson planning, topic selection, material creation, and lesson organization by pre-service teachers. Writing competence or writing-related variables of L2 learners are not the central outcome; the study concerns pedagogical planning practices.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study uses thematic analysis of how PSTs use generative AI and discusses efficiency, creativity, and pedagogical challenges, without experimental measures of writing performance.""
    }
}"
114,"Digital Plagiarism in Efl Education during the Ai Era: a Comparative Study of Perceptions among Learners and Instructors in Korea, Mongolia, and China",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL education in Korea, Mongolia, and China, implying participants are L2 English learners and their instructors in EFL settings.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines perceptions of digital plagiarism and AI usage via scenario-based survey items. There is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is academic integrity and perceptions of digital plagiarism in the AI era, not on writing competence or writing-related skill development. L2 writing is mentioned only as a context where integrity issues arise, not as the main instructional focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are perceptions measured via survey items about plagiarism and AI use. No quantifiable writing performance or writing-related outcome metrics are reported to assess an LLM-mediated writing intervention.""
    }
}"
115,"Factors Influencing Bangladeshi English Teachers' Perceptions of Academic Policy, Academic Culture and Knowledge Related to Plagiarism in Higher Education",2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are English teachers at tertiary level in Bangladesh, not L2 English learners in ESL/EFL/ELL contexts. The focus is on teachers’ perceptions of plagiarism, not on learner data or learner writing development.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study discusses concerns about AI-based plagiarism and misuse of AI tools, but there is no experimental or quasi-experimental integration of LLMs (e.g., ChatGPT) into writing instruction or processes. AI appears only as a topic of concern, not as an instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is academic integrity, plagiarism policies, and institutional factors, not on writing competence or writing-related pedagogical interventions. Writing courses are mentioned only as contextual factors, not as an intervention under study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes concern perceptions of plagiarism and factors influencing these perceptions, not changes in learners’ writing performance following an LLM-mediated intervention.""
    }
}"
116,Integrating Corpus-based Methods to Determine Grammatical Topics for Teaching English Writing in the Thai Context,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Thai university students learning English writing, i.e., EFL learners in a non-English-speaking context, with a clear focus on English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used to improve students’ essays to create a refined corpus for analysis, not as part of an instructional intervention or experimental/quasi-experimental teaching design. There is no indication of LLM-mediated teaching or comparison of instructional conditions.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on corpus-based identification of grammatical topics for teaching, not on evaluating a writing intervention. ChatGPT is a tool to generate refined texts for linguistic analysis, not to support learners’ writing processes pedagogically.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports corpus-derived grammatical features and needs analysis, but does not report quantifiable writing outcome measures (e.g., pre/post writing scores, accuracy gains) resulting from an LLM-mediated intervention.""
    }
}"
117,Integration of Artificial Intelligence (ai) in Learning English Writing in Higher Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses AI in learning English writing in higher education but does not specify that the participants are L2 English learners in ESL/EFL/ELL contexts, nor does it describe any concrete participant group since it is a conceptual paper.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a conceptual paper that applies a conceptual approach exploring literature. It does not report an experimental or quasi-experimental design, nor a specific LLM-based intervention (e.g., ChatGPT, GPT-4) implemented with learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus is on AI integration in English writing, the paper is conceptual and does not describe an implemented pedagogical intervention or instructional context with measurable outcomes; it instead discusses concepts, acceptance, and expectations.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract indicates no empirical data or quantifiable writing outcome metrics. It is a conceptual analysis and literature-based discussion without experimental measures of writing performance.""
    }
}"
118,Transforming Ai Chatbots for a Brainstorming Teaching Technique of Process Writing,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are third-year Thai university students working with foreign English lecturers, indicating an EFL context with English as the target language. The study explicitly concerns English writing instruction and outcomes.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses AI chatbots for brainstorming in process writing, with ChatGPT identified as the most popular tool. ChatGPT is a large language model, and the design compares an intervention group using AI tools with a conventional group, indicating an experimental/quasi-experimental intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is process writing instruction and students’ writing outcomes. AI chatbots are integrated as brainstorming tools within the writing process, focusing on writing competence rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: the intervention group significantly outperformed the conventional group on two of three assignments, with p-values reported (People: p = 0.002; Things: p < 0.001). These are measurable writing performance metrics resulting from the LLM-mediated intervention.""
    }
}"
119,"Comparing Teacher E-feedback, Ai Feedback, and Hybrid Feedback in Enhancing Efl Writing Skills",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 'Iranian intermediate-level EFL learners,' indicating L2 English learners in an EFL context with a focus on English writing skills.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention includes 'AI-generated feedback using tools such as ChatGPT and Grammarly.' ChatGPT is a large language model integrated into the writing feedback process within a randomized controlled trial, satisfying the LLM-based intervention requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on 'enhancing the writing performance' and 'writing skills' of EFL learners via different feedback approaches. It is a pedagogical intervention in writing, not an automated scoring or purely functional evaluation of the AI.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing proficiency was measured pre- and post-intervention using IELTS writing tasks and the Oxford Placement Test, with reported quantitative outcomes such as improvements in 'task achievement, coherence, and grammatical accuracy' and 'lexical resources.' These are clear, quantifiable writing outcome metrics.""
    }
}"
120,Exploring Potential Biases in Gpt-4o's Ratings of English Language Learners' Essays,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses the ELLIPSE corpus (English Language Learner Insight, Proficiency and Skills Evaluation), which consists of essays written by English language learners, indicating an L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""GPT-4o is used as an automated essay scoring (AES) tool to rate existing essays. There is no experimental or quasi-experimental instructional intervention integrating LLMs into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on GPT-4o’s fairness and bias as an AES system (gender, race/ethnicity, SES), not on improving learners’ writing competence or implementing a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No writing outcome metrics are reported as a result of an LLM-mediated intervention. The study analyzes rating bias across demographic groups, not changes in learners’ writing performance following LLM use.""
    }
}"
121,Do Ai-generative Tools Kill or Nurture Creativity in Efl Teaching and Learning?,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are EFL undergraduates in an English as a Foreign Language learning context, clearly fitting the target population of L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study involves AI-generative tools such as ChatGPT, it uses a descriptive-survey design to explore students’ perspectives. There is no experimental or quasi-experimental intervention integrating LLMs into instruction or writing processes; rather, it is a perception-based survey and interviews.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing is mentioned among several uses (conversation practice, idea generation, feedback on writing, vocabulary building, collaborative learning), but the primary focus is creativity in EFL education broadly, not specifically writing competence or writing-related variables as the central outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports students’ perceptions via questionnaires and interviews, with no quantifiable writing outcome metrics or measured changes in writing performance. It is not an intervention study assessing writing outcomes.""
    }
}"
122,Ai Tools for Writing: a Q-method Study with Turkish Instructors of English,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study concerns Turkish learners of English and their writing skill development, which fits L2 English learners in an EFL context, even though the direct participants are instructors.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a Q-methodological investigation of instructors’ perspectives on AI tools. It does not describe an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly about the use of AI tools for students’ writing skill development and writing improvement, which aligns with writing competence as the primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports instructors’ perspectives and ethical concerns, using Q-methodology and interviews. There is no indication of quantifiable writing outcome metrics or measured effects of an AI/LLM-mediated writing intervention.""
    }
}"
123,Chatgpt-3.5 as an Automatic Scoring System and Feedback Provider in Ielts Exams,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions IELTS essay preparation and second language writing, implying L2 English learners, but it does not explicitly describe the participant population or learner context (ESL/EFL/ELL). It also appears to use pre-rated essays from a book rather than data from identified learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines ChatGPT-3.5 as an Automatic Essay Scoring (AES) system and feedback provider, focusing on score alignment with official examiners and on the strategies ChatGPT uses to revise essays. There is no experimental or quasi-experimental pedagogical intervention integrating ChatGPT into learners’ writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on ChatGPT’s reliability as an AES and its revision strategies, not on a teaching/learning context or structured writing instruction. It evaluates tool functionality rather than an LLM-mediated writing intervention with learners.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes or pre/post intervention measures are reported. The study uses pre-rated essays from an IELTS preparatory book and compares ChatGPT scores to official scores, without assessing changes in learners’ writing performance following an LLM-based intervention.""
    }
}"
124,Ai-generated Feedback in English Writing Instruction for Language Learners: a Systematic Review,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to 'language learners' in English writing instruction but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts. As a systematic review, it may include mixed or unspecified populations.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a systematic review of 22 studies on generative AI feedback (primarily ChatGPT). Review articles are to be excluded according to the protocol, which requires primary experimental or quasi-experimental studies.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on AI-generated feedback in English writing instruction, including types of feedback and its effectiveness relative to teacher and peer feedback, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions examining the effectiveness of AI feedback and perceptions but does not specify whether the included primary studies report quantifiable writing outcome metrics; as a review, it aggregates prior work rather than reporting its own experimental outcomes.""
    }
}"
125,Digital Tools and Writing Education: a Thematic Analysis of Technology's Role in Writing Skills Development,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a systematic review including diverse groups of learners (EFL students and those with dyslexia, among others). It does not focus specifically on L2 English learners, and the population is not an empirical sample but aggregated literature, which falls outside the inclusion criteria for primary studies.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a systematic review and thematic analysis of 40 articles on digital tools, including AI-based feedback systems. It does not itself implement or test an LLM-based intervention (e.g., ChatGPT, GPT-4) in an experimental or quasi-experimental design.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus is broadly on writing skills (including higher-order skills like creativity and critical thinking), the article is a review of various technologies and environments rather than a primary pedagogical intervention study targeting writing competence in a specific learner group.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic review, the study does not report its own experimental or quasi-experimental writing outcome metrics. It synthesizes themes from prior work rather than providing quantifiable outcome data from an LLM-mediated writing intervention.""
    }
}"
126,Integrating Automated Writing Evaluation into Saudi Efl Students' Writing Practice,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 154 Arabic-speaking EFL undergraduate students at a Saudi university, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is an Automated Writing Evaluation (AWE) system. The abstract does not indicate that it is an LLM-based tool (e.g., ChatGPT, GPT-4). AWE here appears as a general feedback system, not explicitly a transformer-based generative LLM, so it does not meet the LLM integration requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on integrating AWE into EFL writing practice and discusses enhancement of writing skills, critical thinking, autonomy, and motivation to write in English. The primary context is writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions writing assignments before and after using the AWE system, but it does not state that quantifiable writing outcome metrics were analyzed; the emphasis is on experiences, evaluations, challenges, satisfaction, and perceived effectiveness. It is unclear whether objective writing scores or measurable gains were reported.""
    }
}"
127,Interacting with Chatgpt in Essay Writing: a Study of L2 Learners' Task Motivation,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are L2 learners writing English argumentative essays at a public university in a non-English-speaking country, which fits ESL/EFL/ELL-type L2 English contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT 4.0 (an LLM) as a tutor and writing support tool within an experimental, AI-enhanced intervention for L2 essay writing.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly L2 English argumentative essay writing, with ChatGPT integrated into the essay-writing process and instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract states the study examined effects on learners' motivation to write and reports motivational outcomes (including delayed post-intervention motivation). It does not indicate any quantifiable writing performance or competence measures; perceived improvement in writing is only self-reported and tied to motivation. Thus, no clear quantitative writing outcome metrics are reported.""
    }
}"
128,Enhancing or Impairing? Exploring Indian Efl Learners' Academic Writing Narratives with Chatgpt,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Indian English as a Foreign Language (EFL) learners, which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study concerns learners’ use of ChatGPT, it is not an experimental or quasi-experimental intervention. Learners had already been using ChatGPT informally for over a year, and the study explores their use and perceptions rather than implementing or testing a structured LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on academic writing, including writing fluency, confidence, and cognitive engagement, which are writing-related variables within an L2 context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study employs a qualitative design using semi-structured interviews and thematic analysis, reporting perceptions and themes (e.g., motivation, anxiety, over-reliance). There is no indication of quantifiable writing outcome metrics or experimental measures of writing performance.""
    }
}"
129,Ai-based Assessment of Students' Writing Skill Progress: Implementing Artificial Neural Network Modeling Vs. Time Series Prediction,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract refers to students’ progress in second language (L2) writing skills and emphasizes application in English language learning, indicating an L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study evaluates AI-based prediction models (Artificial Neural Networks and time series methods) to assess writing progress. There is no indication that a large language model (e.g., ChatGPT, GPT-4) is integrated into writing instruction or writing processes; the AI is used for prediction/assessment, not as an LLM-based pedagogical intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on modeling and predicting students’ writing skill development using ANN vs. time series, i.e., assessment/forecasting accuracy. It does not describe an instructional or pedagogical writing intervention mediated by an LLM; rather, it is an AI-based assessment study.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""While writing pretests, periodic tests, and posttests are mentioned, the reported outcomes focus on model performance metrics (MAE, RMSE, R²) rather than quantifying the effect of an AI-mediated writing intervention. It is unclear whether structured intervention outcomes on writing quality are analyzed beyond being inputs for prediction models.""
    }
}"
130,An Ai-assisted Critical Thinking Intervention to Enhance Undergraduate Efl Learners' Writing Proficiency,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 250 undergraduate EFL learners from three public universities, indicating L2 English learners in an EFL context with a focus on English writing proficiency.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines an AI-assisted critical thinking-oriented writing intervention supported with ChatGPT. ChatGPT is a large language model, and it is integrated as a scaffolding tool within the writing instruction, using a pretest–posttest experimental design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing proficiency and CT as reflected in writing. The intervention is explicitly a CT-oriented writing intervention, and outcomes are based on writing tests evaluated across nine dimensions related to writing quality.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantifiable writing outcomes are reported via pre- and post-writing tests for 250 students, evaluated on nine dimensions (clarity, accuracy, precision, relevance, depth, breadth, logic, significance, fairness). The abstract reports significant enhancement in CT reflected in writing, indicating measured writing-related gains.""
    }
}"
131,Factors Affecting Efl Students' Behavioral Intention to Use Ai in Efl Writing Development,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 415 Chinese university students using AI for English as a Foreign Language (EFL) writing development, clearly an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a cross-sectional survey on behavioral intention to adopt AI, grounded in UTAUT. There is no experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes; it only measures acceptance factors.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is EFL writing development, the primary focus is technology acceptance (behavioral intention, attitude, expectancy) rather than a pedagogical writing intervention or instructional use of LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes are psychological/behavioral (intention, attitude, expectancy) rather than measures of writing competence or performance following an AI-mediated intervention.""
    }
}"
132,Students' Self-determination in Using Machine Translation and Generative Ai Tools for English for Academic Purposes,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EAP students in an ESL context (Australia) and an EFL context (Vietnam), focusing on academic writing in English. This matches the target population of L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study involves students’ use of MT and generative AI tools, it does not describe an experimental or quasi-experimental intervention integrating LLMs into writing instruction. It focuses on motivations and self-determination in existing use, not on a structured LLM-based instructional treatment with control/comparison.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context is academic writing (EAP) and MT/GAI-assisted academic writing, which is writing-related. However, the primary focus is on motivational constructs (autonomy, competence, relatedness) and contextual perceptions rather than on writing competence as an outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports survey and interview data on motivational variables and perceptions, analyzed via CFA and mixed-effects regression. There is no indication of quantifiable writing performance outcomes (e.g., writing scores, text quality measures) used to assess the effectiveness of MT/GAI-mediated writing interventions.""
    }
}"
133,Artificial Intelligence as a Catalyst for Overcoming Barriers to English Language Learning in Higher Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract focuses on dyslexic students in English as a Second Language (ESL) classrooms in higher education, clearly indicating L2 English learners in an ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study discusses AI broadly (speech recognition, NLP, adaptive learning platforms) and examines case studies, but there is no indication that large language models (e.g., ChatGPT, GPT-4) are used, nor that there is an experimental or quasi-experimental intervention design. It appears to be a critical evaluation/review of AI applications rather than an LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions difficulties with reading, comprehension, and written expression and refers generally to fostering language proficiency and academic achievement. However, it does not specify that the primary focus is on writing competence or writing-related variables; it seems to address overall ESL learning and support for dyslexic learners.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""There is no mention of experimental measures, quantifiable writing outcomes, or structured intervention results. The study appears to be a critical evaluation and discussion of AI tools and case studies, not a study reporting quantitative writing outcome metrics.""
    }
}"
134,Enhancing Efl Writing Skills for Adult Deaf and Hard of Hearing Individuals,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as Deaf and hard of hearing (D/HH) learners developing English as a Foreign Language (EFL) writing skills during EU-funded summer schools. This fits L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract notes use of internet tools including Google Translate, ChatGPT, and online dictionaries, but does not specify an experimental or quasi-experimental design, nor a structured LLM-based instructional intervention. ChatGPT appears as one of several tools used, with no clear indication of a controlled LLM-focused intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on developing EFL writing skills and how tools affect writing quality, coherence, and confidence. This aligns with a primary focus on writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are reported as participants’ perceptions that tools improved vocabulary, grammar, coherence, and confidence, and as qualitative descriptions of strategies. There is no indication of quantifiable writing outcome metrics or experimental measures; the study appears primarily qualitative and perception-based.""
    }
}"
135,The Effects of Chatgpt-generated Feedback on Saudi Efl Learners' Writing Skills and Perception at the Tertiary Level: a Mixed-methods Study,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Saudi EFL (English as a Foreign Language) university students, i.e., L2 English learners in an EFL context. The focus is on English academic writing skills.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses ChatGPT, a generative AI large language model, to provide feedback on students’ writing. The design is experimental (pretest–posttest control group) comparing ChatGPT-generated feedback (experimental) with teacher-generated feedback (control).""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence: the study examines the effects of ChatGPT-generated feedback on EFL learners’ writing skills and their perceptions in an academic writing context, not on automated scoring or system evaluation alone.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative writing outcomes are reported: pretests and posttests of writing skills analyzed via ANCOVA to compare posttest scores between groups. These provide measurable writing outcome metrics for the LLM-mediated intervention.""
    }
}"
136,"A Mixed-methods Study on the Use of Chatgpt in the Pre-writing Stage: Efl Learners' Utilization Patterns, Affective Engagement, and Writing Performance",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a Foreign Language (EFL) learners: 56 first-year university students performing argumentative writing tasks in an EFL context, with outcomes focused on English writing performance.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses ChatGPT, a large language model, as support in the pre-writing stage. The design is quasi-experimental: each learner completes two argumentative writing tasks, one with and one without ChatGPT support, enabling comparison of conditions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence and related variables: pre-writing strategy use, affective engagement during planning, and subsequent writing performance (text quality). ChatGPT is integrated pedagogically into the writing process rather than used solely for automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: it compares text quality and overall writing performance between ChatGPT and non-ChatGPT conditions and examines correlations between affective engagement and writing performance, satisfying the requirement for measurable writing outcomes.""
    }
}"
137,Predicting Kazakhstani Tefl Students' Continuance Intention towards Using Chatgpt in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are TEFL (Teaching English as a Foreign Language) students at two Kazakhstani universities, i.e., L2 English learners in an EFL context, and the focus is on academic writing in English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines perceptions and continuance intention toward using ChatGPT via a survey-based model (perceived usefulness, ease of use, satisfaction, continuance intention). There is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is academic writing, the primary focus is on technology acceptance (perceptions, satisfaction, continuance intention), not on a pedagogical writing intervention or systematic use of ChatGPT to develop writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports attitudinal and intention constructs (perceived usefulness, ease of use, satisfaction, continuance intention) and qualitative perceptions. It does not report quantifiable writing performance outcomes or writing-related competence measures resulting from an LLM-mediated intervention.""
    }
}"
138,Probing Language Teachers' Complaints about Chatgpt and Genai Tools: a Social Media Dataset Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on language teachers’ reactions and complaints about ChatGPT and GenAI tools using social media data. There is no indication that participants are L2 English learners in ESL/EFL/ELL contexts, nor that learner data are analyzed.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT and GenAI tools are mentioned, they are the topic of discussion, not part of an experimental or quasi-experimental pedagogical intervention. The study is an interpretive analysis of teachers’ social media posts, not an LLM-mediated instructional design.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on perceived negative impacts of GenAI on language education, academic integrity, and trust, not on writing competence or writing-related variables. No specific writing instruction or writing process is targeted.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is qualitative, based on Facebook posts and comment threads, and does not report quantifiable writing outcome metrics or measure the effectiveness of any LLM-mediated writing intervention.""
    }
}"
139,Metacognitive Awareness and Efl Learners' Perceptions and Experiences in Utilising Chatgpt for Writing Feedback,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 40 EFL undergraduates in a semester-long writing course, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study investigates EFL students’ use of ChatGPT (an LLM) to seek feedback for writing within a course, which constitutes an LLM-mediated writing-related intervention, even though it is more exploratory than tightly controlled.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on perceptions, experiences, and metacognitive awareness in using ChatGPT for writing feedback (motivation, engagement, self-efficacy, collaborative tendency). It does not focus on writing competence or writing-related performance outcomes; rather, it examines affective and cognitive variables around tool use.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports quantitative differences in perceptions and experiences (motivation, engagement, self-efficacy, collaborative writing tendency) and correlations with metacognitive awareness, but does not mention any quantifiable writing performance outcomes (e.g., writing scores, quality measures, accuracy). Thus, no experimental measure of writing improvement is reported.""
    }
}"
140,Students' Appraisals Post-chatgpt Use: Students' Narrative after Using Chatgpt for Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 'students learning English as a Foreign Language,' indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study involves students who 'utilised ChatGPT in academic writing classes' and explores ChatGPT as scaffolding for essay writing. ChatGPT is an LLM-based tool, satisfying the intervention criterion, though the design is qualitative rather than experimental.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on using ChatGPT for 'writing essays' and benefits such as 'writing accuracy, writing efficiency, idea generation,' which are clearly writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract states that data come from semi-structured interviews and reports students’ experiences, advantages, and criticisms. There is no mention of experimental or quasi-experimental measures, nor any quantifiable writing outcome metrics; the study is purely qualitative perception-based.""
    }
}"
141,'what' Is the Machine? Teachers' Professional Learning about Generative Artificial Intelligence as Tutors for Children,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions teachers and children in school settings but does not specify that the children are L2 English learners (ESL/EFL/ELL) or that the focus is on English language learning. The population and language-learning context are not defined.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as a critical posthuman analysis of a professional learning scenario about GenAI. It does not indicate an experimental or quasi-experimental design, nor an implemented GenAI/LLM-based tutoring or writing intervention; rather, it critiques discourses around GenAI adoption.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on teachers’ professional learning and critical perspectives on GenAI as tutors for children, not on writing competence or writing-related variables. No mention is made of writing instruction, writing processes, or writing skills as a primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""There is no indication of any quantitative writing outcome measures or assessment of writing performance. The work is conceptual/critical, discussing encounters and implications rather than reporting intervention outcomes.""
    }
}"
142,University Students' Perceptions of Ai-assisted Writing Tools in Supporting Self-regulated Writing Practices,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students at an Islamic-based university in East Java, Indonesia, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to 'AI-assisted writing tools' and 'AI applications' (grammar checking, spelling correction, paraphrasing, translation). It does not specify that these are LLM-based tools (e.g., ChatGPT, GPT-4) or transformer-based generative models, and could refer to traditional non-LLM tools like Grammarly or machine translation. No explicit LLM integration or experimental/quasi-experimental design is described.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on students' perceptions of AI tools in supporting self-regulated writing strategies (planning, monitoring, evaluation), not on a structured pedagogical intervention to improve writing competence. It is a qualitative case study about perceptions and use, not an intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative perceptions and concerns but does not mention any quantifiable writing outcome metrics or experimental measures of writing performance. There is no assessment of effectiveness of an AI/LLM-mediated writing intervention.""
    }
}"
143,Ai-based Assessment of Students’ Writing Skill Progress: Implementing “artificial Neural Network Modeling” Vs. “time Series Prediction”,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to 'second language (L2) writing skills' and 'English language learning and assessment', but does not explicitly state that participants are L2 English learners in ESL/EFL/ELL contexts. The target language is likely English but not definitively specified.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study evaluates AI-based prediction models (Artificial Neural Networks vs. time series) to assess students’ writing progress. There is no indication that a large language model (e.g., ChatGPT, GPT-4) is integrated into writing instruction or writing processes; instead, AI is used for predictive assessment of scores.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on modeling and predicting writing skill development using ANN and time series methods, i.e., an assessment/analytics task. There is no described pedagogical writing intervention using an LLM; the AI is not used as an instructional tool but as an assessment/prediction mechanism.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing test scores and error metrics (MAE, RMSE, R²) are reported, these are used to evaluate prediction model accuracy, not to assess the effectiveness of an LLM-mediated writing intervention. No LLM-based instructional treatment or its impact on writing outcomes is examined.""
    }
}"
144,‘critical Chatting’ or ‘casual Cheating’: How Graduate Efl Students Utilize Chatgpt for Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are four graduate EFL students, clearly indicating L2 English learners in an EFL context, and the focus is on their academic writing in English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the study is described as a qualitative case study exploring how students utilize ChatGPT, not as an experimental or quasi-experimental intervention in writing instruction. There is no indication of a structured LLM-mediated instructional treatment being tested for effectiveness.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context is academic writing and ChatGPT-assisted writing, but the primary focus is on purposes, rationales, and critical thinking rather than on systematically improving writing competence through an instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports a qualitative thematic analysis of how students use ChatGPT and how critical thinking is embedded. It does not mention any quantifiable writing outcome metrics or experimental measures of writing performance.""
    }
}"
145,Navigating Ai Writing Tools in Medical Education: a Swot Analysis of L2 Academic Writing Perspectives,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 42 medical students in Iran engaged in an L2 academic writing course, indicating they are L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines perspectives on using unspecified ‘AI writing tools’ via SWOT and reflections. There is no indication that the tools are specifically LLM-based (e.g., ChatGPT, GPT-4) nor that there is an experimental or quasi-experimental design integrating a particular LLM into instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on L2 academic writing in medical education and on integrating AI writing tools into L2 writing instruction, which aligns with a writing competence context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses weekly reflections, SWOT analysis, and thematic analysis of perceptions. No quantifiable writing outcome metrics or experimental measures of writing performance are reported.""
    }
}"
146,Leveraging Open-source Large Language Models for Native Language Identification,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the data involve L2 writing used for native language identification, the participants are not described as L2 English learners in ESL/EFL/ELL instructional contexts; the focus is on NLI as an NLP task, not on a defined learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""LLMs are used as classifiers for native language identification (zero-shot and fine-tuned) rather than as part of an instructional or quasi-experimental pedagogical intervention in writing.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is NLI model performance (forensics/marketing/SLA applications) rather than improving writing competence or writing-related pedagogical outcomes. There is no writing instruction or intervention context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports accuracy of NLI classification, not quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) resulting from an LLM-mediated writing intervention.""
    }
}"
147,Modeling Chinese Efl Learners' Intention to Use Generative Ai for L2 Writing through an Integrated Model of the Tam and Ttf,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese EFL learners (304 university students in China) using generative AI for L2 English writing, clearly fitting an EFL/ELL English-learning context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a survey and structural equation modeling to examine intention to use generative AI. There is no experimental or quasi-experimental pedagogical intervention integrating an LLM into actual writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on technology acceptance (TAM, TTF) and behavioral intention, not on implementing or evaluating a concrete writing intervention. It is about attitudes toward potential use, not an instructional context measuring writing competence changes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes are psychological/behavioral constructs (perceived usefulness, ease of use, attitude, intention), not measures of writing performance or related writing skills.""
    }
}"
148,The Effects of Generative Ai Usage in Efl Classrooms on the L2 Motivational Self System,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Japanese university students in an EFL context, i.e., L2 English learners in an English language classroom.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study integrates the generative pre-trained AI chatbot ChatGPT into an instructor-led writing class, with a control and treatment group, indicating an experimental design using an LLM in instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is situated in a writing class; the treatment group participated in writing workshops, collaborated, and received feedback from ChatGPT, indicating a primary focus on writing instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes measured are motivational constructs (Ideal L2 Self, Ought-to L2 Self, L2 Learning Experience) via questionnaires. Although the abstract mentions potential for enhancing writing skills, it does not report any quantifiable writing performance metrics or writing-related outcome measures.""
    }
}"
149,"An Ai Chatbot for Efl Writing: Students' Usage Tendencies, Writing Performance, and Perceptions",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL high school students in Northern Vietnam, clearly L2 English learners in an EFL context: “EFL students at a high school in Northern Vietnam…”.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention is an “AI chatbot designed to support their writing practice at home” (Writing Assistant Bot, WAB). However, the abstract does not specify whether WAB is a large language model (e.g., transformer-based generative model like ChatGPT/GPT-4) or a rule-based / non-LLM AI tool. Without this information, it is unclear if it meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL writing: the chatbot supports “writing practice,” and outcomes include “writing performance across all aspects: content, organization, vocabulary, language use, and mechanics.” The focus is on writing competence, not on automated scoring or system evaluation alone.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: “The chatbot significantly enhanced writing performance across all aspects: content, organization, vocabulary, language use, and mechanics, for both levels.” Timed-writing tests and performance scores indicate measurable intervention effects.""
    }
}"
150,Fostering Transparency: a Critical Introduction of Generative Ai in Students' Assignments,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions 'language learners in two Swiss universities' and 'L2 writing', but does not explicitly state that the target language is English (it could be any L2). Thus, it is unclear whether participants are L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students could use GenAI tools (e.g., ChatGPT) in their written assignments, the study focuses on a transparency protocol and students’ reporting of tool use, not on an experimental or quasi-experimental LLM-based writing instruction or structured LLM-mediated intervention. The design is action research about disclosure rather than a controlled LLM writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on transparency, trustworthiness, and preserving take-home written assignments in the GenAI era, not on systematically improving writing competence or writing-related skills through LLM-based pedagogy. Writing is the context, but not the main outcome variable of an instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports questionnaire data on use, attitudes, and transparency, and insights into students’ use of GenAI, but does not indicate any quantifiable writing outcome metrics (e.g., writing scores, quality measures) to assess effectiveness of an LLM-mediated writing intervention.""
    }
}"
151,Generative Artificial Intelligence (gen-ai) in Undergraduate Literature Courses,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions 'undergraduate literature courses' and 'language educators' but does not specify that participants are L2 English learners (ESL/EFL/ELL). They could be native or mixed-proficiency literature students; the L2 status and English-learning focus are not explicit.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study describes activities using OpenAI's ChatGPT 3.5 (a large language model) in literature courses, with structured tasks involving interpretive reading and presentational writing based on Gen-AI generated synopses and Gen-AI-supported compositional tasks. This fits an instructional integration of an LLM.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on undergraduate literature courses using Don Quixote as a referent. While 'presentational writing' and 'analytical essays' are mentioned, the primary aim appears to be literary interpretation and Gen-AI engagement models, not explicitly improving writing competence or writing-related variables as a central outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes activities (analytical essays, presentational writing, conference-style speaking) but does not indicate any experimental or quasi-experimental design, nor any quantifiable writing outcome metrics to assess the effectiveness of the Gen-AI-mediated writing intervention. It appears to be a pedagogical description without measured outcomes.""
    }
}"
152,Utilizing Large Language Models for Efl Essay Grading: an Examination of Reliability and Validity in Rubric-based Assessments,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are English as a foreign language (EFL) students whose essays are being graded, and EFL instructors are raters. The context is clearly L2 English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""LLMs (ChatGPT, Bard) are used solely as automated graders to evaluate essays. There is no experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the reliability and validity of LLMs for rubric-based essay grading, not on improving learners’ writing competence or writing-related learning outcomes through instructional use of LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports reliability metrics (ICC scores) for grading but does not report any quantifiable writing outcome measures resulting from an LLM-mediated writing intervention. No pre/post or comparative writing performance data are presented.""
    }
}"
153,Revolutionising Essay Evaluation: a Cutting-edge Rubric for Ai-assisted Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are in English as a Foreign Language (EFL) contexts and wrote AI-assisted essays in English, satisfying the L2 English learner population requirement.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT and Claude (LLMs) are mentioned, they are used as evaluators of essays, not as part of an instructional or experimental writing intervention aimed at improving learners’ writing. The focus is rubric development and AI-based assessment, not LLM-mediated instruction or process support.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on developing and validating a rubric and examining AI tools’ assessment capabilities (inter-rater reliability, convergent validity), not on writing competence or pedagogical intervention. This aligns with automated essay scoring/assessment research, which is to be excluded.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported to assess the effectiveness of an LLM-mediated writing intervention. The quantitative results concern rubric reliability/validity and consistency of AI scoring, not changes in learners’ writing performance due to LLM use.""
    }
}"
154,Incorporating Chatgpt for Efl Writing and Its Effects on Writing Engagement,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are first-year undergraduates in China in an English as a Foreign Language (EFL) writing class, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The treatment group used ChatGPT with designed prompts to receive feedback on their writing, compared to a control group receiving peer feedback. This is an experimental design integrating an LLM into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is an EFL writing class, and ChatGPT is used to provide feedback on students’ writing. The focus is on writing engagement within a writing course, which is a writing-related variable.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports outcomes only on affective, behavioral, and cognitive engagement via surveys. There is no mention of quantifiable writing performance or competence measures (e.g., writing scores, quality ratings), so it does not meet the requirement for writing outcome metrics.""
    }
}"
155,The Impact of Ai-assisted Blended Learning on Writing Efficacy and Resilience,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as lower intermediate English as a foreign language learners, which fits EFL L2 English learners in an English-focused context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that the experimental group used ‘AI tools’ that provided personalized feedback, but it does not specify whether these are large language model–based tools (e.g., ChatGPT, GPT-4) or other non-LLM AI (e.g., grammar checkers). Without explicit mention of LLMs or transformer-based generative models, it is unclear if the intervention meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is writing instruction: the study focuses on writing self-efficacy, resilience, linguistic accuracy, and writing development in an AI-assisted blended learning environment, not on automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental design comparing an AI-assisted group with a traditional instruction group and reports quantifiable outcomes such as linguistic accuracy, performance self-efficacy, and resilience, indicating measurable writing-related outcomes.""
    }
}"
156,Effectiveness and Moderating Factors of Computer-mediated Feedback in L2 Writing: a Meta-analysis,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states that the meta-analysis focuses on EFL and ESL contexts and L2 learners’ writing performance, indicating participants are L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a meta-analysis of computer-mediated feedback (CMF) and does not describe an original experimental or quasi-experimental intervention integrating specific LLMs (e.g., ChatGPT, GPT-4). It synthesizes prior CMF studies, which may or may not involve LLMs, but this article itself is a review, not an LLM-based intervention study.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 writing performance and how CMF affects writing development, clearly centering on writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the meta-analysis reports quantitative writing outcomes (effect sizes), the inclusion criteria require primary studies with LLM-mediated interventions. As a meta-analysis/review article, it does not itself report original experimental outcomes of an LLM-based writing intervention.""
    }
}"
157,Transforming Efl Teaching with Ai: a Systematic Review of Empirical Studies,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The population is broadly described as school-based EFL learners, which likely includes L2 English learners in EFL contexts. However, as this is a systematic review aggregating multiple studies, the specific participant populations are not detailed in the abstract.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly a systematic review of empirical studies on AI in EFL teaching, not an original experimental or quasi-experimental study implementing a specific LLM-based intervention. It synthesizes prior work rather than reporting a new LLM-integrated writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on AI in EFL teaching across multiple skills (reading, writing, listening, speaking, vocabulary, comprehension). Writing is only one of several skills and not the primary focus of a specific intervention; the paper is a broad review of AI in EFL education rather than a targeted writing competence intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic review, it does not report original, study-level quantitative writing outcome metrics from a specific LLM-mediated intervention. It summarizes improvements across skills but does not present new experimental measures or structured intervention outcomes for writing attributable to a particular LLM tool.""
    }
}"
158,Integrating Ai: Challenges and Opportunities in Teaching English Writing Skills,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract focuses on students learning English as a second or foreign language in the Arab world, with data from English language instructors at universities in KSA and UAE. This aligns with L2 English learners in EFL/ESL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although AI tools like ChatGPT are mentioned, the study is a qualitative exploration of instructors’ perceptions, challenges, and opportunities. There is no indication of an experimental or quasi-experimental design integrating LLMs into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The title and abstract mention teaching English writing skills and concerns about students’ skills development, but the focus is on general AI use in teaching and ethical issues, not a specific, structured writing intervention or measured writing competence outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is based on qualitative interviews and discusses perceptions, challenges, and recommendations. It does not report quantifiable writing outcome metrics or experimental measures of LLM-mediated writing interventions.""
    }
}"
159,Chatgpt Affordances and Indonesian Efl Students’ Perceptions in L2 Writing: a Collaborative Reflexive Thematic Analysis,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Indonesian EFL students, clearly indicating L2 English learners in an EFL context, and the focus is on EFL writing in English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, the study is exploratory and observational, using screen capture and interviews to examine affordances and perceptions. There is no mention of an experimental or quasi-experimental design or structured pedagogical intervention integrating ChatGPT into instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL writing, specifically essay quality and writing processes (brainstorming, outlining, idea development, feedback on hedging devices), which are writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports perceived potential improvements and qualitative findings but does not indicate any quantifiable writing outcome metrics or experimental measures (e.g., pre/post tests, rubric scores) to assess effectiveness. The analysis is described as collaborative reflexive thematic analysis, indicating a qualitative design only.""
    }
}"
160,"23rd International Conference on Web-based Learning, Icwl 2024 Was Held in Conjunction with the 9th International Symposium on Emerging Technologies for Education, Sete 2024",2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a proceedings volume description listing multiple heterogeneous papers. The abstract does not specify that any included empirical study focuses on L2 English learners in ESL/EFL/ELL contexts with analyzable data; it is a collection, not a single defined population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The item is a conference proceedings book, not a single experimental or quasi-experimental study. While some listed papers mention AI, LLMs, or AI-assisted writing, the abstract does not describe a specific LLM-based writing intervention with an experimental design that can be evaluated as a standalone study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The proceedings cover diverse topics (collaborative learning, robotics, interpreting, translation, etc.). Writing is only one of many themes (e.g., ‘AI-Assisted Writing on News Report’ and ‘AI-Assisted Academic Writing Platform’), and no single, clearly defined pedagogical writing intervention is described at the level of this record.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported in the abstract. It is a high-level description of 21 papers, not a report of experimental results on L2 writing performance. Therefore, it does not meet the requirement for measurable writing outcomes from an LLM-mediated intervention.""
    }
}"
161,Exploring whether Generative Artificial Intelligence Can Enhance Chinese Efl Learners’ Academic Writings,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Chinese EFL learners, and the focus is on their English academic writing, satisfying the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, the study design compares original student texts with ChatGPT-revised versions via computational analysis. There is no experimental or quasi-experimental pedagogical intervention integrating the LLM into instruction or learners’ writing processes; ChatGPT functions as an automated editor for comparison.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on evaluating ChatGPT’s performance as an editor and its impact on textual features (narrativity, cohesion) using Coh-Metrix, not on an instructional writing intervention or learner development over time. It is closer to a tool/functionality evaluation than a pedagogical study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports quantitative changes in text features between human and ChatGPT-revised versions, but these are not outcomes of an LLM-mediated writing intervention applied to learners (e.g., no pre/post measures of learner writing after using ChatGPT in instruction). It assesses text transformation, not learner outcome from an intervention.""
    }
}"
162,Shifting Roles: Employing Ai-driven Translation Engines to Enhance the Writing Proficiency of Efl Learners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL learners at Qassim University, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses neural machine translation (MT) engines described as AI-driven translation engines. There is no indication these are large language models (e.g., ChatGPT/GPT-4-style generative transformers used interactively for writing), but rather MT tools repurposed for writing. The focus is on MT, not LLM-based writing assistance.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly aims to shift MT engines from translation to developing writing proficiency among EFL learners, with documented gains in writing skills such as spelling, construction, concordance, and meaning. The primary focus is writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports a pre–post comparison of learners’ writings with significant differences in favor of the AI-based MT intervention, and mentions evaluation via electronic proofreading software and documented gains in specific writing skills, indicating quantifiable writing outcomes.""
    }
}"
163,The Role of Ai-based Writing Tools on L2 Writing Competency: Evidence from Palestinian Efl Learners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Palestinian EFL learners (“evidence from Palestinian EFL learners”; “learning English as a foreign language”), so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Grammarly, described as an “AI-based tool (Grammarly).” Grammarly is not an LLM-based, transformer generative model in the sense required (e.g., ChatGPT, GPT-4, Gemini). It is primarily a grammar-checking/writing support tool, which falls under the exclusion of AI tools not based on LLMs.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly targets “enhancing EFL learners’ writing aspects” and examines “writing aspects and mechanics of writing,” so the primary focus is on writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""A quasi-experimental pretest–posttest design with control and experimental groups is used to measure writing before and after using the tool, and statistically significant differences in writing mechanics are reported, indicating quantifiable writing outcome metrics.""
    }
}"
164,Effects of Human-ai Collaborative Writing Strategy on Efl Students’ Argumentative Writing Skills,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Indonesian EFL university freshmen, clearly L2 English learners in an EFL context. The focus is on their English argumentative writing skills.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to a “human-AI collaborative writing strategy” and “AI-assisted tools” and “intelligent technology-enhanced writing instruction,” but does not specify which AI tools are used or whether they are LLM-based (e.g., ChatGPT, GPT-4). Without explicit mention of an LLM or transformer-based generative model, it is unclear if the intervention meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on improving EFL students’ argumentative writing skills, including constructing well-structured arguments and conveying critical thinking skills through written discourse. This aligns directly with writing competence in a pedagogical context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a pre-experimental one-group pretest–posttest design with essay tests scored using established rubrics (MT and HCTSR). Quantitative outcomes are reported (t-values, p-values, effect sizes) for writing-related traits, satisfying the requirement for quantifiable writing outcome metrics.""
    }
}"
165,Undergraduate Esl Students' Use and Perceptions of Chatgpt for Academic Writing Purposes,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are undergraduate ESL students in an intensive academic writing course at a public science and engineering institute in India, clearly fitting an L2 English/ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a survey of students’ existing use of ChatGPT and their perceptions. There is no experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction; it is observational, not an intervention study.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly ESL academic writing, focusing on students’ use of ChatGPT to generate and review academic texts, summarise, and correct grammar and vocabulary—clearly writing-related.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses Likert-scale and multiple-choice survey items plus one open-ended question to examine use and perceptions. It reports no quantifiable writing performance outcomes or measures of writing competence; only attitudes and usage patterns are analyzed.""
    }
}"
166,Chatgpt and the Development of Core Language Skills: an Exploratory Study of Efl College Students,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 30 English as a foreign language (EFL) college students from Iraq and the Czech Republic, clearly L2 English learners in EFL contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explores the application of ChatGPT, an advanced AI-powered chatbot based on LLM technology, as a tool for language learning over a six-week experiment. ChatGPT is integrated as guide, exercise partner, and rater, indicating an instructional intervention using an LLM.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on ‘core language skills such as speaking, reading, writing, listening, and communication.’ Writing is one of several skills, but the abstract does not indicate that writing competence or writing-related variables are the primary focus; it appears to be a broad, multi-skill language learning study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are mainly attitudinal percentages (e.g., students finding ChatGPT essential for speaking, writing, etc.). There is no mention of quantifiable writing performance measures (e.g., pre/post writing scores, rubric-based writing quality, accuracy, complexity). The design is described as phenomenographic with interviews, emphasizing perceptions rather than measured writing outcomes.""
    }
}"
167,Artificial Intelligence-supported Procedural Scaffolding for Promoting Efl Learners' Writing Performance in Flipped Peer Assessment Activities,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 74 university students in three English writing classes in northern Taiwan, explicitly described as EFL learners. The focus is on English writing performance, satisfying the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention is an “AI-based Procedural Scaffolding Peer Assessment (AI-PSPA) system.” However, the abstract does not specify that this AI is a large language model (e.g., ChatGPT/GPT-like, transformer-based generative model). It could be rule-based or another non-LLM AI. Without explicit mention of LLMs or generative models, it is unclear whether C2 is met.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on EFL learners’ writing performance in a flipped peer assessment context. The AI-PSPA is integrated into writing instruction/activities, and outcomes include writing accuracy, indicating a clear writing competence focus rather than mere automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental design with pre- and posttests of writing performance and reports quantitative outcomes (e.g., writing accuracy, problem-solving, creative thinking). Thus, it provides quantifiable writing outcome metrics to assess the AI-mediated intervention.""
    }
}"
168,Examining Language Learners' Genai-assisted Writing Self-efficacy Profiles and the Relationship with Their Writing Self-regulated Learning Strategies,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English-as-a-foreign-language (EFL) learners, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “GenAI-assisted writing” and “GenAI as scaffolding tool,” but does not specify that the GenAI is an LLM (e.g., ChatGPT/GPT-4) nor describe an experimental or quasi-experimental intervention; it appears to be a correlational/person-centered profiling study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on self-efficacy profiles and self-regulated learning strategies in GenAI-assisted writing, not on writing competence or writing-related performance outcomes. The study is motivational/strategic rather than a pedagogical writing intervention with performance focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, text quality measures) are reported. Outcomes are self-efficacy profiles, SRL strategy use, and antecedents such as years of learning and perceived proficiency, not measured changes in writing performance.""
    }
}"
169,Efl Secondary Students' Use of Chatgpt for Writing Task Completion Pathways,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'English as a foreign language (EFL) secondary students', clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, the study is observational: students used ChatGPT 'with no prior instruction' and the study 'examines the content and sequencing of prompts.' There is no experimental or quasi-experimental instructional intervention integrating the LLM into teaching; rather, it analyzes naturally occurring use.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing: students use ChatGPT 'to complete a writing task' and the discussion focuses on EFL writing classrooms and collaboration with ChatGPT on writing tasks.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative findings about prompt types, pathways, and the need for prompt engineering education, but does not mention any quantifiable writing outcome metrics (e.g., writing scores, quality ratings, accuracy measures) to assess effectiveness of the LLM-mediated writing process.""
    }
}"
170,Gpt Api-based Chatbots as Adaptive and Facilitative Tutors for L2 English Process Writing,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL secondary school students (six ninth-graders) engaged in L2 English process writing, clearly fitting ESL/EFL/ELL L2 English learner contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses GPT-4 Turbo API-based chatbots as adaptive and facilitative tutors across four stages of the L2 writing process, integrating an LLM (GPT-4) into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL process writing, with chatbots providing stage-specific feedback (prewriting, drafting, revising, editing) to promote L2 writing development and support writing quality.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports that learners acknowledged a positive impact on writing quality and that chatbots effectively assisted at each stage, but it does not clearly state whether quantifiable writing outcome metrics (e.g., scores, rubric-based measures, error counts) were collected, or if findings are based mainly on perceptions in a small case study.""
    }
}"
171,Chatgpt-assisted Writing: Learners’ Perceptions of Ai Feedback and Influencing Factors,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are intermediate and advanced university students who are English language learners, focusing on English writing. This fits L2 English learners in an EFL/ESL/ELL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT 3.5 as an AI chatbot writing aid, indicating integration of an LLM into learners’ writing processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly English writing, with ChatGPT used for creating ideas, vocabulary, organization, and grammar in writing. The focus is on writing abilities and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are changes in confidence and attitudes toward English writing (pre- and post-surveys) and qualitative perceptions of ChatGPT’s usefulness. There is no mention of quantifiable writing performance metrics (e.g., writing scores, text quality measures), so no direct writing outcome measure is reported.""
    }
}"
172,Improving Academic Writing Proficiency for Efl Students: Leveraging Chatgpt Using Data-driven Learning Principles,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 92 international students in a pre-sessional foundation writing course at a Thai university, described as EFL students working on IELTS-style essay writing. The focus is clearly on English as a foreign language writing proficiency.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT (GPT-3.5) as part of a quasi-experimental design. Experimental Group 2 used ChatGPT-generated paraphrases of their own compositions with guided worksheets, integrating an LLM directly into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is embedded in essay writing instruction, aiming to improve academic short essay writing skills. The primary focus is writing proficiency and related variables (e.g., confidence), not automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative posttest writing scores for control and experimental groups (e.g., control x = 74.03%, Experimental Group 2 x = 94.3%), providing measurable writing outcomes to assess the effectiveness of the ChatGPT-mediated intervention.""
    }
}"
173,Exploring Factors Influencing L2 Learners’ Use of Gai-assisted Writing Technology: Based on the Utaut Model,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 419 graduate students in China using GAI for second language writing, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study concerns Generative AI use in L2 writing, it is not an experimental or quasi-experimental pedagogical intervention. It examines factors influencing usage behavior via the UTAUT model, not an instructional design integrating LLMs into writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is technology acceptance and usage behavior (performance expectancy, effort expectancy, social influence, etc.), not writing competence or writing-related performance variables. Writing is the context, not the main outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity) are reported. Outcomes are behavioral intention and actual usage behavior, not measured changes in writing performance.""
    }
}"
174,"Assessing the Use of Ai Tools for Efl Exam Preparation at Saudi Universities: Efficiency, Benefits, and Challenges",2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are EFL teachers, not L2 English learners. The abstract states: “Sixty-one EFL teachers from two universities in Saudi Arabia participated in this study via an online survey.” No learner data are reported.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although LLM tools such as ChatGPT and Gemini are mentioned, the study is a survey of teachers’ adoption and perceptions. There is no experimental or quasi-experimental design integrating LLMs into writing instruction or learner writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on exam preparation and question generation (often lower-order multiple-choice/true-false) rather than on students’ writing competence or writing-related pedagogical interventions. Essay prompt design is mentioned only as a challenge, not as an instructional focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports survey-based perceptions of efficiency, benefits, and challenges. It does not report quantifiable writing outcome metrics for learners or any measured impact of LLM-mediated writing interventions.""
    }
}"
175,"Examining the Impact of Gamified Mobile and Ai-assisted Language Learning on Academic Integrity, Creative Trait Motivation and Writing Performance",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as upper-intermediate English as a foreign language learners, which fits ESL/EFL/ELL L2 English learner contexts and focuses on English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “AI-assisted language learning (AIALL)” and “AI tools” but does not specify whether these are large language model–based systems (e.g., ChatGPT, GPT-4) or other types of AI (e.g., grammar checkers, adaptive apps). Without explicit mention of LLMs or transformer-based generative models, it is not possible to confirm that the intervention meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing performance is one of the primary outcome variables, and the intervention is framed as language learning with a clear focus on writing performance alongside academic integrity and creative trait motivation. This aligns with a focus on writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental design with validated pre-tests and post-tests and reports that both experimental groups outperformed the control group on post-tests for writing performance. This indicates quantifiable writing outcome metrics are reported.""
    }
}"
176,From Retrieval to Generative Models: a Design-based Research Approach to Developing a Chatbot for Argumentative Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states that Argumate is designed to facilitate EFL students’ argumentative writing, indicating a population of English as a foreign language learners with English as the target language.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The paper describes a design-based research project developing a chatbot, moving from retrieval models to generative models. It is not clearly stated whether the generative component is a large language model (e.g., GPT-like transformer) or another type of generative system, nor whether it is actually implemented in classroom intervention as opposed to being a design/development report.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The chatbot, Argumate, is specifically designed to facilitate EFL students’ argumentative writing, and the paper focuses on developing chatbots to support students’ argumentative writing. Thus, the primary focus is on writing competence and writing-related support.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is labeled an ‘Innovative Practice paper’ and the abstract emphasizes the development process and design-based research over approximately three years. It does not mention any experimental or quasi-experimental evaluation, nor any quantifiable writing outcome metrics; it appears to focus on design insights rather than measured intervention effects.""
    }
}"
177,The Impact of Genai-based Collaborative Inquiry on Critical Thinking in Argumentation: a Case Study of Blended Argumentative Writing Pedagogy,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as seven EFL university freshmen, indicating second language English learners in an EFL context, with a focus on argumentative writing in English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “GenAI” and “GenAI-based collaborative inquiry” but does not specify that the tool is a large language model (e.g., ChatGPT, GPT-4). It could be an LLM, but this is not explicit from the title/abstract alone.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is argumentative writing pedagogy; GenAI is integrated into collaborative inquiry for argumentative writing, and the study analyzes argumentative writing products, indicating a primary focus on writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary reported outcome is critical thinking in argumentation (CTA). While argumentative writing products are analyzed, the abstract only states that CTA was enhanced in collaborative discourse and writings, without indicating quantifiable writing outcome metrics (e.g., writing quality scores, accuracy, complexity). The focus is on critical thinking rather than measurable writing performance.""
    }
}"
178,Efl Secondary Students’ Use of Chatgpt for Writing Task Completion Pathways,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'English as a foreign language (EFL) secondary students', clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, the study focuses on students’ spontaneous use of ChatGPT 'with no prior instruction' and analyzes their prompt pathways. There is no experimental or quasi-experimental instructional intervention integrating LLMs into writing instruction; rather, it is an observational case analysis.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is a 'writing task' in EFL classrooms, and the study concerns how students use ChatGPT to complete that writing task, which is directly related to writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative findings about prompt types, pathways, and the need for prompt engineering education. It does not mention any quantifiable writing outcome metrics (e.g., writing scores, quality ratings, accuracy measures) to assess the effectiveness of ChatGPT-mediated writing on writing performance.""
    }
}"
179,Students’ Appraisals Post-chatgpt Use: Students’ Narrative after Using Chatgpt for Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 12 students learning English as a Foreign Language who used ChatGPT in academic writing classes, clearly indicating an EFL (L2 English) population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, the study is purely exploratory and based on semi-structured interviews about students’ experiences. There is no indication of an experimental or quasi-experimental design or structured pedagogical intervention being evaluated.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on using ChatGPT for essay writing, including translation, writing accuracy, efficiency, and idea generation, which are all writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study relies on qualitative data from interviews about experiences and appraisals. It does not report quantifiable writing outcome metrics or measured changes in writing performance.""
    }
}"
180,Investigating L2 Learners’ Text-to-video Resemiotisation in Ai-enhanced Digital Multimodal Composing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 75 undergraduates in an English writing course at a comprehensive university in China, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Pictory, an AI-powered text-to-video platform that generates video clips from search queries. The abstract does not indicate that this is a large language model (e.g., ChatGPT/GPT-4-like transformer-based generative text model) integrated into writing instruction; it is primarily a text-to-video tool for multimodal composing.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on digital multimodal composing (DMC) and text-to-video resemiotisation, examining how students integrate linguistic, semiotic, and technological elements to create videos. The outcome focus is DMC skills and multimodal products, not specifically writing competence or writing-related variables as primary outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports qualitative content and comparative analyses of students’ query revisions and resulting videos. There is no mention of quantifiable writing outcome metrics (e.g., writing scores, accuracy, complexity) to assess the effectiveness of an AI-mediated writing intervention.""
    }
}"
181,Exploring the Impact of Chatgpt on Psychological Factors in Learning English Writingamong Undergraduate Students,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 142 undergraduate students at a university in Saudi Arabia learning English writing, which fits an EFL/ESL/ELL context focused on English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states the study explores how ChatGPT influences psychological factors in learning English writing and that a questionnaire was used, but it does not clearly describe an experimental or quasi-experimental LLM-based writing intervention (e.g., structured use of ChatGPT in writing instruction with controlled conditions).""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on psychological factors (cognition, emotions, motivation, attitudes, resilience, stress, coping) rather than writing competence or writing-related performance variables. Reported outcomes are correlations between ChatGPT use and psychological constructs, not writing skill development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, text quality measures, accuracy, complexity) are reported. Outcomes are limited to psychological measures gathered via questionnaire, without experimental measures of writing performance.""
    }
}"
182,Investigating Efl Teachers’ Lesson Planning for Chatbot-assisted Learning of Argumentative Writing: a Tpack Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context is EFL teaching of argumentative writing, but the abstract focuses on teachers and their lesson planning. It does not clearly state that data are collected from L2 English learners or that learner outcomes are measured.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates teachers’ lesson planning for chatbot-assisted learning and analyzes their professional knowledge using TPACK. There is no indication of an experimental or quasi-experimental intervention implemented with learners, nor evidence that the chatbot is specifically an LLM (e.g., ChatGPT, GPT-4).""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is argumentative writing, the primary focus is on teachers’ integration approaches and professional knowledge, not on an implemented pedagogical intervention with learners’ writing performance as the central outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports no quantitative writing outcome metrics or experimental measures of writing improvement. It is a qualitative exploration of lesson plans and teacher interviews, without assessed learner writing outcomes.""
    }
}"
183,Exploring Multimodality of Chatgpt for Language Teaching and Learning: a Preliminary Study on Its Pedagogical Prospects,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses language education in general and mentions L1 and L2 texts, but does not specify that the participants are L2 English learners in ESL/EFL/ELL contexts, nor that the focus is specifically on English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper is described as a preliminary, conceptual exploration of ChatGPT’s pedagogical prospects, based on the authors’ first-hand use, simulated examples, and theory. There is no indication of an experimental or quasi-experimental design or a structured instructional intervention with learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing and writing devices are mentioned among various skills, the study’s primary focus is on general pedagogical potential and multimodality of ChatGPT across multiple language skills, not on writing competence or writing-related variables in a concrete instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any empirical, quantifiable writing outcome measures. It is positioned as a theoretical and exploratory piece intended to stimulate future empirical research, without experimental measures or structured intervention outcomes.""
    }
}"
184,Chatgpt-assisted Language Learning: Effects on Vietnamese English Majors’ Writing Skills and Motivation,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Vietnamese first-year English majors, clearly L2 English learners in an EFL context. The focus is on English writing skills, satisfying the population requirement.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is explicitly described as 'ChatGPT-assisted writing instruction' compared to traditional instruction over a 15-week semester. ChatGPT is a large language model, and the design is experimental with control and experimental groups.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence: effects on 'writing skills' using IELTS writing assessments, and the abstract discusses improvements in writing performance and domains such as task achievement and coherence within a pedagogical framework.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantifiable writing outcomes are reported via pre- and post-tests using IELTS writing assessments, with ANCOVA results and effect sizes (e.g., ηp² for task achievement and coherence), directly measuring the impact of the LLM-mediated intervention on writing performance.""
    }
}"
185,Bringing Cinderella into Spotlight: Genai-assisted Grammar Acquisition in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described only as “first-year undergraduate students” in an academic writing context. It is not specified that they are L2 English learners (ESL/EFL/ELL), so their L2 status and the focus on English as a second/foreign language cannot be confirmed from the abstract.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a “qualitative case study” design to explore how a localized version of ChatGPT assists students. There is no indication of an experimental or quasi-experimental design (e.g., control group, pre/post tests, or structured intervention with measurable comparison) required for inclusion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is academic writing, focusing on grammar development “in writing tasks” and grammar acquisition within writing instruction. This aligns with a primary focus on writing-related competence rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract emphasizes a qualitative case study and mentions that results indicate ChatGPT promotes grammar proficiency and learning experience, but it does not report or clearly imply quantifiable writing outcome metrics (e.g., scores, error rates, statistical comparisons). The focus appears to be qualitative perceptions and observed improvement without explicit experimental measures.""
    }
}"
186,The Robustness of Ai-classifiers in the Face of Ai-assisted Plagiarism: the Case of Turnitin Ai Content Detector,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly includes English as a foreign language (EFL) texts and discusses issues related to English as a second language writings, indicating an L2 English learner context is part of the data.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study evaluates Turnitin’s AI content detector and its accuracy on different text types. There is no experimental or quasi-experimental design integrating an LLM into writing instruction or writing processes; ChatGPT is only mentioned as the source of AI-generated text, not as an instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the robustness and accuracy of an AI classifier (Turnitin AI Detector) in detecting AI-assisted plagiarism, not on improving writing competence or writing-related pedagogical variables. This is an assessment/forensics study rather than a writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported concern detection accuracy of AI-generated, paraphrased, and humanized texts, not quantifiable writing outcomes (e.g., writing quality, complexity, accuracy) resulting from an LLM-mediated writing intervention.""
    }
}"
187,Investigating the Effects of Ai-assisted Teacher Instruction on Online Ielts Writing,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as EFL learners and IELTS candidates in an online IELTS writing course. The context is clearly English as a foreign language, focusing on IELTS Writing Task 2, which is an English writing test.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses an “AI Copilot” to assist teachers and provide AI-driven insights and personalized feedback. However, the abstract does not specify whether this AI Copilot is a large language model (e.g., ChatGPT/GPT-4 or similar transformer-based generative model) or another type of AI tool. Without explicit indication that it is LLM-based, it is not possible to confirm it meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on IELTS Writing Task 2 instruction and students’ writing performance. The study examines writing score improvements and components such as Task Achievement, Coherence and Cohesion, Lexical Resource, and Grammatical Range and Accuracy, indicating a clear focus on writing competence within an instructional context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: pre- and post-test IELTS writing scores and improvements in four scoring components (TA, CC, LR, GRA). A paired-sample analysis is used to compare pretest and post-test writing scores, satisfying the requirement for measurable writing outcomes.""
    }
}"
188,Using Generative Artificial Intelligence as an Automated Essay Scoring Tool: a Comparative Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions 120 essays and implications for L2 writing teaching and assessment, but does not clearly state that the essays are written by L2 English learners in ESL/EFL/ELL contexts. The population could be L1 or mixed; this is not specified.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT-4 and Gemini are used solely as automated essay scoring tools. There is no indication of an instructional or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or writing processes; the focus is on rating reliability versus human raters.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the reliability and consistency of LLM-based automated essay scoring compared with human raters, not on improving writing competence or writing-related learning outcomes through an intervention. This aligns with excluded contexts (AES functionality studies).""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports reliability and correlation metrics for scoring but does not report quantifiable writing outcome measures assessing the effectiveness of an LLM-mediated writing intervention. No pre/post or comparative writing performance data are described.""
    }
}"
189,Comparing Hong Kong Secondary School Students’ Perceptions of Chatgpt-assisted Efl Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 107 Hong Kong secondary school students in an EFL context, and the focus is explicitly on EFL (English as a foreign language) writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study investigates ChatGPT-assisted EFL writing and compares three teaching approaches in that context, indicating an instructional intervention using an LLM (ChatGPT).""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing instruction, and the intervention is framed as ChatGPT-assisted EFL writing, aligning with a focus on writing competence and writing-related pedagogy.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports outcomes on motivation, cognitive load, and satisfaction, but does not mention any quantitative writing performance or writing quality measures. Outcomes are affective/cognitive, not writing competence metrics, so it does not meet the requirement for quantifiable writing outcome measures.""
    }
}"
190,Investigating Efl Students’ Perceptions of Feedback: a Comparative Study of Instructor and Chatgpt-generated Responses in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Saudi English as a Foreign Language (EFL) learners enrolled in an advanced writing course, clearly fitting L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study compares instructor feedback with ChatGPT-generated feedback on students’ writing assignments, integrating an LLM (ChatGPT) into the feedback stage of the writing process within a course context.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is academic writing; feedback (from instructor and ChatGPT) is provided on writing assignments with the stated aim of developing writing skills, so the primary focus is writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes a mixed-methods study focusing on learners’ perceptions and preferences via a survey. Although it mentions that feedback is used to develop writing skills, no quantifiable writing outcome measures (e.g., pre/post writing scores, rubric-based gains) are reported; only perceptions of usefulness, immediacy, and accessibility are presented.""
    }
}"
191,Thai Efl University Students’ Writing in the Digital Age: Error Analysis Revisited,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Thai EFL university students, clearly L2 English learners in an EFL context: “Thai EFL university students… 70 undergraduates.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions Google Translate and ChatGPT and discusses the impact of digital tools, there is no indication of an experimental or quasi-experimental LLM-based instructional intervention. The tools are surveyed as resources students use, not as a structured LLM-mediated teaching treatment.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence and grammatical errors in student writing: “investigated the grammatical errors and writing strategies… effective writing instruction should combine explicit grammar teaching… to improve writing accuracy.”""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports error analysis and survey results but does not describe any LLM-mediated intervention with pre/post or comparative quantitative writing outcomes. LLMs are only discussed as tools students use and as implications for future instruction, not as an evaluated intervention.""
    }
}"
192,Motivation and Achievement in Efl: the Power of Instructional Approach,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 43 first-year EFL students at a Chinese university, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The AI-blended approach used AWE, ASR, and the chatbot DouBao. The abstract does not specify that DouBao (or the other tools) is an LLM-based, transformer generative model; it is only described generically as a chatbot. Without explicit indication that an LLM (e.g., ChatGPT, GPT-4, similar) underpins the intervention, it does not meet the LLM-specific criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing is one of the key language skills measured, alongside listening and translation. The AI-blended approach is said to improve writing, and AWE is part of the instructional design, so writing competence is a primary focus among the outcomes.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes: goal orientation, self-efficacy, instructional support, and English academic achievement, including specific skills such as listening comprehension, translation, and writing, analyzed via repeated measures ANOVA and Friedman tests.""
    }
}"
193,Exploring the Use of Chatgpt-generated Model Texts as a Feedback Instrument: Efl Students’ Text Quality and Perceptions,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 104 Chinese high school EFL students, clearly indicating L2 English learners in an EFL context. The focus is on English writing quality (content, organisation, vocabulary, grammar).""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses ChatGPT-generated model texts as a feedback instrument for writing. ChatGPT is a large language model, and the study employs a quasi-experimental pretest–post-test design with control and experimental groups, integrating the LLM into writing instruction/feedback.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL writing competence: effects of ChatGPT-generated model texts on students’ text quality (content, organisation, vocabulary, grammar) and their perceptions. This is a pedagogical writing intervention, not an automated scoring or purely technical evaluation study.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: pretest and post-test writing scores on analytical measures (content, organisation, vocabulary, grammar), analysed with descriptive and inferential statistics, allowing assessment of the effectiveness of the LLM-mediated feedback intervention.""
    }
}"
194,The Revolution of Artificial Intelligence in Scientific Writing: Analysis and Perspectives from Multiple Studies,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract discusses 'non-native English speakers' and 'non-English speaking' researchers in general, not a defined population of L2 English learners in ESL/EFL/ELL instructional contexts. It focuses on scientific writing broadly rather than language learning settings.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a narrative review of AI tools in scientific writing and does not describe an experimental or quasi-experimental intervention integrating LLMs (e.g., ChatGPT) into instruction. It is explicitly labeled as a 'non-systematic assessment' and 'narrative review'.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on scientific writing practices, literature review, reference management, and publication quality and integrity, not on pedagogical writing instruction or L2 writing competence development. It is not situated in an ESL/EFL teaching/learning context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a narrative review, the paper does not report original quantitative writing outcome measures from an intervention. It synthesizes existing literature and discusses benefits, drawbacks, and ethics without experimental outcome data.""
    }
}"
195,Boosting Punctuation Proficiency: the Power of an Interactive Chatbot for Efl Learners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 60 Omani EFL learners at Sohar University in Oman, clearly an EFL (L2 English) context with focus on English punctuation marks.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is a WhatsApp-based interactive chatbot developed for the study. There is no indication that it is a large language model (e.g., ChatGPT, GPT-4, Gemini) or a transformer-based generative model; it appears to be a rule-based or conventional chatbot for punctuation practice.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study targets rule-based writing skills, specifically English punctuation, which is a writing-related subskill. The chatbot is used to provide explanation and practice on punctuation marks, aligning with writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative outcomes are reported: pretest, posttest, and delayed posttest scores on punctuation, with statistical analyses (Kruskal-Wallis, p-values, effect sizes) comparing control and experimental groups.""
    }
}"
196,Exploring Patterns of Ai-powered Machine Translation Use in Second Language Writing: a Translanguaging Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are undergraduate students at a Chinese university (English and non-English majors) engaged in L2 (English) writing, fitting an EFL/ESL/ELL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is AI-powered machine translation (MT), not a large language model such as ChatGPT/GPT-4 or similar transformer-based generative LLM used pedagogically. The study is qualitative and observational of existing MT use, not an experimental or quasi-experimental LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly L2 writing; the study explores patterns of MT use in second language writing and their pedagogical implications, so the primary focus is on writing-related behavior and pedagogy.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly qualitative, focusing on patterns and ideologies of MT use. There is no mention of experimental or quasi-experimental measures of writing performance or quantifiable writing outcome metrics.""
    }
}"
197,Enhancing Vocabulary Learning through Technology: Ai-driven Pushed Output Hypothesis for Saudi Efl Learners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are three male Saudi undergraduate EFL learners enrolled in an English degree program at Albaha University, clearly an EFL/ESL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract repeatedly mentions “AI-driven technology” and “AI-enhanced tool,” the concrete intervention is described as a “pushed email condition” compared with classroom-based conditions. There is no indication that a large language model (e.g., ChatGPT, GPT-4, Gemini) was integrated into instruction or writing processes; email itself is not an LLM-based tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context involves learners submitting nine writing samples under different conditions, with analysis of vocabulary size and lexical errors in their written output. This is directly related to writing performance and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative vocabulary size (measured via V_Words) and qualitative lexical errors (Engber’s 1995 taxonomy), and compares outcomes across conditions, noting that the pushed email condition led to greater vocabulary expansion and lexical accuracy. These are quantifiable writing-related outcomes.""
    }
}"
198,The Role of Generative Ai and Hybrid Feedback in Improving L2 Writing Skills: a Comparative Study,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 60 Chinese EFL students, clearly L2 English learners in an EFL context, and the focus is on L2 academic writing in English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract repeatedly refers to “Generative AI (GenAI)” feedback but does not specify the tool (e.g., ChatGPT, GPT-4) or confirm that it is an LLM-based system. Without explicit indication that GenAI is a transformer-based large language model rather than another type of AI feedback system, it is not possible to be certain it meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on L2 academic writing skills, including grammar, sentence variety, organization, and critical thinking. It investigates GenAI and hybrid feedback as part of L2 writing instruction, not as an automated scoring or purely functional evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing performance is quantitatively assessed using GRE writing rubrics, with reported improvements in specific dimensions (grammar, sentence variety, organization, critical thinking). This provides measurable writing outcome metrics for the intervention.""
    }
}"
199,English as a Foreign Language (efl) Secondary School Students’ Use of Artificial Intelligent (ai) Tools for Developing Writing Skills: Unveiling Practices and Perceptions,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL secondary school students using AI tools to develop English writing skills, clearly fitting an EFL/ELL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is exploratory/descriptive, examining students’ existing practices and perceptions of AI tools (Grammarly, ChatGPT, Google Translate). There is no experimental or quasi-experimental intervention integrating LLMs into instruction; rather, it uses questionnaires and interviews about current use.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on how AI writing tools mediate stages of the writing process and support idea generation, vocabulary, and accuracy—i.e., writing competence and writing-related variables in an educational context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports students’ practices and perceptions via questionnaires and interviews, with no mention of quantifiable writing outcome measures (e.g., pre/post writing scores, rubric-based performance). Outcomes are attitudinal and descriptive, not experimental measures of writing improvement.""
    }
}"
200,We Should Promote Genai Writing Tools for Linguistic Equity,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions 'English as an additional language students' but does not specify any actual participant sample or empirical data collection. It appears to be a conceptual/position essay rather than a study with defined L2 participants.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although GenAI writing tools and chatbots (e.g., ChatGPT, Copilot, Claude) are discussed, there is no indication of an experimental or quasi-experimental intervention. The piece is an essay arguing for adoption, not an empirical study implementing LLMs in instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on advocating for the use of GenAI for linguistic equity and policy development, not on a concrete pedagogical intervention targeting writing competence with measured outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or empirical results are reported. The abstract describes a normative argument, not an intervention study with measured writing performance.""
    }
}"
201,The Design and Evaluation of an Interactive Ai Companion for Foreign Language Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “foreign language writing” learners but does not specify that the target language is English or that the context is ESL/EFL/ELL. The population could involve any foreign language, so it is not clear that L2 English learners are the focus.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study describes an “interactive AI companion” and “AI chatbot” for writing, but it does not specify that it is based on a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model). It could be another type of AI system, so its status as an LLM intervention is uncertain.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The AI companion is explicitly designed as a writing companion to support a process-oriented approach to foreign language writing, emphasizing writing as a collaborative process and focusing on textual conventions. The primary pedagogical focus is on writing processes and competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are perceptions and psychological constructs (writing self-efficacy, anxiety, self-regulation, anthropomorphism, teaching presence, enjoyment). The abstract does not indicate any quantifiable writing performance metrics (e.g., text quality, accuracy, complexity) were measured, only self-reported perceptions.""
    }
}"
202,Exploring Ai-assistance in L2 Chinese Writing with Standardized Assessment Tasks,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are 'university-level Mandarin Chinese foreign language students' completing AP Chinese writing tasks. The target language and writing focus are Mandarin Chinese, not English. The review requires L2 English learners in ESL/EFL/ELL contexts with data focused on English.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study allows students to use ChatGPT, a large language model, for assistance on one of the writing prompts and compares performance with and without ChatGPT. This constitutes an experimental design integrating an LLM into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 writing performance in standardized assessment tasks, examining how ChatGPT supports completion of writing tasks and which aspects students rely on (e.g., vocabulary, translation). This aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study compares writing scores with and without ChatGPT, using standardized prompts and professional raters, and reports that ChatGPT assistance resulted in higher scores. These are quantifiable writing outcome metrics.""
    }
}"
203,Generative Ai and English Essay Writing: Exploring the Role of Chatgpt in Enhancing Learners' Task Engagement,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 60 undergraduate learners writing English argumentative essays in an English as a Foreign Language (EFL) context, clearly indicating L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a generative AI-based tool, ChatGPT, within a mixed-methods experimental design with control and experimental groups over a 2‑month instructional period, indicating an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on learners’ task engagement in English essay writing (motivation, anxiety, interest, partnership, perceived competence), not on writing competence or writing-related performance variables. The abstract does not mention assessing writing quality, accuracy, or other competence-related outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantitative outcomes reported are engagement levels during essay writing tasks. There is no indication of quantifiable writing performance metrics (e.g., scores, complexity, accuracy, organization) to evaluate the effectiveness of the intervention on writing quality.""
    }
}"
204,Generative Ai in Academic Writing: Exploring Esl Students' Strategies and Performance,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 13 university students in Malaysia doing academic writing in English, which reasonably indicates an ESL/EFL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as an exploratory case study of students’ self-reported GenAI-assisted writing strategies using ChatGPT. There is no indication of an experimental or quasi-experimental instructional intervention; rather, it observes existing usage without a designed LLM-based teaching or practice intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on GenAI-assisted academic writing in English and how students incorporate ChatGPT into their writing, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions ‘effects on their output’ and ‘writing performance’ but only reports a thematic analysis of self-reported usage and strategies. It does not indicate any quantitative or experimental writing outcome measures; outcomes appear to be qualitative themes rather than measurable writing gains.""
    }
}"
205,English Language Teaching (elt) in the Digital Age: a Meta-thematic Analysis of Artificial Intelligence Research,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The article is a meta-analysis of AI in EFL instruction, so it likely involves EFL learners in the underlying studies, but the abstract does not specify participant details or confirm that the focus is on L2 English learners’ data rather than broader ELT contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a meta-thematic/meta-analysis of prior AI-in-ELT research, not an experimental or quasi-experimental primary study integrating a specific LLM (e.g., ChatGPT, GPT-4) into writing instruction. It synthesizes existing work and does not itself implement an LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is broad—AI in English language teaching generally. While it notes that AI can facilitate academic writing, writing is only one of several themes (motivation, personalized learning, ethical/pedagogical/technical issues), not the primary focus of a concrete intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses content analysis of existing research and reports thematic findings (e.g., motivation, personalized learning, academic writing facilitation). It does not report quantifiable writing outcome metrics from an LLM-mediated writing intervention.""
    }
}"
206,Incorporating Chatgpt into Genre-based Instruction for Argumentative Writing among Efl College Students,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 48 first-year EFL English majors at universities of technology in Taiwan. This clearly identifies them as L2 English learners in an EFL context, with English as the target language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly examines “ChatGPT-integrated genre-based instruction” over a six-week experiment. ChatGPT is a large language model, and it is integrated into the instructional design, satisfying the LLM-based intervention requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on argumentative writing performance and related constructs (willingness to write, perceptions). ChatGPT is used pedagogically for idea generation and feedback within writing instruction, not merely for automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports pre- and post-writing tests and pre- and post-WtW questionnaires, with findings such as “significant improvements in some moves after the instruction” and changes in WtW scores. These constitute quantifiable writing outcome metrics.""
    }
}"
207,Empowering Authorship with Ai: a Novel Academic Writing Technology for Authorial Voice,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as “23 first-year ESL students at a Fijian university,” and the focus is on their academic writing in English, satisfying the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that AVATAR is an intelligent tutoring system integrating Technology-Enhanced Learning and Generative Artificial Intelligence (GAI). However, it does not specify whether the GAI component is a large language model (e.g., ChatGPT/GPT-like transformer-based generative model) or another form of AI. Without explicit indication that AVATAR uses an LLM, it is unclear if this meets the LLM-based intervention requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on academic writing, specifically the development of authorial voice in argumentative essays. AVATAR is used while students work on an argumentative essay, and the intervention is clearly pedagogical and writing-focused rather than automated scoring or system benchmarking.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes: statistically significant improvement in authorial voice performance, increased authorial voice strength scores for essays edited in AVATAR, and higher post-use authorship survey results and self-scores. These constitute measurable writing-related outcomes linked to the intervention.""
    }
}"
208,Are Ai Tools Effective in Reducing Cognitive Load or Boosting Writing Self-efficacy for L2 Postgraduates?,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as postgraduate students engaged in research-based L2 writing, but the abstract does not specify that the target language is English or that the context is ESL/EFL/ELL. It only states “second-language (L2) writing,” so the population’s L2 and context remain unclear.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study investigates “AI tools” in L2 writing but does not specify that these are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems. The type of AI (LLM vs. other tools such as machine translation, summarizers, or grammar checkers) is not identified, so it is impossible to confirm that LLMs are the intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary outcomes are writing self-efficacy and cognitive load. The abstract does not indicate that writing competence, text quality, or other writing performance variables were measured. The focus is on psychological and cognitive variables related to AI use, not on writing competence itself.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, text quality ratings, linguistic measures) are reported. The quantitative data concern self-efficacy and perceived cognitive load, and the qualitative data concern perceptions of AI tools. There is no experimental measure of changes in writing performance attributable to AI use.""
    }
}"
209,Examining the Impact of Artificial Intelligence (ai) Tools for Saudi Arabian English as a Second Language (esl) Students,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are ESL students at a Saudi Arabian university, explicitly described as ESL learners, with outcomes focused on English writing proficiency.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines a bundle of AI tools: ChatGPT (LLM-based) plus Grammarly and QuillBot, which are not clearly LLM-based in this context. More importantly, the design is correlational/impact-focused rather than an experimental or quasi-experimental instructional intervention integrating LLMs into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is ESL students’ writing proficiency and writing-related opportunities and challenges when using AI formative feedback tools, which aligns with writing competence as the main context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although quantitative significance values are reported, the study appears to be cross-sectional, examining perceived impact and associations rather than outcomes of a structured LLM-mediated writing intervention. It does not clearly report pre/post or controlled experimental writing outcome measures attributable to an LLM-based intervention.""
    }
}"
210,Empowering Efl Learning: Leveraging Chatgpt for Lesson Planning and Activity Generation in the Efl Classroom,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is an EFL classroom with first-year EFL students in Algeria, and the course is on paragraph writing in English. This fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used to generate a lesson plan and activities, and the study investigates EFL writing teachers’ opinions of these materials via a questionnaire. There is no experimental or quasi-experimental design integrating ChatGPT into learners’ writing instruction or processes; it is an evaluation of materials, not an intervention with learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the topic is a course on paragraph writing, the primary focus of the study is on the quality and perceived usefulness of ChatGPT-generated lesson plans and activities as judged by teachers, not on learners’ writing competence or writing-related performance outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports teachers’ opinions collected via questionnaire and does not report any quantifiable writing outcome metrics for students (e.g., writing scores, accuracy, complexity, fluency) resulting from an LLM-mediated intervention.""
    }
}"
211,Willm: a System for Academic Writing Improvement Based on Large Language Models,2025,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that the study involved 19 non-native English-speaking participants and focuses on academic writing in English. However, it does not specify whether these learners are in ESL/EFL/ELL instructional contexts (e.g., formal language courses) or are general university students using the tool, so it is unclear if they fit the targeted L2 learner population definition.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The paper introduces WILLM, explicitly described as a system for academic writing improvement based on Large Language Models (LLMs). A three-week user study indicates an intervention where participants used this LLM-based system, satisfying the requirement for an LLM-mediated writing intervention with an experimental component.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The system provides context-aware feedback on grammar, vocabulary, coherence, and organization, and integrates quizzes and personalized reviews to enhance long-term writing proficiency. The focus is clearly on improving academic writing competence rather than on automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that the three-week user study demonstrated improvements in grammar and vocabulary scores, which are quantifiable writing-related outcome metrics. Although details of the measures are not given, the presence of measurable score improvements meets the criterion for quantitative writing outcomes.""
    }
}"
212,Integrating Various Types of Feedback in L2 Writing Instruction: Teachers' and Students' Perspectives,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 286 tertiary EFL students and 65 teachers in L2 writing classrooms, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions 'automated feedback' enabled by NLP and AI, it does not specify the use of large language models (e.g., ChatGPT, GPT-4) nor an experimental or quasi-experimental intervention integrating LLMs into writing instruction. The focus is on surveying preferences, not on an LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on teachers’ and students’ perspectives on integrating teacher, peer, and automated feedback and on task complexity and feedback preferences, not on evaluating a pedagogical writing intervention or its impact on writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is survey-based and reports perceptions, preferences, and correlations; it does not report quantifiable writing outcome metrics (e.g., changes in writing scores or quality) resulting from an LLM-mediated writing intervention.""
    }
}"
213,Exploring Student Engagement with Artificial Intelligence-guided Chatbot Feedback in Efl Writing: Interactions and Revisions,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are three Chinese university students engaged in English writing learning, clearly an EFL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to an “AI-guided chatbot” providing feedback, but does not specify that it is a large language model (e.g., ChatGPT/GPT-based or similar transformer LLM). It could be a rule-based or non-LLM chatbot; the underlying technology is not described.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on engagement with AI-guided chatbot feedback in English writing learning and second language writing instruction, which aligns with writing competence and writing-related processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a multiple-case study examining behavioral, cognitive, and emotional engagement. Data sources are chat records, drafts, and interviews. The abstract reports engagement patterns but does not mention any experimental or quasi-experimental design or quantifiable writing outcome metrics assessing effectiveness of the AI intervention on writing performance.""
    }
}"
214,Quantum Psychology Approach on Enjoyment as Mediator in Relationship between L2 Flow and Engagement,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 162 high school students in English as a Foreign Language (EFL) speaking and writing classes, so they are L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is described as 'AI-assisted' EFL speaking and writing classes, there is no indication that a specific large language model (e.g., ChatGPT, GPT-4) is integrated as an experimental or quasi-experimental intervention. The study is a quantitative, cross-sectional survey of psychological variables, not an LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on psychological flow, enjoyment, and academic engagement, not on writing competence or writing-related performance variables. Writing is only part of the class context, not the central outcome of interest.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports path analysis results on flow, enjoyment, and engagement scales. It does not report quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity) to assess any writing intervention, nor does it describe an LLM-mediated writing intervention.""
    }
}"
215,Enhancing Students’ L2 Writing by Integrating Artificial Intelligence with Corpus-based Language Pedagogy,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 50 English as a Foreign Language (EFL) learners majoring in English at an English-Medium Instruction university in China, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers only to generic 'AI tools' and does not specify that they are large language model–based (e.g., ChatGPT, GPT-4). They could include non-LLM tools such as grammar checkers or other AI-based applications. Without explicit mention of LLMs or transformer-based generative models, it is not possible to confirm that the intervention integrates LLMs.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on L2 writing revision, integrating AI and corpus tools to support writing development, refine collocations, and revise sentences. The primary context is clearly writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract emphasizes questionnaires, interviews, and analysis of changes made in drafts to explore tool use and learner attitudes. It does not report quantifiable writing outcome metrics (e.g., pre/post writing scores, rubric-based gains) to assess effectiveness of the AI-mediated intervention; instead, it focuses on types of changes and perceptions.""
    }
}"
216,Effects of Ai Chatbots on Efl Students’ Critical Thinking Skills and Intrinsic Motivation in Argumentative Writing,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 40 Chinese undergraduates in an EFL context (“integrating AI chatbots into EFL classroom activities”), so they are L2 English learners and the focus is on English argumentative writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses an “AI chatbot” called Spark Desk for writing activities and AI feedback. However, the abstract does not specify whether Spark Desk is a large language model (e.g., transformer-based generative model like ChatGPT/GPT-4). Without confirmation that Spark Desk is LLM-based, it is unclear if this meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is argumentative writing in an EFL classroom. The chatbot is integrated into writing activities, and outcomes include critical thinking skills in argumentative writing and intrinsic motivation related to writing. The focus is pedagogical, not automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""A pretest–posttest quasi-experimental design with control group is used. CTS in argumentative writing is measured with the Illinois Critical Thinking Essay Scoring Rubric, and intrinsic motivation is measured with the Intrinsic Motivation Inventory. Quade’s test reports significant improvements, providing quantifiable outcome metrics.""
    }
}"
217,Efl Student Engagement with Chatgpt in College Reading Classes Via Prompts and Perceptions,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL university freshmen in college English classes, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines EFL students’ interactions with ChatGPT, an LLM, in a college English class. Although mainly exploratory, it integrates ChatGPT into classroom activities and analyzes prompt types and usage over time.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on prompting practices, interaction patterns, and perceptions in a reading class. Writing is mentioned only as one of several skills (reading, writing, vocabulary, grammar) supported by ChatGPT, without a clear focus on writing competence or a writing-specific intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study uses conversation logs, questionnaire data, and qualitative responses to analyze prompt types and perceptions, but does not measure changes in writing performance or related quantitative writing outcomes.""
    }
}"
218,Generative Ai–mediated Scaffolds for Enhanced Critical Thinking in Efl Writing,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL students in vocational colleges, indicating English is the target L2 in an EFL context: “enhancing critical thinking (CT) in English as a Foreign Language (EFL) writing instruction… across three vocational colleges, involving 92 students.”""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “Generative AI tools” and “GenAI-CT framework” and “AI interaction logs,” suggesting use of generative AI, but it does not specify that these are large language models (e.g., ChatGPT, GPT-4) as opposed to other generative systems. The nature of the tools (LLM-based vs other AI) is not clearly identified.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context is EFL writing instruction with “iterative writing and revision cycles” and student essays, but the primary reported outcomes are critical thinking (CT) dimensions. It is not explicit whether writing competence or writing-related performance (e.g., text quality) is a primary focus of the intervention and analysis, or if writing is mainly a vehicle to measure CT.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study reports “statistically significant gains across all CT dimensions (p<.001)” but does not state whether any quantitative writing outcome metrics (e.g., writing scores, rubric-based writing quality, accuracy, complexity) were measured. Outcomes appear centered on CT rather than writing performance per se.""
    }
}"
219,Teachers as End-user Developers: Two Case Studies of Adapting Language Models for Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions English as a foreign language and language education, implying possible EFL learners, but it does not clearly specify that the participants are L2 English learners or provide details on the learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on teachers as end-user developers adapting AI systems, contrasting a specialized AI-based writing tool (EssayCritic) with a customized chatbot (SchoolGPT). It does not clearly describe an experimental or quasi-experimental design integrating LLMs into writing instruction; rather, it examines EUD processes and system adaptation.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""EssayCritic is an AI-based writing tool providing feedback in EFL, suggesting a writing-related context, but the primary focus of the paper is on end-user development and adaptation of AI systems, not on writing competence or writing-related learning outcomes per se.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports that adaptable AI systems can help improve teaching methods and facilitate language learning, but it does not indicate any quantifiable writing outcome metrics or experimental measures of writing performance. The emphasis is on design, adaptation, and challenges, not on measured writing gains.""
    }
}"
220,"Chinese College Students’ Usage, Evaluation, Perception and Attitude Toward Generative Ai in English as a Foreign Language Writing",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese college students using generative AI tools in English as a Foreign Language (EFL) writing, which fits the L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a two-stage survey (interviews and questionnaire) about students’ usage, perceptions, and attitudes toward generative AI tools. There is no experimental or quasi-experimental design integrating LLMs as a structured instructional intervention; it is descriptive, not an intervention study.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context is EFL writing and AI-assisted writing, but the focus is on usage patterns, benefits, concerns, and attitudes rather than a pedagogical intervention targeting writing competence. It does not clearly implement or evaluate a specific writing instruction context using LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports survey data on agreement scores for perceived benefits and concerns, but no quantifiable writing performance outcomes (e.g., writing scores, quality measures) are reported. Outcomes are attitudinal and perceptual, not writing competence metrics.""
    }
}"
221,Reimagining Ai Integration: Vietnamese Efl Instructors’ Cultural Reconceptualization of the 6-p Framework,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 16 Vietnamese English as a Foreign Language (EFL) instructors working in Vietnamese universities, clearly situated in an EFL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study discusses integrating generative AI into academic writing instruction via the 6-P framework, it is a qualitative investigation of instructors’ cultural adaptation, using interviews, focus groups, and workshops. There is no experimental or quasi-experimental design testing an LLM-based intervention with learners, nor explicit mention of a specific LLM (e.g., ChatGPT) being implemented as an instructional tool in a measured way.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on instructors’ cultural reconceptualization of a framework for AI integration and related professional/institutional issues, not on empirically examining changes in learners’ writing competence or writing-related performance. It is a theoretical and pedagogical framing study rather than an intervention study on writing outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports only qualitative themes (cultural reconceptualization, authority anxieties, adaptation strategies, pedagogical double consciousness). It does not mention any quantifiable writing outcome metrics or measured changes in students’ writing performance resulting from LLM-mediated interventions.""
    }
}"
222,Exploring Feedback Literacy in L2 Students' Academic Writing: Insights from Their Reported Engagement with Genal for Typical Revision Activities,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are described as “16 L2 Chinese graduate students.” This indicates they are learning Chinese as an L2, not English. The review requires L2 English learners in ESL/EFL/ELL contexts with a focus on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study involves L2 writers’ engagement with GenAI tools such as DeepSeek and ChatGPT for grammar correction, linguistic refinement, and logical optimization in academic writing. These are LLM-based tools integrated into the revision process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is L2 academic writing, focusing on revision activities (grammar correction, refinement, coherence). The primary lens is feedback literacy in writing, which is writing-related.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports survey, interviews, and reflective reports about perceptions (cognitive, behavioral, affective, ethical dimensions). There is no mention of experimental or quasi-experimental design or quantifiable writing outcome metrics assessing effectiveness of the GenAI intervention.""
    }
}"
223,Predictors of Childhood Vaccination Uptake in England: an Explainable Machine Learning Analysis of Regional Data (2021-2024),2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study analyzes childhood vaccination coverage across districts in England using regional demographic and cultural variables. It does not involve L2 English learners in ESL/EFL/ELL instructional contexts; English proficiency appears only as a population-level predictor, not as a learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is an explainable machine learning analysis (CatBoost + SHAP) of vaccination data. There is no integration of large language models (e.g., ChatGPT, GPT-4) into any educational or writing-related intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is public health and vaccination uptake, not writing competence or writing-related variables. No writing instruction, writing process, or literacy intervention is described.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes are vaccination coverage prediction accuracy and identification of predictors. No writing outcomes or writing performance metrics are reported.""
    }
}"
224,Students’ Perceptions of Multiliteracies Development Using Ai-assisted Portfolio Assessment,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 50 freshmen students in an EFL classroom, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “Generative Artificial Intelligence (GenAI)” and “AI-generated feedback” but does not specify that the tools are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative models. The exact nature of the AI system is not described.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on multiliteracies and multimodal competence development in a GenAI-supported portfolio assessment context, not specifically on writing competence. Writing is one component of broader multimodal artefacts and multiliteracies, and the study centers on perceptions and developmental stages rather than writing-focused instruction or outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study employs a qualitative design using reflective journals, focus group interviews, and narrative inquiries, analyzed thematically. No quantifiable writing outcome metrics or experimental/quasi-experimental measures of writing performance are reported.""
    }
}"
225,Does Writing about Ai Detection Tools Benefit Ethical Conduct?,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are described as ‘first-year students’ who are ‘second-language speakers of English’ enrolled in a written communication course dedicated to scientific writing. This matches the target population of L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is an assignment about the accuracy of AI detection programs versus a control assignment on cognitive biases. Generative AI writing tools are present as a prohibited but voluntarily used resource, not as an instructional or experimentally integrated LLM-based writing intervention. The study does not design or implement an LLM-mediated pedagogical treatment.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on ethical conduct and the deterrent effect of an assignment about AI detection on students’ reliance on generative AI tools, not on improving writing competence or writing-related skills through LLM use. Writing is the context, but not the target of an LLM-based instructional intervention.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study reports assignment grades and differences between AI users and non-users, but these outcomes are not tied to a structured LLM-mediated writing intervention; rather, they reflect incidental, prohibited use. It is unclear whether these measures qualify as writing outcomes of an LLM-based pedagogical treatment as required by the review.""
    }
}"
226,Exploring the Use of Generative Ai on Students' Academic Writing: an Exploratory Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) learners, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “generative AI (GenAI)” but does not specify whether it is an LLM-based tool (e.g., ChatGPT, GPT-4) or another kind of generative system. However, even if it were an LLM, the design focuses on observing use patterns rather than a structured instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on students’ questioning behaviors, adoption of GenAI responses, and perceptions of usefulness and ease of use during a designed writing task. It does not describe a pedagogical writing intervention aimed at improving writing competence; rather, it is exploratory usage/behavior research.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, quality measures, accuracy, complexity) are reported. Outcomes concern question categories, utilization/modification of GenAI responses, and perceived usefulness/ease of use, not measured changes in writing performance.""
    }
}"
227,Generative Ai-powered Non-player Characters in Digital Storyline-based Learning: an Innovative Approach to Efl Writing,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as being in an EFL writing workshop, indicating they are English-as-a-foreign-language learners and the focus is on English writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that the study uses 'generative artificial intelligence (AI)' to power NPCs and enable dynamic interactions. However, it does not specify whether these generative AI NPCs are based on large language models (e.g., ChatGPT/GPT-like transformer models) or some other generative technique. Thus, it is unclear if an LLM is the core of the intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is an EFL writing workshop using digital storyline-based learning. The intervention is clearly embedded in writing instruction, and the activities are described as 'digital storyline-based writing activities,' indicating a primary focus on writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""Data sources include 'questionnaires, chat histories, essays, and interviews.' The findings emphasize increased situational interest, intrinsic motivation, and unchanged cognitive load. While the abstract claims the approach is essential for improving writing performance and mentions 'insights from students’ essays,' it does not clearly report or describe quantifiable writing outcome metrics (e.g., scores, rubric-based gains, error rates). It is therefore unclear whether writing performance was measured quantitatively as an outcome.""
    }
}"
228,From Clueless to Confident: How Chatgpt Transforms Academic Writing in Chinese as a Second Language,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are L2 Chinese learners using ChatGPT for academic writing in Chinese as a second language. The focus is on Chinese, not English (ESL/EFL/ELL), so the target population and language do not match the review’s scope.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines students’ use of ChatGPT (a large language model) in their L2 academic writing processes, clearly involving an LLM-based tool as part of writing activity.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 academic writing processes and how ChatGPT supports writing, including phases of self-regulated learning and GenAI-assisted writing, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly qualitative, using screenshots, written assignments, and interviews to explore usage patterns and perceptions. There is no indication of experimental or quasi-experimental design or quantifiable writing outcome metrics assessing effectiveness.""
    }
}"
229,Engaging Multimodal Literacy through Generative Artificial Intelligence: a Case Study from an English as Second Language Writing Classroom,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as two ESL students engaged in an English as a second language writing classroom, so the population is L2 English learners in an ESL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to ‘generative artificial intelligence (GenAI)’ and ‘AI-assisted multimodal writing’ but does not specify whether the GenAI tool is a large language model (e.g., ChatGPT, GPT-4) or another type of generative system (e.g., image generator only). The underlying model type is not identifiable from the abstract alone.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on multimodal literacy and metafunctions (ideational, interpersonal, textual) in AI-assisted multimodal storytelling and photo essays. The outcomes concern awareness of multimodality and the role of images, not writing competence or writing-related variables as the main focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a case study of two students, emphasizing how they focus on different metafunctions and self-report increased awareness. The abstract does not indicate any experimental or quasi-experimental design, nor does it report quantifiable writing outcome metrics; it appears primarily qualitative and descriptive.""
    }
}"
230,An Autoethnographic Study of Esl Academic Writing with Chatgpt: from Psychological Insights to the Super Framework,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract focuses on ESL higher education students (and specifically the author’s own experience as an ESL doctoral student and assistant professor) using ChatGPT for academic writing in English, fitting the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is an autoethnographic reflection on the author’s personal use of ChatGPT, not an experimental or quasi-experimental intervention. There is no structured instructional design, control/comparison, or systematic implementation of ChatGPT as a pedagogical intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly academic writing in ESL, and the paper discusses how ChatGPT is used in that writing process, including psychological aspects and a proposed framework for ethical and effective use in writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses autoethnographic and reflective thematic analysis of diaries, logs, and drafts, focusing on psychological needs and experiences. It does not report quantifiable writing outcome metrics or experimental measures of writing performance.""
    }
}"
231,Possibilities for Improving Esp Curriculum Design and Assessment Strategies for Saudi Universities with Chatgpt,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students in Saudi Arabian universities enrolled in ESP writing courses. The abstract explicitly states: “ESP writing courses for EFL students at Saudi Arabian universities,” indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is integrating ChatGPT, described as an AI-powered language model, into ESP writing courses. ChatGPT is a large language model, and the study examines its use in classroom settings, aligning with LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on ESP writing competence and related variables: “impact of integrating ChatGPT… into ESP writing courses,” aiming to improve “ESP writing skills” and reporting on writing performance, grammar, vocabulary, creativity, and critical thinking. This is a pedagogical writing intervention, not automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a mixed-methods design including “pre-and post-tests” and reports “significant improvements in students' writing proficiency, particularly in grammar accuracy, vocabulary enrichment, creativity, and critical thinking,” indicating quantifiable writing outcome measures.""
    }
}"
232,Exploring the Impact of Ai on Critical Thinking Development in Esl: a Systematic Literature Review,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on ESL learners and ESL writing, indicating that the population is English L2 learners in an ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a systematic literature review (SLR) of prior studies on AI and ESL, not an experimental or quasi-experimental primary study implementing an LLM-based intervention. It synthesizes findings from 15 articles rather than reporting an original LLM-integrated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The review examines AI’s influence on ESL learners’ critical thinking and writing skills, with explicit reference to ESL writing and AI-assisted learning, aligning with a writing-focused context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic literature review, it does not itself report original, quantifiable writing outcome metrics from an intervention; instead, it summarizes existing literature. Review articles are to be excluded.""
    }
}"
233,Unlocking Potential: Saudi Efl Male Students' Perspectives on Ai Tools for Enhancing English Writing Proficiency,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Saudi EFL male students from the Languages and Translation Department at a Saudi university, clearly positioning them as L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study explores students’ perceptions of unspecified ‘AI tools’ for writing via qualitative group interviews. There is no indication of an experimental or quasi-experimental design, nor explicit integration of a specific LLM (e.g., ChatGPT) as a structured instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on English writing proficiency and how AI tools affect students’ writing skills, including grammar, vocabulary, confidence, and cultural nuances in writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses qualitative methodology (group interviews, thematic analysis) to examine perceptions and challenges. It does not report quantifiable writing outcome metrics or experimental measures of writing improvement.""
    }
}"
234,Enhancing or Impairing? Exploring Indian Efl Learners’ Academic Writing Narratives with Chatgpt,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Indian English as a Foreign Language (EFL) learners, which fits the ESL/EFL/ELL population focus on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is qualitative and based on semi-structured interviews with learners who have used ChatGPT informally for over a year. There is no indication of an experimental or quasi-experimental design, nor a structured LLM-based instructional intervention implemented by the researchers.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on academic writing, including writing fluency, confidence, and cognitive engagement in writing, and on integrating ChatGPT into English language pedagogy, which aligns with writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study employs a qualitative design using thematic analysis of interviews and reports perceptions and narratives. It does not mention any quantifiable writing outcome metrics or experimental measures of writing performance.""
    }
}"
235,Integrating Large Language Models with Corpus-based Language Pedagogy: an Approach to Collocation Use in L2 Writing Instruction,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 70 sophomore students learning lexical collocations in English writing. The context is clearly L2 English writing instruction, consistent with EFL/ESL/ELL settings, and the focus is on English as the target language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly integrates large language models (LLMs) into instruction via the Corpus-Based Language Pedagogy with Large Language Models (CBLP-LLM). It uses an experimental design with an experimental group receiving CBLP-LLM instruction and a control group receiving traditional corpus-based instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 writing instruction, specifically teaching lexical collocations in English writing. Outcomes include writing performance and lexical quality, indicating a clear emphasis on writing competence rather than automated scoring or non-pedagogical evaluation of LLMs.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes: significant improvements in writing performance, lexical quality, motivational beliefs, and reduced cognitive load, measured pre-, post-, and at one-month follow-up. These constitute experimental measures of writing-related outcomes in an LLM-mediated intervention.""
    }
}"
236,Exploring the Use of Chatbots in Efl Argumentative Writing: from the Perspective of Dynamic Assessment,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 49 Chinese English as a foreign language (EFL) undergraduate students, clearly indicating L2 English learners in an EFL context with a focus on English argumentative writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses “chatbots” (CA-DA and CA-NDA) in writing assessment/mediation, but the abstract does not specify whether these chatbots are LLM-based (e.g., ChatGPT/GPT-4) or rule-based/other AI. Without explicit mention of LLMs or transformer-based generative models, it is unclear if the tools meet the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on chatbot-assisted dynamic and non-dynamic assessment of argumentative writing and reports on learners’ argumentative writing performance and perceptions, indicating a primary focus on writing competence and writing-related variables in a pedagogical context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines the effects of CA-DA and CA-NDA on learners’ argumentative writing performance using data from an argumentative essay writing test, implying quantifiable writing outcome metrics comparing groups.""
    }
}"
237,Enhancing the Retrieval and Application of English Teaching Resources through Artificial Intelligence Technology as Computational Creativity in Short Story Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as Indonesian EFL undergraduate students in a computer science faculty, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to AI, conversational AI chatbots, and an 'AI story' tool, but does not specify that these are large language model–based systems (e.g., ChatGPT, GPT-4). The primary method appears to be a survey of perceptions rather than an experimental or quasi-experimental intervention design.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on how educators implement AI and on students’ emotions, challenges, and needs regarding AI use. While creative writing and academic writing are mentioned, the study is positioned as an exploration of implementation, policy, and training needs, not as a structured writing intervention evaluating writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports survey findings about emotions, engagement, perceived benefits, and challenges. There is no indication of quantifiable writing outcome metrics (e.g., writing scores, text quality measures) used to assess the effectiveness of AI-mediated writing interventions.""
    }
}"
238,"Bridging Ai and Pedagogy: How Ai-adaptive Feedback Shapes Chinese Efl Students’ Writing Engagement, Metacognitive Writing Strategies, and Writing Performance",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese university EFL learners, clearly indicating L2 English learners in an EFL context. The focus is on EFL writing performance, which implies English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract refers to 'AI-adaptive feedback' and 'AI-enhanced adaptive feedback' but does not specify that the system is based on a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model). It could be any AI-driven adaptive system. Without explicit indication of LLM use, it does not meet the LLM-specific intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is situated in EFL writing pedagogy and examines effects on writing engagement, metacognitive writing strategies, and writing performance, which are all writing-related variables in an instructional context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports quantifiable writing outcomes, including writing performance and structural equation modeling coefficients (e.g., β = 0.32 for writing performance), indicating measurable effects of the AI-adaptive feedback on writing.""
    }
}"
239,"Writing with Ai, Thinking with Toulmin: Metacognitive Gaps and the Rhetorical Limits of Argumentation",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Indonesian EFL undergraduates (“Indonesian EFL settings… 30 final-year students”), so they are L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students report using AI tools such as Grammarly and ChatGPT, the study is described as an exploratory mixed-methods investigation that ‘examined’ argumentative quality, metacognitive competence, and AI literacy. There is no indication of an experimental or quasi-experimental LLM-based instructional intervention or structured integration of ChatGPT into teaching; AI use is observed/self-reported rather than manipulated pedagogically.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on argumentative writing quality in EFL settings and how it relates to metacognition and AI literacy in ‘AI-assisted argumentative writing,’ which is clearly writing-focused rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""While the study reports quantitative measures (e.g., Toulmin element scores, MAI scores, AI literacy questionnaire), these are used to map existing abilities and gaps, not to evaluate the effectiveness of an LLM-mediated writing intervention. There is no pre/post or comparative outcome tied to a specific LLM-based instructional treatment.""
    }
}"
240,"Unmasking the Impacts of Self-evaluation in Ai-supported Writing Instruction on Efl Learners’ Emotion Regulation, Self-competence, Motivation, and Writing Achievement",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as pre-intermediate EFL learners at a high school in Iran, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that the experimental group received AI-supported writing instruction and refers to ‘AI tools’ but does not specify whether these are large language models (e.g., ChatGPT, GPT-4) or other non-LLM tools (e.g., grammar checkers). Without explicit mention of LLM-based tools or generative transformer models, it is unclear if the intervention meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL writing instruction, and the intervention is ‘AI-supported writing instruction’ with self-evaluation. One of the main outcomes is ‘writing achievement,’ indicating a primary focus on writing competence rather than only assessment or non-writing skills.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental pretest–posttest design and reports standardized writing assessments as one of the outcome measures, with statistical analyses (Chi-square tests and t-tests) showing that the experimental group outperformed the control group in writing achievement. This satisfies the requirement for quantifiable writing outcome metrics.""
    }
}"
241,Engagements with Gpt Responses and Learner Prompts in Chatgpt-based Learning of English Argumentative Writing Logic and Their Impacts,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 42 Chinese university students learning English as a foreign language (EFL). The focus is explicitly on English argumentative writing logic, so the target language is English in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study developed a discipline-specific GPT-4-powered chatbot (ChatGPT-based) for learning English argumentative writing logic. Learners used this LLM-based tool as part of an instructional intervention, indicating an experimental design integrating an LLM into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on English argumentative writing logic, a core component of writing competence. The intervention is framed as ChatGPT-based learning of English argumentative writing logic, not as automated scoring or system evaluation, but as a pedagogical tool.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Learning outcomes were assessed via pre-post-delayed tests and pre-post writing tasks, providing quantifiable measures of changes in writing-related performance (logic knowledge and writing logic). Thus, the study reports experimental outcome metrics for the LLM-mediated writing intervention.""
    }
}"
242,Enhancing Writing Skills through Ai-powered Tools: Perceived Benefits and Challenges among Vietnamese Efl Students,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are English-majored Vietnamese students in EFL classes at a university in Vietnam, clearly fitting an EFL/ESL/ELL L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students use AI tools such as ChatGPT, QuillBot, and Claude, the study is observational and perception-based. There is no experimental or quasi-experimental design integrating LLMs as a structured writing intervention; AI use is self-initiated and surveyed, not manipulated as an instructional treatment.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on enhancing writing skills in EFL classes and on how AI tools are used across stages of the writing process, addressing writing-related variables rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are students’ perceived benefits and challenges and a correlation between frequency of AI use and perceived writing benefits. There are no objective or quantifiable writing performance measures (e.g., scores, text quality metrics) assessing the effectiveness of an LLM-mediated intervention.""
    }
}"
243,Academic Socialization with Generative Ai: a Longitudinal Case Study of an L2 Graduate Student's Academic Literacies Development,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participant is described as an international, English as a Second Language (ESL) graduate student using English in an academic context, which fits the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study involves the use of ChatGPT (an LLM), it is a longitudinal case study of naturally occurring use, not an experimental or quasi-experimental intervention design integrating LLMs into instruction. There is no structured pedagogical treatment or controlled intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing is one of several foci (reading and writing support, exploring genres, navigating disciplinary expectations, generating research ideas). The primary framing is academic discourse socialization and academic literacies more broadly, not specifically a writing competence intervention, and no explicit instructional context is described.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative outcomes such as research interest, genre knowledge, disciplinary identity, and confidence. It does not mention any quantifiable writing outcome metrics or experimental measures of writing performance.""
    }
}"
244,Evaluating the Potential of Chatgpt-reformulated Essays as Written Feedback in L2 Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses 1,200 argumentative essays written for the TOEFL iBT independent writing task, which are produced by L2 English learners. The focus is clearly on second language (L2) English writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used to reformulate learner essays, the design is not an experimental or quasi-experimental pedagogical intervention with learners. It is a system-focused evaluation of ChatGPT’s reformulations and prompt types, not an instructional treatment applied to participants’ writing processes or instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on evaluating the properties of ChatGPT-generated reformulations (meaning retention, linguistic development, cohesion) and comparing prompt types. There is no implemented teaching/learning context or writing instruction intervention; the discussion of how reformulations could be used pedagogically is speculative rather than part of the study design.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports quantitative metrics (ROUGE-L, syntactic complexity, lexical sophistication, etc.) but these are applied to ChatGPT outputs versus original essays, not to measure changes in learners’ writing following an LLM-mediated intervention. No learner outcome or pre–post writing performance is assessed.""
    }
}"
245,"The Role of Techno-competence in Ai-based Assessments: Exploring Its Influence on Students’ Boredom, Self-esteem, and Writing Development",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 66 Saudi Arabian male EFL learners, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “AI-driven evaluations” and “AI-enhanced assessments” but does not specify that the AI is a large language model (e.g., ChatGPT, GPT-4) or a transformer-based generative model. It could be any AI-based assessment tool, not necessarily an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing skills/proficiency is one of the primary outcome variables, and the intervention is situated in language assessment with a focus on writing development, which aligns with writing-related competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although pre- and post-assessments of writing proficiency are mentioned, the intervention is AI-based assessment in general, not clearly an LLM-mediated writing intervention. Because the nature of the AI tool (LLM vs. non-LLM) is unspecified, it does not meet the review’s requirement for LLM-mediated writing outcomes.""
    }
}"
246,Predictors of Childhood Vaccination Uptake in England: an Explainable Machine Learning Analysis of Regional Data (2021–2024),2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study analyzes childhood vaccination coverage across districts in England using regional demographic and cultural variables. It does not involve L2 English learners in ESL/EFL/ELL educational contexts; English proficiency appears only as a population-level predictor, not as a learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is a public health data analysis using CatBoost and SHAP for explainable machine learning. There is no educational intervention, no language instruction, and no integration of large language models (e.g., ChatGPT, GPT-4) into any learning or writing process.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is public health and vaccination uptake, not writing competence or writing-related variables. No writing instruction, tasks, or assessment are mentioned.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes are vaccination coverage prediction accuracy and identification of predictors via SHAP. There are no writing outcome metrics or measures of writing performance or development.""
    }
}"
247,Tracking the Effects of Gemini as a Genai Tool on L2 Learners' Writing Proficiency and Anxiety: Latent Growth Curve Modeling Approach,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 274 undergraduate English learners in Iran enrolled in academic writing classes. The context is clearly L2 English (EFL) at a public university, and the focus is on English writing proficiency and anxiety.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses Gemini, explicitly described as a generative AI (GenAI) tool, in a treatment group receiving GenAI-assisted instruction versus a control group with traditional instruction. Gemini is a large language model, and the design is experimental with random assignment over a 16-week course.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 writing competence and related affective variables: writing proficiency and writing anxiety in academic writing classes. Gemini is integrated into writing instruction, not just for scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantifiable writing outcomes are reported: writing proficiency measured via a standardized rubric-based assessment, and writing anxiety via an L2 writing anxiety scale. The abstract reports statistical results (MD, SE, CR, p-values) for changes in these outcomes.""
    }
}"
248,Exploring Factors Influencing L2 Learners' Use of Gai-assisted Writing Technology: Based on the Utaut Model,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The participants are 419 graduate students in China, described as L2 learners using GAI in second language writing. It is highly likely they are L2 English learners, but the target language is not explicitly stated in the title or abstract.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is framed with the UTAUT model and investigates factors influencing learners’ usage behavior of GAI. It examines acceptance and use (behavioral intention, facilitating conditions) rather than implementing an experimental or quasi-experimental LLM-based writing intervention. No specific LLM tool or instructional treatment is described.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is L2 writing and GAI, the primary focus is on technology acceptance and usage behavior (PE, EE, SI, BI, FCs, AU), not on writing competence or writing-related performance variables. It is a technology adoption study rather than a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are behavioral intention and actual usage behavior, moderated by gender, experience, and proficiency. There are no quantifiable writing outcome metrics (e.g., writing quality scores, complexity, accuracy, fluency) assessing the effectiveness of GAI-mediated writing intervention.""
    }
}"
249,Exploring Second Language Writers' Engagement with Chatgpt Feedback: Revision Behaviors and Perceptions,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 25 B1-level English as a Foreign Language (EFL) university students in Türkiye, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""ChatGPT (an LLM) is used as a feedback tool on students’ opinion essays, but the abstract does not specify an experimental or quasi-experimental design (e.g., control group, pre-post comparison, or structured intervention beyond a single use). It focuses on exploring engagement with feedback rather than testing an instructional intervention’s effectiveness.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on L2 writing (opinion essays) and how students engage with ChatGPT-generated feedback on content, organization, and language use—clearly centered on writing competence and writing-related processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Data sources include essay drafts, change tracker sheets, a questionnaire, and interviews. The analyses are described as descriptive and thematic, focusing on types of revisions, acceptance/rejection of feedback, and perceptions. There is no indication of quantifiable writing outcome metrics (e.g., pre-post writing scores, rubric-based gains) used to assess effectiveness of the LLM-mediated intervention.""
    }
}"
250,Using Chatgpt to Bring Non-player Characters to Life: Effects on Students' Storyline-driven Game-based Writing Learning,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese undergraduate students in English as a Foreign Language (EFL) writing classrooms, clearly indicating L2 English learners in an EFL context with a focus on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study integrates ChatGPT, an LLM, into a game-based learning environment via ChatGPT-powered NPCs. It uses a quasi-experimental design comparing a ChatGPT condition with a conventional NPC condition, constituting an LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL writing classrooms, with the game designed to enhance argumentative writing skills. The primary focus is on writing learning and writing performance, not on automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Student essays were evaluated to compare writing performance across conditions, and results report superior writing performance (clarity, elaboration, persuasiveness, addressing opposing viewpoints) in the ChatGPT condition, providing quantifiable writing outcome metrics.""
    }
}"
251,Chinese Efl Learners' Genai Literacy in Digital Multimodal Composing and Self-regulated Writing: Chain Mediation Effects of Needs Satisfaction and Creative Self-concept,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 634 Chinese EFL learners, which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines students’ GenAI literacy in digital multimodal composing via questionnaires and structural equation modeling. There is no indication of an experimental or quasi-experimental pedagogical intervention where LLMs (e.g., ChatGPT) are integrated into writing instruction or processes; rather, it is a correlational/mediation study of literacy and psychological variables.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on GenAI literacy, needs satisfaction, creative self-concept, and self-regulated writing, not on a concrete LLM-mediated writing intervention or instructional context. Writing competence is only indirectly referenced, and no specific LLM-based writing activity or instructional design is described.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are self-report questionnaire measures (GenAI literacy, needs satisfaction, creative self-concept, self-regulated writing). The abstract does not report any quantifiable writing performance metrics (e.g., text quality, accuracy, complexity) resulting from an LLM-mediated intervention.""
    }
}"
252,Exploring the Effectiveness of a Ddl-genai Teaching Mode in Students' Efl Writing Classroom,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 75 second-year Chinese university students in an EFL writing classroom, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract describes an innovative teaching mode integrating Data-Driven Learning with Generative Artificial Intelligence (GenAI), and mentions a separate GenAI class. However, it does not specify whether the GenAI tools are large language models (e.g., ChatGPT/GPT-like transformer-based generators) or other forms of AI. Without explicit mention of LLM-based tools, it is unclear if the intervention meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL expository writing performance and related variables (structure, content quality, efficiency, classroom engagement) within a writing classroom, indicating a pedagogical writing intervention rather than automated scoring or non-instructional evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental design with three instructional modes and reports that the DDL-GenAI mode significantly improved students’ writing performance, including specific aspects such as structure and content quality, indicating quantifiable writing outcome measures.""
    }
}"
253,Students' Perceptions of Multiliteracies Development Using Ai-assisted Portfolio Assessment,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 50 freshmen students in an EFL classroom, indicating L2 English learners in an EFL context. The portfolios involve multimodal writing about touring route recommendations, implying English as the target language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is set in a “GenAI-supported portfolio assessment classroom” where students revise artefacts based on “AI-generated feedback.” Although the specific tool is not named, it is described as Generative AI, which reasonably implies an LLM-based system integrated into the writing/portfolio process.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on multiliteracies, multimodal competence, and portfolio-based formative assessment, not specifically on writing competence or writing-related variables as primary outcomes. The abstract emphasizes multiliteracies development, metacognitive development, and professional growth rather than writing proficiency.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study employs a qualitative design, collecting reflective journals, focus group interviews, and narrative inquiries, analyzed thematically. No quantifiable writing outcome metrics or experimental comparison are reported; outcomes are described qualitatively (e.g., stages of multiliteracies development, confidence, awareness).""
    }
}"
254,"Impacts of Genai-assisted Collaborative Prewriting on University Efl Students' Interactions with Genai, Outline Quality, and Task Motivation",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were sixty-nine Chinese undergraduates in an English as a foreign language (EFL) writing context, clearly indicating L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study integrates a generative AI (GenAI) tool—i.e., an LLM-based system—into prewriting instruction via GenAI-assisted collaborative and individual prewriting, using a within-subjects comparative design.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary outcome is the quality of prewriting outlines (content, organization, language) and task motivation, not actual writing performance. The focus is on prewriting/planning and interaction with GenAI rather than on writing competence or writing-related performance measures (e.g., essay quality).""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantitative outcomes are reported for outline quality and task motivation, but no quantifiable metrics of written text (e.g., essays, compositions) are provided. The intervention outcomes do not include measurable L2 writing performance, which is required for inclusion.""
    }
}"
255,"The Role of Generative Ai in Writing Doctoral Dissertation: Perceived Opportunities, Challenges, and Facilitating Strategies to Promote Human Agency",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly situates the work in ESL and EFL academic writing contexts and involves doctoral scholars and thesis supervisors, implying participants are L2 English users in higher education.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study concerns GenAI-assisted dissertation writing, it is framed as an exploration of perceived usefulness and use, grounded in the Technology Acceptance Model. There is no indication of an experimental or quasi-experimental instructional intervention integrating a specific LLM into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on perceived opportunities, challenges, and human agency in GenAI-assisted dissertation writing, not on a structured pedagogical intervention targeting writing competence. It is more about attitudes and conceptual discussion than a writing-focused instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as qualitative, using survey and test data to explore perceptions. No quantifiable writing outcome metrics (e.g., writing scores, text quality measures) assessing the effectiveness of GenAI-mediated writing intervention are reported in the abstract.""
    }
}"
256,Evaluating Chatgpt's Effectiveness in Enhancing Argumentative Writing: a Quasi-experimental Study of Efl Learners in Pakistan,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Pakistani students pursuing the Secondary School Certificate in an English as a Foreign Language (EFL) environment. The study explicitly focuses on English argumentative writing skills, satisfying the L2 English learner population requirement.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study evaluates the effectiveness of ChatGPT, explicitly identified as an artificial intelligence tool, in improving argumentative writing. It uses a quasi-experimental design with three months of ChatGPT interaction as the intervention, aligning with LLM-based writing instruction criteria.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on argumentative writing competence, including key components of argumentative writing and error types. ChatGPT is integrated as a pedagogical tool to enhance writing skills, not merely as an assessment engine.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pre- and post-tests to measure changes in students' argumentative writing abilities and reports significant progress and decreased error types after the ChatGPT intervention, providing quantifiable writing outcome metrics.""
    }
}"
257,Assessing the Reliability and Relevance of Deepseek in Efl Writing Evaluation: a Generalizability Theory Approach,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners: 92 CET-4 essays written by non-English majors at a Chinese university. The focus is clearly on English as a foreign language writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""DeepSeek-V3 and DeepSeek-R1 are used as automated raters to assess reliability of holistic scores and qualitative feedback, compared with teacher raters. There is no experimental or quasi-experimental instructional intervention integrating LLMs into writing instruction or writing processes; the focus is on assessment reliability.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on writing assessment reliability and feedback relevance (G-theory analysis of scores and feedback), not on a pedagogical intervention to improve writing competence. It functions as an automated essay scoring/feedback evaluation study, which falls under the exclusion criteria.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No writing outcome metrics for learners are reported. The study analyzes reliability coefficients and relevance of feedback, but does not measure changes in learners’ writing performance following an LLM-mediated intervention.""
    }
}"
258,Ai Partner Versus Human Partner: Comparing Ai-based Peer Assessment with Human-generated Peer Assessment in Examining Writing Skills,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL college students from the University of Diyala (Iraq) and the University of Hradec Kralove (Czech Republic). The abstract explicitly states the focus is on improving EFL college students’ writing skills, indicating L2 English learners in EFL/ESL contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention contrasts traditional peer assessment (group A) with AI-based assessment using ChatGPT (group B). ChatGPT is a large language model integrated into the peer assessment process, constituting an LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing skills and how different feedback mechanisms (human vs. AI-based via ChatGPT) affect EFL students’ writing. The context is clearly pedagogical, centered on peer assessment to improve writing competence rather than automated scoring alone.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: final writing scores for group A (7–14/15) and group B (6–12/15), and notes comparative improvement in writing skills. These numeric scores provide measurable writing outcome metrics for evaluating the LLM-mediated intervention.""
    }
}"
259,"Integrating Flipped Learning in Ai-enhanced Language Learning: Mapping the Effects on Metacognitive Awareness, Writing Development, and Foreign Language Learning Boredom",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 70 intermediate Iranian EFL learners, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract repeatedly refers to an “AI-enhanced” flipped learning environment and “AI-enhanced instruction,” but does not specify the AI tool or whether it is an LLM (e.g., ChatGPT, GPT-4) versus other forms of AI (e.g., analytics, non-LLM feedback tools). Thus, it is not possible to confirm that an LLM is integrated into the writing instruction or process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""Among the key variables examined is “writing development,” and pre- and post-intervention writing tasks are used, indicating that writing competence is a primary focus alongside metacognitive awareness and boredom.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pre- and post-intervention writing tasks and analyzes inter-group differences via ANCOVA, implying quantifiable writing outcome metrics to assess the impact of the AI-enhanced flipped learning intervention on writing development.""
    }
}"
260,Exploring Teacher Perspectives on Gpt in L2 Disciplinary Academic Writing through the Lens of Feedback Literacy: a Q-methodology Approach,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The participants are 27 L2 university instructors, not L2 English learners. The focus is on teacher perspectives and feedback literacy, not on learner outcomes or learner data.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although GPT/LLMs are discussed, the study is not an experimental or quasi-experimental intervention integrating LLMs into learners’ writing processes. It is a Q-methodology study of teacher perspectives, without an instructional treatment using LLMs.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context is L2 disciplinary academic writing education and feedback practices, but the study examines perceptions and ethical/pedagogical considerations rather than a concrete writing intervention or measured changes in writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study uses Q-sorts and interviews to capture subjective teacher perspectives, without assessing changes in student writing performance.""
    }
}"
261,Chatwell: an Ai-enabled Adaptive Tutoring System for Improving Mandarin Composition Skills in L2 Students with Learning Difficulties,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are HSK4 learners working on Mandarin (Chinese) composition skills. The focus is on L2 Chinese, not L2 English, and the abstract does not indicate that English is the target language. The review requires L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study develops CHATWELL, described as an intelligent tutoring platform that incorporates optimised large language models to provide writing assistance. It uses a 12-week quasi-experimental design comparing this LLM-based system to a Bi-LSTM-based AES.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on improving Mandarin composition skills and writing capabilities, with outcomes such as writing scores, grammatical and logical errors, and self-regulated learning. This aligns with writing competence as the central context rather than mere automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: score gains (14.2 vs. 6.8 points, with statistical test results), reductions in grammatical and logical errors, and accessibility metrics. These provide measurable effects of the LLM-mediated writing intervention.""
    }
}"
262,A Duoethnographic Study of Writing-with as a Mode of Efl Teacher Professional Development Practice in the Age of Ai,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The participants are EFL teachers engaged in professional development, not L2 English learners in ESL/EFL/ELL contexts. The focus is on teacher reflection and professional development rather than learner writing outcomes.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT is mentioned, it is discussed as part of teachers’ reflective practice and experiences with digital tools, not as an experimental or quasi-experimental LLM-based writing instruction intervention for learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on teacher professional development, reflection, and ethical inquiry, not on writing competence or writing-related variables for L2 learners. Writing is framed as a mode of reflection, not as a target of instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is duoethnographic and qualitative, centering on reflective episodes and themes such as emotional labor and pedagogical ambivalence. It does not report quantifiable writing outcome metrics or experimental measures of LLM-mediated writing interventions.""
    }
}"
263,Algorithmic Feedback and Multilingual Identity: Translanguaging Practices in Jordanian Efl Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as multilingual EFL students in a Jordanian university, i.e., L2 English learners in an EFL context. The focus is on English academic writing, with translanguaging between Arabic and English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “AI-mediated writing support” and “algorithmic feedback systems” but does not specify that these are large language models (e.g., ChatGPT, GPT-4) as opposed to other AI tools (e.g., grammar checkers). The underlying technology is not identified.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly academic writing: the study examines how students respond to AI-mediated writing support, focusing on translanguaging practices, personal voice, and ownership of writing. The primary focus is on writing practices and pedagogy, not on automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly described as a qualitative multi-case design using interviews, observations, writing samples, AI-generated feedback, and journals. The abstract reports no experimental or quasi-experimental design and no quantifiable writing outcome metrics; it focuses on practices, agency, and identity rather than measured changes in writing performance.""
    }
}"
264,Optimizing Self-regulated Learning: a Mixed-methods Study on Gai's Impact on Undergraduate Task Strategies and Metacognition,2025,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are 40 undergraduate students in Eastern China engaged in L2 writing. It is highly likely they are EFL learners writing in English, but the abstract does not explicitly state that the target language is English; it only refers to “second language (L2) writing” and “L2 writing contexts.”""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a “GAI chatbot tool” on the Tongyi.ai platform as the core intervention, compared with a control group using traditional resources, over an 8‑week intervention. Tongyi.ai is a generative AI chatbot (LLM-based), and it is integrated into the learning process as an instructional tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly L2 writing and self-regulated learning. Outcomes include writing performance and writing-related processes (task strategies, metacognitive awareness) in L2 writing. The focus is pedagogical, not on automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative analysis showing that the experimental group improved more than the control group in writing performance, alongside task strategy diversity and metacognitive awareness. Writing performance assessments constitute quantifiable writing outcome metrics.""
    }
}"
265,Is Generative Ai Ready to Replace Human Raters in Scoring Efl Writing? Comparison of Human and Automated Essay Evaluation,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are English as a Foreign Language (EFL) learners: 35 undergraduate students producing 210 essays. The context is clearly L2 English writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Generative AI is used as an Automated Essay Scoring (AES) system to rate existing essays, not as part of an instructional or experimental intervention in the writing process. There is no LLM-mediated teaching or practice component.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on comparing human and GenAI scoring reliability and correlations, i.e., assessment functionality. There is no pedagogical writing intervention or instructional context; it is an evaluation of an automated scoring tool.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports rubric-based scores from human raters and GenAI, but these are not outcomes of an LLM-mediated writing intervention. No experimental manipulation of writing instruction or process is conducted, so there are no intervention effectiveness metrics.""
    }
}"
266,Formally Integrating Generative Ai into Secondary Education: Application of Chatgpt in Efl Writing Instruction,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 99 Grade-10 students in a Hong Kong secondary school enrolled in a compulsory English as a foreign language (EFL) writing course. The focus is explicitly on EFL (English) learners in a school context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is a quasi-experiment integrating ChatGPT, a generative AI large language model, into EFL writing instruction. The treatment group used ChatGPT as the tool for EFL writing instruction, while the control group used conventional media.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is a compulsory EFL writing course, and the intervention is explicitly described as ChatGPT-supported EFL writing instruction. The primary focus is on writing instruction and performance, not on automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative outcomes: analysis of participants’ EFL writing performance at the end of the experiment, comparison between treatment and control groups, and interaction effects with baseline proficiency. These are measurable writing outcome metrics.""
    }
}"
267,Efl Lecturers’ Experiences and Perceptions towards Using Chatgpt in Teaching Writing: a Case Study in Vietnam,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL in Vietnam, and the abstract explicitly mentions EFL lecturers and their students’ writing classes, indicating L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used in writing instruction, the study is a qualitative case study of lecturers’ experiences and perceptions, not an experimental or quasi-experimental intervention study with controlled conditions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on using ChatGPT in teaching writing, including its use at pre-, while-, and post-writing stages, clearly centering on writing competence and writing-related pedagogy rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses semi-structured interviews and a qualitative case study design, reporting perceptions, experiences, and recommendations. No quantifiable writing outcome metrics or experimental measures of writing performance are mentioned.""
    }
}"
268,Tame the Beast of Chatgpt: Developing Design Principles to Strategically Integrate Chatgpt into Efl Writing through an Activity Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as four Chinese EFL writers, clearly indicating L2 English learners in an EFL context, with a focus on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly focuses on ChatGPT-assisted EFL writing and develops an intervention with design principles to guide ChatGPT-assisted writing, indicating integration of an LLM into writing processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing, and the study aims to integrate ChatGPT into EFL writing and develop design principles for writing instruction, so the primary focus is on writing competence and writing-related processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes a design-based research study using screen recordings and interviews, analyzed via Reflexive Thematic Analysis, to derive design principles and strategies. It does not mention any quantitative or experimental writing outcome measures (e.g., scores, quality ratings, accuracy gains). Outcomes are conceptual/design rather than quantifiable writing performance metrics.""
    }
}"
269,Artificial Intelligence-supported Procedural Scaffolding for Promoting Efl Learners’ Writing Performance in Flipped Peer Assessment Activities,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners: 74 university students in English writing classes in Taiwan. The focus is clearly on English as a Foreign Language writing performance.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract describes an “AI-based Procedural Scaffolding Peer Assessment (AI-PSPA) system” but does not specify the underlying AI technology. It is unclear whether this system is powered by a large language model (e.g., ChatGPT/GPT-like transformer-based generative model) or by other non-LLM AI (e.g., rule-based or traditional NLP).""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL learners’ writing performance in a flipped peer assessment context. The intervention is integrated into writing instruction and peer assessment, not just automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental design with pre- and posttests of writing performance and reports quantitative outcomes (e.g., writing accuracy) analyzed via t-tests and ANCOVA, satisfying the requirement for quantifiable writing outcome metrics.""
    }
}"
270,University Students' Acceptance of Chatgpt as a Writing Assistance Tool in Esl and Esp Studies,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are ESL and ESP students at two universities in Lithuania and Ukraine, clearly indicating L2 English learners in ESL/ESP contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is the focus, the study is not an experimental or quasi-experimental intervention. It examines perceptions and acceptance using a TAM-based questionnaire in a non-mandatory use context, not a structured instructional intervention integrating ChatGPT into writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is technology acceptance (perceptions and willingness to use ChatGPT) rather than writing competence or writing-related performance variables. Writing is only the task context for acceptance, not the main outcome of interest.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports only quantitative survey data on acceptance factors. It does not mention any quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity) resulting from ChatGPT use or an intervention.""
    }
}"
271,Ai Vs. Teacher Feedback on Efl Argumentative Writing: a Quantitative Study,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 60 undergraduate students in a writing-focused EFL course in Jordan. The abstract explicitly refers to them as English as a Foreign Language (EFL) learners, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study compares AI-generated feedback with teacher-generated feedback on students’ argumentative writing. The discussion explicitly mentions large language models (LLMs) as the AI source, indicating an LLM-based intervention integrated into the writing process in a quasi-experimental pretest–posttest design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on argumentative writing performance in an EFL writing course. The intervention is feedback on students’ essays and subsequent revision, directly targeting writing competence rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing outcomes are quantitatively measured using an analytic rubric with pre- and post-test scores analyzed for gains. Results report significant improvement in writing performance and effect sizes, satisfying the requirement for quantifiable writing outcome metrics.""
    }
}"
272,Ai-driven Corrective Feedback for Low-proficiency Learners: a Study on Writing Skill Development,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract focuses on low-proficiency second language (L2) learners working on writing in a second language context. While it does not explicitly say ‘English’, the context, terminology, and typical Springer L2 writing research strongly suggest L2 English learners. No other target language is mentioned, and the constructs (grammar, vocabulary, coherence, task achievement) align with common EFL/ESL writing assessment dimensions.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is ‘AI-driven corrective feedback, specifically utilizing ChatGPT’. ChatGPT is a large language model. A quasi-experimental design with a 10-week intervention and iterative writing tasks using real-time feedback from ChatGPT clearly integrates an LLM into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on ‘writing skill development’ and ‘improving the writing skills’ of L2 learners. The intervention targets grammatical accuracy, vocabulary, sentence structure, coherence, and task achievement in writing, which are core writing competence variables, not just automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports ‘statistically significant improvements across all five assessed components of writing: grammar, vocabulary, sentence structure, coherence, and task achievement.’ These are quantifiable outcome measures used to assess the effectiveness of the ChatGPT-mediated writing intervention.""
    }
}"
273,Assessing Ai Literacy in Second Language Writing: a Scale Development and Validation Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are university-level English as a Foreign Language (EFL) learners in China, clearly an L2 English population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on developing and validating the AI Literacy in L2 Writing Scale (AIL-L2WS). It does not describe an experimental or quasi-experimental pedagogical intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes; rather, it measures literacy regarding AI tools in general.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is L2 writing, the primary focus is on constructing a scale of AI literacy (understanding, ethics, attitudes, self-efficacy), not on implementing or evaluating a writing intervention or instructional use of LLMs to improve writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports psychometric properties (EFA, CFA, reliability, validity) of a literacy scale, not quantifiable writing outcome metrics (e.g., writing quality scores, complexity, accuracy, fluency) resulting from an LLM-mediated writing intervention.""
    }
}"
274,On the Role of Engagement in Automated Feedback Effectiveness: Insights from Keystroke Logging,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were N = 453 English-as-a-foreign-language (EFL) learners (mean age 16.11). The abstract explicitly states an EFL context and the writing tasks are in English, satisfying the L2 English learner population requirement.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is a classroom experiment where learners received feedback generated by a large language model (GPT‑3.5 Turbo) or no feedback. This is an experimental design integrating an LLM into the writing/revision process as an instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on writing tasks, revision processes, and automated feedback effectiveness. Outcomes include revision performance and a second writing task as a transfer task, clearly centering on writing competence and writing-related variables rather than mere scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: learners’ revision performance and transfer performance, with all texts scored automatically to assess performance. It also analyzes behavioral and cognitive engagement indicators (keystrokes, typing time, pauses) as mediators, providing measurable intervention effects.""
    }
}"
275,Using Chatgpt to Bring Non-player Characters to Life: Effects on Students’ Storyline-driven Game-based Writing Learning,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese undergraduate students in English as a Foreign Language (EFL) writing classrooms, clearly indicating L2 English learners in an EFL context with a focus on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention explicitly integrates ChatGPT (a large language model) into game-based learning by using ChatGPT-powered NPCs. A quasi-experimental design compares a ChatGPT condition with conventional NPCs, satisfying the requirement for an LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing classrooms with a storyline-based game designed to enhance argumentative writing skills. The primary focus is on writing learning and writing performance, not on automated scoring or non-pedagogical evaluation of the LLM.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Student essays were evaluated to compare writing performance across conditions. The abstract reports that students with ChatGPT-powered NPCs produced essays that were clearer, more elaborated, more persuasive, and better at addressing opposing viewpoints, indicating quantifiable writing outcome measures.""
    }
}"
276,Tracking Progress to Foster Motivation: Implementing a Rubric-based P-score Model in Japanese University Efl Courses,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are in Japanese university EFL courses, i.e., learners of English as a foreign language. The context is clearly English-focused (timed writing tests in university-level English courses).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Generative AI is used to support rubric-based writing assessments and feedback generation, but the abstract frames this as AI-supported testing/assessment rather than an experimental or quasi-experimental LLM-based instructional intervention in writing. There is no indication of a designed LLM-mediated teaching/learning treatment being compared to another condition.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on assessment (a rubric-based P-score model) and student perceptions of this assessment system. AI is used for rubric-based writing assessment and feedback, aligning more with automated scoring/assessment support than with a pedagogical writing intervention aimed at improving writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports survey results on student perceptions and feasibility of the P-score model. It does not report quantifiable writing outcome metrics (e.g., pre–post writing quality gains attributable to LLM use) to evaluate the effectiveness of an LLM-mediated writing intervention.""
    }
}"
277,Do Ai Chatbot-integrated Writing Tasks Influence Writing Self-efficacy and Critical Thinking Ability? an Exploratory Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as “vocational college students” engaged in “L2 writing” with “limited language proficiency,” but the abstract does not explicitly state that they are L2 English learners (ESL/EFL/ELL) or that the target language is English. The specific L2 is not identified.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses “generative AI chatbots” and “AI chatbot-integrated writing tasks,” but no specific system (e.g., ChatGPT, GPT-4) or indication that the chatbot is an LLM-based tool is provided. It could be any AI chatbot, not necessarily a transformer-based LLM.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary measured outcomes are “critical thinking ability” and “writing self-efficacy.” While the context is L2 writing, the focus is on self-efficacy and critical thinking rather than writing competence or writing-related performance variables. No direct assessment of writing quality or writing performance is reported.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantitative outcomes are limited to questionnaire measures of writing self-efficacy and critical thinking ability. The abstract does not report any quantifiable writing outcome metrics (e.g., scores of written texts, accuracy, complexity, organization) to assess the effectiveness of the intervention on writing performance.""
    }
}"
278,Harnessing Ai in Academic Writing: the Complex Interplay of Ai Literacy and Self-directed Learning among University L2 Learners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese university students engaged in academic English writing, i.e., L2 English learners in an EFL context: “academic English writing among Chinese university students.”""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “AI tools” and “advancement of AI in the field of…writing” and examines AI literacy and AI usage, but it does not specify that the tools are LLM-based (e.g., ChatGPT) nor describe an experimental or quasi-experimental instructional intervention integrating LLMs. It appears observational/correlational rather than an intervention study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on AI literacy and self-directed learning in the context of academic writing, not on a designed writing instruction intervention. AI is discussed as tools students use (summarization, translation, feedback), but there is no structured pedagogical writing intervention being tested; it is a study of relationships between AI literacy and SDL.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are self-directed learning and perceptions of AI literacy. The abstract does not mention any quantifiable writing performance metrics (e.g., writing scores, text quality measures). It focuses on SDL predictors and qualitative perceptions, not measured changes in writing competence.""
    }
}"
279,"Impacts of Genai-assisted Collaborative Prewriting on University Efl Students’ Interactions with Genai, Outline Quality, and Task Motivation",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 69 Chinese undergraduates in an EFL context, and the study explicitly concerns English as a foreign language writing instruction. Thus, the population consists of L2 English learners.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to a ‘GenAI tool’ and ‘GenAI-assisted’ prewriting, but does not specify whether this tool is an LLM (e.g., ChatGPT, GPT-4) or another type of generative AI. However, given current usage, it is likely LLM-based, though not definitively stated in the abstract alone.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary measured outcomes are interactions with GenAI, outline quality, and task motivation during the prewriting phase. The study does not report on actual writing performance or broader writing competence; it focuses on outline writing as a planning activity rather than full L2 writing outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantitative outcomes are reported for outline content quality, organization, language, and task motivation, but there is no indication of quantifiable measures of full-text writing performance or writing competence. Since the review requires writing outcome metrics, and this study limits outcomes to outlines and motivation, it does not meet the criterion.""
    }
}"
280,Understanding Efl Student Writers’ Metacognitive Awareness in Utilizing Chatgpt,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 452 EFL undergraduate students in a semester-long writing course, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students use ChatGPT for academic writing feedback, the study is described as a mixed-method investigation of metacognitive awareness, not as an experimental or quasi-experimental intervention study. There is no indication of controlled instructional treatment or comparison groups to test an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL academic writing and the use of ChatGPT for writing feedback and improvement, which is directly related to writing competence and writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports validation of a metacognitive awareness scale and qualitative insights into metacognitive practices. It does not mention any quantifiable writing performance outcomes (e.g., writing scores, text quality measures) used to assess the effectiveness of ChatGPT-mediated writing intervention.""
    }
}"
281,"Ai-driven Language Learning in Higher Education: an Empirical Study on Self-reflection, Creativity, Anxiety, and Emotional Resilience in Efl Learners",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 205 English as a Foreign Language (EFL) undergraduate learners from various Chinese universities, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “AI-powered feedback” (grammar/vocabulary corrections, motivational feedback) but does not specify that the tools are large language model–based (e.g., ChatGPT, GPT-4). They could be traditional NLP/grammar checkers. No explicit mention of LLMs or transformer-based generative models is made.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on self-reflection, creativity, anxiety, and emotional resilience. Writing is mentioned only tangentially (“enjoyment in writing and speaking”), and there is no indication that the study centers on writing competence or writing-related instructional interventions; it is a general AI feedback and affective/psychological outcomes study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported concern self-reflection, creativity, confidence, anxiety reduction, and emotional resilience. There is no mention of quantifiable writing performance metrics (e.g., writing scores, text quality measures) used to assess the effectiveness of the AI intervention on writing competence.""
    }
}"
282,From Algorithms to Annotations: Rethinking Feedback Practices in Academic Writing through Ai-human Comparison,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on Malaysian L2 students in an English for Academic Purposes (EAP) setting, clearly indicating L2 English learners in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used to generate feedback, the design is comparative/descriptive: it examines how ChatGPT and instructors use epistemic strategies and delivery methods in comments on 200 introductions. There is no experimental or quasi-experimental instructional intervention integrating LLMs into writing instruction or processes; it is an AI–human feedback comparison study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on characterizing feedback practices (epistemic strategies and delivery methods) of ChatGPT vs. instructors, not on improving or measuring writing competence. It informs pedagogy conceptually but does not constitute a pedagogical writing intervention with outcome evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports no quantifiable writing outcome metrics (e.g., changes in writing quality, scores, accuracy). It analyzes properties of feedback, not the effects of LLM-mediated feedback on learners’ writing performance.""
    }
}"
283,The Role of Ai Assisted Writing Feedback in Developing Secondary Students Writing Skills,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as secondary-level EFL students in Turkey, which fits L2 English learners in an EFL context. The focus is clearly on English writing skills.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to an “AI writing assistant” and “AI-assisted writing feedback” but does not specify whether the tool is an LLM (e.g., ChatGPT, GPT-4) or a non-LLM AI tool (e.g., rule-based or traditional NLP). Without explicit indication that a transformer-based generative model is used, it is not possible to confirm it meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on developing students’ writing skills and writing performance (grammar, vocabulary, coherence) through AI-assisted feedback in a pedagogical context, not on automated scoring or system evaluation alone.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an experimental design with pre-test and post-test writing assessments and reports quantifiable improvements in overall writing performance and subcomponents (grammar, vocabulary, coherence) between experimental and control groups.""
    }
}"
284,Chatgpt-generated Versus Human Direct Corrective Feedback on L2 Writing,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are second-year English Pedagogy students at a Chilean university, indicating they are L2 English learners in an EFL/ESL context. The study explicitly concerns L2 essay writing in English.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention compares direct written corrective feedback (WCF) provided by ChatGPT (an LLM) versus a human teacher. Students were randomly assigned to ChatGPT or teacher feedback over four sessions, indicating an experimental design integrating an LLM into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 essay writing quality, with ChatGPT used to deliver written corrective feedback as part of writing instruction. This directly targets writing competence rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: task response, cohesion and coherence, lexical resource, and grammatical range and accuracy. It compares effectiveness of ChatGPT vs. human WCF in improving these writing measures, noting significant enhancement and ChatGPT’s superiority.""
    }
}"
285,Efl Students’ Writing Engagement and Ai Attitude in Genai-assisted Contexts: a Mixed-methods Study Grounded in Sdt and Tam,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners (“EFL learners’ engagement in GenAI-assisted writing”), clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines engagement profiles and attitudes toward GenAI and includes teacher interviews about potential use. It explicitly notes that few teachers have actively integrated such tools into their teaching. There is no described experimental or quasi-experimental LLM-based writing intervention or structured use of a specific LLM (e.g., ChatGPT) as part of instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is GenAI-assisted writing and writing engagement in EFL, which is directly related to writing competence–related variables (engagement in writing).""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are engagement profiles and attitudes; there is no indication of quantifiable writing performance metrics (e.g., writing scores, quality measures) assessing effectiveness of an LLM-mediated writing intervention.""
    }
}"
286,Examining Language Learners’ Genai-assisted Writing Self-efficacy Profiles and the Relationship with Their Writing Self-regulated Learning Strategies,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as English-as-a-foreign-language (EFL) learners, which fits the target population of L2 English learners in EFL/ESL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to ‘GenAI-assisted writing’ and GenAI as a scaffolding tool, but does not specify whether the GenAI tools are large language models (e.g., ChatGPT, GPT-4) or other forms of AI. It also does not clearly describe an experimental or quasi-experimental instructional intervention; the focus is on profiling learners’ self-efficacy rather than testing an intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on GenAI-assisted writing self-efficacy profiles and their relationship with self-regulated learning strategies, not on writing competence or writing-related performance variables. The study examines motivational constructs underlying GenAI-assisted writing processes rather than implementing and evaluating a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, text quality measures) are reported. Outcomes are self-efficacy profiles, SRL strategy use, and antecedents such as years of English learning and perceived proficiency, without measured changes in writing performance following an LLM-mediated intervention.""
    }
}"
287,"Effects of Three Levels of Ai Integration on Second Language Academic Writing: Evaluating Restricted, Guided, and Free Use of Chatgpt",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Korean college students in English essay writing courses, explicitly described as L2-English learners. The focus is on English academic writing, fitting ESL/EFL/ELL L2 English contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention manipulates three levels of ChatGPT use (Restricted, Guided, Free) as instructional tools. ChatGPT is a large language model, and the design is quasi-experimental with three comparison groups over a semester.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on academic English essay writing. The study examines how different levels of AI integration affect academic writing outcomes, not on automated scoring or system evaluation alone.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: essay scores and subcomponents (content quality, organization, language use) comparing the three groups, thus providing measurable effects of the LLM-mediated intervention.""
    }
}"
288,Exploring Second Language Writers’ Engagement with Chatgpt Feedback: Revision Behaviors and Perceptions,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 25 B1-level English as a Foreign Language (EFL) students at a university in Türkiye, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used as a feedback tool, but the design is observational/descriptive (mixed methods) rather than experimental or quasi-experimental. The study explores engagement with feedback and perceptions, not an intervention tested for effectiveness against a control or pre-post design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on L2 writing, specifically how EFL writers engage with ChatGPT feedback when revising opinion essays, including content, organization, and language use.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although essay drafts and revisions are analyzed, the abstract reports descriptive patterns of revision behavior and perceptions, not quantifiable writing outcome metrics assessing the effectiveness of a ChatGPT-mediated intervention (e.g., pre-post writing scores or comparative gains).""
    }
}"
289,Empowering Students' Autonomy in Efl Learning: Ai Innovations in Schools of the Global South,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The population focus is on school-based English as a Foreign Language (EFL) learning across the Global South, which aligns with L2 English learners in EFL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a PRISMA-guided systematic review of AI in EFL learning, not an experimental or quasi-experimental primary study integrating specific LLMs (e.g., ChatGPT, GPT-4) into writing instruction. It synthesizes 22 empirical studies rather than reporting its own LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The review addresses AI support for student autonomy across multiple skills (speaking, reading, writing, listening, vocabulary). Writing is only one of several skills and not the primary focus on writing competence or writing-related variables required by the review’s scope.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic review, it does not itself report original, quantifiable writing outcome metrics from an LLM-mediated intervention; instead, it synthesizes diverse AI-related studies with a focus on autonomy, not specific writing outcome measures.""
    }
}"
290,"Negotiating Understanding, Control, and Authorship: L2 Learners’ Experiences with Ai-assisted Paraphrasing in Academic Writing",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are twelve English-as-a-foreign-language (EFL) students at a Chinese university, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “AI tools” for paraphrasing but does not specify that they are large language models (e.g., ChatGPT, GPT-4). They could be other AI-based paraphrasers or translators not grounded in LLMs. The design is qualitative (interviews) rather than an experimental or quasi-experimental intervention study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on learners’ experiences and interactions with AI-assisted paraphrasing in academic writing, not on a structured pedagogical writing intervention or systematic integration of LLMs into instruction. It explores use patterns and agency rather than an instructional treatment targeting writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is purely qualitative, based on interviews and thematic analysis. No quantifiable writing outcome metrics or experimental measures of writing performance are reported.""
    }
}"
291,"Exploring L2 Writing Motivation in Ai-mediated Efl Contexts: the Role of Teacher Affective Support, Ai Literacy, and Self-efficacy through the Lens of Self-determination Theory",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 627 Chinese university students in an AI-mediated EFL writing context, i.e., L2 English learners. The focus is clearly on L2 writing motivation in EFL settings.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is correlational/structural (questionnaires, SPSS, AMOS) and examines AI-mediated contexts, teacher affective support, AI literacy, and self-efficacy. It does not describe an experimental or quasi-experimental LLM-based writing intervention (e.g., ChatGPT use in instruction); AI is a contextual factor, not a specific LLM intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is L2 writing motivation and its predictors (teacher affective support, AI literacy, self-efficacy) within AI-mediated contexts, not on writing competence or writing-related performance variables. It is a motivational study rather than a writing instruction or competence intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are self-reported motivational and psychological constructs measured via questionnaires and modeled structurally. No quantifiable writing performance or competence outcomes (e.g., writing scores, quality measures) are reported to assess effectiveness of an LLM-mediated writing intervention.""
    }
}"
292,The Psychology of Pedagogical Compromise: Written Corrective Feedback in Chinese Efl Writing through an Ecological Systems Lens,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese university EFL (English as a Foreign Language) students and teachers, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention concerns different types of written corrective feedback (selective, comprehensive, minimal) delivered by teachers. There is no mention of large language models or any LLM-based tool (e.g., ChatGPT, GPT-4) being integrated into the writing instruction or process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence, specifically written corrective feedback practices and their impact on student writing accuracy and anxiety in EFL writing.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative writing outcomes, including improvements in writing accuracy and satisfaction, with statistical results (F = 15.61, p < .001, d = 1.08) comparing selective, comprehensive, and minimal feedback.""
    }
}"
293,Threshold-triggered Dual Effects in Ai-assisted Efl Writing: Self-efficacy Modulates Grammar Learning Pathways,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly refers to EFL (English as a Foreign Language) grammar instruction and EFL learners, indicating L2 English learners in an EFL context. The focus is clearly on English grammar learning.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study examines “AI writing tools” and “AI-assisted EFL writing,” but the abstract does not specify whether these tools are large language model–based (e.g., ChatGPT, GPT-4) or other forms of AI (e.g., rule-based grammar checkers). Without explicit mention of LLMs or transformer-based generative models, it is not possible to confirm that the intervention meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on “EFL grammar instruction,” “grammatical competence growth,” and “grammar learning pathways” within AI-assisted EFL writing. While this is related to writing, it is not clear whether the primary outcome is overall writing competence or broader writing-related performance, as opposed to isolated grammar learning. The title and abstract emphasize grammar rather than writing quality or composition skills.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports quantifiable outcomes: a self-efficacy threshold (T=3.278), proportions of learners showing regression (60.32%), and differential grammatical competence growth/erosion. These indicate measured, quantitative learning outcomes under AI-assisted conditions, even though the exact writing metrics are not fully detailed.""
    }
}"
294,A Student-centered Framework for Understanding Efl Thesis Writing Difficulties in Vietnam,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Vietnamese English as a Foreign Language undergraduate students writing theses in English, clearly fitting an EFL/ELL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""AI tools are mentioned only as part of the support systems and in relation to institutional policies and ethical use. There is no indication of an experimental or quasi-experimental design integrating LLMs (e.g., ChatGPT) into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on understanding thesis writing difficulties and support systems broadly, not on a specific LLM-mediated writing intervention. AI tools are one of several supports and not the central pedagogical intervention under study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a qualitative design with semi-structured interviews and thematic analysis. It does not report quantifiable writing outcome metrics or experimental measures of the effectiveness of AI/LLM-mediated writing interventions.""
    }
}"
295,Feedback Literacy and Efl Learner Engagement with Chatgpt Feedback: Predicting Feedback Uptake and Perceived Usefulness,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 51 Chinese university students in EFL writing, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT, a large language model, to provide feedback on three ChatGPT-supported writing assignments, integrating it into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing with a focus on engagement with ChatGPT-generated feedback and revision-based tasks, directly tied to writing instruction and feedback use.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are feedback uptake (behavioral adoption) and perceived usefulness, analyzed via regression and mediation. The abstract does not indicate any quantifiable writing performance or quality measures (e.g., scores, rubric-based writing improvement); it focuses on engagement and perceptions rather than writing competence outcomes.""
    }
}"
296,Exploring Sentence-level Revision Capabilities of Large Language Models in English for Academic Purposes Writing Assistance,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions challenges for non-native English speakers in English for Academic Purposes, but it does not state that the study involves human L2 English learners as participants. It appears to be a system-level evaluation of LLM performance rather than a learner-based study.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study evaluates LLMs’ sentence-level revision (SentRev) capabilities via three experimental setups, but these are NLP/system experiments, not pedagogical interventions integrated into writing instruction or learner writing processes. No teaching or learning intervention with L2 writers is described.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on assessing LLM performance on SentRev and improving it via prompting and academic phrase integration. There is no indication of a classroom or instructional context, nor of writing competence development among learners; it is a technical evaluation of LLM functionality.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are LLM performance metrics on sentence-level revision tasks and benchmark considerations, not quantifiable writing outcomes for L2 learners. No learner writing scores, gains, or writing-related learner variables are measured.""
    }
}"
297,A Multi-stage Interactive Writing Task for the Assessment of English Language Writing Proficiency,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses an assessment of English language writing proficiency but does not specify that participants are L2 English learners (ESL/EFL/ELL). They could be native or mixed populations; the population type is not explicit.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""A large language model is used to automatically analyze test-taker responses and generate customized follow-up prompts, but this is within a testing/assessment system, not an instructional or pedagogical writing intervention. There is no indication of experimental or quasi-experimental integration of LLMs into teaching or learning processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on assessment design and validity of a high-stakes writing test, not on improving writing competence through instruction. The LLM is used for theme detection and prompt generation to support measurement, aligning with assessment functionality rather than a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported concern test validity, fairness, and the effect of follow-up task type on scores, not the effectiveness of an LLM-mediated writing intervention. There is no structured instructional treatment or quantifiable learning gain in writing ability attributable to LLM-based teaching or feedback.""
    }
}"
298,Integrating Move Analysis and Sentence Reconstruction in Automated Writing Evaluation for L2 Academic Writers,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “L2 academic writers” and “learners,” implying L2 English users in an academic writing context, but it does not explicitly specify ESL/EFL/ELL participants or any concrete learner sample; the focus is primarily on system development and evaluation.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although GURUS uses transformer-based LLMs and is framed as an AWE system for academic writing, the study centers on system design and performance metrics (classification, reconstruction) rather than an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction with learners as participants.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automated move classification and sentence reconstruction performance (F1, Brier, BERTscore, human assessment of outputs). While writing instruction is discussed conceptually, the study does not report an implemented instructional intervention or learner use in a writing course; it is essentially a system evaluation, not a pedagogical study of writing competence change.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcome metrics (e.g., pre/post writing scores, improvements in accuracy, complexity, or genre performance) are reported. The quantitative results concern model performance (classification and reconstruction quality), not measured changes in L2 learners’ writing following an LLM-mediated intervention.""
    }
}"
299,Examining the Consistency of Instructor Versus Large Language Model Ratings on Summary Content: Toward Checklist-based Feedback Provision with Second Language Writers,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Japanese undergraduate students producing learner-generated summaries in an L2 writing instruction context in Japan, indicating L2 English writers in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines consistency between instructor ratings and LLM-estimated ratings using different prompts. It focuses on LLM-based scoring/checklist ratings, not on an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on rating agreement and prompt design for LLM-generated checklist ratings, akin to automated assessment functionality. There is no described instructional intervention where LLMs are used to teach or support writing; the pedagogical use is only discussed as a potential future application.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study does not report quantifiable outcomes of an LLM-mediated writing intervention (e.g., changes in writing quality due to LLM use). It analyzes agreement between human and LLM ratings on existing summaries, without measuring writing improvement or intervention effects.""
    }
}"
300,"Evaluating Generative Ai Tools for Improving English Writing Skills: a Preliminary Comparison of Chatgpt-4, Google Gemini, and Microsoft Copilot",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as B+ level English as a Foreign Language (EFL) students at a preparatory school in Türkiye, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study uses LLM-based tools (ChatGPT-4, Google Gemini, Microsoft Copilot), the design focuses on comparing the tools’ performance in supporting brainstorming, outlining, and feedback, rather than an experimental or quasi-experimental pedagogical intervention where learners’ writing development is measured over time. The primary unit of analysis appears to be tool outputs and student perceptions, not an instructional treatment effect on learners.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is opinion essay writing in EFL, with focus on idea generation, essay structuring, and feedback—clearly writing-related variables within a pedagogical context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Rubric-based evaluations are used to compare the tools’ performance (e.g., idea generation, structuring, feedback actionability), but the abstract does not indicate that students’ own writing outcomes (e.g., improvements in essay quality or scores attributable to the intervention) are measured as dependent variables. The focus is on tool comparison and perceptions, not quantifiable learner writing gains from an LLM-mediated intervention.""
    }
}"
301,The Role of Chatgpt in Enhancing Efl Students’ Esp Writing Skills: an Experimental Study of Gender and Major Differences,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as EFL university students learning ESP writing, which clearly indicates L2 English learners in an EFL context with a focus on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is an experimental study using ChatGPT as a self-directed learning tool. ChatGPT is a large language model, and it is integrated into the learning process to enhance ESP writing skills.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on ESP writing skills, i.e., writing competence. The intervention uses ChatGPT specifically to enhance writing, not for automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports pre- and post-test data on writing skills, analyzed with Wilcoxon signed-rank test and ANOVA, indicating quantifiable writing outcome metrics to assess the effectiveness of the ChatGPT-mediated intervention.""
    }
}"
302,Perceptions and Effectiveness of Ai-assisted Written Corrective Feedback: a Case Study of Chinese Efl University Students,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese EFL university students in a College English course, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “AI-assisted written corrective feedback (AI-WCF)” and “AI tools,” but does not specify that these are large language model–based systems (e.g., ChatGPT, GPT-4). They could be other AI feedback tools not based on LLMs.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is argumentative writing in a College English course, with AI-assisted written corrective feedback integrated into structured writing tasks. The focus is on writing subskills (unity, support, cohesion/coherence, language use).""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are based on self-assessed progress via questionnaires, i.e., perceived gains in writing subskills. There is no indication of objective, quantifiable writing performance measures (e.g., rated texts, scores) to assess effectiveness of the AI-mediated intervention.""
    }
}"
303,A Hybrid System for Automated Assessment of Korean L2 Writing: Integrating Linguistic Features with Llm,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The population consists of Korean L2 learners and the focus is on Korean L2 writing assessed on the TOPIK scale. The review requires L2 English learners in ESL/EFL/ELL contexts with data focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The LLM is used to generate an ideal reference answer as part of an automated essay scoring (AES) system. There is no experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or learner writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on developing and validating an automated assessment system (AES) for Korean L2 writing, not on writing instruction or intervention. This falls under excluded contexts (LLM functionality as an automated essay scoring system).""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports system performance metrics (scoring accuracy, alignment with human judgments) rather than quantifiable learner writing outcomes resulting from an LLM-mediated instructional intervention.""
    }
}"
304,Teachers’ Perceptions and Students’ Strategies in Using Ai-mediated Informal Digital Learning for Career Esl Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are university students in an English writing course in an ESL context (“career ESL writing instruction”), so they are L2 English learners in an ESL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students use AI tools including ChatGPT (an LLM), the study is described as a case study exploring teachers’ perceptions and students’ strategies. There is no indication of an experimental or quasi-experimental design testing an LLM-based intervention; instead, it is observational/qualitative.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly writing-focused: “career ESL writing instruction,” “English writing course,” and exploration of how AI-mediated informal digital learning tools are used for writing projects and rhetorical accessibility.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative findings about strategies and perceptions and mentions that students became more aware of how to improve their writing, but it does not report any quantifiable writing outcome metrics or experimental measures of writing improvement.""
    }
}"
305,Blending Focus on Form and Technology: Teaching Essay Writing with Ai Tools; Biçim Ve Teknolojiye Odaklanmayı Harmanlamak: Yapay Zekâ Araçlarıyla Makale Yazmayı Öğretme,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 120 undergraduate ESL learners, indicating L2 English learners in an ESL context with a focus on English essay writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract states that the intervention integrates focus-on-form instruction with ‘AI tools’ but does not specify that these are large language models (e.g., ChatGPT, GPT-4). Given the generic term ‘AI tools’ and no mention of generative or LLM-based systems, it cannot be assumed they are LLMs rather than other AI-based writing aids.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on teaching essay writing and examining effects on accuracy, fluency, and overall writing proficiency, clearly centering on writing competence rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The design includes pre- and post-tests comparing control and experimental groups, and reports significant enhancement in essay writing in terms of linguistic accuracy and engagement, indicating quantifiable writing outcome metrics.""
    }
}"
306,Pre-service Teachers’ Perceptions of the Use of Artificial Intelligence in an English as a Foreign Language Learning Context,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 120 EFL university students (B1–B2 CEFR) in an English as a Foreign Language learning context, which fits the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although generative AI tools, specifically ChatGPT, are mentioned, the study focuses on pre-service teachers’ perceptions of integrating these tools, not on an experimental or quasi-experimental LLM-based writing intervention. No structured instructional treatment using ChatGPT is described.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing is mentioned as one of several perceived benefits (students affirmed ChatGPT enhanced their writing abilities), but the primary focus is general EFL learning and perceptions of AI, not a targeted writing competence intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses surveys, narratives, questionnaires, and interviews to explore perceptions. There is no indication of quantifiable writing outcome measures (e.g., pre/post writing scores, rubric-based writing assessment) to evaluate the effectiveness of an LLM-mediated writing intervention.""
    }
}"
307,Artificial Intelligence in Esl/efl Education: Evidence from Recent Reviews (2024–2025),2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a “review of reviews,” synthesizing 14 systematic reviews, meta-analyses, and meta-syntheses. It does not report on a primary study with a defined participant population of L2 English learners; instead, it aggregates findings from other reviews.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""As a secondary study (“review of reviews”), it does not implement an experimental or quasi-experimental LLM-based intervention itself. It summarizes prior work on AI-enhanced instruction, including generative AI such as ChatGPT, but does not constitute an intervention study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on synthesizing evidence across multiple skills and dimensions (writing, speaking, learner roles, ethics), not on a specific, primary writing-focused pedagogical intervention. It is a higher-level synthesis rather than a context-specific writing intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The article does not report original, quantifiable writing outcome metrics from a primary intervention. Any effectiveness data are aggregated from other reviews, which falls under excluded publication types (reviews, meta-analyses).""
    }
}"
308,Genai and Human Assessments of L2 Chinese Writing: Interrater Reliability and Rater Bias,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are learners of Chinese as a second language (L2 Chinese writing). The review targets L2 English learners in ESL/EFL/ELL contexts with a focus on English writing, so the population and target language do not match the inclusion criteria.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT and DeepSeek are used as automated raters to assess L2 Chinese writing. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or writing processes; the focus is on assessment reliability and rater bias.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on writing assessment (interrater reliability, severity, consistency, genre-based bias) rather than on improving writing competence or writing-related learning outcomes. It evaluates LLMs as essay scorers, which the protocol specifies should be excluded.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports psychometric outcomes (agreement, correlation, severity, bias) for rating performance, not quantifiable writing outcome metrics resulting from an LLM-mediated writing intervention. There is no structured instructional intervention whose impact on learners’ writing is measured.""
    }
}"
309,Examining the Efficacy of Chatgpt and Human-derived Corrective Feedback in Addressing Grammatical Errors in Saudi Efl Students’ Compositions,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 53 Saudi EFL undergraduates at the University of Jeddah. The context is explicitly EFL and the focus is on English grammatical accuracy in students’ compositions.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention compares ChatGPT-based written corrective feedback (experimental group) with human corrective feedback (control group) over eight weeks. ChatGPT is a large language model integrated into the writing instruction process, and the design is experimental with pretest–posttest groups.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on written corrective feedback on students’ compositions and aims to foster linguistic accuracy in writing. The context is clearly writing instruction (EFL compositions) rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Pretests and posttests assessed participants’ grammatical competence in writing, and quantitative findings report that the experimental group significantly outperformed the control group in the posttest. These are quantifiable writing-related outcome measures of the LLM-mediated intervention.""
    }
}"
310,Exploring Efl Teachers' Strategies in Employing Ai Chatbots in Writing Instruction to Enhance Student Engagement,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL students, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “AI chatbots” and “advanced AI language models” but does not specify that they are large language models (e.g., ChatGPT, GPT-4) as opposed to rule-based or simpler AI chatbots. The specific technology and model type are not identified.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing instruction, and the intervention is the use of AI chatbots within writing classes. The focus is pedagogical, not automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study’s primary quantitative outcome is student engagement (affective, behavioral, cognitive). There is no indication of quantifiable writing performance or writing quality measures; writing outcomes are only mentioned generically as ‘eventually enhancing student learning outcomes’ without reported metrics.""
    }
}"
311,Self-assessment Accuracy in the Age of Artificial Intelligence: Differential Effects of Llm-generated Feedback,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are N = 459 upper secondary students who wrote an argumentative essay in English as a foreign language, clearly indicating an EFL (L2 English) population.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses GPT-3.5-turbo-generated feedback as the intervention in a randomized control experiment, integrating an LLM into the writing process (feedback on first drafts during revision).""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the task is argumentative essay writing in EFL and involves revision, the primary outcome of interest is self-assessment accuracy (SAA), not writing competence or writing-related performance variables. The abstract reports effects on SAA and its moderators, not on writing quality or other writing outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The only reported quantitative outcome is self-assessment accuracy (SAA) and its change; there is no mention of quantifiable writing performance metrics (e.g., scores, quality ratings, linguistic measures) used to assess the effectiveness of the LLM-mediated writing intervention on writing itself.""
    }
}"
312,Evaluating L2 Learners’ Experience with Genai-powered Academic Reading Tool in Higher Education: a Small-scale Exploratory Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “L2 learners” and “postgraduate students” using an academic reading tool, but it does not explicitly state that they are L2 English learners in ESL/EFL/ELL contexts or that English is the target language. The context (academic reading, theoretical frameworks) suggests English-medium study, but this is not clearly specified.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is a GenAI-powered academic reading tool (Fullpicture) using ChatGPT to generate reading reports. The focus is on academic reading support, not on integrating LLMs into writing instruction or writing processes. There is no experimental or quasi-experimental design targeting writing intervention; instead, students evaluate the tool and reflect on their reading experience.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is academic reading comprehension and learners’ experiences with a GenAI reading tool. While the tool may indirectly influence academic writing (e.g., generating perspectives for writing), the study is framed around reading comprehension levels and evaluation of arguments and evidence, not on writing competence or writing-related instructional interventions.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are learners’ reflections and Likert-scale ratings of the tool’s effectiveness for reading-related constructs (e.g., comprehension, evaluation of arguments). There are no quantifiable writing outcome metrics (e.g., writing quality scores, revisions, text features) assessing the effectiveness of an LLM-mediated writing intervention.""
    }
}"
313,Effects of Deepseek-assisted Writing Instruction on Efl Learners' Writing Performance,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL learners working on English writing skills, which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is a prospective quasi-experimental design where DeepSeek, a named LLM, is employed to assist learners’ writing during a defined intervention period, integrating the LLM into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on English writing competence, examining different dimensions of learners’ English writing skills (micro- and macro-level performance) within an instructional intervention, not on automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Learners’ writing production from baseline, intervention, and follow-up periods was collected and rated, yielding quantifiable writing performance outcomes (e.g., vocabulary, grammar, mechanics, macro-level performance) to assess the effect of DeepSeek-assisted instruction.""
    }
}"
314,Ai-driven Scaffolding and Affective Support in Esl Argumentative Writing: a Multimodal Analytics Approach,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly refers to ESL students and an ESL system for writing argumentative essays, indicating L2 English learners in an ESL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The system uses a Transformer architecture with an emotion recognition model and AI-based scaffolding. However, it is not clear whether this is a large language model used for generative writing support (e.g., ChatGPT-like) or primarily a multimodal emotion-recognition/analytics model without LLM-based text generation. The abstract does not specify LLM-based generative intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on ESL argumentative writing, writing quality, writing patterns, and performance, with AI-driven scaffolding and affective support as part of a dynamic intervention framework. This aligns with writing competence and writing-related variables in a pedagogical context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract notes that it was ‘experimentally determined’ that the system managed writing quality and reduced cognitive load, and that statistical modeling examined correlations between multimodal characteristics and writing performance. This implies quantifiable writing outcome metrics were collected.""
    }
}"
315,Understanding Efl Learners’ Strategies in Aiassisted English Writing: an Activity Theory Perspective; Comprensión De Estrategias De Los Estudiantes De Efl En La Escritura Asistida Por Ia,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) learners, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “AI-assisted writing” and “interacting with AI,” but does not specify that the AI tools are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems. The type of AI is not identified.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL learners’ strategies when using AI to assist with writing tasks, clearly centering on writing processes and practices in an educational context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is qualitative, using screenshots, chat logs, and semi-structured interviews to explore strategies and perceptions. No experimental or quasi-experimental design or quantifiable writing outcome metrics are reported.""
    }
}"
316,Bridging the Gap: a Systematic Deconstruction Strategy for Esl Student Success in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly targets ESL students and discusses their challenges in academic writing, clearly situating the population as English L2 learners in an ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the paper mentions AI tools and prompt engineering, it does not specify the use of large language models (e.g., ChatGPT, GPT-4) nor describe an experimental or quasi-experimental intervention integrating LLMs into writing instruction. It appears to be a conceptual/strategic paper about prompt design rather than an LLM-based intervention study.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on academic writing and a strategy to help ESL students handle writing prompts, addressing rhetorical and disciplinary requirements in writing tasks. Thus, the primary context is writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any empirical, quantifiable writing outcome measures or an experimental evaluation of the proposed strategy. It describes a strategy and provides an illustrative example (using “The Gift of the Magi”) but no structured intervention outcomes or metrics.""
    }
}"
317,Students’ Self-determination in Using Machine Translation and Generative Ai Tools for English for Academic Purposes,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EAP students in an English as a Second Language context in Australia and an English as a Foreign Language context in Vietnam, i.e., L2 English learners in ESL/EFL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates students’ use of machine translation and generative AI tools and their motivations, but there is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) as a structured writing intervention. It is primarily a survey/interview study of existing practices and perceptions.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on self-determination (autonomy, competence, relatedness) and motivational aspects of MT/GAI use in academic writing, not on evaluating a pedagogical writing intervention or systematically designed LLM-mediated writing instruction. Mention of ‘innovations’ is illustrative rather than an assessed intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are motivational constructs and perceptions (autonomy, competence, relatedness) analyzed via survey and regression. There is no report of quantifiable writing performance or writing quality measures as outcomes of an LLM-mediated intervention.""
    }
}"
318,The Algorithmic Adjuvant: Synthesizing Human Pedagogy and Artificial Intelligence in the Modern Esl Classroom with Insights from Uzbekistan,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on ESL classrooms in Uzbekistan, explicitly describing English as a Second Language (ESL) education and learners, which fits the target population of L2 English learners in ESL/EFL contexts.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions AI technologies such as intelligent tutoring systems, automated writing aids, and speech recognition software, but does not specify that these are large language model (LLM)-based tools (e.g., ChatGPT, GPT-4). The nature of the AI tools (LLM vs. other AI) is not clear, and there is no explicit mention of transformer-based generative models.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing is mentioned only indirectly via ‘automated writing aids’; the broader focus is on ESL instruction, learner engagement, fluency, autonomy, and general AI integration. The primary emphasis appears to be overall ESL teaching rather than a focused intervention on writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is based on qualitative case studies and observational evidence, discussing opportunities, challenges, motivation, fluency, and autonomy. It does not report quantifiable writing outcome metrics or experimental measures of writing performance; outcomes are described qualitatively rather than via structured, quantitative writing assessments.""
    }
}"
319,Probing into Efl Students’ Perceptions about the Impact of Utilizing Ai-powered Tools on Their Academic Writing Practices,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL students enrolled in an “Academic Writing 2” course at a private university in Oman, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is among the tools used, the study is framed as an exploration of perceptions of multiple AI-powered tools (Grammarly, Wordtune, ChatGPT, Quillbot) and uses a qualitative approach without an explicit experimental or quasi-experimental design to test an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is academic writing instruction; tools are used for grammar/style suggestions, paraphrasing, summarizing, and brainstorming within an academic writing classroom, focusing on writing practices and performance.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract emphasizes qualitative data (learning journals, observations, focus-group interviews) and students’ perceptions. While it mentions improved writing skills and performance, there is no indication of reported quantifiable writing outcome metrics or experimental measures of effectiveness.""
    }
}"
320,When Ai Meets Source Use: Exploring Chatgpt's Potential in L2 Summary Writing Assessment,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study analyzes 90 L2 student summary essays in an integrated writing assessment context, indicating participants are L2 writers. Although the target language is not explicitly stated, the context (Elsevier, L2 summary writing, integrated writing assessment) strongly implies L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used as an automated rater (GPT_original, GPT_calibrated) to score L2 summary writing and is compared with human raters. There is no indication of an instructional or quasi-experimental pedagogical intervention integrating ChatGPT into learners’ writing processes or instruction; it is a scoring/assessment study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on ChatGPT’s performance as a rating tool for integrated L2 summary writing (scoring, rater severity, source-use criterion), not on improving learners’ writing competence through an instructional intervention. This aligns with automated essay scoring/assessment research, which is outside the review scope.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports quantitative outcomes in terms of rating behavior (severity, alignment with human raters, gaps in assessing source use), but these are not writing outcome measures from an LLM-mediated instructional intervention. No experimental manipulation of learners’ writing with pre/post or comparative writing performance metrics is described.""
    }
}"
321,Investigating a Customized Generative Ai Chatbot for Automated Essay Scoring in a Disciplinary Writing Task,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are engineering students in a disciplinary English course at a university in Hong Kong, which implies L2 English learners in an EFL/ESL context. The focus is on English writing scores.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a customized GenAI chatbot (LLM-based) solely for automated essay scoring, comparing its scores with those of English teachers. There is no indication of an instructional or intervention design integrating the LLM into writing instruction or writing processes for learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the chatbot’s performance as an automated essay scoring system (correlations between chatbot and teacher scores). There is no pedagogical intervention or focus on improving writing competence; it is an assessment-functionality study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing scores are reported, they are used to evaluate the GenAI scoring tool’s reliability, not to assess the effectiveness of an LLM-mediated writing intervention. No experimental or quasi-experimental instructional treatment or learner outcome change is described.""
    }
}"
322,Attitudes of Pakistani Undergraduate Esl Students Toward Artificial Intelligence in Improving English Writing Skills,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are Pakistani undergraduate ESL students, clearly L2 English learners in an ESL context, and the focus is on English writing skills.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines attitudes toward AI in general and AI adoption using TAM and CLT, but there is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT, GPT-4) into writing instruction or processes. It is an attitudinal survey, not an LLM-based intervention study.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly English writing skills and how AI might improve them, so the primary focus is on writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports attitudes, perceived usefulness, ease of use, and behavioral intentions, analyzed via descriptive statistics. It does not report quantifiable writing outcome metrics (e.g., changes in writing scores, quality, accuracy) resulting from an AI/LLM-mediated writing intervention.""
    }
}"
323,Exploring the Efficacy of Chatgpt-4 Feedback in Second Language Spanish Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are advanced Spanish learners; the target language is Spanish, not English. The abstract focuses on second language Spanish writing, so the population and data are not in an ESL/EFL/ELL English context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT-4, a large language model, to provide rubric-aligned feedback on student writing as part of a treatment where students revise drafts based on AI and instructor feedback.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly L2 writing development, with AI-generated feedback used to support writing revisions and drafting processes in a formal writing task.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study is described as qualitative, focusing on thematic analysis of questionnaires, revisions, and reflections. While there is a pre- and post-treatment writing task, the abstract does not state that quantifiable writing outcome metrics were analyzed or reported; emphasis is on perceptions and thematic findings.""
    }
}"
324,Efl Learners’ Perceptual Perezhivaniya and Actual Writing Revision Behaviors Mediated by Genai: a Sociocultural Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are nineteen EFL learners at a university in Southern China, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that learners revised L2 continuation writing tasks using GenAI, but it does not specify that the GenAI tool is an LLM (e.g., ChatGPT, GPT-4) or provide details about the underlying technology. It could be any generative AI system, not necessarily an LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on L2 writing revision processes (word choice, content, discourse, syntax, errors, alignment, typographic elements) mediated by GenAI, which is central to writing competence and writing-related behaviors.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses interviews, Q-methodology, and Translog screen recordings to explore revision processes and the alignment between perceived experiences and actual behaviors. The abstract reports consistency between perceptions and behaviors but does not mention any quantifiable writing outcome metrics (e.g., writing quality scores, accuracy gains, pre-post tests) assessing effectiveness of the GenAI-mediated intervention.""
    }
}"
325,Automated Scoring in the Era of Artificial Intelligence: an Empirical Study with Turkish Essays,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are learners of Turkish as a second language, not L2 English learners. The focus is on Turkish essays and assessment in an under-represented language (Turkish), not English.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses OpenAI's GPT-4o (a large language model) in a zero-shot approach to score essays, indicating LLM integration. However, this is for automated scoring, not instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automated scoring reliability and alignment between human and AI scores for Turkish essays. There is no pedagogical writing intervention or instructional use of the LLM; it is an assessment/AS system study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports quantitative metrics (Quadratic Weighted Kappa, Pearson correlation, overlap) about scoring agreement, not about changes in learners’ writing performance or outcomes following an LLM-mediated writing intervention.""
    }
}"
326,Can Chatgpt Serve as a Writing Collaborator? Insights from Chinese Efl Learners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese EFL learners at a tier-one university in China with over ten years of English learning experience and upper-intermediate English proficiency. The context is clearly L2 English learning (EFL).""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly investigates how Chinese EFL learners interact with ChatGPT, a large language model, in an argumentative writing task, integrating it as a writing collaborator in L2 writing.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 writing: an argumentative writing task, the nature of student–chatbot collaboration in writing, and its impact on the quality of students’ final writing products, within L2 writing instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract states that the study examines the influence of student–chatbot collaboration on the quality of writing, it describes the analysis as qualitative (interaction logs, think-aloud protocols, final texts, interviews) and does not indicate any experimental or quasi-experimental design or quantifiable outcome measures (e.g., scores, rubrics, pre–post comparisons). The focus appears to be qualitative exploration rather than measured intervention effects.""
    }
}"
327,Large Language Models Fall Short in Classifying Learners’ Open-ended Responses,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 143 Japanese university students studying English as a foreign language (EFL), which fits the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""LLMs are used to classify learners’ open-ended responses about their essay-writing process, not as part of an instructional or quasi-experimental writing intervention. The focus is methodological (classification accuracy), not on integrating LLMs into writing instruction or processes for learning.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on using LLMs for qualitative data analysis (classification of responses) and methodological implications, not on improving writing competence or writing-related pedagogical variables. There is no LLM-mediated writing instruction or support described.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study does not report quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity). Outcomes are Cohen’s kappa for classification agreement between LLMs and human coders, unrelated to learners’ writing performance.""
    }
}"
328,"Enhancing Efl Writing with Visualised Genai Feedback: a Cognitive Affective Theory of Learning Perspective on Revision Quality, Emotional Response, and Human-computer Interaction",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL learners, indicating second language English learners in an EFL context. The focus is on their English writing and revision performance.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a self-developed GenAI-powered writing chatbot based on large language models to provide feedback during writing revision. A 2×2 quasi-experimental design compares visualised vs. non-visualised GenAI feedback, satisfying the requirement for an LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL writing performance, specifically revision quality (coherence and cohesion) and related variables (emotional responses, cognitive load) within a GenAI-assisted writing context, not on automated scoring or system evaluation alone.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes via pre- and post-tests, showing that visualised feedback significantly improved coherence and cohesion in learners’ writing. These are measurable writing performance metrics aligned with the review’s criteria.""
    }
}"
329,Examining Longitudinal Development of Writing Motivation in the Genai Context: a Self-determination Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as '261 Chinese EFL student writers,' which fits L2 English learners in an EFL context with a focus on English writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that the study is conducted in 'generative AI (GenAI)-supported writing contexts' and that GenAI provides adaptive feedback and personalized support. However, it does not specify that the GenAI is an LLM (e.g., ChatGPT, GPT-4) or provide enough detail to confirm that the underlying technology is a transformer-based generative model.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on 'development of motivation' and four SDT constructs (autonomy, competence, relatedness, identified regulation) in GenAI-supported writing contexts. Writing competence or writing performance is not the main outcome; the study is framed as motivation research rather than a writing competence intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are motivational (curvilinear trajectories of motivation, gains in SDT-related constructs). The abstract does not mention any quantifiable writing performance metrics (e.g., writing scores, quality ratings, accuracy, complexity) used to assess the effectiveness of the GenAI intervention on writing outcomes.""
    }
}"
330,"Mastering Efl Writing with Chatgpt: a Systematic Review of Benefits, Challenges, and Best Practices",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on EFL students and their writing skills in English, which fits the target population of L2 English learners in EFL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is described as a systematic review drawing on 21 studies about ChatGPT in EFL writing, not as an experimental or quasi-experimental primary study implementing an LLM-based intervention itself. Review articles are to be excluded.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The review’s primary focus is on EFL writing instruction and writing-related outcomes such as accuracy, vocabulary use, fluency, and coherence, aligning with the writing competence context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although it summarizes that ChatGPT improves various aspects of writing, the paper is a systematic review and does not itself report original experimental outcome data from a specific intervention; per the criteria, reviews are excluded.""
    }
}"
331,Exploring High School Students’ Preferences for English Writing Feedback: Non-native English Teacher Vs. Native English Teacher Vs. Chatgpt,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are high school students in Korea in an English newspaper club, clearly an EFL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""ChatGPT, a generative AI LLM, is used to provide writing feedback alongside native and non-native English teachers. Although primarily comparative, it constitutes an LLM-based feedback intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on English writing feedback and students’ preferences among feedback sources, which is directly related to writing instruction and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports Likert-scale ratings of feedback preference and qualitative perceptions, but there is no indication of any measured change in writing performance or other quantifiable writing outcome metrics. It evaluates attitudes toward feedback sources rather than effectiveness on writing outcomes.""
    }
}"
332,An Ai-assisted Critical Thinking Intervention to Enhance Undergraduate Efl Learners’ Writing Proficiency,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 250 undergraduate EFL learners from three public universities. The context is explicitly EFL, and the focus is on English writing proficiency and critical thinking reflected in writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an AI-assisted critical thinking-oriented writing intervention supported with ChatGPT. ChatGPT is a large language model, and it is integrated as a scaffolding tool within the writing instruction. A pretest–posttest experimental design is employed.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing proficiency and critical thinking as reflected in writing. The intervention is a CT-oriented writing intervention, not just evaluation or scoring. ChatGPT is used pedagogically to support writing training in EFL contexts.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative writing outcomes are reported via pre- and post-writing tests evaluated across nine dimensions (clarity, accuracy, precision, relevance, depth, breadth, logic, significance, fairness). The abstract states that the intervention significantly enhanced students’ CT reflected in writing, indicating measurable writing-related outcomes.""
    }
}"
333,"Generative Ai Is Useful for Second Language Writing, but When, Why, and for How Long Do Learners Use It?",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states that the participants are L2 learners of English, indicating an ESL/EFL/ELL context focused on English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study involves learners using ChatGPT (an LLM) during a writing task, the design is observational: screen recordings and an open-ended question are analyzed. There is no indication of an experimental or quasi-experimental intervention (e.g., treatment vs. control, pre/post measures) integrating ChatGPT into instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is clearly on L2 writing processes: how learners use ChatGPT during a writing task (idea generation, grammar checking, polishing) and their perceptions of its usefulness for writing. This aligns with writing-related variables rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports frequency and time-series analyses of ChatGPT use and semantic network analyses of perceptions, but it does not mention any quantifiable writing outcome metrics (e.g., writing quality scores, accuracy, complexity) to assess effectiveness of the LLM-mediated intervention.""
    }
}"
334,From Feedback to Artificial Intelligence: a Bibliometric Mapping Analysis of the Thematic Evolution of Efl Writing Assessment Research Trends (2014–2024),2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a bibliometric mapping of EFL writing assessment research using 697 papers from Scopus. It does not report on a specific participant population of L2 English learners; instead, it analyzes publications as data units.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract notes that themes such as automated writing evaluation and artificial intelligence are emerging, the study itself is a bibliometric review and does not implement an experimental or quasi-experimental LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on mapping research trends in EFL writing assessment, not on conducting a pedagogical intervention or integrating LLMs into writing instruction or processes. It is a meta-level analysis of the literature.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics for learners are reported. Outcomes concern publication trends, thematic evolution, and network structures, not learner writing performance under an LLM-mediated intervention.""
    }
}"
335,"Integrating Ai in Pakistani Esl Classrooms: Teachers’ Practices, Perspectives, and Impact on Student Performance",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 100 undergraduate students in Pakistani ESL classrooms, clearly described as ESL learners with outcomes focused on English vocabulary and writing skills.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses AI tools such as Grammarly and QuillBot. These are not specified as LLM-based transformer generative models in the abstract and are listed in the protocol as examples of tools to be excluded when not LLM-based. No mention is made of ChatGPT, GPT-4, or other LLMs.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on ESL instruction with measured outcomes in vocabulary and writing performance, and discusses how AI tools support grammar correction and vocabulary enhancement in writing.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: pre- and post-tests on writing skills, with a reported +46% gain in writing performance (d=1.03) for the experimental group compared to the control group.""
    }
}"
336,Investigating the Role of Ai Tool Interactions in Enhancing English Language Acquisition among Saudi College Students,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Saudi college students learning English as a second language in an EFL context, and the focus is explicitly on English language acquisition.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study involves ChatGPT and other AI tools, it is a qualitative design using semi-structured interviews to explore how students use these tools. There is no experimental or quasi-experimental intervention integrating LLMs into instruction; rather, it is an exploratory usage/perception study.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract notes that students use ChatGPT primarily for writing assistance, brainstorming, and translation, but the primary focus is broader English language acquisition and AI tool use, not a structured writing competence intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is purely qualitative, using thematic analysis of interviews. It does not report quantifiable writing outcome metrics or measure the effectiveness of an LLM-mediated writing intervention.""
    }
}"
337,A Comparative Study of Human and Ai-assisted Assessment Using Chatgpt: the Case of Moroccan Efl Learners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses writing assignments from EFL classes in Moroccan higher education, indicating participants are Moroccan EFL (L2 English) learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT-4 is used as an AI-assisted grader to compare AI and human assessment. There is no indication of an instructional or process-oriented writing intervention; the LLM is not integrated into teaching or supporting learners’ writing, only into assessment.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on summative e-assessment and the comparability of AI vs. human grading. This aligns with automated essay scoring research rather than pedagogical intervention targeting writing competence or writing-related learning processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports grading score differences between human and AI assessments, but these are not outcomes of an LLM-mediated writing intervention. No experimental manipulation of writing instruction or process with LLM support is described, and no learner writing gains attributable to LLM use are measured.""
    }
}"
338,Preserving Authorial Voice in Academic Texts in the Age of Generative Ai: a Thematic Literature Review,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract notes that the topic is particularly relevant in ESL university settings and that the majority of synthesized studies were conducted there, indicating a focus on L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a thematic literature review, not an experimental or quasi-experimental primary study. It synthesizes findings from 18 papers and discusses AI writing tools in general, without reporting a specific LLM-based intervention implemented by the authors.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the review concerns academic writing, authorial voice, and AI tools, it does not present a concrete pedagogical intervention or instructional context implemented and evaluated by the authors; it is a secondary synthesis of existing work.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a thematic literature review, the article does not report original quantitative writing outcome metrics from an intervention study; instead, it summarizes stylistic and linguistic differences and pedagogical implications from prior research.""
    }
}"
339,"A Q Method Study on Turkish Efl Learners’ Perspectives on the Use of Ai Tools for Writing: Benefits, Concerns, and Ethics",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Turkish English language learners enrolled in a preparatory program at a state university in Istanbul, clearly an EFL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a Q methodological investigation of learners’ perspectives on AI tools. It does not describe an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into instruction; rather, it surveys existing usage and attitudes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is writing and AI tools, the primary focus is on perceived benefits, concerns, and ethics, not on a structured pedagogical writing intervention or instructional design using LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study uses Q methodology and qualitative interviews to explore perceptions, without measuring changes in writing performance or related quantitative outcomes.""
    }
}"
340,From Struggle to Mastery: Ai-powered Writing Skills in Esl Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 10th grade ESL learners in a bilingual secondary school in Colombia, explicitly described as ESL students working on academic writing in English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention integrates AI-powered tools Grammarly and ChatGPT. Grammarly is a grammar-checking tool that is not clearly an LLM-based generative model in this context. The abstract does not specify that the intervention or measured effects are attributable specifically to an LLM (e.g., ChatGPT) rather than to a mixed or non-LLM AI tool. Because the design and outcomes are tied to a combined Grammarly+ChatGPT package, it does not meet the requirement of a clearly LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on improving academic writing skills (grammar accuracy, textual coherence, organizational structure) through integration of AI tools within the Writing Workshop Instructional Model. This is a pedagogical writing intervention, not an automated scoring or purely functional evaluation study.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that combining WWIM with AI feedback ‘significantly improved students’ academic writing performance,’ implying quantitative outcome measures of writing performance, alongside reported changes in confidence and engagement.""
    }
}"
341,The Impact of Automated Writing Evaluation on Writing Gains,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 105 first-year university students in Belgium described as English as a foreign language (EFL) students, clearly indicating L2 English learners in an EFL context with focus on English writing skills.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines the effectiveness of ChatGPT, explicitly a large language model, in improving English writing skills over a nine-week intervention. It compares a teacher-feedback-only group with a group using ChatGPT alongside teacher feedback, indicating an experimental design integrating an LLM into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence, specifically syntactic and lexical complexity as key dimensions of writing development, and on text length and complexity. ChatGPT is used as part of a pedagogical writing intervention, not merely as an automated scoring tool.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes, including measures of syntactic and lexical complexity and text length, to assess ChatGPT’s impact on writing gains and sustained writing improvement over a nine-week period.""
    }
}"
342,Exploring the Impact of Ai Technologies on Efl Writing Proficiency,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The participants are Saudi EFL teachers at King Saud University, not L2 English learners. The study focuses on teachers’ perspectives rather than learner data or learner outcomes.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is mentioned, the study uses a descriptive survey design to explore teachers’ perceptions. There is no experimental or quasi-experimental intervention integrating ChatGPT into learners’ writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on perceived merits and challenges of using ChatGPT in writing classes, not on an implemented pedagogical intervention targeting writing competence. It is essentially an attitudinal/perception study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes are reported. The study gathers questionnaire data from teachers about perceptions; there are no measured changes in students’ writing performance or related variables.""
    }
}"
343,Cognitive Offload Instruction with Generative Ai: a Quasi-experimental Study on Critical Thinking Gains in English Writing,2025,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as “first-year university students” in “English essay writing” and the conclusion mentions “second-language writing contexts,” but it is not explicitly stated that these particular participants are L2 English learners (ESL/EFL/ELL). The population could be native or mixed, so eligibility is uncertain.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “generative AI-enabled cognitive offload instruction” and “generative AI tools,” but does not specify whether these are large language models (e.g., ChatGPT/GPT-4 or similar transformer-based generative models) versus other generative systems. Without explicit mention of LLM-based tools, it is unclear if the intervention meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is English essay writing, with AI used for brainstorming, co-revision, and other writing-related processes. Outcomes include essay quality (logical coherence, evidence use, originality), indicating a primary focus on writing competence and writing-related variables rather than solely on assessment or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental design comparing traditional vs AI-augmented instruction and reports quantifiable outcomes: standardized critical thinking assessments and measurable essay quality indicators (logical coherence, evidence use, originality). These constitute quantifiable writing-related outcome metrics.""
    }
}"
344,Revising with Intelligence: Chatgpt Feedback and Its Impact on Efl Students’ Revision and Self-efficacy,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 82 university-level EFL students, i.e., English as a Foreign Language learners, and the context is English writing development. This matches the required L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental design with two groups: a ChatGPT-supported writing group and a teacher-supported writing group. ChatGPT, a large language model, is integrated as the feedback provider in the writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on writing development and revision in a process-based writing instruction context. Outcomes include revision productivity, macro-level and content-based revisions, and writing self-efficacy related to revision and discourse organization, all of which are writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative outcomes: significant increases in revision productivity, more macro-level and content-based revisions, and higher self-efficacy gains across three dimensions. These are structured, measurable outcomes of the LLM-mediated writing intervention.""
    }
}"
345,Traditional Strategies and Ai-integrated Strategies in Learning English among Efl Omani Students,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL Omani students at a public Omani university, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a survey using a questionnaire (Likert-scale items) about traditional and AI-integrated learning strategies. It does not describe an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT, GPT-4) into instruction; AI tools are referenced generically as strategies, not as a tested LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on general learning strategies (listening, speaking, pronunciation, grammar, writing) and gender/academic level differences in their use. Writing is only one of several skills and is not the primary focus of a pedagogical intervention; the study is about strategy use, not a writing-focused instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are self-reported frequency of using strategies (Likert scores), not quantifiable writing performance measures. There is no assessment of changes in writing competence or writing-related performance resulting from an LLM-mediated intervention.""
    }
}"
346,Design Opportunities for Explainable Ai Paraphrasing Tools: a User Study with Non-native English Speakers,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as non-native English speakers (NNESs), but the abstract does not specify whether they are in ESL/EFL/ELL learning contexts or formal L2 English learners, nor their educational setting.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses ParaScope, an AI paraphrasing assistant, but the abstract does not state that it is based on a large language model (e.g., ChatGPT/GPT-style transformer). It could be another type of AI paraphraser, so LLM integration cannot be confirmed from the abstract alone.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on interaction with AI-generated paraphrases, information aids, and design implications for explainable AI tools. While related to writing support (paraphrasing, confidence, autonomy, efficiency), it is framed as a user study and design exploration rather than a pedagogical writing intervention aimed at improving writing competence in an instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports outcomes such as confidence, autonomy, and writing efficiency, but does not mention any quantifiable writing quality metrics or experimental evaluation of writing performance. It centers on user preferences and interaction patterns, not measured writing outcomes.""
    }
}"
347,The Role of Ai in Improving Writing Skills of Indian Undergraduate Efl Learners: a Research Review,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract focuses on Indian undergraduate EFL learners, clearly identifying L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a research review examining the potential of AI writing tools; it does not report an experimental or quasi-experimental intervention, nor does it specify use of LLM-based tools like ChatGPT in an implemented study.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on improving writing skills and EFL writing training, discussing how AI tools might support writing-related competencies.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a review article, it does not report original quantitative writing outcome metrics from an intervention; it discusses potential benefits and challenges conceptually and calls for further investigation.""
    }
}"
348,Coachgpt: a Scaffolding-based Academic Writing Assistant,2025,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions that academic writing can be overwhelming 'particularly when writing in a second language,' but it does not specify that the study participants are L2 English learners in ESL/EFL/ELL contexts, nor does it state the target language of the writing tasks. The population and language focus remain ambiguous.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study develops CoachGPT, an AI agent-based web application that 'provides real-time feedback and suggestions using large language models.' This is an LLM-based writing assistant integrated into the writing process, and the description implies an intervention-like use (scaffolding, sub-tasks, feedback) rather than mere evaluation of the tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on 'academic writing skills' and assisting 'academic writing' through scaffolding and feedback. The tool is explicitly a 'writing assistant,' and the context is improving or supporting writing competence, not automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that 'Our user studies prove the usefulness of CoachGPT and the potential of large language models for academic writing,' but it does not specify whether these user studies include quantifiable writing outcome metrics (e.g., writing scores, quality ratings, measurable improvement) versus only usability or perceived usefulness. No explicit experimental measures of writing performance are described.""
    }
}"
349,Chatgpt for English Writing: a Qualitative Inquiry among English Major Students at Thai Higher Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are seven fourth-year English majors in Thailand, explicitly described as Thai English as a Foreign Language (EFL) students, so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study concerns ChatGPT, it is a qualitative inquiry into students’ attitudes and perceptions. There is no indication of an experimental or quasi-experimental design integrating ChatGPT as a structured writing intervention; rather, it explores perceived roles and experiences.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on ChatGPT’s roles in English writing, including vocabulary, grammar, and content organization, which are writing-related variables in an L2 context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly qualitative, using semi-structured interviews and thematic analysis to explore attitudes and perceptions. It does not report quantifiable writing outcome metrics or measure changes in writing performance following an intervention.""
    }
}"
350,The Collaboration of Ai and Teacher in Feedback Provision and Its Impact on Efl Learner’s Argumentative Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 28 tenth-grade EFL learners focusing on English argumentative writing, which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses DeepL Write as the AI tool. DeepL Write is primarily a machine translation/AI writing assistance tool and is not clearly identified as an LLM-based (transformer generative) system like ChatGPT, GPT-4, Gemini, etc. The abstract does not indicate use of a large language model; thus it does not meet the specified LLM-based intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly targets English argumentative writing and examines the impact of AI and teacher feedback on writing quality (lexical, grammatical, content, coherence, cohesion), which aligns with a primary focus on writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study compares writing quality across three drafts using Coh-Metrix, providing quantifiable outcome measures of writing performance under AI-only and teacher+AI feedback conditions.""
    }
}"
351,Assigning Cefr-j Levels to English Learners’ Writing: an Approach Using Lexical Metrics and Generative Ai,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The system is designed for assessing English learners’ writing proficiency in an EFL context (CEFR-J, particularly in Japan), so the population is L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study develops and validates an automated writing level analyzer (CWLA) using lexical metrics and AI-based scoring. It is an assessment tool validation study, not an experimental or quasi-experimental pedagogical intervention integrating an LLM into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automated assessment of writing proficiency (scoring alignment with CEFR-J, correlation with human ratings), i.e., functionality as an automated scoring system. There is no described instructional or intervention context targeting writing competence development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are tool validation metrics (correlation with human ratings, entropy analysis, expert agreement). There is no experimental or quasi-experimental writing intervention and no quantifiable pre/post or comparative writing outcome measures for learners.""
    }
}"
352,Modeling Chinese Efl Learners’ Intention to Use Generative Ai for L2 Writing through an Integrated Model of the Tam and Ttf,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese EFL learners (304 university students in China) using generative AI for L2 English writing, clearly fitting an EFL/ELL English-learning context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a survey and structural equation modeling (TAM + TTF) to examine intention to use generative AI. There is no experimental or quasi-experimental pedagogical intervention integrating a specific LLM into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on technology acceptance and task–technology fit for generative AI as an English writing assistant, not on an implemented writing intervention or instructional context where writing competence is directly targeted.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes are psychological/behavioral (perceived usefulness, ease of use, attitude, behavioral intention), not measures of writing performance or related writing skills.""
    }
}"
353,"A Mixed-methods Study on the Use of Chatgpt in the Pre-writing Stage: Efl Learners’ Utilization Patterns, Affective Engagement, and Writing Performance",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 56 first-year university students described explicitly as English as a Foreign Language (EFL) learners. The focus is on English argumentative writing tasks, fitting ESL/EFL/ELL L2 English contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT, a large language model, as support in the pre-writing stage. It employs a mixed-methods design with two writing tasks (with vs. without ChatGPT), constituting an experimental/quasi-experimental intervention integrating an LLM into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence and related variables: pre-writing strategies, text quality, and affective engagement during writing. ChatGPT is used pedagogically in the planning stage of argumentative writing, not merely for automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports quantifiable writing outcomes: learners ‘produced better text quality’ in the ChatGPT condition and a ‘moderate positive correlation’ between affective engagement and overall writing performance. This indicates measured, comparative writing performance data as part of the intervention evaluation.""
    }
}"
354,Predicting Kazakhstani Tefl Students’ Continuance Intention towards Using Chatgpt in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are TEFL (Teaching English as a Foreign Language) students at two Kazakhstani universities, i.e., L2 English learners in an EFL context, and the focus is on academic writing in English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is the focal tool, the study is not an experimental or quasi-experimental intervention in writing instruction. It examines perceptions and continuance intention via a survey model, not a structured pedagogical writing intervention using ChatGPT.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on technology acceptance variables (perceived usefulness, ease of use, satisfaction, continuance intention) rather than on developing or assessing writing competence through an instructional intervention. It is not a writing pedagogy study but a usage-intention study in an academic writing context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, text quality measures) are reported. Outcomes are psychological/behavioral (perceptions, satisfaction, continuance intention) and qualitative comments, not measured changes in writing performance.""
    }
}"
355,Exploring the Potential of Genai for Personalised English Teaching: Learners' Experiences and Perceptions,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are first-year English for Academic Purposes students, i.e., L2 learners in an EAP/ESL-type context, and the focus is on English language competencies.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on learners’ use of GenAI tools such as Grammarly and Quillbot. These are not clearly described as LLM-based generative tools in an instructional intervention; rather, they are general support tools whose underlying models may not be transformer-based LLMs as required. There is no explicit experimental or quasi-experimental LLM-mediated writing instruction design.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions L2 writing instruction and improvements in grammar, writing, vocabulary, and reading, but the primary emphasis is on experiences and perceptions of GenAI tools rather than a structured pedagogical writing intervention or writing competence as the central outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study uses surveys and interviews and reports usage rates (e.g., 66.7% regularly used the tools), it does not report quantifiable writing outcome metrics (e.g., pre/post writing scores, rubric-based writing performance). The focus is on perceived helpfulness and experiences, not measured changes in writing performance.""
    }
}"
356,The Impact of Integrating Chatgpt with Teachers’ Feedback on Efl Writing Skills,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 68 intermediate Iranian EFL learners, explicitly identified as English as a foreign language learners working on IELTS Task 2 argumentative essays. The focus is clearly on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention integrates ChatGPT, described as a state-of-the-art AI chatbot, with teacher feedback to provide individualized writing feedback. Learners were randomly assigned to ChatGPT+teacher feedback vs teacher-only feedback, indicating an experimental design using an LLM-based tool in writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL writing skills and improvement in IELTS Task 2 argumentative essays. ChatGPT is used pedagogically to provide feedback on writing, not as an automated scoring tool. Outcomes relate directly to writing competence (task achievement, coherence, cohesion, vocabulary, grammar).""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: Paired Samples t-Test results showing significantly greater improvement for the ChatGPT+teacher group across IELTS scoring criteria (task achievement, coherence, cohesion, vocabulary, grammar range and accuracy). These are structured, measurable writing outcomes.""
    }
}"
357,Mobile Ai Tools in Language Learning: Efl Students’ Acceptance of Chatgpt for Writing Brainstorming,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 257 EFL students at a Vietnamese university, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used for writing brainstorming, the study focuses on students’ acceptance and perceptions. There is no indication of an experimental or quasi-experimental instructional intervention design; rather, it is a survey of existing use.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly writing-related: use of ChatGPT for brainstorming in a writing class and support for enhancing writing quality and skills.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a Likert-scale questionnaire and interviews to examine acceptance, perceptions, advantages, and disadvantages. It does not report quantifiable writing performance outcomes (e.g., scores, rubric-based writing measures) from an intervention, only self-reported perceptions of impact.""
    }
}"
358,The Development and Validation of a Scale on Student Ai Literacy in L2 Writing: a Domain-specific Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 435 and 350 Chinese university students engaged in L2 writing, implying they are L2 English learners in an EFL context. The scale is explicitly for L2 writing, and in Chinese university contexts this typically refers to English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study develops and validates a self-report scale of student AI literacy in L2 writing. It does not describe an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT, GPT-4) into writing instruction or processes; rather, it is a psychometric instrument development study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on measuring AI literacy (understanding, use, evaluation, ethics) via a questionnaire, not on implementing or evaluating a writing intervention or instructional context that targets writing competence or writing-related performance outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, text quality measures) are reported. The outcomes are psychometric properties of the AI literacy scale (factor structure, reliability), not changes in writing performance following an LLM-mediated intervention.""
    }
}"
359,Students' Perceptions and Usage Patterns of Chatgpt as an Automated Writing Evaluation (awe) Tool,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 47 graduate EFL students at a university in Hong Kong, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used as an Automated Writing Evaluation tool, the study is descriptive, focusing on how students interact with it and their perceptions. There is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on perceptions and usage patterns of ChatGPT as an AWE tool, not on a structured pedagogical writing intervention or systematic integration into writing instruction aimed at improving competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Data were collected via a questionnaire survey about usage patterns and perceptions. The abstract does not report any quantifiable writing outcome measures (e.g., changes in writing scores, quality, accuracy) resulting from ChatGPT use.""
    }
}"
360,A Pilot Study on Bridging Efl Writing and Speaking Skills through Ai-enhanced Authentic Short Video-making,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 20 first-year university students in an EFL context (public university in central Taiwan), clearly L2 English learners.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions 'Artificial Intelligence-enhanced authentic short video-making (AI-eSV)' but does not specify the use of large language models (e.g., ChatGPT, GPT-4) or any transformer-based generative model. The nature of the AI enhancement (e.g., editing, recommendation, or LLM-based support) is not described.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing is a primary focus: students engaged in collaborative scriptwriting, and outcomes include improvements in writing skills such as creativity and content organization. The intervention is pedagogical, not just assessment-focused.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although a pretest-posttest design is used and results report 'significant improvements' in writing and speaking, the abstract does not indicate that the AI component is specifically an LLM-based writing intervention. Given the review’s scope, AI tools must be LLM-based; here, the AI type is unspecified, so it cannot be assumed to be an LLM-mediated writing intervention with quantifiable LLM-related writing outcomes.""
    }
}"
361,Exploring Efl Learners’ Academic Emotions and Emotion Regulation Strategies in Ai-assisted Collaborative Academic Writing Tasks,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as EFL learners, which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions a '6-week AI-assisted collaborative academic writing project' and 'AI feedback limitations,' but does not specify that the AI is an LLM (e.g., ChatGPT, GPT-4) rather than another type of AI tool. The nature of the AI system is not clear from the abstract alone.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is AI-assisted collaborative academic writing, the primary focus of the study is on academic emotions and emotion regulation strategies, not on writing competence or writing-related performance variables. Writing is the task context, not the main outcome of interest.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports data from questionnaires and semi-structured interviews about emotions and regulation strategies. It does not mention any quantifiable writing outcome metrics (e.g., writing scores, quality measures, accuracy, complexity) to assess the effectiveness of the AI-assisted writing intervention.""
    }
}"
362,The Benefits and Risks of Ai-assisted Academic Writing: Insights from Current Research; Prednosti in Tveganja Pri Znanstvenem Pisanju S Pomočjo Umetne Inteligence: Spoznanja Iz Aktualnih Raziskav,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses “English as a foreign language” and “English language students’ writing abilities,” implying an EFL/ESL population, but it does not specify concrete participant groups or empirical samples; it appears to be a conceptual/literature-based paper.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as “a review of existing literature and a discussion of the findings of recent studies,” not as an experimental or quasi-experimental intervention study. It does not report implementing ChatGPT in a controlled instructional setting.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus is on writing and AI-assisted academic writing, the paper is positioned as an overview of benefits and risks, not as a primary empirical intervention study targeting writing competence through LLM integration.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any original quantitative writing outcome measures or experimental results; it synthesizes insights from multiple studies instead, fitting a review-type article rather than reporting structured intervention outcomes.""
    }
}"
363,Enhancing Writing Accuracy and Empowering Students: the Transformative Influence of Chatgpt’s Informative Feedback on Students’ Writing,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 50 undergraduate students enrolled in English language courses, indicating L2 English learners in an ESL/EFL/ELL-type context. The focus is clearly on English writing development.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study evaluates instructional assistance formative feedback provided by ChatGPT, a large language model, as part of writing instruction. This constitutes an LLM-based intervention integrated into learners’ writing processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on enhancing learners’ writing skills and writing accuracy, with outcomes such as coherence, grammar, and engagement with the writing process. ChatGPT is used pedagogically as a formative feedback tool, not merely for scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""A mixed-methods design includes quantitative data from students’ essays and TAM surveys. The abstract reports significant improvements in writing quality (coherence, grammar, engagement), indicating quantifiable writing outcome metrics were analyzed.""
    }
}"
364,Exploring Potential Biases in Gpt-4o’s Ratings of English Language Learners’ Essays,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses the ELLIPSE corpus (English Language Learner Insight, Proficiency and Skills Evaluation), which consists of essays written by English language learners, indicating an L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""GPT-4o is used solely as an automated essay scoring (AES) tool to rate existing essays. There is no experimental or quasi-experimental instructional intervention integrating the LLM into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on GPT-4o’s fairness and bias as an AES system (rating bias across gender, race/ethnicity, SES), not on improving learners’ writing competence or implementing a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although essay scores are analyzed, they are used to evaluate GPT-4o’s rating bias, not as outcomes of an LLM-mediated writing intervention. No instructional treatment or change in writing performance is measured.""
    }
}"
365,"The Impact of Self-revision, Machine Translation, and Chatgpt on L2 Writing: Raters’ Assessments, Linguistic Complexity, and Error Correction",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as learners in a South Korean high school English as a Foreign Language (EFL) context, clearly indicating L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a controlled experiment with three proofreading interventions, including ChatGPT-assisted proofreading (CAP). ChatGPT is an LLM integrated into the writing process as part of an experimental design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on L2 writing outcomes (overall writing quality, text length, lexical diversity, sentence complexity, grammatical and prepositional errors) and on how MT and ChatGPT can be integrated into L2 writing pedagogy. This is a pedagogical writing intervention, not just automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports quantifiable writing outcome metrics: overall writing quality (raters’ assessments), text length, lexical diversity, sentence complexity, verb cohesion, and grammatical/prepositional error rates, comparing SP, MT-assisted, and ChatGPT-assisted conditions.""
    }
}"
366,Trinka: Facilitating Academic Writing through an Intelligent Writing Evaluation System,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions potential integration into second language (L2) writing instruction but does not specify any actual participant population, nor whether they are L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is described as a technology review of Trinka, an intelligent writing evaluation system. There is no indication of an experimental or quasi-experimental study design, nor explicit evidence that Trinka is an LLM-based (transformer generative) tool used in an intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on describing features and potential integration of Trinka, not on an implemented pedagogical intervention with measured effects on writing competence. It is a review of a tool rather than a study of a writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental results are reported. The paper is a technology review discussing potential benefits and limitations, without empirical measures of writing improvement.""
    }
}"
367,A Qualitative Descriptive Study of Teachers’ Beliefs and Their Design Thinking Practices in Integrating an Ai-based Automated Feedback Tool,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is Norwegian 9th-grade students in English as a second language classes, indicating L2 English learners in an ESL/EFL/ELL setting. The focus is on L2 writing in English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although an AI-driven automated feedback tool (Essay Assessment Technology, EAT) is used, the abstract does not specify that it is a large language model (e.g., ChatGPT/GPT-like transformer-based generative model). It is presented as an automated feedback/assessment tool, and there is no indication it is an LLM-based generative system integrated into instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on teachers’ beliefs, perceptions, user experiences, and design thinking practices when integrating an AI-based automated feedback tool, not on students’ writing competence or writing-related learning outcomes. It is essentially about technology integration and teacher cognition, not a pedagogical writing intervention outcome study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly described as a descriptive qualitative study using teacher interviews. No quantitative or experimental writing outcome measures (e.g., writing scores, accuracy, complexity) are reported. The focus is on perceptions and pedagogical decisions, not measurable changes in student writing performance.""
    }
}"
368,The Differential Impact of Ai Tools among Efl University Learners: a Process Writing Approach,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Vietnamese EFL majors (first-year university students), clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Grammarly, Write & Improve, and Slick Write. These are AI writing assistants but are not described as large language model (LLM)-based transformer generative systems like ChatGPT or GPT-4. They primarily provide grammar checking, feedback, and readability analysis, which falls outside the review’s required LLM-based interventions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on writing proficiency and related variables (grammatical correctness, task completion, coherence, language range) within a process writing approach, aligning with a writing competence context rather than automated scoring only.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative pre- and post-test scores are analyzed via paired t-tests and logistic regression, reporting significant changes in grammatical correctness, task completion, coherence, and language range. These are clear, quantifiable writing outcome metrics.""
    }
}"
369,Integrating Quillbot to Enhance Students’ Academic Writing: Opportunities and Challenges,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract focuses on a review of studies involving EFL students using QuillBot, but it is itself a review article, not an empirical study with its own participant population. Review articles are excluded by design.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper is a critical review of 15 articles on QuillBot, not an experimental or quasi-experimental study implementing an LLM-based intervention. Moreover, QuillBot is generally not classified as an LLM-based generative tool in the sense required (e.g., ChatGPT, GPT-4).""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the topic is academic writing, the article synthesizes themes (emotional impact, user experience, ethics) rather than reporting a specific pedagogical intervention or instructional context implemented by the authors.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a qualitative thematic review and does not report original quantitative writing outcome metrics from an intervention conducted by the authors. It summarizes prior work and methodological limitations instead.""
    }
}"
370,Effects of the Use of Generative Ai Tools on Eap Writing Development: a Case Study with Medicine Undergraduates,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'undergraduate EFL learners' at a Saudi university, majoring in Medicine and taking English for Academic Purposes (EAP). The focus is clearly on English as a foreign language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses 'AI tools, such as ResearchRabbit for referencing, Acrobat Chat with PDFs for summary, and Otio for grammar check and planning, drafting and revising the essays.' These tools are not identified as LLM-based systems like ChatGPT/GPT-4, and at least ResearchRabbit and Acrobat Chat with PDFs are primarily retrieval/summarization/reference tools rather than explicit LLM-mediated writing instruction. The abstract does not clearly indicate integration of a transformer-based generative LLM into the writing process as required.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly targets 'writing development' in EAP, teaching students to 'plan, organize, draft, revise and prepare the final drafts of the essays.' The primary focus is on writing competence, not on automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative writing outcomes are reported: pre-test and post-test essay scores, comparison between experimental and control groups, mean difference of 2.95 points, and t-test values with statistical significance. These constitute measurable writing outcome metrics.""
    }
}"
371,Efl Pre-service Teachers’ Acceptance of Chatgpt for Writing: a Sequential Explanatory Mixed-method Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL pre-service teachers from four universities in Indonesia, clearly positioning them as L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines acceptance and intention to use ChatGPT via a TAM questionnaire and interviews. There is no indication of an experimental or quasi-experimental instructional intervention where ChatGPT is integrated into actual writing instruction or tasks.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on technology acceptance, perceptions, and ethical concerns regarding ChatGPT for writing, not on a structured pedagogical writing intervention or measured changes in writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes are attitudinal (perceived usefulness, ease of use, behavioral intention) and qualitative perceptions, without assessment of writing performance.""
    }
}"
372,From Prompting to Proficiency: a Mixed-methods Analysis of Prompting with Chatgpt Versus Lecturer Interaction in an Efl Classroom,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 60 Indonesian university students in an EFL classroom context. The abstract explicitly refers to English as a Foreign Language (EFL) and reports outcomes in general English proficiency and writing competency, indicating L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is prompting with ChatGPT, explicitly described as an extensive/large language model (GenAI). Students were allocated to an experimental (ChatGPT) and a control (lecturer) group, indicating an experimental or quasi-experimental design integrating an LLM into instruction/help-seeking.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""One of the primary measured outcomes is writing competency, and the study compares ChatGPT versus lecturer interaction in an EFL classroom. The context clearly involves writing instruction/academic help-seeking with a focus on writing-related competence, not just automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pre/post-tests including a writing test and analyzes data via ANCOVA. It reports that the ChatGPT group significantly outperformed the control group in writing competency (p < .001), providing quantifiable writing outcome metrics.""
    }
}"
373,Using Ai-supported Peer Review to Enhance Feedback Literacy: an Investigation of Students' Revision of Feedback on Peers' Essays,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 44 Chinese undergraduate students providing feedback on peers’ English argumentative essays in an L2 writing classroom context, i.e., L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study introduces EvaluMate, an AI-supported peer review system with a large language model-based chatbot (Eva) that evaluates and provides feedback on students’ comments. This is an LLM-based pedagogical intervention integrated into the writing/peer review process.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on enhancing students’ peer feedback provision skills and the quality of peer review comments, not on learners’ own writing competence or writing performance. Outcomes concern comment quality and revision strategies, rather than writing quality or related writing competence variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study reports quantifiable improvement in the quality of peer review comments, it does not report quantifiable outcomes on students’ own writing performance or writing-related competence. The measured outcome is feedback/comment quality, not L2 writing outcomes as required.""
    }
}"
374,Leveraging Chatgpt for Research Writing: an Exploration of Esl Graduate Students’ Practices,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as two ESL graduate students, indicating L2 English learners in an ESL context, and the focus is on their English research writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the study is a case study of naturally occurring student practices after a tutorial on AI literacy. There is no experimental or quasi-experimental design testing an LLM-based instructional intervention; rather, it explores how students choose to use ChatGPT.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is research writing by ESL graduate students, with attention to genre, content, language use, documentation, coherence, and clarity—clearly focused on writing competence and writing-related processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative findings about how students use ChatGPT and maintain academic integrity and scholarly voice. It does not mention any quantifiable writing outcome metrics or measured effectiveness of the LLM-mediated intervention.""
    }
}"
375,“teaching Is Basically Feeling”: Unpacking Efl Teachers’ Perceived Emotions and Regulatory Strategies in Ai-powered L2 Speaking and Writing Skills Instruction,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 21 Iranian EFL teachers working in English as a foreign language contexts, so the population is clearly situated in L2 English teaching/learning settings.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract refers broadly to “AI tools” in L2 speaking and writing classes but does not specify large language models (e.g., ChatGPT, GPT-4) nor describe any experimental or quasi-experimental intervention design. It is a qualitative study of perceptions, not an LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on teachers’ AI-induced emotions and regulatory strategies during L2 speaking and writing instruction, not on writing competence or writing-related performance variables. Writing is only the instructional context, not the main outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly qualitative, using semi-structured interviews and narrative frames, and reports thematic findings about emotions and regulation. No quantifiable writing outcome metrics or measures of writing performance are reported.""
    }
}"
376,"The Impact of Artificial Intelligence and Machine Learning on Linguistic Accuracy, Fluency, and Self-direction among Advanced Efl Students",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'advanced EFL students' and 'those who speak English as a foreign language,' clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses 'technology-enhanced adaptive grammar tools, translation software, and artificial intelligence-driven feedback systems.' There is no indication that these are large language model (LLM)-based tools (e.g., ChatGPT, GPT-4). They could be traditional AI/ML or rule-based systems, and no transformer-based generative model is specified.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on 'linguistic accuracy, fluency, and self-direction' in writing, with explicit mention of 'students’ writing fluency' and 'Linguistic precision,' indicating a primary focus on writing competence rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports 'a significant improvement in students’ writing fluency' and differences in 'learners’ autonomy and Linguistic precision' between experimental and control groups, implying quantifiable outcome measures following an experimental intervention.""
    }
}"
377,Guarding Integrity: a Case Study on Tackling Ai-generated Content and Plagiarism in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are in an ENG102 advanced writing course and freshman writing assessments, which suggests L2 English learners are possible, but the abstract does not specify ESL/EFL/ELL status or that English is a second language for the participants.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""AI is used in the context of Turnitin’s detection of AI-generated content and plagiarism. There is no indication of an experimental or quasi-experimental design integrating an LLM (e.g., ChatGPT) into writing instruction or writing processes as an intervention; AI is only part of integrity monitoring.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is academic integrity (plagiarism and AI-generated content rates, attitudes toward cheating), not on improving writing competence or writing-related pedagogical interventions. Writing is the context of assessment, not the target of instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports plagiarism and AI usage rates and student attitudes, but does not report quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity) resulting from an LLM-mediated writing intervention.""
    }
}"
378,Teachers' Use of Generative Ai in Jordanian Universities: Practices and Perceptions,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on EFL instructors at Jordanian universities, not on L2 English learners. Data are about teachers’ perceptions and practices, not learner outcomes or learner participants.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although generative AI tools such as ChatGPT and ChatPDF are mentioned, the study investigates instructors’ perceptions and practices via surveys and interviews. There is no experimental or quasi-experimental design integrating LLMs into actual writing instruction or learner writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is the development of reading and writing materials and general EFL teaching with AI, not a focused intervention targeting learners’ writing competence or writing-related performance variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports instructors’ perceptions, practices, and perceived opportunities/challenges. It does not report quantifiable learner writing outcome metrics or evaluate the effectiveness of an LLM-mediated writing intervention.""
    }
}"
379,Ai-assisted L2 Assessment: a Biblio-systematic Analysis,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The article is a biblio-systematic analysis of AI-assisted L2 assessment and synthesizes 57 SSCI-indexed articles. While many of these likely involve L2 English learners, the abstract does not specify that the focus is exclusively or primarily on L2 English, nor does it provide participant details for individual studies.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a secondary study (biblio-systematic/bibliometric review) analyzing prior research on AI-assisted L2 assessment. It does not itself implement an experimental or quasi-experimental LLM-based writing intervention; instead, it maps existing literature and technologies (e.g., automated scoring systems, NLP tools).""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is AI-assisted L2 assessment broadly (writing and speaking), not a specific pedagogical intervention targeting writing competence. It examines assessment tools and their use, not an instructional context or writing intervention design.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a bibliometric/systematic overview, the study does not report original, quantifiable writing outcome metrics from an intervention it conducts. It summarizes effectiveness, advantages, and challenges across studies, which falls outside the inclusion criteria requiring primary experimental outcome data.""
    }
}"
380,Korean Efl Learners’ Perceptions of Using Chatgpt for English Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Korean EFL (English as a foreign language) learners, so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, the design is exploratory and perception-focused. Students compared their original writing with ChatGPT-edited versions and wrote reflection notes; there is no indication of an experimental or quasi-experimental intervention design to test instructional effects.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly English writing: students use ChatGPT for English writing, compare their drafts with ChatGPT-edited versions, and discuss feedback types, which is directly related to writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports perceptions, engagement with feedback types, and questionnaire responses about advantages and disadvantages. There is no mention of quantitative writing outcome measures (e.g., scores, quality ratings, accuracy gains) to assess effectiveness of the LLM-mediated intervention.""
    }
}"
381,Unleashing the Transformers: Nlp Models Detect Ai Writing in Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not describe any participant sample or learning context (ESL, EFL, or ELL). It only mentions datasets of human- and AI-generated abstracts and general concerns about non-native speakers, without indicating an L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses transformer models (e.g., BERT) to detect whether text is AI- or human-generated. There is no experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or writing processes; the models are used as detectors, not instructional tools.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on AI-writing detection in education, not on developing or assessing writing competence or writing-related pedagogical interventions. It is essentially a detection/classification study, not a writing instruction context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy, fluency) are reported. Outcomes concern detection accuracy of AI vs. human text, not learner writing performance following an LLM-mediated intervention.""
    }
}"
382,Exploring Learner Prompting Behavior and Its Effect on Chatgpt-assisted English Writing Revision,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states the participants are EFL learners engaged in English writing revision, indicating L2 English learners in an EFL context with a focus on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT as an assistant in English writing revision and employs a one-group pretest–posttest experimental design. ChatGPT is a large language model integrated into the writing revision process, satisfying the LLM-based intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on English writing revision quality, including surface-level and higher-order writing elements (content, organization, cohesion). The context is clearly writing competence and writing-related variables, not automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a one-group pretest–posttest experiment and reports measurable changes in writing quality (improvements in surface-level aspects, minimal enhancement in higher-order elements). The use of Wilcoxon signed-rank test indicates quantifiable outcome measures of writing performance.""
    }
}"
383,The Effects of Chatgpt-generated Feedback on Saudi Efl Learners’ Writing Skills and Perception at the Tertiary Level: a Mixed-methods Study,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Saudi EFL (English as a Foreign Language) university students, i.e., L2 English learners in an EFL context. The focus is on English academic writing skills.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is ChatGPT-generated feedback on students’ writing, compared to teacher-generated feedback, using a pretest–posttest control group design. ChatGPT is a large language model integrated into the writing feedback process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing skills and academic writing, examining the effects of ChatGPT-generated feedback on EFL learners’ writing performance and perceptions. This is a pedagogical writing intervention, not an automated scoring study.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative writing outcomes are reported via pretest and posttest writing scores analyzed with ANCOVA. The abstract notes no statistically significant differences in posttest scores between groups, indicating measurable writing outcome metrics.""
    }
}"
384,"An Ai Chatbot for Efl Writing: Students’ Usage Tendencies, Writing Performance, and Perceptions",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students at a high school in Northern Vietnam, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses an AI chatbot called the Writing Assistant Bot (WAB) to support EFL writing practice. However, the abstract does not specify whether WAB is based on a large language model (e.g., transformer-based generative model like ChatGPT/GPT-4) or a non-LLM AI system. Without this information, it is unclear if it meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The chatbot is explicitly used to support students’ writing practice at home, with analysis of usage at different writing stages (Planning, Translating) and its impact on aspects of writing (content, organization, vocabulary, language use, mechanics). The focus is clearly on writing competence, not on automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports that the chatbot significantly enhanced writing performance across content, organization, vocabulary, language use, and mechanics, implying quantifiable outcome measures (e.g., timed-writing tests and scoring). Thus, it includes experimental measures of writing outcomes.""
    }
}"
385,Assessing the Efficacy of Ai-driven Corrective Feedback Via Whatsapp Application to Improve Esl Learners’ Writing Skills: an Experimental Study,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 112 undergraduate ESL learners in India. The abstract explicitly refers to them as ESL learners and focuses on English writing skills, satisfying the population requirement.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention is described as “AI-driven corrective feedback via WhatsApp application” and outcomes are scored using ChatGPT 4.0. However, it is not clear whether the corrective feedback itself is generated by a large language model (e.g., ChatGPT) integrated into WhatsApp, or by some other non-LLM AI system or human plus AI workflow. The only explicit LLM mentioned (ChatGPT 4.0) is used for scoring, not clearly for the instructional feedback intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on improving ESL learners’ writing skills by reducing grammatical errors in written submissions. It uses AI-driven corrective feedback as a pedagogical intervention and compares it to traditional feedback, aligning with a writing competence context rather than automated essay scoring research alone.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study employs a quasi-experimental pre-test/post-test design with control and experimental groups. Participants’ written submissions are assessed and scored, and RM-ANOVA is used to analyze scores. It reports performance differences in grammatical error correction, providing quantifiable writing outcome metrics.""
    }
}"
386,"Chatgpt Usage Patterns in Essay Writing: a Case Study of Advanced, Intermediate, and Low-proficiency English Learners",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are described as second language learners at different English proficiency levels (advanced, intermediate, low), indicating L2 English learners in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used during argumentative essay writing, the study is framed as a case study of usage patterns and interaction with the tool, not as an experimental or quasi-experimental intervention designed to test an instructional treatment or compare conditions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly writing-focused: students use ChatGPT during argumentative essay writing, and the study explores how they use the AI tool in their writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative analysis of writing processes and interviews, highlighting usage strategies and AI literacy. It does not mention any quantifiable writing outcome metrics (e.g., scores, accuracy measures, complexity indices) to assess effectiveness of the LLM-mediated intervention.""
    }
}"
387,Comparing Native and Non-native English Speakers' Behaviors in Collaborative Writing through Visual Analytics,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract distinguishes between native speakers (NS) and non-native speakers (NNS) of English, but it does not specify that NNS are L2 English learners in ESL/EFL/ELL instructional contexts. The setting appears to be collaborative writing research rather than language learning per se.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Large language models are used within COALA to generate behavior summaries and support visual analytics, not as an instructional or pedagogical intervention in learners’ writing processes. There is no experimental or quasi-experimental design integrating LLMs into writing instruction for learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on analyzing and visualizing collaborative writing behaviors and model interpretability, not on improving writing competence or implementing a writing pedagogy. COALA is an analytics tool for researchers, not a writing intervention for learners.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports user studies on the effectiveness of the visual analytics tool and insights about collaborative processes, but it does not report quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity) resulting from an LLM-mediated writing intervention.""
    }
}"
388,Mind the Gap! Choice Independence in Using Multilingual Llms for Persuasive Co-writing Tasks in Different Languages,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are described as globalized workers and Spanish-speaking female participants, but there is no indication that they are L2 English learners in ESL/EFL/ELL contexts. The focus is multilingual LLM use (Spanish and English), not specifically L2 English learning.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly involves writers engaging with an LLM-based writing assistant for charity advertisement writing tasks in Spanish and English, examining utilization patterns. This is a generative multilingual LLM used in writing tasks.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on behavioral economics concepts (choice independence, beliefs about AI) and donation behavior, not on writing competence or pedagogical writing instruction. The writing task is a vehicle to study decision-making, not an instructional writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported concern persuasiveness of advertisements and donation behavior, and beliefs about AI vs human source. There is no indication of quantifiable L2 English writing development or writing proficiency outcomes as part of an instructional intervention.""
    }
}"
389,Feedback Seeking Abilities of L2 Writers Using Chatgpt: a Mixed Method Multiple Case Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'three EFL learners of distinct language proficiencies,' indicating L2 English learners in an EFL context, with a focus on English writing classrooms.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""ChatGPT, a large language model, is explicitly used as an automated written corrective feedback (AWCF) provider in L2 writing classrooms, satisfying the requirement for an LLM-based intervention in writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is L2 writing classrooms, with ChatGPT used to provide written corrective feedback. The focus is on feedback seeking abilities in L2 writing, which is directly related to writing processes and instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative findings about feedback seeking abilities, perceptions, and a conceptual model. There is no indication of quantifiable writing outcome metrics (e.g., writing scores, accuracy measures, text quality) assessing the effectiveness of the ChatGPT-mediated intervention on writing performance.""
    }
}"
390,Analysis of a Comparative Study between Traditional Online Automatic Writing Evaluation Systems and Large Language Model-assisted Online Revision for Second Language Writing,2025,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “L2 writing” and “learners,” implying second language learners, but it does not explicitly state that the target language is English or that the context is ESL/EFL/ELL. The specific L2 is not identified in the title or abstract.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study compares a traditional online automatic writing evaluation system (Pigaiwang) with “Large Language Models (LLMs)” for online revision of L2 writing. It is described as using experimental data and LLM-assisted online writing correction and feedback, which indicates an experimental or quasi-experimental design integrating LLMs into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on “two online revision modes of L2 writing” and how they assist learners’ writing levels and enthusiasm for writing revision. This aligns with a primary focus on writing competence and writing-related variables in a pedagogical context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract notes that “through experimental data” significant differences were found between the two modes in assisting learners’ writing levels, and that LLM-assisted correction can improve learners’ writing levels. This implies quantifiable outcome measures of writing performance were collected and analyzed.""
    }
}"
391,Assessing the Impact of Chatgpt on Efl Students’ Writing Productivity and Proficiency,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 52 Saudi female university students in an English as a Foreign Language (EFL) course, clearly indicating L2 English learners in an EFL context with focus on English writing skills.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study investigates incorporating ChatGPT, explicitly identified as an AI-based tool, into an EFL course. It uses a pretest–posttest design to examine its effects, indicating an experimental/quasi-experimental LLM-mediated intervention in writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence: writing productivity and proficiency, including topic sentence formation, organization, supporting details, mechanics, and word count. ChatGPT is used pedagogically to assist with idea generation, reducing redundancy, and fostering writing clarity, not merely as an automated scoring tool.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study employs a pretest–posttest design and reports measurable changes in writing skills (e.g., topic sentence formation, supporting details, mechanics, organization, word count), providing quantifiable writing outcome metrics to assess the effectiveness of the ChatGPT-mediated intervention.""
    }
}"
392,Students’ Perceptions of Generative Artificial Intelligence (genai) Use in Academic Writing in English as a Foreign Language †,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 56 undergraduate university students in Ecuador studying English as a foreign language (EFL), clearly an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a perception survey about GenAI/ChatGPT use and academic integrity. There is no indication of an experimental or quasi-experimental design integrating an LLM into writing instruction or writing processes as an intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is academic writing in EFL, the focus is on perceptions of academic integrity, cheating, and AI-giarism, not on a pedagogical writing intervention or instructional use of LLMs to develop writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports students’ perceptions and worries, not quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity) resulting from an LLM-mediated writing intervention.""
    }
}"
393,Use of Ai Tools in Efl Writing Instruction: a Case Study of Chinese Vocational College Instructors,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is English as a foreign language (EFL) at Chinese vocational and technical colleges, so the implied learners are L2 English users in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “AI writing tools” but does not specify whether these are LLM-based tools (e.g., ChatGPT) or other forms of AI (e.g., automated feedback systems not using transformer-based generative models). However, the study is about instructors’ experiences and perceptions, not an experimental or quasi-experimental intervention testing an LLM in instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on teachers’ use, experiences, and perceptions of AI tools in EFL writing instruction, using a qualitative case study with interviews. There is no structured pedagogical intervention being experimentally evaluated for its impact on writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is qualitative and interview-based, reporting perceptions and experiences. It does not report quantifiable writing outcome metrics or experimental measures of writing performance related to AI/LLM-mediated interventions.""
    }
}"
394,Navigating the Digital Writing Landscape: Efl Students’ Perspectives on Chatgpt Utilization,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are English as a foreign language (EFL) students at an Indonesian university, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines students’ perceptions of various AI tools (grammar checkers, text-to-speech, language learning apps, and ChatGPT) via survey and interviews. There is no indication of an experimental or quasi-experimental design integrating an LLM into writing instruction or processes; it is a perception/acceptance study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on general AI use for language skills development, usefulness, ease of use, and social influence, not specifically on writing competence or writing-related variables as the primary outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study relies on self-reported perceptions and experiences, with no reported quantitative writing outcome measures or structured LLM-mediated writing intervention outcomes.""
    }
}"
395,Integrating Generative Ai into Digital Multimodal Composition: a Study of Multicultural Second-language Classrooms,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are “eleven culturally diverse students from two high schools in Hong Kong,” which implies L2 English learners in an EFL/ESL context, and the abstract discusses vocabulary, grammar, and structure, consistent with English L2 writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses “generative AI tools” but does not specify whether these are LLM-based tools such as ChatGPT/GPT-4 or other generative systems (e.g., image generators). However, references to content generation, feedback, revision, and multilingual support suggest text-based generative AI, likely LLMs, but this is not explicit in the abstract.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on “digital multimodal composition (DMC)” and multimodal literacy, including visual representation and DMC skills. While vocabulary, grammar, and structure are mentioned, the central outcome domain is broader multimodal composition rather than writing competence or writing-related variables as the main focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports that AI integration resulted in “enhancements to the vocabulary, grammar, and structural elements of students’ work,” but there is no indication of experimental or quasi-experimental design with quantifiable writing outcome metrics (e.g., pre/post tests, rubric scores, statistical comparisons). Data sources are usage logs, observations, surveys, and interviews, suggesting primarily qualitative analysis.""
    }
}"
396,Artificial Intelligence as a Provider of Feedback on Efl Student Compositions,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 29 English major students at a Saudi university, described as foreign language writers (EFL context), so they are L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT is used to provide feedback on student essays, the study is not described as experimental or quasi-experimental. It qualitatively analyzes ChatGPT’s feedback characteristics (consistency, credibility, feedback types) rather than implementing and testing a structured LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on analyzing the nature and quality of AI feedback (types, consistency, credibility), not on systematically improving or measuring students’ writing competence through an intervention. It is essentially an evaluation of ChatGPT as a feedback provider, not a pedagogical writing intervention with outcome assessment.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports only qualitative analysis of feedback and does not mention any quantifiable writing outcome metrics (e.g., pre/post writing scores, rubric-based gains). No experimental measures of changes in learners’ writing performance are reported.""
    }
}"
397,Translanguaging with Generative Ai in Efl Writing: Students’ Practices and Perceptions,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students in China (six college students with lower to intermediate proficiency), clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study involves generative AI (ERNIE Bot), it is a qualitative exploration of how students utilize the tool, not an experimental or quasi-experimental intervention design integrating LLMs into instruction. There is no structured pedagogical treatment being tested.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL writing processes and how generative AI is used in writing, framed through translanguaging practices, which aligns with writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly qualitative, using semi-structured interviews and artefacts. It examines practices and perceptions, with no mention of quantifiable writing outcome metrics or measured effectiveness of the AI-mediated intervention.""
    }
}"
398,Secondary School English Teachers’ Application of Artificial Intelligence-guided Chatbot in the Provision of Feedback on Student Writing: an Activity Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 13 secondary school English teachers in China providing feedback on student L2 English writing. The context is clearly L2 English writing instruction in an EFL setting, so the population focus aligns with L2 English learners, even though learners themselves are not the direct participants.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses Kimi, described as an AI-guided chatbot, to support teacher feedback. However, the abstract does not specify that Kimi is a large language model (e.g., transformer-based generative model like ChatGPT/GPT-4). Without explicit indication that Kimi is an LLM, it is unclear whether the intervention meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on how teachers incorporate an AI-guided chatbot into their feedback practices, analyzed via Activity Theory. Outcomes reported concern characteristics of Kimi vs. teacher feedback and components of the activity system, not on changes in learners’ writing competence or writing-related performance. Thus, the main focus is not on writing competence outcomes but on feedback practices and system components.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports differences in feedback features (amount, length, foci, types) and describes complementary patterns between Kimi and teacher feedback. It does not mention any quantitative measures of student writing outcomes or experimental evaluation of the intervention’s effect on writing performance. Therefore, no quantifiable writing outcome metrics are reported.""
    }
}"
399,Using Ai-text Generated Mentor Texts for Genre-based Pedagogy in Second Language Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers generally to “second language (L2) writing instruction” and “L2 writing classrooms” but does not specify that participants are L2 English learners or that the target language is English. No concrete participant group is described.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study discusses using “GenAI tools” and “AI text generators” to create mentor texts for genre-based pedagogy, but it is presented as a conceptual or illustrative exploration rather than an experimental or quasi-experimental intervention study. No specific LLM (e.g., ChatGPT, GPT-4) is identified, and no intervention design is described.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""While the context is L2 writing and genre pedagogy, the article focuses on demonstrating how AI-generated mentor texts can illustrate genre stages and language features within the Teaching and Learning Cycle. It does not describe an implemented pedagogical intervention with measured effects; rather, it is a descriptive/theoretical piece.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantitative writing outcome metrics or experimental results. It highlights potential uses of AI-generated mentor texts and identifies language features, but there is no mention of measured changes in learners’ writing performance or related variables.""
    }
}"
400,Unlocking Efl Learners’ Insights into Chatgpt Use for L2 Writing: the Impacts of Usage Frequency and Gender Variations,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 874 Turkish undergraduate English majors at a state university in Türkiye, i.e., EFL learners using English as an L2.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates learners’ perceptions of ChatGPT use and how gender and usage frequency affect these perceptions. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating ChatGPT into writing instruction; ChatGPT use is self-initiated ‘beyond the classroom’ and only surveyed, not manipulated as an intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is L2 writing, the primary focus is on perceptions of ChatGPT use (Technology Acceptance Model) and gender/usage frequency differences, not on writing competence or writing-related performance variables within an instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports quantitative data on perceptions (via the ChatGPT Perception Scale) and usage frequency, but does not report any quantifiable writing outcome metrics (e.g., writing scores, quality measures, accuracy, complexity) to assess the effectiveness of ChatGPT-mediated writing intervention.""
    }
}"
401,An Exploratory Research on Effects of Ai Chabots on Syntactic Complexity of L2 Writing,2025,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “second language learners” and “English writing,” indicating L2 English writers, but it does not explicitly specify ESL/EFL/ELL contexts or learner profiles. Population appears likely to fit, but context is not fully detailed.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention is an “AI-powered chatbot” used as an “AI Writing Assistant.” However, the specific technology (e.g., ChatGPT, GPT-4, other LLM-based system vs. rule-based/chatbot without LLMs) is not identified. It is impossible to confirm from the abstract alone that the chatbot is an LLM-based tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on “second language writing instruction,” “English writing,” and the impact of the chatbot on “syntactic complexity” and “writing proficiency.” This aligns with writing competence as the primary outcome, not automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a control and experimental group, collects English compositions, analyzes them with the Web-based L2 Syntactic Complexity Analyzer, and conducts statistical analysis with SPSS. It reports superior writing proficiency and a positive correlation between syntactic complexity and writing quality, indicating quantifiable writing outcome metrics.""
    }
}"
402,An Empirical Research on Ai Chatbot-assisted Continuation Writing Task,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are L2 learners in China working on an English continuation writing task in a foreign language teaching context, indicating EFL learners focused on English writing proficiency.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses an “AI chatbot” to provide feedback on writing. However, the abstract does not specify whether this chatbot is a large language model (e.g., ChatGPT/GPT-based) or another type of AI system. Without this detail, it is unclear if the tool is LLM-based.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly investigates the effects of AI chatbot feedback on L2 learners’ English continuation writing, focusing on writing proficiency, overall quality, syntactic development, and the writing process, which aligns with writing competence as the primary focus.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study “employs quantitative research methods” and reports that AI chatbot integration improves “overall quality and syntactic development” of writing, implying quantifiable writing outcome metrics are used to assess the intervention’s effectiveness.""
    }
}"
403,Impact of Gpt on the Academic Ecosystem,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract discusses GPT’s impact on the academic ecosystem in general and mentions non-native English speakers only as potential users of GPT for academic writing. It does not specify a population of L2 English learners in ESL/EFL/ELL instructional contexts, nor does it report empirical data on such learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a summary and discussion of potential impacts of GPT-like technologies. It does not describe an experimental or quasi-experimental intervention integrating LLMs into writing instruction or writing processes; it is conceptual/review in nature.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""While academic writing is mentioned, the focus is broad (academic ecosystem, publishing, services, integrity) rather than a pedagogical context targeting writing competence. There is no specific instructional or classroom writing intervention being evaluated.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study does not report any quantitative writing outcome measures. It is a narrative discussion of potential uses and impacts, without experimental measures or structured intervention outcomes related to writing.""
    }
}"
404,Finding Your Voice: Using Generative Ai to Help International Students Improve Their Writing,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract focuses on “international students” and “non-native English speakers” writing in academia, indicating L2 English learners in an EAP/ESL-type context, though the exact program label (ESL/EFL/ELL) is not specified.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses “Gen-AI tools built on large language models (LLMs) such as ChatGPT and Claude” in “a series of structured exercises” to improve student writing, implying an LLM-based instructional intervention rather than mere tool evaluation.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly writing-focused: improving the “quality and efficiency of writing,” addressing literature reviews, summaries, and reflective reports, and helping students “develop their own distinct voice.” This aligns with writing competence as the primary focus.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions structured exercises and that some were repeated with another group, but it does not state whether any quantifiable writing outcome metrics (e.g., scores, rubric ratings, error counts) were collected. It may be descriptive or conceptual rather than reporting experimental outcome data.""
    }
}"
405,Complementing but Not Replacing: Comparing the Impacts of Gpt-4 and Native-speaker Interaction on Chinese L2 Writing Outcomes,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as '23 Chinese L2 learners' engaged in 'L2 writing'. The abstract focuses on second language writing outcomes, and the comparison with a native-speaker partner implies English as the target language in an L2 context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses GPT-4, a large language model, as an interactive support tool in the pre-writing phase. A within-subject behavioral experiment compares three conditions: without interaction, interaction with GPT-4, and interaction with a human language partner, satisfying the requirement for an experimental LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 writing competence: the study examines how GPT-4 and native-speaker interaction in the pre-writing phase affect 'L2 writing outcomes' including overall writing scores, organization, language, and content. This is a pedagogical intervention, not an automated scoring or purely functional evaluation of the LLM.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: 'overall writing scores, organization, and language' and 'content scores' are compared across conditions. Additional quantitative measures include topic familiarity, writing confidence, and perceived difficulty, with reported correlations to writing outcomes.""
    }
}"
406,The Impact of Digital Storytelling on Efl Learners' Speaking and Writing Skills,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a Foreign Language (EFL) learners, which fits the target population of L2 English learners in EFL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is digital storytelling in general. Although the abstract notes that educators have ‘increasingly integrated digital storytelling with Artificial Intelligence (AI) technologies,’ it does not specify the use of large language models (e.g., ChatGPT, GPT-4) nor indicate that the study’s own intervention used an LLM-based tool. Thus, it does not meet the requirement for an LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on speaking and writing skills, with explicit mention of improvements in grammatical accuracy and creativity in writing, indicating a primary focus on language production skills including writing.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports ‘significant improvement’ in oral fluency, accuracy, and writing-related aspects, but does not specify concrete, quantifiable writing outcome measures (e.g., scores, rubrics, pre/post tests). It is unclear whether structured quantitative writing metrics were used.""
    }
}"
407,Envisioning the Future of Ai-assisted Efl Teaching and Learning: Conceptual Representations of Prospective Teachers,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are 67 prospective EFL teachers, not L2 English learners in ESL/EFL/ELL contexts. The focus is on teachers’ conceptualizations of AI, not on learner data or learner writing performance.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a descriptive qualitative exploration of how teachers envision AI’s future role. There is no experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing assistants are mentioned among AI tools, the study’s primary focus is on general AI in EFL teaching and learning, teacher perceptions, and future roles, not on writing competence or writing-related instructional interventions.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a descriptive qualitative approach and reflexive thematic analysis, reporting themes and nodes. It does not report quantifiable writing outcome metrics or evaluate the effectiveness of an LLM-mediated writing intervention.""
    }
}"
408,Ai and Discourse Analysis: Implications for Esp Genre Pedagogy in Efl Settings,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The title and abstract explicitly reference ESP genre pedagogy in EFL settings and ‘speakers of English as a second language,’ indicating an L2 English learner population in EFL/ESL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the article discusses ‘generative AI tools’ conceptually, there is no indication of an experimental or quasi-experimental design, nor a specific implemented LLM-based intervention. It appears to be a conceptual/pedagogical discussion rather than an empirical study integrating LLMs into instruction.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on implications for ESP genre pedagogy and discourse analytical skills in professional/ESP writing, which is writing-related. However, the abstract does not clearly describe a concrete instructional context or implemented intervention, only theoretical implications.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental results are mentioned. The article argues for opportunities and implications but does not report measured effects of an LLM-mediated writing intervention.""
    }
}"
409,Applying Neural Machine Translation and Chatgpt in the Teaching of Business English Writing,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as students in EFL (English as a foreign language) business English writing classes across three majors (finance, economics, business administration). The focus is on English writing, satisfying the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study evaluates the application of NMT and ChatGPT in teaching EFL writing. ChatGPT is a large language model, and it is used to complement NMT by making improvements and providing feedback to students. The design involves building comparable corpora of direct-writing vs. post-edited machine-translated texts and using ChatGPT as part of the instructional intervention, indicating an experimental/quasi-experimental integration of an LLM into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on business English writing competence, examining how NMT and ChatGPT affect students’ academic/business English writing in multiple dimensions (word, syntax, cohesion, content, organization, mechanics). ChatGPT is used pedagogically to improve and provide feedback on students’ essays, not merely for automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports statistical analyses of students’ writing performance across multiple quantified dimensions (word level, syntax, cohesion, content, organization, mechanics) comparing direct-writing and post-edited writing based on NMT, and examines how ChatGPT complements NMT. These constitute quantifiable writing outcome metrics assessing the effectiveness of the intervention.""
    }
}"
410,Evaluating Chatgpt's Reliability in Second Language Acquisition (sla): Insights on Language Skills and Technology's Role,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any participants or learners. The study evaluates ChatGPT-4.0’s responses to 48 SLA-related questions rated by expert linguists, not by L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT-4.0 is an LLM, it is not integrated into an instructional intervention or experimental/quasi-experimental design for writing instruction. The study only evaluates the reliability and quality of ChatGPT’s responses to SLA questions.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on ChatGPT’s responses about SLA topics broadly (technology’s role and language skills) rather than on an intervention targeting writing competence or writing-related variables in learners.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes are reported. The only quantitative measures concern expert ratings of ChatGPT’s answers, not changes in L2 writing performance following an LLM-mediated intervention.""
    }
}"
411,Assessing Human Evaluations of Cover Letters Written or Edited by Ai and Non-native English Speakers,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly focuses on non-native English speakers (NNES) and their formal writing (cover letters), which aligns with L2 English learner populations.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although AI is involved in producing and editing cover letters (AI-written, AI-edited), the design is a survey-embedded experiment where native English speakers evaluate texts. There is no instructional or pedagogical intervention integrating an LLM into NNES writing instruction or process; rather, it is a perception/evaluation study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on human evaluations of hireability and writing quality of different types of cover letters, not on developing or testing a writing competence intervention. It examines how AI impacts perceptions of NNES writing, not a teaching/learning context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports ratings of hireability and writing quality given by native speakers, but there is no structured LLM-mediated writing intervention with pre/post or comparative learning outcomes for NNES writers. Thus, it does not provide quantifiable writing outcome metrics for an LLM-based pedagogical intervention.""
    }
}"
412,Chatgpt-supported Collaborative Argumentation: Integrating Collaboration Script and Argument Mapping to Enhance Efl Students’ Argumentation Skills,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students: “Argumentation is a complex skill essential for English as a Foreign Language (EFL) students… A total of 67 freshmen university students participated…”. The focus is clearly on English as the target language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT, explicitly described as “a large language model,” in a quasi-experimental design: “we proposed using ChatGPT… to guide students through three stages of collaboration script… 34 of them using ChatGPT-supported collaborative argumentation… and 33 using conventional-based collaborative argumentation.” This is an LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on argumentation and speaking: “enhanced EFL students’ argumentative speaking performance, critical thinking awareness, and collaboration tendency.” Writing is mentioned only generally (“in writing and speaking”) without indication that writing competence or writing-related variables were measured as outcomes. The reported outcomes are speaking, critical thinking, and collaboration, not writing.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study reports quantitative outcomes (e.g., η2 values) for argumentative speaking performance, critical thinking awareness, and collaboration tendency, and notes that “using ChatGPT to learn argumentation improved the quality of arguments.” However, it is not specified that any of these are writing outcome metrics; they appear to be speaking and general argument quality measures. Since C3 already fails, the precise status of writing outcomes is secondary.""
    }
}"
413,Artificial Intelligence Integration in Acquisition of English Academic Writing: a Comparative Analysis of Student Perspectives in School and University Settings,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are upper-secondary school and university students from Latvia using AI when acquiring academic writing skills in English, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a questionnaire survey about student experiences and types of AI tools used. There is no experimental or quasi-experimental design integrating LLMs into instruction; it only surveys existing usage and perceptions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on the acquisition of English academic writing skills and how students apply AI in academic writing, which aligns with writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports perceptions and usage patterns via questionnaire; it does not report quantifiable writing outcome metrics or measure the effectiveness of an LLM-mediated intervention on writing performance.""
    }
}"
414,Ai and Uncertain Motivation: Hidden Allies That Impact Efl Argumentative Essays Using the Toulmin Model,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Saudi EFL learners, i.e., learners of English as a foreign language. The focus is on their argumentative writing in English, satisfying the population criterion.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that the study uses “artificial intelligence (AI) tools” that provide real-time feedback, but it does not specify whether these are large language model–based tools (e.g., ChatGPT, GPT-4) or other AI systems (e.g., grammar checkers, rule-based tools). Without explicit mention of LLMs or transformer-based generative models, it is unclear if C2 is met.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on argumentative writing performance using the Toulmin Model. AI tools are integrated into the writing process to provide feedback on claims, data, backing, and counterarguments, clearly situating the study in writing instruction rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports “significant improvements in essay quality, particularly in clarity, structure, and depth” across four writing tasks, indicating quantifiable writing outcome metrics were used to assess the intervention’s effectiveness, even though specific measures are not detailed.""
    }
}"
415,The Role of Ai-assisted Learning in Academic Writing: a Mixed-methods Study on Chinese as a Second Language Students,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are described as 'Chinese as a Second Language (CSL) students' in a Chinese university context. The focus is on learning Chinese academic writing, not English as an L2 (ESL/EFL/ELL). Therefore, the population and target language do not match the review’s focus on L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The experimental group used 'AI-assisted learning using ChatGPT' compared with a traditional learning control group, indicating an experimental design integrating an LLM (ChatGPT) into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly focuses on 'academic writing' and evaluates 'Chinese academic writing' performance, with AI used to support writing-related learning processes. Thus, the primary focus is on writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses 'pre- and post-test quantitative data' and 'writing samples ... evaluated using established scoring rubrics for Chinese academic writing,' providing quantifiable writing outcome metrics.""
    }
}"
416,Enhancing Efl Writing Revision Practices: the Impact of Ai- and Teacher-generated Feedback and Their Sequences,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students: fourteen Vietnamese undergraduates in an EFL academic writing course. The focus is clearly on English as a foreign language writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses Gemini (a generative AI LLM) to provide AI-generated feedback on student writing, comparing it with teacher-generated feedback and different sequencing. This is an instructional intervention integrating an LLM into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL academic writing and revision practices. The intervention targets writing revisions (local grammar/vocabulary and global content/organization), which are core writing-related variables, not automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are revision frequencies (quantity of revisions) in response to different feedback conditions and sequences. The abstract does not indicate any quantifiable measures of writing quality, proficiency, or competence; it focuses on how often students revise, not on whether their writing improves. Thus, it does not meet the requirement for quantifiable writing outcome metrics assessing effectiveness of the LLM-mediated intervention on writing quality.""
    }
}"
417,Bothorship: Ai Chatbot Authorship after Two Years,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract discusses non-native English speakers in scholarly publishing in general terms but does not specify a defined participant group of L2 English learners in ESL/EFL/ELL instructional contexts. It is a perspective/review piece, not an empirical study with a learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper is described as exploring recent publications and discourse and presenting a perspective on AI contributions to scholarly publications. There is no indication of an experimental or quasi-experimental design integrating LLMs into writing instruction or processes for learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on scholarly publishing practices, AI authorship, and copyediting, not on pedagogical writing interventions or writing competence development in an L2 learning context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental measures are reported. The article is a review/perspective on issues and future directions, not an intervention study with measured writing outcomes.""
    }
}"
418,Using Ai Large Language Model (llm-chatgpt) to Mitigate Spelling Errors of Efl Learners,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 60 EFL students (English as a Foreign Language learners), indicating L2 English learners in an EFL context, with focus on English spelling and writing proficiency.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an AI Large Language Model (LLM-GPT/ChatGPT) as an application to provide automated feedback, spelling assistance, and practice. A between-subjects design with control and experimental groups is described, indicating an experimental LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is writing skills, specifically mitigating spelling errors and improving writing proficiency. LLM-GPT is integrated into writing instruction (spelling within writing), not just for assessment or grading.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports that learners taught using the LLM_GPT application outscored the control group and better remembered spelling in the post-test, indicating quantifiable writing-related outcome measures (spelling performance).""
    }
}"
419,Decoding Efl Learners’ Intention to Use Chatgpt for Academic Writing: Cognitive and Emotional Drivers,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Bangladeshi English as a Foreign Language (EFL) learners in public and private universities, clearly fitting an EFL/ESL/ELL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is the focal technology, the study is not an experimental or quasi-experimental intervention integrating ChatGPT into writing instruction or processes. It is a survey study using a Likert-scale questionnaire to measure attitudes and behavioral intentions, without implementing or testing an instructional use of ChatGPT.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on cognitive and affective attitudes and behavioral intention to use ChatGPT for academic writing, not on an implemented writing intervention or measured changes in writing competence. There is no pedagogical writing intervention being evaluated.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports only attitudinal and intention measures (cognitive and affective attitudes, behavioral intention). It does not report any quantifiable writing outcome metrics (e.g., writing quality scores, accuracy, complexity) resulting from LLM-mediated writing intervention.""
    }
}"
420,The Role of Generative Ai in Mediating L2mss and Engagement with Written Feedback in Efl Learning: a Structural Equation Modeling Approach,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 174 students in an English as a Foreign Language (EFL) context in Japan, clearly indicating L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""Students were required to use Generative AI (GenAI) to receive feedback on their writing and to collaboratively construct essays, indicating an LLM-based writing intervention integrated into instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing classes where students use GenAI for feedback and essay construction; the focus is on writing and its pedagogy, not on automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are motivation, AI usage, and three aspects of engagement (affective, behavioral, cognitive) measured via survey and analyzed with structural equation modeling. The abstract does not indicate any quantifiable writing performance or writing quality metrics; the focus is on engagement, not writing outcomes.""
    }
}"
421,Integrating Automated Writing Evaluation into Saudi Efl Students’ Writing Practice,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 154 Arabic-speaking undergraduate EFL students at a Saudi university, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses generic 'AWE systems' (Automated Writing Evaluation). The abstract does not indicate that these are LLM-based tools (e.g., ChatGPT, GPT-4) or transformer-based generative models; AWE is typically scoring/feedback software, not an LLM writing assistant.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on integrating AWE into EFL writing practice and its impact on writing skills, autonomy, and motivation, which are writing-related variables in a pedagogical context.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study mentions collecting 'samples of EFL writing assignments before and after utilising the AWE system,' but the abstract does not clearly state that quantifiable writing outcome metrics were analyzed; emphasis is on experiences, evaluations, challenges, satisfaction, and perceived effectiveness.""
    }
}"
422,The Impact of Ai-generated Feedback Explicitness (generic Vs. Specific) on Efl Students' Use of Automated Written Corrective Feedback,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL university students in Saudi Arabia (Arab schools and universities), clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is described as AI-driven Automated Written Corrective Feedback and Automated Essay Scoring systems/AWE systems, but there is no indication these are large language model (LLM)-based tools (e.g., ChatGPT, GPT-4). They are generic AWCF/AWE systems, which are often non-LLM. The abstract does not specify transformer-based generative models.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL writing, corrective feedback, and writing proficiency, clearly within writing competence and writing-related variables in a pedagogical context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the main research question mentions writing proficiency, the reported methods and results focus on perceptions (questionnaires, interviews, exploratory factor analysis of ease of use, clarity, usefulness, perceptions, feedback explicitness). No concrete quantitative writing outcome measures (e.g., scores, accuracy gains) are reported in the abstract.""
    }
}"
423,Saudi Efl Learners’ Perceptions of Using Artificial Intelligence and Its Impact on Their Writing Skills,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are female Saudi learners of English as a Foreign Language at the University of Jeddah, clearly an EFL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT and other AI tools are mentioned, the abstract frames the study as examining learners’ perceptions and experiences, not as an experimental or quasi-experimental intervention integrating LLMs into instruction. No controlled or structured LLM-based instructional treatment is described.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is broadly on writing skills and writing development, but the study appears to center on perceptions and experiences rather than a defined pedagogical writing intervention. It is not explicit that there is a structured writing-instruction context being experimentally manipulated.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses questionnaires and semi-structured interviews to explore attitudes, perceived benefits, and drawbacks. There is no indication of quantifiable writing outcome measures (e.g., pre/post writing scores, rubric-based writing performance) to assess effectiveness of LLM-mediated writing intervention.""
    }
}"
424,Evaluating the Quality of Ai Feedback: a Comparative Study of Ai and Human Essay Grading,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract specifies that the essays were written by English as a foreign language (EFL) students, which fits the target population of L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""AI tools are used only as evaluators of essays and their feedback quality is compared with human grading. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the quality and scoring behavior of AI essay grading/feedback compared to human raters, not on improving learners’ writing competence through an instructional intervention. This aligns with automated essay scoring evaluation rather than a writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports on AI vs. human scoring and feedback characteristics, but does not report quantifiable changes in students’ writing outcomes resulting from an LLM-mediated intervention. No pre/post or comparative writing performance measures are described.""
    }
}"
425,The Integration of Chatgpt in English for Foreign Language Course: Elevating Ai Writing Assistant Acceptance,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 95 English as a Foreign Language (EFL) students in Indonesia, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study integrates ChatGPT, an LLM, into students’ writing process over a four-week assignment, examining its use as a writing aid in an English language learning course.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is writing-related: students used ChatGPT during the writing process as a writing aid in an ICT for ELT course, and the discussion focuses on academic writing and use of ChatGPT in writing tasks.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study applies the Technology Acceptance Model and reports outcomes such as perceived ease of use, perceived usefulness, attitude toward change, and behavioral intentions. There is no mention of quantifiable writing performance or writing quality outcomes; the focus is on acceptance and attitudes, not writing competence.""
    }
}"
426,Investigating Students’ Uptake of Teacher- and Chatgpt-generated Feedback in Efl Writing: a Comparison Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL students: twenty Chinese undergraduate students writing argumentative essays in English. This fits L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used to generate feedback on students’ writing, but the design is a comparison of teacher- vs ChatGPT-generated feedback uptake and perceptions. There is no indication of an experimental or quasi-experimental LLM-based instructional intervention aimed at improving writing performance (e.g., no pre/post or controlled treatment condition using ChatGPT as a pedagogical tool).""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly EFL writing: students compose argumentative essays, receive feedback, and revise. The focus is on writing quality and feedback use, not on automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported concern engagement with feedback, appropriateness of revisions, and questionnaire-based perceptions and preferences. The abstract does not report quantifiable writing outcome metrics (e.g., holistic/analytic writing scores, measurable gains in writing competence) to assess the effectiveness of the LLM-mediated intervention.""
    }
}"
427,"Beyond Policing: Ai Writing Detection Tools, Trust, Academic Integrity, and Their Implications for College Writing",2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions bias against non-native English speakers and focuses on college writing, but it does not specify that the participants are L2 English learners in ESL/EFL/ELL contexts, nor that data are specifically about L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article discusses AI writing detection tools, trust, and academic integrity, and argues for collaborative AI integration in writing. However, it does not describe an experimental or quasi-experimental study using a specific LLM (e.g., ChatGPT, GPT-4) as an instructional intervention; it appears to be conceptual/perspective-based.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""While the context is college writing and AI, the focus is on detection tools, institutional guidelines, and trust-based frameworks rather than a concrete pedagogical intervention targeting writing competence or writing-related variables using LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantitative writing outcome measures or experimental results. It discusses implications and proposed shifts in approach but no measured effects on writing performance.""
    }
}"
428,Unpacking the Rejection of L2 Students Toward Chatgpt-generated Feedback: an Explanatory Research,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are L2 learners: 45 university students in a Computer Science program producing an argumentative writing report, described as L2 learners dealing with corrective feedback in an AI-assisted environment.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""ChatGPT, a generative AI LLM, is used to provide corrective feedback on students’ argumentative writing. Students were encouraged to seek corrective feedback from ChatGPT, indicating an LLM-based writing-related intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on learners’ challenges and rejection of ChatGPT-generated feedback, framed through UTAUT (technology acceptance). The abstract does not indicate that the study’s main aim is to improve or measure writing competence; rather, it examines acceptance and reasons for rejecting feedback.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports proportions of accepted vs. rejected AI feedback and qualitative reasons for rejection. It does not report quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity) to assess the effectiveness of the LLM-mediated intervention.""
    }
}"
429,Collaborative Writing Based on Generative Ai Models: Revision and Deliberation Processes in German as a Foreign Language,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are learners of German as a foreign language, not L2 English learners. The title and abstract explicitly state the context is German as a Foreign Language, so the target language is not English.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study integrates generative AI models (e.g., ChatGPT) into a classroom-based collaborative writing intervention, where students compare their own writing with GenAI models. This reflects an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on L2 writing and revision processes in collaborative writing, including how GenAI influences revision and deliberation, clearly centering on writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports changes in text quality and evaluates texts for functional adequacy, indicating quantifiable writing outcome metrics linked to the GenAI-mediated intervention.""
    }
}"
430,Exploring Chatgpt as a Tool for Thesis Writing: Perspectives of Efl Supervisors in Jordanian Universities,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The population of interest is clearly in an EFL context: the study focuses on Jordanian EFL supervisors and their views on students’ thesis writing in English. Thus, the context involves L2 English learners in an EFL setting, even though the direct participants are supervisors.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the study is not an experimental or quasi-experimental intervention integrating ChatGPT into writing instruction. It is a perception study using a questionnaire to gather supervisors’ views; no structured LLM-mediated instructional treatment is implemented or tested.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on supervisors’ perspectives about ChatGPT’s usefulness and effects on thesis writing, not on an implemented pedagogical intervention or measured changes in writing competence. It is attitudinal rather than an intervention study targeting writing outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports Likert-scale ratings of supervisors’ opinions (e.g., on usefulness, correctness, dependability) but does not report any quantifiable writing performance outcomes for students. There are no experimental measures of changes in writing quality or related variables following LLM use.""
    }
}"
431,More Human Than Human? Differences in Lexis and Collocation within Academic Essays Produced by Chatgpt-3.5 and Human L2 Writers,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly involves human L2 writers producing academic essays, indicating a population of second language learners writing in English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT-3.5 is used to generate essays, there is no experimental or quasi-experimental pedagogical intervention integrating the LLM into L2 writing instruction or learners’ writing processes. The design is a comparative corpus analysis of AI vs. human texts, not an instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on linguistic differences (lexis and collocation) between AI-generated and human L2 essays and implications for academic integrity and AI detection, not on improving writing competence through an instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study does not report quantifiable writing outcome measures for an LLM-mediated intervention. It analyzes textual features but does not assess changes in learners’ writing performance resulting from using an LLM in instruction.""
    }
}"
432,Chatgpt and L2 Chinese Writing: Evaluating the Impact of Model Version and Prompt Language on Automated Corrective Feedback,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on L2 Chinese writing and the need for Chinese grammar checking. Although prompt language includes English, the target language being learned and corrected is Chinese, not English, so it does not match the review’s requirement for L2 English learners and English writing outcomes.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study evaluates ChatGPT-3.5 and 4.0 (LLMs) as automated corrective feedback tools for L2 Chinese writing, comparing model versions and prompt languages in an experimental setup using erroneous sentences.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is writing-focused: the study examines automated corrective feedback on L2 Chinese written sentences, with teacher ratings of grammaticality, fluency, and related writing-focused dimensions.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative evaluations are reported: teacher ratings of corrections and feedback on dimensions such as grammaticality, fluency, minimal alterations, over-correction, correctness, understandability, and detail, providing measurable outcome metrics.""
    }
}"
433,Using an Ai-powered Chatbot for Improving L2 Korean Grammar: a Comparison between Proficiency Levels and Task Types,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are L2 Korean learners, not L2 English learners. The abstract explicitly states the study is about incorporating an AI chatbot (Iruda) in L2 Korean teaching to improve Korean lexico-grammar, and it is framed as research on a less commonly taught language (LCTL), not English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The tool is described as an AI-powered chatbot (Iruda), but the abstract does not specify whether it is based on a large language model or transformer-based generative architecture. It could be rule-based or another non-LLM system; this cannot be determined from the abstract alone.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on improving Korean lexico-grammar and assessing grammar performance via selected-response and constructed-response tasks. The study is about grammar instruction and grammatical accuracy, not writing competence in English or writing-related variables in an L2 English context.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study reports quantifiable outcomes (item means, t-tests, ANOVAs) on grammar tasks, including constructed-response sentence completion and composition. However, these outcomes pertain to Korean grammar, not L2 English writing, and it is unclear whether the constructed responses are treated as broader writing outcomes or narrowly as grammar test items.""
    }
}"
434,Interacting with Chatgpt in Essay Writing: a Study of L2 Learners’ Task Motivation,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are L2 learners writing English argumentative essays at a public university in a non-English-speaking country, which fits ESL/EFL/ELL contexts with English as the target language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT 4.0 (an LLM) as a writing support tool and tutor within an experimental, mixed-methods design to inform AI-enhanced interventions for L2 essay writing.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on learners’ task motivation when interacting with ChatGPT in English essay writing, not on writing competence or writing-related performance variables. Writing skill is mentioned only as a perceived improvement, not as a measured outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports quantitative outcomes on motivation, not on writing performance. There is no indication of quantifiable writing outcome metrics (e.g., scores, quality ratings, accuracy) used to assess the effectiveness of the LLM-mediated intervention on writing.""
    }
}"
435,Empowering Dialogic Feedback in Flw with Llm,2025,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to foreign/second language (L2) writing and L2 learners but does not specify that the target language is English or that participants are ESL/EFL/ELL learners. The specific language context cannot be confirmed from the abstract alone.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly proposes leveraging large-language models (LLMs) to create an AI-writing tool and to facilitate dialogic feedback in L2 writing. It mentions testing the tool’s effectiveness through experimental sessions, indicating an experimental or quasi-experimental LLM-based intervention in writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on L2 writing instruction, dialogic feedback, and iterative editing/rewriting to enhance linguistic and cognitive development. The context is clearly writing competence and feedback practices, not automated essay scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that the study will test the effectiveness of the AI-writing tool and understand the impact on L2 learners’ writing progress, perceptions, and interaction patterns. However, it does not explicitly state that quantifiable writing outcome metrics (e.g., scores, rubric-based gains) will be reported, leaving the nature of outcome measures uncertain.""
    }
}"
436,Exploring Efl Students’ Prompt Engineering in Human–ai Story Writing: an Activity Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 67 Hong Kong secondary school students described as English as a foreign language (EFL) students, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""Students used and even created their own generative-AI tools based on open-source language models for story writing, which implies LLM use. However, the abstract does not specify an experimental or quasi-experimental intervention design (e.g., treatment vs. control, pre–post comparison) integrating LLMs into instruction; it appears more exploratory/observational.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is short story writing in English, and the study explicitly examines how students prompt generative AI tools during story writing. The primary focus is on writing processes and related variables (purposes for prompting, activity systems) rather than on automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study mentions the ‘quality of their stories’ as a characteristic of students’ activity systems, the abstract does not indicate any structured, quantifiable writing outcome metrics used to assess the effectiveness of an LLM-mediated intervention. The focus is on thematic analysis of purposes and activity systems, not on measured writing gains or experimental outcomes.""
    }
}"
437,Ai-assisted Feedback in Clil Courses as a Self-regulated Language Learning Mechanism: Students’ Perceptions and Experiences; Retroalimentación Asistida Por Ia En Cursos Clil Como Mecanismo De Aprendizaje Autorregulado De Idiomas: Percepciones Y Experiencias De Estudiantes,2025,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are university students in a business CLIL course, but the abstract does not explicitly state that they are L2 English learners or that English is the target language. CLIL often implies L2 use, yet the specific language (English vs. another L2) is not identified.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study integrates ChatGPT (an LLM) into a 15-week Data Description writing course. Students used ChatGPT weekly to receive criteria-based feedback on compositions and revised drafts accordingly, which constitutes an LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing: a Data Description writing course, weekly compositions, and AI-assisted feedback on content, grammar, and vocabulary. The study examines improvements in writing and linguistic enhancement, not automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Beyond survey data on perceptions, the study reports that a sample of 336 compositions was coded and analyzed to evaluate linguistic enhancement, and it notes significant improvement in content accuracy and linguistic proficiency, indicating quantitative writing outcome measures.""
    }
}"
438,Empowering Efl Learners: Assessing the Ai Brainstorming Tools' Impact on Essay Writing Proficiency,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are thirty Saudi EFL learners in English Departments, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses an AI brainstorming tool (AYOA). The abstract does not indicate that AYOA is a large language model or transformer-based generative model (e.g., ChatGPT, GPT-4). It appears to be a general AI brainstorming/mind-mapping tool rather than an LLM integrated into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on essay writing proficiency: learners brainstorm ideas (with or without AI) and then write essays based on those ideas. The primary outcome is writing performance, fitting the writing competence context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an experimental design with control and experimental groups and reports that the experimental group showed better performance in essay writing, indicating quantifiable writing outcome metrics were collected.""
    }
}"
439,Efl Teachers and Feedback Fatigue: Ai to the Rescue?,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses EFL teachers and L2 writing in general but does not specify any participant group of L2 English learners or empirical data collection with such learners. It appears to be a conceptual or discussion paper rather than a participant-based study.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper \""looks at the contribution of Automated Writing Evaluation (AWE) programmes and Generative Artificial Intelligence (GenAI) to feedback\"" but there is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT, GPT-4) into instruction. It reads as a discussion of tools and roles rather than an intervention study.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""While the focus is on feedback for L2 writing and teacher workload, the abstract does not describe a concrete pedagogical intervention or study context; it appears more like a conceptual or reflective piece on AI-supported feedback and teacher roles.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental measures are mentioned. The abstract raises questions about whether AI can improve writers and not just texts, but does not report any empirical results or structured intervention outcomes.""
    }
}"
440,Cognitive Load Scale for Ai-assisted L2 Writing: Scale Development and Validation,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to 'L2 writing' and 'second language (L2) composition' but does not specify that participants are L2 English learners (ESL/EFL/ELL) or that the target language is English. The specific language context is not stated.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on developing and validating a Cognitive Load Scale for AI-assisted L2 writing. It does not describe an experimental or quasi-experimental pedagogical intervention integrating a specific LLM (e.g., ChatGPT, GPT-4) into instruction; rather, it is a measurement instrument development study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is AI-assisted L2 writing, the primary focus is on cognitive load measurement and scale validation, not on improving writing competence or writing-related performance through an instructional intervention. It aims to provide a tool for future pedagogy, not to test a writing intervention itself.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are psychometric properties (factor structure, internal consistency, criterion-related validity via correlations with anxiety, self-efficacy, and mental effort). No quantifiable writing performance outcomes (e.g., writing quality scores, accuracy, complexity) are reported to assess effectiveness of an LLM-mediated writing intervention.""
    }
}"
441,Chatgpt Affordance for Logic Learning Strategies and Its Usefulness for Developing Knowledge and Quality of Logic in English Argumentative Writing,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 40 EFL university students, indicating second language English learners in an EFL context, with outcomes focused on English argumentative writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study developed a GPT-4-based logic learning bot (ChatGPT-based) and engaged students in logic learning via learner-bot conversations, constituting an LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly English argumentative writing, focusing on developing knowledge and quality of logic in that writing through ChatGPT-based logic learning strategies, i.e., a writing-related pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study used pre-post knowledge tests and essay writing tasks to evaluate the usefulness of ChatGPT affordance, and reports that ChatGPT-based strategies significantly developed knowledge and quality of logic in English argumentative writing, indicating quantifiable writing outcome measures.""
    }
}"
442,Exploring the Effectiveness of a Ddl-genai Teaching Mode in Students’ Efl Writing Classroom,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 75 second-year Chinese university students in an EFL writing classroom, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract describes an innovative teaching mode integrating Data-Driven Learning with Generative Artificial Intelligence (GenAI), and a separate GenAI class, but it does not specify that the GenAI tools are large language models (e.g., ChatGPT, GPT-4). GenAI could refer to other generative tools (e.g., image or non-LLM text tools). Without explicit mention of LLM-based systems, it is unclear whether the intervention uses LLMs.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL expository writing instruction. The study evaluates a DDL-GenAI teaching mode in an EFL writing classroom, focusing on writing performance, structure, content quality, efficiency, and engagement—clearly writing-related pedagogical outcomes rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The quasi-experimental design compares three instructional modes and reports that the DDL-GenAI mode significantly improved students’ writing performance, including structure and content quality. This implies quantifiable writing outcome metrics derived from students’ writing, beyond purely qualitative perceptions.""
    }
}"
443,"Longitudinal Comparison of Ai, Exemplar, and Teacher Feedback for Sustainable L2 Writing Development: a Latent Growth Curve Analysis",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 181 Chinese L2 learners, clearly indicating English as an L2 in an EFL context (“Chinese L2 learners” in an L2 writing development study, situated in L2 writing education). The focus is on L2 writing proficiency, which in this context is standardly English.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention compares three feedback modalities: exemplar-based feedback (EF), Generative AI-generated feedback (AF), and traditional teacher feedback (TF). AF is explicitly described as ‘Generative AI-generated feedback’ and ‘GAI tools,’ implying use of LLM-based generative AI in an experimental design with groups assigned to EF, AF, or TF.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is L2 writing development and writing performance. The study investigates how different feedback sources (including generative AI) drive L2 writing development over 12 weeks, clearly a pedagogical writing intervention rather than automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study models ‘developmental trajectories in writing performance’ and reports ‘overall writing proficiency displayed a significant upward trajectory’ and that ‘writing progress varied significantly by feedback resource.’ Use of latent growth curve analysis over 12 weeks indicates quantifiable writing outcome metrics are reported.""
    }
}"
444,"Ai Feedback Literacy in Higher Education: Understanding, Measuring, and Predicting Student Feedback Uptake",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states that the participants are EFL learners (486 university students), indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study concerns AI-generated feedback and AI feedback literacy, it focuses on developing and validating a psychometric scale and examining predictors of feedback uptake. There is no indication of an experimental or quasi-experimental LLM-based writing intervention or structured integration of a specific LLM (e.g., ChatGPT) into instruction.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context is English writing practices and AI-generated feedback, but the primary focus is on feedback literacy and motivational variables rather than a targeted intervention to improve writing competence. It is not clear that writing performance itself is the central outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are psychometric properties of the AIFL scale and relationships between AIFL, motivational appraisals, and feedback uptake. The abstract does not mention any quantifiable writing performance metrics or changes in writing quality as outcomes of an LLM-mediated intervention.""
    }
}"
445,Does Metalinguistic Explanation of Teacher and Chatgpt Feedback Improve Efl Learners’ Writing Quality and Engagement? Findings from an Intervention Study,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as EFL learners (English as a Foreign Language), indicating L2 English learners in a foreign language context. The focus is on English writing quality and engagement.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is a quasi-experimental intervention examining scaffolded metalinguistic explanations of teacher and ChatGPT feedback. ChatGPT is a large language model integrated into the writing feedback process, satisfying the LLM-based intervention requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on foreign language writing instruction and writing quality. The intervention targets feedback on learners’ written drafts and examines how this affects writing performance and engagement, clearly centering on writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports significant improvements in learners’ writing performance, specifically grammatical accuracy, vocabulary use, and mechanical control, based on pre-tests, post-tests, and written drafts. These are quantifiable writing outcome metrics derived from an intervention.""
    }
}"
446,Exploring Feedback Literacy in L2 Students’ Academic Writing: Insights from Their Reported Engagement with Genal for Typical Revision Activities,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are described as “16 L2 Chinese graduate students.” The abstract does not indicate that they are L2 English learners; rather, they are L2 users of Chinese. The review requires L2 English learners in ESL/EFL/ELL contexts with a focus on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines learners’ engagement with GenAI tools such as DeepSeek and ChatGPT for grammar correction, linguistic refinement, and logical optimization in academic writing. These are LLM-based tools integrated into the writing process, even though the design is not experimental.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is L2 academic writing, focusing on how GenAI feedback is used for revision (grammar, refinement, coherence). The primary focus is on writing and feedback literacy, not on automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses surveys, interviews, and reflective reports to explore perceptions of feedback literacy (cognitive, behavioral, affective, ethical). The abstract does not report any quantitative writing outcome measures (e.g., changes in writing quality, scores, or measurable performance), focusing instead on perceptions and experiences.""
    }
}"
447,A Translanguaging Perspective on Students’ Use of Generative Artificial Intelligence in L2 Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese multilingual undergraduates engaged in L2 writing, which in this journal context strongly implies English as the target language (L2 writing, Chinese multilinguals, GAI-assisted L2 writing).""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study investigates students’ use of ‘generative artificial intelligence (GAI)’ in L2 writing, but the abstract does not specify whether the tools are large language models (e.g., ChatGPT/GPT-based) or other generative systems. However, even if they are LLMs, the design is observational/qualitative rather than experimental or quasi-experimental intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on GAI-assisted L2 writing, examining how students use GAI for creation, translation, evaluation, and revision in their writing processes. This aligns with a writing competence/process context rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses screen recordings, reflective journals, and semi-structured interviews, analyzed via thematic analysis. The abstract reports patterns of use and stances, with no mention of experimental or quasi-experimental measures, nor any quantifiable writing outcome metrics assessing effectiveness of GAI-mediated intervention.""
    }
}"
448,Demystifying Large Language Models in Second Language Development Research,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on Chinese L2 learners’ English writing development and compares L2 with L1 writing, clearly involving L2 English learners in an EFL/ESL-type context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study uses LLMs to compute an LLM-Surprisal metric and build an automatic assessment pipeline, there is no indication of an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or learners’ writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automatic writing assessment and computational metrics (LLM-Surprisal) to distinguish L2 from L1 writing and predict human scores. This is an assessment/measurement study, not a writing instruction or intervention study targeting writing competence development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports how LLM-Surprisal relates to human scores and L2 development stages, but there is no structured LLM-mediated writing intervention whose effectiveness on writing outcomes is experimentally evaluated. It is an analytic/validation study rather than an intervention with pre/post or controlled outcome measures.""
    }
}"
449,Flow in Chatgpt-based Logic Learning and Its Influences on Logic and Self-efficacy in English Argumentative Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 40 Chinese university English-as-a-foreign-language (EFL) students, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a ‘ChatGPT-based environment’ for developing logic in English argumentative writing, indicating an LLM (ChatGPT) is integrated into the instructional environment in an empirical study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary instructional focus is ‘developing logic in English argumentative writing’ and examining flow experiences. While writing is the context, the main targeted competence and measured learning outcome is ‘understanding of argumentative writing logic’ and self-efficacy, not writing performance or writing competence per se.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""They used ‘knowledge tests, essay writing tasks’ and report that deeper flow led to ‘better understanding of argumentative writing logic’ and lower writing self-efficacy. The abstract does not clearly state that quantifiable writing quality or performance metrics (e.g., scores on essays) were analyzed as outcomes of the ChatGPT-mediated intervention, rather than logic understanding and self-efficacy.""
    }
}"
450,"Metacognitive Strategies, Ai-based Writing Self-efficacy and Writing Anxiety in Ai-assisted Writing Contexts: a Structural Equation Modeling Analysis",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as EFL learners, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is conducted in an AI-assisted writing context and examines AI-based writing self-efficacy, but there is no indication of an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT, GPT-4). It appears to be a correlational/SEM study based on questionnaires rather than an LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on psychological variables (metacognitive strategies, AI-based writing self-efficacy, and writing anxiety) rather than on writing competence or writing-related performance outcomes. Writing anxiety is the main outcome, not writing proficiency or product quality.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses questionnaires and SEM to analyze relationships among metacognitive strategies, AI-based writing self-efficacy, and writing anxiety. It does not report quantifiable writing performance outcomes (e.g., scores, quality measures) resulting from an LLM-mediated writing intervention.""
    }
}"
451,Chatbots or Cheatbots? University Students’ Uses of Ai Literacy Tools across Four Nations,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are undergraduate and graduate students in English-medium programs in India, Indonesia, Morocco, and the US, and the paper discusses implications for second-language literacy instruction. This indicates a substantial L2 English learner population in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a cross-case analysis of first-person accounts of students’ uses of LLMs (e.g., ChatGPT). There is no indication of an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction; rather, it is descriptive of existing practices and perceptions.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing is mentioned (e.g., brainstorming ideas, learning to write more complex sentences), the focus is on how students use AI tools and the ethical/productive use of AI in literacy instruction, not on a structured writing competence intervention or instructional design centered on writing outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative accounts of opportunities and challenges. It does not mention any quantitative or experimental writing outcome measures (e.g., writing scores, rubric-based improvements) to assess the effectiveness of LLM-mediated writing interventions.""
    }
}"
452,Developing L2 Postgraduate Students’ Strategic and Responsible Use of Genai through a Purposefully Designed Workshop in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly targets “second language (L2) postgraduate students” and focuses on their challenges in academic writing in condensed master’s programs. While the target language is not explicitly stated as English, the context of postgraduate academic writing and publication venue strongly suggests an English-medium L2 context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention is a workshop on “GenAI” using “a diverse range of GenAI tools,” but no specific tools (e.g., ChatGPT, GPT-4) or model types are named. It is unclear whether the tools are LLM-based or include other forms of generative AI. Thus, it cannot be confidently classified as an LLM-based intervention from the abstract alone.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The workshop is explicitly situated in academic writing, covering “key stages of the writing process, from brainstorming and literature searching to revising and ethical considerations.” The focus is on how GenAI is used within the writing process, aligning with a writing competence/writing-process context rather than assessment-only uses.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are reported for “technology proficiency, critical evaluation skills, ethical competence, and AI agency” based on pre- and post-workshop questionnaires. No quantifiable writing performance or writing quality metrics are mentioned; the measures are attitudinal/skills related to AI use rather than direct writing outcomes. Therefore, it does not meet the requirement for quantifiable writing outcome metrics.""
    }
}"
453,Ai-powered Feedback in Second Language Writing: a Systematic Scoping Review of Technological Innovations in Digital Language Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “second language (L2) writing instruction” and “intermediate-level L2 learners” but does not specify that the target language is English or that the context is ESL/EFL/ELL. It may include multiple target languages, so it is not clear that data are focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as “a systematic review” of empirical research on AI-driven feedback systems. It is not itself an experimental or quasi-experimental primary study integrating LLMs into writing instruction; rather, it synthesizes prior work. Review articles are to be excluded.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on “AI-driven feedback systems in second language (L2) writing instruction” and their effectiveness in improving writing proficiency (grammar, vocabulary, coherence, argumentation), which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract notes that the review examines effectiveness and analyzes outcomes related to linguistic proficiency, but as a secondary study it does not itself report primary experimental writing outcome metrics. It summarizes others’ findings rather than presenting its own intervention results.""
    }
}"
454,"Poe or Gemini for Fostering Writing Skills in Japanese Upper-intermediate Learners: Uncovering the Consequences on Positive Emotions, Boredom to Write, Academic Self-efficacy and Writing Development",2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 519 Japanese upper-intermediate EFL learners. The context is clearly English as a Foreign Language, and the focus is on English writing skills and related affective variables.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention integrates AI-based platforms Poe and Gemini into writing instruction, with two experimental groups (Poe-assisted and Gemini-assisted writing instruction) compared to a traditional control group. Both Poe and Gemini are LLM-based tools, and the design is experimental with random assignment.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on developing writing skills and writing-related variables (positive emotions, boredom to write, academic self-efficacy). The AI tools are used pedagogically within writing instruction, not merely for automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing development is quantitatively assessed through pre- and post-tests, and outcomes are compared across groups using ANOVA and MANOVA. The abstract reports significant improvements in learners’ writing skills in the Poe and Gemini groups relative to the control group.""
    }
}"
455,A Skill-specific Perspective on Ai-mediated Informal Digital Learning of English (ai-idle): Examining the Contributing Roles of L2 Writing Motivation and Enjoyment,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 412 Chinese university students engaged in informal digital learning of English, clearly positioning them as L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study concerns AI-mediated informal digital learning (AI-IDLE), the abstract does not specify the use of large language models (e.g., ChatGPT, GPT-4) nor describe any experimental or quasi-experimental instructional intervention integrating LLMs into writing. It focuses on motivational and affective factors rather than an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on L2 writing motivation, future selves, enjoyment, and their relationship with AI-IDLE writing behavior. It does not describe a structured pedagogical writing intervention or instructional design using LLMs to develop writing competence; instead, it examines psychological mechanisms in an informal learning context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are questionnaire measures of AI-IDLE writing engagement and L2 writing enjoyment, not quantifiable writing performance or competence metrics. There is no indication of pre/post writing tests, rubric-based writing scores, or other direct writing outcome measures tied to an LLM-mediated intervention.""
    }
}"
456,Generative Ai and L2 Written Feedback Studies: a Scoping Review,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a PRISMA-informed scoping review of 51 studies on GenAI-influenced L2 written feedback, not a primary empirical study with its own participant sample. As a review article, it does not itself involve a defined population of L2 English learners for experimental intervention.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a scoping review synthesizing prior research on generative AI in L2 written feedback. It does not implement an experimental or quasi-experimental LLM-based writing intervention itself; instead, it summarizes others’ interventions.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the topic concerns L2 written feedback and writing quality, the article’s primary focus is to map and synthesize existing studies (publication outlets, regions, methods, findings), not to conduct a new pedagogical intervention or evaluate a specific LLM tool in a writing-instruction context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports that included studies use methods such as pre/post-tests and revision analysis, but these are outcomes of the reviewed literature, not original experimental measures from this article. As a scoping review, it does not report its own quantifiable writing outcome metrics from an LLM-mediated intervention.""
    }
}"
457,Embrace or Resist? Efl Teachers on Adopting Chatgpt as a Teaching and Feedback Tool,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The participants are 301 Iranian EFL teachers, not L2 English learners. The study focuses on teachers’ perceptions and reported practices, not learner outcomes.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the study does not implement an experimental or quasi-experimental instructional intervention. It uses a questionnaire to survey perceptions and reported practices rather than testing an LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on teachers’ attitudes toward using ChatGPT for L2 instruction, writing, and feedback, not on an implemented pedagogical intervention targeting writing competence. It is attitudinal rather than an instructional study with measured writing-related outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes are reported. The study reports factor-analytic and inferential results on teachers’ perceptions and practices, without measuring changes in students’ writing performance.""
    }
}"
458,Designing Chatgpt-mediated Feedback Activities in Efl Writing: a Design-based Study of the Dialogic Feedback Triangle,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as EFL learners engaged in English as a Foreign Language writing, which fits the target population of L2 English learners in EFL contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on designing and implementing ChatGPT-mediated dialogic feedback activities in EFL writing. ChatGPT is a large language model, and it is integrated as a formative feedback provider and interactive partner within a structured intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly EFL writing, with ChatGPT used to provide dialogic feedback on writing. The primary focus is on writing processes and feedback literacy in EFL writing, not on automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes a design-based research study with data from observations and interviews about writing experiences and feedback on the intervention. It reports identification of design elements and principles, but does not mention any quantitative or otherwise explicit writing outcome measures (e.g., writing scores, quality ratings, accuracy measures). The focus is on design and perceptions rather than measured writing gains.""
    }
}"
459,"Evaluating the Effectiveness of Ai Tools across the Essay Writing Process: a Comparative Study of Pre-writing, Drafting, and Post-writing Stages",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a Foreign Language learners at Arab Open University, Kuwait. The focus is on English writing, satisfying the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that the experimental group used 'AI tools' in their writing tasks but does not specify which tools or whether they are LLM-based (e.g., ChatGPT, GPT-4). Without clarification that the tools are transformer-based generative models, it is impossible to confirm they are LLMs rather than other AI-assisted tools like grammar checkers.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on the essay writing process (pre-writing, drafting, post-writing) and reports on students’ writing performance. The intervention is clearly pedagogical and centered on writing competence, not on automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an experimental design with pre- and post-tests and reports statistically significant differences in writing performance between experimental and control groups, indicating quantifiable writing outcome metrics.""
    }
}"
460,Incorporating Ai-administered Personalized Feedback in an Inquiry-based Learning Efl Writing Class,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 95 female undergraduate native speakers of Arabic in an EFL academic writing class. This clearly indicates L2 English learners in an EFL context, with English as the target language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses ChatGPT-3.5 to provide personalized feedback on students’ essays via the prompt “correct my grammar.” ChatGPT-3.5 is a large language model, and it is integrated into the writing instruction process as part of an inquiry-based learning design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is an academic EFL writing class. ChatGPT-3.5 is used specifically to give feedback on essays, and the study examines its role in improving essay-writing performance and grammar sub-scores. The primary focus is writing competence within a pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: essay-writing grades on a handwritten final exam and grammar sub-scores within the total essay grade. It analyzes relationships between engagement with AI-mediated feedback (reflections) and these writing performance metrics.""
    }
}"
461,Non-academic Learner Socialisation with Chatgpt and Its Influences on Learning English Argumentative Writing Logic,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 40 EFL university students learning English argumentative writing. The context is clearly English as a foreign language, with outcomes focused on English argumentative writing logic and quality.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a GPT-4-powered bot (an LLM) for learning English argumentative writing logic. Learners engaged with this bot for 45–75 minutes as part of a structured ChatGPT-assisted learning intervention, indicating an experimental/quasi-experimental design integrating an LLM into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on English argumentative writing competence, specifically logical knowledge, logical quality, and self-efficacy in English argumentative writing. The LLM is used pedagogically, not merely for automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable learning outcomes: pre-post tests, writing tasks, and questionnaire surveys assessing logical knowledge, logical quality, and self-efficacy in English argumentative writing. These constitute measurable writing-related outcome metrics within an LLM-mediated intervention.""
    }
}"
462,Genai-assisted Critical Reading Report Revision: a Mixed-methods Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract states the study involves 22 postgraduate L2 learners working on critical reading and writing, implying they are second language users in an academic English context. Thus, the population aligns with L2 English learners in an ESL/EFL/ELL-type setting.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses “GenAI tools” and mentions “interactions with the chatbot” and “GenAI-generated critical reading reports,” which likely indicates an LLM-based tool, but the specific model (e.g., ChatGPT, GPT-4) is not named. However, the design is observational/mixed-methods (lag sequential and thematic analysis of engagement) rather than an explicit experimental or quasi-experimental intervention comparing conditions.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on critical reading and writing dimensions and patterns of engagement during revision, not on writing competence as an instructional outcome. The study explores which dimensions receive engagement and factors influencing selective engagement, emphasizing critical thinking and student agency rather than a structured pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, quality ratings, accuracy, complexity) are reported. The analysis centers on engagement patterns across critical reading/writing dimensions and qualitative factors, without measuring changes in writing performance attributable to the GenAI-assisted revision.""
    }
}"
463,"Ai-generated, L2 Learner, and Native German Writing: a Comparative Analysis of Linguistic Complexity",2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on German argumentative essays and compares AI-generated, L1, and L2 learner writing in German. The target language is German, not English, and the context is foreign language German writing, so it does not meet the requirement that data relate to English L2 learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""ChatGPT and DeepSeek (LLMs) are used to generate texts, but the abstract does not describe an experimental or quasi-experimental pedagogical intervention integrating these LLMs into instruction; it appears to be a comparative corpus-style analysis.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on linguistic complexity and comparative analysis of AI vs. human texts, not on a writing intervention or instructional context. Pedagogical implications are discussed only at the level of implications, not as an implemented intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics from an LLM-mediated intervention are reported. The study analyzes existing texts’ linguistic complexity rather than measuring changes in learners’ writing performance following an LLM-based instructional treatment.""
    }
}"
464,Experiences of Esl Students and Instructors Using Grammarly in Academic Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are English as a second language (ESL) graduate students at a Malaysian public university, clearly fitting the L2 English learner population in an ESL/EFL/ELL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention tool is Grammarly, described as an AI writing assistant. Grammarly is not an LLM-based generative tool like ChatGPT or GPT-4; it is a non-transformer-based writing assistant and thus does not meet the requirement that the intervention integrate large language models.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on academic writing, formative assessment, and how Grammarly feedback affects writing proficiency, motivation, and engagement, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Data were collected through semi-structured interviews and focus groups, and the abstract reports perceived improvements (motivation, engagement, proficiency) but does not indicate any experimental or quasi-experimental design with quantifiable writing outcome metrics.""
    }
}"
465,Tracking the Effects of Gemini as a Genai Tool on L2 Learners’ Writing Proficiency and Anxiety: Latent Growth Curve Modeling Approach,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 274 undergraduate English learners in Iran enrolled in academic writing classes. The context is clearly L2 English (EFL) learners, and the focus is on English writing proficiency and anxiety.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is a GenAI-assisted instruction using Gemini, a large language model, compared to traditional instruction. Participants were randomly assigned to treatment and control groups over a 16-week course, indicating an experimental design integrating an LLM into instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 writing proficiency and writing anxiety in academic writing classes. Gemini is used pedagogically to provide tailored, immediate feedback within writing instruction, not merely for automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: writing proficiency measured via a standardized rubric-based assessment and writing anxiety via an L2 writing anxiety scale. Results include specific statistics (MD, SE, CR, p-values) for changes in proficiency and anxiety.""
    }
}"
466,"Comparing the Effects of Teacher- and Ai-mediated Corrective Feedback on Accuracy, Complexity, and Quality in L2 Written Narratives",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 166 upper-intermediate ESL undergraduates in international writing classes at a U.S. university. The context is clearly L2 English (ESL).""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “generative artificial intelligence (AI)” and “AI-mediated WCF” but does not specify the tool (e.g., ChatGPT, GPT-4) or whether it is an LLM-based system. It could be an LLM or another AI feedback tool; this cannot be determined from the abstract alone.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on written corrective feedback in L2 narrative writing and examines effects on complexity, accuracy, and quality of written texts, which are core writing-related variables in a pedagogical context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes: changes in accuracy (error reduction), lexical and syntactic complexity, and writing quality scores, comparing teacher vs. AI-mediated feedback groups.""
    }
}"
467,"Artificial Intelligence in Language Education: a Systematic Review of Multilingual Applications, Large Language Models, and Emerging Challenges",2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a broad systematic review of AI in language education across multilingual settings. It does not focus specifically on L2 English learners in ESL/EFL/ELL contexts; instead, it covers multiple languages, including low-resourced and marginal languages in general.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a review article synthesizing 161 studies and discussing various AI tools (conversational agents, speech recognition, writing assistants, LLMs like Aya and LLaMA). It does not itself implement an experimental or quasi-experimental LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on AI in language education broadly (anxiety reduction, pronunciation support, real-time feedback, mobile learning, gamification, ethics, infrastructure). Writing is only one of several skills mentioned and not the central focus of a specific intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic review, it does not report original experimental outcome metrics for an LLM-mediated writing intervention. It summarizes general benefits and gaps without presenting quantifiable writing outcome data from a specific study design.""
    }
}"
468,Efl Teachers’ Inquisitive Agency in Ai-enhanced Writing Instruction,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are twelve Indonesian EFL teachers, not L2 English learners. The focus is on teacher agency rather than learner outcomes.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions integration of AI tools in EFL writing instruction but does not specify that these are LLM-based tools (e.g., ChatGPT, GPT-4) or describe an experimental/quasi-experimental intervention design.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""While the context is EFL writing instruction, the primary focus is on teachers’ inquisitive agency and pedagogical practices, not directly on writing competence or writing-related learner variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses qualitative methods and reports thematic categories about teacher practices. It does not report quantifiable writing outcome metrics or experimental measures of LLM-mediated writing interventions.""
    }
}"
469,Evaluating the Performance of Chatgpt and Claude in Automated Writing Scoring: Insights from the Many-facet Rasch Model,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 117 English as a Foreign Language (EFL) students in China, clearly an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT and Claude are used as automated writing scorers (LLM-based raters). There is no experimental or quasi-experimental instructional intervention integrating LLMs into learners’ writing processes or teaching; the LLMs function solely as assessment tools.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automated writing scoring (AWS) performance, rater severity, consistency, and gender bias using Many-Facet Rasch Modeling. It evaluates LLMs as scoring systems, not as pedagogical tools to improve writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics for learners are reported. Outcomes concern scoring characteristics (severity, consistency, bias) of LLM raters, not changes in students’ writing performance following an LLM-mediated intervention.""
    }
}"
470,Genai Image Creation in Efl: Prompt Writing as an Emerging Writing Activity for Sustainability-focused Artivism,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL preparatory-year students at a university in Northern Cyprus, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses GenAI for image generation based on English prompts, but the abstract does not specify that the tool is an LLM (e.g., ChatGPT, GPT-4) or any transformer-based generative text model. It focuses on AI image generation, not an LLM-mediated writing system.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on prompt writing and sustainability-focused artivism. While there is writing practice (English prompts, descriptive texts), the primary emphasis is sustainability awareness and artivism, not systematic development of writing competence as a central outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a qualitative descriptive study with thematic analysis. Outcomes reported are perceived gains in writing confidence and strategy use; there is no mention of quantifiable writing outcome metrics (e.g., scores, rubric-based assessments, pre-post tests) to evaluate writing improvement.""
    }
}"
471,"Lexical Diversity, Syntactic Complexity, and Readability: a Corpus-based Analysis of Chatgpt and L2 Student Essays",2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions a corpus of 50 student essays and notes implications for L2 learners, but it does not explicitly state that the 50 student essays are written by L2 English learners in ESL/EFL/ELL contexts. The learner population is therefore not clearly defined as L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares AI-generated texts via ChatGPT with student-written essays using corpus-based measures. There is no indication of an experimental or quasi-experimental pedagogical intervention where ChatGPT is integrated into writing instruction or the writing process; it is an observational comparison of text corpora.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus is on writing-related variables (lexical diversity, syntactic complexity, readability), the study does not describe an instructional context or intervention aimed at improving writing competence. It analyzes existing texts rather than implementing a teaching/learning activity involving LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports quantitative measures of texts (TTR, MLT, readability indices) but not as outcomes of an LLM-mediated writing intervention. There is no pre/post or treatment/control design assessing changes in learners’ writing performance due to LLM use.""
    }
}"
472,Factors Affecting Efl Students’ Behavioral Intention to Use Ai in Efl Writing Development,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese university students using AI for English as a Foreign Language (EFL) writing development, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines behavioral intention to adopt AI via a technology acceptance model using a cross-sectional survey. It does not specify the use of LLM-based tools (e.g., ChatGPT) in an experimental or quasi-experimental instructional intervention; AI is treated generically and only at the level of intention, not as an implemented LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on factors influencing intention to use AI, not on writing competence or writing-related performance outcomes. It is a technology acceptance study rather than a pedagogical intervention targeting writing development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes are psychological/attitudinal (behavioral intention, attitude, expectancy variables) analyzed via SEM, with no experimental measures of changes in writing performance.""
    }
}"
473,A Case Study of Applying Grammarly for Mastering Pre-service Teachers' Writing Skills,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are university students majoring in English at Pavlo Tychyna Uman State Pedagogical University (Ukraine). They are clearly L2 English learners in an EFL/ESL context, and the focus is on English academic writing skills.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention tool is Grammarly. While described as AI-based, Grammarly is not an LLM-based, transformer-style generative model like ChatGPT, GPT-4, or Gemini. The review explicitly excludes tools such as Grammarly that do not utilize LLMs as the core intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on improving English academic writing skills (grammar, vocabulary, spelling, pragmatic components, language accuracy) through the use of Grammarly, which is directly related to writing competence.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions pre- and post-interviews to collect data on writing problems and discusses criteria for pragmatic components and language accuracy, but it does not clearly report quantifiable writing outcome metrics (e.g., scores, error rates). It is unclear whether structured, quantitative outcome measures were used.""
    }
}"
474,Leveraging Chatgpt for L2 Writing: Teacher Cognition and the Impact of Professional Development,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are 11 EFL teachers working in L2 writing contexts, and the abstract mentions student writing with ChatGPT feedback, implying an English-as-a-foreign-language setting focused on L2 English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study centers on teacher cognition and a professional development program about using ChatGPT. There is no indication of an experimental or quasi-experimental LLM-based instructional intervention implemented with L2 learners; ChatGPT is used mainly as an object of teacher learning, not as a structured classroom intervention tested for effectiveness.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is L2 writing and feedback, the primary focus is on teachers’ beliefs and understanding of ChatGPT’s pedagogical potential, not on systematically improving learners’ writing competence through an implemented intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics for students. Outcomes are qualitative (teacher cognition changes, feedback literacy), with no experimental measures of student writing performance or related quantitative writing variables.""
    }
}"
475,"Comparing Peer Feedback and Generative Artificial Intelligence Feedback in Japanese English as a Foreign Language Speaking Context: Impacts on Motivation, Engagement, and Writing Self-efficacy",2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Japanese university students learning English as a Foreign Language (EFL), clearly an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study contrasts peer feedback with generative AI feedback using ChatGPT, a large language model, as part of an instructional intervention across semesters.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary context is speaking preparation; the focus variables are motivation, engagement, and writing self-efficacy during script-writing for speaking tasks. Writing is present but as support for speaking, and the main outcome focus is not writing competence or writing-related performance measures.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are motivation, ideal L2 self, engagement, and writing self-efficacy, measured via surveys. There are no quantifiable writing performance or quality metrics assessing the effectiveness of the LLM-mediated writing intervention.""
    }
}"
476,Artificial Intelligence in Efl Writing Enhancement: a Study on Chatbot Feedback and Learner Autonomy,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on English as a Foreign Language (EFL) learners and writing as part of second language acquisition, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study uses an online AI chatbot and mentions a transformer-based NLP system, it is described as producing feedback based on ICLE essays, not as a large language model (LLM) such as ChatGPT/GPT-4. It appears to be a feedback-generation NLP system rather than a generative LLM integrated into instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on writing enhancement, with the chatbot providing feedback on grammar, vocabulary, and discourse-level characteristics, and the study discusses its role as a writing partner in learning environments. This aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: changes in lexical diversity (MTLD), syntactic complexity (C/T), and cohesion, and notes significant language gains among high-level learners through self-directed revisions.""
    }
}"
477,Guided or Guiding: Contradictions and Conflicts in Ai-assisted Second Language Writing for Efl Learners from the Activity Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a Foreign Language (EFL) learners engaged in second language writing, so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “artificial intelligence (AI)” and “AI-assisted writing” but does not specify that the tools are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems. The nature of the AI tool is not detailed, so it is unclear whether an LLM is involved.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on second language writing, AI-assisted writing practices, and tensions between learning processes, product improvement, and assessment standards. The context is clearly writing competence and writing-related practices in L2 instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as a qualitative analysis of three EFL learners using Activity Theory to examine contradictions and learner agency. There is no mention of experimental or quasi-experimental design, nor of quantifiable writing outcome metrics; the outcomes are theoretical and qualitative (tensions, strategies, agency), not measured writing performance.""
    }
}"
478,"Descriptive Writing Using Generative Ai as a Cognitive Scaffold in the Metaverse Environment: University Students’ Perceptions, Learning Engagement, and Performance",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as undergraduate students in two English as a foreign language (EFL) writing classes, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses a generative AI tool called ‘GAIscaffold’ as a cognitive scaffold. However, the abstract does not specify whether GAIscaffold is an LLM-based, transformer-style generative model (e.g., similar to ChatGPT/GPT-4) or another form of generative AI. Without this detail, it is unclear if it meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on EFL descriptive writing performance in a metaverse environment, using generative AI as a scaffold in the writing process. The primary outcomes relate to writing and writing-related engagement, not automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative outcomes, including final writing performance compared between experimental and control groups using MANCOVA, and notes statistically significant improvements in writing performance for the experimental group.""
    }
}"
479,Overview of the Clef 2025 Joker Task 1: Humour-aware Information Retrieval,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes an information retrieval task and datasets in English and Portuguese, but does not mention any participants, let alone L2 English learners in ESL/EFL/ELL contexts. It is a shared task overview, not a learner study.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on humour-aware information retrieval and humour detection. There is no indication of an experimental or quasi-experimental pedagogical intervention using LLMs (e.g., ChatGPT) in writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is information retrieval of humorous texts and cross-linguistic humour detection. Writing competence or writing-related pedagogical variables are not the focus; any mention of writing is only as a potential use case, not as an instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No writing outcome measures are reported. The paper reports dataset statistics and system runs for an IR task, not quantifiable changes in learners’ writing performance following an LLM-mediated intervention.""
    }
}"
480,Personalized L2 Argumentative Writing Instruction through Genai-enhanced Corpus-based Language Pedagogy: an Intervention Study,2025,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are L2 learners engaged in IELTS Task 2 argumentative writing, which is an English proficiency exam. The study explicitly concerns L2 argumentative writing, implying L2 English learners in an EFL/ESL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses GPT-4o (a large language model) to analyze learners’ essay corpus and generate individualized linguistic profiles, tailored writing tips, coherence/cohesion checks, vocabulary lists, and grammar exercises. It is an experimental design with a control group receiving traditional instruction and an experimental group receiving LLM-mediated instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on L2 argumentative writing instruction and enhancement of L2 learners’ argumentative writing. GPT-4o is integrated pedagogically to support writing-related feedback, coherence, vocabulary, and grammar within a corpus-based language pedagogy framework.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative results from IELTS writing tasks (pre/post and long-term), showing significant differences between control and experimental groups. These are clear, quantifiable writing outcome measures assessing the effectiveness of the GenAI-mediated intervention.""
    }
}"
481,Postgraduate Students' Attitude Toward Using Chatgpt in Enhancing Their Master's Thesis: a Mixed Method Study,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as postgraduate EFL learners, indicating they are L2 English learners in an EFL context and the focus is on English thesis writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the study is not an experimental or quasi-experimental intervention. It investigates students’ attitudes and self-reported uses of ChatGPT rather than implementing and testing a structured LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on enhancing the quality of Master’s thesis writing (content, structure, grammar, sentence structure, APA style), which are writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses semi-structured interviews and a questionnaire to explore attitudes and perceived benefits. There is no indication of quantifiable writing outcome measures (e.g., pre/post writing scores, rubric-based performance) assessing the effectiveness of ChatGPT on writing quality.""
    }
}"
482,Enhancing Argumentative Essay Skills: Evaluating the Efficacy of Ai-powered Tools Versus the Traditional Approach among Learners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly refers to “second language (L2) learners” and “second language learners,” indicating an L2 population. While the target language is not named, the context of argumentative essay writing and institutional teaching strongly suggests an ESL/EFL academic writing context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses “AI-powered writing tools like Quill Bot, Jeni AI, and others.” QuillBot is not an LLM-based pedagogical tool in the sense required (it is primarily a paraphrasing/editing tool and not framed here as a transformer-based generative LLM used for instruction). No specific LLMs (e.g., ChatGPT, GPT-4, Gemini) are mentioned, and the tools are not clearly identified as LLM-based writing assistants integrated into instruction, so it does not meet the LLM intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s focus is on teaching and learning argumentative essay writing: “mentor students to write argumentative essays,” “teach students the skill of crafting persuasive essays,” and it evaluates different instructional approaches. This aligns with a writing competence intervention context rather than automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is described as a quasi-experimental design with experimental and control groups, and it reports that combining traditional methods with AI tools “significantly improved writing competency and the long-term retention of argumentative writing abilities.” This implies quantitative outcome measures of writing performance over a semester.""
    }
}"
483,Leveraging Llm-based Chatbots for Interactional Grammar Feedback in L2 Writing: Opportunities and Challenges,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 89 second-year pre-service teachers in South Korea receiving grammar feedback on their English essays, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The title and abstract describe a ‘LLM-based chatbot’ and mention ChatGPT as context, but do not explicitly state that the implemented chatbot itself is powered by a large language model (e.g., GPT-4) versus a rule-based or non-LLM system. It is also unclear whether the design is experimental or quasi-experimental rather than descriptive/showcase of practice.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is L2 writing instruction, focusing on interactional grammar feedback on students’ English essays and its role as a feedback provider in L2 writing classrooms, which aligns with writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports that the chatbot ‘offers several advantages’ and could be a complementary resource, but does not indicate any quantitative writing outcome measures (e.g., changes in writing scores, accuracy, complexity) or an experimental comparison. It appears to be a practice-oriented or evaluative study without reported quantifiable writing outcomes.""
    }
}"
484,Chinese Efl Learners’ Genai Literacy in Digital Multimodal Composing and Self-regulated Writing: Chain Mediation Effects of Needs Satisfaction and Creative Self-concept,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 634 Chinese EFL learners, i.e., L2 English learners in an EFL context, with focus on English writing and digital multimodal composing in EFL.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines learners’ GenAI literacy in digital multimodal composing via questionnaires and structural equation modeling. There is no experimental or quasi-experimental intervention where an LLM (e.g., ChatGPT, GPT-4) is integrated into writing instruction or writing processes; GenAI is treated as a literacy construct, not as an implemented pedagogical tool.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on psychological mechanisms (needs satisfaction, creative self-concept) linking GenAI literacy in DMC to self-regulated writing. It does not describe a concrete LLM-mediated writing intervention or instructional context; rather, it is a correlational/mediation study of literacy and SRL, not an implemented writing pedagogy using LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are questionnaire-based measures of GenAI literacy, needs satisfaction, creative self-concept, and self-regulated writing. The study does not report quantifiable writing performance outcomes (e.g., text quality, accuracy, complexity) resulting from an LLM-mediated intervention.""
    }
}"
485,Artificial Intelligence Vs. Instructor Supported Ai: Teaching Second Language Writing Via “write&improve”,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study investigates ‘second language writing’ and ‘English writing success’ and ‘English writing self-efficacy beliefs,’ indicating participants are L2 English learners in an ESL/EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses the Write&Improve system. While it is an AI-based feedback tool, the abstract does not indicate that it is an LLM/transformer-based generative model (e.g., ChatGPT, GPT-4). Write&Improve is typically an automated feedback system, not a large language model–mediated writing assistant as required by the review.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on second language writing, specifically ‘English writing success’ and related constructs (self-efficacy, achievement emotions, teacher-student interaction) within a writing instruction context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an 8-week pretest–posttest control group design and reports a ‘statistically significant increase’ in English writing success and other variables, indicating quantifiable writing outcome metrics are collected and analyzed.""
    }
}"
486,"International Conference on Artificial Intelligence and Networks, Icain 2024",2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a conference proceedings volume description listing multiple papers across AI and networks. No specific study with L2 English learners is described in the abstract. One title mentions EFL teachers, but no participant details or focus on L2 English learners’ writing outcomes are provided at the proceedings level.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract summarizes a collection of 50 papers on diverse AI topics. It does not specify any experimental or quasi-experimental integration of large language models (e.g., ChatGPT, GPT-4) into writing instruction. The only writing-related title, “EFL Teachers’ Inquisitive Agency in AI-Enhanced Writing Instruction,” does not indicate LLM use or an intervention design in this proceedings-level abstract.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The proceedings cover broad AI and network topics (cybersecurity, fake news detection, medical imaging, etc.). Writing is only tangentially mentioned in one paper title, and there is no indication that the primary focus of any described study is writing competence or writing-related variables in a pedagogical context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported in this proceedings abstract. It is a general description of a conference volume, not a specific empirical study with measured writing outcomes related to an LLM-mediated intervention.""
    }
}"
487,"Ai-assisted Academic Writing in a Blended Efl Setting: Practices and Perceived Effectiveness at Fpt University, Hanoi",2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as first-year EFL students at FPT University Hanoi, indicating L2 English learners in an EFL context, with outcomes reported in terms of IELTS writing band scores (English).""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that students use AI tools such as ChatGPT, QuillBot, and DeepSeek to support academic writing, but it does not clearly specify whether there is an experimental or quasi-experimental intervention design centered on LLM integration versus a control/comparison condition. It may be observational use within a blended course rather than a structured LLM-mediated intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on academic writing in an EFL blended learning environment, examining how AI tools are used for idea generation, grammar correction, and content refinement, and discussing AI’s pedagogical potential in EFL writing instruction.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study reports that writing scores improved by an average of 0.94 IELTS band scores, but the abstract does not clarify whether this gain is causally attributed to a defined LLM-based intervention (e.g., pre/post with structured AI use) or is simply correlational/observational. The design and measurement structure are not sufficiently detailed to confirm it as an experimental or quasi-experimental outcome of LLM-mediated intervention.""
    }
}"
488,Large Language Model-driven Dynamic Assessment of Grammatical Accuracy in English Language Learner Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions 'learners of English' and 'English Language Learner Writing', suggesting an ELL context, but it does not clearly specify that participants are L2 English learners in ESL/EFL/ELL settings, nor does it describe an actual learner sample.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study develops DynaWrite and tests 21 LLMs (with focus on GPT-4o and neural-chat) for their ability to provide dynamic assessment feedback and identify grammatical errors. The focus is on system performance and model comparison, not on an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction with learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is grammatical accuracy in learner writing, the primary focus is on evaluating LLM capabilities (error detection, DA quality, responsiveness, stability) rather than on improving learners’ writing competence through an instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes are reported. The metrics concern model performance (error identification accuracy, quality of hints, responsiveness, stability), not changes in learners’ writing performance following an LLM-mediated intervention.""
    }
}"
489,Prompt Engineering as Mediation: Investigating Ai Chatbot-assisted Writing Process from an Activity Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Chinese EFL (English as a Foreign Language) undergraduates, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to an ‘AI chatbot’ and ‘chatbot-supported expository writing tasks’ but does not specify that the chatbot is a large language model (e.g., ChatGPT, GPT-4). It could be any AI chatbot, so the LLM nature of the tool is not confirmed.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on ‘chatbot-supported expository writing tasks’ and ‘AI chatbot-assisted writing within activity systems,’ clearly centering on writing processes and outcomes in an instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions ‘shaping writing outcomes,’ it presents a qualitative, activity-theory-based investigation using interaction logs, artifacts, and interviews. There is no indication of an experimental or quasi-experimental design with quantifiable writing outcome metrics to assess intervention effectiveness.""
    }
}"
490,The Role of Artificial Intelligence in Writing Assessment: Learner Perceptions and System Effectiveness,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions 'learners of varying educational levels' but does not specify that they are L2 English learners in ESL/EFL/ELL contexts. Their language background and whether English is an L2 is not stated.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on AI-driven writing tools such as Grammarly and Turnitin, which are not described as large language model (LLM)-based generative systems. There is no mention of ChatGPT, GPT-4, or other LLMs, nor of an experimental or quasi-experimental LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on writing assessment, learner perceptions, and system effectiveness (accuracy, fairness, clarity of feedback), not on a pedagogical writing intervention or instructional integration of LLMs. It evaluates an assessment tool rather than a structured teaching/learning process in writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract claims that regular usage of the AI tool 'significantly enhances writing skills, particularly in grammar,' it does not clearly describe an experimental or quasi-experimental design with quantifiable writing outcome metrics specific to an LLM-mediated intervention. The emphasis is on perceptions and satisfaction ratings rather than measured writing performance changes from an LLM-based intervention.""
    }
}"
491,The Potential Advantages of Using an Llm-based Chatbot for Automated Writing Evaluation for English Teaching Practitioners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Korean high school EFL students, clearly L2 English learners in an EFL context: “narrative essays written by Korean high school EFL students.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study develops an AWE chatbot based on ChatGPT 4.0-turbo used as an automated rater. There is no experimental or quasi-experimental pedagogical intervention integrating the LLM into writing instruction or writing processes; it is a tool validation study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automated writing evaluation and score reliability/validity: comparing chatbot scores with human raters using analytic measures and Rasch modeling. It evaluates LLM functionality as an essay scoring system, not as part of a teaching/learning intervention targeting writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics from an intervention are reported. The study analyzes correlations between LLM and human scores on existing essays, without any instructional treatment or pre/post writing performance measures.""
    }
}"
492,Development and Validation of a Multidimensional Chatgpt Feedback Engagement Scale in Second Language Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to 'second language (L2) writing' and 'students' but does not specify that the target language is English or that participants are ESL/EFL/ELL learners. The L2 could be any language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on developing and validating a 'ChatGPT Feedback Engagement Scale.' It examines engagement with ChatGPT feedback but does not describe an experimental or quasi-experimental pedagogical intervention integrating an LLM into writing instruction; rather, it is a measurement development/validation study.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context is L2 writing and ChatGPT feedback engagement, which is writing-related. However, the primary focus is on engagement constructs and scale development, not on writing competence or instructional intervention outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are psychometric properties of an engagement scale (factor structure, validity, reliability). There is no indication of quantifiable writing performance or writing quality measures used to assess the effectiveness of an LLM-mediated writing intervention.""
    }
}"
493,Understanding How Ai Chatbots Influence Efl Learners' Oral English Learning Motivation and Outcomes: Evidence from Chinese Learners,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 351 EFL students in China learning spoken English with an AI chatbot, clearly an EFL/ESL context focused on English as L2.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers generically to “AI chatbots” for spoken English learning but does not specify that they are large language model–based (e.g., ChatGPT, GPT-4) or transformer generative models. They could be rule-based or other non-LLM systems.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on spoken/oral English learning, motivation, self-efficacy, and social presence. There is no indication that writing instruction, writing processes, or writing competence are targeted outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes concern oral English learning motivation and learning outcomes in a general sense, analyzed via SEM from questionnaire data. No quantifiable writing outcome metrics or writing performance measures are reported.""
    }
}"
494,A Qualitative Descriptive Study of Teachers' Beliefs and Their Design Thinking Practices in Integrating an Ai-based Automated Feedback Tool,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is Norwegian 9th-grade students learning English as a second language, taught by ESL teachers. The abstract explicitly mentions ‘English as a second language teachers’ and ‘L2 writing’, indicating L2 English learners in an ESL/EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention involves an AI-driven automated feedback tool (Essay Assessment Technology, EAT), but it is not identified as an LLM-based tool (e.g., ChatGPT, GPT-4). It is framed as an automated assessment/feedback system, and there is no indication it is a transformer-based generative LLM. Thus it does not meet the LLM requirement.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on teachers’ beliefs, perceptions, and design thinking practices when integrating an AI-based automated feedback tool, not on students’ writing competence or writing-related learning outcomes. It is essentially about technology integration and teacher cognition, not a pedagogical writing intervention outcome study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly described as a ‘descriptive qualitative study’ using teacher interviews to explore perceptions and pedagogical decisions. No quantitative or experimental writing outcome measures for students are reported in the abstract.""
    }
}"
495,Effects of Ai Chatbots on Efl Students' Critical Thinking Skills and Intrinsic Motivation in Argumentative Writing,2025,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 40 Chinese undergraduates in an EFL context (“EFL classroom activities”), indicating they are L2 English learners. The focus is on argumentative writing in English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses an “AI chatbot” called Spark Desk. The abstract does not specify whether Spark Desk is a large language model (LLM)–based chatbot (e.g., transformer-based generative model) or a different type of AI system. Without confirmation that it is LLM-based, it is unclear if this meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is argumentative writing in an EFL classroom. The chatbot is integrated into writing activities, and outcomes include critical thinking skills in argumentative writing and intrinsic motivation related to writing. This aligns with a writing-focused pedagogical intervention rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""Critical thinking skills were assessed using the Illinois Critical Thinking Essay Scoring Rubric applied to students’ argumentative writing, and intrinsic motivation was measured quantitatively. However, the abstract does not clearly state whether direct writing performance metrics (e.g., writing quality scores, language accuracy, coherence) were quantified as outcomes, or only CTS as a construct applied to essays. It is therefore unclear if it reports quantifiable writing outcome metrics as defined in the inclusion criteria.""
    }
}"
496,To Disclose or Not to Disclose: Exploring the Risk of Being Transparent about Genai Use in Second Language Writing,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on second language (L2) writers and L2 writing assessment, indicating that the population is L2 learners. While the target language is not named, the context of L2 writing assessment and GenAI in academic settings strongly suggests L2 English, so this criterion is treated as passed.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines the impact of disclosing GenAI use on teachers’ grading. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes; GenAI use is a background condition, not the designed instructional treatment.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on how disclosure of GenAI use affects L2 writing assessment (grades and teacher bias), not on improving writing competence or writing-related skills through LLM-mediated instruction. This aligns more with assessment bias and policy rather than a writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although quantitative differences in grades under different disclosure conditions are reported, these are not outcomes of an LLM-mediated writing intervention. The study does not evaluate the effectiveness of GenAI/LLM use on writing quality; it evaluates teacher scoring behavior when GenAI use is disclosed.""
    }
}"
497,Creating an Internationally Equitable Playing Field for Publishing in English-language Scholarly Journals,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article discusses non-Anglophone authors publishing in English-language scholarly journals, but not as L2 English learners in ESL/EFL/ELL instructional contexts. It focuses on academic publishing inequities rather than language learners in educational settings.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Artificial intelligence is mentioned only as a recommendation to facilitate translation, not as an implemented LLM-based intervention in an experimental or quasi-experimental study. No specific LLM tools or instructional integration are described.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on barriers to publishing and equity in academic journals, not on writing instruction, writing pedagogy, or systematic intervention in writing competence. It is a conceptual/recommendation piece, not a pedagogical writing intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any empirical data or quantifiable writing outcomes. It offers recommendations and arguments without experimental measures or structured intervention outcomes.""
    }
}"
498,Digital Literacy in the Age of Artificial Intelligence: Exploring Student Engagement with Automated Writing Evaluation (awe) Feedback,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract is situated in the context of L2 writing but does not specify the target language (e.g., English) or clearly identify participants as ESL/EFL/ELL learners. It appears more conceptual/theoretical than participant-based.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the title mentions AI and automated writing evaluation (AWE), the abstract describes a review and conceptual discussion of digital literacy and student engagement. There is no indication of an experimental or quasi-experimental design integrating an LLM-based tool (e.g., ChatGPT, GPT-4) into writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on theorizing digital literacy and engagement in L2 writing, not on a concrete pedagogical intervention targeting writing competence or writing-related variables using LLMs. It is primarily a conceptual article rather than an intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental measures are reported. The article reviews concepts and proposes an integrated model; it does not assess the effectiveness of an LLM-mediated writing intervention.""
    }
}"
499,Secondary School English Teachers' Application of Artificial Intelligence-guided Chatbot in the Provision of Feedback on Student Writing: an Activity Theory Perspective,2025,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are 13 secondary school English teachers in China. The abstract does not specify the language background of the students whose writing receives feedback, though the context suggests L2 English learners. However, the study’s participants and data focus are on teachers, not learners, so it is unclear whether learner-level L2 English data are central.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses Kimi, an AI-guided chatbot, to support teacher feedback on student writing. Kimi may be an LLM-based tool, but the abstract does not explicitly identify it as a large language model (e.g., ChatGPT/GPT-4-type transformer). Without confirmation that Kimi is LLM-based, it is unclear whether this meets the LLM intervention criterion.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on how teachers incorporate an AI-guided chatbot into their feedback practices, analyzed through Activity Theory. Outcomes reported concern characteristics of Kimi vs. teacher feedback and components of the activity system, not on changes in learners’ writing competence or writing-related performance variables. Thus, the context is feedback practice, not a pedagogical writing intervention with learner outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics (e.g., writing scores, complexity, accuracy, fluency) for students. Findings relate to amount, length, foci, and types of feedback and to activity system components, but not to measured changes in student writing performance. Therefore, it does not meet the requirement for quantifiable writing outcomes.""
    }
}"
500,Efl Students' Writing Engagement and Ai Attitude in Genai-assisted Contexts: a Mixed-methods Study Grounded in Sdt and Tam,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as EFL learners in GenAI-assisted writing contexts, which fits the target population of L2 English learners in EFL settings.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is ‘GenAI-assisted writing’, the abstract does not describe any experimental or quasi-experimental instructional intervention integrating a specific LLM into writing instruction. It focuses on profiling engagement and attitudes, and notes that few teachers have actively integrated such tools into their teaching, suggesting no structured LLM-based intervention was implemented.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on writing engagement and attitudes toward GenAI, not on writing competence or writing-related performance variables. The study examines engagement profiles and teacher perceptions rather than pedagogical effects on writing skills.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, quality ratings, accuracy, complexity) are reported. Outcomes are engagement profiles and attitude measures, plus qualitative interview data, without experimental measures of writing performance.""
    }
}"
501,Is This Really Your Work?: a Qualitative Study of Teacher-led Interviews and Student Accountability in the Age of Generative Ai,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 24 Master's-level English as a Foreign Language (EFL) students, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study concerns student engagement with generative AI tools, it does not describe an experimental or quasi-experimental LLM-based writing instruction or intervention. The focal intervention is teacher-led interviews as an assessment practice, not structured LLM-mediated writing instruction or process support.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on authorship, integrity, accountability, and ethical orientation in academic work, not on writing competence or writing-related performance variables. Writing is the context, but the outcome focus is ethical and reflective engagement with GenAI, not writing development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly qualitative, using thematic analysis of reflection data. It reports cognitive, emotional, and agentive developments but no quantifiable writing outcome metrics or experimental measures of writing performance.""
    }
}"
502,Integrating Iwrite Tools into English Writing Instruction,2025,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract describes English writing instruction in Chinese universities, implying that participants are Chinese learners of English in an EFL context, i.e., L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The tool mentioned is ‘iWrite’, described generically as an AI tool for grammar correction, vocabulary enhancement, and structural analysis. There is no indication that it is a large language model (e.g., ChatGPT/GPT-4-like transformer-based generative model). It appears more akin to traditional AI-assisted writing tools, which fall outside the LLM-focused scope.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on English writing instruction and improving writing proficiency, including grammar, vocabulary, and structure, which aligns with writing competence as the primary context.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions ‘methods, outcomes, and challenges’ and claims that iWrite ‘improves writing proficiency’ and ‘enhance[s] writing skills’, but it does not specify any experimental or quasi-experimental design or report quantifiable writing outcome metrics. It is unclear whether systematic, measurable outcomes are presented.""
    }
}"
503,A Literature Review on Generative Artificial Intelligence Applications in Foreign Language Education,2025,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a literature review of generative AI in foreign language education, synthesizing 30 empirical studies. It is not an empirical study with its own participant population of L2 English learners; instead, it aggregates prior work.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""As a literature review, the paper does not itself implement an experimental or quasi-experimental LLM-based writing intervention. It only summarizes existing studies and their use of GenAI tools.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is broad—foreign language education across multiple categories (user perceptions, language learning applications, assessment, teacher preparation, affective factors). It is not a primary study centered on a specific writing competence intervention context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The article does not report original, quantifiable writing outcome metrics. It is a qualitative synthesis of prior empirical studies and thus falls under review articles, which are excluded by the protocol.""
    }
}"
504,"Effects of Speech-enabled Corrective Feedback Technology on Efl Speaking Skills, Anxiety and Confidence",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are clearly described as learners of English as a foreign language (EFL) and university students from China and Kazakhstan engaged in EFL speaking practice, so the population fits L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is a speech-enabled corrective feedback (SECF) system combining speech-to-text recognition (STR) and automated corrective feedback (ACF). There is no indication that this system is based on large language models (e.g., ChatGPT, GPT-4, transformer-based generative models); it appears to be an STR plus rule-based or non-LLM ACF tool.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on speaking skills, foreign language anxiety, and confidence in speaking. Although STR converts speech to text, the intervention and outcomes target spoken English proficiency, not writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantitative outcomes reported concern EFL speaking ability (pronunciation, grammar, vocabulary, discourse length) and affective variables (anxiety, confidence). No quantifiable writing outcome metrics are mentioned.""
    }
}"
505,Chatgpt in Foreign Language Teaching and Assessment: Exploring Efl Instructors' Experience,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The participants are EFL/ESP instructors (teachers) from Ukraine, the EU, and the USA, not L2 English learners. The study focuses on teachers’ perceptions and experiences, not learner outcomes.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the study is a survey of instructors’ perceptions about using ChatGPT for teaching and assessment. There is no experimental or quasi-experimental design integrating ChatGPT into actual learner writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing is mentioned as one of several skills (along with vocabulary and grammar) for which ChatGPT can assist in task design and assessment, but the primary focus is broad foreign language teaching and assessment, not specifically writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports survey-based perceptions (confidence, familiarity, satisfaction) of instructors. It does not report any quantifiable learner writing outcome metrics or results from an LLM-mediated writing intervention.""
    }
}"
506,Evaluating Automated Grammar Corrective Feedback Tools: a Comparative Study of Grammarly and Quillbot in Esl Expository Essays,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Malaysian ESL students producing expository essays, clearly indicating L2 English learners in an ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The tools investigated are Grammarly and Quillbot, which are automated grammar feedback applications. The abstract frames this as a comparative analysis of their error detection capabilities, not as an LLM-based pedagogical intervention. Grammarly and Quillbot are not specified as transformer-based generative LLMs in this context, and the study design is tool-comparison rather than an instructional intervention using LLMs.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on how well the tools identify and classify errors in existing writing samples, not on improving learners’ writing competence through an instructional intervention. It is essentially an evaluation of automated writing evaluation tools, not a writing pedagogy study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes or pre/post intervention measures are reported. The metrics are frequencies of errors flagged by the tools, not changes in students’ writing performance following an intervention.""
    }
}"
507,Engage Learn: an Ai-based English Proficiency Improviser,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract describes an English learning and teaching platform but does not specify the learner population (e.g., EFL/ESL/ELL, age, educational context) or confirm that participants are L2 English learners rather than general users.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The system integrates generative models (ChatGPT 3.5 Turbo and Gemini 1.5 Flash) with RAG into an English learning platform that provides targeted feedback on grammar, vocabulary, and fluency, indicating an LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The platform aims to help users write and speak English more effectively, with modules for grammar correction, vocabulary buildup, and feedback on user input. Writing competence and related variables are explicitly part of the focus, alongside speaking.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract only mentions that the paper presents planned evaluation methods and user testing to ensure the system promotes language learning. It does not report any experimental or quasi-experimental results, nor quantifiable writing outcome metrics; it appears to be a system description with prospective evaluation.""
    }
}"
508,Personalized Recommendation Design of English Writing Marking System Based on Corpus,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract discusses college English writing teaching and higher vocational English teaching, implying learners of English in an EFL/ESL context. The population appears to be L2 English learners in tertiary education settings.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on a corpus-based automatic scoring and computer-aided composition marking system. There is no indication that large language models (e.g., ChatGPT, GPT-4) or transformer-based generative models are used; it appears to be a traditional automated scoring/AE system rather than an LLM-mediated intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly English writing instruction and assessment, with emphasis on composition marking and integrating an automatic evaluation system into classroom teaching, which is directly related to writing competence.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract describes a teaching method and system design but does not report any explicit quantitative writing outcome measures or experimental evaluation results. It is unclear whether the study includes measurable writing outcomes.""
    }
}"
509,University Students' Perceptions of Artificial Intelligence-based Tools for English Writing Courses,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Korean university students who have taken English writing courses and are described as English language learners (ELLs), fitting an EFL/ELL L2 English context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates perceptions of AI-based tools (Google Translate, Naver Papago, Grammarly). These are not clearly LLM-based interventions, and there is no experimental or quasi-experimental design integrating an LLM (e.g., ChatGPT, GPT-4) into instruction; it is a perception survey and focus group.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on students’ perceptions of AI-based tools, their strengths/weaknesses, and potential interference with writing processes, not on a structured pedagogical writing intervention or measured changes in writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses mixed methods (survey and interviews) to explore perceptions. There is no indication of quantifiable writing outcome metrics (e.g., writing scores, text quality measures) resulting from an AI-mediated intervention.""
    }
}"
510,Investigating Efl Faculty Members' Perceptions of Integrating Artificial Intelligence Applications to Improve the Research Writing Process: a Case Study at Majmaah University,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are EFL faculty members (teachers), not L2 English learners in ESL/EFL/ELL contexts. The focus is on their own research writing, not on student L2 learning.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “AI applications and tools” without specifying large language models (e.g., ChatGPT, GPT-4). It also does not describe any experimental or quasi-experimental instructional intervention; it investigates perceptions via questionnaires and interviews.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is research writing by EFL educators and their perceptions of AI tools, not a pedagogical intervention targeting L2 writing competence of learners. It is not framed as writing instruction or an L2 writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports attitudes and perceptions, using descriptive and inferential statistics on questionnaire data, but does not report quantifiable writing outcome measures (e.g., changes in writing quality, accuracy, complexity) resulting from an AI-mediated intervention.""
    }
}"
511,The Effects of Generative Ai Usage in Efl Classrooms on the L2 Motivational Self System,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Japanese university students in an EFL writing class, i.e., L2 English learners in an EFL context: “Japanese university students… writing class.”""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention integrates the LLM-based chatbot ChatGPT into an instructor-led writing class: “incorporating the generative pre-trained AI chatbot, ChatGPT, into an instructor-led writing class… treatment group… received feedback from ChatGPT.”""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on motivation (L2 Motivational Self System), not on writing competence or writing-related performance variables: “This study aimed to examine the effect… on the motivation of Japanese university students… examines changes in students’ Ideal L2 Self, Ought-to L2 Self, and L2 Learning Experience.” Writing is the context, but not the main outcome variable.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantitative outcomes reported are motivational constructs (Ideal L2 Self, Ought-to L2 Self, L2 Learning Experience). The abstract does not report any quantifiable writing performance metrics (e.g., scores, quality ratings, accuracy, complexity). References to “enhancing… writing skills” are not accompanied by measured writing outcomes.""
    }
}"
512,Investigating the Impact of Chatgpt as an Ai Tool on Esl Writing : Prospects and Challenges in Saudi Arabian Higher Education,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states the population is ESL students at a Saudi Arabian university, indicating L2 English learners in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study clearly involves ChatGPT as an AI tool in writing, but the abstract does not specify whether there is an experimental or quasi-experimental design (e.g., control group, pre/post intervention) or describe the structured nature of the intervention. It only notes a mixed-methods approach and that data from 130 students showed a positive effect.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on ESL students’ writing proficiency and how ChatGPT is integrated into writing instruction, with discussion of feedback, language skill development, vocabulary, and autonomy. This aligns with writing competence and writing-related variables rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports that data from 130 students showed a significant positive effect on writing, implying quantitative outcomes, but it does not specify what writing measures were used or how proficiency was quantified. It is unclear whether concrete, quantifiable writing outcome metrics were systematically assessed.""
    }
}"
513,Beyond Syntax: Exploring Moroccan Undergraduate Efl Learners' Engagement with Ai-assisted Writing,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Moroccan undergraduate EFL learners in a general English course, clearly indicating L2 English learners in an EFL context: “undergraduate EFL learners… Business Law undergraduates enrolled in a general English course at the International University of Rabat, Morocco.”""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “AI-supported writing tools” and “AI assistance” but does not specify whether these are large language model tools (e.g., ChatGPT, GPT-4) or other AI tools (e.g., grammar checkers). Without explicit mention of LLM-based tools or transformer-based generative models, it is unclear if the intervention meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing: “focusing specifically on writing,” examining “student-written assignments,” and reporting impacts on “language proficiency, creativity, organizational skills, and vocabulary use with AI assistance,” all within the context of AI-supported writing processes.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is described as a quasi-experimental design with a control group and reports “positive outcomes in language proficiency, creativity, organizational skills, and vocabulary use with AI assistance,” implying quantifiable outcome measures to compare groups, even though specific metrics are not detailed in the abstract.""
    }
}"
514,Chatgpt for Language Learning: Assessing Teacher Candidates' Skills and Perceptions Using the Technology Acceptance Model (tam),2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL teacher candidates performing tasks in Spanish (L1) and English (L2), so they are L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT-4 is used only to generate comparison texts. There is no experimental or quasi-experimental instructional intervention where learners use the LLM as part of their writing instruction or process; instead, participants compare and evaluate human vs. machine texts.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on critical skills in distinguishing human vs. machine-generated texts and perceptions of ChatGPT (TAM variables), not on improving writing competence through an LLM-mediated pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although text metrics (SC, ASL, VOCD) are used to compare human and machine texts, they are not reported as learning outcomes of an LLM-based writing intervention. The study does not assess changes in learners’ writing performance due to using ChatGPT.""
    }
}"
515,"Graduate Students' Use of Chatgpt for Academic Text Revision: Behavioral, Cognitive, and Affective Engagement",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as six Iranian graduate ESL students from STEM fields, indicating L2 English learners in an ESL context with a focus on English academic writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is observational/qualitative, examining how students engaged with ChatGPT for revising their own academic research proposals. There is no indication of an experimental or quasi-experimental intervention design (e.g., treatment vs. control, pre/post measures) integrating ChatGPT into instruction; rather, it analyzes existing use and engagement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly L2 academic writing and text revision, focusing on how students use ChatGPT for revising research proposals and paraphrasing to enhance professionalism in writing, which aligns with writing competence and writing-related processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are behavioral, cognitive, and affective engagement (e.g., satisfaction, doubts about accuracy). The abstract does not mention any quantifiable writing outcome metrics (such as scores, rubric-based writing quality measures, or error rates) to assess effectiveness of the ChatGPT-mediated revision.""
    }
}"
516,Understanding Efl Students ' Use of Self-made Ai Chatbots as Personalized Writing Assistance Tools: a Mixed Methods Study,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 69 Chinese undergraduate EFL students, clearly L2 English learners in an EFL context: “English as a foreign language (EFL) students… 69 Chinese undergraduate students.”""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention involves students creating and using self-made RAG chatbots via Poe to assist with their writing processes. RAG chatbots are LLM-based tools, and the study integrates them into writing instruction/workshop activities.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on writing: chatbots assist with idea generation, outlines, and error identification, and students write essays using their chatbots. The workshop is about learning to write and using chatbots as personalized writing assistance tools.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Reported outcomes are motivational and attitudinal: “positive impact on students' writing motivation… clearer writing goals, increased writing confidence, reinforced writing beliefs, and a more positive attitude towards writing.” The abstract does not indicate any quantitative writing performance metrics (e.g., scores, quality ratings, accuracy measures); essays are collected but no measured writing outcomes are reported.""
    }
}"
517,Identifying Chatgpt-generated Texts in Efl Students' Writing: through Comparative Analysis of Linguistic Fingerprints,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Japanese EFL learners (140 first-year university students), clearly fitting an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is present only as a source of comparison texts and as a tool some students used (proofreading or full generation), but there is no described experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or a structured writing process. The design focuses on distinguishability of texts, not an instructional treatment.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on identifying ChatGPT-generated texts via linguistic fingerprints and machine learning classification, not on improving writing competence or evaluating a writing intervention. It is essentially a detection/forensics study, not a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., gains in writing quality, accuracy, complexity) are reported to assess the effectiveness of an LLM-mediated intervention. Outcomes concern distinguishability and classification performance, not learner writing development.""
    }
}"
518,Generative Ai's Recolonization of Efl Classrooms,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is Chinese English as a Foreign Language (EFL) classrooms, clearly involving L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the paper discusses generative AI and AI chatbots producing continuation writing samples, it is a critical/discursive analysis, not an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction. No structured intervention design is described.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on ideological, cultural, and linguistic risks (recolonization, native-speakerism) in AI-generated texts, not on developing or evaluating writing competence through an instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or assessment of learners’ writing performance. It illustrates arguments with AI-generated data and SFL analysis, not learner outcome metrics.""
    }
}"
519,Korean-as-a-foreign-language Learners' Engagement with Machine Translation Output,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are US university students learning Korean as a foreign language. The target language is Korean, not English, and the context is not ESL/EFL/ELL focused on English, so it does not meet the population criterion.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses 'machine translators and other artificial intelligence-assisted programs' and a Guided Use of Machine Translation model. It is not specified whether the machine translator is an LLM-based system (e.g., GPT-based) or a traditional MT system, so its status as an LLM intervention is unclear.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly focuses on how learners use machine translators to revise their writing and analyzes their engagement and revision strategies, indicating a primary focus on writing processes and competence.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses cognitive and behavioral engagement, focus on word choice, and revision strategies, but does not report quantifiable writing outcome metrics (e.g., scores, accuracy rates pre/post). It is unclear whether such quantitative outcomes are measured.""
    }
}"
520,Automatic Scoring of Arabic Essays: a Parameter-efficient Approach for Grammatical Assessment,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on Arabic automated essay scoring using AraBART and evaluates essays in Arabic (datasets QALB-2014, QALB-2015, ZAEBUC). There is no indication that participants are L2 English learners or that the target language is English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although a transformer-based model (AraBART) is used, it is applied for automated essay scoring, not as an instructional or intervention tool integrated into learners’ writing processes. There is no experimental or quasi-experimental pedagogical design involving LLM-mediated writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on developing and validating an automatic scoring system for grammaticality and other criteria in Arabic essays. This is an AES functionality study, not a pedagogical writing intervention aimed at improving learners’ writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are model performance metrics (e.g., scoring accuracy, efficiency) rather than quantifiable changes in learners’ writing performance following an LLM-mediated intervention. No experimental measures of learner writing improvement are described.""
    }
}"
521,Technology-assisted Language Learning Systems: a Systematic Literature Review,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract notes that most reviewed studies target English, but it does not specify that participants are L2 English learners in ESL/EFL/ELL contexts. As a review article, it aggregates multiple populations, some of which may not match the required population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a systematic literature review of technology-assisted language learning in general. It does not itself implement an experimental or quasi-experimental LLM-based intervention (e.g., ChatGPT, GPT-4). It summarizes prior work rather than reporting a primary LLM-integrated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The review covers multiple language skills (vocabulary, writing, grammar, etc.) and technology types broadly. Writing is only one of several skills mentioned and is not the primary focus of a specific intervention; the article is not centered on a concrete writing pedagogy context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a secondary study, it synthesizes empirical evidence from other articles and does not report its own quantifiable writing outcome metrics from an LLM-mediated intervention. It therefore does not meet the requirement for primary experimental measures of writing outcomes.""
    }
}"
522,Automatic Correction Method for English Composition Errors Assisted by Artificial Intelligence,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to students and second language learners in general but does not specify that the participants are L2 English learners in ESL/EFL/ELL contexts, nor does it describe an actual learner sample; it mainly presents a system description and simulation results.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study introduces an AI-assisted deep learning–based automatic correction system for English composition errors. It is framed as an AI/DL system, not explicitly as a large language model (e.g., ChatGPT, GPT-4). The description focuses on preprocessing, feature extraction, and dynamic time normalization, which are characteristic of traditional ML/DL, not transformer-based generative LLMs.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on developing an automatic essay correction and grading system to support teachers’ correction and data analysis. It is essentially an automated scoring/correction tool; there is no described pedagogical writing intervention design or instructional integration beyond general claims of supporting teaching.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The article reports simulation results about system effectiveness in supporting teachers and improving efficiency, but it does not report quantifiable writing outcome metrics for learners (e.g., changes in writing quality, accuracy, or complexity) resulting from an intervention using the system.""
    }
}"
523,Chatgpt over My Friends: Japanese English-as-a-foreign-language Learners' Preferences for Editing and Proofreading Strategies,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 33 Japanese English-as-a-foreign-language learners, clearly an EFL population learning English as L2.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT-3.5 (an LLM) is used, the design is not experimental or quasi-experimental in terms of learning outcomes. The study contrasts experiences and preferences between writing groups and ChatGPT use, focusing on perceptions rather than testing an instructional intervention’s effect on performance.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is academic writing: learners use writing groups and ChatGPT for editing and proofreading academic writing assignments, and the focus is on writing practices and feedback.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are questionnaire-based experiences, preferences, and perceived effectiveness. There is no mention of quantifiable writing performance metrics (e.g., scores, error rates, rubric-based gains) to assess the effectiveness of the LLM-mediated intervention.""
    }
}"
524,Exceptional Talent and Enthusiasm for Math: an Examination of Storylines Circulated by Chatgpt about Mathematical Learners,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are described broadly as different types of mathematical learners, including English language learners, but the focus is not on L2 English learners in ESL/EFL/ELL contexts nor on English as the target language. The context is mathematics learning and identity, not L2 English learning.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used to provide feedback to learners’ mathematical writing, but the study is explicitly described as an exploratory examination of ChatGPT’s feedback and the storylines it circulates. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on narratives and storylines about mathematical learners (race, labels such as gifted/special education/ELL) and how ChatGPT participates in these narratives. Writing competence or writing-related pedagogical outcomes are not the central focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative analysis of ChatGPT’s feedback and the narratives it promotes. There is no mention of quantifiable writing outcome metrics or assessment of the effectiveness of an LLM-mediated writing intervention.""
    }
}"
525,Chatgpt as Artificial Intelligence-based Generative Multimedia for English Writing Pedagogy: Challenges and Opportunities from an Educator's Perspective,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses English language writing pedagogy and teachers’ views on integrating ChatGPT, but it does not specify any concrete participant population (e.g., EFL/ESL/ELL learners) in an empirical study. It is framed as a narrative literature review, not as primary research with defined L2 English learner participants.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly described as a narrative literature review synthesizing existing work, blog posts, and other sources about ChatGPT in English writing pedagogy. It does not report an experimental or quasi-experimental intervention where LLMs are directly integrated into instruction with primary data collection; instead, it summarizes opportunities and challenges from educators’ perspectives.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus is on English language writing pedagogy, the paper is a conceptual/narrative review of ChatGPT’s role, benefits, and challenges. It does not describe a specific pedagogical intervention being implemented and evaluated; rather, it discusses potential uses and implications at a general level.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or experimental results. Findings are thematic (teachers’ views, benefits, challenges) and qualitative in nature, consistent with a narrative literature review. There are no reported metrics of writing performance or other quantifiable writing-related outcomes.""
    }
}"
526,Leveraging Chatgpt for Second Language Writing Feedback and Assessment,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The title and abstract explicitly focus on L2 writing and the use of ChatGPT in L2 writing contexts, implying second language English learners are a primary population of interest.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper is described as reviewing representative studies and explaining sub-topics, not as conducting an experimental or quasi-experimental intervention itself. It is conceptual/review-based rather than an empirical intervention study integrating ChatGPT into instruction with its own data.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is clearly on L2 writing feedback, assessment, and writing processes (e.g., ChatGPT-student collaboration in the L2 writing process, teacher feedback, assessment), which are writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not indicate that the paper reports original, quantifiable writing outcome metrics. It reviews literature and discusses projects and potential uses, but no experimental measures or structured outcome data are mentioned.""
    }
}"
527,Whether English Proficiency and English Self-efficacy Influence the Credibility of Chatgpt-generated English Content of Emi Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are college students in English-medium instruction (EMI) courses and non-English majors, which likely implies L2 English learners, but the abstract does not explicitly state that they are ESL/EFL/ELL or L2 English learners. The focus is on EMI rather than clearly defined L2 status.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is present, but the study is observational/survey-based. Instructors encouraged use of ChatGPT for discovery learning; there is no experimental or quasi-experimental design testing a structured LLM-based writing intervention. The study examines factors influencing perceived credibility of ChatGPT-generated content, not an intervention effect.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The course is titled “Technical Writing and Presentation,” but the measured construct is the credibility of ChatGPT-generated English content (CCGEC), not writing competence or writing-related performance variables. The focus is on credibility judgments in EMI tasks, not on writing development or instruction outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are survey-based measures of perceived credibility (CCGEC) and relationships with English proficiency and self-efficacy. No quantifiable writing performance metrics (e.g., writing quality scores, accuracy, complexity) are reported to assess the effectiveness of an LLM-mediated writing intervention.""
    }
}"
528,Investigating the Impact of Chatgpt as an Ai Tool on Esl Writing: Prospects and Challenges in Saudi Arabian Higher Education,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as ESL students at a Saudi Arabian university, indicating L2 English learners in an EFL/ESL context with focus on English writing proficiency.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that the study explores the impact of ChatGPT on ESL students' writing proficiency and discusses integration into writing instruction, but it does not specify whether there was an experimental or quasi-experimental intervention design (e.g., treatment vs. control, pre/post with structured ChatGPT use) versus a more general correlational or exploratory use.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on ESL writing proficiency and writing instruction. Reported opportunities (personalized feedback, vocabulary expansion, autonomy) and challenges (loss of individuality, reduced creativity) are all framed around writing and its development.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions a ‘significant positive effect on their writing’ based on data from 130 students, suggesting quantitative outcomes, but it does not specify the nature of the writing measures (e.g., rubric scores, test scores) or whether these are structured, quantifiable writing outcome metrics derived from an intervention using ChatGPT.""
    }
}"
529,Generative Ai's Recolonization of Efl Classrooms: the Case of Continuation Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is Chinese English as a Foreign Language (EFL) classrooms and continuation writing in China's EFL assessment, clearly involving L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the paper discusses using generative AI and AI chatbots to provide sample writings, it is a critical/discursive analysis. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction; instead, it problematizes potential recolonization and analyzes AI-generated texts.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on ideological, cultural, and linguistic risks (recolonization, native-speakerism) in AI-generated continuation writing samples, not on improving writing competence or evaluating a writing intervention. It is a critical examination of language patterns, not a teaching experiment.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantifiable writing outcome metrics or measured effects on learners’ writing. It illustrates arguments with AI-generated data and SFL analysis, but there is no structured intervention with pre/post or comparative writing scores.""
    }
}"
530,Generative Ai as a Collaborative Companion: Enhancing Peer Feedback in Efl Writing Classes,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly EFL writing classes, so participants are English as a Foreign Language learners, i.e., L2 English learners.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “Generative Artificial Intelligence (GAI)” as a collaborative companion in peer feedback, but does not specify that it is an LLM (e.g., ChatGPT/GPT-4) or detail any concrete experimental or quasi-experimental intervention; it mainly proposes a framework and implementation steps.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL writing classes, peer feedback, and improving overall writing ability, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes an exploratory, conceptual framework and discusses advantages and implications. It does not mention any experimental or quasi-experimental design, nor any reported quantitative writing outcome metrics; it focuses on understanding and proposing an approach rather than measuring effects.""
    }
}"
531,A Lesson Study on a Mooc-based and Ai-powered Flipped Teaching and Assessment of Efl Writing Model: Teachers' and Students' Growth,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are clearly described as college EFL (English as a Foreign Language) teachers and their students, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is described as a MOOC-based and AI-powered flipped teaching and assessment model (MAFTA), but the abstract does not specify that the AI component is a large language model (e.g., ChatGPT, GPT-4). It only mentions ‘technology tools’ and ‘multiple technological affordances’ without identifying transformer-based generative models. Thus, it cannot be confirmed that LLMs are used.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL writing instruction and assessment, examining teachers’ TPACK in teaching EFL writing and students’ argumentative essays, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports ‘substantial improvements’ in students’ essays before and after MAFTA instruction, implying quantifiable writing outcome metrics (pre/post argumentative essays) were analyzed to assess effectiveness.""
    }
}"
532,"Enhancing Efl Reading and Writing through Ai-powered Tools: Design, Implementation, and Evaluation of an Online Course",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 43 senior high school students in Taiwan enrolled in an English course, explicitly described as EFL learners. The focus is on English reading and writing, fitting ESL/EFL/ELL L2 English contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses three AI-powered tools: Linggle Write, Linggle Read, and Linggle Search. These are corpus/AI-assisted tools, not identified as large language models (e.g., ChatGPT, GPT-4). The abstract does not indicate transformer-based generative LLMs; thus it does not meet the LLM-specific intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The course explicitly targets EFL reading and writing, and the tools are used to support learning to read and write. The primary pedagogical focus is on literacy skills, including writing competence within an online course context.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study reports that language proficiency predicted semester grade and assignment quantity, and mentions quantitative data, but the abstract does not clearly state that specific writing performance metrics (e.g., writing scores, quality measures) were used to evaluate the AI-mediated writing intervention. It is unclear whether quantifiable writing outcomes were directly assessed.""
    }
}"
533,Chatgpt Vs Teacher Roles in Developing Efl Writing,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 50 English-language learners at a public university in an EFL context (“developing English as a Foreign Language writing”). The focus is clearly on learners of English as an L2.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention explicitly uses ChatGPT (a large language model) to provide revisions on students’ writing, and compares this with teacher instruction. This is an experimental comparison of LLM-mediated writing support versus teacher feedback.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on developing EFL writing and comparing ChatGPT’s role with teacher roles in writing instruction. The study is pedagogical, not an automated scoring or purely technical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study quantitatively examines learners’ writing performance before and after ChatGPT revisions and before and after teacher instruction, using TOEFL iBT criteria and reporting score differences and improvement, which are clear quantifiable writing outcomes.""
    }
}"
534,Recursive Editing with Google Translate: the Impact on Writing and Error Correction,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL university sophomores, clearly indicating L2 English learners in an EFL context. The study focuses on English writing performance (error correction test and essay writing).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Google Translate as a machine translation (MT) tool. The abstract does not indicate that a large language model (e.g., ChatGPT, GPT-4, Gemini) or transformer-based generative model is being used for writing instruction; it is standard MT, which falls outside the LLM-focused inclusion criteria.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence and related variables: error correction, overall writing scores, and sub-dimensions of writing (fluency, complexity, accuracy). The intervention is pedagogical, integrating MT into the writing process via recursive editing.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: performance on an error correction test, writing scores, and specific measures of fluency (sentence, clause, T-unit counts, word count), syntactic complexity (mean length of clause), and accuracy. These allow assessment of intervention effectiveness.""
    }
}"
535,"The Effectiveness of Chatgpt as a Lexical Tool for English, Compared with a Bilingual Dictionary and a Monolingual Learner's Dictionary",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 166 university students working with uncommon English phrasal verbs as English language learners, indicating an L2 English learner population in an EFL/ESL-type context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used as a lexical tool and compared with dictionaries for receptive and productive lexical tasks. There is no indication of an experimental or quasi-experimental *writing instruction* intervention; rather, it is a tool-comparison study focused on vocabulary support.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on receptive and productive lexical tasks involving phrasal verbs, not on broader writing competence or writing-related pedagogy. It is essentially a lexical support comparison, not a writing-focused instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes concern accuracy in understanding and producing phrasal verbs, not quantifiable measures of writing performance or writing development. No structured LLM-mediated writing intervention outcomes are reported.""
    }
}"
536,Assessing Human Evaluations of Cover Letters Written or Edited by Al and Non-native English Speakers,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Non-native English speakers are mentioned, but they are not participants in an instructional or learning context; instead, native English speakers evaluate texts. There is no indication that NNES are L2 learners in ESL/EFL/ELL educational settings, nor that learner data are collected.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""AI is used to write or edit cover letters, but there is no experimental or quasi-experimental pedagogical intervention integrating an LLM into writing instruction or a learning process. The study is a survey-embedded experiment on human evaluations of texts, not an LLM-mediated teaching/learning intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on perceived hireability and writing quality of different author types (NNES vs AI), not on improving learners’ writing competence through instruction. It evaluates AI’s impact on perceptions of cover letters rather than a writing intervention context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing quality is rated, these are evaluations of pre-produced texts, not outcomes of an LLM-mediated instructional intervention with learners. No structured teaching/learning process or pre/post writing outcome measures for L2 learners are reported.""
    }
}"
537,Students' Perceptions of the Impact of Ai Chatbots on Vocabulary and Grammar in Efl Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 100 undergraduate EFL students from universities in Indonesia, clearly identifying them as L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students use various AI chatbots (including LLM-based tools like ChatGPT, Gemini, Perplexity, Bing Chat), the study is observational and perception-based. There is no experimental or quasi-experimental design integrating LLMs into a structured writing intervention; it simply surveys existing usage and perceptions.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on perceived impact of AI chatbots on vocabulary and grammar in EFL writing, which is writing-related. However, there is no explicit pedagogical writing intervention; the context is general use of chatbots in students’ digital activities rather than a designed instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are self-reported perceptions of improvement (e.g., students ‘reported substantial improvements’). There is no indication of objective, quantifiable writing performance measures (e.g., pre/post tests, rubric-based writing scores) derived from an intervention, only descriptive survey data on perceptions.""
    }
}"
538,Avery: a Genai-based Approach to Enhancing Learner Engagement in English Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to 'English Language learners' but does not specify whether they are L2 English learners in ESL/EFL/ELL contexts or, for example, native speakers in school settings. The L2 status and context are not clearly stated.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The system is described as a 'GenAI-based' image-text-image game, but the abstract does not specify that it uses a large language model (e.g., ChatGPT, GPT-4) as the core engine for text generation or feedback. It could be any generative AI, including image models, so LLM use is not clearly established.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on a gamified learning experience and enhancing learner engagement. While the game involves English sentence production and feedback, the study’s reported outcomes center on engagement and affect, not on writing competence or writing-related performance variables as the main focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports that 12 respondents played the game and completed a questionnaire, with results showing positive affect and engagement. There is no mention of quantifiable writing outcome metrics (e.g., writing scores, accuracy, complexity) to assess the effectiveness of the intervention on writing performance.""
    }
}"
539,Co-creating Stories with Generative Ai: Reflections from Undergraduate Students of a Storytelling Service-learning Subject in Hong Kong,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are undergraduate students in Hong Kong taking a language-related service-learning subject and are described as ESL learners, so they are L2 English learners in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses publicly available Generative AI tools to help students co-create digital stories, but the abstract does not specify whether these are large language models (e.g., ChatGPT/GPT-based) or other generative tools (e.g., image/audio). It is therefore unclear if LLMs specifically are integrated into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on co-creating written digital stories in English and how GenAI supports creative text production, linguistic awareness, and ownership of English, which aligns with writing-related competence and processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is based on qualitative content analysis of semi-structured interviews and reports perceived expansion of creative potential and awareness. There is no mention of experimental or quasi-experimental design, nor of quantifiable writing outcome metrics assessing the effectiveness of the GenAI-mediated writing intervention.""
    }
}"
540,"Using Artificial Intelligence to Foster Students' Writing Feedback Literacy, Engagement, and Outcome: a Case of Wordtune Application",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states the context is second language (L2) learning and refers to L2 writing skills development. The 46 students at upper-intermediate level are L2 learners, and the focus is on L2 writing outcomes.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Wordtune, described only as an AI-based application. Wordtune is primarily a rewriting/paraphrasing tool and is not clearly identified as an LLM-based, transformer generative model in the abstract. Given the review’s strict requirement for explicit LLM integration (e.g., ChatGPT, GPT-4, Gemini) and the lack of evidence that Wordtune is an LLM-based pedagogical writing intervention, this does not meet C2.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on L2 writing competence and related variables: writing outcomes, engagement, and writing feedback literacy. It is not about automated essay scoring or system evaluation; rather, it is a pedagogical intervention using AI in writing instruction.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that the experimental group using Wordtune ‘significantly improve[d] their writing outcomes, engagement, and feedback literacy when compared to the control group,’ indicating quantifiable outcome measures in a mixed-method, experimental design.""
    }
}"
541,The Impact of Chatgpt on Learners in English Academic Writing: Opportunities and Challenges in Education,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on EFL learners and their use of ChatGPT for academic English writing, which fits the L2 English learner population in EFL/ESL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the study is exploratory and descriptive, using interviews about learners’ self-initiated use. There is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction or a structured writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on English academic writing, including how ChatGPT affects writing fluency, content, and knowledge, and on challenges and opportunities in using ChatGPT as an academic English writing tool.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses semi-structured and open-ended interviews with thematic analysis, yielding qualitative findings about reasons for use, perceived effects, and challenges. No quantifiable writing outcome metrics or experimental measures of writing performance are reported.""
    }
}"
542,"A Scholarly Dialogue: Writing Scholarship, Authorship, Academic Integrity and the Challenges of Ai",2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract discusses higher education in general and writing scholars’ perspectives on AI. It does not specify any participant group of L2 English learners in ESL/EFL/ELL contexts, nor does it focus on data related to English language learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a conceptual/dialogical piece about AI in higher education. It does not describe an experimental or quasi-experimental design, nor an implemented LLM-based writing intervention (e.g., using ChatGPT in instruction).""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""While it is situated within writing studies, the focus is on theoretical and ethical issues (academic integrity, authorship, assessment) and the role of writing scholars, not on a specific pedagogical intervention targeting writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or empirical evaluation of an LLM-mediated writing intervention are mentioned. The article appears to be a scholarly dialogue/opinion piece rather than an empirical study with measured outcomes.""
    }
}"
543,Artificial Intelligence Pedagogical Chatbots as L2 Conversational Agents,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL undergraduate students at a Saudi university, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses a ‘text-based pedagogical chatbot’ as a conversational agent, but the abstract does not specify that it is an LLM (e.g., ChatGPT/GPT-based) rather than a rule-based or other non-LLM chatbot. Thus it is unclear whether an LLM is integrated.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on students’ experiences, perceptions, and affective/cognitive domains in relation to chatbot-mediated interaction. While writing development and anxiety are mentioned, the study is framed around perceptions of the chatbot’s affordances and limitations, not a structured writing instruction intervention or writing process support as the primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports questionnaire and focus group data about perceptions and experiences. No quantifiable writing performance outcomes (e.g., writing scores, text quality measures, pre/post tests) are mentioned; only attitudes and perceived usefulness are analyzed (e.g., via Mann-Whitney U on perceptions).""
    }
}"
544,Artificial Intelligence in Writing Courses: Attitudes of University Instructors in Lebanon,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The participants are Lebanese university writing instructors, not L2 English learners. The study focuses on instructors’ attitudes, not on learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study explores attitudes toward AI (including generative AI like ChatGPT) but does not describe an experimental or quasi-experimental intervention integrating LLMs into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on instructors’ attitudes toward AI use in writing courses and grading, not on a pedagogical intervention targeting writing competence or writing-related performance variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes are reported. The study reports survey-based attitudinal data from instructors rather than experimental measures of writing performance following an LLM-mediated intervention.""
    }
}"
545,Understanding Chinese University Efl Learners' Perceptions of Ai in English Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 140 Chinese university EFL learners in a Chinese university setting, clearly an EFL context focused on English writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates perceptions of Grammarly, which is an AI-assisted writing tool but not an LLM-based generative model like ChatGPT or GPT-4. There is no indication that a large language model is integrated into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly English writing, examining learners’ perceptions of AI (Grammarly) in English writing and providing suggestions for AI writing support.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is based on an extended TAM and uses structural equation modeling to explain perceptions and intentions to use AI. It does not report quantifiable writing outcome metrics (e.g., writing quality scores, accuracy, complexity) but focuses on attitudes and behavioral intention.""
    }
}"
546,Revolutionizing Efl Writing: Unveiling the Strategic Use of Chatgpt by Indonesian Master's Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are postgraduate EFL students (Indonesian Master's students), clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a qualitative case study exploring students’ experiences and strategies in using ChatGPT. There is no indication of an experimental or quasi-experimental intervention design; ChatGPT use is described, not systematically implemented or tested as an instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL students’ use of ChatGPT in their writing process (vocabulary, grammar, idea generation, essay structuring, language refinement), which is directly related to writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study relies on self-reported experiences and perceptions. The abstract does not mention any quantitative or experimental writing outcome measures; it is purely qualitative, so no quantifiable writing outcomes are reported.""
    }
}"
547,Assessing Interactional Metadiscourse in Efl Writing through Intelligent Data-driven Learning: the Microsoft Copilot in the Spotlight,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'English as a foreign language (EFL) learners' and 'advanced language learners', clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The hands-on group used 'Microsoft Copilot, artificial intelligence (AI) chatbot' during a 10-session treatment. Copilot is an LLM-based chatbot integrated into the instructional design, satisfying the LLM intervention requirement.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary measured outcome is 'realizing and identifying interactional metadiscourse markers (IMMs)' and perceptions of DDL. While the authors claim this may help 'develop their writing performance', the intervention and assessment focus on recognition/identification of IMMs rather than actual writing competence or writing-related performance measures.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantitative outcomes reported are ANCOVA results on 'realizing and identifying IMMs' and questionnaire perceptions. There is no indication of quantifiable writing outcome metrics (e.g., writing quality scores, text production measures); the outcomes are metadiscourse identification and attitudes, not measured changes in written output.""
    }
}"
548,A Multi-strategy Computer-assisted Efl Writing Learning System with Deep Learning Incorporated and Its Effects on Learning: a Writing Feedback Perspective,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly refers to EFL students and EFL writing learning, indicating participants are English as a Foreign Language learners and the target language is English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is a computer-assisted EFL writing system (MsCAEWL) using neural network models and semantic-based NLP techniques, positioned as an AWE/AES-type system. There is no indication that it is based on large language models (e.g., transformer-based generative models like ChatGPT/GPT-4). It appears to be an automated evaluation/feedback engine rather than an LLM-based tool.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on developing and validating an automated writing evaluation/feedback system and comparing it with AWE baselines and human raters. Although writing proficiency is measured, the emphasis is on system performance and feedback theory rather than an LLM-mediated pedagogical writing intervention. It aligns more with AWE/AES functionality studies, which are to be excluded.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative outcomes (independent- and paired-sample t-tests) showing significant impact on students’ EFL writing proficiency, indicating measurable writing outcome metrics are provided.""
    }
}"
549,Understanding Efl Students' Chatbot-assisted Argumentative Writing: an Activity Theory Perspective,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are five Chinese undergraduate EFL students composing argumentative essays in English, clearly fitting an EFL/ESL L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses a chatbot named Argumate to assist argumentative writing. However, the abstract does not specify whether Argumate is an LLM-based (transformer generative) system like ChatGPT or a rule-based/chatbot of another type. Thus it is unclear if it meets the LLM requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on chatbot-assisted argumentative writing, examining how students engage with the chatbot while composing essays and discussing implications for writing pedagogy. The primary context is writing competence and writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as qualitative, using activity theory to analyze screen recordings, chat logs, essays, and questionnaire responses. The abstract reports process-oriented findings about interaction and scaffolding but does not mention any experimental or quasi-experimental design or quantifiable writing outcome metrics to assess effectiveness of the chatbot intervention.""
    }
}"
550,A Systematic Review of Grammarly in L2 English Writing Contexts,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states that the review focuses on Grammarly research involving L2 learners in L2 English writing contexts, so the population criterion is met.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention examined is Grammarly, an automated writing evaluation (AWE) system that is not based on large language models as defined in the review criteria. The article is also a systematic review, not an experimental or quasi-experimental primary study integrating LLMs.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is clearly on L2 English writing, discussing Grammarly’s instructional design and its support for L2 English writing, which aligns with a writing competence context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic review, this article synthesizes prior studies and does not itself report original experimental or quasi-experimental outcome data on an LLM-mediated writing intervention. It also centers on Grammarly, which is excluded by the criteria.""
    }
}"
551,Chatgpt in English Writing: Experiences and Perceptions of Saudi Efl Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Saudi English as a Foreign Language (EFL) students, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states that students used ChatGPT for language writing tasks, but it does not specify an experimental or quasi-experimental instructional intervention; it appears to be exploratory/qualitative rather than a structured pedagogical treatment.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on using ChatGPT for English writing tasks, including content structuring and feedback, which are writing-related processes rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is based on semi-structured interviews about experiences and perceptions. No quantitative writing outcome measures or experimental effectiveness data are reported.""
    }
}"
552,An Application of Many-facet Rasch Measurement to Evaluate Automated Essay Scoring: a Case of Chatgpt-4.0,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses essays from the International Corpus Network of Asian Learners of English (ICNALE), explicitly described as being written by English language learners in Asian regions, i.e., L2 English learners in EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT-4.0 is used solely as an automated essay scoring (AES) tool to assign scores to existing essays. There is no experimental or quasi-experimental pedagogical intervention integrating the LLM into writing instruction or writing processes for learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on evaluating ChatGPT-4.0’s performance as an AES system (severity, consistency, correlation with human raters) using many-facet Rasch measurement. There is no instructional context or intervention aimed at improving writing competence; it is an assessment-functionality study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports correlations and measurement properties of ChatGPT-4.0’s scores versus human raters, but does not implement or evaluate an LLM-mediated writing intervention, nor does it report pre/post or comparative writing outcome metrics resulting from such an intervention.""
    }
}"
553,Strategic Use of Machine Translation,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are CEFR A2 university students engaged in L2 writing, but the abstract does not specify that the target language is English; it refers only to ‘foreign languages (L2)’ and ‘L2 writing’ in general. Thus, it is unclear whether they are L2 English learners, as required.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention involves machine translation (MT) and strategy instruction for MT use. The abstract does not indicate that the MT system is an LLM-based, transformer generative model (e.g., ChatGPT, GPT-4). It is framed as generic MT use, which falls outside the specified LLM-focused scope.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on L2 writing with MT, examining learners’ strategies in the writing process and how these change after strategy instruction. The primary context is clearly writing-related (L2 writing process and strategy use).""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a qualitative case study exploring strategy use and changes in strategies. The abstract reports increased and more elaborate strategy use but does not mention any quantifiable writing outcome metrics (e.g., writing quality scores, accuracy, complexity). Outcomes are process- and strategy-focused, not quantitative writing performance measures.""
    }
}"
554,Tapping into the Pedagogical Potential of Infinigochatic: Evidence from Iwrite Scoring and Comments and Lu & Ai's Linguistic Complexity Analyzer,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are postgraduate students taking an English reading and writing course in Southwest China, clearly an EFL/L2 English context: “L2 English writing… postgraduate students learning an English reading and writing course in a prestigious university in Southwest China.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although infinigoChatIC is described as a Chinese version of ChatGPT, the design is not an experimental or quasi-experimental pedagogical intervention. The teacher simply polishes existing texts in the LLM with a single prompt; learners do not interact with the tool as part of instruction, and there is no comparison of learner outcomes across conditions. This is more a text-transformation/comparison study than an instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on how LLM-polished texts compare to original learner texts in terms of quality and complexity, using iWrite scoring and a complexity analyzer. There is no structured teaching activity or writing process intervention involving learners; it functions similarly to an automated enhancement/assessment study rather than a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are text-level comparisons (scores from iWrite and linguistic complexity indices) between original and LLM-polished versions of the same assignments. There is no measurement of changes in learners’ own writing performance over time or across conditions, so no quantifiable learner writing outcome attributable to an LLM-mediated intervention is reported.""
    }
}"
555,Distributed Agency in Second Language Learning and Teaching through Generative Ai,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses second language learning and teaching in general and mentions learners and teachers, but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor any specific target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although generative AI tools like ChatGPT are mentioned, the article appears to be conceptual/theoretical, discussing opportunities, affordances, limitations, ethics, and ecological theories. There is no indication of an experimental or quasi-experimental design or a concrete instructional intervention being implemented and studied.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing is mentioned as one modality (chats in written or voice formats), but the focus is broad language learning, immersive technologies, and distributed agency. The primary focus does not appear to be on writing competence or writing-related variables in a pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report or allude to any quantitative writing outcome measures or structured intervention outcomes. It is a conceptual discussion of generative AI, agency, and theoretical perspectives rather than an empirical study with measurable writing results.""
    }
}"
556,Effects of Learner Uptake Following Automatic Corrective Recast from Artificial Intelligence Chatbots on the Learning of English Caused-motion Construction,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 69 novice-level EFL learners in a Korean high school, clearly indicating L2 English learners in an EFL context with a focus on English caused-motion construction.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses “artificial intelligence (AI) chatbots” providing automatic corrective recasts, but the abstract does not specify whether these chatbots are based on large language models (e.g., transformer-based generative models) or on earlier rule-based/statistical systems. Without this detail, it is unclear if the intervention qualifies as an LLM-based integration.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary outcome is performance on elicited writing tasks (EWT) targeting the English caused-motion construction, and the intervention is corrective recast during interaction with AI chatbots. This directly concerns writing production and writing-related grammatical competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports statistically significant gains in immediate and delayed posttests on elicited writing tasks, and correlates learner uptake with learning gains. These are quantifiable writing outcome measures assessing the effectiveness of the AI-mediated intervention.""
    }
}"
557,The Impact of Chatgpt on L2 Writing and Expected Responses: Voice from Doctoral Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described only as 'doctoral students' engaged in L2 writing; it is not explicitly stated that they are L2 English learners in ESL/EFL/ELL contexts, nor that the target language is English specifically.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is qualitative, using reflection papers and focus group interviews to explore students’ views on ChatGPT. There is no indication of an experimental or quasi-experimental design integrating ChatGPT as a structured instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on the impact of ChatGPT on L2 writing, including its role at pre-, during-, and post-writing stages and as a self-learning tool for writing and thinking development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as qualitative and based on thematic analysis of reflections and interviews. No quantifiable writing outcome metrics or experimental measures of writing performance are reported.""
    }
}"
558,Impact of Chatgpt on Esl Students' Academic Writing Skills: a Mixed Methods Intervention Study,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 'undergraduate ESL students' and 'tertiary level ESL students', indicating L2 English learners in an ESL context with a focus on English academic writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines 'the impact of ChatGPT as a formative feedback tool on the writing skills of undergraduate ESL students.' ChatGPT is a large language model, and the design is an 'intervention study' using ChatGPT within writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on 'students' academic writing skills' and the use of ChatGPT as a feedback tool in writing classes. The context is clearly writing instruction rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses 'three tests' and reports 'a significant positive impact of ChatGPT on students' academic writing skills,' indicating quantifiable writing outcome measures in an experimental/quasi-experimental framework.""
    }
}"
559,The Impact of Chatgpt Feedback on the Development of Efl Students' Writing Skills,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 110 university students learning English as a Foreign Language (EFL). The context is explicitly foreign language education with English as the target language, fitting ESL/EFL/ELL L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT feedback as the core intervention in a quasi-experimental design. ChatGPT is a large language model integrated into the writing process as an instructional tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing skills and writing proficiency. The abstract details improvements in conciseness, grammar, inclusion of key information, and use of passive voice, all directly related to writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study employs pre-tests and post-tests to evaluate the impact of ChatGPT feedback on writing proficiency and reports significant quantitative improvements in specific writing aspects, providing measurable writing outcomes.""
    }
}"
560,Genre-based Writing in the German Classroom in the Age of Generative Ai,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are learners of German in an intermediate, fifth-semester German class. The target language is German, not English, and the context is not ESL/EFL/ELL focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The case study investigates genre-based instruction in a German class. ChatGPT and generative AI are only discussed conceptually in the final section as potential tools; there is no experimental or quasi-experimental integration of an LLM into the actual intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on genre-based L2 writing pedagogy and its effects on student writing, clearly centered on writing competence and writing instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantifiable writing outcomes are reported for genre-based instruction (pre/post film reviews), but no outcomes are reported for any LLM-mediated intervention. LLM use is only proposed, not implemented or measured.""
    }
}"
561,"Learner Interaction With, and Response To, Ai-programmed Automated Writing Evaluation Feedback in Efl Writing: an Exploratory Study",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are five Chinese university-level English as a foreign language (EFL) students, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Pigai, described as an AI-programmed automated writing evaluation (AWE) system. Pigai is a traditional AWE tool, not identified as a large language model (e.g., ChatGPT, GPT-4, Gemini). The study focuses on interaction with AWE feedback, not an LLM-based generative system.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing and student interaction with automated writing evaluation feedback, which is directly related to writing processes and writing pedagogy.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as an exploratory analysis of how students interact with Pigai feedback and their response patterns. The abstract does not report quantifiable writing outcome metrics (e.g., pre/post writing scores, quality ratings); it focuses on interaction patterns and take-up rates of feedback types, not on measured changes in writing competence.""
    }
}"
562,Efl Teachers' Perceptions of the Use of an Ai Grading Tool (cograder) in English Writing Assessment at Saudi Universities: an Activity Theory Perspective,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are EFL teachers (n=10) at Saudi universities, not L2 English learners. The focus is on teachers’ beliefs, not learner outcomes.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines perceptions of an AI grading tool (CoGrader) for essay scoring and feedback. There is no indication that it is an LLM-based tool (e.g., ChatGPT/GPT-4) or that it is integrated as an instructional writing intervention in an experimental/quasi-experimental design.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on assessment (AI grading) and teachers’ beliefs, not on a pedagogical writing intervention aimed at improving learners’ writing competence. It evaluates CoGrader as a scoring/feedback tool rather than as part of a structured instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes are reported. The study uses questionnaires and interviews about teacher perceptions; there is no experimental measure of changes in students’ writing performance due to an LLM-mediated intervention.""
    }
}"
563,Indonesian University Students' Perspectives on Integrating Aied into English Language Learning,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Indonesian university students using AIEd for English language learning, which fits an EFL/ELL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a quantitative survey of perceptions of AIEd tools. It does not describe an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes, nor does it specify that the listed tools are LLM-based.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing-related features (translation, grammar checkers, paraphrasers, idea generators, citation management) are mentioned in the questionnaire, the study’s primary focus is on general perceptions of AIEd in English learning, not on a writing-focused pedagogical intervention or writing competence outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are perception indices (e.g., positive/negative perceptions) based on TAM constructs. No quantifiable writing performance or writing-related competence measures are reported to assess effectiveness of an LLM-mediated writing intervention.""
    }
}"
564,"Chatgpt Is Powerful, but Does It Have Power Distance? a Study of Culturally Imbued Discourse in Ai-generated Essays",2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares 200 essays written by ChatGPT with 200 essays written by L1-English university learners. There is no mention of L2 English learners, ESL/EFL/ELL contexts, or second language writers; the human comparison group is explicitly L1-English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used to generate essays for comparison with human texts, but there is no experimental or quasi-experimental pedagogical intervention integrating ChatGPT into writing instruction or learners’ writing processes. It is a corpus/comparative study of discourse features, not an instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on culturally imbued discourse (power distance) in AI-generated versus human essays, examining formulaic language (stances, modals, pronoun deixis). It does not study writing competence development or a teaching/learning context; rather, it evaluates linguistic characteristics of outputs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although quantitative analyses (Wilcoxon tests) are reported, they concern linguistic feature frequencies in ChatGPT vs. L1 essays, not writing outcomes of an LLM-mediated intervention for learners. No learner performance or improvement metrics are provided.""
    }
}"
565,Investigating the Accuracy of Chatgpt as a Writing Error Correction Tool,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions ESL learners in a general sense but does not clearly state that actual L2 English learners participated as subjects; it instead refers to pre-created data sets. It is unclear whether the data are authentic learner texts or constructed examples, and whether any learner participants are involved.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, the study is framed as an evaluation of ChatGPT’s accuracy as an error correction tool using pre-created data sets and computational processing. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating ChatGPT into writing instruction or learners’ writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on ChatGPT’s error detection and correction performance across error categories, not on developing or assessing learners’ writing competence through an instructional context. This is a tool-functionality evaluation rather than a writing intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are accuracy levels of ChatGPT across error categories (high, moderate, low), not quantifiable changes in learners’ writing performance following an LLM-mediated intervention. No experimental measures of learner writing outcomes are described.""
    }
}"
566,Enhancing L2 Writing Skills: Chatgpt as an Automated Feedback Tool,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Turkish pre-service teachers of English in an academic writing course, clearly functioning as L2 English learners in an EFL/ESL higher education context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly investigates ChatGPT, an AI-powered large language model, used as an automated feedback tool for L2 writing in an academic writing course. This constitutes an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is L2 academic writing, focusing on ChatGPT as a feedback tool to support the L2 writing process. The primary emphasis is on writing and writing-related support, not on assessment-only or non-pedagogical use.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The methodology describes focus-group interviews and thematic analysis of perceptions regarding ChatGPT feedback. The abstract reports only qualitative findings about affordances and constraints, with no mention of quantitative or experimental writing outcome measures (e.g., changes in writing scores, accuracy, complexity).""
    }
}"
567,The Differential Role of Ai-operated Wcf in L2 Students' Noticing of Errors and Its Impact on Writing Scores,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 75 university undergraduate EFL students, clearly indicating L2 English learners in an EFL context. Writing tasks were IELTS Task 2 argumentative prompts, which are English writing tasks.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The AI tools used are Grammarly and E-rater. These are automated writing evaluation/correction systems and are not described as large language models or transformer-based generative models (e.g., ChatGPT, GPT-4). The intervention is AI-operated WCF but not LLM-based.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on written corrective feedback during and after writing, using argumentative IELTS prompts, and examines its impact on writing scores and noticing of errors. The primary context is writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly mentions investigating the impact of feedback modes and timing on writing scores, implying quantifiable writing outcome measures in a quasi-experimental design with four feedback conditions.""
    }
}"
568,"Which One? Ai-assisted Language Assessment or Paper Format: an Exploration of the Impacts on Foreign Language Anxiety, Learning Attitudes, Motivation, and Writing Performance",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 70 intermediate English learners at Bangladeshi universities, clearly an EFL/ESL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is described only as 'AI-assisted language assessment.' No indication is given that the AI is a large language model (e.g., ChatGPT, GPT-4) or that it involves transformer-based generative text. It appears to be an assessment tool rather than an LLM-based writing assistant.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing skills are a primary outcome, measured via the TOEFL iBT writing section, and the study compares AI-assisted versus paper-format assessment in relation to writing performance and affective variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports pretest and posttest writing abilities using TOEFL iBT writing scores, providing quantifiable writing outcome metrics, even though posttest differences were not statistically significant.""
    }
}"
569,Examining Ai-based Accuracy Assessment in L2 Learners' Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract refers to 'L2 learners' writing' and 'EFL learners', indicating a population of English L2 learners in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used solely as an evaluator of writing accuracy, compared to human raters. There is no experimental or quasi-experimental instructional intervention integrating the LLM into the writing process or teaching; it is a rater-functionality study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the performance of ChatGPT as an accuracy assessor (automated scoring/feedback function) and its correlation with human ratings, not on a pedagogical writing intervention or instruction aimed at improving writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports correlations between ChatGPT and human ratings but does not implement an LLM-mediated writing intervention or measure pre/post changes in learners’ writing outcomes as a result of such an intervention.""
    }
}"
570,Strategic Use of Machine Translation: a Case Study of Japanese Efl University Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Japanese EFL university students at CEFR A2 level, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention focuses on the use of machine translation (MT) in L2 writing. The abstract does not indicate that the MT system is an LLM-based generative model (e.g., ChatGPT, GPT-4). It is framed as generic MT use, not as an LLM-integrated writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly examines L2 writing with MT, focusing on learners’ strategies and engagement in the L2 writing process, which is a writing-related context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as a qualitative case study exploring strategy use and changes after instruction. Outcomes reported are increases in strategy use and cognitive engagement, not quantifiable writing performance metrics (e.g., scores, accuracy, complexity).""
    }
}"
571,Incorporating Ai in Foreign Language Education: an Investigation into Chatgpt's Effect on Foreign Language Learners,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as ‘preparatory class students studying at the School of Foreign Languages at a university in Turkey.’ The target language is not explicitly stated as English in the title or abstract; it is only referred to as ‘foreign language education,’ so it is unclear whether they are L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study ‘aimed to utilize ChatGPT in foreign language education’ and students were ‘introduced to ChatGPT through learning experiences over a span of four weeks.’ ChatGPT is an LLM and is integrated into instruction, satisfying the LLM-based intervention requirement, even though the design is qualitative case study rather than experimental.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract notes that ChatGPT ‘positively affects students' learning experiences, especially in writing, grammar, and vocabulary acquisition,’ and mentions ‘various learning activities.’ Writing is a primary focus area among the reported effects, so the context includes writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly a ‘qualitative case study’ with data from interviews analyzed via thematic analysis. The abstract reports perceived effects (e.g., ‘positively affects students' learning experiences’) but does not indicate any quantitative or experimental writing outcome measures. Thus, it does not meet the requirement for quantifiable writing outcome metrics.""
    }
}"
572,Leveraging Chatgpt in the Writing Classrooms: Theoretical and Practical Insights,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to 'second language (L2) writing pedagogy' but does not specify that the target L2 is English or that participants are ESL/EFL/ELL learners. It appears conceptual rather than reporting on a specific learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper is described as exploring the potential of integrating ChatGPT into L2 writing pedagogy and discussing integration across stages of the writing process. However, it is presented as theoretical and practical insights, not as an experimental or quasi-experimental study implementing an LLM-based intervention with participants.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus is on L2 writing pedagogy and the writing process, the article is conceptual (theoretical frameworks, challenges, recommendations) rather than an empirical pedagogical intervention study with implemented instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or empirical assessment of writing performance. It offers recommendations and theoretical discussion without reporting measured effects of an LLM-mediated writing intervention.""
    }
}"
573,"Teacher- Versus Ai-generated (poe Application) Corrective Feedback and Language Learners' Writing Anxiety, Complexity, Fluency, and Accuracy",2024,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “language learners” and “undergraduate language learners at East China University of Political Science and Law,” which strongly suggests EFL learners in China, but it never explicitly states that the target language is English. The mention of ‘primary school settings’ at the end further confuses the context. Thus, it is likely but not certain that these are L2 English learners.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses an “AI-driven application called Poe” to provide corrective feedback. However, the abstract does not specify whether Poe is using a large language model (e.g., GPT-based, transformer generative model) or some other AI technology. Without confirmation that Poe is LLM-based, it is unclear whether this meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on writing-related variables: writing anxiety, complexity, fluency, and accuracy. The AI tool is integrated as corrective feedback within a writing task, and the primary outcomes are writing competence and related affective variables, not automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""A quasi-experimental pretest–posttest design with three groups (teacher CF, AI CF, no feedback) is used. Quantitative outcomes include writing complexity, fluency, accuracy, and writing anxiety, analyzed via one-way ANOVA. These are clear, quantifiable writing-related outcome measures of the AI-mediated intervention.""
    }
}"
574,Exploratory Study on the Potential of Chatgpt as a Rater of Second Language Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Korean secondary-level EFL students writing English essays, clearly fitting an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT (GPT-4) is used as an automated writing evaluation (AWE) scoring tool, not as part of an instructional or experimental writing intervention. The focus is on rating reliability, not on integrating LLMs into writing instruction or processes for learning.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on assessment—comparing ChatGPT’s essay scores with human raters—rather than on improving writing competence or implementing a pedagogical writing intervention. It is essentially an AWE/automated scoring validity study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No intervention or pre/post or comparative writing outcome measures are reported. The only quantitative outcomes are reliability/fit indices (intraclass correlation, Rasch model) for scoring, not measures of changes in learners’ writing performance due to LLM-mediated instruction.""
    }
}"
575,Facilitating Learners' Self-assessment during Formative Writing Tasks Using Writing Analytics Toolkit,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions “learners” but does not specify that they are L2 English learners in ESL/EFL/ELL contexts, nor that the target language is English. Their linguistic background and language of writing are not stated.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is a “writing analytics toolkit” using “data visualisation and cutting-edge machine learning technology” to provide feedback. There is no indication that it is based on large language models (e.g., ChatGPT, GPT-4, transformer-based generative models). It appears to be an analytics/ML feedback tool rather than an LLM-integrated writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on formative writing tasks, self-assessment of writing products, and monitoring writing processes. The toolkit is used during revision of written texts, so the primary focus is on writing-related competence and processes.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes: learners’ self-assessment accuracy and processes of self-assessment were compared between experimental and control groups, and the toolkit’s effect on self-assessment accuracy is reported. These are structured, measurable outcomes related to writing assessment processes.""
    }
}"
576,The Effect of Chatgpt-integrated English Teaching on High School Efl Learners' Writing Skills and Vocabulary Development,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 10th grade Turkish EFL learners in English lessons, clearly an EFL context with English as the target language: “10th grade Turkish EFL learners' writing skill and vocabulary development.”""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention explicitly integrates ChatGPT, a large language model, into English lessons: “ChatGPT-integrated English lessons… the experimental group took ChatGPT-integrated vocabulary and writing instruction whereas the control group took traditional instruction,” indicating an experimental design using an LLM in instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence and related variables: “aims to explore the effect of ChatGPT-integrated English lessons on… writing skill and vocabulary development.” ChatGPT is used pedagogically in writing instruction, not merely for automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pre- and post-tests and statistical analysis to measure outcomes: “participated in the study by taking place in experimental phase and completing pre- and post-tests… The results of pre- and post-tests showed that the traditional instruction had more effect on writing and vocabulary development,” indicating quantifiable writing outcome metrics.""
    }
}"
577,Potentials and Implications of Chatgpt for Esl Writing Instruction,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a systematic review/meta-analysis of prior research on ChatGPT for L2 writing, not an empirical study with its own participant sample of L2 English learners. Thus, it does not itself report primary data from a defined L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a systematic review design to synthesize research on ChatGPT’s educational potentials. It does not implement an experimental or quasi-experimental LLM-based writing intervention itself; it is a secondary study.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on implications of ChatGPT for L2 composition and writing instruction, discussing how ChatGPT can enhance L2 writing instruction and its practical applications in L2 writing classes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although it mentions a meta-analysis of 42 articles, the abstract does not report primary, study-level quantitative writing outcomes from an intervention conducted by the authors. As a review/meta-analysis, it falls under the exclusion criteria for non-primary research.""
    }
}"
578,Enhancing English as a Foreign Language (efl) Learners' Writing with Chatgpt: a University-level Course Design,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as university-level English as a Foreign Language (EFL) learners, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study integrates OpenAI’s GPT-3.5 (an LLM) into a university-level EFL writing course, framed within ADDIE and TPACK. GPT-3.5 is used to provide feedback, generate ideas, and act as a peer reviewer, indicating an instructional intervention using an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly an EFL writing course, focusing on academic writing, organization, feedback, and writing proficiency. The emphasis is on writing instruction and writing-related variables, not on automated scoring.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports that GPT-3.5 enhances efficiency, cohesion, and serves as a substitute for peer reviewers, and that it promotes writing proficiency. However, it does not specify any experimental or quasi-experimental design, control/comparison, or quantifiable writing outcome metrics; it may be descriptive/course design rather than outcome-based. Without explicit mention of measured writing scores or other quantitative outcomes, eligibility is uncertain.""
    }
}"
579,Generating Genre-based Automatic Feedback on English for Research Publication Purposes,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “L2 writers” and “multilingual classrooms” and to English for research publication purposes, but does not specify participant characteristics or whether any empirical learner data were collected. It is unclear if actual L2 English learners participated in a study or if this is purely a tool-development paper.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the paper describes developing an AI-mediated L2 writing technology that leverages large language models and genre-based instruction, the abstract focuses on system development and evaluation (accuracy, precision, recall of network classification). There is no indication of an experimental or quasi-experimental pedagogical intervention where LLMs are integrated into instruction with learners as participants.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on generating genre-based automatic feedback and evaluating the classification network’s performance, not on an implemented writing intervention or instructional context. It is essentially an automated writing evaluation/tool-development study rather than a pedagogical study of writing competence outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Reported outcomes are technical metrics (accuracy, precision, recall) of the classification network. The abstract does not report any quantifiable learner writing outcomes (e.g., changes in writing quality, complexity, accuracy) resulting from LLM-mediated intervention with learners.""
    }
}"
580,A Study on Chatgpt-4 as an Innovative Approach to Enhancing English as a Foreign Language Writing Learning,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 76 undergraduate students in Algeria learning English as a Foreign Language (EFL). The abstract explicitly focuses on EFL writing, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is the use of ChatGPT-4, explicitly named, which is a large language model. An experiment with experimental and control groups was conducted to investigate its use in students’ EFL writing, indicating an experimental design integrating an LLM into writing learning.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s focus is on EFL writing learning and how ChatGPT-4 helps students address challenges in EFL writing and put what they learn about EFL writing into practice. The primary outcome is writing skills, not automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that the experimental group outperformed the control group and that post-test scores exceeded pre-test scores, indicating quantifiable writing outcome measures. Additional questionnaire data on perceptions is secondary to these measured writing outcomes.""
    }
}"
581,Towards a Taxonomy of Artificial Intelligence in Teaching Writing in a Foreign Language,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to 'foreign language teaching' and 'teaching writing in a foreign language' without specifying English or L2 English learners (ESL/EFL/ELL). The target language and learner population are not clearly identified.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article aims to identify characteristics and capacities of AI sites and proposes a taxonomy, describing advantages, disadvantages, and potential applications. There is no indication of an experimental or quasi-experimental design integrating LLMs (e.g., ChatGPT) into instruction; it appears to be a conceptual/overview piece.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus is on AI in teaching writing, the study is framed as taxonomy-building and functional description of tools, not as an implemented pedagogical intervention or study of writing competence outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any empirical data, experimental measures, or quantifiable writing outcomes. It focuses on describing tools, proposing a taxonomy, and discussing benefits, drawbacks, and potential applications.""
    }
}"
582,Using Ai-generative Tools in Tertiary Education: Reflections on Their Effectiveness in Improving Tertiary Students' English Writing Abilities,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are tertiary students in Hong Kong whose English writing abilities are the focus, implying L2 English learners in an EFL/ESL context: the study aims to see whether AI tools can improve students' English writing skills in university.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly mentions AI-generative tools such as ChatGPT, which are LLM-based. The study explores their use in learning and writing, though mainly from a perception standpoint.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on English writing abilities and the use of AI tools in learning and writing, aligning with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The methodology is based on interviews to gather students’ and teachers’ opinions. The abstract reports perceptions (convenience, concerns about feedback) but does not mention any experimental or quasi-experimental design or quantifiable writing outcome measures.""
    }
}"
583,An Investigation of Artificial Intelligence Tools in Editorial Tasks among Arab Researchers Publishing in English,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are described as 'Arab researchers who publish in English,' not L2 English learners in ESL/EFL/ELL instructional contexts. The focus is on researchers’ use of AI in scholarly publishing, not on language learners in educational settings.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study surveys use of AI tools such as Grammarly, Endnote, and QuillBot. These are not clearly LLM-based pedagogical interventions but general-purpose tools, and there is no experimental or quasi-experimental design integrating LLMs into instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is editorial tasks in scholarly publishing, not writing instruction or L2 writing development. The study examines adoption, challenges, and ethics of AI tools, not a pedagogical intervention targeting writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports survey-based insights on usage patterns, challenges, and ethical considerations, but no quantifiable writing outcome metrics or measures of changes in writing performance are mentioned.""
    }
}"
584,Analyzing the Use of Ai Writing Assistants in Generating Texts with Standard American English Conventions: a Case Study of Chatgpt and Bard,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any human participants, learners, or educational cohort, let alone L2 English learners in ESL/EFL/ELL contexts. It is a corpus-based analysis of AI-generated texts, not a learner study.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT and Bard (LLMs) are examined, they are not integrated into an experimental or quasi-experimental pedagogical intervention. The study analyzes their output linguistically rather than using them as part of a writing instruction or writing process intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on collocational patterns and SAE conventions in AI-generated texts, with pedagogical implications discussed conceptually. There is no actual instructional context targeting learners’ writing competence or writing-related variables through LLM use.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes are reported. The study provides corpus analyses of AI output and discusses implications, but does not measure changes in human writing performance or related metrics following an LLM-mediated intervention.""
    }
}"
585,Network Algorithms for Intelligent Evaluation of Composition in Middle School English Cloud Classrooms,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are described only as ‘middle school students’ with English compositions. It is not specified that they are L2 English learners in ESL/EFL/ELL contexts; they could be native speakers. Thus the population does not clearly meet the L2 English learner requirement.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a link grammar detector and N-gram model to evaluate grammar and score compositions. These are traditional NLP methods, not transformer-based large language models such as ChatGPT, GPT-4, or similar. Therefore, there is no LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on automated evaluation and scoring of compositions (an essay scoring system), not on integrating the tool into writing instruction or learners’ writing processes as a pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are system performance metrics (recall, accuracy, mean square error, runtime) and comparison with manual scoring. There are no learner writing outcome measures assessing the effectiveness of an instructional or feedback intervention.""
    }
}"
586,Can My Writing Be Polished Further? When Chatgpt Meets Human Touch,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL learners (“Four groups of 19 EFL learners”), indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT, a large language model, in collaborative writing processes with teacher and peer scaffolding in an EFL writing classroom, which fits an LLM-based writing intervention contextually (though not clearly experimental).""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL writing processes and refinement (planning, translating, reviewing) using ChatGPT in class, clearly centered on writing competence and writing-related processes rather than assessment-only uses.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative methods (think-aloud sessions, interviews) and process-oriented findings (collaborative work, emotional reassurance, metacognitive awareness). It does not mention any quantitative or experimental writing outcome measures (e.g., scores, rubric-based gains), so no quantifiable writing outcomes are evident.""
    }
}"
587,To Resist It or to Embrace It? Examining Chatgpt's Potential to Support Teacher Feedback in Efl Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese undergraduate students writing English argumentative essays in an EFL context, clearly L2 English learners: “Fifty English argumentative essays composed by Chinese undergraduate students were collected…” and the study concerns “writing English as a Foreign Language (EFL).”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is exploratory and examines ChatGPT’s potential to support teacher feedback. ChatGPT and teachers both generate feedback on existing essays, and the study compares amount and type of feedback plus teacher perceptions. There is no experimental or quasi-experimental pedagogical intervention where LLMs are integrated into instruction or students’ writing processes; it is a functionality/feasibility and perception study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on ChatGPT’s role in supporting teacher feedback and comparing feedback characteristics, not on an implemented writing intervention or instructional context aimed at improving learners’ writing competence. No actual teaching cycle using ChatGPT feedback with students is described; the work is about feedback generation and teacher perceptions rather than a pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study does not report quantifiable writing outcome metrics (e.g., pre/post writing scores, quality ratings) for students. Outcomes are the amount and type of feedback and teachers’ perceptions. There is no measurement of changes in students’ writing performance resulting from an LLM-mediated intervention.""
    }
}"
588,"Automated Writing Evaluation Systems: a Systematic Review of Grammarly, Pigai, and Criterion with a Perspective on Future Directions in the Age of Generative Artificial Intelligence",2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract indicates that most included studies involve non-native English-speaking university students, which would fit an L2 English population. However, this article itself is a systematic review of prior work, not a primary study with its own participant sample relevant to the target review.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper is a systematic review of AWE systems (Grammarly, Pigai, Criterion). These tools are not clearly framed as transformer-based LLMs in the abstract, and the article does not report an experimental or quasi-experimental LLM-based writing intervention conducted by the authors.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the review focuses on writing proficiency and AWE systems in language classrooms, it synthesizes existing studies rather than implementing a specific pedagogical intervention or instructional context designed and tested by the authors.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic review, the article does not present original experimental outcome data on writing performance from an LLM-mediated intervention; instead, it summarizes findings from other studies. Review articles are explicitly excluded.""
    }
}"
589,Adopting Chatgpt as a Writing Buddy in the Advanced L2 Writing Class,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are advanced L2 writers of German producing summaries in L2 German. The focus is on German as the target language, not English (ESL/EFL/ELL), so the population does not meet the review’s requirement of L2 English learners.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study integrates ChatGPT-3.5 (an LLM) into a classroom-based writing intervention. Students compare their drafts with ChatGPT-produced texts and use them for revision, which constitutes an LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly the L2 writing and revision process. ChatGPT is used as a writing buddy/model to support revision of student summaries, focusing on writing quality and revision behavior rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions rubric-based ratings of ChatGPT models and coded revision processes (focus, source, success), and notes that students improved their texts. However, it does not clearly state that quantifiable writing outcome metrics (e.g., pre/post writing scores) for learners’ own writing were reported, so it is unclear if formal writing outcome measures are provided.""
    }
}"
590,“chatgpt Seems Too Good to Be True”: College Students’ Use and Perceptions of Generative Ai,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The population is broadly described as U.S. college students (N = 1001). While the abstract notes that non-native English speakers are included, the study is not situated in an ESL/EFL/ELL instructional context, nor is it focused specifically on L2 English learners as the target population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines how students perceive and use ChatGPT, but there is no indication of an experimental or quasi-experimental pedagogical intervention integrating ChatGPT into writing instruction or structured writing processes. It is observational/survey-based rather than an intervention study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT use for writing tasks is mentioned, the primary focus is on usage patterns and perceptions across tasks (general, writing, programming) and demographic/societal factors, not on writing competence or writing-related instructional interventions.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study analyzes frequency of ChatGPT use and attitudes, not changes in writing performance or related measurable writing outcomes following an LLM-mediated intervention.""
    }
}"
591,Identifying Chatgpt-generated Texts in Efl Students’ Writing: through Comparative Analysis of Linguistic Fingerprints,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Japanese EFL learners (140 first-year university students), clearly fitting an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used to generate comparison texts and some students used it for proofreading or full-text generation, but there is no experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction. The focus is on detectability of AI-generated texts, not on an instructional treatment using LLMs.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on distinguishing human vs. ChatGPT-generated essays via linguistic fingerprints and machine learning classification. It does not examine writing competence development or a writing intervention; rather, it addresses detection and ethical concerns.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported to assess the effectiveness of an LLM-mediated writing intervention. The analyses concern linguistic feature differences and classification performance, not changes in learners’ writing quality due to an LLM-based instructional treatment.""
    }
}"
592,Using Chatgpt for Second Language Writing: Experiences and Perceptions of Efl Learners in Thailand and Vietnam,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Thai and Vietnamese EFL learners using ChatGPT for L2 (English) writing, fitting ESL/EFL/ELL contexts focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the study is a survey/interview of existing use and perceptions, not an experimental or quasi-experimental intervention integrating ChatGPT into instruction or a structured writing process with controlled conditions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on using ChatGPT for L2 writing (brainstorming, organizing ideas, refining outlines, editing drafts), which is clearly writing-related and pedagogically oriented.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports perceptions and practices but does not mention any quantifiable writing outcome metrics (e.g., writing scores, quality ratings, accuracy measures) to assess effectiveness of ChatGPT-mediated writing intervention.""
    }
}"
593,Evaluating the Role of Chatgpt in Enhancing Efl Writing Assessments in Classroom Settings: a Preliminary Investigation,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners: 30 CET-4 essays written by non-English majors at a university in Beijing, China. The focus is clearly on English as a foreign language writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT (3.5 and 4) is used as an automated rater and feedback provider to evaluate reliability and relevance of assessment. There is no experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction or learners’ writing processes; ChatGPT functions as an assessment tool, not as part of a teaching intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on writing assessment reliability and feedback relevance (G-theory analysis of scores and qualitative feedback), not on improving learners’ writing competence through an instructional intervention. It evaluates ChatGPT as an assessment system rather than as a pedagogical tool in a writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcome metrics (e.g., pre/post writing performance) are reported. Outcomes concern reliability coefficients of ChatGPT vs. teachers and relevance of feedback, not changes in students’ writing ability following an LLM-mediated intervention.""
    }
}"
594,The Grass Is Not Always Greener: Teacher Vs. Gpt-assisted Written Corrective Feedback,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to student writing and L2 writing practice but does not explicitly state that participants are L2 English learners in ESL/EFL/ELL contexts, nor that the target language is English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares written corrective feedback (WCF) produced by teachers and ChatGPT, focusing on their characteristics. There is no indication of an experimental or quasi-experimental pedagogical intervention where LLMs are integrated into instruction or student writing processes; it is an evaluative comparison of feedback types.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the topic is related to L2 writing and feedback, the primary focus is on analyzing and contrasting teacher vs. ChatGPT WCF practices, not on an instructional intervention aimed at improving writing competence. It resembles a functionality/feature comparison rather than a pedagogical study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative findings about the nature of teacher and ChatGPT feedback (e.g., metalinguistic feedback, reformulation, redundancy) but does not mention any quantifiable writing outcome measures (e.g., changes in writing scores, accuracy gains) resulting from an LLM-mediated intervention.""
    }
}"
595,"Brave New World or Not?: a Mixed-methods Study of the Relationship between Second Language Writing Learners' Perceptions of Chatgpt, Behaviors of Using Chatgpt, and Writing Proficiency",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as “215 university L2 writing learners,” indicating second/foreign language learners engaged in L2 writing. The abstract does not explicitly state English, but the context of ‘L2 writing proficiency’ and ChatGPT-based writing tools strongly suggests an L2 English academic writing context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines learners’ perceptions of ChatGPT and their self-reported usage behaviors. There is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT into teaching; rather, it is a correlational/mixed-methods study of existing usage and perceptions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on L2 writing proficiency (complexity, accuracy, fluency) and on AI-based writing tools in the context of writing instruction, satisfying the writing-related context requirement.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study reports quantitative writing outcomes (complexity, accuracy, fluency), these are used to examine relationships with naturally occurring ChatGPT usage, not to evaluate the effectiveness of a structured LLM-mediated writing intervention. There is no controlled intervention whose impact on writing is being tested.""
    }
}"
596,Using Generative Ai to Provide High-quality Lexicographic Assistance to Chinese Learners of English,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The target users are explicitly described as Chinese learners of English, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study explores how generative AI (ChatGPT, Ernie Bot) can be used to generate explanations and lexicographic content and argues for future integration into writing assistants. It does not describe an experimental or quasi-experimental pedagogical intervention where LLMs are actually integrated into learners’ writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on lexicographic assistance and explanations for subject-verb disagreement errors, with a design-oriented perspective on integrating AI into writing assistants. However, there is no clear indication of an implemented instructional context or measured impact on writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantitative writing outcome measures or experimental evaluation of learners’ writing performance. It focuses on identifying error subcategories and evaluating chatbot-generated explanations, not on measured changes in learner writing.""
    }
}"
597,Instructors' and Learners' Perspectives on Using Chatgpt in English as a Foreign Language Courses and Its Effect on Academic Integrity,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are university learners of English as a foreign language (EFL), clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although instructors incorporated ChatGPT into their teaching for one trimester, the study focuses on perspectives and academic integrity, not on an experimental or quasi-experimental evaluation of a structured LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on attitudes toward ChatGPT use in EFL learning and concerns about academic integrity. While written work is mentioned, the study does not center on writing competence or writing-related instructional outcomes as the main context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses questionnaires, open-ended responses, and interviews to gather opinions and attitudes. No quantifiable writing outcome metrics or measured changes in writing performance are reported.""
    }
}"
598,A Case Study of Implementing Generative Ai in University's General English Courses,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners in Korean university-level general English courses, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions a 'generative AI-based instruction model' but does not specify that it is an LLM (e.g., ChatGPT, GPT-4) or provide tool names. It could be any generative AI, not necessarily an LLM-based system.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract notes that the instruction is for 'writing and speaking' and mentions 'supporting linguistic proficiency,' but the primary stated focus of the study is on affective factors (motivation, interest, confidence), not specifically on writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study explicitly investigates effects on affective factors (motivation, interest, confidence). There is no indication of quantifiable writing outcome metrics or specific measures of writing performance being reported.""
    }
}"
599,Investigating Students' Uptake of Teacher- and Chatgpt-generated Feedback in Efl Writing: a Comparison Study,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL students: twenty Chinese undergraduate students writing argumentative essays in English. This fits L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used to generate feedback on students’ writing, but the design is a comparison of teacher- vs ChatGPT-generated feedback uptake and perceptions, not an experimental or quasi-experimental intervention evaluating an LLM-based instructional treatment (e.g., no control vs treatment groups, no pre/post design assessing LLM-mediated instruction).""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL writing, specifically argumentative essays and how students use feedback from teachers and ChatGPT in revising their writing. This directly concerns writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study analyzes revisions to assess engagement with feedback and appropriateness of revisions, and collects questionnaire data on perceptions. It does not report quantifiable writing outcome metrics (e.g., pre/post writing scores, rubric-based writing quality measures) to evaluate the effectiveness of an LLM-mediated intervention; instead, it focuses on feedback uptake and preferences.""
    }
}"
600,Uncovering Students' Processing Tactics towards Chatgpt's Feedback in Efl Education Using Learning Analytics,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students using ChatGPT for reading and writing tasks in English, fitting the L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines students’ interaction with ChatGPT, a generative AI chatbot based on LLMs, during reading and writing tasks, indicating an LLM-based intervention embedded in instruction.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""ChatGPT supports both reading and writing, but the abstract does not specify that the primary focus is writing competence or writing-related variables; it emphasizes processing tactics, learning modes, and domain knowledge gains rather than writing development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Reported outcomes are ‘learning gains’ and ‘improvement of domain knowledge.’ There is no indication of quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity). The focus is on processing tactics and domain knowledge, not measured changes in writing performance.""
    }
}"
601,Metacognitive Mastery: Transformative Learning in Efl through a Generative Ai Chatbot Fueled by Metalinguistic Guidance,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL students taking linguistics courses, which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a Generative AI Chatbot (GAC) to provide metalinguistic guidance and corrective feedback, and employs a quasi-experimental pretest–posttest design comparing CF-based GAC vs. MG-based GAC. This aligns with an LLM-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on linguistics courses, metalinguistic guidance, learning achievement, reflective performance, perception, and metacognitive awareness. The abstract does not indicate that writing competence or writing-related performance is a primary outcome; it appears to target general learning and metacognition rather than writing.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""Quantitative outcomes are reported (learning achievement, reflective performance, metacognitive awareness), but the abstract does not specify that any of these are writing outcome measures (e.g., writing quality, accuracy, complexity). It is unclear whether writing performance was assessed at all.""
    }
}"
602,Exploring Efl Learners' Integration and Perceptions of Chatgpt's Text Revisions: a Three-stage Writing Task Study,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) learners in an EFL classroom context, so the population is L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used to provide reformulations as feedback within a three-stage writing task, the abstract does not indicate an experimental or quasi-experimental design (e.g., no control/comparison condition, no pre-post or treatment contrast). It is primarily an observational study of how learners notice and integrate ChatGPT’s revisions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly EFL writing: a three-stage writing task (composing–comparison–rewriting) focusing on learners’ revision behavior and perceptions of ChatGPT’s reformulations in writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported concern noticing (type and depth), number of reformulations integrated, and perceptions from a questionnaire. There is no mention of quantifiable writing performance metrics (e.g., scores, accuracy, complexity) to assess effectiveness of the intervention on writing competence.""
    }
}"
603,Chatgpt as a Tool for Self-learning English among Efl Learners: a Multi-methods Study,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 344 English as a Foreign Language (EFL) learners, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is the focus, the study is not an experimental or quasi-experimental intervention in writing instruction. It is a multi-methods study (systematic review, survey, interviews) examining factors influencing ChatGPT acceptance and use, not testing a structured LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is general self-directed English language learning. Writing is only one of several skills mentioned (reading, writing, vocabulary, grammar), and the primary focus is technology acceptance and usage patterns, not writing competence or writing-related variables as the main outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes concern perceived usefulness, ease of use, interactivity, enjoyment, trust, and continued use, rather than measured changes in writing performance or related quantitative writing outcomes.""
    }
}"
604,Ai or Student Writing? Analyzing the Situational and Linguistic Characteristics of Undergraduate Student Writing and Ai-generated Assignments,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The corpus consists of undergraduate assignments from an English as a Foreign Language (EFL) context, indicating L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares existing student assignments with ChatGPT-generated texts to analyze situational and linguistic characteristics. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on comparing linguistic/register features of student vs. AI-generated texts, not on improving or assessing writing competence through an instructional intervention. It is essentially a comparative corpus/register analysis, not a teaching/learning context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics related to an LLM-mediated intervention are reported. The study does not measure changes in learners’ writing performance; it only analyzes characteristics of existing texts.""
    }
}"
605,Ai-powered Efl Pedagogy: Integrating Generative Ai into University Teaching Preparation through Utaut and Activity Theory,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The participants are EFL lecturers in Indonesian higher education, focusing on their adoption of generative AI for teaching preparation. There is no indication that the study involves L2 English learners or reports learner data; the population is teachers, not students.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions ‘generative AI’ but does not specify whether it is an LLM (e.g., ChatGPT) or how exactly it is integrated into instruction. The focus is on adoption factors (UTAUT, Activity Theory), not on a structured LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on EFL teaching preparation, technology adoption, and pedagogical practices. There is no mention of writing competence or writing-related variables as the main outcome; the study is about general teaching efficiency and content personalization.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes concern behavioral intention, actual use behavior, and factors influencing adoption of generative AI, not learners’ writing performance or writing-related measures.""
    }
}"
606,Success through Error: Using Error Analysis of Chatgpt Output in English as a Foreign Language Learner Writing Instruction,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were Arabic-English speakers in an English communication course, described as foreign language learners (EFL) and classified by IELTS standards. The focus is clearly on English as the target L2.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is an in-class exercise using text generated by ChatGPT, a large language model. There is a treatment group (error detection on ChatGPT output) and a control group (same exercises without ChatGPT), indicating a quasi-experimental design integrating an LLM into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing instruction. After the exercises, students wrote a descriptive essay, and the study explicitly aims to see whether ChatGPT-based exercises aid foreign language writing, focusing on writing quality and related variables (lexical sophistication, syntactic complexity, sentence length).""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: essay length (number of words, number of sentences, sentence length) and quality indicators such as use of low-frequency and abstract words and complex syntactic structures. These are used to assess the effectiveness of the ChatGPT-mediated intervention.""
    }
}"
607,"Unlocking English Proficiency: Transforming the English Learning Curriculum for Colombian Middle Schoolers with Ipt Powered by Elsa’s Ai-assisted App & Asr; Desbloqueando a Competência Em Inglês: Transformando O Currículo De Aprendizagem De Inglês Para Alunos Colombianos Do Ensino Médio Com Ipt Alimentado Pelo Aplicativo Assistido Por Ia Da Elsa E Asr; Desbloqueando La Proficiencia En Inglés: Cómo La Aplicación Asistida Por Inteligencia Artificial Elsa, Basada En Asr E Ipt, Beneficia La Competencia En Inglés De Los Estudiantes De Educación Secundaria En Colombia",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Colombian middle school students learning English as a Foreign Language (EFL), clearly an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Elsa Speak, described as an AI app using Automatic Speech Recognition (ASR) and Intentional Phonetic Training (IPT). There is no indication that it is based on a large language model or transformer-based generative model; it is focused on ASR and pronunciation training, not LLM-mediated generation.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on phonetic skills (intonation, fluency, pronunciation, sound discrimination, stressed syllables) and speaking proficiency (IELTS Speaking Score). Writing is only mentioned indirectly and not as a central instructional or assessment focus, so the context is not writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are mainly speaking-related (IELTS Speaking via Elsa, pronunciation, fluency, intonation). There are no quantifiable writing outcome metrics or structured writing intervention measures reported in the abstract.""
    }
}"
608,Generative Ai’s Recolonization of Efl Classrooms the Case of Continuation Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is Chinese English as a Foreign Language (EFL) classrooms and continuation writing in China’s EFL assessment, clearly involving L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study uses ‘generative AI’ and ‘AI chatbots’ to generate continuation writing samples, it is not described as an experimental or quasi-experimental pedagogical intervention. AI is used to illustrate an argument about cultural and linguistic patterns, not as an instructional treatment whose effects are measured.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on ideological, cultural, and discourse risks (recolonization, native-speakerism, cultural hollowness) in AI-generated texts, analyzed via systemic functional linguistics. It does not describe an instructional design aimed at improving writing competence, but rather critiques the potential impact of using such texts.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or learner performance data are reported. The study illustrates arguments with AI-generated data and discourse analysis, not with experimental measures of students’ writing development.""
    }
}"
609,Worddecipher: Enhancing Digital Workspace Communication with Explainable Ai for Non-native English Speakers,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly targets non-native English speakers (NNES) in digital workspace communication, implying L2 English users in an EFL/ESL/ELL-type context focused on English writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The tool WordDecipher is described as leveraging large language models and word embeddings to provide writing support. However, the abstract does not specify an experimental or quasi-experimental study design; it mainly presents a tool and a usage scenario, not a structured intervention study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on enhancing digital workspace communication (emails, Slack messages) and explaining nuances of expressions, but there is no indication of a pedagogical writing intervention or systematic instruction aimed at developing writing competence; it is a tool demonstration rather than an instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions a usage scenario showing potential benefits but does not report any quantifiable writing outcome metrics or experimental evaluation of writing performance. No structured measures of writing improvement are described.""
    }
}"
610,"Proceedings of the 3rd Workshop on Intelligent and Interactive Writing Assistants, In2writing 2024, Co-located with the Acm Chi Conference on Human Factors in Computing Systems, Chi 2024",2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract describes a proceedings volume with 17 papers on AI writing assistants, including some references to non-native English speakers and students, but it does not specify that any study focuses on L2 English learners in ESL/EFL/ELL contexts with analyzable data on English writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""Several papers involve AI/LLM-based writing assistants (e.g., ChatGPT, LLMs for educational materials), but the abstract does not clearly indicate which, if any, use experimental or quasi-experimental designs integrating LLMs into writing instruction or processes in a way suitable for intervention analysis.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The proceedings focus broadly on intelligent and interactive writing assistants, including topics like self-disclosure, ecosystem risks, mental models, and communication support. It is not clear which papers, if any, primarily target writing competence or writing-related pedagogical outcomes rather than general HCI or usage patterns.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantifiable writing outcome metrics (e.g., writing quality scores, complexity measures, accuracy) resulting from LLM-mediated interventions. It instead highlights conceptual, design, and usage studies, so it cannot be confirmed that any included paper reports experimental writing outcome measures.""
    }
}"
611,They May Have Seen My Chatgpt Tab: Exploring Social Perceptions of Ai-assisted Writing for Esl Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on English as a Second Language (ESL) students using generative AI tools to improve their writing artifacts, so the population is L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although generative AI tools (likely LLM-based) are mentioned, the study is not an experimental or quasi-experimental intervention integrating LLMs into instruction. It is a diary and interview study about perceptions and social dynamics, not a designed pedagogical intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on social perceptions and socio-technical implications of AI-assisted writing, not on writing competence or writing-related performance variables as an instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses diary studies and interviews and does not report any quantifiable writing outcome metrics or experimental measures of writing performance. It is qualitative and exploratory in nature.""
    }
}"
612,Exploring Chatgpt-supported Teacher Feedback in the Efl Context,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 102 students in a Chinese tertiary EFL context, clearly L2 English learners in an EFL setting: “Chinese tertiary EFL context… two undergraduate classes in the world language education program.”""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study integrates ChatGPT (an LLM) into writing pedagogy: “integrating ChatGPT into teacher writing feedback provisions… Two prompts were provided to ChatGPT… corrective feedback… holistic rhetorical feedback. Afterwards, the teachers adapted the ChatGPT feedback and shared… with each student.” This is an LLM-mediated feedback intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on L2 writing and feedback: students complete argumentative and expository essays; the study examines “ChatGPT-supported teacher feedback” and “how EFL students incorporate this feedback into their writing revisions,” clearly centered on writing competence and revision behavior.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports descriptive findings about feedback types and student incorporation (“students incorporated more of the feedback into their revisions across tasks”) but does not indicate an experimental or quasi-experimental design with quantifiable writing outcome metrics (e.g., scores, quality ratings, pre-post gains) to assess effectiveness of the LLM-mediated intervention. The focus is on feedback characteristics and uptake, not measured writing improvement.""
    }
}"
613,Cognitive and Sociocultural Dynamics of Self-regulated Use of Machine Translation and Generative Ai Tools in Academic Efl Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 79 learners in a compulsory EFL course at a Japanese university, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on learners’ self-regulated use of AI tools (ChatGPT and Google Translate) rather than an experimental or quasi-experimental instructional intervention integrating LLMs. There is no indication of a structured pedagogical treatment or controlled comparison; instead, it examines naturally occurring use and perceptions.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context is academic EFL writing and use of AI tools for writing tasks, but the primary focus described is on cognitive and sociocultural dynamics and perceptions, not on systematically improving writing competence through an instructional design.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantitative data are from pre- and post-surveys about attitudes toward AI-assisted writing. The abstract does not report objective, quantifiable writing performance outcomes; perceived improvement is self-reported rather than measured writing scores or quality metrics.""
    }
}"
614,Chatgpt as an Automated Writing Evaluation (awe) Tool: Feedback Literacy Development and Awe Tools' Integration Framework,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 18 English as a Foreign Language (EFL) students in Indonesia, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""ChatGPT is used as an automated writing evaluation (AWE) tool in a writing course, i.e., a generative AI/LLM integrated into writing instruction alongside Grammarly and Quillbot.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is a Recount and Narrative essay course, the stated primary objective is to investigate the impact of AWE tools on learners' feedback literacy, not on writing competence or writing-related performance measures. The focus is on feedback literacy development and an integration framework, rather than writing outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a single qualitative case study design with interviews, reflective journals, and artifacts, and reports thematic findings about feedback literacy. No quantifiable writing outcome metrics or experimental measures of writing performance are mentioned in the abstract.""
    }
}"
615,Exploring Ai-generated Text in Student Writing: How Does Ai Help?,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 23 Hong Kong secondary school students described as English as a foreign language (EFL) students, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students used “AI-writing tools” that generate human-like text, the study is observational: students wrote stories with these tools, and the researchers analyzed resulting texts. There is no indication of an experimental or quasi-experimental instructional intervention (e.g., treatment vs. control, pre/post design) integrating LLMs into teaching; the tools’ specific LLM nature is also not specified.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on written stories, analyzing structure, organization, syntactic complexity, and expert-rated quality (content, language, organization). The context is clearly writing performance and writing-related variables, not automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantifiable writing outcomes are reported: expert scores for content, language, and organization, and analyses via multiple linear regression and cluster analysis examining contributions of human vs. AI-generated words to writing scores.""
    }
}"
616,Rethinking Ai: Bias in Speech-recognition Chatbots for Elt,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are ELT students using English with a speech-recognition chatbot, indicating an English language learning context (ESL/EFL/ELL).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a speech-recognition chatbot, but there is no indication it is an LLM-based tool (e.g., ChatGPT/GPT-4). The focus is on speech recognition accuracy and bias, not on a transformer-based generative language model integrated into writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is English language teaching with emphasis on pronunciation, speech recognition, and attitudes toward English varieties. Writing competence or writing-related variables are not the primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are based on text-mining of reflection papers and thematic analysis of interviews to explore attitudes and conceptions of English. No quantifiable writing outcome metrics or writing performance measures are reported.""
    }
}"
617,"Teaching Efl Students to Write with Chatgpt: Students' Motivation to Learn, Cognitive Load, and Satisfaction with the Learning Process",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are twenty-one Hong Kong secondary school students described as EFL students completing a 500-word English language writing task, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study integrates ChatGPT, an LLM, into a classroom writing task where students learn prompt engineering and write a 500-word composition with ChatGPT’s support. This constitutes an LLM-mediated writing instructional intervention, though not strictly experimental.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL writing instruction: students complete a 500-word English composition with ChatGPT’s support in a workshop format. The focus is on using ChatGPT in the writing classroom, not on automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes measured are motivation, cognitive load, and satisfaction. The abstract does not report any quantitative writing performance metrics (e.g., scores, accuracy, complexity, quality ratings). Writing is the task context, but no writing competence or product measures are analyzed, so there is no quantifiable writing outcome to assess intervention effectiveness.""
    }
}"
618,"Utilising Artificial Intelligence (ai) in Vocabulary Learning by Efl Omani Students: the Effect of Age, Gender, and Level of Study",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL Omani students learning English in Oman, clearly an EFL/ELL context focused on English vocabulary learning.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a mixed-method survey of existing AI tool use (Google Translate, dictionary apps, ChatGPT, chatbots, Duolingo). There is no experimental or quasi-experimental LLM-based instructional intervention; it only measures frequency of use and attitudes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is vocabulary learning strategies and attitudes toward AI tools, not writing competence or writing-related variables. Writing is mentioned only as a low-frequency use, not as a central outcome or instructional focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports quantitative data on frequency of AI tool use and attitudes, but does not report quantifiable writing outcomes or any measured change in writing performance resulting from an LLM-mediated writing intervention.""
    }
}"
619,Analyzing the Impact of Call Tools on English Learners' Writing Skills: a Comparative Study of Errors Correction,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as ESL/EFL learners (English as a second/foreign language), and the focus is on their English writing errors (spelling, verb forms, subject-verb agreement, etc.), indicating L2 English learners in appropriate contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention compares three CALL tools, including ChatGPT, which is a large language model, used as an instructional tool for error correction in writing. An experimental design with different classes (ChatGPT, Grammarly, Google Translate, control) is described, satisfying the requirement for an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on learners’ writing skills and common writing errors (spelling, punctuation, capitalization, verb forms, etc.). The tools are integrated into instruction to correct these errors, so the context is clearly writing competence rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an experimental pre/post design with quantifiable outcomes: frequencies or rates of eight types of writing errors before and after intervention across groups. These are measurable writing outcome metrics assessing the effectiveness of the LLM-mediated intervention (ChatGPT) relative to other tools and a control group.""
    }
}"
620,The Effects of Chatgpt on English Language Learning in Regards to Language Proficiency and Learning Motivation,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly refers to EFL students and English language learning, indicating a population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a review study: the author ‘selected eight targeted studies based on the STARLITE standards’ and ‘reviewed the studies’. It does not report an original experimental or quasi-experimental intervention; instead, it synthesizes prior work.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""Among the reviewed topics are ‘automated writing evaluation and writing ability’, indicating a focus on writing competence and related variables within English language learning.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a review of eight studies, it does not itself report primary, quantifiable writing outcome metrics from an intervention it conducts; it only ‘briefly summarized the influences’ of ChatGPT. Review articles are to be excluded.""
    }
}"
621,Undergraduate Esl Students’ Use and Perceptions of Chatgpt for Academic Writing Purposes; O Uso E as Percepções De Estudantes De Graduação Em Esl Sobre O Chatgpt Para Fins De Escrita Acadêmica,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are undergraduate ESL students in an intensive academic writing course at a public science and engineering institute in India, clearly indicating L2 English learners in an ESL academic writing context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a survey of students’ existing use and perceptions of ChatGPT. There is no mention of an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction; it is observational, not an intervention study.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly ESL academic writing, focusing on students’ use of ChatGPT to generate and review academic texts, summarise, and correct grammar and vocabulary in writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses Likert-scale, multiple-choice, and one open-ended item to examine use, trustworthiness, and utility perceptions. It reports no quantifiable writing performance outcomes or measures of writing competence; only attitudes and self-reported use are analyzed.""
    }
}"
622,Understanding Vietnamese English Majors' Use and Acceptance of Ai-powered Tools for English Academic Writing at University,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Vietnamese English majors (EFL learners) using AI tools for English academic writing at university, clearly fitting an L2 English EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates learners’ use and acceptance of various AI-powered tools, noting the popularity of Generative AI, but it does not describe an experimental or quasi-experimental instructional intervention integrating a specific LLM into writing instruction. It is a survey/interview study of existing practices and attitudes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly English academic writing in EFL tertiary settings, focusing on AI-assisted academic writing practice and related perceptions, which is writing-focused.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports questionnaire and interview data on use, acceptance, and perceptions (e.g., determinants of user acceptance, perceived advantages and concerns). It does not report quantifiable writing outcome metrics (e.g., changes in writing quality, scores, or measurable performance) resulting from an LLM-mediated intervention.""
    }
}"
623,Impact of Chatgpt on Esl Students’ Academic Writing Skills: a Mixed Methods Intervention Study,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 'undergraduate ESL students' and 'tertiary level ESL students,' indicating L2 English learners in an ESL context with a focus on English academic writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines 'the impact of ChatGPT as a formative feedback tool on the writing skills of undergraduate ESL students' and is described as a 'mixed methods intervention study,' indicating an experimental/quasi-experimental design integrating an LLM (ChatGPT) into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on 'students' academic writing skills' and the use of ChatGPT as a feedback tool in 'large-size writing classes.' The context is clearly writing instruction and development, not automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports that 'data were collected ... through three tests' and that 'findings indicate a significant positive impact of ChatGPT on students' academic writing skills,' implying quantifiable writing outcome measures were used to assess the intervention’s effectiveness.""
    }
}"
624,Detecting Contract Cheating through Linguistic Fingerprint,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 150 learners majoring in engineering and business who were studying English as a foreign language at a college in Saudi Arabia, clearly an EFL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions AI-based language models such as ChatGPT as a concern, the intervention studied is a machine learning model (TF-IDF + logistic regression) for detecting contract cheating, not an LLM integrated into writing instruction or writing processes. No LLM-based pedagogical intervention is implemented.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on detecting contract cheating via linguistic fingerprinting and academic integrity, not on improving writing competence or writing-related pedagogical outcomes. Writing is used as data for detection, not as the target of instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The reported quantitative outcomes are ML performance metrics (accuracy, precision, recall, F1-score) for detecting non-consistent essays, not measures of learners’ writing quality or development following an LLM-mediated writing intervention.""
    }
}"
625,"“chatgpt Is the Companion, Not Enemies”: Efl Learners’ Perceptions and Experiences in Using Chatgpt for Feedback in Writing",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 45 EFL learners in Macau, clearly indicating L2 English learners in an EFL context with focus on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines learners’ use of ChatGPT, an LLM, for feedback in their English writing process over a semester-long writing course, indicating an instructional context integrating an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL writing, focusing on the use of ChatGPT for feedback in writing and its impact on writing-related variables such as motivation, self-efficacy, engagement, and collaborative writing tendency.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports quantitative data from a questionnaire and qualitative interview data, focusing on perceptions and affective/behavioral variables (motivation, self-efficacy, engagement, collaboration). It does not indicate any objective or quantifiable writing performance outcomes (e.g., writing scores, text quality measures). Thus, no direct writing competence metrics are reported.""
    }
}"
626,Exploring Eap Students' Perceptions of Genai and Traditional Grammar-checking Tools for Language Learning,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are first-year students in an English for Academic Purposes (EAP) course at a Hong Kong university, i.e., L2 English learners in an EAP/ESL-type context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study explores perceptions of GenAI and traditional grammar-checking tools via interviews; it does not describe an experimental or quasi-experimental intervention integrating LLMs into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on perceptions and implications of GenAI in academic writing instruction, but not on a specific, structured writing intervention or measured change in writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The methodology is qualitative (semi-structured interviews) and reports perceptions, ethical and pedagogical implications; no quantifiable writing outcome metrics or experimental measures are mentioned.""
    }
}"
627,L2 Writer Engagement with Automated Written Corrective Feedback Provided by Chatgpt: a Mixed-method Multiple Case Study,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly refers to 'L2 writers' and 'L2 writing classrooms', indicating a population of second language learners engaged in English L2 writing pedagogy.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study investigates ChatGPT, a generative AI large language model, as an automated written corrective feedback (AWCF) provider in L2 writing, which constitutes an LLM-based intervention in the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is L2 writing classrooms and the use of ChatGPT for AWCF on 'writing products'. The focus is on engagement with feedback in the writing process, which is directly writing-related and pedagogical rather than assessment-only.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as a 'mixed-method multiple case study' focusing on behavioral, cognitive, and affective engagement, with data from prompt techniques, revision operations, strategies, and attitudes. The abstract does not indicate any experimental or quasi-experimental design measuring changes in writing quality or other quantifiable writing outcome metrics; it centers on engagement, not effectiveness of the intervention on writing performance.""
    }
}"
628,Examining the Relationship between the L2 Motivational Self System and Technology Acceptance Model Post Chatgpt Introduction and Utilization,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 35 second-year university English as a foreign language (EFL) students, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study includes two sessions of instructor-led ChatGPT usage writing workshops, indicating an intervention that integrates an LLM (ChatGPT) into writing activities.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the workshops involve ChatGPT usage for writing, the primary focus of the study is on the relationship between the L2 Motivational Self System and the Technology Acceptance Model post-ChatGPT introduction, not on writing competence or writing-related performance variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports survey-based correlations between L2MSS and TAM constructs (e.g., Ought-to L2 Self predicting Actual Usage). It does not mention any quantifiable writing outcome metrics or measures of writing performance resulting from the ChatGPT-mediated intervention.""
    }
}"
629,Gen Z Students and Their Perceptions of Technology in the Process of Second Language Acquisition Based on the Language Proficiency Level,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Gen Z students at different levels of English proficiency (A2–C2), indicating L2 English learners in an ESL/EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) and NMT are mentioned, the study is based on a survey of perceptions and self-reported use. There is no experimental or quasi-experimental design integrating LLMs into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on general second language acquisition and technology use (NMT and ChatGPT) across proficiency levels. Writing is only briefly mentioned (e.g., summary writing) as one of many uses, not as the primary focus or context of the study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports survey-based perceptions and usage patterns, not quantifiable writing outcome metrics or measured changes in writing performance following an LLM-mediated intervention.""
    }
}"
630,"Graduate Students’ Use of Chatgpt for Academic Text Revision: Behavioral, Cognitive, and Affective Engagement",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were six Iranian graduate ESL students revising academic research proposals, clearly indicating L2 English learners in an ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used for text revision, the study is observational/qualitative, examining how students engage with ChatGPT rather than implementing an experimental or quasi-experimental instructional intervention or treatment condition.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on academic text revision and use of ChatGPT for paraphrasing and improving professionalism in writing, which is directly related to L2 writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports behavioral, cognitive, and affective engagement and satisfaction, but does not mention any quantifiable writing outcome metrics (e.g., writing scores, quality ratings, accuracy measures) to assess effectiveness of the ChatGPT-mediated revision.""
    }
}"
631,Ai Language Models: an Opportunity to Enhance Language Learning,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract clearly refers to ‘second language writing’ and ‘language learners’ proficiency levels’, indicating an L2 learner population, though the target language is not explicitly stated as English. Given the context of ‘second language writing’ and ‘interlanguage development’, it is reasonable to infer L2 learners are the focus.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses AI language models to derive similarity metrics for quantitatively characterizing and indexing second language writing. There is no indication of an experimental or quasi-experimental pedagogical intervention where LLMs are integrated into instruction or learners’ writing processes; instead, LLMs are used as analytic tools.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on using similarity metrics from AI language models for writing proficiency assessment and studying interlanguage development, not on a teaching/learning intervention to improve writing competence. This aligns more with automated assessment/diagnostic research than with a writing instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study reports quantitative relationships between similarity metrics and human-rated writing scores, these are not outcomes of an LLM-mediated instructional intervention. There is no experimental manipulation of LLM use in teaching or writing practice, so no intervention effectiveness on writing outcomes is evaluated.""
    }
}"
632,The Impact of Using Interactive Chatbots on Self-directed Learning,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are fifty Omani EFL students, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is an ‘interactive chatbot’ implemented via WhatsApp, but there is no indication it is a large language model (e.g., ChatGPT, GPT-4). It appears to be a delivery platform for instructions and tests rather than an LLM-based generative tool.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing tasks are mentioned among several activities (grammar, reading comprehension), but the primary focus of the study is on self-directed learning, not specifically on writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports significant gains in self-directed learning abilities based on a questionnaire. While writing tasks were assigned, no specific, quantifiable writing outcome metrics (e.g., writing scores, quality measures) are reported in the abstract.""
    }
}"
633,Potential Uses and Concerns of Chatgpt in Efl Academic Writing Classrooms: a Preliminary Portrait,2024,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Only the title is available. It mentions 'EFL academic writing classrooms', which suggests L2 English learners in an EFL context, but without an abstract it is not certain that participants are actual EFL learners rather than a conceptual discussion.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The title refers to 'Potential Uses and Concerns of ChatGPT', which could indicate a conceptual or exploratory piece rather than an experimental or quasi-experimental intervention study. No abstract is available to confirm the presence of an LLM-based instructional intervention or study design.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus appears to be on EFL academic writing classrooms, which aligns with writing-related context, but without an abstract it is unclear whether the paper empirically investigates writing competence or is primarily a discussion of uses and concerns.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""There is no indication in the title that quantifiable writing outcome metrics are reported; it may be a preliminary, possibly descriptive or opinion-based portrait. Without an abstract, the presence of measurable writing outcomes cannot be confirmed.""
    }
}"
634,Enhancing English as a Foreign Language Academic Writing through Ai and Peer-assisted Learning,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a Foreign Language (EFL) learners. The course is an academic writing course in English, and all outcomes discussed relate to English writing proficiency.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention integrates an LLM-based tool, ChatGPT, into instruction: peer mentors in a PAL center used ChatGPT to provide personalized, immediate feedback on writing tasks. This is an applied pedagogical intervention using an LLM within a structured course.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on enhancing academic writing skills and writing proficiency. ChatGPT is used to give feedback on writing tasks, and the study examines improvements in academic writing, confidence, and engagement, not automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative pre- and post-tests assessing writing proficiency were administered, and the results indicated substantial improvements in writing scores. These constitute quantifiable writing outcome metrics for evaluating the LLM-mediated intervention.""
    }
}"
635,Efl Tertiary Teachers’ and Students’ Conceptualizations and Challenges of Using Ai Tools to Improve Writing Skills Ithailand and Vietnam during the Covid-19 Pandemic,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL tertiary teachers and students in Thailand and Vietnam, clearly L2 English learners/users in EFL contexts, with focus on English writing skills.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract refers generically to “AI tools (AITs)” without specifying large language models (e.g., ChatGPT, GPT-4). It focuses on perceptions and challenges of using unspecified AITs, not on an experimental or quasi-experimental LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly writing skills in EFL, examining how AI tools are used to improve writing and teaching writing during COVID-19. The primary focus is writing competence and related teaching/learning issues.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses questionnaires and interviews to explore perceptions and challenges. There is no indication of an intervention with pre/post or controlled measures of writing performance; outcomes are attitudinal/experiential rather than quantifiable writing gains from an LLM-mediated intervention.""
    }
}"
636,Efl Students’ Perception in Indonesia and Taiwan on Using Artificial Intelligence to Enhance Writing Skills,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students in Indonesia and Taiwan, described as second-year students specializing in English. The focus is clearly on English as a Foreign Language learners.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to ‘AI tools’ used in students’ writing processes but does not specify whether these are large language models (e.g., ChatGPT, GPT-4) or other AI tools (e.g., grammar checkers, paraphrasers). However, regardless of AI type, there is no described experimental or quasi-experimental intervention; the study is exploratory/qualitative.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is academic writing in EFL, the study focuses on students’ perceptions of AI use, not on a structured pedagogical intervention or instructional design integrating LLMs into writing instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses qualitative methods (semi-structured interviews, thematic analysis) and reports perceptions, benefits, and concerns. It does not report quantifiable writing outcome metrics or experimental measures of writing performance.""
    }
}"
637,Can Novice Teachers Detect Ai-generated Texts in Efl Writing?,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing and involves novice English teachers evaluating EFL learners’ texts, which aligns with L2 English settings (EFL).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although generative AI and AI-generated texts are central, the study is not an experimental or quasi-experimental intervention integrating LLMs into writing instruction or learners’ writing processes. It focuses on teachers’ ability to detect AI-generated writing.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on detection of AI-generated texts by novice teachers and their strategies, not on improving learners’ writing competence or writing-related pedagogical interventions.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics for learners are reported. The outcomes concern teacher detection performance and strategies, not LLM-mediated writing improvement.""
    }
}"
638,Exploring Chatgpt's Potential as an Ai-powered Writing Assistant: a Comparative Analysis of Second Language Learner Essays,2024,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The title mentions 'Second Language Learner Essays' but does not specify that the target language is English or that the context is ESL/EFL/ELL. Without an abstract, it is unclear whether the population is L2 English learners.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The title indicates exploration of ChatGPT as an AI-powered writing assistant, but does not clarify whether there is an experimental or quasi-experimental pedagogical intervention, or if it is only a comparative analysis of texts without instructional integration.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus on 'writing assistant' and 'Second Language Learner Essays' suggests a writing-related context, but it is unclear whether the study centers on writing competence or instead on system performance (e.g., text comparison) without an instructional context.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""No abstract is available, so it is unknown whether the study reports quantifiable writing outcome metrics (e.g., gains in writing quality) or only conducts a comparative analysis of essays without measuring intervention effects.""
    }
}"
639,Incorporating Ai in Foreign Language Education: an Investigation into Chatgpt’s Effect on Foreign Language Learners,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as 'preparatory class students studying at the School of Foreign Languages at a university in Turkey.' The target language is not explicitly stated as English in the title or abstract, only 'foreign language education' and 'foreign language learners.' It is therefore unclear whether they are L2 English learners or learners of another language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly uses ChatGPT, a large language model, in foreign language education. Students were 'introduced to ChatGPT through learning experiences over a span of four weeks by the researcher as a language teacher,' indicating an instructional intervention integrating an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract notes that ChatGPT 'positively affects students’ learning experiences, especially in writing, grammar, and vocabulary acquisition,' and mentions 'various learning activities.' Writing is a primary focus area among the targeted skills, aligning with writing-related instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as a 'qualitative case study' with data from interviews analyzed via thematic analysis. Outcomes are reported in terms of perceived effects on learning experiences, motivation, and engagement. There is no indication of quantitative writing outcome metrics or experimental/quasi-experimental measures of writing performance.""
    }
}"
640,Effects of an Ai-supported Approach to Peer Feedback on University Efl Students' Feedback Quality and Writing Ability,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 124 Chinese undergraduate English as a foreign language (EFL) students. The context is clearly EFL with English as the target language, matching the required L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention used an AI chatbot named Eva integrated into an online peer review system to assist students in generating feedback. However, the abstract does not specify whether Eva is a large language model (e.g., transformer-based generative model like ChatGPT/GPT-4) or a non-LLM AI tool. Without this information, it is unclear if the AI meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on EFL writing instruction, specifically peer feedback quality and the writing ability of student reviewers. The AI-supported approach is embedded in a writing-focused peer review process, aligning with the context of writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Pre- and post-tests were conducted to assess both feedback quality and the writing performance of feedback providers. The abstract reports that the intervention significantly enhanced feedback quality and improved writing ability, indicating quantifiable writing outcome measures.""
    }
}"
641,A Case Study of Implementing Generative Ai in University’s General English Courses,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners in Korean university-level general English courses, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions a 'generative AI-based instruction model' but does not specify that it is an LLM (e.g., ChatGPT, GPT-4) or provide details on the specific tool or model architecture. It could be any generative AI, not necessarily an LLM.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study refers to 'English instruction for writing and speaking' and 'supporting linguistic proficiency,' but the primary stated focus is on affective factors (motivation, interest, confidence). It is not clear that writing competence or writing-related variables are the primary focus of the intervention or analysis.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract specifies that the research investigated effects on affective factors (motivation, interest, confidence). It does not indicate that any quantifiable writing outcome metrics were collected or reported; writing is only mentioned as a domain of instruction, not as an assessed outcome.""
    }
}"
642,Detecting and Assessing Ai-generated and Human-produced Texts: the Case of Second Language Writing Teachers,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on second language writing teachers evaluating texts written by various authors (NS lecturer, NS student, NNS student, NNS lecturer, ChatGPT). There is no indication that the participants are L2 English learners; rather, they are teachers assessing texts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used to generate one of the essays, but there is no experimental or quasi-experimental integration of an LLM into writing instruction or learners’ writing processes. The study examines detection and assessment of AI vs. human texts, not an LLM-mediated pedagogical intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on teachers’ ability to detect and assess AI-generated versus human-produced texts, not on improving learners’ writing competence through an instructional intervention. It is an assessment/detection study rather than a writing pedagogy study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although scores are analyzed, they pertain to teacher ratings of different source texts (AI vs. human) and teachers’ identification strategies, not to changes in L2 learners’ writing outcomes following an LLM-based intervention. No quantifiable learner writing gains are reported.""
    }
}"
643,The Impact of Chatgpt on English Language Learners’ Writing Skills: an Assessment of Ai Feedback on Mobile,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as English as a second language (ESL) learners in a senior secondary public school in India. The focus is explicitly on English writing skills and common English grammatical errors.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT’s mobile application as the intervention, providing AI feedback on students’ writing. It employs a quasi-experimental design comparing ChatGPT feedback with traditional teacher feedback, clearly integrating an LLM into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on ESL writing skills, including grammar and composition proficiency, and the impact of ChatGPT feedback on common writing errors. This is a pedagogical intervention in writing, not an automated scoring study.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Quantitative writing outcomes are reported: pre- and post-test story-writing tasks, with measured reduction in specific error types and improved writing proficiency in the experimental group compared to the control group.""
    }
}"
644,Large Language Models and Automated Essay Scoring of English Language Learner Writing: Insights into Validity and Reliability,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses 119 essays from an English language placement test written by English language learners, indicating an ELL/L2 English population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""LLMs (PaLM 2, Claude 2, GPT-3.5, GPT-4) are used solely for automated essay scoring, not as part of an instructional or quasi-experimental writing intervention. There is no integration of LLMs into teaching or learners’ writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the validity and reliability of LLM-based automated essay scoring, not on improving writing competence or implementing a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports reliability and validity metrics of LLM scoring, not quantifiable outcomes of learners’ writing performance resulting from an LLM-mediated intervention.""
    }
}"
645,Evaluating Cami Ai across Samr Stages: Students’ Achievement and Perceptions in Efl Writing Instruction,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states that participants are 126 EFL (English as a Foreign Language) university students, indicating L2 English learners in an EFL context, with a focus on EFL writing instruction.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses “Cami, an AI-powered tool” and refers to “Cami AI technology,” but the abstract does not specify whether Cami is a large language model (e.g., ChatGPT-like, transformer-based generative model) or another type of AI (e.g., annotation, feedback, or grading tool). Without clarification that it is LLM-based, it is unclear if it meets the LLM intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly “EFL writing instruction,” and the study examines the impact of Cami AI-SAMR implementation on EFL students’ writing achievement, indicating a primary focus on writing competence within a pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that Cami AI-SAMR implementation “significantly impacted EFL students’ writing achievement,” implying quantitative measures of writing performance as outcomes, alongside qualitative perceptions.""
    }
}"
646,Advancing Efl Writing Proficiency in Jordan: Addressing Challenges and Embedding Progressive Strategies,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 150 Jordanian EFL students majoring in English across three public universities, clearly an EFL (L2 English) context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is descriptive and exploratory, using surveys and semi-structured interviews. AI, including potential LLM tools, is only mentioned as a prospective strategy; no actual AI/LLM-based intervention or experimental/quasi-experimental design is implemented.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus is on EFL writing challenges and strategies, there is no implemented writing instruction or intervention using LLMs; AI is discussed conceptually as a possible future tool, not as a tested pedagogical context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports challenges and proposed strategies but does not report quantifiable writing outcome metrics from an AI/LLM-mediated intervention. Data are survey statistics and thematic analysis, not experimental writing performance outcomes linked to LLM use.""
    }
}"
647,Can Chatgpt Reliably and Accurately Apply a Rubric to L2 Writing Assessments? the Devil Is in the Prompt(s),2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to 'second language (L2) writing' and is published in the Journal of Technology and Chinese Language Teaching. It is unclear whether the target language is English or Chinese, and no explicit mention of ESL/EFL/ELL or English writing is made.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates ChatGPT as an assessment tool, focusing on accuracy and reliability of AI-generated scores compared to human raters and the impact of prompting strategies. There is no indication of an instructional or quasi-experimental pedagogical intervention integrating ChatGPT into L2 writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on L2 writing assessment—using ChatGPT to score writing and examining reliability and accuracy. This aligns with automated essay scoring functionality rather than a pedagogical writing intervention aimed at improving learners’ writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported concern the accuracy and reliability of ChatGPT’s scores relative to human raters and across topics, not quantifiable changes in learners’ writing performance following an LLM-mediated intervention.""
    }
}"
648,Paraphrase or Plagiarism? Exploring Eap Students’ Use of Source Material in a Transnational University Context,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states that the study investigates English as a Second Language (ESL) student writers in an English for Academic Purposes (EAP) context, which fits the target L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions Generative AI and students’ confidence in technological tools, there is no indication of an experimental or quasi-experimental intervention integrating an LLM (e.g., ChatGPT) into writing instruction or processes. The study is exploratory, focusing on students’ paraphrasing practices and perceptions, not on an LLM-based instructional treatment.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on academic writing practices—specifically paraphrasing, plagiarism, and use of source material in EAP writing—clearly a writing-related context rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a text-based interview method and a custom-designed writing task to explore how students make decisions about source use. The abstract reports qualitative insights (e.g., focus on sentence-level paraphrasing, low confidence in tools) but does not mention any quantifiable writing outcome metrics or experimental measures of intervention effectiveness.""
    }
}"
649,Improving Writing Feedback for Struggling Writers: Generative Ai to the Rescue?,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions students with and without disabilities who struggled with writing and notes that AI feedback did not reflect student characteristics such as ELL status. However, it does not specify that the target population is L2 English learners in ESL/EFL/ELL contexts, nor that the analysis focuses specifically on English as an L2.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study imports existing student essays into two versions of ChatGPT and analyzes the feedback and instructional suggestions generated, comparing them with teachers’ feedback. This is an evaluation of AI-generated feedback quality, not an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or writing processes for learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is writing instruction and feedback, the primary focus is on comparing AI and teacher feedback via thematic analysis, not on implementing an LLM-mediated instructional intervention aimed at improving learners’ writing competence. It is more a functionality/feasibility study of AI feedback than a pedagogical intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses inductive thematic analysis of AI and teacher responses. There is no indication of quantitative writing outcome measures (e.g., pre/post writing scores, rubric-based gains) assessing the effectiveness of an LLM-mediated intervention on student writing performance.""
    }
}"
650,Efl Learners’ Attitudes towards Utilizing Chatgpt for Acquiring Writing Skills in Higher Education: a Case Study of Computing Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners: fifty-two students at a private university in Sharjah taking an English language course. The focus is on acquisition of English writing skills, clearly an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT is mentioned, the study is described as exploring students’ attitudes towards utilizing ChatGPT. There is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction; rather, it is an attitudinal case study using a questionnaire and interviews.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly writing-focused: acquisition of writing skills in English as a foreign language and ChatGPT-based essay writing versus self-dependent essay writing. The primary focus is on writing competence and related skills.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are students’ attitudes and perceptions (e.g., time-saving, language accuracy, limited progress in higher-order thinking). There is no mention of quantifiable writing performance measures (e.g., writing scores, rubric-based assessments) used to evaluate the effectiveness of ChatGPT-mediated writing intervention.""
    }
}"
651,Detecting Chatgpt-generated Essays in a Large-scale Writing Assessment: Is There a Bias Against Non-native English Speakers?,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study involves GRE writing assessment data that likely includes non-native English speakers, the focus is not on L2 learners’ development or instruction but on detector bias. Participants are not clearly framed as L2 English learners in ESL/EFL/ELL contexts for pedagogical purposes.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study develops detectors of ChatGPT-generated essays using linguistic and perplexity features. ChatGPT is only the source of generated texts; there is no experimental or quasi-experimental integration of an LLM into writing instruction or writing processes as an intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on AI-generated text detection performance and bias, not on improving writing competence or writing-related pedagogical variables. It is essentially an assessment/detection study, not a writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics related to learners’ writing development or performance under an LLM-mediated intervention are reported. Outcomes concern detector accuracy and bias, not changes in writing quality or related constructs.""
    }
}"
652,Testing the Viability of Chatgpt as a Companion in L2 Writing Accuracy Assessment,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses the Cambridge Learner Corpus First Certificate in English (CLC FCE), which consists of L2 English learner writing. The focus is clearly on L2 English writing accuracy.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used as an automated evaluator of linguistic accuracy, not as part of an experimental or quasi-experimental instructional intervention in which learners use the LLM during writing or receive LLM-mediated instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on validating ChatGPT as an automated accuracy assessment tool, comparing it to human raters and Grammarly. There is no pedagogical writing intervention; it is a functionality/assessment study rather than a teaching or learning context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports correlations between ChatGPT’s accuracy assessments and human ratings, but does not report writing outcome changes resulting from an LLM-mediated intervention. No experimental manipulation of instruction or learner use of ChatGPT is described.""
    }
}"
653,"A Meta-analysis of Effects of Automated Writing Evaluation on Anxiety, Motivation, and Second Language Writing Skills",2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to second language (L2) writing skills but does not specify that the population is L2 English learners in ESL/EFL/ELL contexts, nor that the target language is English specifically.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a PRISMA-based meta-analysis of automated writing evaluation (AWE) technologies in general, not specifically of LLM-based tools (e.g., ChatGPT, GPT-4). It also does not describe an experimental or quasi-experimental intervention conducted by the authors; instead, it synthesizes prior studies.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus includes L2 writing skills, the article is a meta-analysis rather than a primary study implementing a pedagogical intervention. Review and meta-analytic studies are to be excluded by design.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The article aggregates effects of AWE on anxiety, motivation, and L2 writing skills but does not itself report original experimental outcome data from an LLM-mediated writing intervention. As a meta-analysis, it falls under excluded publication types.""
    }
}"
654,Understanding Efl Students’ Use of Self-made Ai Chatbots as Personalized Writing Assistance Tools: a Mixed Methods Study,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 69 Chinese undergraduate EFL students, clearly L2 English learners in an EFL context, and the focus is on English writing (‘learning to write’, ‘writing processes’).""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""Students created self-made RAG chatbots using Poe to assist with their writing processes. These are LLM-based chatbots integrated as tools in a pedagogical workshop, fitting the LLM intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly writing-focused: chatbots assist with idea generation, outlines, and error identification in writing. The study examines chatbots as pedagogical tools for personalized writing assistance, not as scoring systems.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Reported outcomes are motivational and attitudinal: clearer writing goals, increased confidence, reinforced beliefs, and more positive attitudes. The abstract does not indicate any quantitative writing performance metrics (e.g., scores, quality ratings, accuracy measures); the focus is on motivation rather than measurable writing competence.""
    }
}"
655,Chatgpt for L2 Learning: Current Status and Implications,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a review of 44 studies on ChatGPT for L2 learning, not an empirical study with its own participant sample. Thus, it does not itself involve a defined population of L2 English learners as participants in an intervention.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a systematic/overview-type study summarizing prior research on ChatGPT for L2 learning. It does not implement an experimental or quasi-experimental LLM-based writing intervention itself; it only reviews others’ interventions.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing skills are mentioned as a major objective in the reviewed studies, the article’s primary focus is synthesizing literature across multiple dimensions (roles, theories, methods, outcomes), not conducting a specific writing-focused pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study does not report original, quantifiable writing outcome metrics from an intervention; it summarizes benefits, challenges, and outcomes from other studies. As a review article, it falls under the exclusion criteria for non-primary research.""
    }
}"
656,"The Metaphor of Ai in Writing in English: a Reflection on Efl Learners’ Motivation to Write, Enjoyment of Writing, Academic Buoyancy, and Academic Success in Writing",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 86 intermediate EFL students from China in an English as a foreign language context, clearly L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is described as 'automated writing evaluation (AWE)'; no indication is given that this system is an LLM (e.g., ChatGPT, GPT-4, transformer-based generative model). AWE tools are typically non-LLM automated scoring/feedback systems, which fall outside the review’s inclusion criteria.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on fostering learners’ writing skills and related constructs (motivation to write, enjoyment of writing, academic buoyancy, academic success in writing), which are writing-related variables in an instructional context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports quantitative outcomes (one-way MANOVA) showing differences between groups in motivation to write, enjoyment in writing, academic buoyancy, and academic success in writing, indicating measurable writing-related outcomes.""
    }
}"
657,Effect of Editgpt on the Learners` Autonomy and Learning Anxiety,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 30 Omani EFL learners, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention used EditGPT, described as an AI application and automated writing evaluation system, integrated into instruction for the experimental group. Given the name and context, it is reasonably inferred to be an LLM-based tool.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although EditGPT is used in the context of English writing instruction, the primary focus of the study is on learning anxiety and learner autonomy, not on writing competence or writing-related performance variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes measured are foreign language anxiety and learner autonomy via questionnaires and scales. No quantifiable writing performance or writing quality metrics are reported to assess the effectiveness of the LLM-mediated writing intervention on writing outcomes.""
    }
}"
658,"Chatgpt-empowered Writing Strategies in Efl Students’ Academic Writing: Calibre, Challenges and Chances",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 60 Chinese university juniors majoring in English (EFL context), and the focus is explicitly on English academic writing for EFL students.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates current usage, potential applications, limitations, and perceptions of ChatGPT via a questionnaire and focus group interviews. There is no indication of an experimental or quasi-experimental instructional intervention where ChatGPT is systematically integrated into writing instruction or processes with controlled conditions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly English academic writing and writing strategies (planning, composing, revising) for EFL students, focusing on how ChatGPT can empower academic writing strategies.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although mixed methods and regression analysis are mentioned, the abstract does not report quantifiable writing outcome metrics (e.g., changes in writing scores, quality, accuracy). The outcomes are about perceived empowerment of writing strategies and reported uses, not measured changes in writing performance following an intervention.""
    }
}"
659,Exploring the Use of Chatgpt as a Tool for Written Corrective Feedback in an Efl Classroom,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are five Form Four students in a Band 2 secondary school in Hong Kong, clearly an EFL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT explicitly as a writing feedback-giving tool, integrated into students’ writing and revision sessions, which fits an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing: students write tasks and revise them based on ChatGPT’s written corrective feedback. The focus is on written corrective feedback and its effectiveness in writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes exploration of cognitive factors and students’ perceptions via stimulated recall interviews. It does not report any quantitative or experimental writing outcome measures (e.g., scores, accuracy gains, quality ratings) to assess effectiveness; the findings are qualitative (two factors related to effectiveness, students’ valuing of feedback).""
    }
}"
660,Tapping into the Pedagogical Potential of Infinigochatic: Evidence from Iwrite Scoring and Comments and Lu & Ai’s Linguistic Complexity Analyzer,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are postgraduate students taking an English reading and writing course in Southwest China, clearly functioning as L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares L2 learner writings with versions polished by infinigoChatIC (a ChatGPT-based tool) using a single prompt by the teacher. There is no experimental or quasi-experimental pedagogical intervention where learners use the LLM as part of instruction or their writing process; it is essentially a text-transformation/comparison study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on how LLM-polished texts differ from learner texts in quality and complexity, scored by iWrite and analyzed by a complexity analyzer. This is an evaluation of LLM output characteristics rather than a teaching/learning intervention aimed at developing learners’ writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although quantitative measures (iWrite scores, lexical and syntactic complexity) are reported, they assess the difference between original and LLM-polished texts, not outcomes of an LLM-mediated instructional intervention on learners’ own writing performance over time.""
    }
}"
661,Beyond Syntax: Exploring Moroccan Undergraduate Efl Learners’ Engagement with Ai-assisted Writing,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Moroccan undergraduate EFL learners in a general English course at the International University of Rabat. The abstract explicitly states they are EFL learners and the focus is on English writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “AI-supported writing tools” and “AI assistance” but does not specify whether these are large language model-based tools (e.g., ChatGPT, GPT-4) or other AI tools (e.g., grammar checkers). Without explicit mention of LLMs or transformer-based generative models, it is unclear if the intervention meets the LLM criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on writing: it examines “student-written assignments,” “the writing process,” and the impact of AI tools on writing quality, including organization, vocabulary, and creativity. The context is clearly writing instruction/performance rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""It is a quasi-experimental study with a control group and reports “positive outcomes in language proficiency, creativity, organizational skills, and vocabulary use,” implying quantifiable writing-related outcome measures were used to assess the effect of AI-assisted writing.""
    }
}"
662,Harnessing Ai Chatbots for Efl Essay Writing: a Paradigm Shift in Language Pedagogy,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on English as a foreign language (EFL) essay writing and on English learners, which fits the target population of L2 English learners in EFL contexts.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study discusses “Artificial Intelligence chatbots” in general but does not specify that they are large language model (LLM)-based tools (e.g., ChatGPT, GPT-4). However, even if they were LLMs, the paper is described as a review rather than an experimental or quasi-experimental intervention study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus is on essay writing and writing proficiency, the article is characterized as “a comprehensive review” presenting insights into pedagogical benefits and challenges, not as an empirical pedagogical intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any experimental or quasi-experimental design, nor any quantifiable writing outcome metrics. It is framed as a review of potential and challenges, not as a study reporting measured effects on writing performance.""
    }
}"
663,Investigating Students’ Cognitive Processes in Generative Ai-assisted Digital Multimodal Composing and Traditional Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) writers, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study investigates generative AI-assisted composing using ChatGPT, Bing Chat, and Bing Image Creator, which are LLM-based tools integrated into students’ composing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on cognitive processes in generative AI-assisted multimodal composing versus traditional writing, not on a pedagogical writing intervention aimed at improving writing competence. It is a qualitative process-tracing study rather than an instructional intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative analyses of composing processes and patterns in text production but does not mention any quantifiable writing outcome metrics (e.g., scores, rubric-based assessments, measurable gains) to evaluate the effectiveness of the AI-assisted writing.""
    }
}"
664,Generative Artificial Intelligence in the Efl Writing Context: Students' Literacy in Perspective,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as language learners in an EFL writing context, focusing on English as a foreign language writing skills.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a descriptive-survey method to detect learners’ generative AI literacy. There is no indication of an experimental or quasi-experimental intervention integrating LLMs into instruction or writing processes; it only measures literacy/awareness and perceptions.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is EFL writing, the primary focus is on students’ literacy regarding generative AI tools (challenges, affordances, suggestions), not on a pedagogical writing intervention or structured use of LLMs to develop writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports questionnaire and interview results about AI literacy levels and related factors (GPA, mastery level), but does not report quantifiable writing outcome metrics or changes in writing performance following an LLM-mediated intervention.""
    }
}"
665,Patterns of Utilizing Ai–assisted Tools among Efl Students: Need Surveys for Assessment Model Development,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Indonesian EFL university students, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a survey of AI-tool utilization patterns based on TAM. There is no experimental or quasi-experimental design integrating LLMs into instruction; tools mentioned (Grammarly, Google Translate) are not specified as LLM-based interventions in a pedagogical experiment.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on technology acceptance and usage patterns of AI tools in general, not on writing competence or writing-related instructional interventions. It is preliminary data for assessment-model development, not a writing-focused intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes relate to perceived ease of use, usefulness, and technology acceptance, not to changes in writing performance.""
    }
}"
666,Chatgpt as an Artificial Intelligence (ai) Writing Assistant for Efl Learners: an Exploratory Study of Its Effects on English Writing Proficiency,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL learners in an English writing classroom. The focus is on English writing proficiency, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses ChatGPT, a large language model, as an AI Writing Assistant. The design is experimental with control (traditional instruction) and experimental (ChatGPT use in pre- and post-writing stages) groups over 10 weeks.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on English writing proficiency and the use of ChatGPT in the writing process (content planning, interaction, tailored feedback) within an English writing classroom, i.e., a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: the experimental group showed better writing proficiency in terms of content, structure, and language use compared with the control group, based on writing tasks over 10 weeks.""
    }
}"
667,"Proceedings of the 9th International Conference on Information and Education Innovations, Iciei 2024",2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract is for a proceedings volume listing multiple papers. One listed paper is “ChatGPT as an artificial intelligence (AI) writing assistant for EFL learners: an exploratory study of its effects on English writing proficiency,” which likely involves EFL learners (L2 English). However, no participant details are provided at the proceedings level, and the volume includes many non-L2 studies.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The listed ChatGPT paper title suggests an LLM-based writing assistant intervention, but the proceedings abstract itself does not describe any specific experimental or quasi-experimental design, only that such a paper exists within the volume.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The proceedings cover diverse topics (robots, biology teaching resources, blockchain, etc.). Only one paper title clearly relates to EFL writing with ChatGPT, but the proceedings abstract does not focus on writing competence or writing-related variables as the primary context.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The title of the ChatGPT paper mentions “effects on English writing proficiency,” implying quantitative outcomes, but the proceedings abstract does not report any specific writing outcome metrics or confirm that such data are presented in that paper.""
    }
}"
668,Enhancing English as a Foreign Language (efl) Learners’ Writing with Chatgpt: a University-level Course Design,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as university-level English as a Foreign Language (EFL) learners in a writing course, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study integrates OpenAI’s GPT-3.5 (a large language model) into a university-level EFL writing course, framed within ADDIE and TPACK for instructional design. This indicates an LLM-based pedagogical intervention in writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on enhancing EFL learners’ writing, including efficiency, organization, and feedback in academic writing. GPT-3.5 is used as part of the writing process (feedback, idea generation, organization), aligning with writing competence as the primary context.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports that GPT-3.5 ‘enhances efficiency,’ ‘ensures cohesive organization,’ and ‘promotes writing proficiency,’ but it does not specify any experimental or quasi-experimental design, control/comparison, or quantifiable writing outcome metrics. It may be descriptive or design-focused rather than reporting measurable intervention effects; this cannot be confirmed from the abstract alone.""
    }
}"
669,Exploring the Feasibility and Efficacy of Chatgpt3 for Personalized Feedback in Teaching,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions 'student writing' and 'language learning' but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor that the target language is English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT-3 (an LLM) is used, the design focuses on evaluating the reliability of AI-generated feedback and rubric-based grading compared with human grading. There is no described experimental or quasi-experimental pedagogical intervention integrating ChatGPT into writing instruction or writing processes for learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on feasibility, reliability, and pedagogical implications of AI feedback and rubric-based grading, not on a structured writing competence intervention. It resembles an evaluation of AI as an assessment/feedback tool rather than a teaching intervention targeting writing development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares AI and human grading of student writing to assess reliability of AI feedback. It does not report quantifiable pre/post or between-group writing outcome measures to evaluate the effectiveness of an LLM-mediated writing intervention on learners’ writing performance.""
    }
}"
670,To Resist It or to Embrace It? Examining Chatgpt’s Potential to Support Teacher Feedback in Efl Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese undergraduate students writing English argumentative essays in an EFL context, and the focus is explicitly on writing English as a Foreign Language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, the study is exploratory and compares ChatGPT-generated feedback with teacher feedback; it does not implement an experimental or quasi-experimental pedagogical intervention where learners use ChatGPT within a structured writing instruction or process.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on evaluating ChatGPT’s potential to support teacher feedback and comparing characteristics of ChatGPT vs. teacher feedback, plus teachers’ perceptions. It does not describe an instructional intervention targeting learners’ writing development; rather, it is a tool/functionality and perception study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcome metrics (e.g., pre/post writing scores, quality ratings) are reported. The study analyzes amount and type of feedback and teacher perceptions, not changes in students’ writing performance following an LLM-mediated intervention.""
    }
}"
671,"Using Llms to Bring Evidence-based Feedback into the Classroom: Ai-generated Feedback Increases Secondary Students’ Text Revision, Motivation, and Positive Emotions",2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were N = 459 upper secondary students of English as a foreign language, clearly indicating L2 English learners in an EFL context and that the writing task was in English.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention used the LLM GPT-3.5-turbo to generate automated feedback on students’ argumentative essays. The design is randomized controlled, comparing an experimental group receiving LLM-generated feedback with a control group receiving no feedback.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on writing proficiency and text revision. Students wrote and revised argumentative essays, and the LLM was integrated specifically to provide feedback on writing, making writing competence the central outcome domain.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: improvement in revision performance assessed via automated essay scoring, with effect size (d = .19). Additional quantitative outcomes include task motivation and positive emotions, but the primary outcome is writing revision quality.""
    }
}"
672,"“brave New World” or Not?: a Mixed-methods Study of the Relationship between Second Language Writing Learners’ Perceptions of Chatgpt, Behaviors of Using Chatgpt, and Writing Proficiency",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'second or foreign language (L2) writing learners' at university level, implying L2 English writing learners in an L2 writing course context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines learners’ perceptions and self-reported usage behaviors of ChatGPT; there is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction or processes. It is correlational rather than an intervention study.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on L2 writing proficiency (complexity, accuracy, fluency) and learners’ use of ChatGPT as an AI-based writing tool, which is directly related to writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcome metrics: L2 writing proficiency operationalized as complexity, accuracy, and fluency, and examines how ChatGPT usage predicts these outcomes.""
    }
}"
673,"Three-wave Cross-lagged Model on the Correlations between Critical Thinking Skills, Self-directed Learning Competency and Ai-assisted Writing",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly refers to “EFL learners,” indicating participants are English as a Foreign Language learners and thus L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study concerns “AI-assisted writing” and “AI-assisted tools,” but it does not specify that these are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems. They could be other AI tools (e.g., grammar checkers). No explicit LLM is mentioned, and the design appears observational (cross-lagged model) rather than an instructional intervention integrating a specific LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on “AI-assisted writing” in English and examines how critical thinking skills and self-directed learning relate to this writing activity. The context is clearly writing-related, not automated scoring or non-pedagogical system evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although participants completed “a writing task” and the study uses a cross-lagged model, the abstract does not describe any experimental or quasi-experimental intervention using AI tools to improve writing, nor does it report pre/post or comparative writing outcome measures to assess the effectiveness of an LLM-mediated intervention. It focuses on correlations among constructs rather than intervention outcomes.""
    }
}"
674,Improving Efl Students’ Cultural Awareness: Reframing Moral Dilemmatic Stories with Chatgpt,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is situated in a Chinese EFL context and discusses EFL teachers and students, indicating that the population is L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT (an LLM) is used, but only as a tool for teachers to co-produce moral dilemmatic stories and teaching materials. There is no indication of an experimental or quasi-experimental design integrating LLMs into students’ writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on generating culturally appropriate EFL teaching materials and analyzing cultural biases in AI-generated stories to foster cultural awareness. The context is material development and cultural appraisal, not writing competence or writing-related performance outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports appraisal analysis of cultural values in AI-generated texts and proposes a prompt-engineering method, but does not mention any quantifiable writing outcome metrics for learners or any measured impact on students’ writing.""
    }
}"
675,Is Artificial Intelligence for Everyone? Analyzing the Role of Chatgpt as a Writing Assistant for Medical Students,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are medical students taking an English academic writing course. The abstract explicitly refers to their 'English academic writing skills,' indicating they are L2 English learners in an EFL/ESL academic context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT as a 'writing assistant' and compares an experimental group using ChatGPT with a control group receiving conventional writing training, indicating an experimental/quasi-experimental LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on academic writing competence, examining whether ChatGPT enhances English academic writing skills and its impact on components such as content, organization, vocabulary, mechanics, and language use. This is clearly a pedagogical writing intervention, not automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports 'significant impact' with 'large effect sizes' on English academic writing skills and specific components, implying quantitative outcome measures of writing performance were collected and analyzed.""
    }
}"
676,Llm-as-a-tutor in Efl Writing Education: Focusing on Evaluation of Student-llm Interaction,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states the context is English as a Foreign Language (EFL) writing education and refers to EFL learners, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study clearly involves LLMs used as tutors providing essay feedback, but it is not explicit whether there is an experimental or quasi-experimental intervention design (e.g., controlled treatment, pre/post, or comparison group) versus a purely evaluative/observational study of interactions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL writing education and LLM-as-a-tutor providing essay feedback, with evaluation criteria tailored to EFL writing education. This aligns with writing competence and writing-related variables rather than automated scoring alone.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract notes that EFL learners assess their ‘learning outcomes from interaction with LLM-as-a-tutor,’ but it does not specify whether these outcomes are quantified writing performance measures (e.g., scores, rubric-based writing quality) or only self-reported perceptions. Thus, it is unclear if quantifiable writing outcome metrics are reported.""
    }
}"
677,Comparing Individual Vs. Collaborative Processing of Chatgpt-generated Feedback: Effects on L2 Writing Task Improvement and Learning,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 117 sophomore EFL learners at a Chinese university, clearly indicating L2 English learners in an EFL context. The focus is on L2 writing, which in this context is English.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is a seven-week experiment using ChatGPT-generated feedback integrated into writing instruction. Different experimental conditions (individual vs. collaborative processing with teacher/peer) indicate an experimental design involving an LLM (ChatGPT).""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 writing development, specifically how processing ChatGPT-generated feedback affects writing task improvement and learning. This is a pedagogical intervention, not an evaluation of ChatGPT as an automated scoring tool.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing outcomes are quantitatively measured as gain scores from draft to final products across three during-intervention writing tasks and performance on a post-intervention similar new writing task. These are clear, quantifiable writing outcome metrics.""
    }
}"
678,Ai-enhanced Collaborative Story Writing in the Efl Classroom,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are students in compulsory English-as-a-foreign-language (EFL) classes at a Japanese university, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The tool Collabowrite includes AI features such as grammar checks, virtual group members, artwork generation, and story narration, but the abstract does not specify that these are powered by large language models (e.g., ChatGPT/GPT-like transformer-based generative models) rather than other AI techniques.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is collaborative story writing in EFL classes, with AI-enhanced collaborative writing tools; the primary pedagogical focus is on writing and writing-related classroom dynamics.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Reported outcomes are AI grammar-check accuracy, adherence to AI guidance, enjoyment ratings, and shifts in perceptions toward English writing, collaboration, and technology. There are no quantifiable writing performance measures (e.g., writing quality, complexity, accuracy) reported; outcomes are primarily attitudinal and system-performance metrics.""
    }
}"
679,Efl Learners’ Motivation and Acceptance of Using Large Language Models in English Academic Writing: an Extension of the Utaut Model,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as EFL learners engaged in business-related English academic writing, which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study involves learners who completed a semester of training in using LLMs (e.g., ChatGPT) for English academic writing, indicating integration of LLMs into writing instruction, even though the design is not intervention-effect focused.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on motivation and technology acceptance (UTAUT, L2 Motivational Self System) regarding LLM use, not on writing competence or writing-related performance variables. Writing is the context, but not the main outcome of interest.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports structural relationships among motivational and acceptance variables and use behavior; it does not report quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity) to assess the effectiveness of the LLM-mediated writing intervention.""
    }
}"
680,Enhancing Efl Writing Skills for Adult Deaf and Hard of Hearing Individuals,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as Deaf and hard of hearing learners developing English as a Foreign Language (EFL) writing skills, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is mentioned among the internet tools used, the abstract does not describe an experimental or quasi-experimental design integrating LLMs into instruction. It appears to be an exploratory study of tool use and perceptions rather than a structured LLM-mediated intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on EFL writing skills, writing quality, coherence, and confidence, not on automated scoring or system evaluation. Thus, the primary context is writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are participants’ perceptions that tools improved vocabulary, grammar, coherence, and confidence. The abstract does not indicate any quantifiable writing outcome metrics or experimental measures; it appears to rely on self-reported perceptions and qualitative findings.""
    }
}"
681,Indocl: Benchmarking Indonesian Language Development Assessment,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are L2 learners of Indonesian: “IndoCL corpus (Indonesian Corpus of L2 Learners), which comprises compositions written by undergraduate students majoring in Indonesian language.” The target language is Indonesian, not English, so it does not match the review’s focus on L2 English learners.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study explores “the feasibility of using existing large-scale language models (LLMs) for LDA tasks,” but this is in the context of automated language development assessment, not an instructional or quasi-experimental pedagogical intervention in writing. It is unclear whether LLMs are integrated into teaching or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is language development assessment (LDA) and benchmarking models for that task, not on writing instruction or improving writing competence. It is essentially an automated assessment/benchmarking study, not a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported concern model performance on LDA tasks (“remarkable performance on both our self-constructed corpus and publicly available corpora”), not quantifiable effects of an LLM-mediated writing intervention on learners’ writing quality. No experimental instructional outcomes are described.""
    }
}"
682,Exploring the Influence of Ai and Chatgpt on University Efl Learners,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are clearly described as university-level English as a Foreign Language (EFL) learners, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly investigates the use of ChatGPT (an LLM) and other AI tools in an experimental design with experimental and control groups, integrating AI-powered customized learning and feedback into instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary outcome is grammatical proficiency and grammatical accuracy, with a secondary focus on related language skills. Writing is only used as a vehicle for reflective essays to capture perceptions, not as the main instructional or assessment focus. The context is grammar learning, not writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantitative outcomes reported concern grammatical competence and grammatical accuracy, not writing performance metrics. Reflective essays are used qualitatively to explore perceptions, not to measure changes in writing quality. Thus, no quantifiable writing outcome metrics are reported.""
    }
}"
683,Students’ Engagement in Seeking and Accepting Chatgpt Feedback in Essay Writing: a Study of Second Language Learners at Varying Proficiency Levels,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The title and abstract indicate the participants are second language learners engaged in academic English writing, which aligns with L2 English learners in an ESL/EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used as a feedback tool, the study is described as a case study focusing on utilization patterns, human-computer interaction, and interviews. There is no indication of an experimental or quasi-experimental design testing an instructional intervention; it is exploratory/descriptive.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly L2 academic English essay writing and the use of ChatGPT feedback during the writing process, which is directly related to writing competence and writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative findings about metacognitive strategies and perceptions at different proficiency levels. It does not mention any quantifiable writing outcome measures (e.g., scores, accuracy, complexity) to assess the effectiveness of ChatGPT-mediated intervention.""
    }
}"
684,"The Effects of a Quillbot-based Intervention on English Language Majors’ Efl Writing Performance, Apprehension, and Self-efficacy",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 18 fourth-year students majoring in English in the English Language Department at Matrouh University, explicitly described as EFL learners. The focus is on EFL writing performance, so the population criterion is satisfied.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is explicitly described as a “QuillBot-based intervention.” QuillBot is an AI-powered writing assistant primarily known as a paraphrasing and grammar tool and is not clearly an LLM-based, transformer generative model in the sense required (e.g., ChatGPT, GPT-4, Gemini). The abstract does not indicate integration of a large language model; it only mentions AI-generated feedback via QuillBot, which falls under excluded tools per the guidelines.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL writing performance and related affective variables (writing apprehension and self-efficacy). The intervention involves drafting, receiving AI-generated feedback, revising, and producing final drafts, which is clearly a writing instruction/writing process context rather than automated essay scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a pre/post design with “one test and two scales” administered before and after the intervention to measure writing performance, apprehension, and self-efficacy. It reports “significant positive effects” on writing performance, indicating quantifiable outcome metrics for the writing intervention.""
    }
}"
685,Developing an Ai-enhanced Video Drama-making Learning System to Support Efl Learners in Authentic Contexts,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL university students, clearly L2 English learners in an EFL context: “improve English as a Foreign Language (EFL) learning… involving sixty-three university students.”""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The system uses “GPT-generated sentences,” which suggests an LLM-based component, but the abstract does not specify whether this is a large language model (e.g., GPT-3/4) or how it is integrated pedagogically into instruction versus as a background feature.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on an AI-enhanced video drama-making system and its evaluation via the Technology Acceptance Model (TAM), emphasizing usability, usefulness, and attitudes. Writing is mentioned only briefly (“enhancing their speaking and writing skills”) without clear indication that writing competence or writing-related variables are the main focus of the intervention or analysis.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are TAM constructs (usability, usefulness, attitudes). The abstract does not report any quantifiable writing outcome metrics (e.g., writing scores, text quality measures) to assess the effectiveness of the AI/LLM component on writing performance.""
    }
}"
686,Exploring the Impact of Ai in Language Education: Vietnamese Efl Teachers’ Views on Using Chatgpt for Fairy Tale Retelling Tasks,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Vietnamese tertiary-level English as a Foreign Language (EFL) teachers discussing students’ fairy tale retelling writing tasks in English, which fits an EFL/ESL/ELL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is the focal technology, the study is purely qualitative and perception-based, using semi-structured interviews with teachers. There is no experimental or quasi-experimental design implementing ChatGPT as an actual classroom writing intervention with measured effects.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context explicitly involves students’ fairy tale retelling writing tasks, which are writing-focused. The article examines how ChatGPT might be integrated into these writing activities, aligning with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports only qualitative perceptions (challenges and opportunities) from teachers. It does not report any quantifiable writing outcome metrics or measured changes in students’ writing performance resulting from an LLM-mediated intervention.""
    }
}"
687,Synergizing Generative Pre-trained Transformer (gpt) Chatbots in a Process-based Writing Paradigm to Enhance University Students’ Writing Skill,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 'university EFL students,' indicating learners of English as a foreign language. The focus of the study is on their English writing skills (organization, content, coherence-cohesion, logical connection, argumentation), satisfying the requirement that the target language is English in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is 'a GPT-based chatbot within a process-based writing framework.' GPT-based chatbots are large language models (Generative Pre-trained Transformer). The study uses a pre- and post-test design with 10 instructional sessions integrating the GPT chatbot into the writing process, meeting the criterion of an experimental/quasi-experimental LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on enhancing 'students’ writing skills' within a 'process-based writing framework,' guiding learners through planning, drafting, revising, and editing. The outcomes and discussion center on writing performance and components of writing quality, not on automated scoring or system evaluation, aligning with a pedagogical writing intervention context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative writing outcomes: pre- and post-writing test scores (mean scores 9.13 vs. 17.03) and progression across four writing quizzes for specific writing components (organization, content, coherence-cohesion, logical connection, argumentation). These provide measurable writing outcome metrics, in addition to qualitative data.""
    }
}"
688,L2 Students’ Barriers in Engaging with Form and Content-focused Ai-generated Feedback in Revising Their Compositions,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are described as 'Forty-five L2 students in a computer science program' writing argumentative essays in English, fitting an L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used to provide corrective feedback, the study is observational/analytic: students were 'tasked with seeking corrective feedback from ChatGPT' and their revisions and rationales were analyzed. There is no experimental or quasi-experimental intervention design comparing conditions or measuring treatment effects.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is L2 writing revision: students used ChatGPT feedback on their argumentative essays, and the study focuses on engagement with form- and content-focused feedback in revising compositions, which is directly writing-related.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports proportions of feedback accepted, argued, or ignored and reasons for non-uptake, but does not mention any quantifiable writing outcome metrics (e.g., changes in writing scores, accuracy, complexity) to assess effectiveness of the LLM-mediated intervention.""
    }
}"
689,Enhancing English Writing Courses in the Uae: the Potential of Generative Ai Tools,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 38 postgraduate students in the UAE who are described as non-native English speakers, indicating an L2 English learner population in an English writing course context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study discusses generative AI tools such as ChatGPT, it is framed as an exploratory, qualitative investigation of potential challenges and possibilities. There is no indication of an experimental or quasi-experimental intervention design integrating LLMs into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly English writing courses in the UAE, focusing on how generative AI might be incorporated into English writing classes and its implications for writing skills and student growth.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The methodology is qualitative, using open-ended questions and thematic analysis. The abstract does not report any quantifiable writing outcome metrics or experimental measures of writing performance; it focuses on perceptions, challenges, and recommendations.""
    }
}"
690,Korean-as-a-foreign-language Learners’ Engagement with Machine Translation Output,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are US university students learning Korean as a foreign language. The target language is Korean, not English, and the context is not ESL/EFL/ELL focused on English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to 'machine translators and other artificial intelligence-assisted programs' but does not specify that these are LLM-based (e.g., ChatGPT, GPT-4). It could be conventional MT systems like Google Translate, which are not necessarily LLMs.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines how learners use machine translators to revise their writing and analyzes their engagement and revision strategies, focusing on writing processes and incorporation of MT output as feedback.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""This is described as an exploratory case study focusing on cognitive and behavioral engagement and revision strategies. There is no indication of experimental or quasi-experimental design with quantifiable writing outcome metrics assessing intervention effectiveness.""
    }
}"
691,Exploring Interrelationships among L2 Writing Subskills: Insights from Cognitive Diagnostic Models,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 500 English as a foreign language (EFL) students, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses cognitive diagnostic models (G-DINA, DINA, DINO, A-CDM, LLM, RRUM) to analyze writing subskills. Here, 'LLM' refers to a log-linear model within CDMs, not a transformer-based large language model used as an instructional tool. No LLM-based writing intervention is described.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on modeling interrelationships among L2 writing subskills using diagnostic psychometric models, not on a pedagogical intervention or instructional use of any LLM in writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing performance data are analyzed, there is no experimental or quasi-experimental intervention involving an LLM, and no comparison of writing outcomes across LLM-mediated conditions. The study is diagnostic/analytical rather than an intervention study.""
    }
}"
692,Efl Teachers’ Perceptions of the Use of an Ai Grading Tool (cograder) in English Writing Assessment at Saudi Universities: an Activity Theory Perspective,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL teachers at Saudi universities, working with English as a Foreign Language learners. The context is clearly EFL with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines teachers’ beliefs about an AI grading tool (CoGrader) used for essay scoring and feedback. There is no indication that CoGrader is an LLM-based tool (e.g., ChatGPT-like transformer-based generative model), nor that it is integrated as an instructional intervention; it is framed as scoring software.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on assessment—teachers’ perceptions of an AI grading tool for essay scoring and feedback. It does not describe a pedagogical writing intervention or instructional use aimed at improving writing competence; rather, it evaluates grading support.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports teachers’ beliefs and perceptions via questionnaires and interviews. It does not report quantifiable student writing outcome measures or experimental effects of an AI-mediated writing intervention on learners’ writing performance.""
    }
}"
693,Crafting with Ai: Personalized Pathways to Boost Critical Language Awareness and Spark Creativity in Writing through Digital Adaptive Learning,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “L2 learners” and “language learning contexts” but does not specify that the target language is English (ESL/EFL/ELL). The population could be English learners, but this is not explicit from the title or abstract.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is an “automated writing application equipped with adaptive learning (AL) strategy.” There is no indication that this tool is a large language model (e.g., ChatGPT, GPT-4, Gemini) or transformer-based generative model. It is described in terms of adaptive learning, individualized instruction, and feedback, which are typical of non-LLM adaptive systems.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on enhancing writing skills and related constructs (critical language awareness and creativity) through an automated writing application. Writing proficiency and accuracy are central outcomes, indicating a writing-focused pedagogical context rather than automated scoring or system evaluation alone.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative outcomes: it compares writing outcomes between an experimental and control group and notes significant improvement in writing skills, accuracy, and language proficiency. These are quantifiable writing-related measures derived from writing tasks and questionnaires.""
    }
}"
694,Understanding Chinese University Efl Learners’ Perceptions of Ai in English Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 140 Chinese university EFL learners in a Chinese university setting, clearly an EFL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines perceptions of Grammarly, which is not described as an LLM-based tool and is treated broadly as ‘AI’. There is no indication of an experimental or quasi-experimental design integrating an LLM (e.g., ChatGPT, GPT-4) into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on learners’ perceptions and technology acceptance (TAM constructs) regarding Grammarly, not on a structured pedagogical writing intervention or development of writing competence. It is attitudinal rather than instructional in focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes are behavioral intention and perceptions (ease of use, usefulness, enjoyment, task relevance). No quantifiable writing performance or writing-related outcome measures are reported.""
    }
}"
695,Ai-enhanced Video Drama-making for Improving Writing and Speaking Skills of Students Learning English as a Foreign Language,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 77 university students learning English as a Foreign Language (EFL). The context is clearly EFL, and the outcomes discussed (writing and speaking skills) are in English.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses an AI-enhanced video drama (AI-EVD) application that incorporates GPT-generated sentences, explicitly referencing a generative pretrained transformer. The design is experimental with an experimental group using the AI features and two control groups (app without AI and conventional learning).""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus includes improving EFL writing (and speaking) skills. AI is used to provide lexical resources (vocabulary and sentence structures) to support students’ writing in the drama-making process, aligning with writing instruction and writing processes rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports learning achievement outcomes and uses correlation and regression analyses to link specific AI-mediated behaviors (e.g., GPT-generated sentences) to improvements in writing and speaking skills. These constitute quantifiable writing outcome metrics within an experimental framework.""
    }
}"
696,Investigating Generative Ai Models and Detection Techniques: Impacts of Tokenization and Dataset Size on Identification of Ai-generated Text,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions that detectors show reduced reliability for English as a Second Language learners, the study itself uses data from prompt 1 of the ASAP Kaggle competition and focuses on AI vs. human text detection. There is no indication that the participants are L2 English learners in ESL/EFL/ELL contexts, nor that the primary data are from such learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Generative AI models (ChatGPT, Claude, Gemini) are included only as sources of AI-generated text for detection experiments. The study does not describe an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or learners’ writing processes; it is a detection/cheating-identification study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on detecting AI-generated or AI-paraphrased text in high-stakes writing assessments using machine learning and LLM-based detectors. It does not investigate writing competence or writing-related pedagogical variables; instead, it evaluates detection techniques and model performance.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity) are reported. Outcomes concern detection accuracy and model performance, not the effectiveness of an LLM-mediated writing intervention on learners’ writing.""
    }
}"
697,Chatgpt for Language Learning: Assessing Teacher Candidates’ Skills and Perceptions Using the Technology Acceptance Model (tam),2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL teacher candidates performing tasks in Spanish (L1) and English (L2), so they are L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT-4 is used to generate machine-written samples that participants compare and evaluate. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating ChatGPT into their own writing instruction or writing process; it is used as material for critical evaluation, not as an instructional writing tool.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on critical skills in distinguishing human vs. machine-generated texts and perceptions of ChatGPT (TAM constructs), not on improving writing competence or writing-related performance through an LLM-mediated intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although text analysis metrics (SC, ASL, VOCD) are reported, they are used to compare human and machine texts, not as outcome measures of a writing intervention’s effect on learners’ writing. The main outcomes are critical discrimination skills and perceptions, not changes in learners’ writing performance.""
    }
}"
698,"Comparing Peer, Chatgpt, and Teacher Corrective Feedback in Efl Writing: Students’ Perceptions and Preferences",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL students, i.e., learners of English as a foreign language, so the population consists of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention includes an AI tool identified as ChatGPT, a large language model, used to provide written corrective feedback on students’ writing as part of the study design.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing: students complete a short writing task, receive written corrective feedback (peer, ChatGPT, teacher), and revise their writing. The focus is on writing skills and feedback practices, not on automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract states that a qualitative approach via survey analysis was used to explore students’ perceptions and preferences. It does not report quantitative writing outcome measures (e.g., scores, accuracy gains) to assess effectiveness of the LLM-mediated intervention; revisions are mentioned but not as measured outcomes. Thus, it lacks quantifiable writing outcome metrics.""
    }
}"
699,An Analysis on the Implementation of Artificial Intelligence (ai) to Improve Engineering Students in Writing an Essay,2024,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions ‘formal EFL essay elements’ and ‘engineering students,’ suggesting they may be English as a Foreign Language learners, but it does not explicitly state that participants are L2 English learners in ESL/EFL/ELL contexts. The institutional or linguistic context is not clearly described.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study refers broadly to ‘Artificial Intelligence (AI) technologies, such as chatbots, Natural Language Processing (NLP), and Sentiment Analysis’ and ‘the use of artificial intelligence to improve writing skills.’ It does not specify whether the intervention uses a large language model (e.g., ChatGPT/GPT-based chatbot) versus non-LLM NLP tools. The VAN framework is mentioned but not explained in terms of underlying AI architecture.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on ‘improving student writing skills in engineering,’ examining ‘formal EFL essay elements, including content and language, in terms of comprehension and production,’ and ‘the flow of information among the participants in essay writing.’ This aligns with writing competence and writing-related variables in an educational context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a mixed-method approach with a control group of essays (224 essays from 52 students) and compares essay elements (content and language). This implies quantifiable writing outcome metrics (e.g., evaluation of essay content/language) to assess the impact of AI-supported writing, even though specific metrics are not detailed in the abstract.""
    }
}"
700,Utilizing an Adaptable Artificial Intelligence Writing Tool (chatgpt) to Enhance Academic Writing Skills among Yemeni University Efl Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Yemeni university EFL learners, clearly L2 English learners in an EFL context: “Yemeni EFL learners at the university level.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is the focus, the study is not an experimental or quasi-experimental intervention. It is a perception survey about using ChatGPT, with no structured instructional treatment or controlled integration into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is academic writing: “AI-based writing tool in academic writing… improved their writing fluency, accuracy, and overall quality of their academic work.” The primary focus is writing competence, not automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses surveys and reports perceived improvements; there is no mention of quantifiable writing outcome metrics (e.g., pre/post writing scores, rubric-based assessments). Outcomes are self-reported perceptions, not measured writing performance.""
    }
}"
701,Chatgpt as an Ai L2 Teaching Support: a Case Study of an Efl Teacher,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context is an EFL class in Spain, so it is likely that learners are L2 English users. However, the study focuses on an EFL teacher as the case, and the abstract does not specify participant details or that learner data are analyzed.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is an exploratory single instrumental case study of one EFL teacher using ChatGPT as teaching support. It examines ChatGPT for planning, designing lessons, and assessing writing, but there is no mention of an experimental or quasi-experimental design testing an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although assessing learners’ writing is mentioned, the primary focus is on ChatGPT as support for teachers (lesson planning, design, reliability/helpfulness of outputs), not on a structured pedagogical intervention targeting learners’ writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses qualitative thematic analysis and does not report quantifiable writing outcome metrics. It focuses on perceived support, reliability, and helpfulness of ChatGPT for the teacher, without experimental measures of changes in learners’ writing performance.""
    }
}"
702,"4th International Conference on Digital Technologies and Applications, Icdta 2024",2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""This is a proceedings volume listing multiple papers across diverse topics. Some titles mention students and EFL contexts (e.g., Moroccan secondary education EFL students), but the abstract does not specify that any paper involves L2 English learners in an ESL/EFL/ELL context with English as the target language in combination with LLM-based writing intervention.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The proceedings description does not indicate any experimental or quasi-experimental study integrating large language models (e.g., ChatGPT, GPT-4) into writing instruction. One listed paper concerns perceptions of AI in academic writing and another about attitudes toward ChatGPT as a learning tool, but these are framed as perception/attitude studies, not LLM-mediated writing interventions.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus of the proceedings is broad digital technologies and applications. The mentioned education-related papers focus on perceptions, attitudes, or general academic performance, not specifically on writing competence outcomes from an LLM-based pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported or implied in the proceedings abstract. The relevant titles emphasize perceptions and attitudes toward AI/ChatGPT rather than measured changes in writing performance following an LLM-based intervention.""
    }
}"
703,Revolutionizing English Language Learning with Ai: Boosting Student Receptive and Productive Skills,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 183 EFL undergraduate students from three universities, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study evaluates three AI tools (Turboscribe, Gliglish, Jenni) via a survey based on TAM. There is no indication these are LLM-based tools integrated into a structured writing instruction or experimental/quasi-experimental intervention; rather, it is a perception/acceptance study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on overall English skills (listening, reading, speaking, and writing) and technology acceptance, not specifically on writing competence or writing-related variables as the primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are behavioral intent to use, perceived usefulness, and user-friendliness based on a TAM survey. No quantifiable writing performance metrics or measured changes in writing ability are reported.""
    }
}"
704,Second Language Writing Anxiety and Chatgpt Adoption as an Automated Writing Evaluation Tool,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as English second language learners (639 undergraduate students), which fits the ESL/EFL/ELL population criterion focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a cross-sectional survey using TAM and SEM-PLS to examine intention to use ChatGPT. There is no experimental or quasi-experimental LLM-based writing intervention or instructional integration; ChatGPT is only considered as a potential tool, not implemented in a treatment.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on writing anxiety and technology acceptance (perceived usefulness, ease of use, attitude, intention) regarding ChatGPT as an automated writing evaluation tool, not on an implemented writing pedagogy or intervention to improve writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome measures are reported. Outcomes are psychological/attitudinal (writing anxiety, perceived usefulness, perceived ease of use, attitude, intention to use), with no assessment of changes in writing performance or related measurable writing skills.""
    }
}"
705,The Impact of Using Chatgpt on Efl Students' Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as English as a foreign language (EFL) learners, which fits the target population of L2 English learners in EFL/ESL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention involves learners revising their English outlines with ChatGPT assistance, directly integrating an LLM (ChatGPT) into the writing process in a comparative design (with vs. without ChatGPT).""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on writing: comparison of English outlines, and reported effects on logical structure, content enrichment, vocabulary, grammar, and overall writing ability. This is clearly a writing-focused intervention, not automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports findings based on discourse analysis and reflection essays but does not indicate any quantifiable writing outcome metrics (e.g., scores, rubric-based ratings, statistical comparisons). Outcomes are described qualitatively (e.g., ‘helps improve’), so it does not meet the requirement for quantifiable writing measures.""
    }
}"
706,Revolutionizing Efl Writing: Unveiling the Strategic Use of Chatgpt by Indonesian Master’s Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are postgraduate EFL students (Indonesian Master’s students), clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a qualitative case study exploring students’ experiences and strategies in using ChatGPT. There is no indication of an experimental or quasi-experimental design or a structured instructional intervention integrating ChatGPT; it focuses on naturally occurring use and perceptions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing; the abstract discusses how ChatGPT is used for vocabulary, grammar, idea generation, essay structuring, and language refinement, all directly related to writing processes and competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study relies on self-reported data and qualitative findings about experiences, strategies, and perceived benefits. It does not report quantifiable writing outcome metrics or experimental measures of writing improvement.""
    }
}"
707,Nurturing Responsible Ai Practices in L2 Writing: Empowering Student Voices,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are students in a freshman academic writing course at an English-medium American university in the UAE, implying L2 English learners in an EFL/ESL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to ‘Artificial Intelligence (AI)’ and contrastive analysis of human vs AI-generated texts, but does not specify use of large language models (e.g., ChatGPT, GPT-4) or any particular AI tool, nor that AI is integrated as an instructional writing aid rather than as an object of analysis.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on responsible and ethical AI integration, digital literacy, learner autonomy, and policy development. AI-generated texts are used for contrastive analysis and policy discussion, not as a pedagogical writing intervention aimed at improving writing competence through AI-mediated support.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although mixed methods and surveys are mentioned, there is no indication of quantifiable writing outcome metrics (e.g., writing scores, complexity, accuracy) assessing the effectiveness of an AI-mediated writing intervention. Outcomes focus on digital literacy and policy engagement rather than measurable changes in writing performance.""
    }
}"
708,"Leveraging Chatgpt to Enhance Students’ Writing Skills, Engagement, and Feedback Literacy",2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 50 Indonesian university students in an English as a Foreign Language (EFL) context taking an Economic English course. The focus is clearly on English language learning and writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The title specifies ‘Leveraging ChatGPT’ and the abstract refers to ‘AI chatbots’ used by the experimental group. ChatGPT is an LLM, and the design is experimental with an experimental and control group, integrating the chatbot into writing-related learning.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly targets ‘students’ writing skills’ and ‘EFL students’ writing,’ with outcomes including writing learning outcomes, feedback literacy, and engagement. The primary pedagogical focus is on writing competence and related variables, not on automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study aims ‘to measure how AI chatbots affect students' writing learning outcomes’ and reports that the experimental group ‘showed significant improvements in writing outcomes.’ Tests and statistical analysis indicate quantifiable writing outcome measures are used.""
    }
}"
709,The Impact of Chatgpt Feedback on the Development of Efl Students’ Writing Skills,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 110 university students learning English as a Foreign Language (EFL). The context is explicitly foreign language education with English as the target language.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is ChatGPT feedback integrated into students’ writing processes. The study uses a quasi-experimental design to examine the effectiveness of this LLM-based feedback in foreign language education.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing skills and writing proficiency. The abstract reports on aspects of writing such as conciseness, grammar, inclusion of key information, and use of passive voice, all within a pedagogical intervention using ChatGPT.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses pre-tests and post-tests to evaluate the impact of ChatGPT feedback on writing proficiency and reports significant improvements in specific, quantifiable aspects of writing (conciseness, grammar, key information, passive voice).""
    }
}"
710,Exploring the Attitudes of Efl University Instructors and Students Toward Utilizing Chatgpt for Acquiring Writing Fluency and Accuracy Skills,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL university instructors and students at a private university in Sharjah, explicitly within an English as a foreign language (EFL) context, focusing on English writing fluency and accuracy.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study explores attitudes toward using ChatGPT but does not describe an experimental or quasi-experimental instructional intervention integrating ChatGPT into actual writing instruction or tasks. It is an attitudinal survey, not an intervention study.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on writing-related variables—specifically writing fluency and accuracy skills in EFL—so the context is clearly writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are perceptions/attitudes measured via Likert-scale questionnaires and interviews. There is no mention of quantifiable writing performance metrics (e.g., scores, error counts, rubric-based writing assessments) resulting from an LLM-mediated intervention.""
    }
}"
711,Usability Study of Genai for English Learning in Vr,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as “7 undergraduate non-native English speakers,” which fits L2 English learners in a higher-education EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the system uses a large language model for language assessment and generative NPC dialogue, the study is a usability test of the VR-GenAI system (SUS, CVI). There is no experimental or quasi-experimental instructional intervention design to evaluate LLM-mediated writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on spoken interaction in VR (real-time conversation game, speaking practice, gestures, NPC dialogue). Writing competence or writing-related variables are not mentioned as a primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Reported outcomes are System Usability Scale (SUS) and Content Validity Index (CVI) regarding conversation quality and interface usability. No quantifiable writing outcomes or writing performance measures are reported.""
    }
}"
712,Exploring the Use of Generative Ai in Student-produced Efl Podcasts: a Qualitative Study,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are university English as a Foreign Language (EFL) students, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “generative AI tools” but does not specify whether these are large language models (e.g., ChatGPT, GPT-4) or other generative tools. However, even if LLMs were used, the study is purely qualitative and not experimental or quasi-experimental in design.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on using generative AI in student-produced EFL podcasts, emphasizing spoken language quality, creativity, ethics, and cultural context. Writing is only mentioned as part of script creation, and the primary outcome is not writing competence or writing-related variables but podcast production and spoken language.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly described as qualitative, based on open-ended responses and thematic analysis. It does not report quantifiable writing outcome metrics or any experimental measures of writing performance.""
    }
}"
713,Utilizing Elsa Speak and Busuu Apps to Enhance English for Professional Purposes among Indian Students: an Education 4.0 Approach,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Indian students learning English for professional purposes in a multilingual context, fitting an ESL/EFL/ELL population: “English as a second language… professional English communication… reflecting India’s multilingual society and numerous regional languages.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses ELSA Speak and Busuu, described as Education 4.0 applications and language learning platforms. There is no indication these are large language model (LLM)-based tools (e.g., ChatGPT, GPT-4). They are general AI/EdTech apps, not transformer-based generative LLMs integrated into writing instruction.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on overall “professional English communication” and improvement in “listening, speaking, reading, and writing skills.” Writing is only one of several skills and the abstract does not indicate that writing competence or writing-related variables are the primary focus of the intervention.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study reports significant improvement in multiple skills, including writing, based on pre- and post-test questionnaires. However, it is unclear whether there are specific, quantifiable writing outcome metrics (e.g., writing scores, text quality measures) as opposed to general self-reported communication skills.""
    }
}"
714,Using Generative Ai to Provide High-quality Lexicographic Assistance to Chinese Learners of English; Die Gebruik Van Generatiewe Ki Om Hoëkwaliteit Leksikografiese Hulp Aan Chinese Aanleerders Van Engels Te Bied,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly targets “Chinese learners of English,” which fits the L2 English learner population in an EFL/ELL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Generative AI (ChatGPT, Ernie Bot) is used to generate explanations and error subcategories and to argue for potential integration into writing assistants. However, the abstract does not describe an experimental or quasi-experimental pedagogical intervention where LLMs are actually integrated into learners’ writing instruction or processes; it is more a design/methodological and lexicographic study.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on lexicographic assistance and explanations for subject–verb disagreement errors, with a proposed integration into writing assistants. While related to writing, the primary emphasis appears to be on tool development and AI capabilities rather than an implemented instructional context with learners’ writing competence as the central outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantitative writing outcome measures or experimental evaluation of learners’ writing performance. It discusses identification of error subcategories and the quality of AI-generated explanations, but no measured impact on learners’ writing is presented.""
    }
}"
715,Investigating Chinese Learners ' Use and Perceptions of Chatgpt in Eap,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese learners in an English for Academic Purposes (EAP) context at a Chinese university, implying they are L2 English learners in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates learners’ use and perceptions of ChatGPT via questionnaire and interviews. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating ChatGPT into instruction; it is observational/perceptual research.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""ChatGPT is used for academic vocabulary and academic writing support, but the focus of the study is on perceptions and usage patterns, not on a structured writing intervention or instructional design targeting writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports attitudes and beliefs about ChatGPT but does not mention any quantitative writing outcome measures (e.g., writing scores, text quality metrics) resulting from an intervention.""
    }
}"
716,Using Ai Tools to Enhance Academic Writing and Maintain Academic Integrity,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are undergraduate students whose first language was not English, i.e., L2 English learners in a higher education context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study explores students’ perceptions of paraphrasing and AI tools but does not describe an experimental or quasi-experimental intervention integrating LLMs into writing instruction or processes. It is a perception-focused qualitative study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on perceptions of plagiarism, academic writing, and AI tool use, not on a structured pedagogical writing intervention or systematic use of LLMs to develop writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract states that qualitative methods were used to analyze focus group data and does not mention any quantifiable writing outcome metrics or measured changes in writing performance.""
    }
}"
717,Chatgpt as a Tool to Improve Written Expression in English as a Foreign Language; Chatgpt Comme Outil D’amélioration De L’expression Écrite En Anglais Langue Étrangère; Chatgpt Como Uma Ferramenta Para Aprimorar a Expressão Escrita No Inglês Língua Estrangeira; Chatgpt Como Herramienta Para Mejorar La Expresión Escrita En Inglés Como Lengua Extranjera,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on students using ChatGPT to improve written expression in English as a foreign language in higher education, which fits an EFL/ESL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""ChatGPT (an LLM) is clearly the tool used, but the abstract does not specify whether there is an experimental or quasi-experimental design (e.g., control group, pre/post comparison, or structured intervention protocol). It only mentions that students performed a writing task and used ChatGPT, with subsequent analysis of interactions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly academic writing in English as a foreign language, focusing on correcting and improving written expression in the essay genre, which is directly related to writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcome is described as a detailed analysis of students’ interactions with ChatGPT, highlighting mistakes and correct answers provided by the tool. There is no indication of quantifiable writing outcome metrics (e.g., scores, measurable gains) assessing the effectiveness of the intervention; the focus is on describing ChatGPT’s feedback and its possibilities/limitations.""
    }
}"
718,Utilising Artificial Intelligence-enhanced Writing Mediation to Develop Academic Writing Skills in Efl Learners: a Qualitative Study,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL learners preparing for the IELTS examination, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention uses ChatGPT, an LLM-based AI platform, for interactive writing activities where learners receive implicit and explicit writing mediation. This is an instructional integration of an LLM into writing processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on developing EFL learners’ academic writing skills via AI-enhanced writing mediation and interactive writing activities, aligning with writing competence as the primary outcome domain.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly described as a qualitative research design using microgenetic tracking, observations, reflexive journal, and think-aloud interviews. The abstract reports perceived development and attitudes but does not indicate any quantifiable writing outcome metrics or experimental/quasi-experimental measures of effectiveness.""
    }
}"
719,Does It Really Help? Exploring the Impact of Al-generated Writing Assistant on the Students’ English Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are four seventh-semester EFL students, clearly L2 English learners in an EFL context, with a focus on English writing skills.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study evaluates an AI-generated writing assistant (ParagraphAI text generator) but the abstract does not specify that it is an LLM-based tool (e.g., ChatGPT/GPT-like transformer model). It is treated as generic AI-powered writing software, and there is no clear indication it is a large language model intervention integrated into instruction or writing processes as defined in the review scope.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on English writing skills, examining grammatical errors, cohesion, coherence, and content density in students’ writing when using the AI assistant, which are core writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses tests, questionnaires, and text comparison to measure Lexical Diversity indices and reports effects on grammatical accuracy, cohesion, coherence, and content density, providing quantifiable writing outcome metrics.""
    }
}"
720,Ghostbuster: Detecting Text Ghostwritten by Large Language Models,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions evaluation on documents by non-native English speakers but not as participants in an L2 learning intervention; they are used as a test set for detection performance, not as L2 learners in ESL/EFL/ELL instructional contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study introduces Ghostbuster, a system for detecting AI-generated text. LLMs are the target of detection, not an instructional tool in an experimental or quasi-experimental writing intervention. No LLM-mediated teaching or feedback is described.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on AI-text detection performance (F1 scores, robustness, generalization) across domains such as student essays, creative writing, and news, not on improving writing competence or writing-related pedagogical variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are detection metrics (F1 scores) and robustness to attacks, not quantifiable L2 writing outcomes or measures of writing quality following an LLM-based intervention.""
    }
}"
721,"A Systematic Review of Chatgpt for English as a Foreign Language Writing: Opportunities, Challenges, and Recommendations",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on English as a Foreign Language (EFL) writing, indicating that the population of interest across the reviewed studies is EFL learners working with English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a systematic review of existing literature on ChatGPT for EFL writing, not an experimental or quasi-experimental primary study implementing an LLM-based intervention. Review articles are to be excluded.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL writing, discussing how ChatGPT is adopted for EFL writing, including opportunities and challenges in writing instruction and curricula.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic review, it synthesizes prior work and provides recommendations but does not itself report original, quantifiable writing outcome metrics from an LLM-mediated intervention.""
    }
}"
722,Chatgpt over My Friends: Japanese English-as-a-foreign-language Learners’ Preferences for Editing and Proofreading Strategies,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 33 Japanese English-as-a-foreign-language learners, clearly an EFL population learning English as L2.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT-3.5 (an LLM) is used, the design is not experimental or quasi-experimental in terms of learning outcomes. Learners simply use writing groups and ChatGPT for editing/proofreading and then complete questionnaires about their experiences and preferences; no controlled intervention to test effectiveness is described.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is academic writing in an EFL classroom, focusing on editing and proofreading to improve clarity and cohesion in writing, which is directly writing-related.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are preferences and perceptions from questionnaires. The abstract does not mention any quantifiable writing performance metrics (e.g., scores, error rates, rubric-based assessments) to evaluate the effectiveness of the LLM-mediated intervention.""
    }
}"
723,Uncovering Students’ Processing Tactics towards Chatgpt’s Feedback in Efl Education Using Learning Analytics,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as being in EFL education, implying they are L2 English learners in an EFL context. The abstract explicitly mentions English as a Foreign Language (EFL) education and reading and writing tasks in that context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses ChatGPT, a generative AI chatbot based on LLMs, during students’ reading and writing tasks. Students interact with ChatGPT’s feedback, and their processing tactics toward this feedback are analyzed, indicating an LLM-based intervention embedded in learning activities.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context includes reading and writing tasks and ChatGPT’s feedback, but the primary measured outcome is described as ‘improvement of domain knowledge’ rather than writing competence or writing-related variables. It is unclear whether writing performance itself is a central focus or just a medium for content learning.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports differences in ‘learning gains’ and ‘improvement of domain knowledge’ among groups but does not indicate any quantifiable writing outcome metrics (e.g., writing quality scores, accuracy, complexity, organization). Outcomes appear to be content/knowledge gains rather than writing performance measures.""
    }
}"
724,Towards Fair Detection of Ai-generated Essays in Large-scale Writing Assessments,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The population is described only as native and non-native English speakers in a large-scale writing assessment. There is no indication that the focus is on L2 English learners in ESL/EFL/ELL instructional contexts; rather, the concern is demographic bias in detection across broad test-taker groups.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on automated detection of AI-generated essays and compares strategies to mitigate detector bias. It does not describe an instructional intervention integrating LLMs into writing instruction or writing processes; LLMs are only the source of generated text to be detected.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on fairness and accuracy of AI-generated text detection in assessments, not on improving writing competence or writing-related pedagogical variables. There is no writing instruction or intervention context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) are reported. Outcomes relate to detection accuracy and bias, not to learners’ writing performance following an LLM-mediated intervention.""
    }
}"
725,Advancing Sustainable Learning by Boosting Student Self-regulated Learning and Feedback through Ai-driven Personalized in Efl Education,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are junior high school EFL students in Asia (English as a Foreign Language), clearly fitting the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “AI-mediated language teaching” and “AI-powered platforms” but does not specify that these are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative tools. They could be other types of AI tools. Without explicit mention of LLMs, it is unclear whether the intervention meets the LLM requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL instruction with outcomes including vocabulary, reading comprehension, writing ability, and grammar. Writing ability is explicitly listed as one of the assessed areas, so writing competence is part of the primary learning focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although pre- and post-tests evaluate multiple skills including writing ability, the abstract does not report any specific, quantifiable writing outcome metrics (e.g., writing scores, rubric-based writing gains) or isolate writing-related results. The reported findings are aggregated as general ‘learning English’ outcomes and self-regulation/feedback measures, without distinct experimental writing outcome data.""
    }
}"
726,Ai in Subconscious Language Learning for Error Remediation,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses second language acquisition and language learning apps (LingQ, Rosetta Stone) but does not specify that the population is L2 English learners or that the focus is on English rather than other target languages.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract refers broadly to AI-powered language learning platforms and intelligent assistants (Siri, Alexa) but does not mention large language models (e.g., ChatGPT, GPT-4) or any specific LLM-based intervention. It appears to be a conceptual or descriptive piece rather than an experimental or quasi-experimental LLM integration in instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on general language acquisition and personalized AI-based learning strategies, not specifically on writing competence or writing-related variables. Writing is not mentioned as a primary outcome or context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental measures are reported. The abstract describes potential benefits and capabilities of AI platforms without presenting structured intervention outcomes or data.""
    }
}"
727,"Integrating Large Language Models into Efl Writing Instruction: Effects on Performance, Self-regulated Learning Strategies, and Motivation",2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are elementary school students in an English as a Foreign Language (EFL) context. The focus is explicitly on EFL writing, i.e., English as the target L2.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study develops and implements an 'LLM-supported Cognitive Academic Language Learning Model (CALLA-LLM)' and compares it to traditional CALLA in a randomized controlled trial. LLMs are integrated into the writing instruction as part of the experimental intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary instructional focus is EFL writing, with outcomes including 'EFL writing performance' and writing-related SRL strategies and motivation. The LLM is used pedagogically within writing instruction, not merely for automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports 'significant improvements in writing performance' and describes a randomized controlled trial with pre-, post-, and follow-up measures, indicating quantifiable writing outcome metrics were collected and analyzed.""
    }
}"
728,Balancing Ai and Authenticity: Efl Students’ Experiences with Chatgpt in Academic Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL students, indicating L2 English learners in an EFL context, with a focus on academic writing in English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used by students in their writing process, the study is a qualitative case study of existing student practices and experiences, not an experimental or quasi-experimental intervention integrating LLMs into instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly academic writing: the study examines how EFL students incorporate ChatGPT into their academic writing process and its perceived impact on essay quality.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract states that data were collected through semi-structured interviews and focuses on experiences, perceptions, and ethical concerns. It explicitly notes reliance on self-reported data and calls for future research with objective measures, indicating no quantifiable writing outcome metrics were reported.""
    }
}"
729,The Impact of Chatgpt on Students’ Writing Proficiency in Second Language Acquisition: Students’ Perception and Experiences: a Qualitative Analysis,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “second language acquisition” and “students’ writing proficiency” but does not specify that the target L2 is English or that the context is ESL/EFL/ELL. Thus, it is unclear whether participants are L2 English learners.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""ChatGPT, an LLM, is clearly the tool under investigation. However, the abstract does not describe an experimental or quasi-experimental instructional design; it only notes that students use ChatGPT as a tool and that their experiences are explored qualitatively. The presence of a structured intervention cannot be confirmed.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on “students’ writing proficiency” in second language acquisition and how ChatGPT influences language learning and writing skills, which aligns with a writing-related context rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as “a qualitative analysis” using interviews and questionnaires to explore perceptions and experiences. There is no indication of quantitative or experimental writing outcome measures; it explicitly goes “beyond mere evaluation of outcomes,” suggesting no reported quantifiable writing metrics.""
    }
}"
730,"Using Artificial Intelligence to Foster Students’ Writing Feedback Literacy, Engagement, and Outcome: a Case of Wordtune Application",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states the context is second language (L2) learning and L2 writing. Participants are upper-intermediate L2 students, implying an ESL/EFL context focused on English, though the language is not named. This fits the target L2 English learner population more closely than other L2s.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Wordtune, described only as an “AI-based application.” Wordtune is primarily a rewriting/paraphrasing tool and is not clearly identified as a large language model (e.g., ChatGPT, GPT-4, Gemini). The abstract provides no indication that a transformer-based generative LLM underpins the tool, and Wordtune is listed in the protocol as an example of tools to exclude if not LLM-based.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s focus is on L2 writing skills, specifically writing feedback literacy, engagement, and writing outcomes. The intervention is clearly pedagogical, integrating AI into L2 writing practice rather than using AI solely for automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that the experimental group using Wordtune “significantly improve[d] their writing outcomes, engagement, and feedback literacy when compared to the control group,” indicating quantitative outcome measures of writing performance within an experimental design.""
    }
}"
731,Understanding Efl Students’ Chatbot-assisted Argumentative Writing: an Activity Theory Perspective,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are five Chinese undergraduate students described as English as a foreign language (EFL) students composing argumentative essays in English, which fits the L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention involves a chatbot named Argumate used to assist argumentative writing. However, the abstract does not specify whether Argumate is an LLM-based chatbot (e.g., transformer-based generative model) or a rule-based/other AI system. Thus, it is unclear if it meets the LLM requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on chatbot-assisted argumentative writing, examining how students engage with the chatbot while composing essays and the activity system of chatbot-assisted writing, which is clearly centered on writing processes and pedagogy.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly described as qualitative, using activity theory to understand engagement processes. Data include screen recordings, chat logs, essays, and a questionnaire, but the abstract reports no experimental or quasi-experimental design, no comparison groups, and no quantifiable writing outcome metrics assessing effectiveness of the intervention. The focus is on process understanding, not measured writing gains.""
    }
}"
732,Enhancing Efl Vocabulary Acquisition through Computational Thinking,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese non-English majors in foreign language education in China, working on English short essay writing and vocabulary acquisition. This fits an EFL context with English as the target L2.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT and AI are mentioned in the introduction, the described intervention is based on computational thinking (CT) skills (data analysis, pattern recognition, abstraction, decomposition, parallelization) applied to vocabulary acquisition. There is no indication that an LLM (e.g., ChatGPT) was actually integrated into the writing instruction or writing process as an experimental tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on improving vocabulary richness in English short essay writing and measures vocabulary-related indices in students’ writing, which is directly related to writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative changes in vocabulary-related indices in short essay writing before and after the CT intervention, using QUITA software, thus providing measurable writing outcomes.""
    }
}"
733,Examining Efl Students' Motivation Level in Using Quillbot to Improve Paraphrasing Skills,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students at Najran University enrolled in a Technical Writing course, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention tool is QuillBot. As specified in the review criteria, tools like QuillBot that are not clearly framed as transformer-based generative LLMs for instructional intervention are to be excluded.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on students’ motivation in using QuillBot to improve paraphrasing skills, not on a structured writing instruction intervention. The design is descriptive-diagnostic, not an experimental or quasi-experimental pedagogical intervention targeting writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports motivational outcomes and gender differences in perceptions, using questionnaires and interviews. It does not report quantifiable writing performance outcomes (e.g., pre/post paraphrasing or writing scores) to assess effectiveness of the AI tool on writing.""
    }
}"
734,The Intersection of Ai and Language Assessment: a Study on the Reliability of Chatgpt in Grading Ielts Writing Task 2,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions IELTS Task 2 writing scripts but does not specify the learners’ status as L2 English learners in ESL/EFL/ELL contexts. While IELTS candidates are typically L2 users, this is not explicitly stated in the abstract.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study evaluates ChatGPT-4 as an automated grader, comparing its scores with official human raters. There is no indication of an instructional or intervention design integrating ChatGPT into writing instruction or learners’ writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the reliability of ChatGPT as a grading tool for IELTS Task 2, not on improving writing competence or implementing a pedagogical writing intervention. It is an assessment-functionality study rather than a teaching/learning intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although quantitative measures (e.g., kappa, ICC) are reported, they relate to score agreement between ChatGPT and human raters, not to changes in learners’ writing performance following an LLM-mediated intervention. No writing outcome metrics for an instructional treatment are presented.""
    }
}"
735,University Students’ Perceptions of Artificial Intelligence-based Tools for English Writing Courses,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Korean university students who are English language learners (ELLs) in English writing courses, fitting an EFL/ESL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study explores perceptions of AI-based tools (Google Translate, Naver Papago, Grammarly) but does not describe an experimental or quasi-experimental intervention integrating LLMs into instruction. Tools mentioned are primarily translation and error-checking systems, and Grammarly is not clearly framed as an LLM-based generative model in an instructional design.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on students’ perceptions of AI-based tools in English writing courses, not on a structured writing intervention or instructional design aimed at improving writing competence. It is attitudinal rather than an intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports perceptions that tools could improve writing skills but does not mention any quantifiable writing outcome measures or experimental comparison of writing performance. Data are survey and interview-based, focusing on strengths, weaknesses, and concerns, not measured writing gains.""
    }
}"
736,From Virtual Assistant to Writing Mentor: Exploring the Impact of a Chatgpt-based Writing Instruction Protocol on Efl Teachers’ Self-efficacy and Learners’ Writing Skill,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Iranian English language teachers (n=12) and learners (n=48) in an L2 writing context. The abstract explicitly refers to second language (L2) writing and IELTS writing, indicating English as the target language in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is a ChatGPT-based writing instruction protocol (CGWIP). ChatGPT is a large language model, and it is integrated systematically into planning, instruction, and assessment phases of writing instruction, constituting an experimental pedagogical intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly L2 writing instruction. ChatGPT is used for brainstorming, engaging learners in the writing process, analyzing drafts, revising, feedback, and simulating IELTS writing exams. The primary focus is on writing competence and related instructional processes, not on automated scoring alone.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative writing outcomes: learners’ writing skills were measured before and after a 10-week program, and One Way ANCOVA showed that CGWIP significantly improved learners’ writing skills with effects persisting over time.""
    }
}"
737,Utilizing Artificial Intelligence Tools for Improving Writing Skills: Exploring Omani Efl Learners’ Perspectives,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Omani EFL learners from the General Requirements Unit at a university in Oman, clearly an EFL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates learners’ perceptions and self-reported practices in using unspecified ‘artificial intelligence writing tools’ (e.g., for translation, spelling, grammar, idea generation). There is no indication of an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into instruction; tools may include non-LLM AI such as grammar checkers or translators.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on perceptions and practices regarding AI tools, not on a structured pedagogical writing intervention. It is a survey study rather than an instructional context designed to improve writing competence via LLM integration.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are Likert-scale perceptions and reported usage patterns; no quantifiable writing performance metrics (e.g., scores, text quality measures) are reported to assess effectiveness of AI/LLM-mediated writing intervention.""
    }
}"
738,Paraphrasing Prowess: Unveiling the Insights of Efl Students and Teachers on Quillbot Mastery,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as English as a Foreign Language (EFL) students and teachers, indicating an L2 English learning context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention tool is QuillBot, which is not clearly identified as an LLM-based, transformer generative model in the abstract and is treated as a generic AI paraphrasing tool. Moreover, the design is a descriptive survey of perceptions, not an experimental or quasi-experimental writing intervention integrating an LLM.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on perceptions of using QuillBot for paraphrasing skills, not on a structured pedagogical writing intervention or systematic integration into writing instruction. It is a perception study rather than an instructional intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports perceptions and attitudinal data (e.g., students and teachers perceived QuillBot can enhance paraphrasing skills) and demographic effects on responses. There is no mention of quantifiable writing outcome measures or pre/post tests of writing performance.""
    }
}"
739,Chatgpt as an Automated Writing Evaluation (awe) Tool: Feedback Literacy Development and Awe Tools’ Integration Framework,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 18 English as a Foreign Language (EFL) students in Indonesia, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""ChatGPT is explicitly used as an AWE tool alongside Grammarly and Quillbot in a writing course, indicating integration of an LLM (ChatGPT) into writing instruction, even though it is combined with non-LLM tools.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on feedback literacy development and an AWE tools integration framework, not on writing competence or writing-related performance variables. Writing is the context, but the outcome focus is literacy about feedback and tool use rather than writing ability.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a single qualitative case study design with interviews, reflective journals, and artifacts, and reports thematic findings. There is no indication of quantifiable writing outcome metrics or experimental measures of writing performance; outcomes are qualitative (feedback literacy, framework).""
    }
}"
740,Evaluating Prompting Strategies for Grammatical Error Correction Based on Language Proficiency,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly mentions “learners of English as a foreign language” and analyzes GEC performance on writing examples of English language learners across proficiency levels (A, B, C). Thus, the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study uses generative LLMs and explores zero-shot, few-shot prompting, and fine-tuning for grammatical error correction, it is framed as an evaluation of prompting strategies and model performance, not as an experimental or quasi-experimental pedagogical intervention integrated into writing instruction or learners’ writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on grammatical error correction system performance (overcorrection, recall vs. precision) and how it varies by learner proficiency. There is no indication of a teaching/learning context or writing instruction intervention; rather, it is a GEC/LLM evaluation study, which falls outside the review’s focus on writing competence interventions.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are GEC evaluation metrics (recall, precision, overcorrection) of LLMs, not quantifiable changes in learners’ writing performance following an LLM-mediated intervention. No experimental measures of learner writing development or instructional impact are described.""
    }
}"
741,Recipe4u: Student-chatgpt Interaction Dataset in Efl Writing Education,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 212 college students in English as a Foreign Language (EFL) writing courses, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study involves a semester-long experiment where students engage in dialogues with ChatGPT to revise their essays, integrating an LLM into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL writing education, with students using ChatGPT to revise essays and the dataset including essay edit histories, focusing on writing-related activity.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes creation and analysis of an interaction dataset, with baseline results for intent detection and satisfaction estimation. It does not report quantifiable writing outcome metrics (e.g., changes in writing quality, scores, or measurable writing performance) to assess the effectiveness of the LLM-mediated intervention.""
    }
}"
742,How Llms Support Efl Writing: a Case Study of K-12 English Learning Based on the Edipt Model,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on K-12 English as a Foreign Language (EFL) learners in Chinese English education, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the paper discusses LLMs conceptually and proposes a response strategy framework (EDIPT model) for using LLMs in K-12 English learning, it is described as a case study and an initial effort exploring potential contributions. There is no indication of an experimental or quasi-experimental design implementing a concrete LLM-based writing intervention with measured effects.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus includes writing instruction and proposes using LLMs to enhance EFL writing and provide feedback. However, the abstract emphasizes a framework and implications rather than a clearly described pedagogical intervention with implementation details, so it is unclear whether the primary focus is an implemented writing intervention versus conceptual discussion.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics or experimental results. It discusses potential benefits (improving learning efficiency, reducing teacher burden) and challenges, but there is no mention of measured changes in writing performance or other quantitative writing-related outcomes.""
    }
}"
743,Leveraging a Diagnostic Exam for Cultivating Ai Literacy: Postgraduate Student Reflections on Chatgpt,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are postgraduate L2 English Language Learner (ELL) students in a high-intermediate L2 English writing and communications course at a U.S. research university, clearly fitting ESL/EAP L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is an AI literacy intervention examining students’ views of AI tools and generative AI. There is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes as a pedagogical tool; rather, it analyzes diagnostic exam output and reflections about AI.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context involves a writing and communications course and a first-day writing diagnostic exam, but the focus is on AI literacy and students’ perspectives on AI tools, not on developing writing competence or writing-related performance through LLM-mediated instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports students’ views and reflections and discusses pedagogical implications. It does not mention any quantitative writing outcome measures or assessment of changes in writing performance resulting from an LLM-mediated intervention.""
    }
}"
744,Network of Discourses: Resistance and Negotiation within Chinese Students’ Ai-assisted Efl Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are English major students in an EFL context at a university in China, clearly L2 English learners: “English as a Foreign Language (EFL) writing assignments… at a university in China.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students use ChatGPT (a generative AI chatbot), the study is not described as experimental or quasi-experimental and does not present a structured pedagogical intervention. It is a qualitative investigation of how students collaborate with AI, framed through Actor-Network Theory and critical discourse analysis.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly EFL writing: “AI-assisted EFL writing,” “EFL writing assignments,” and discussion of EFL writing instruction and assessment criteria. The focus is on writing practices and related ideologies.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports discourse-analytic findings about authenticity, authority, and language ideologies, but does not mention any quantitative or experimental writing outcome measures (e.g., scores, quality ratings, accuracy). It focuses on practices and perceptions rather than measurable writing gains.""
    }
}"
745,Voices of the Future: Exploring Students' Views on the Use of Genai in Academic and Professional Pr Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are described as 'native Thai PR major university students.' While they write PR texts in English rather than Thai, the abstract does not frame them as L2 English learners in an ESL/EFL/ELL context or focus on L2 English learning outcomes; the emphasis is on adoption and perceptions of GenAI.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is qualitative, using focus groups and a workshop on GenAI. There is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) as a structured writing intervention; GenAI is trialed for discussion of adoption, not as a controlled pedagogical treatment.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context involves academic and professional PR writing and students’ views on using GenAI for such writing. However, the primary focus is on perceptions, adoption, and attitudes rather than systematic development of writing competence or writing-related performance variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly qualitative, based on semi-structured focus groups. The abstract reports attitudes, awareness, and reservations but does not mention any quantifiable writing outcome metrics or measured changes in writing performance following GenAI use.""
    }
}"
746,Integrating Automated Written Corrective Feedback into E-portfolios for Second Language Writing: Notion and Notion Ai,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers generally to “second language (L2) educators” and “L2 learners,” but does not specify that the target language is English or that the context is ESL/EFL/ELL. The population and language focus cannot be confirmed from the abstract alone.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a “review” and “technology review” that proposes the use of Notion and Notion AI for L2 writing pedagogy. It does not describe an experimental or quasi-experimental study or an implemented intervention; it only discusses potential use and affordances/limitations.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is clearly on L2 writing pedagogy, e-portfolios, and automated written corrective feedback (AWCF) for writing, with Notion AI as an AI-powered writing assistant that edits texts in terms of lexico-grammar, cohesion, and structure. The primary context is writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a technology review, the article does not report any empirical, quantifiable writing outcome metrics. It provides an overview and discussion of affordances and limitations, without experimental measures or structured intervention outcomes.""
    }
}"
747,The Use of Ai Tools in English Academic Writing by Saudi Undergraduates,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Saudi undergraduates enrolled in freshmen academic writing courses, proficient in English. This fits an EFL/ESL/ELL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students use ChatGPT (an LLM) along with Grammarly and Google Translate, the study is a perception survey with no experimental or quasi-experimental design integrating LLMs into instruction. There is no structured LLM-mediated intervention being tested.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on English academic writing and how AI tools support writing processes (idea generation, outlining, grammar, spell-check), which is clearly writing-related.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports perceptions and factor-analytic results about attitudes toward AI tools but does not report quantifiable writing outcome measures (e.g., changes in writing scores, quality, accuracy) resulting from an LLM-based intervention.""
    }
}"
748,Navigating Ai Writing Assistance Tools: Unveiling the Insights of Thai Efl Learners,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'Thai EFL learners' and 'Thai non-English-major undergraduates,' indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to 'AI writing assistance tools' without specifying that they are LLM-based (e.g., ChatGPT, GPT-4) or detailing the underlying technology. However, the study is qualitative and focuses on learners’ existing use and perceptions rather than an experimental or quasi-experimental intervention integrating a specific LLM into instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on learners’ perceptions, benefits, and challenges of using AI writing assistance tools, not on a structured pedagogical intervention targeting writing competence. It is an exploratory qualitative study of experiences rather than an instructional context evaluating an intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly qualitative, based on interviews, and does not report quantifiable writing outcome metrics. It discusses perceived improvements and challenges but no experimental measures of writing performance.""
    }
}"
749,Investigating Efl Faculty Members’ Perceptions of Integrating Artificial Intelligence Applications to Improve the Research Writing Process: a Case Study at Majmaah University,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are EFL faculty members/teachers at Majmaah University, focusing on their own research writing, not on L2 English learners in ESL/EFL/ELL instructional contexts. The population is teachers as writers, not student L2 learners.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “AI applications and tools” without specifying whether they are large language models (e.g., ChatGPT, GPT-4) or other types of AI. The study is about perceptions of integrating AI tools, not a clearly described experimental or quasi-experimental LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on faculty members’ research writing processes and their perceptions of AI tools, not on pedagogical writing instruction or student writing competence. It is not situated as an L2 writing instructional intervention context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports attitudes and perceptions via questionnaires and interviews. There is no indication of quantifiable writing outcome measures (e.g., writing scores, text quality metrics) assessing the effectiveness of an AI/LLM-mediated writing intervention.""
    }
}"
750,Transforming Academic Writing with Ai: Tools for Effective Learning,2024,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract does not specify that participants are L2 English learners (ESL/EFL/ELL). It mentions ‘students’ and ‘CAE grades’ (possibly Cambridge Advanced English), which suggests an English L2 testing context, but this is not explicit. The learner population and their L2 status remain unclear from the abstract alone.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""ChatGPT is clearly the focal AI tool, and the study analyzes revision data and ChatGPT feedback. However, it is not clearly stated whether there is an experimental or quasi-experimental design (e.g., control vs. treatment, pre–post with ChatGPT as the intervention) or if this is primarily an observational/analytic study of revisions. The design is not sufficiently described to confirm it meets the intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on academic writing, revision, and essay quality. The paper examines how ChatGPT supports revision, addresses structural, grammatical, and stylistic issues, and explores improvements in essay quality and CAE grades. The primary context is clearly writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract notes that the analysis examined revision data from eleven student texts, including error types, word count changes, and revision behaviours, and relates these to improvements in essay quality, essay scores, and CAE grades. These constitute quantifiable writing outcome metrics linked to the use of ChatGPT.""
    }
}"
751,Ai-empowered Applications Effects on Efl Learners' Engagement in the Classroom and Academic Procrastination,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Chinese EFL learners, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses AI-powered applications including ChatGPT, POE, and Duolingo. ChatGPT is an LLM, but Duolingo is not necessarily LLM-based in the sense required, and the abstract does not specify that the intervention is an LLM-mediated writing instruction or process. It focuses on general language learning and engagement, not clearly on LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The stated focus is on affective, cognitive, and behavioural engagement and academic procrastination. There is no indication that the primary focus is writing competence or writing-related variables; writing is not mentioned in the abstract.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcome measures are engagement and academic procrastination scales. No quantifiable writing outcomes (e.g., writing quality, accuracy, complexity, or other writing performance metrics) are reported.""
    }
}"
752,Inheriting and Innovating Yishan Seal Art: Huang Mufus Style in Contemporary Seal Carving Education,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are three male Saudi undergraduate EFL learners enrolled in an English degree program at Albaha University, clearly fitting an EFL/ESL English-learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions “AI-driven technology” and “AI-enhanced tool,” the concrete intervention described is a “pushed email condition” compared with classroom-based conditions. There is no indication that a large language model (e.g., ChatGPT, GPT-4, Gemini) was integrated into writing instruction; email as a medium does not itself constitute an LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context involves learners submitting nine writing samples under different conditions, with analysis of vocabulary size and lexical errors in their written output. The focus is on writing performance and vocabulary use in writing tasks.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative writing-related outcomes: vocabulary size (measured via V_Words) and lexical errors (Engber’s 1995 taxonomy). It compares conditions and finds the pushed email condition leads to greater vocabulary expansion and lexical accuracy.""
    }
}"
753,Enhancing University Level English Proficiency with Generative Ai: Empirical Insights into Automated Feedback and Learning Outcomes,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 918 university language students in Hong Kong. While not explicitly labeled as EFL/ESL, Hong Kong university language students learning English are reasonably interpreted as L2 English learners in an EFL/ESL/ELL context, and the study clearly concerns English essay writing proficiency.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is AI-generated feedback using GPT-3.5-turbo, a large language model, compared to a control group without such feedback, within a randomized controlled trial. This is an experimental design integrating an LLM into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on essay writing proficiency, student engagement with writing tasks, and revision processes. LLMs are used pedagogically to provide feedback for revising essays, not merely for automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable metrics: statistical analysis of the impact of AI feedback on essay grading and effect sizes, indicating measurable writing outcomes (caliber of students’ essays) in addition to qualitative data.""
    }
}"
754,Teachers or Chatgpt: the Issue of Accuracy and Consistency in L2 Assessment,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study analyzes 100 writing assignments from B1-level students at an international branch university in Egypt, clearly indicating L2 English learners in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used solely as an automated rater to assess existing writing samples. The design is quantitative correlational and explicitly non-experimental, with no instructional or pedagogical intervention integrating the LLM into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the accuracy, consistency, and intra-rater reliability of ChatGPT’s scoring compared to teachers. This is an assessment/automated essay scoring validity study, not a study of writing competence development or a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing scores are analyzed, they are used only to compare ChatGPT and teacher ratings, not as outcomes of an LLM-mediated writing intervention. There is no experimental manipulation or instructional use of ChatGPT intended to improve learners’ writing performance.""
    }
}"
755,Learning and Teaching with Chatgpt: Potentials and Applications in Foreign Language Education,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses foreign language education and foreign language writing skills in general, but does not specify that the focus is on L2 English learners (ESL/EFL/ELL) or that the target language is English specifically.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a literature review using content analysis of prior work on ChatGPT in foreign language acquisition. It does not report an original experimental or quasi-experimental intervention integrating an LLM into writing instruction.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing skills are mentioned as one of the areas potentially enhanced by ChatGPT, but the paper is a broad review of applications in foreign language education rather than a focused empirical study on writing competence in a specific instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a literature review, the study does not present original quantitative writing outcome metrics from an intervention; it synthesizes existing literature and discusses potentials and implications instead.""
    }
}"
756,Generative Ai as Writing or Speaking Partners in L2 Learning: Implications for Learning-oriented Assessments,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to L2 learning and assessment but does not specify that the reviewed studies focus on L2 English learners in ESL/EFL/ELL contexts, nor that English is the primary target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a review of the literature on GenAI as writing and speaking partners, framed through a Learning-Oriented Assessment lens. It is not an experimental or quasi-experimental primary study implementing an LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing is one of the skills discussed, but the focus is on reviewing how GenAI tools can be used for both writing and speaking within assessment contexts, not on a specific primary intervention study centered on writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a literature review, the paper does not report original, quantifiable writing outcome metrics from an intervention; it synthesizes existing research conceptually through the LOA framework.""
    }
}"
757,Identifying whether a Short Essay Was Written by a University Student or Chatgpt,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses essays from Japanese university students who are English L2 learners (CEFR A2 level), fitting ESL/EFL/ELL contexts with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used only to generate comparison essays for a detection task. There is no experimental or quasi-experimental pedagogical intervention integrating an LLM into writing instruction or learners’ writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on teachers’ ability to distinguish human vs. ChatGPT-generated essays, not on improving writing competence or writing-related learning outcomes. It is essentially a detection/identification study, not a writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The only quantitative outcome reported is teachers’ classification accuracy (54.25%). No quantifiable writing outcome metrics for learners (e.g., writing quality, complexity, accuracy) are assessed, and no LLM-mediated writing intervention outcomes are measured.""
    }
}"
758,Evaluating Cami Ai across Samr Stages: Students' Achievement and Perceptions in Efl Writing Instruction,2024,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 126 EFL (English as a Foreign Language) university students, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract describes ‘Cami, an AI-powered tool’ and refers to ‘Cami AI technology’ but does not specify whether it is a large language model (e.g., ChatGPT-like, transformer-based generative model) or another type of AI (e.g., feedback/annotation tool). Without clarification that Cami is LLM-based, it is unclear if this meets the LLM intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is situated in EFL writing instruction and examines the impact of Cami AI-SAMR implementation on EFL students’ writing achievement, clearly focusing on writing competence within a pedagogical context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that Cami AI-SAMR implementation ‘significantly impacted EFL students' writing achievement’ and mentions investigation of ‘quantitative effects’ on student performance, indicating quantifiable writing outcome measures.""
    }
}"
759,Efl Tertiary Teachers' and Students' Conceptualizations and Challenges of Using Ai Tools to Improve Writing Skills in Thailand and Vietnam during the Covid-19 Pandemic,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are clearly EFL tertiary teachers and students in Thailand and Vietnam, focusing on English as a foreign language and writing skills during the COVID-19 pandemic.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers generically to 'AI tools' (AITs) but does not specify whether these are large language models (e.g., ChatGPT, GPT-4) or other AI-based tools (e.g., grammar checkers). No explicit mention of LLMs or transformer-based generative models is provided.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates perceptions and challenges of using AI tools to improve writing skills, but there is no indication of an instructional intervention design; it is a perception-focused survey/interview study rather than an experimental or quasi-experimental writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports perceptions (beliefs, struggles, neutrality) about AI tools and their use in writing, using descriptive analysis of survey data. It does not report quantifiable writing outcome measures (e.g., changes in writing scores, quality, accuracy) resulting from an AI-mediated intervention.""
    }
}"
760,"The Metaphor of Ai in Writing in English: a Reflection on Efl Learners' Motivation to Write, Enjoyment of Writing, Academic Buoyancy, and Academic Success in Writing",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 86 intermediate EFL students from China in an English as a foreign language context, clearly L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses an automated writing evaluation (AWE) system. The abstract does not indicate that this AWE is an LLM-based, transformer generative model (e.g., ChatGPT, GPT-4). AWE tools are typically rule-based or non-LLM scoring/feedback systems, which fall outside the review’s inclusion criteria for LLM-based interventions.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on fostering learners’ writing skills and related affective variables (motivation to write, enjoyment of writing, academic buoyancy, and academic success in writing) in an EFL writing context, aligning with a primary focus on writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes: motivation to write, enjoyment in writing, academic buoyancy, and academic success in writing, analyzed via one-way MANOVA, indicating measurable writing-related outcomes.""
    }
}"
761,Writing Argumentative Essays: Jambi Efl Students' Challenges and Strategies,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students at the English Education Study Program of a public university in Jambi, Indonesia, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although students report using ‘AI applications’ as a technology utilization strategy, the study is a qualitative case study exploring challenges and self-reported strategies. There is no experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into instruction or writing processes as an intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on difficulties in writing argumentative essays and strategies to overcome them, which is directly related to writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses qualitative methods (semi-structured interviews, document analysis, thematic analysis) and reports problems and strategies. It does not report quantifiable writing outcome metrics or evaluate the effectiveness of an LLM-mediated intervention.""
    }
}"
762,L2 Students' Barriers in Engaging with Form and Content-focused Ai-generated Feedback in Revising Their Compositions,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are described as 'L2 students in a computer science program' writing argumentative essays in English, indicating L2 English learners in an academic EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""Students were 'tasked with seeking corrective feedback from ChatGPT for their argumentative essays,' which is an LLM-based tool integrated into their writing process in an experimental task.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on L2 writing, specifically revision behavior in response to AI-generated feedback on argumentative essays, clearly centering on writing processes and feedback use.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports proportions of feedback accepted/rejected and qualitative reasons for non-uptake, but does not mention any quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, or scores) to assess the effectiveness of the LLM-mediated intervention.""
    }
}"
763,Balancing Ai and Authenticity: Efl Students' Experiences with Chatgpt in Academic Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL students, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, the study is a qualitative case study of students’ experiences and strategies, not an experimental or quasi-experimental intervention design integrating LLMs into instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on academic writing processes and how ChatGPT is incorporated into students’ writing, including effects on essay quality and authenticity, which aligns with writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study relies on semi-structured interviews and self-reported experiences; it does not report quantifiable writing outcome metrics or experimental measures of writing performance.""
    }
}"
764,Investigating Students' Cognitive Processes in Generative Ai-assisted Digital Multimodal Composing and Traditional Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) writers, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although generative AI tools (ChatGPT, Bing Chat, Bing Image Creator) are used, the study is described as a qualitative exploration of composing processes over two weeks, not as an experimental or quasi-experimental intervention design testing the effectiveness of an LLM-based instructional treatment.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on generative AI-assisted composing processes in multimodal PPT projects and traditional argumentative essays, which are clearly writing-related tasks and processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports qualitative analyses of cognitive and composing patterns, use of AI-generated text and images, and pedagogical implications. It does not mention any quantifiable writing outcome metrics (e.g., scores, rubric-based ratings, measurable gains) to assess effectiveness of the AI-assisted writing intervention.""
    }
}"
765,Ai Chatbot as a Companion in Writing Travel Notes1,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are Russian heritage language speakers and advanced Russian-as-a-foreign-language learners in a German university. The target language is Russian, not English, so the population does not consist of L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a customized chatbot built on the ChatGPT model (a large language model) as an interactive interlocutor and writing assistant within a structured learning scenario, indicating an LLM-based intervention in writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on improving writing competency in the travel note genre, using a genre-based approach and a five-step genre cycle. The chatbot is integrated specifically to support writing processes and genre awareness, not for automated scoring.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports observations about potential benefits and contributions to L2 reading and writing skills but does not clearly indicate experimental or quasi-experimental quantitative writing outcome measures. It appears more exploratory/observational, but this cannot be fully confirmed from the abstract alone.""
    }
}"
766,English Paraphrasing Strategies and Levels of Proficiency of an Ai-generated Quillbot and Paraphrasing Tool: Case Study of Scientific Research Abstracts,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study paraphrases 30 abstracts from the Journal of Second Language Writing using AI tools. There are no human participants, and thus no L2 English learners in ESL/EFL/ELL contexts are involved.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The tools examined are QuillBot and an unnamed Paraphrasing Tool. These are generic AI paraphrasers and the abstract does not indicate that they are LLM-based (e.g., ChatGPT/GPT-4-like transformer generative models) nor that they are integrated into an instructional intervention; they are only evaluated as tools.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on analyzing paraphrasing strategies and proficiency levels of the tools themselves, not on a pedagogical context or intervention aimed at improving learners’ writing competence. It is a tool-focused case study, not a writing instruction study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics for learners are reported. The study evaluates outputs of AI tools qualitatively; there is no experimental or quasi-experimental intervention measuring changes in learner writing performance.""
    }
}"
767,Eap Teacher Feedback in the Age of Ai: Supporting First-year Students in Efl Disciplinary Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly refers to “English as a foreign language (EFL) disciplinary writing” and “first-year EFL undergraduate students in their discipline-specific academic writing within EMI settings,” indicating L2 English learners in an EFL/EMI context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although generative AI is mentioned as a feedback tool, the study investigates the nature of EAP teacher feedback and compares it with students’ perceptions of teacher vs. AI-generated feedback. There is no indication of an experimental or quasi-experimental LLM-based writing intervention; AI is a comparison point in perceptions, not an instructional treatment integrated into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on “EFL disciplinary writing,” “discipline-specific academic writing,” and feedback on that writing, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes qualitative analysis (three-layer coding scheme, interview themes) about the nature of feedback and perceptions. It does not report quantifiable writing outcome metrics or experimental measures of the effectiveness of AI-mediated writing interventions.""
    }
}"
768,Reflections on Co-researching Ai Literacy: a Students-as-partners Approach with International Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The participants are described as international students in a UK pre-sessional English for Academic Purposes (EAP) course, which likely implies L2 English learners, but this is not explicitly stated in the abstract.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a Students-as-Partners case study on AI literacy, focusing on learning about AI limitations and prompt writing. There is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into writing instruction as an intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is AI literacy, SaP processes, and partnership reflections, not writing competence or writing-related variables. Writing is not presented as the central outcome domain.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics. It discusses perceived benefits (e.g., learning about AI limitations, prompt writing skills) and offers recommendations, but no experimental measures of writing performance are mentioned.""
    }
}"
769,Chatgpt-generated Corrective Feedback: Does It Do What It Says on the Tin?,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as students at CEFR B1 level attending an English for Academic Purposes (EAP) course at an international branch campus of a UK university, which fits an ESL/EAP L2 English learner context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares ChatGPT-generated corrective feedback with teacher-provided feedback on students’ essays, but it is framed as an evaluation of ChatGPT’s feedback capabilities, not as an experimental or quasi-experimental pedagogical intervention integrating ChatGPT into instruction or the writing process with measured learning effects.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the quantity and quality of corrective feedback produced by ChatGPT versus teachers, i.e., the adequacy of the feedback strategy and guidance. It does not describe an instructional intervention aimed at improving writing competence; rather, it assesses ChatGPT as a feedback tool, similar to functionality or tool-evaluation studies.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics (e.g., pre/post writing scores, revisions quality, accuracy gains). Outcomes concern the adequacy and characteristics of feedback, not measured changes in learners’ writing performance following an LLM-mediated intervention.""
    }
}"
770,"Chatgpt, Plagiarism, and Multilingual Students' Learning to Write",2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions “multilingual students” and “writing instructors,” but does not specify that the learners are L2 English learners in ESL/EFL/ELL contexts or that the focus is specifically on English writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the piece is described as a “short piece” sharing “exploratory interactions” and discussing how instructors can use the tool. There is no indication of an experimental or quasi-experimental design or a structured pedagogical intervention being implemented and studied.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on plagiarism, academic integrity, and ethics in academic writing, not on developing writing competence or writing-related performance. The aim is to facilitate teaching and learning of ethics rather than to improve writing skills per se.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or assessment of writing performance. It appears to be conceptual/practical guidance rather than an empirical study with measurable writing outcomes.""
    }
}"
771,Chatgpt in Language Writing Education: Reflections and a Research Agenda for a Chatgpt Feedback Engagement Framework,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers generally to 'ESL writing education' and 'student writers' but does not specify any actual participant group or empirical data collection. It appears to be a conceptual/personal reflection rather than a study with defined L2 English learner participants.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper is described as a 'personal reflection' that reviews ethical considerations and proposes a research agenda and framework for ChatGPT feedback engagement. There is no indication of an experimental or quasi-experimental intervention actually integrating ChatGPT into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is ESL writing education and feedback, the article is conceptual/theoretical. It discusses models and ethical dimensions rather than implementing or empirically evaluating a writing-focused pedagogical intervention with ChatGPT.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or empirical assessment. It focuses on reflections, framework development, and a call for future research, without reporting intervention outcomes.""
    }
}"
772,The Reliability of Using Chatgpt in Rating Efl Writings,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL writers whose compositions were drawn from the Written English Corpus of Chinese Learners, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses ChatGPT solely as an automated rater to evaluate existing EFL compositions and compare its scores with human raters. There is no experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the reliability of ChatGPT as an essay scoring tool (intra- and inter-rater reliability), not on improving writing competence or implementing a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No writing outcome measures are reported as a result of an LLM-mediated intervention. The only quantitative outcomes are reliability statistics comparing ChatGPT and human ratings, not changes in learners’ writing performance.""
    }
}"
773,"Comparing Peer, Chatgpt, and Teacher Corrective Feedback in Efl Writing: Students' Perceptions and Preferences",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL students in English as a Foreign Language classrooms, and the focus is on English writing skills.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention includes an AI tool (ChatGPT) providing written corrective feedback on students’ writing, alongside peer and teacher feedback, which constitutes integration of an LLM into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is written corrective feedback on an EFL writing task, with revisions after each feedback mode; the focus is clearly on writing competence and feedback practices.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as using a qualitative approach via survey analysis to explore students’ perceptions and preferences. No quantitative writing outcome metrics (e.g., scores, error rates, measurable improvement) are reported; revisions are mentioned but not as measured outcomes.""
    }
}"
774,Enhancing Usability and Learner Engagement: a Heuristic Evaluation of the Ai-enhanced Video Drama Maker App,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The app is designed for learners of English as a Foreign Language (EFL), clearly indicating an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the app includes GPT-generated sentences, the study itself is a heuristic evaluation of usability with UI/UX experts, not an experimental or quasi-experimental pedagogical intervention with learners integrating LLMs into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on usability and user experience (heuristic evaluation based on Nielsen’s principles) rather than on writing competence or writing-related learning outcomes. Writing is mentioned as an intended skill area, but not as the central evaluative focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The quantitative data concern usability (e.g., Cronbach’s alpha, descriptive statistics on heuristic evaluation), not measures of learners’ writing performance or development.""
    }
}"
775,Developing a Thai Grammatical Error Correction Tool for Deaf Students,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are deaf students writing in Thai; the focus is on Thai grammatical error correction, not on L2 English learners in ESL/EFL/ELL contexts or English-language data.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract describes a Thai grammatical error correction system and mentions comparing different detection and correction models, but does not specify that these are large language models (e.g., transformer-based generative LLMs like GPT). It may be traditional GEC models.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on developing and evaluating an automated Thai GEC tool and corpus, not on a pedagogical writing intervention or instructional context aimed at improving learners’ writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are model performance metrics (off-the-shelf vs corpus-trained models) rather than quantifiable writing outcomes for learners following an LLM-mediated writing intervention.""
    }
}"
776,Deep Learning Approaches to Predict Student Success in English Language Learning,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to 'English language learning' and 'student-written texts' but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts. They could be L1 or mixed populations; the learner profile is not clearly defined.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""GPT-3 is used to predict student success and assess texts, functioning as an analytic/predictive model. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating GPT-3 into writing instruction or writing processes; it is primarily a prediction/assessment tool.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on predicting student achievement and improving accuracy of success predictions, not on developing writing competence. While GPT-3 analyzes writing and generates feedback, the study centers on prediction performance rather than a structured writing intervention or instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported concern prediction accuracy of student success and the actionability of feedback, not quantifiable changes in learners’ writing performance following an LLM-mediated intervention. No pre/post or comparative writing outcome measures are described.""
    }
}"
777,Xducation of Things (xot): Harnessing Ai and Edge Computing to Educate All Things,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 26 EFL learners, divided into experimental and control groups. The context is English as a foreign language, and the outcome mentioned is learners’ writing skills, implying English writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is the smartXoT environment with a Smart Question Answer Forwarding Mechanism (SQA-Forwarding) built on edge computing and AI-Agents/smart things. The abstract does not indicate that this system is based on large language models (e.g., ChatGPT, GPT-4, transformer-based generative models). It appears to be an AI/edge-computing knowledge-base system rather than an LLM-mediated writing tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly reports that interaction with smartthings with SQA-Forwarding significantly improved learners’ writing skills and that revisions enhanced writing quality. Thus, the primary measured educational focus includes writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""A quasi-experimental design with experimental and control groups is used to examine differences in learning achievement and writing skills. The abstract reports significant improvement in learners’ writing skills, implying quantifiable outcome measures of writing quality.""
    }
}"
778,Automated English Language Learning Using Bert-lstm Model,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “automatic English learning” and “students,” but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor does it clearly describe any learner population or study sample.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is an automated BERT-LSTM model for English learning. While BERT is transformer-based, this is not an LLM-based pedagogical tool like ChatGPT/GPT-4; it is a feature-extraction/classification model. The study focuses on model design and performance, not on integrating an LLM into writing instruction in an experimental or quasi-experimental educational design.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions grammar correction, comprehension, and written responses, but the primary focus appears to be general ‘automatic English learning’ and linguistic feature handling, not a clearly defined writing-instruction context or writing competence intervention.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""It notes that “experimental findings affirm the usefulness” of the model, but does not specify quantifiable writing outcome metrics (e.g., writing scores, complexity, accuracy, fluency) for learners. The nature of the reported outcomes (system performance vs. learner writing gains) is not clear.""
    }
}"
779,"The Effects of a Quillbot-based Intervention on English Language Majors' Efl Writing Performance, Apprehension, and Self-efficacy",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 18 fourth-year English Language majors in an EFL context at Matrouh University. The study explicitly concerns EFL writing performance, indicating L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is based on QuillBot, described as an AI-powered writing assistant. QuillBot is not specified as an LLM-based tool (e.g., ChatGPT, GPT-4, Gemini) in the abstract, and in the review’s criteria, tools like QuillBot that are not clearly transformer-based generative LLMs are to be excluded.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on EFL writing performance and related affective variables (writing apprehension and self-efficacy). The intervention involves drafting, receiving AI-generated feedback, revising, and producing final drafts, clearly centering on writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a pre/post test to measure writing performance and two scales to measure apprehension and self-efficacy, reporting significant positive effects. These are quantifiable outcome metrics of the writing intervention.""
    }
}"
780,Revolutionizing Efl Learning through Chatgpt: a Qualitative Study,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students at the University of Hail in Saudi Arabia, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, the study is exploratory and qualitative, based on interviews about general use of ChatGPT in learning English. There is no indication of an experimental or quasi-experimental design or a structured pedagogical intervention being tested.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing is mentioned among several skills (reading, writing, grammar, spelling), but the focus is broad on overall English learning and experiences with ChatGPT, not specifically on writing competence or writing-related variables as the primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is explicitly described as qualitative, using interviews. It reports perceived enhancements and challenges but does not mention any quantifiable writing outcome metrics or experimental measures of writing performance.""
    }
}"
781,Efl Students' Perception in Indonesia and Taiwan on Using Artificial Intelligence to Enhance Writing Skills,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students in Indonesia and Taiwan, described as second-year students specializing in English. The focus is explicitly on English as a Foreign Language writing skills.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to 'Artificial Intelligence (AI)' and 'AI tools' but does not specify whether these are large language models (e.g., ChatGPT, GPT-4) or other non-LLM tools (e.g., grammar checkers, paraphrasers). However, the study is not described as experimental or quasi-experimental; it is a qualitative perception study of existing AI use, not a structured LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on academic writing skills in EFL, including grammar, sentence structure, paraphrasing, vocabulary, and topic generation, all of which are writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses qualitative methods (semi-structured interviews, thematic analysis) to explore perceptions. It does not report quantifiable writing outcome metrics or evaluate the effectiveness of an AI/LLM-mediated writing intervention; it focuses on perceived benefits and concerns.""
    }
}"
782,From Virtual Assistant to Writing Mentor: Exploring the Impact of a Chatgpt-based Writing Instruction Protocol on Efl Teachers' Self-efficacy and Learners' Writing Skill,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Iranian English language teachers (n=12) and learners (n=48) in an L2 writing context. The abstract explicitly refers to L2 writing and IELTS writing, indicating English as the target language in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is a ChatGPT-based writing instruction protocol (CGWIP). ChatGPT is a large language model, and it is integrated systematically into planning, instruction, and assessment phases of writing instruction, constituting an experimental pedagogical intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly L2 writing instruction. ChatGPT is used for brainstorming, engaging learners in the writing process, analyzing drafts, simulating IELTS writing exams, and providing feedback. The primary focus is on writing competence and related instructional processes, not on automated scoring alone.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative outcomes: Independent Samples t-test and One Way ANCOVA results showing that CGWIP significantly improved learners’ writing skills and that effects persisted over time. These are quantifiable writing outcome metrics.""
    }
}"
783,The Influence of Chatgpt on Thinking Skills and Creativity of Efl Student Teachers: a Narrative Inquiry,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 12 English student teachers in an EFL context (“EFL student teachers,” “pre-service language teacher education”), so they are L2 English users in an EFL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, the study is framed as a narrative inquiry into experiences and perceptions during practicum, not as an experimental or quasi-experimental intervention study. There is no indication of controlled instructional treatment or comparison groups.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on thinking skills and creativity in teaching practices and teacher education, not on writing competence or writing-related variables. Written narratives are data collection tools, not targeted writing instruction outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses qualitative narratives and interviews and reports perceptions, benefits, and challenges. It does not report quantifiable writing outcome metrics or structured evaluation of writing performance.""
    }
}"
784,Generative Ai and Essay Writing: Impacts of Automated Feedback on Revision Performance and Engagement,2024,unsure,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as first-year university students in Hong Kong, but their L2 status is not specified. While many Hong Kong undergraduates are L2 English users, the abstract does not explicitly state that they are EFL/ESL/ELL learners or that English is the target L2, so this cannot be confirmed from the abstract alone.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses feedback generated by large language models (LLMs) as the intervention in a randomized controlled trial. One group received AI-generated feedback on essay drafts, indicating an experimental design integrating generative AI (LLM-based) into the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on essay-writing skills, revision performance, and engagement with writing tasks. The LLM is used pedagogically to provide feedback for essay revision, not merely for automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative outcomes: statistical analysis of essay grades and significant improvements in essay quality for students receiving AI feedback. These are quantifiable writing outcome metrics assessing the effectiveness of the LLM-mediated intervention.""
    }
}"
785,Impacts of Chatgpt-assisted Writing for Efl English Majors: Feasibility and Challenges,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 'English as a foreign language (EFL) English college majors,' indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study investigates 'ChatGPT-assisted revised essays' and describes ChatGPT as providing feedback for revision, which is an LLM-based intervention integrated into the writing process.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on how ChatGPT-assisted revisions affect essay scores and fairness in evaluation, not on a pedagogical writing intervention or instruction. It functions more as a tool to generate revised texts for grading comparison rather than as a structured instructional intervention to develop writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcome metrics: essay scores before and after ChatGPT-assisted revision, with improvements in vocabulary, grammar, organization, and content, and distributional changes in scores.""
    }
}"
786,Examining the Impact of Ai-powered Writing Tools on Independent Writing Skills of Health Science Graduates,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are ‘English as Second Language (ESL) learners’ who are health science graduates at a South Indian private medical university. The focus is on English writing skills, satisfying the population criterion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions ‘AI-powered writing tools’ and distinguishes ‘generative writing with AI assistance’ from ‘independent writing with AI editing assistance’, it does not specify that these are LLM-based tools (e.g., ChatGPT, GPT-4). More importantly, the study is purely survey-based, examining familiarity, attitudes, and usage patterns, not an experimental or quasi-experimental intervention integrating LLMs into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on self-reported knowledge, attitudes, and usage of AI-powered tools, not on a structured pedagogical intervention targeting writing competence. There is no implemented teaching or training program using the tools; the study is descriptive rather than an instructional intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports survey frequencies (knowledge, attitudes, usage) but does not report quantifiable writing outcome metrics (e.g., changes in writing quality, scores, accuracy) resulting from an AI-mediated intervention. It only infers potential impact on independent writing without measuring it experimentally.""
    }
}"
787,"Chatgpt, the End of L2 Academic Writing or a Blessing in Disguise?",2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on academic writing in English as a second language and discusses opportunities and challenges for L2 students and teachers, indicating an L2 English learner population in ESL/EFL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the paper is described as an overview and a descriptive account of an interview with ChatGPT. There is no indication of an experimental or quasi-experimental design integrating ChatGPT into instruction; it is conceptual/descriptive rather than an intervention study.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing skills, specifically L2 academic writing in English, and on how ChatGPT might enhance the second language writing process, which aligns with a writing-focused context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantitative or experimental writing outcome measures. It reports an interview with ChatGPT and discusses opportunities, challenges, and suggested activities, but no structured intervention outcomes or measurable writing performance data.""
    }
}"
788,Exploring the Educational Potential of Chatgpt: Ai-assisted Narrative Writing for Efl College Students,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 44 university students in South Korea engaged in college-level L2 (EFL) writing. The context is explicitly EFL and focuses on English narrative writing, satisfying the L2 English learner population requirement.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study investigates “ChatGPT-assisted narrative writing” and analyzes “prompts initiated by students,” indicating direct integration of an LLM (ChatGPT) into the writing process as an instructional intervention, with pre/post testing and structured use of the tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on narrative writing competence and related variables (writing fluency, syntactic complexity, overall performance) in an L2 writing course. ChatGPT is used pedagogically as a writing assistant, not merely as an automated scoring tool.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative writing outcomes: pre/post-test scores for writing fluency, overall performance, syntactic complexity, and clause complexity, analyzed via paired sample t-test and Wilcoxon signed rank test to determine the effect of the ChatGPT-assisted intervention.""
    }
}"
789,Zone of Proximal Creativity: an Empirical Study on Efl Teachers' Use of Chatgpt for Enhanced Practice,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are EFL teachers enrolled in a postgraduate program, not L2 English learners in ESL/EFL/ELL contexts. The focus is on teacher creativity, not learner language development.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used, the study is exploratory/qualitative, examining how teachers use ChatGPT for creative ideation. There is no experimental or quasi-experimental instructional intervention targeting learner writing.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on teacher creativity and ideation (lesson planning, perspectives, tools), not on writing competence or writing-related variables for L2 learners.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses inductive content analysis of inquiry threads, lesson plans, reflections, and open-ended survey responses. It does not report quantifiable writing outcome metrics assessing LLM-mediated writing interventions.""
    }
}"
790,Patterns of Utilizing Ai-assisted Tools among Efl Students: Need Surveys for Assessment Model Development,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Indonesian EFL university students, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a survey of AI-tool utilization patterns and technology acceptance. It does not describe an experimental or quasi-experimental intervention integrating LLMs into writing instruction. The main tools mentioned are Grammarly and Google Translate, which are not specified as LLM-based in this context.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on general AI-tool use, knowledge, and technology acceptance, not specifically on writing competence or writing-related instructional interventions. Writing outcomes or writing-focused pedagogy are not central.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study reports survey data on knowledge, frequency of use, perceived ease of use, and usefulness, but not on changes in writing performance or related measurable writing outcomes.""
    }
}"
791,Chain-of-thought in Neural Code Generation: from and for Lightweight Language Models,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on large and lightweight language models for code generation in software engineering. There is no mention of human participants, learners, or L2 English learning contexts (ESL/EFL/ELL).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although LLMs are central to the study, they are used for code generation and Chain-of-Thought reasoning, not as an instructional intervention in L2 English writing. No educational or pedagogical integration is described.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is software engineering and code generation performance, not writing competence or writing-related variables in an L2 context. There is no focus on writing instruction or writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are automated and human evaluation metrics of code generation and CoT quality, not quantifiable L2 English writing outcomes. No writing performance measures are mentioned.""
    }
}"
792,The Impact of Using Interactive Chatbots on Self- Directed Learning,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'fifty Omani EFL students', clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is an 'interactive chatbot' implemented via WhatsApp. There is no indication that this chatbot is a large language model (e.g., ChatGPT, GPT-4, Gemini) or any transformer-based generative model; it appears to be a custom, likely rule-based chatbot delivering instructions and tests.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing tasks are mentioned among several activities (grammar, reading comprehension), but the primary focus of the study is on self-directed learning abilities, not specifically on writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports quantitative outcomes for self-directed learning (questionnaire pretest–posttest differences). While writing tasks were assigned, no specific, quantifiable writing outcome metrics (e.g., writing scores, quality measures) are reported in the abstract.""
    }
}"
793,Ai Tools for Enhanced English Learning: Leveraging Machine Learning for Improved Outcomes,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses “English as a foreign language” and “students,” implying EFL learners, but it does not clearly specify the participant population, level, or context (ESL/EFL/ELL) in an empirical study. It may be a system proposal rather than a participant-based study.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper describes a proposed AI/ML-based system using NLP, adaptive methods, speech recognition, and text recognition. It does not explicitly mention large language models (e.g., ChatGPT, GPT-4) or transformer-based generative models, and appears to be a conceptual or technical design rather than an experimental or quasi-experimental LLM-mediated intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing is mentioned only briefly (“writing and speaking feedback”) within a broader English learning platform that includes pronunciation, gamification, and flexible curriculum. The primary focus seems to be general English learning, not specifically writing competence or writing-related variables as the main outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any experimental or quasi-experimental results, nor any quantifiable writing outcome metrics. It appears to propose a methodology/system rather than evaluate its impact on writing performance with measurable outcomes.""
    }
}"
794,Role of Artificial Intelligence in Ict Based Teaching and Learning,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses students and language learning/ELT applications in general but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor does it indicate the target language is English specifically.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a general exploration of the role of AI in ICT-based teaching and learning and lists various AI tools (Google Translate, Duolingo, etc.). It does not describe an experimental or quasi-experimental design integrating LLMs (e.g., ChatGPT, GPT-4) into instruction; it appears descriptive/conceptual rather than an intervention study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing and language proficiency are mentioned, the focus is broad (AI in teaching and learning, language learning generally) rather than a specific, structured writing competence intervention. It is not centered on writing instruction or writing-related variables as the primary context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental measures are reported in the abstract. The study appears to analyze or describe AI technologies and their potential roles, without reporting measured effects on writing performance.""
    }
}"
795,How Llms Support Efl Writing:a Case Study of K-12 English Learning Based on the Edipt Model,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on K-12 English as a Foreign Language (EFL) learners in Chinese English education, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as a case study that proposes a response strategy framework (EDIPT model) and discusses potential contributions and recommendations for using LLMs. There is no indication of an experimental or quasi-experimental design implementing a concrete LLM-based writing intervention with measured effects.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The paper’s stated focus is on the contribution of LLMs to the instruction and acquisition of EFL writing in K-12 and on enhancing writing abilities, which aligns with writing competence as the primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics or structured intervention results. It discusses potential benefits, challenges, and recommendations, but no experimental measures of writing performance are mentioned.""
    }
}"
796,Predictive Feedback Loops: Harnessing Ai for Continuous Assessment and Personalized Growth in English Language Learners,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “English language learners” and “English language learning” but does not specify whether participants are L2 English learners in ESL/EFL/ELL contexts, nor does it describe any concrete participant sample. It may be conceptual or system-focused rather than involving actual L2 learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is based on an LSTM model for predictive feedback loops, not on a large language model (e.g., ChatGPT, GPT-4, Gemini). LSTM is a recurrent neural network architecture, not a transformer-based generative LLM. Thus, it does not meet the LLM-based intervention requirement.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions monitoring performance in comprehension, grammar, vocabulary, and fluency, but does not specify that the primary focus is writing competence or writing-related variables. It appears to address general language proficiency rather than writing instruction or writing processes specifically.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study claims to investigate the model’s efficacy in enhancing language proficiency and learner autonomy, but the abstract does not describe specific, quantifiable writing outcome metrics or any explicit writing-focused experimental results. It is unclear whether writing outcomes are measured at all.""
    }
}"
797,Ai in Foreign Language Learning in Engineering Education: the Benefits and Challenges of Using Chatgpt,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are first-year students in engineering faculties using ChatGPT for foreign language learning, including English (vocabulary, grammar, writing styles). However, it is not explicitly stated that they are L2 English learners in ESL/EFL/ELL contexts, only that this is a foreign language class in engineering education.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used and practical classroom uses are described, the abstract does not indicate an experimental or quasi-experimental design. It appears to be a descriptive/practice-based study focusing on benefits, challenges, and suggested uses, not a controlled intervention study.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing-related activities are mentioned (written practice, learning writing styles), but the primary focus seems broader—general foreign language learning, vocabulary, grammar, dialogue, and attitudes toward ChatGPT—rather than a focused investigation of writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports a questionnaire on students’ attitudes and tips for using ChatGPT, but there is no mention of quantifiable writing outcome metrics (e.g., writing scores, text quality measures) to assess the effectiveness of the ChatGPT-mediated writing activities.""
    }
}"
798,Exploring Chatgpt's Ability to Classify the Structure of Literature Reviews in Engineering Research Articles,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any participants, learners, or educational context (ESL/EFL/ELL). It is a tool-focused evaluation of ChatGPT’s classification ability on literature review structures in engineering research articles, not a study involving L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used to classify paragraphs in literature reviews and its performance is compared to manual coding. There is no experimental or quasi-experimental pedagogical intervention integrating ChatGPT into writing instruction or learners’ writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on ChatGPT’s functionality in identifying literature review structure, not on developing or assessing writing competence through an instructional intervention. Any pedagogical implications are speculative and not part of an implemented teaching context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes are reported. The numerical results concern ChatGPT’s classification performance, not changes in students’ writing quality or related writing measures following an LLM-mediated intervention.""
    }
}"
799,Using Ai-text Editing Tools to Enhance Writing Skills: an Attitudinal Case Study of Egyptian Undergraduates,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Egyptian undergraduates in a TEFL (EFL) context, and the focus is on improving their EFL writing abilities, i.e., L2 English learners.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “AI-text editing tools” and “different AI tools” without specifying whether they are LLM-based (e.g., ChatGPT, GPT-4) or non-LLM tools (e.g., Grammarly-style editors). It is not possible to confirm that transformer-based generative LLMs are used.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on using AI-text editing tools to refine translated manuscripts and improve EFL writing abilities, clearly centering on writing competence in an instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as an attitudinal case study based on students’ self-reported observations and perceptions. The abstract reports favorable attitudes and perceived enhancement of writing skills but does not mention any experimental or quasi-experimental design, nor any quantifiable writing outcome measures.""
    }
}"
800,Investigating Chinese Learners ‘ Use and Perceptions of Chatgpt in Eap,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese learners in an English for Academic Purposes (EAP) context at a Chinese university, which fits L2 English learners in an EFL/ESL/ELL setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is central, the study investigates learners’ use and perceptions via questionnaire and interviews. There is no indication of an experimental or quasi-experimental instructional intervention integrating ChatGPT into writing instruction; it is observational/descriptive.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract notes that students use ChatGPT for academic writing among other purposes, but the primary focus is on general use and perceptions in EAP, not on a structured writing-focused pedagogical intervention or systematic examination of writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports questionnaire and interview data on use and attitudes. There is no mention of quantifiable writing outcome measures (e.g., writing scores, text quality metrics) assessing the effectiveness of ChatGPT-mediated writing intervention.""
    }
}"
801,Argumentative Writing Software: Perceptions of Undergraduate Students Toward Artist Prototype,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are 30 undergraduate students at a Thai university. Their L2 status and whether the focus is specifically on English as a foreign/second language is not stated. The language of writing is not specified, so it is unclear if they are L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The tool Artist uses NLP and AI technologies and incorporates ChatGPT recommendations, but the study is described as a research-and-development usability/feasibility test of prototype interfaces. There is no clear experimental or quasi-experimental design evaluating an LLM-based pedagogical intervention; ChatGPT appears as a component, not as the central focus of an instructional experiment.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The tool is explicitly an argumentative writing support software, and the study focuses on argumentative writing, including graphical representation and ways to create argumentations. Thus, the primary focus is on writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are perceptions of feasibility, usability, and feelings about ChatGPT, gathered via focus group interviews. There is no mention of quantifiable writing outcome metrics (e.g., writing scores, quality ratings, error counts) to assess effectiveness of the LLM-mediated intervention.""
    }
}"
802,Mcaimem: a Mixed Sram and Edram Cell for Area and Energy-efficient On-chip Ai Memory,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article focuses on AI chip memory design (SRAM, eDRAM, mixed CMOS cell memory) and deep neural network data representation. There is no mention of human participants, language learners, ESL/EFL/ELL contexts, or L2 English learning.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is a hardware memory architecture (MCAIMem) for AI chips, not an educational or pedagogical intervention using large language models such as ChatGPT or GPT-4. No LLM-based writing instruction or writing process support is described.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is hardware performance (area, energy efficiency) for AI memory in DNN applications. There is no focus on writing competence, writing instruction, or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are chip-level metrics (area reduction, energy consumption, accuracy of DNN tasks) rather than quantifiable writing outcomes. No writing performance measures are included.""
    }
}"
803,Identifying Language Anxiety among Foreign Language Learners Using Gru,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The participants are described as foreign language learners writing English essays, suggesting they may be L2 English learners, but the abstract does not clearly specify ESL/EFL/ELL context or confirm that English is the target L2 rather than just the medium of the task.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is the development of machine learning classifiers (Decision Tree, LSTM, GRU) to detect language anxiety from student-produced text. These are not large language models (no mention of transformer-based generative models such as GPT, ChatGPT, etc.), and there is no LLM-based instructional or writing-process intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on identifying language anxiety via text classification, not on improving writing competence or writing-related pedagogical interventions. Writing is used as data for anxiety detection, not as the target of instruction or assessment of writing development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are model performance metrics (F1-score, accuracy, ROC-AUC) for anxiety classification. There are no quantifiable writing outcome measures (e.g., writing quality, complexity, accuracy, fluency) assessing the effect of an intervention on learners’ writing.""
    }
}"
804,Fluent Futures: Cutting-edge Ai Techniques for Mastering English,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses the ELLIPSE Corpus, described as a dataset of English Language Learner (ELL) writing samples, indicating an L2 English learner population in an ELL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is based on BERT and a sequence-to-sequence fine-tuning mechanism. While BERT is a transformer model, it is not a large language model used in an interactive, generative way like ChatGPT/GPT-4; the focus is on automated feedback generation, not an LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on developing an AI feedback system and evaluating it with automatic metrics (ROUGE). There is no clear pedagogical writing intervention or instructional context; it is essentially a feedback-generation/NLP system study rather than a teaching/learning intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions potential measures like student satisfaction and gains in writing skill, the reported experimental findings are only ROUGE-1, ROUGE-2, and ROUGE-L scores, which are system performance metrics, not quantifiable learner writing outcomes from an intervention.""
    }
}"
805,Synergizing Generative Pre-trained Transformer (gpt) Chatbots in a Process-based Writing Paradigm to Enhance University Students' Writing Skill,2024,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 'university EFL students,' indicating learners of English as a foreign language. The focus of the study is on their English writing skills (organization, content, coherence-cohesion, logical connection, argumentation), satisfying the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study 'investigates the influence of a GPT-based chatbot within a process-based writing framework' and integrates 'GPT-based chatbots' over 10 sessions. GPT-based chatbots are LLMs, and the design is experimental with pre- and post-tests, meeting the requirement for an LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on enhancing 'university students' writing skill' within a 'process-based writing framework.' Outcomes are specific writing components (organization, content, coherence-cohesion, logical connection, argumentation). The chatbot is used pedagogically in the writing process, not merely for automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: pre- and post-writing test scores (mean scores 9.13 vs. 17.03) and progressive changes across four writing quizzes in specific components. This provides measurable evidence of the effectiveness of the GPT-based intervention on writing performance.""
    }
}"
806,Examining Writing Feedback Dynamics from Chatgpt Ai and Human Educators: a Comparative Study,2024,unsure,模型调用失败
807,Chatbot-based Learning of Logical Fallacies in Efl Writing: Perceived Effectiveness in Improving Target Knowledge and Learner Motivation,2024,unsure,模型调用失败
808,Co-creating Stories with Generative Ai,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are undergraduates in Hong Kong taking a language-related subject and are described as ESL learners, so they are L2 English learners in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “publicly available Generative Artificial Intelligence (GenAI) tools” but does not specify whether these are LLM-based tools (e.g., ChatGPT) or other generative systems. However, even if they are LLMs, the design appears to be descriptive/qualitative rather than experimental or quasi-experimental.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context involves co-creating digital stories (written and podcast formats) with GenAI support, focusing on creative writing and storytelling, which is a writing-related activity in an ESL context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is based on qualitative content analysis of semi-structured interviews and reports perceived expansion of creative potential and awareness. There is no indication of quantifiable writing outcome metrics or experimental measures of writing performance.""
    }
}"
809,Aes Model with Logic Rule Reasoning and Self-explanation Based on Amr and Llm,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract focuses on automated essay scoring (AES) models and mentions second-language learners only as a potential user group needing explanations. There is no indication of an actual participant sample of L2 English learners in ESL/EFL/ELL contexts, nor any empirical study with such learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""LLMs are used to build an interpretable AES system, not as part of an instructional or quasi-experimental pedagogical intervention in writing. The study is about model development and evaluation, not integrating LLMs into writing instruction or learner writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on AES model interpretability and performance, i.e., automated scoring and explanation generation. There is no pedagogical context or intervention targeting writing competence; it is an assessment/technology study rather than a writing instruction study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are model performance metrics (e.g., surpassing prompt-tuned ChatGPT-4) and explanation quality, not quantifiable changes in learners’ writing performance following an LLM-mediated intervention. No experimental writing outcome measures with learners are described.""
    }
}"
810,Morpho-phraseological Based Classification of Cefr Italian L2 Learner Writing Proficiency,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are Italian L2 learners; the focus is on Italian as the target language, not English. The abstract describes CEFR classification for Italian L2 proficiency using texts from Italian CEFR certification exams.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study presents a model for automatic classification of writing proficiency and compares it with machine learning models. There is no indication that large language models (e.g., ChatGPT, GPT-4) are used, nor that there is any instructional or intervention component.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automated proficiency classification (assessment) using morpho-phraseological features, not on writing instruction, intervention, or support for learners’ writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports prediction metrics (accuracy, etc.) for proficiency classification models, not quantifiable outcomes of a pedagogical or LLM-mediated writing intervention. No experimental writing improvement measures are described.""
    }
}"
811,Enhancing Writing Skills with Ai: Personalized Feedback Mechanisms for English Learners,2024,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers broadly to “English learners” and “diverse learning contexts” but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor does it describe any actual learner sample; it may be a system paper without human participants.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses the T5 model to generate feedback. While T5 is a transformer-based model, the abstract presents it as an automated feedback system evaluated via BLEU, ROUGE, and METEOR against reference texts, not as an experimental or quasi-experimental pedagogical intervention integrated into writing instruction with learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on developing and evaluating an automated feedback mechanism (system performance) rather than on a structured educational intervention targeting writing competence. There is no description of instructional context, teaching procedures, or integration into actual writing classes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Reported outcomes are system-level NLP metrics (BLEU, ROUGE, METEOR) assessing alignment with reference texts, not quantifiable learner writing outcomes (e.g., pre/post writing scores, rubric-based writing quality measures). No experimental measures of learner writing improvement are described.""
    }
}"
812,The Impact of Using Chatgpt on Efl Students’ Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) learners, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study investigates the impact of using ChatGPT, a large language model, on EFL students’ writing by comparing outlines written without and with ChatGPT assistance, indicating an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on writing: comparison of English outlines, analysis of logical structure, content enrichment, vocabulary and grammar polishing, and overall writing ability. This aligns with writing competence as the primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports discourse analysis results and qualitative improvements (logical structure, content, vocabulary, grammar) and student reflections, but does not indicate any quantitative or otherwise clearly operationalized writing outcome metrics (e.g., scores, rubric-based ratings, statistical comparisons). Outcomes appear qualitative only.""
    }
}"
813,Visual Analysis of Mobile-assisted Language Education and Discussion on the Role of Mobile Llm Applications in Tcsol,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article focuses on mobile-assisted language education broadly and specifically discusses mobile LLM applications in Teaching Chinese to Speakers of Other Languages (TCSOL) and L2 Chinese learners, not L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a visual analysis/review using Citespace and a conceptual discussion of the role of mobile LLM applications. It does not describe an experimental or quasi-experimental intervention integrating LLMs into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract addresses mobile-assisted language education in general and potential roles of LLMs (e.g., as auxiliary teachers and practice partners). It does not focus on writing competence or writing-related variables; skills are discussed at a general language learning level.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The paper is a bibliometric/visual analysis and forward-looking discussion, without experimental measures of LLM-mediated writing outcomes.""
    }
}"
814,Exploring Efl Learners’ Integration and Perceptions of Chatgpt's Text Revisions: a Three-stage Writing Task Study,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states the context is an English as a foreign language (EFL) classroom, so participants are L2 English learners and the focus is on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""ChatGPT, an LLM, is used to provide reformulations as feedback within a three-stage writing task (composing–comparison–rewriting). This constitutes an LLM-mediated writing intervention, even though the design appears more observational than controlled experimental.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is situated in EFL writing, examining how learners notice and integrate ChatGPT’s text reformulations during revision. The primary focus is on writing processes and improvement, not on automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study analyzes types and depth of noticing, instances of reformulations integrated into rewriting, and questionnaire responses. These are process and perception measures; the abstract does not indicate any quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity, or scores) used to assess effectiveness of the intervention.""
    }
}"
815,Efl Learners' Perceptions of Written Corrective Feedback in Online Learning,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 113 EFL students (English as a Foreign Language) in English preparation classes at a private university in Vietnam, clearly L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates perceptions of written corrective feedback (WCF) in online writing classes. There is no mention of large language models (e.g., ChatGPT, GPT-4) or any LLM-based intervention; it focuses on WCF practices in general.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is English writing classes and written corrective feedback, which is directly related to writing competence and writing instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines students’ perceptions via questionnaires and interviews and uses thematic analysis. It does not report quantifiable writing outcome metrics (e.g., changes in writing scores or accuracy) resulting from an intervention.""
    }
}"
816,Uses and Misuses of Chatgpt as an Ai-language Model in Academic Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not specify any participant population, let alone L2 English learners in ESL/EFL/ELL contexts. It appears to be a conceptual or discussion paper about academic writing in general, not an empirical study with defined L2 learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is discussed, there is no indication of an experimental or quasi-experimental intervention integrating ChatGPT into instruction. The paper examines uses, misuses, advantages, limitations, and ethical concerns, suggesting a descriptive or conceptual analysis rather than an intervention study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is broadly on academic writing and ethical/functional aspects of ChatGPT use, not on a structured pedagogical context targeting writing competence with measurable instructional design. It reads as a general discussion of tool use rather than a writing intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are mentioned. The abstract refers to ‘findings’ in terms of understanding benefits and risks, but there is no indication of measured changes in writing performance or related variables resulting from an LLM-mediated intervention.""
    }
}"
817,"Chatgpt, a Helpful Scaffold or a Debilitating Crutch for Academic Writing?",2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract discusses academic writing in general and does not specify that the population is L2 English learners in ESL/EFL/ELL contexts. It appears to target a broad audience of educators, researchers, and students, not a defined L2 learner group.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a review paper that draws on existing literature, empirical studies, and expert opinions. It does not report an original experimental or quasi-experimental intervention integrating ChatGPT into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on ChatGPT’s role in academic writing, including its influence on the writing process, quality of content, and critical thinking, which aligns with writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a review paper, it does not report original, quantifiable writing outcome metrics from an intervention. It synthesizes advantages, constraints, and ethical implications rather than presenting measured effects on writing performance.""
    }
}"
818,Exploring the Young Learners' Interactions with Ai-enerated Multimodal Feedback in Collaborative Writing,2024,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are young learners in Chinese language learning activities. The abstract explicitly states the focus is on supporting teaching and learning in Chinese language and promoting vocabulary learning in collaborative Chinese language learning, not L2 English (ESL/EFL/ELL) learners.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses an AI-enabled automated feedback learning system with AI-generated image feedback, AI-enabled audio feedback, and automatic scoring. However, it does not specify that these tools are large language model-based (e.g., ChatGPT, GPT-4), so it is unclear whether LLMs are involved.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on vocabulary learning and collaborative Chinese language learning activities, not on writing competence or writing-related variables in English. While it mentions collaborative writing, the detailed focus is vocabulary learning in Chinese, not writing outcomes in English.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract notes that the study will focus on students' learning outcomes, learning process, and learner enjoyment, but it does not specify quantifiable writing outcome metrics; the outcomes appear to be vocabulary learning and affective/process measures rather than writing performance.""
    }
}"
819,To Use or Not to Use? a Mixed-methods Study on the Determinants of Efl College Learners' Behavioral Intention to Use Ai in the Distributed Learning Context,2024,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 464 Chinese EFL college learners, clearly an English-as-a-foreign-language population, which fits the required L2 English learner context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates determinants of behavioral intention to use AI based on the Technology Acceptance Model. It does not describe an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT, GPT-4) into writing instruction or processes; AI is treated generically and only at the level of intention to use.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on attitudes and behavioral intention toward AI in distributed EFL learning, not specifically on writing competence or writing-related variables. No indication is given that the AI use is tied to writing instruction or writing tasks.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes are TAM constructs (perceived ease of use, perceived usefulness, attitude, behavioral intention). There are no reported quantitative writing performance measures or writing-related outcome metrics assessing an AI- or LLM-mediated writing intervention.""
    }
}"
820,Opening the Black Box: Interpretable Machine Learning Reveals the Relationship between Lexical Diversity and Writing Quality,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract references CET-4 writing, which typically involves Chinese L1 learners writing in English, suggesting an L2 English population. However, this is not explicitly stated in the title or abstract, so the L2 English learner status is inferred rather than confirmed.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses interpretable machine learning to analyze the relationship between lexical diversity and writing quality and to verify the validity of automatic essay scoring. There is no indication that a large language model (e.g., ChatGPT, GPT-4) is integrated into instruction or writing processes as an intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on understanding the writing construct, rating scales, and validating automatic essay scoring, not on a pedagogical or instructional intervention targeting writing competence using LLMs. It is an assessment/construct validation study rather than a teaching/learning intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing quality is analyzed, the study does not describe an experimental or quasi-experimental intervention with pre/post or comparative writing outcome measures mediated by an LLM. It focuses on modeling and interpretation, not on evaluating the effectiveness of an LLM-based writing intervention.""
    }
}"
821,Feeding Two Birds with One Scone: Using Awe to Enhance Writing and Creativity among Pre-university Students,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as “eleven CEFR B1 second language learners” in “English language writing instructions,” indicating L2 English learners in an EFL/ESL-type context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses an Automated Writing Evaluation (AWE) tool based on NLP to generate feedback. The abstract does not indicate that this is a large language model (e.g., ChatGPT/GPT-4 or similar transformer-based generative model); it appears to be a conventional AWE system, which falls outside the LLM-focused scope.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly focuses on “English language writing instructions to improve writing proficiency and creative performance,” using AWE as formative assessment in writing lessons. The primary context is writing competence and related creativity.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports pre- and post-test scores for writing and creativity, noting “improvements in writing and creativity scores.” These are quantifiable outcome measures of the writing intervention.""
    }
}"
822,The Combination of Recognition Technology and Artificial Intelligence for Questioning and Clarification Mechanisms to Facilitate Meaningful Efl Writing in Authentic Contexts,2023,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL learners, indicating L2 English learners in an EFL context. The focus is on EFL writing, so the target language is English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses an app with “generative-AI that can generate meaningful questions and clarifications.” However, the abstract does not specify whether this generative AI is a large language model (e.g., transformer-based LLM such as ChatGPT/GPT-4) or another type of AI. Without explicit indication that an LLM is used, it is unclear if it meets the LLM-based intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is designed to facilitate EFL writing in authentic contexts via a Smart Questioning-Answering-Clarification mechanism. Outcomes include writing more meaningful words and enhancing EFL writing, so the primary focus is on writing competence and related variables, not on automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is a five-week quasi-experiment with experimental and control groups, reporting significant differences in learning behaviors, post-test results, and the amount of meaningful words written in assignments. These are quantifiable writing-related outcome measures.""
    }
}"
823,Rating Short L2 Essays on the Cefr Scale with Gpt-4,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract specifies that the essays are written by L2 English learners on a high-stakes language assessment, clearly matching the target population of L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""GPT-3.5 and GPT-4 are used as automated raters of essays, not as part of an instructional or intervention design for writing. There is no experimental or quasi-experimental integration of LLMs into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automated essay scoring performance and inter-rater agreement with human ratings, not on improving writing competence or implementing a pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports agreement between LLM and human scores as an evaluation of scoring reliability, not as outcome measures of a writing intervention. There is no LLM-mediated instructional treatment whose impact on writing performance is measured.""
    }
}"
824,The Impact of Automated Writing Evaluation on Second Language Writing Skills of Chinese Efl Learners: a Randomized Controlled Trial,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 190 Chinese EFL students, clearly L2 English learners in an EFL context. The writing test is an IELTS writing sample, confirming the target language is English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is Automated Writing Evaluation (AWE) training using Grammarly. Grammarly is described as an AI-driven AWE platform, but it is not a large language model-based generative tool like ChatGPT, GPT-4, or similar transformer-based LLMs. The study focuses on AWE, not LLM-mediated writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on L2 writing competence, assessing task achievement, coherence and cohesion, lexicon, and grammatical accuracy in IELTS writing tasks. The intervention is pedagogical, not just automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The randomized controlled trial reports quantifiable writing outcomes: performance differences between experimental and control groups across multiple writing skill dimensions, with pre- and post-test measures.""
    }
}"
825,Sentence-level Feedback Generation for English Language Learners: Does Data Augmentation Help?,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions ‘English language learners’ as the target of feedback comments, but it does not specify whether any actual L2 English learners participated as subjects, nor whether data come from ESL/EFL/ELL learners versus synthetic or existing corpora.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses LLMs to generate feedback comments and explores data augmentation for a feedback generation system. There is no indication of an experimental or quasi-experimental pedagogical intervention where L2 learners use LLMs within writing instruction or writing processes; it is a system-development/evaluation paper.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on the NLP task of feedback comment generation and system performance, not on learners’ writing competence or writing-related learning outcomes. It aims to aid future studies but does not itself implement a teaching/learning context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes are reported. The results concern performance of feedback generation models and analysis of generated comments, not changes in learners’ writing quality or related measurable educational outcomes.""
    }
}"
826,Exploring the Capabilities of Chatgpt for Lexicographical Purposes: a Comparison with Oxford Advanced Learner’s Dictionary within the Microstructural Framework,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract focuses on comparing ChatGPT’s lexicographical output with the Oxford Advanced Learner’s Dictionary. It does not mention any participant group, learners, or empirical data from L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is evaluated as a lexicographical resource, not implemented as an instructional intervention or within an experimental/quasi-experimental design involving learners’ writing processes. The study is a tool comparison, not a pedagogical intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on lexicographical microstructure and dictionary content quality, not on writing competence or writing-related variables. There is no indication of writing instruction or writing performance being targeted.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are similarity metrics (BLEU, ROUGE) and percentage presence of lexicographical items, not quantifiable writing outcomes from learners. No writing performance measures or intervention effects on writing are described.""
    }
}"
827,An Impact of Artificial Intelligence Tools on Technical Students’ Esl Oral Communication Skills-a Study,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are technical engineering students in India learning English as a second language (ESL), which fits the target population of L2 English learners in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses unspecified ‘Artificial Intelligence based mobile applications.’ There is no indication these are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative tools; they could be generic AI language-learning apps. Thus it does not clearly meet the LLM requirement.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on oral communication skills (speaking accuracy and fluency). Writing is only mentioned in the conclusion as a future recommendation, not as the focus of the intervention or measured outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Quantitative outcomes are reported only for speaking (oral communication) via pre-post tests and speaking rubrics. No writing-related outcome measures are reported.""
    }
}"
828,The Impact of Ai Writing Tools on the Content and Organization of Students’ Writing: Efl Teachers’ Perspective,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students as reported via their teachers’ perspectives in Indonesian universities, clearly within an EFL/ELL context focused on English writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although several AI tools are mentioned (Quillbot, WordTune, Jenni, ChatGPT, etc.), the study is not an experimental or quasi-experimental intervention integrating LLMs into instruction. It is a qualitative case study exploring teachers’ perceptions of various AI tools, without a structured LLM-based pedagogical intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on the impact of AI writing tools on students’ writing, specifically content and organization, which are core writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a qualitative case study design with semi-structured interviews and reports teachers’ perceptions. It does not report quantifiable writing outcome metrics or experimental measures of writing performance.""
    }
}"
829,The Use of Artificial Intelligence to Improve the Scientific Writing of Non-native English Speakers,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The population is described broadly as 'non-native English-speaking scientists,' not as L2 English learners in ESL/EFL/ELL instructional contexts. The focus is on researchers’ scientific writing, not language learners in educational settings.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a narrative, non-systematic review of AI tools (Elicit, ResearchRabbit, Scispace Copilot, Grammarly, Paperpal, ChatGPT). It does not report an experimental or quasi-experimental intervention integrating LLMs into instruction; it only describes potential uses.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the topic is scientific writing, the paper is conceptual/descriptive, not an empirical study of a writing intervention. There is no implemented pedagogical context or structured writing program being evaluated.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The article is a narrative review discussing how AI might improve clarity, style, and coherence, without experimental measures or assessed intervention outcomes.""
    }
}"
830,"17th Linguistic Annotation Workshop, Law 2023 @ Acl 2023 - Proceedings of the Workshop",2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a proceedings volume from the 17th Linguistic Annotation Workshop, covering multiple NLP/annotation topics (e.g., Byzantine Greek marginal writing, mythological events, mathematical expressions, hate speech labelling). There is no indication that any paper focuses on L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""While one paper mentions using fine-tuned LLM suggestions to extend an event-type ontology, this is in the context of annotation and ontology extension, not an experimental or quasi-experimental LLM-based writing instruction intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus of the proceedings is linguistic annotation and related NLP tasks, not writing competence or writing-related pedagogical interventions. No writing instruction or writing process support is described.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""There is no mention of quantifiable writing outcome metrics or any structured LLM-mediated writing intervention. The described works concern annotation, datasets, and NLP pipelines rather than L2 writing outcomes.""
    }
}"
831,Chatback: Investigating Strategies of Providing Synchronous Grammatical Error Feedback in a Gui-based Language Learning Social Chatbot,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “second-language learners” and “language-learning AI chatbots” but does not specify that the target language is English or that participants are ESL/EFL/ELL learners. The L2 and context are not explicitly identified.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates a GUI-based language-learning social chatbot providing synchronous grammatical error feedback. There is no indication that the chatbot is powered by a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model). It appears to be a feedback-delivery interface rather than an LLM-integrated writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on synchronous grammatical corrective feedback in conversational chatbot interactions, including spoken language skills and general language learning experience and intention to use. Writing competence or writing-related variables are not the primary focus; online writing tasks are only mentioned as background, not as the main outcome context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported concern “learning experiences” and “intention to use the system.” The abstract does not mention quantifiable writing performance metrics or other objective writing outcomes; it centers on user experience and feedback presentation methods.""
    }
}"
832,Using Ai-based Detectors to Control Ai-assisted Plagiarism in Esl Writing: the Terminator Versus the Machines,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is ESL composition, implying participants or texts from ESL learners. The focus is on ESL writing and AI-assisted plagiarism in ESL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates RoBERTa-based AI detectors and their ability to identify ChatGPT-generated texts. There is no experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or processes; instead, it evaluates detection tools.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on controlling AI-assisted plagiarism and evaluating AI-based detectors’ accuracy, not on improving writing competence or writing-related learning outcomes. It is an assessment/detection study rather than a writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported concern detection accuracy of RoBERTa-based classifiers on human vs. ChatGPT-generated essays. No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) for learners are reported.""
    }
}"
833,Analyzing Bias in Large Language Model Solutions for Assisted Writing Feedback Tools: Lessons from the Feedback Prize Competition Series,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions English Language Learner status as a demographic factor, the study does not focus on L2 English learners as participants in an instructional context; rather, it analyzes model performance across demographic groups within an existing dataset.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study analyzes winning LLM-based solutions used for evaluating student writing in competitions. There is no experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on bias and performance of LLM-based evaluation models (automated feedback/assessment), not on improving learners’ writing competence through instructional use of LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are model performance accuracy and bias across demographic groups, not quantifiable writing outcomes for learners following an LLM-mediated writing intervention.""
    }
}"
834,Investigating Efl Students' Writing Skills through Artificial Intelligence: Wordtune Application as a Tool,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Saudi English as a Foreign Language (EFL) students, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Wordtune (and mentions Grammarly) as AI-powered writing tools. The abstract does not indicate that these are large language model (LLM)-based tools (e.g., ChatGPT/GPT-4-style transformer generative models), and Wordtune/Grammarly are typically not framed as LLM-based pedagogical agents in this context. Thus it does not meet the requirement of integrating LLMs into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly focuses on EFL students’ writing skills and examines how Wordtune facilitates their writing, including lexical and syntactic gains and overall writing quality. The primary focus is writing competence, not automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental design with control and experimental groups, pretests and post-tests, and final writing exam scores analyzed quantitatively, along with rated writing samples. These provide quantifiable writing outcome metrics.""
    }
}"
835,Engaging Efl Students’ Critical Thinking Tendency and In-depth Reflection in Technology-based Writing Contexts: a Peer Assessment-incorporated Automatic Evaluation Approach,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are clearly described as university EFL (English as a Foreign Language) writing students, so the population consists of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses an automatic writing evaluation (AWE) system integrated with peer assessment. The abstract does not indicate that the AWE tool is an LLM-based, transformer generative model (e.g., ChatGPT, GPT-4). AWE in this context typically refers to non-LLM scoring/feedback systems, which fall outside the review’s scope.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on EFL writing instruction and performance in technology-based writing contexts, examining how AWE and peer assessment affect writing performance, motivation, critical thinking, and anxiety. Writing competence is a primary focus.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes: the PA-AWE group ‘outperformed’ the control group in EFL writing performance, learning motivation, critical thinking, and writing anxiety, implying measured, comparative writing-related outcomes from a quasi-experiment.""
    }
}"
836,Artificial Intelligence in Global World: a Case Study of Grammarly as E-tool on Esl Learners’ Writing of Darul Uloom Nadwa,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Madrasa ESL learners in India (Alimiyat grade), explicitly described as English as a Second Language (ESL) students, with focus on English writing and inflectional morpheme errors.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Grammarly as an electronic tool. Grammarly is a grammar-checking/writing support tool and is not described as an LLM-based, transformer generative model (e.g., ChatGPT, GPT-4). The study does not involve integration of large language models into instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on improving ESL learners’ writing, specifically reducing inflectional morpheme errors. The intervention is pedagogical, comparing Grammarly-supported writing with communicative language teaching, not automated essay scoring research.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantitative writing outcomes: pre- and post-treatment measures of inflectional morpheme-related errors analyzed via repeated-measures two-way ANOVA, showing Grammarly enhanced ESL learners’ writing relative to a control group.""
    }
}"
837,Understanding English as a Foreign Language Students’ Idea Generation Strategies for Creative Writing with Natural Language Generation Tools,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as English as a foreign language (EFL) students in Hong Kong secondary schools, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses “natural language generation (NLG) tools” for idea generation in creative writing, but the abstract does not specify whether these are large language model–based tools (e.g., ChatGPT, GPT-4) or other, non-LLM NLG systems. Thus it is unclear if LLMs are involved.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is creative writing: students attend workshops to learn to write stories using their own words and words generated by NLG tools. The focus is on writing processes (idea generation) in an instructional setting.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is exploratory and uses thematic analysis of students’ written reflections about their experience with NLG tools. The abstract does not report any quantitative or experimental writing outcome measures (e.g., writing quality scores, complexity, accuracy). It focuses on strategies and concerns, not measurable writing gains.""
    }
}"
838,Exploring the Role of Artificial Intelligence in Facilitating Assessment of Writing Performance in Second Language Learning,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are students in a Chinese language learning program in the US, and the study focuses on assessing writing accuracy in Chinese, not English. Thus, the target language is not L2 English.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses four LLMs (GPT-4, GPT-3.5, iFLYTEK, Baidu Cloud) via official APIs to assess writing accuracy, indicating integration of LLMs in language-related assessment, though not as a pedagogical intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on using LLMs to assess writing accuracy and compare their ratings to human raters. This is an automated assessment/essay scoring context, not an instructional or intervention context aimed at improving writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports performance metrics of LLMs (e.g., precision, robustness, efficiency) in rating writing, not quantifiable outcomes of a writing intervention on learners’ writing performance. There is no experimental or quasi-experimental pedagogical intervention with learner writing outcomes.""
    }
}"
839,Interaction Patterns between Learners and Ai Tools for English Writing,2023,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL (English as a foreign language) undergraduates, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to an unspecified 'AI tool for English writing' but does not indicate whether it is a large language model (e.g., ChatGPT, GPT-4) or a non-LLM tool (e.g., grammar checker). Without the tool’s nature or name, it is impossible to confirm that an LLM is integrated into the writing instruction or process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on how EFL learners interact with an AI tool 'for English writing' and how different interaction patterns affect 'writing performance,' which aligns with a primary focus on writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study 'explores the effects of different interaction patterns on their writing performance' and reports that different patterns lead to varied benefits, implying quantitative comparison of writing outcomes across clusters, even though specific metrics are not detailed in the abstract.""
    }
}"
840,Empowering Language Learners: Harnessing Computer-based Writing for Enhanced Chinese Language Proficiency,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are Chinese Language (CL) learners in Singapore primary schools, focusing on Chinese language proficiency and Chinese writing, not L2 English learners or English writing outcomes.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is computer-based writing (CBW) versus paper-and-pen writing in Chinese. Generative AI is only mentioned in a proposed future platform (WeeWrite) and is not part of the implemented experimental or quasi-experimental intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on writing quality and related variables (typing speed, handwriting speed, writing strategies) in the context of computer-based writing, which is a writing competence context, albeit in Chinese.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcome metrics, comparing post-CBW and post-PPBW scores using mixed-effects modeling to assess the impact on writing quality.""
    }
}"
841,Exploring the Potential of Chatgpt in Assessing L2 Writing Accuracy for Research Purposes,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions '100 L2 essays across five proficiency levels' but does not specify that these are L2 English learners or that the target language is English. The L2 could be any language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT-4 is used to measure linguistic accuracy and detect errors in L2 essays, not as part of an instructional or quasi-experimental writing intervention. The focus is on tool validation for research purposes, not on integrating LLMs into teaching or learning processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on assessing ChatGPT’s performance in error detection (measurement/assessment function), not on improving learners’ writing competence or implementing a pedagogical writing intervention. This aligns with automated assessment validation rather than instructional use.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics related to learner improvement or intervention effects are reported. Outcomes concern precision, recall, and correlation between ChatGPT and human error coding, not changes in learners’ writing performance.""
    }
}"
842,Using Ai-based Detectors to Control Ai-assisted Plagiarism in Esl Writing: “the Terminator Versus the Machines”,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is ESL composition, implying involvement of L2 English learners in ESL settings. The focus is on essays written in English within ESL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates RoBERTa-based AI detectors for identifying ChatGPT-generated texts. ChatGPT is used as a source of machine-generated essays, not as an instructional or intervention tool in writing pedagogy. There is no experimental or quasi-experimental design integrating LLMs into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on controlling AI-assisted plagiarism and evaluating AI-based detectors’ accuracy, not on improving writing competence or writing-related pedagogical outcomes. It is essentially a detection/forensics study rather than a writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) are reported. Outcomes relate to detection accuracy of classifiers, not to learners’ writing performance following an LLM-mediated intervention.""
    }
}"
843,"A Triple Challenge: Students' Identification, Interpretation, and Use of Individualized Automated Feedback in Learning to Write English as a Foreign Language.",2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are eighth-grade students learning English as a foreign language, clearly indicating an EFL context and L2 English learners: “eighth-grade students'…writing skills in English as a foreign language.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses an “AI-based automated essay assessment tool (EAT)” that provides automatic feedback and logs revisions. There is no indication that this tool is a large language model (e.g., ChatGPT/GPT-style transformer-based generative model); it is framed as an automated essay assessment system, which typically predates LLMs and focuses on scoring/feedback rather than generative language modeling.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence and related processes: “assessment literacy and writing skills in English as a foreign language,” and the study examines how automated feedback and teacher/peer discussion foster students’ writing skills.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes: “the improvements made on the essay based on the feedback logs… and the different versions of the essay were examined using frequency analyses,” indicating measurable changes in writing following the intervention.""
    }
}"
844,From Process to Product: Writing Engagement and Performance of Efl Learners under Computer-generated Feedback Instruction,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 42 English as a foreign language (EFL) learners, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Pigai, described as a Chinese automated writing evaluation (AWE) system. Pigai is a traditional AWE tool, not specified as an LLM or transformer-based generative model (e.g., ChatGPT, GPT-4). Thus it does not meet the requirement that the intervention integrate an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on revision processes and writing products, analyzing feedback uptake and text quality (complexity, accuracy, fluency), which are core writing-related variables in L2 writing instruction.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes, including text quality measured via complexity, accuracy, and fluency (CAF), and examines the impact of automated feedback on these measures.""
    }
}"
845,"Artificial Intelligence in Language Instruction: Impact on English Learning Achievement, L2 Motivation, and Self-regulated Learning",2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are English as a Foreign Language (EFL) university students, and outcomes are explicitly about English learning (grammar, vocabulary, reading, writing).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract only states that the experimental group received “AI-mediated instruction” via an “AI platform” or “AI-powered platforms.” It does not specify that the AI is a large language model (e.g., ChatGPT, GPT-4) or a transformer-based generative model. It could be any AI-driven educational technology, so it cannot be confidently classified as an LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing is one of several domains assessed (grammar, vocabulary, reading comprehension, and writing skills), but the primary focus appears to be overall English learning achievement, L2 motivation, and self-regulated learning rather than writing competence specifically. The extent to which writing is a central focus is not clear from the abstract.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Pre- and post-tests were used to evaluate English learning achievement, including writing skills, providing quantifiable outcome measures. Thus, there are experimental measures of writing-related performance, even if writing is only one component.""
    }
}"
846,Local Similarity and Global Variability Characterize the Semantic Space of Human Languages,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study uses TOEFL essays written by 38,500 speakers from various native languages, the focus is not on these writers as L2 learners in an instructional ESL/EFL/ELL context, but on cross-linguistic semantic variability. The participants are not situated in a pedagogical intervention or learning context targeting English writing development.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Large language models are used as analytic tools to characterize semantic space across languages, not as an instructional intervention or integrated into learners’ writing processes. There is no experimental or quasi-experimental design where LLMs support or mediate writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on semantic variability and cross-linguistic meaning organization, not on writing competence or writing-related pedagogical variables. TOEFL essays are used as data to infer semantic structure, not to improve or assess writing through an educational intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study does not report quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity) resulting from an LLM-mediated intervention. Outcomes concern semantic similarity/variability across languages, not changes in learners’ writing performance.""
    }
}"
847,Bibliometrically and Systematically Analyzing Automated Writing Evaluation for English Learning,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a bibliometric and systematic review of automated writing evaluation (AWE) for English learning, not an empirical study with its own participant sample. It synthesizes 56 peer-reviewed articles rather than reporting original data from a defined group of L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The work is a bibliometric and systematic review of AWE tools in general. It does not report an experimental or quasi-experimental intervention using a specific LLM (e.g., ChatGPT, GPT-4) in writing instruction; instead, it aggregates prior studies on AWE, many of which may not involve LLMs.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the topic is automated writing evaluation in English learning, the paper’s primary focus is mapping the literature (topics, authors, countries) and summarizing general findings, not implementing or evaluating a concrete pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study does not present original quantitative writing outcome measures from an intervention. It synthesizes existing studies and discusses overall effectiveness and variability, which falls under review/overview rather than reporting new experimental outcomes.""
    }
}"
848,Enhancing Academic Writing Skills and Motivation: Assessing the Efficacy of Chatgpt in Ai-assisted Language Learning for Efl Students,2023,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese English as a Foreign Language (EFL) students. The abstract explicitly states the context is EFL and focuses on English writing skills and motivation, satisfying the L2 English learner requirement.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is ‘AI-assisted instruction via ChatGPT’ for the experimental group, compared to traditional instruction. ChatGPT is a large language model, and the design is experimental with random assignment and pre/post testing.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on academic writing skills and writing motivation. The intervention integrates ChatGPT into language learning specifically to impact writing, not for automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a pre-test and post-test design to assess writing skills, with writing samples evaluated using established scoring rubrics. Quantitative analysis reports significant improvements in writing skills and motivation, providing measurable writing outcomes.""
    }
}"
849,"A Triple Challenge: Students’ Identification, Interpretation, and Use of Individualized Automated Feedback in Learning to Write English as a Foreign Language",2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are eighth-grade students learning English as a foreign language, clearly an EFL context with English as the target language: “eighth-grade students’ … writing skills in English as a foreign language.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses an “AI-based automated essay assessment tool (EAT)” that provides automatic feedback. The abstract frames it as an automated essay assessment system, not as an LLM (e.g., ChatGPT/GPT-4) or transformer-based generative model integrated into instruction. No indication is given that the tool is a large language model; it appears to be a conventional automated essay scoring/feedback system.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on “assessment literacy and writing skills in English as a foreign language” and how automated feedback plus teacher/peer discussion fosters students’ writing skills. This is a pedagogical writing intervention, not merely evaluation of an automated scoring system’s reliability.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study examines “improvements made on the essay based on the feedback logs … and the different versions of the essay … using frequency analyses,” indicating quantifiable writing outcome measures related to revisions and improvements.""
    }
}"
850,Second Language Learners’ Post-editing Strategies for Machine Translation Errors,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract refers to generic 'second language (L2) learners' and 'L2 writing' but does not specify that the target language is English or that the context is ESL/EFL/ELL. The institutional affiliation (University of Hawaii at Manoa) does not guarantee that the L2 is English in this study.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Google Translate, described as a neural machine translator. While it is an AI tool, the abstract does not indicate that it is a large language model (LLM) such as ChatGPT/GPT-4 or similar transformer-based generative model used interactively for writing instruction. The focus is on MT output and post-editing, not on an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study clearly focuses on L2 writing: learners use machine translation to address lexical and grammatical problems during L2 writing, and the analysis concerns MT errors, post-editing strategies, and writing competence in the 'AI era.'""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports a quantitative outcome: 'Successfulness of PE was gauged by comparing sentence adequacy scores of the MT output and PEd texts.' This provides measurable writing-related outcomes linked to the intervention.""
    }
}"
851,Engineering Chatgpt Prompts for Efl Writing Classes,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers generally to 'EFL education' and 'student writing' but does not specify that an empirical study with EFL learners was conducted, nor provide participant details. It may be a conceptual or practical article rather than a participant-based study.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is discussed as a feedback tool and the article 'will demonstrate effective prompts for writing classes', there is no indication of an experimental or quasi-experimental design or structured intervention being implemented and evaluated. It appears to be a descriptive or pedagogical piece on prompt design.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on EFL writing classes and feedback on student writing, which is writing-related. However, without evidence of an actual intervention study, it is unclear whether the context meets the review’s requirement for a pedagogical intervention rather than a conceptual discussion.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or assessment of effectiveness. It only states that the article will demonstrate effective prompts, suggesting no empirical evaluation of writing outcomes.""
    }
}"
852,Exploring the Effects of Grammarly on Efl Students’ Foreign Language Anxiety and Learner Autonomy,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students in academic writing courses at a Japanese university, clearly L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Grammarly, described as an automated writing evaluation (AWE) tool. Grammarly is not an LLM-based, transformer generative model like ChatGPT or GPT-4; it is an AI-assisted grammar checker, which falls outside the specified LLM-based tools.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is L2 English academic writing, with Grammarly used while editing English writing. The focus is on writing-related variables (foreign language anxiety and learner autonomy in writing).""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports pre- and post-survey measures of foreign language anxiety and learner autonomy, and qualitative perceptions. It does not report quantifiable writing performance outcomes; the main outcomes are affective and autonomy-related, not direct writing competence metrics.""
    }
}"
853,"2023 Ieee 15th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management, Hnicem 2023",2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The record is a conference proceedings volume containing 263 papers. One listed paper is “utilization of artificial intelligence in academic writing class: L2 learners perspective,” which may involve L2 learners, but no specific information on participants or language (English vs. other) is provided in the abstract of the proceedings.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The proceedings-level abstract does not specify that any paper uses large language models (e.g., ChatGPT, GPT-4). The mentioned study on AI in academic writing is generic (“artificial intelligence”) with no indication that it is LLM-based or that it uses transformer-based generative models in an experimental or quasi-experimental design.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""One paper title suggests a focus on academic writing (“utilization of artificial intelligence in academic writing class: L2 learners perspective”), but the proceedings abstract provides no detail on whether the primary focus is writing competence or pedagogy versus general perceptions or technology use.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental results are reported in the proceedings abstract. It only lists paper titles and broad topics, so it is impossible to confirm that any included study reports measurable writing outcomes from an AI/LLM-mediated intervention.""
    }
}"
854,Fusion Weighted Features and Bilstm-attention Model for Argument Mining of Efl Writing,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The title mentions EFL writing, suggesting texts may be from EFL learners, but the abstract does not specify participants, learner status, or that the corpus consists of L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study proposes an argument mining model using BERT and BiLSTM-attention for automatic annotation of argumentative essays. This is an NLP system evaluation, not an experimental or quasi-experimental pedagogical intervention integrating an LLM into writing instruction or writing processes for learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on argument mining performance and potential support for automated scoring, not on improving learners’ writing competence or writing-related variables through an instructional intervention. It evaluates a computational model, not a teaching/learning context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are model precision (69%) and comparison with existing models. There are no quantifiable learner writing outcomes or measures of writing improvement resulting from an LLM-mediated intervention.""
    }
}"
855,"Navigating the Impact of Chatgpt/gpt4 on Legal Academic Examinations: Challenges, Opportunities and Recommendations",2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract discusses students and researchers in universities and higher education generally, including non-native English speakers, but it does not specify that the population is L2 English learners in ESL/EFL/ELL contexts, nor does it present empirical data on such a population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper is a conceptual/discussion piece about the impact of ChatGPT/GPT-4 on academic writing, plagiarism, and ethics. It does not describe an experimental or quasi-experimental intervention integrating LLMs into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""While the focus is on academic writing and AI tools, the article addresses challenges, opportunities, and policy/ethical recommendations rather than a pedagogical intervention aimed at improving writing competence with measurable outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental measures are reported. The article proposes strategies and discusses implications but does not assess the effectiveness of an LLM-mediated writing intervention.""
    }
}"
856,Teachers’ Reflections on Academic Dishonesty in Efl Students’ Writings in the Era of Artificial Intelligence,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The participants are 67 teachers, not L2 English learners. Although the context involves EFL students’ writings, the data and analysis focus on teachers’ perceptions rather than on L2 learners as the study population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study explores teachers’ perceptions of AI and academic dishonesty; it does not describe an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is academic dishonesty and ethical implications of AI in student writing, not on improving writing competence or writing-related pedagogical interventions using LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study is based on questionnaires and interviews about perceptions, without experimental measures of writing performance or structured LLM-mediated writing interventions.""
    }
}"
857,Chatgpt's Capabilities in Spotting and Analyzing Writing Errors Experienced by Efl Learners,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly refers to 'English as a foreign language (EFL) learners' and 'EFL writing education', indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates ChatGPT’s effectiveness in detecting EFL learners’ writing errors compared to human instructors. It evaluates ChatGPT as an error-detection tool, not as part of an experimental or quasi-experimental pedagogical intervention in writing instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on ChatGPT’s capability to spot and analyze writing errors (i.e., tool performance and reliability), similar to an automated error-detection/assessment study. There is no described instructional intervention or integration into learners’ writing development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported concern ChatGPT’s error-detection performance (e.g., types of errors identified, F-score, p-value). There are no quantifiable learner writing outcome measures (e.g., improvement in writing quality, accuracy, complexity) following an LLM-mediated intervention.""
    }
}"
858,Improving Logical Flow in English-as-a-foreign-language Learner Essays by Reordering Sentences,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The corpus ICNALE-AS2R consists of essays written by English-as-a-foreign-language learners from various Asian countries, clearly indicating an EFL L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study proposes and evaluates a computational sentence reordering system trained on learner essays. It is an NLP/AI system development and evaluation paper; there is no indication that an LLM (e.g., ChatGPT, GPT-4) is used, nor that the system is integrated into an instructional intervention with learners.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on developing an automatic sentence reordering system and evaluating its performance on metrics like longest common subsequence ratio and Kendall’s Tau. There is no pedagogical context, classroom implementation, or writing instruction intervention; it is a text-processing task, not a teaching/learning intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are system performance metrics on reordering accuracy, not learner writing outcomes. No experimental or quasi-experimental measures of changes in learners’ writing competence or related variables are presented.""
    }
}"
859,Second Language Learners' Post-editing Strategies for Machine Translation Errors,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study involves 57 second language (L2) learners using Google Translate in L2 writing. While the target language is not explicitly stated as English, the general L2 context and focus on L2 writing suggest it could include English; however, this is not central to the exclusion decision.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention centers on Google Translate, a neural machine translation (MT) system, not a large language model (LLM) such as ChatGPT, GPT-4, or similar transformer-based generative models used interactively for writing instruction. The study analyzes post-editing of MT output rather than an LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly L2 writing: learners use MT output during L2 writing and apply post-editing strategies to address lexical and grammatical problems. The focus is on writing competence and strategies in an AI-supported writing process.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes: sentence adequacy scores comparing MT output and post-edited texts, and examines how proficiency affects successful post-editing. These are measurable writing-related outcomes.""
    }
}"
860,The Impact of Artificial Intelligence in Foreign Language Learning Using Learning Management Systems: a Systematic Literature Review,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract focuses on English as a foreign language and discusses learners and teachers in EFL contexts using AI via learning management systems. Thus, the population is aligned with L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a systematic literature review, not an experimental or quasi-experimental primary study. It synthesizes prior work on AI tools in LMSs rather than implementing a specific LLM-based intervention itself.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing is mentioned among the four skills, the paper’s primary focus is broad foreign language learning (reading, writing, speaking, listening) and the general effects of AI in LMSs, not a targeted writing competence intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic literature review, it does not report original, quantifiable writing outcome metrics from an intervention; instead, it summarizes perceived benefits and general improvements across skills.""
    }
}"
861,The Application of Chatbot as an L2 Writing Practice Tool,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were 75 Korean elementary school students engaged in English L2 writing practice, clearly an EFL/ESL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention used a chatbot developed with Google Dialogflow by encoding textbook expressions. This is a rule/intent-based chatbot, not a transformer-based large language model such as ChatGPT, GPT-4, Gemini, etc. Thus, it does not meet the requirement that the intervention integrate an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly focuses on chatbot-based L2 writing practice and compares it with traditional teacher-led writing instruction, with the primary outcome being writing performance.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports pretest and posttest writing performance scores and compares experimental and control groups, providing quantifiable writing outcome metrics. It also includes a survey, but the quantitative writing scores satisfy C4.""
    }
}"
862,Academic Integrity Considerations of Ai Large Language Models in the Post-pandemic Era: Chatgpt and beyond,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions 'supporting EFL learners' as one of several potential uses of LLMs, but the paper is framed broadly around students and higher education institutions, not a defined population of L2 English learners. It is unclear whether any empirical data specifically involve EFL/ESL/ELL participants.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper is a conceptual/position piece on academic integrity and the potential uses and risks of LLMs such as ChatGPT. It does not describe an experimental or quasi-experimental design integrating LLMs into writing instruction or writing processes; rather, it discusses possibilities and policy implications.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""While writing and composition are mentioned, the primary focus is academic integrity, plagiarism detection, and institutional policy in the post-pandemic era. There is no structured pedagogical intervention targeting writing competence; writing is discussed mainly as the context in which integrity issues arise.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantitative writing outcome measures or assessment of intervention effectiveness. It analyzes issues and demonstrates that LLMs can generate undetectable text, but there is no experimental measure of changes in learners’ writing performance.""
    }
}"
863,A Systematic Review on Artificial Intelligence Dialogue Systems for Enhancing English as Foreign Language Students’ Interactional Competence in the University,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The population of interest in the reviewed studies is English as a Foreign Language (EFL) university students, i.e., L2 English learners in an EFL context. The abstract explicitly states the focus is on EFL university students’ interactional competence and English language abilities.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article itself is a systematic review of AI dialogue systems, not an experimental or quasi-experimental primary study integrating a specific LLM (e.g., ChatGPT, GPT-4) into writing instruction. As a review article, it does not present a distinct LLM-based intervention designed and tested by the authors.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on interactional competence and broader EFL learning (reading, writing, listening) via AI dialogue systems, not specifically on writing competence or writing-related variables. Writing is mentioned only generally as one of several skills previously improved, and the review centers on interactional competence, not writing-focused pedagogy.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a systematic review, the study does not report original, quantifiable writing outcome metrics from an LLM-mediated intervention conducted by the authors. It synthesizes prior work on AI dialogue systems and interactional competence, and the abstract does not indicate any experimental measures of writing outcomes.""
    }
}"
864,Utilizing Artificial Intelligence Technologies in Saudi Efl Tertiary Level Classrooms,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly Saudi EFL tertiary-level classrooms, i.e., learners of English as a foreign language in Saudi Arabia. The abstract explicitly refers to EFL and ELT settings, indicating L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study discusses a broad range of AI technologies (Google Translate, Bing Translator, machine translation, automatic evaluation systems, and Wordtune). These are not identified as large language model–based tools, and the design is exploratory using questionnaires about use and perceptions, not an experimental or quasi-experimental LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing with AI technologies is mentioned, the primary focus is on general AI use in EFL classrooms and communication training, not on a structured writing competence intervention. It is framed as an exploratory investigation of AI technologies in ELT rather than a targeted writing-instruction context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Data were collected via questionnaires and analyzed with SPSS, indicating attitudinal or usage measures. The abstract does not report any quantifiable writing performance outcomes or writing-related proficiency metrics; it only concludes that AI technologies can assist teaching and learning.""
    }
}"
865,A Corpus-based Study of the Usage of Chinese Core Separable Words in the Use of Language,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are Chinese as a second language learners and native Chinese speakers. The focus is on learning and usage of Chinese core separable words, not on L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a corpus-based analysis using BCC, CCL, and HSK corpora. There is no mention of large language models, ChatGPT-like systems, or any AI-based instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is lexical usage of Chinese separable words and their treatment in International Chinese Language Education, not writing competence in English or writing-related interventions with LLMs.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports corpus-based usage patterns and error types, not quantifiable outcomes of an LLM-mediated writing intervention. There is no experimental or quasi-experimental design assessing writing outcomes.""
    }
}"
866,A Deep Fusion Model for Human Vs. Machine-generated Essay Classification,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions essays in English and Spanish written by L2 learners, it does not specify that these are L2 English learners in ESL/EFL/ELL contexts, and the focus is on classification of human vs. machine-generated essays rather than L2 English learning.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study proposes a deep neural network-based classifier for distinguishing human vs. machine-generated essays. There is no experimental or quasi-experimental pedagogical intervention integrating an LLM (e.g., ChatGPT) into writing instruction or processes; LLMs are only an implicit source of machine-generated text.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on essay classification for academic integrity (human vs. machine-generated), not on improving writing competence or writing-related learning outcomes. It is essentially a text classification/forensics task, not a writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) are reported. Outcomes are model performance metrics (classification accuracy, etc.), not learner writing development under an LLM-mediated intervention.""
    }
}"
867,Efl Paraphrasing Skills with Quillbot: Unveiling Students' Enthusiasm and Insights,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as EFL (English as a foreign language) preparatory year students, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention tool is QuillBot. Based on the review’s criteria, tools like QuillBot are treated as AI writing aids that are not clearly positioned as transformer-based generative LLMs for instructional integration. The abstract does not indicate use of an LLM such as ChatGPT, GPT-4, Gemini, etc., but rather a paraphrasing tool, which falls under the exclusion note for non-LLM AI tools.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on paraphrasing skills within writing, including performance in synonyms, sentence structure, and word choice, and the context is a writing class. This aligns with writing competence as the primary focus.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a quasi-experimental design and reports that students improved their performance in synonyms, sentence structure, and word choice, indicating quantifiable writing-related outcome measures alongside attitudinal data.""
    }
}"
868,Comparing Measures of Syntactic and Lexical Complexity in Artificial Intelligence and L2 Human-generated Argumentative Essays,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are first-year Tswana L2 learners of English at a South African university, clearly an L2 English learner population in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT-3.5 is used only to generate comparison essays; there is no experimental or quasi-experimental pedagogical intervention integrating the LLM into writing instruction or learners’ writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on comparing syntactic and lexical complexity between AI- and human-generated essays, not on improving learners’ writing competence or implementing a writing intervention. It is an analytic comparison, not a teaching/learning context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics for an LLM-mediated intervention are reported. The study analyzes complexity features but does not assess changes in learners’ writing due to an LLM-based instructional treatment.""
    }
}"
869,The Use and Abuse of Artificial Intelligence-enabled Machine Translation in the Efl Classroom: an Exploratory Study,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners in higher education where English is not their first language, fitting the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses AI-enabled machine translation, specifically Google Translate. GT is not described as an LLM-based, transformer generative model used as a writing assistant (e.g., ChatGPT, GPT-4); it is a machine translation tool, which falls outside the specified LLM-focused intervention scope.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study compares writing drafts created with and without Google Translate, focusing on how MT use affects writing quality and learners’ practices in the EFL classroom, which is directly related to writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Pre- and post-tests are used to compare the quality of writing drafts with and without GT, indicating quantifiable writing outcome measures are reported.""
    }
}"
870,Work in Progress: Chatgpt as an Assistant in Paper Writing,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions “non-native English speakers,” which suggests L2 English users, but it does not specify ESL/EFL/ELL instructional contexts or participant characteristics. It may be more conceptual than participant-based.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as a discussion of the potential of ChatGPT as an assistant in paper writing. There is no indication of an experimental or quasi-experimental design, structured intervention, or empirical implementation of ChatGPT in instruction.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is on “paper writing” in natural English, which is writing-related, but the abstract frames it as a conceptual discussion of ChatGPT’s potential and ethical use rather than a pedagogical intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or empirical evaluation are mentioned. The abstract only states that the paper discusses potential and educational use, with no indication of measured effects on writing performance.""
    }
}"
871,A Deep Fusion Model for Human $vs$. Machine-generated Essay Classification,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract states that the datasets contain short essays in English and Spanish written by L2 learners. Thus, the population includes L2 learners writing in English, which fits the ESL/EFL/ELL context requirement.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study proposes a deep neural network-based model for classifying essays as human vs. machine-generated. It does not describe an instructional intervention using an LLM (e.g., ChatGPT) in writing instruction or processes; instead, it is a text classification/modeling study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on essay classification for academic integrity (human vs. machine-generated), not on improving writing competence or writing-related pedagogical variables. It is a computational classification task rather than a writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity) are reported. Outcomes relate to classification performance, not to the effectiveness of an LLM-mediated writing intervention.""
    }
}"
872,A Syntactic Complexity Analysis of Revised Composition through Artificial Intelligence-based Question-answering Systems,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are college English learners taking the TEM-4 test, which is an English proficiency test for Chinese EFL learners. The focus is clearly on L2 English argumentative essay writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although ChatGPT (an LLM) is used to revise students’ essays, the design is a comparison between original student texts and ChatGPT-revised versions, not an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction or learners’ writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on syntactic complexity differences between human-written and AI-revised texts. There is no described instructional context, no learner interaction with the tool as part of a teaching/learning intervention, and no evaluation of writing competence development—only text-level comparison.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports syntactic complexity metrics comparing student vs. ChatGPT-revised essays, but these are not outcomes of an LLM-mediated intervention on learners’ writing performance over time. No experimental measures of learner improvement or structured intervention outcomes are reported.""
    }
}"
873,Intertextuality in Pre-service Teachers' Argumentative Essay in Raising Ai: Practices and Beliefs,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Indonesian EFL pre-service teachers, clearly L2 English learners in an EFL context: “Indonesian EFL pre-service teachers… were recruited as participants.”""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions “argumentative essays assisted by AI” and “assistance using AI while writing argumentative essays,” but does not specify that the AI is an LLM (e.g., ChatGPT, GPT-4) or describe the AI tool or its generative/transformer-based nature. It could be any AI-based support, not necessarily an LLM, and there is no explicit experimental or quasi-experimental intervention design described.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on argumentative essay writing and intertextuality practices: “investigate… intertextuality in argumentative essays assisted by AI.” This is a writing-focused context, examining rhetorical moves and use of sources in EFL academic writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as a case study using content analysis of essays and interviews to portray practices and beliefs. There is no indication of an experimental or quasi-experimental design, no comparison groups, and no reported quantifiable writing outcome metrics assessing effectiveness of an AI/LLM-mediated intervention. The focus is descriptive/qualitative (practices and beliefs), not on measured writing gains.""
    }
}"
874,Utilization of Artificial Intelligence in Academic Writing Class: L2 Learners Perspective,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as second language (L2) learners in the Philippines, implying English L2 learners in an EFL/ESL academic writing context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a descriptive survey of perceptions and experiences with AI tools; there is no experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly academic writing, focusing on how AI tools are utilized to support various aspects of writing (idea generation, error detection, structural feedback, etc.).""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports awareness, preferences, and concerns, but does not mention any quantifiable writing outcome measures or effectiveness data from an AI-mediated writing intervention.""
    }
}"
875,Looks like Google to Me: Instructor Ability to Detect Machine Translation in L2 Spanish Writing,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are L2 learners of Spanish in an intermediate-level writing course. The target language is Spanish, not English, so the population does not match the review’s focus on L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study concerns detection of machine translation (MT) in L2 Spanish writing, not an instructional intervention using large language models such as ChatGPT or GPT-4. MT tools are not specified as LLM-based generative models, and there is no experimental or quasi-experimental LLM-mediated writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on instructors’ ability to detect MT versus non-MT texts and related factors, not on a pedagogical intervention aimed at improving writing competence through LLM integration.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study does not report quantifiable writing outcome metrics assessing the effectiveness of an LLM-mediated writing intervention; it reports detection accuracy and related variables instead.""
    }
}"
876,Impact of Chatgpt on Learners in a L2 Writing Practicum: an Exploratory Investigation,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract clearly states the context is a 'one-week L2 writing practicum' and refers to 'L2 writing learners,' indicating participants are second language learners engaged in English L2 writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""ChatGPT, an AI-powered chatbot capable of automatic text generation, was applied in a one-week L2 writing practicum. This is an LLM-based tool integrated into writing instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly L2 writing pedagogy and a writing practicum, focusing on the impact of ChatGPT on L2 writing learners and composing workflows, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is described as adopting a qualitative approach to investigate students' behaviors, reflections, developmental features in learning activities, and perceptions. There is no mention of quantitative or experimental writing outcome measures (e.g., scores, rubric-based improvements), only exploratory qualitative evaluation.""
    }
}"
877,Roles and Research Foci of Artificial Intelligence in Language Education: an Integrated Bibliographic Analysis and Systematic Review Approach,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a broad review of AI in language education (AILEd) from 1990–2020 and does not focus specifically on L2 English learners in ESL/EFL/ELL contexts. It aggregates diverse studies across language skills and technologies without specifying an L2 English learner population as the primary focus.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is an integrated bibliographic analysis and systematic review, not an experimental or quasi-experimental study implementing an LLM-based intervention. It surveys prior work using ITS, NLP, and various AI algorithms, but does not itself integrate LLMs (e.g., ChatGPT, GPT-4) into writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the review notes that writing is one of the main application domains in AILEd research, the article’s primary focus is mapping roles and research foci of AI across multiple skills and constructs, not conducting a specific writing competence intervention or study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a review article, it does not report original, quantifiable writing outcome metrics from an LLM-mediated intervention. It synthesizes existing literature and offers suggestions rather than testing and measuring the effectiveness of a particular AI/LLM writing intervention.""
    }
}"
878,Recipe: How to Integrate Chatgpt into Eflwriting Education,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 213 undergraduate and graduate students enrolled in EFL writing courses, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study introduces RECIPE, a platform that integrates ChatGPT (a large language model) into EFL writing education, with ChatGPT taking an EFL teacher role and engaging in dialogue based on students’ self-written summaries.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly EFL writing courses, and the platform is designed for revising an essay with ChatGPT, focusing on writing-related learning processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract states that the study collects interaction data, students’ perceptions and usage, examines user scenarios, and conducts interviews to explore design opportunities. It does not mention any experimental or quasi-experimental design with quantifiable writing outcome measures (e.g., writing scores, quality ratings, accuracy gains). Outcomes are primarily perceptions and usage, so it does not meet the requirement for quantifiable writing outcomes.""
    }
}"
879,Who Wrote This Essay? Detecting Ai-generated Writing in Second Language Education in Higher Education,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is English as a Second Language (ESL) in higher education, and the essays are C1-level L2 English texts. Although the participants are lecturers, the focus remains on L2 English writing in an ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates lecturers’ ability to detect AI-generated texts and compares their judgments with AI detectors. There is no experimental or quasi-experimental integration of an LLM (e.g., ChatGPT) into writing instruction or learners’ writing processes as an intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is academic integrity and detection of AI-generated writing, not on improving learners’ writing competence or implementing a pedagogical writing intervention. It examines assessment practices and detection challenges rather than writing instruction outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics for learners are reported. The study analyzes lecturers’ evaluations and AI detectors’ performance, not changes in students’ writing quality or related measurable writing outcomes following an LLM-mediated intervention.""
    }
}"
880,Assessing Second-language Academic Writing: Ai Vs. Human Raters,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are first-year college students producing L2 academic paragraph writing; the context is clearly second-language (L2) writing, likely English, used for departmental eligibility.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT-3.5 is used as an automated rater to score student writing, not as part of an instructional or intervention design to support writing development. There is no experimental or quasi-experimental LLM-based teaching or feedback intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on assessment—comparing AI vs. human raters for evaluating L2 writing quality. This is an automated essay scoring/assessment study, not a pedagogical writing intervention or process-oriented support.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing scores are reported, they are used solely to examine rater agreement (AI vs. humans), not to evaluate the effectiveness of an LLM-mediated writing intervention on learners’ writing outcomes over time.""
    }
}"
881,Large Language Model-based Artificial Intelligence in the Language Classroom: Practical Ideas for Teaching,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses language learning and language classrooms in general but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor that the focus is specifically on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper is described as providing examples and practical ideas for using LLMs (e.g., GPT/ChatGPT) for materials development, activities, and feedback. There is no indication of an experimental or quasi-experimental study design or an implemented intervention with participants; it appears to be a conceptual/practical article.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing is mentioned only indirectly via ‘materials development’ and ‘providing feedback’; the abstract does not state that the primary focus is on writing competence or writing-related variables, and seems to address language teaching more broadly.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantitative outcome measures or assessment of writing performance. It focuses on examples and discussion of potential uses, not on measured effects of an LLM-mediated writing intervention.""
    }
}"
882,"Perceptions of High School Students on Ai Chatbots Use in English Learning: Benefits, Concerns, and Ethical Consideration",2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are high school students using AI chatbots in English learning, which fits an EFL/ESL/ELL-type context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a perception survey about AI chatbot use; there is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) into a structured writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on general English learning, benefits, concerns, and ethical considerations. Writing competence or writing-related variables are not mentioned as a primary focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports perceptions and attitudes (via survey, frequency, means, t-test) but does not report quantifiable writing outcome metrics or effects of an LLM-mediated writing intervention.""
    }
}"
883,Analyzing Composition Complexity in Revised Versions through Artificial Intelligence-based Writing Assistants,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on English learners’ writing practice and analyzes university-level English essays, indicating an L2 English learner population in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Grammarly, described as an AI-powered correction system. Grammarly is not a large language model-based generative tool like ChatGPT or GPT-4; it is typically rule-based/ML-based proofreading, so it does not meet the LLM requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence, specifically lexical and syntactic complexity in essays before and after correction by Grammarly, which is clearly a writing-related outcome.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcome metrics, using three lexical complexity indicators and ten syntactic complexity indicators to measure changes in essays pre- and post-correction.""
    }
}"
884,Work in Progress: Safeguarding Authenticity: Strategies for Combating Ai-generated Plagiarism in Academia,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract does not specify that participants are L2 English learners in ESL/EFL/ELL contexts. It mentions students in STEM and use of English language sentence patterns, but their L1/L2 status and language learning context are not described.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""ChatGPT is used only to generate a comparison paragraph for plagiarism-detection purposes. There is no experimental or quasi-experimental design integrating an LLM into writing instruction or the students’ writing process as an intervention; rather, the focus is on assessment and detection of AI-generated plagiarism.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on safeguarding authenticity and detecting AI-generated plagiarism via a rubric, not on improving writing competence or writing-related pedagogical interventions. The LLM is not used as a teaching or learning tool for writing but as a source of text to be distinguished from human writing.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although rubric scores and thresholds are discussed, these metrics relate to identifying/deconstructing language frames for the purpose of distinguishing human vs. AI text, not to evaluating the effectiveness of an LLM-mediated writing intervention on learners’ writing outcomes.""
    }
}"
885,Teaching Chatbot Prompt Strategies in Efl Essay Writing Instruction,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are EFL students in an essay writing unit, which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “AI chatbots” and “chatbot outputs” but does not specify that these are large language models (e.g., ChatGPT, GPT-4). It could involve LLMs, but this is not explicit from the title/abstract alone.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly EFL essay writing instruction, focusing on AI chatbot prompt strategies within an essay writing unit, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on students’ perceptions, reflections, and content analysis of opportunities and challenges. There is no mention of quantitative writing outcome measures or experimental assessment of writing performance.""
    }
}"
886,"The Challenges of Developing Technological, Pedagogical, and Content Knowledge in Aviation English Field",2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Indonesian aviation English teachers working in an ESP (English for Specific Purposes) context, which implies a focus on L2 English teaching/learning. Thus, the population is relevant to L2 English education, even though learners themselves are not the direct participants.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study explores teachers’ perceptions of their TPACK development and challenges in using technologies generally. There is no mention of large language models (e.g., ChatGPT, GPT-4) or any specific LLM-based intervention; it is about technology integration in broad terms.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing is mentioned as a macro skill, the primary focus is on teachers’ technological, pedagogical, and content knowledge (TPACK) and challenges, not on a concrete writing instruction intervention or writing competence outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses qualitative interview data to examine perceptions. It does not report quantifiable writing outcome metrics or any experimental/quasi-experimental evaluation of a writing intervention.""
    }
}"
887,Integration of Big Data and Artificial Intelligence in Constructing Learners' Individualized Feedback System,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are described as '65 intermediate Chinese second language learners.' The population appears to be learners of Chinese as an L2, not L2 English learners in ESL/EFL/ELL contexts. The abstract does not mention English as the target language.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses an 'AI-based feedback system' for L2 writing, but there is no indication that it is based on large language models (e.g., ChatGPT, GPT-4, transformer-based generative models). It could be any AI feedback system, including non-LLM approaches.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on L2 writing feedback and its impact on 'writing quality,' 'writing proficiency,' and 'high-quality writing.' The intervention is clearly pedagogical and centered on writing instruction and feedback.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an experimental vs. control group design and reports that the AI-based feedback system 'will significantly improve learners' overall writing gains and the learning engagement,' implying quantifiable writing outcome measures were collected.""
    }
}"
888,An Investigation into the Use of Educational Apps in Efl Courses,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are 43 English teachers, not L2 English learners. The study focuses on teachers’ use of educational apps in EFL courses rather than on data from L2 learners themselves.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention involves general educational apps such as Quizizz, Blooket, and Kahoot. There is no mention of large language models (e.g., ChatGPT, GPT-4) or transformer-based generative tools integrated into writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The study examines overall use of apps for multiple skills (vocabulary, grammar, speaking, listening, writing, reading). Writing is only one of several skills and not the primary focus, and there is no specific writing-focused pedagogical intervention described.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The article discusses app usage and perceived engagement, not measured changes in writing performance or related variables.""
    }
}"
889,Incorporating a Reflective Thinking Promoting Mechanism into Artificial Intelligence-supported English Writing Environments,2023,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are clearly described as EFL (English as a Foreign Language) university students in two EFL writing classes, so the population consists of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to an “AI-supported English writing (RTP-AIEW) approach” and “conventional AI-supported EFL writing,” but does not specify the AI technology (e.g., ChatGPT, GPT-4, transformer-based LLM) or whether it is an LLM-based generative system versus earlier NLP/automated feedback tools. Without this detail, it is unclear if the intervention uses an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on EFL writing, proposing a reflective thinking promotion mechanism in an AI-supported English writing environment. The primary outcomes include English writing performance and related learning variables, indicating a clear focus on writing competence rather than mere automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that the proposed approach “significantly improved the experimental group students' English writing performance” and also measured self-efficacy, self-regulated learning, and cognitive load. This implies quantifiable writing outcome metrics within a quasi-experimental design.""
    }
}"
890,Leveraging Artificial Intelligence (ai) Technology for English Writing: Introducing Wordtune as a Digital Writing Assistant for Efl Writers,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly targets English as a Foreign Language (EFL) writers and discusses English writing, so the population and language focus align with the review’s scope.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is described as a 'tech review' that provides an overview of Wordtune and its affordances. There is no indication of an experimental or quasi-experimental design, nor of an implemented LLM-based instructional intervention; it is a descriptive review of a tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on English writing support for EFL writers, specifically on how Wordtune can assist during the writing process (formulating, translating ideas, rewriting). This aligns with a writing competence context rather than automated scoring.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any empirical study, intervention, or quantifiable writing outcome metrics. It is positioned as a tech review discussing benefits and limitations, without reporting measured effects on writing performance.""
    }
}"
891,Engaging Efl Students' Critical Thinking Tendency and In-depth Reflection in Technology-based Writing Contexts: a Peer Assessment-incorporated Automatic Evaluation Approach,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are clearly described as university EFL (English as a Foreign Language) writing students, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is an automatic writing evaluation (AWE) system combined with peer assessment. The abstract does not indicate that the AWE tool is a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model); it is framed as conventional AWE, which typically predates LLMs. No LLM or generative transformer-based system is mentioned.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on EFL writing instruction and writing performance in technology-based writing contexts, comparing a PA-AWE approach with a conventional AWE approach. The primary context is writing competence and related variables (motivation, anxiety, critical thinking).""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes: EFL writing performance, learning motivation, critical thinking, and writing anxiety, comparing experimental and control groups in a quasi-experimental design.""
    }
}"
892,Ai and Recognition Technologies to Facilitate English as Foreign Language Writing for Supporting Personalization and Contextualization in Authentic Contexts,2023,unsure,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL (English as a Foreign Language) undergraduate students, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention uses an app (Smart RoamLingo) with AI-generated sample sentences (AI-SS) and AI-based writing feedback (AI-WF). However, the abstract only mentions “recognition technologies” and does not specify that these AI components are based on large language models or transformer-based generative models (e.g., ChatGPT/GPT-like systems). It could be non-LLM NLP or ASR-based recognition.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on EFL writing: helping students write meaningful content, improving writing quality, cohesion, and consistency, with an app designed specifically for EFL writing in authentic contexts. This aligns with writing competence as the primary outcome.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses an experimental design with an experimental group and two control groups, reports that the experimental group significantly outperformed others in a post-test, and mentions assignment scores and number of revisions predicting post-test performance. These are quantifiable writing outcome measures.""
    }
}"
893,Exploring the Potential and Limitations of Chatgpt for Academic Peer-reviewed Writing: Addressing Linguistic Injustice and Ethical Concerns,2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract discusses “non-native English speakers in academic publishing” in general, not a defined population of L2 English learners in ESL/EFL/ELL instructional contexts. It focuses on researchers using English for publication, not language learners in a pedagogical setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a commentary exploring the potential and limitations of ChatGPT. There is no indication of an experimental or quasi-experimental design, nor a structured instructional intervention integrating ChatGPT into writing instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""While it addresses academic writing and linguistic injustice, the focus is conceptual and ethical (potential, limitations, injustice, ethics), not on a concrete pedagogical context or intervention aimed at developing writing competence in an L2 learning environment.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or empirical evaluation are reported. The piece is a commentary without experimental measures or structured intervention outcomes related to writing performance.""
    }
}"
894,Validity Arguments for Automated Essay Scoring of Young Students' Writing Traits,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions K-12 students in grades 3–6 and refers to language backgrounds, but does not specify that the participants are L2 English learners in ESL/EFL/ELL contexts. Their L2 status and English as target language are not clearly established.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates machine learning models for automated essay scoring and human–machine score alignment. It does not describe an instructional or quasi-experimental intervention integrating LLMs (e.g., ChatGPT) into writing instruction or writing processes; rather, it focuses on assessment models.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on the validity of automated essay scoring (evaluation and explanation inferences, human–machine score alignment, detection of off-topic/gibberish). This is an assessment/measurement study, not a pedagogical writing intervention aimed at improving writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing trait scores are analyzed, they are used to evaluate the performance and validity of ML scoring models, not to measure the effectiveness of an LLM-mediated writing intervention. No experimental instructional treatment or its impact on writing outcomes is reported.""
    }
}"
895,Using Ai-based Detectors to Control Ai-assisted Plagiarism in Esl Writing: 'the Terminator Versus the Machines',2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is ESL composition and AI-assisted plagiarism in ESL writing, implying involvement of L2 English learners in ESL settings.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is a descriptive evaluation of RoBERTa-based AI detectors on a dataset of human-written and ChatGPT-generated essays. There is no experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or processes; ChatGPT is only a text source, not an instructional tool.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on controlling AI-assisted plagiarism and evaluating AI-based detectors’ ability to identify machine-generated texts, not on improving writing competence or writing-related learning outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) are reported. Outcomes concern detection accuracy of classifiers, not learner writing performance after an LLM-mediated intervention.""
    }
}"
896,Ai-generated Feedback on Writing: Insights into Efficacy and Enl Student Preference,2023,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'university English as a new language (ENL) learners.' This clearly indicates L2 English learners in an English language learning context, with outcomes and instruction focused on English writing.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""Study 1 uses ChatGPT (GPT-4), a large language model, to generate writing feedback for the experimental group in a six-week repeated-measures quasi-experimental design, compared to human tutor feedback for the control group. This is an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly writing-focused: students receive feedback on their writing, and the study concerns how AI-generated feedback can be used in ENL essay evaluation and in developing students' writing skills. The primary focus is writing competence and learning outcomes, not only automated scoring.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""Study 1 'examined learning outcomes' and reports that 'results of study 1 showed no difference in learning outcomes between the two groups,' indicating quantitative measures of writing-related learning outcomes were collected and compared between AI and human feedback conditions.""
    }
}"
897,An Assistive Environment for Eal Academic Writing Using Formulaic Sequences Classification,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as novice English as an additional language (EAL) writers, which likely fits L2 English learners, but the abstract does not specify ESL/EFL/ELL instructional contexts or learner status (e.g., students vs. researchers).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is an assistive environment based on formulaic sequences extracted and classified with a machine learning technique. There is no indication that a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model) is used; it appears to be corpus-based FS extraction and classification, not an LLM-mediated writing tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on academic writing improvement for EAL writers through an assistive environment that provides domain-specific formulaic sequences, clearly targeting writing competence in research article writing.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports a ‘positive impact’ and ‘significantly higher degree of perceived usefulness’ but does not clearly state whether objective, quantifiable writing outcome measures (e.g., writing scores, text quality metrics) were collected, or only perceptions and usefulness ratings.""
    }
}"
898,"Trends, Research Issues and Applications of Artificial Intelligence in Language Education",2023,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a bibliometric review of 516 papers on AI in language education from 2000–2019. It does not report on a specific participant population of L2 English learners; instead, it aggregates trends across many studies.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a bibliometric review, not an experimental or quasi-experimental study implementing an LLM-based intervention. It surveys various AI applications (e.g., automated writing evaluation, ITS) but does not itself integrate an LLM into instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although writing-related AI applications are among the topics identified, the paper’s primary focus is mapping trends and topics in AI-enhanced language education, not conducting a specific writing competence intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. The study is a bibliometric analysis and does not measure or compare writing performance resulting from any AI or LLM-mediated intervention.""
    }
}"
899,The Impact of Ai Writing Tools on the Content and Organization of Students' Writing: Efl Teachers' Perspective,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students as reported via interviews with four EFL teachers from three Indonesian universities, so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although several AI writing tools are mentioned (Quillbot, WordTune, Jenni, ChatGPT, etc.), the study is a qualitative case study of teachers’ perceptions and tool diversity. There is no experimental or quasi-experimental design integrating a specific LLM-based intervention into instruction; tools also include non-LLM systems.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on the impact of AI writing tools on students’ writing, particularly content and organization, which are core writing competence variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a qualitative case study with semi-structured interviews and reports teachers’ perceptions that AI tools improve writing quality. It does not report quantifiable writing outcome metrics or experimental measures of effectiveness.""
    }
}"
900,Chatbot-based Training on Logical Fallacy in Efl Argumentative Writing,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as 'Fifteen Chinese EFL undergraduate and graduate students,' clearly indicating L2 English learners in an EFL context, with outcomes focused on EFL argumentative writing.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses an 'educational chatbot' for training, but the abstract does not specify that it is a large language model (e.g., ChatGPT, GPT-4) or transformer-based generative system. It could be a rule-based or non-LLM chatbot. Without explicit indication of LLM use, it cannot be confidently classified as an LLM intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL argumentative writing, focusing on logical fallacies as a component of writing quality. The chatbot-based training is clearly a pedagogical intervention aimed at improving writing proficiency, not automated scoring or system evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports pre-post questionnaires on writing self-efficacy and analysis of pre-post argumentative writings using the Illinois Critical Thinking Essay Scoring Rubric, providing quantifiable writing outcome metrics.""
    }
}"
901,Understanding English as a Foreign Language Students' Idea Generation Strategies for Creative Writing with Natural Language Generation Tools,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) students in Hong Kong secondary schools, so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses “natural language generation (NLG) tools” for idea generation, but the abstract does not specify whether these are large language model–based tools (e.g., ChatGPT/GPT-like) or other AI/NLG systems. Thus, it is unclear if LLMs are involved.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on idea generation strategies and students’ interactions and concerns when using NLG tools, not on systematically improving or measuring writing competence. The workshops involve creative writing, but the study centers on qualitative reflections and strategy use rather than a writing-focused pedagogical intervention with assessed outcomes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports a thematic analysis of written reflections and discusses students’ strategies and attitudes. There is no indication of quantitative writing outcome metrics or experimental comparison to assess the effectiveness of NLG-mediated writing intervention.""
    }
}"
902,"Artificial Intelligence in English Language Teaching: the Good, the Bad and the Ugly",2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses English language teaching (ELT) broadly and mentions learners, teachers, and institutions, but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts within an empirical study. It appears to be a conceptual or overview article rather than a participant-based study.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a general discussion of AI in ELT, describing current uses, opportunities, challenges, and ethical issues. It mentions chatbots, machine translation, intelligent tutoring systems, and automated writing evaluation, but there is no indication of an experimental or quasi-experimental design integrating LLMs into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is broad AI use in ELT, including ethical issues, surveillance, privacy, and digital literacies. Writing is only briefly referenced via automated writing evaluation as one of many AI tools, and the abstract explicitly states that detailed consideration of these tools is beyond the scope of the article. Writing competence is not the central focus.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not describe any empirical intervention or report quantifiable writing outcome metrics. It is an overview/discussion piece about AI in ELT, not an experimental study measuring writing-related outcomes.""
    }
}"
903,Recipe: How to Integrate Chatgpt into Efl Writing Education,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as 213 undergraduate and graduate students enrolled in EFL writing courses, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study presents RECIPE, a learning platform that integrates ChatGPT (a large language model) into EFL writing education, with ChatGPT prompted to take an EFL teacher role and interact with students about their self-written summaries.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing courses, and the platform is designed for revising an essay and supporting EFL writing education, so the primary focus is on writing-related learning.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports collection of interaction data, students’ perceptions, usage, user scenarios, and qualitative interviews to explore design opportunities. It does not mention any experimental or quasi-experimental design with quantifiable writing outcome measures (e.g., writing scores, quality ratings, accuracy gains). Outcomes appear to be usage/perception-focused rather than measured writing improvement.""
    }
}"
904,Chatgpt and the Efl Classroom: Supplement or Substitute in Saudi Arabia’s Eastern Region,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 64 EFL learners at a language learning institution in Saudi Arabia’s Eastern Region, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The study compares teacher-mediated versus ChatGPT-assisted writing opportunities, indicating that an LLM (ChatGPT) is integrated into the writing process as part of the instructional context.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly writing-focused: it examines satisfaction with teacher-mediated versus bot-created writing opportunities in an EFL classroom, which is directly related to writing instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are learners’ perceptions of learning satisfaction (learning content, learning progress, ease of use, interactive opportunities) based on open-ended questions and factor analysis. The abstract does not report any quantifiable writing performance metrics or objective writing outcomes; it focuses solely on satisfaction and perceptions.""
    }
}"
905,Using Chatgpt for Second Language Writing: Pitfalls and Potentials,2023,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses second language (L2) writing in general but does not specify that the focus is on L2 English learners or any particular language context (ESL/EFL/ELL).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a 'tech review' that explores potential benefits and challenges of using ChatGPT for L2 writing. It does not describe an experimental or quasi-experimental intervention or actual classroom implementation.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the focus is on L2 writing pedagogy, the paper is a conceptual/tech review, not an empirical study of a writing intervention or instructional context with implemented activities.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics or experimental measures are mentioned. The paper offers recommendations and discusses potentials and pitfalls rather than reporting measured effects on writing performance.""
    }
}"
906,Assessing the Effectiveness of Quillbot-mediated Instruction in Enhancing Efl Students’ Paraphrasing Skills,2023,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL students enrolled in a Technical Writing course at university, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses QuillBot, described as an online paraphrasing tool. QuillBot is not clearly identified as an LLM-based, transformer generative model in the abstract, and is generally categorized as an AI paraphrasing tool rather than an educational integration of LLMs like ChatGPT or GPT-4. Thus it does not meet the specified LLM-based intervention criterion.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on paraphrasing skills within Technical Writing, a core writing-related competence. The study examines how QuillBot-mediated instruction affects students’ paraphrasing performance, aligning with writing competence as the primary focus.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""A test was used to investigate the effect of QuillBot-mediated instruction on students’ paraphrasing skills, indicating quantifiable outcome measures of writing performance, supplemented by semi-structured interviews.""
    }
}"
907,X-education: Education of All Things with Ai and Edge Computing-one Case Study for Efl Learning,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly mentions a preliminary study for EFL writing with 22 learners, indicating participants are EFL (English as a Foreign Language) learners, which fits the L2 English learner population criterion.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses “on-device AI” and an X-Education framework with Q&A forwarding mechanisms, but it is not specified that this AI is a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model). The nature of the AI (LLM vs. other AI) is unclear from the abstract.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The context includes EFL writing and Q&A to support EFL learning, and learners report that X-Education could help them learn EFL writing better. However, the primary focus appears to be on ‘knowledge of all things’ and Q&A interactions rather than clearly on writing competence or writing-related variables as the main outcome.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports that knowledge of all things in the experimental group increased more than the control group and that learners received better EFL answers and perceived help for EFL writing. It does not report any quantifiable writing outcome metrics (e.g., writing scores, text quality measures); outcomes are knowledge gains and perceived support, not measured writing performance.""
    }
}"
908,Impact on Second Language Writing Via an Intelligent Writing Assistant and Metacognitive Training,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) learners using TOEFL iBT-style independent writing tasks, indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is an “internally developed writing aid with next-word prediction, reverse translation support, and metacognitive prompts.” There is no indication that this tool is a large language model (e.g., ChatGPT/GPT-style transformer-based generative model); it appears to be a predictive text/translation aid rather than an LLM-based system.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on second language writing output and writing quality in TOEFL-style tasks, with an intervention designed to support writing and metacognitive thinking. This aligns with a writing competence context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses a randomized control trial and assesses writing outputs with machine and human ratings using several measures of writing quality, providing quantifiable writing outcome metrics.""
    }
}"
909,Determinants Affecting Teachers' Adoption of Ai-based Applications in Efl Context: an Analysis of Analytic Hierarchy Process,2022,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on EFL teachers’ adoption of AI-based applications and collects opinion data from 17 experts. There is no indication that participants are L2 English learners or that learner writing data are involved.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study analyzes determinants of teachers’ adoption of AI-based applications using an Analytic Hierarchy Process model. It does not describe an experimental or quasi-experimental LLM-based writing intervention (e.g., ChatGPT integrated into instruction). The specific AI tools and whether they are LLMs are not detailed, and the focus is on adoption factors, not an instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on technology adoption factors (effectiveness, efficiency, complexity, fees, rewards, etc.) for AI applications in EFL, not on writing competence or writing-related variables. Writing is not mentioned as a target skill or context of the AI use.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported. Outcomes concern weighted importance of adoption factors, not changes in learners’ writing performance or related measurable writing constructs.""
    }
}"
910,The Role of Psycholinguistics for Language Learning in Teaching Based on Formulaic Sequence Use and Oral Fluency,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are explicitly described as Chinese EFL learners (learners of English as a foreign language), which fits the target population of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions that the study used ‘artificial intelligence techniques’ for analysis, but there is no indication that a large language model (e.g., ChatGPT, GPT-4) was integrated into instruction or learners’ writing processes. AI appears to be used as an analytic tool, not as an LLM-based pedagogical intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on oral fluency and the role of formulaic sequences in spoken narratives. The primary outcome variables are speed, breakdown, and repair fluency in speaking, not writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the study reports quantitative outcomes (correlations between formulaic sequence use and oral fluency measures), these outcomes are exclusively related to oral fluency, not writing performance or writing-related metrics. Thus it does not meet the requirement for quantifiable writing outcomes.""
    }
}"
911,Automated Feedback and Teacher Feedback: Writing Achievement in Learning English as a Foreign Language at a Distance,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are open education faculty students in Turkey learning English as a foreign language, which fits an EFL context with English as the target language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention compares teacher feedback with automated feedback from unspecified ‘software’. There is no indication that the tool is a large language model (e.g., ChatGPT, GPT-4) or transformer-based generative system; it appears to be generic automated feedback software, which does not meet the LLM requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly focuses on academic writing achievement in EFL and examines the effect of feedback (teacher vs automated) on writing performance, which is a writing-focused pedagogical context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study uses diagnostic and post-test writing scores and statistically analyzes grades to determine effects on academic writing achievement, providing quantifiable writing outcome metrics.""
    }
}"
912,An Analysis and Research on Chinese College Students' Psychological Barriers in Oral English Output from a Cross-cultural Perspective,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The population is clearly Chinese college students learning English, described as treating English as a second language in China. This fits L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions an 'artificial-intelligence-based oral English teaching assistance system' but provides no indication that it is based on large language models (e.g., ChatGPT, GPT-4, transformer-based generative models). It appears focused on pronunciation correction rather than LLM-mediated generation, so it does not meet the LLM intervention requirement.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on oral English output, pronunciation, and psychological barriers to speaking. It does not focus on writing competence or writing-related variables, but rather on speaking and pronunciation training.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics. Outcomes, where implied, relate to oral English, pronunciation improvement, and psychological barriers in speaking, not writing performance.""
    }
}"
913,"Proceedings - 2022 International Conference on Artificial Intelligence of Things and Crowdsensing, Aiotcs 2022",2022,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract is for a proceedings volume listing many diverse papers. One listed paper mentions “computerized dynamic ESL writing,” suggesting ESL learners may be involved, but no specific participant details or language focus are provided for that individual study.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The proceedings description does not indicate that any paper uses large language models (e.g., ChatGPT, GPT-4) in an experimental or quasi-experimental writing intervention. The only writing-related item is “a multi-facet Rasch measurement of peer evaluation in computerized dynamic ESL writing,” which appears to be an assessment/measurement study, not an LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The volume covers many AI and engineering topics. The ESL writing-related paper is framed around Rasch measurement of peer evaluation, not a pedagogical intervention focused on improving writing competence via LLMs.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract does not specify whether the ESL writing-related paper reports quantifiable writing outcome metrics; it only mentions Rasch measurement of peer evaluation. In any case, there is no indication of LLM-mediated writing intervention outcomes.""
    }
}"
914,Icall Offering Individually Adaptive Input: Effects of Complex Input on L2 Development,2022,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “language learners” and “L2 development” but does not specify that the target language is English or that the context is ESL/EFL/ELL. The institutional affiliation (University of Hawaii at Manoa) is not sufficient to infer that the study focuses on L2 English writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses an ICALL system and mentions “Artificial Intelligence methods,” but there is no indication that the system is based on large language models or transformer-based generative models (e.g., ChatGPT, GPT-4). It appears to be an adaptive input selection system rather than an LLM-mediated writing tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on how different challenge levels of adaptive input impact learners’ written output, and the outcome is writing complexity. This aligns with a primary focus on writing competence and writing-related variables in an instructional context.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports quantifiable outcomes: learners in low- and medium-challenge conditions produced more complex writings after receiving adaptive input, while the high-challenge group did so less. This indicates measured writing outcomes (writing complexity) following the intervention.""
    }
}"
915,"Proceedings of the 19th International Conference on Cognition and Exploratory Learning in the Digital Age, Celda 2022",2022,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""This is a proceedings volume containing 55 papers across diverse topics. The abstract does not specify that any included study focuses on L2 English learners in ESL/EFL/ELL contexts with analyzable data; it only lists titles, many of which are not about L2 English writing. The volume as a whole is not a single empirical L2 study.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The proceedings include a paper titled “student perceptions of AI-powered writing tools,” but no specific LLM-based intervention (e.g., ChatGPT, GPT-4) or experimental/quasi-experimental design integrating LLMs into writing instruction is described. The volume is not itself an intervention study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus of the proceedings is broad (cognition and exploratory learning in the digital age), not specifically on writing competence. The one mentioned paper on AI-powered writing tools appears to focus on perceptions, not a structured pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are reported in the abstract. The referenced paper on AI-powered writing tools is framed around student perceptions, suggesting an absence of experimental measures of writing performance within this proceedings description.""
    }
}"
916,Exploring the Interaction between L2 Learners and Ai Translator in English Writing,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as L2 learners writing an essay in English, and one cluster is labeled 'Korean writing', indicating L1 Korean learners of English (an EFL/ESL-type context). The focus is on English writing skills.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses an 'AI translator' for English writing, but there is no indication that this is a large language model (e.g., ChatGPT, GPT-4). It appears to be a translation tool rather than an LLM-based generative writing assistant, so it does not meet the LLM requirement.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is explicitly English essay writing, examining interaction patterns with an AI translator during English writing. This aligns with a primary focus on writing processes and competence.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions 'expression scores' and clusters based on interaction patterns, but it is not clear whether these are used as quantifiable outcome measures of writing improvement due to the AI-mediated intervention, or simply as descriptors of existing skill levels.""
    }
}"
917,An Integrated Automatic Writing Evaluation and Svvr Approach to Improve Students’ Efl Writing Performance,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are clearly described as EFL (English as a Foreign Language) university students in an EFL writing course, so the population consists of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention integrates Automatic Writing Evaluation (AWE) and spherical video-based virtual reality (SVVR). The abstract does not indicate that the AWE system is based on a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model); it is presented as a conventional AWE tool. SVVR is a VR technology, not an LLM. Thus, there is no explicit LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on improving EFL writing performance and related affective variables (motivation, self-efficacy, anxiety) through an instructional intervention in an EFL writing course, so the context is clearly writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports that the integrated SVVR–AWE method ‘considerably enhanced the students’ EFL writing performance’ compared with a control group, implying quantifiable writing outcome measures in a quasi-experimental design.""
    }
}"
918,"Investigating English as a Foreign Language Learners’ Perceptions, Emotions, and Performance during Online Collaborative Writing",2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners: 58 male students enrolled in writing courses in the Department of English Language and Translation at Qassim University, clearly indicating English as a foreign language context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Blackboard and Blackboard Chatbox for online collaborative writing. There is no mention of large language models (e.g., ChatGPT, GPT-4) or any transformer-based generative AI; the technology is a standard LMS/chat tool, not an LLM-based system.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on collaborative writing in EFL classes and examines learners’ perceptions, emotions, and performance in face-to-face vs. Blackboard Chatbox conditions, which is clearly writing-focused.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports learners’ overall performance and compares performance between two instructional models, indicating quantifiable writing-related outcomes (even though no significant difference was found).""
    }
}"
919,Using Chatbots to Scaffold Efl Students’ Argumentative Writing,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The population is explicitly English as a foreign language (EFL) students, and the focus is on their argumentative writing in English.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to a ‘chatbot system’ (Argumate) developed to scaffold argument construction, but it does not specify that it is based on a large language model (e.g., transformer-based generative model like GPT). Given the 2022 date and lack of LLM terminology, it is unclear whether this is an LLM or a rule-based/task-specific chatbot.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on teaching and learning of argumentative writing and assisting students in producing high-quality argumentative writing, which aligns with writing competence as the central context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes a proposed chatbot-assisted approach and discusses advantages and limitations, but does not indicate any experimental or quasi-experimental design, nor any reported quantitative writing outcome measures. It appears to be more of a system description and conceptual discussion.""
    }
}"
920,Proactive Learner Empowerment: towards a Transformative Academic Integrity Approach for English Language Learners,2022,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are described as undergraduate students in diverse global locations and as English language learners, but it is not explicitly stated that they are L2 English learners in ESL/EFL/ELL contexts. The focus is on academic integrity and language development in higher education, which may include both L1 and L2 English users.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions a curated set of ‘AI online resources’, but this refers to Academic Integrity (AI), not artificial intelligence or large language models. There is no indication that ChatGPT, GPT-4, or any LLM-based tool was integrated into writing instruction or processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on academic integrity socialization, educative engagement, and learner empowerment, with writing used mainly as a vehicle (journal entries) rather than as the central target of a writing competence intervention. The study is not about evaluating an LLM-mediated writing pedagogy.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Reported outcomes include volume of written output and self-perceptions of readiness for academic writing (paraphrasing, summarizing, organization, critical thinking, logic/argument). However, these outcomes are not tied to any LLM-mediated intervention; no generative AI or LLM tool is evaluated for its effect on writing performance.""
    }
}"
921,Automated Scoring of Speaking and Writing: Starting to Hit Its Stride,2022,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes a review of automated scoring of writing and speaking, not an empirical study with a defined participant population of L2 English learners. It focuses on literature from 2011 onward and implications for assessment, teaching, and learning, but no specific learner group is identified.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is a literature review on automated scoring systems, not an experimental or quasi-experimental intervention integrating LLMs (e.g., ChatGPT, GPT-4) into writing instruction or processes. It surveys AS research rather than implementing an LLM-based pedagogical tool.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automated scoring for assessment (design considerations, role of humans and AI, accuracy with different groups) rather than on writing competence development through instructional intervention. It discusses implications for teaching and learning but does not present a writing-focused pedagogical context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a review article, it does not report original, quantifiable writing outcome metrics from an LLM-mediated intervention. It synthesizes existing AS research and future directions, not experimental measures of writing improvement.""
    }
}"
922,Assessing Readability of Learning Materials on Artificial Intelligence in English for Second Language Learners,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly focuses on English-as-a-second-language (ESL) learners studying AI, so the population is L2 English learners in an ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study develops automatic readability assessors using deep-learning-based NLP and classic NLP to estimate text difficulty. There is no indication that an LLM (e.g., ChatGPT, GPT-4) is integrated into writing instruction or learners’ writing processes; the tools are used for readability assessment of input texts, not as pedagogical LLM interventions.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on reading difficulty/readability of AI learning materials, not on writing competence or writing-related variables. No writing instruction or writing tasks are described.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported concern readability levels of texts and the proportion of materials accessible to intermediate ESL learners. There are no quantifiable writing outcome metrics or evaluation of a writing intervention.""
    }
}"
923,A Multi-facet Rasch Measurement of Peer Evaluation in Computerized Dynamic Esl Writing,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly states the context is ESL (English as a Second Language) writing with 41 students, indicating L2 English learners in an ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention involves Computerized Dynamic Assessment and a peer assessment system (Peerceptiv). There is no mention of large language models (e.g., ChatGPT, GPT-4) or transformer-based generative AI; the focus is on peer evaluation and Rasch measurement, not LLM-mediated instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on second language writing and peer assessment within computerized dynamic assessment, which is directly related to writing competence and writing assessment processes.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports on reliability and consistency of peer assessment using Multi-facet Rasch measurement but does not clearly state whether quantifiable writing outcome metrics (e.g., improvement in writing quality) are reported. The focus appears to be on assessment reliability rather than learner writing gains.""
    }
}"
924,Design of Interactive System for Autonomous Learning of Business English Majors Based on Deep Learning Algorithms,2022,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The population is described as 'business English majors', which likely implies L2 English learners, but this is not explicitly stated and could also include native speakers studying Business English. The abstract does not clearly specify ESL/EFL/ELL status or that English is a foreign/second language for the participants.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study mentions 'deep learning algorithms' and an 'interactive system for autonomous learning' but does not indicate the use of large language models (e.g., ChatGPT, GPT-4) or transformer-based generative models integrated into writing instruction. It appears to be a recommendation/learning system based on heterogeneous data, not an LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on 'self-service learning ability' and 'deep learning goals' for business English majors. While 'written tests and work evaluations' are mentioned, the abstract does not specify that the primary focus is writing competence or writing-related variables; it seems more about autonomous learning and reflection rather than writing instruction or writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although there is mention of 'written tests and work evaluations', these are used to verify a hypothesis about reflection and deep learning goals, not clearly as quantifiable writing outcome metrics within an LLM-mediated writing intervention. No explicit writing performance measures tied to an LLM-based writing intervention are reported.""
    }
}"
925,The Integration of Multiple Recognition Technologies and Artificial Intelligence to Facilitate Efl Writing in Authentic Contexts,2022,include,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 71 undergraduate English as a Foreign Language (EFL) learners. The focus is explicitly on English writing, satisfying the requirement for L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""pass"",
        ""evidence"": ""The intervention is a mobile app (Smart UEnglish) integrating multiple recognition technologies and generative-AI. The experimental group uses AI-generated sample sentences (AI-GS) as part of instruction, compared to a control group without AI-GS, indicating an experimental design with a generative AI (LLM-like) writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on facilitating EFL writing, providing lexical resources and AI-generated sample sentences to support essay writing. Outcomes discussed include meaningful English writing and post-test writing performance, clearly centering on writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports that the experimental group outperformed the control group in the posttest and identifies ITR use as a predictive variable in the post-test. This indicates quantifiable writing outcome metrics (pre/post-test comparison) to assess the effectiveness of the AI-mediated writing intervention.""
    }
}"
926,Using Chatbots to Scaffold Efl Students? Argumentative Writing,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The population is explicitly EFL (English as a foreign language) students, and the focus is on English argumentative writing, satisfying the L2 English learner requirement.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to a ‘chatbot’ and ‘Argumate, a novel chatbot system’, but does not specify that it is a large language model (e.g., transformer-based generative model like GPT). It could be a rule-based or non-LLM chatbot, so its status as an LLM intervention is unclear.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is clearly the teaching and learning of argumentative writing, with the chatbot used to scaffold students’ argument construction and assist them in producing high-quality argumentative writing. The primary focus is on writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes a proposed chatbot-assisted approach and discusses advantages and limitations of the system, but does not indicate any experimental or quasi-experimental design, nor any reported quantitative writing outcome measures. It appears to be a design/description paper rather than an intervention study with measurable writing outcomes.""
    }
}"
927,To Err Is Human: Comparing Human and Automated Corrective Feedback,2022,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions a corpus of 115 texts written by college students, but does not specify whether these are L2 English learners (ESL/EFL/ELL) or native speakers. The learner status and L2 context are not clearly indicated.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares corrective feedback from human teachers with Grammarly, described as a ‘well-known writing assistant’ and ‘Automated Written Evaluation (AWE)’ tool. Grammarly is not an LLM-based generative model in the sense required (e.g., ChatGPT, GPT-4, Gemini); it is a non-LLM AWE/grammar-checking tool. No LLM-based intervention is reported.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on comparing types and accuracy of corrective feedback (error detection by teachers vs Grammarly) on a corpus of texts, not on a pedagogical writing intervention or instructional integration of an LLM. It is essentially an evaluation of automated vs human CF, not an LLM-mediated writing instruction study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports statistics on number and types of errors detected by each feedback source, but does not report pre/post or comparative writing outcome measures for learners (e.g., improvement in writing quality or accuracy after intervention). It is descriptive and tool-comparative, not an outcome-based intervention study.""
    }
}"
928,A Review of Artificial Intelligence in Foreign Language Learning,2022,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses foreign/second language learning in general and does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor that the focus is on English specifically.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a brief review of AI implementation in second language learning, not an experimental or quasi-experimental study. No specific LLM-based intervention (e.g., ChatGPT, GPT-4) is reported.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is broadly on foreign language learning and AI, with no indication that writing competence or writing-related variables are the primary focus; multiple aspects of language learning may be covered.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a review article, it does not report original quantitative writing outcome metrics from an intervention; it summarizes existing attempts instead.""
    }
}"
929,The Effects of an Augmented-reality Ubiquitous Writing Application: a Comparative Pilot Project for Enhancing Efl Writing Instruction,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as EFL undergraduates in an English as a foreign language writing context, so the population is L2 English learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is an augmented-reality context-aware ubiquitous writing (ARCAUW) application compared with a mobile-assisted classroom-based writing mode. There is no indication that the tool is a large language model or transformer-based generative system (e.g., ChatGPT, GPT-4). It is an AR ubiquitous learning application, not an LLM-based writing assistant.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on EFL writing instruction and compares two writing modes, examining writing development, task schema, and self-regulation in writing. Thus, the primary focus is on writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports pre- and post-test results showing significant improvement in writing process analysis essays and mixed results in writing performance, indicating quantifiable writing outcome measures were used.""
    }
}"
930,Partnering with Al: Intelligent Writing Assistance and Instructed Language Learning,2022,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses “instructional language learning” and “learners,” but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor that the focus is specifically on English rather than other languages.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The piece is explicitly described as a “column” that examines tools, reviews findings, and discusses their use. It does not present an experimental or quasi-experimental study; rather, it is a narrative/overview of AI-enabled writing tools (AWE, MT, Grammarly, predictive text, generative tools). Thus, it does not meet the requirement for an LLM-based intervention study design.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The focus is broadly on “intelligent writing tools” and their use in writing instruction, which is writing-related, but because this is a column/review rather than an empirical intervention study, the context criterion cannot be properly applied.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics or experimental results. It states that the column will review findings and discuss use in instructional settings, which aligns with a narrative/review format rather than reporting original, measured writing outcomes.""
    }
}"
931,Exploring Artificial Intelligence Using Automated Writing Evaluation for Writing Skills,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Malaysian public university students in ESL writing classrooms, indicating L2 English learners in an ESL/EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is Automated Writing Evaluation (AWE) software. The abstract does not indicate that this AWE system is an LLM-based, transformer generative model (e.g., ChatGPT, GPT-4). AWE tools are typically rule-based or non-LLM NLP systems, which fall outside the review’s scope.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on improving writing skills in ESL writing classrooms and on detecting grammatical errors, which are writing-related variables.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions investigating the effectiveness of AWE and students’ perceptions, but only reports positive perceptions and implications. It does not clearly state that quantifiable writing outcome metrics (e.g., pre/post writing scores) were measured.""
    }
}"
932,Clustering Students' Writing Behaviors Using Keystroke Logging: a Learning Analytic Approach in Efl Writing,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The title specifies an EFL writing context, implying participants are English as a Foreign Language learners engaged in English writing tasks.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses keystroke logging and clustering (machine learning) to identify writing behavior profiles. There is no mention of large language models (e.g., ChatGPT, GPT-4) or any transformer-based generative model being integrated into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on writing processes and writing quality in EFL writing, using process indicators and clustering to understand writing behaviors, which is clearly writing-related.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract notes that the clusters are validated by comparing them with students’ writing quality, indicating quantifiable writing outcome measures are analyzed.""
    }
}"
933,An Integrated Automatic Writing Evaluation and Svvr Approach to Improve Students' Efl Writing Performance,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are clearly described as EFL (English as a Foreign Language) university students in an EFL writing course, so the population consists of L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention integrates Automatic Writing Evaluation (AWE) and spherical video-based virtual reality (SVVR). The abstract does not indicate that the AWE system is based on large language models (e.g., ChatGPT, GPT-4) or transformer-based generative models; it is presented as a conventional AWE tool. Therefore, it does not meet the requirement of an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on improving EFL writing performance and related affective variables (motivation, self-efficacy, anxiety) through an instructional intervention in a writing course, which aligns with a writing competence context rather than automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes: it states that the integrated SVVR-AWE method enhanced students’ EFL writing performance and also measured motivation, self-efficacy, sense of presence, and writing anxiety, implying pre/post or comparative quantitative measures in a quasi-experimental design.""
    }
}"
934,Automatic Scoring of Arabic Essays over Three Linguistic Levels,2022,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are learners of Arabic as a second language; the focus is on Arabic essays, not English. The review targets L2 English learners in ESL/EFL/ELL contexts with data related to English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study presents an automatic scoring system using feature extraction and experiments with linear and non-linear combination methods. There is no indication that large language models (e.g., ChatGPT, GPT-4) are used, nor that the system is transformer-based generative AI.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automated essay scoring reliability and agreement with human raters, not on a pedagogical writing intervention or integration into writing instruction or processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports scoring accuracy and kappa values for the automated system versus human raters, but does not report quantifiable writing outcome metrics from an instructional or intervention context aimed at improving learners’ writing.""
    }
}"
935,Analysis of Syntactic Complexity and Semantic Coherence of Academic English Writing Based on Particle Swarm Optimization,2022,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers generally to ‘language learners’ and ‘second language writing’ but does not specify that participants are L2 English learners in ESL/EFL/ELL contexts, nor does it clearly describe a learner population (it may be corpus-based or system-focused).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses particle swarm optimization (PSO) and compares it with data mining, AI, and decision tree algorithms as evaluation methods. PSO is an optimization algorithm, not a large language model or transformer-based generative model (e.g., ChatGPT, GPT-4). There is no LLM-based instructional or writing-process intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on developing an ‘intelligent evaluation method’ for syntactic complexity and semantic coherence in academic English writing, essentially an automated evaluation system. There is no indication of a pedagogical intervention in writing instruction or integration into learners’ writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although quantitative metrics (e.g., significance values) are reported, they relate to algorithm performance in evaluating writing, not to changes in learners’ writing outcomes following an LLM-mediated intervention. No experimental writing outcome measures for learners are described.""
    }
}"
936,Writing Issues in Esl and Their Potential Solutions: Case Study Imco's Foundation Students,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participants are IMCO foundation students who are described as non-native English speakers (ESL context, A1–B1 levels). The focus is clearly on English writing issues of L2 learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is an experimental investigation of common writing mistakes and their causes. Although it mentions a need for apps, technology, and artificial intelligence, there is no indication that any LLM-based tool (e.g., ChatGPT, GPT-4) was actually integrated into instruction or the writing process.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on writing competence, specifically common writing mistakes (spelling, punctuation, thesis statements, structure, etc.) and factors contributing to these issues in ESL learners.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study records and analyzes common errors but does not describe an LLM-mediated intervention or report quantifiable outcomes of such an intervention. It is diagnostic/descriptive rather than an evaluation of an LLM-based writing intervention.""
    }
}"
937,X-education: Education of All Things with Ai and Edge Computing—one Case Study for Efl Learning,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract explicitly mentions a preliminary study for EFL writing with 22 learners, indicating participants are EFL (L2 English) learners.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The study uses an 'on-device AI' and Q&A forwarding mechanisms within an X-Education framework. However, it is not specified that this AI is a large language model (e.g., transformer-based generative model like ChatGPT/GPT-4). The nature of the AI (LLM vs. other AI) is unclear from the abstract.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the context is EFL writing and Q&A for EFL answers, the primary focus appears to be on knowledge building for 'all things' and the X-Education framework, not specifically on writing competence or writing-related variables. The outcomes discussed are knowledge increase and perceived help for learning EFL writing, not targeted writing instruction or processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports that knowledge of all things in the experimental group increased more than the control group and that learners felt X-Education could help them learn EFL writing better. It does not report quantifiable writing outcome metrics (e.g., writing scores, text quality measures); the quantitative result pertains to 'knowledge,' not writing performance.""
    }
}"
938,Computer-assisted Efl Writing and Evaluations Based on Artificial Intelligence: a Case from a College Reading and Writing Course,2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL students in a college reading and writing course, clearly indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses three online automated essay evaluation (AEE) systems and is framed under ICALL and deep learning theory, but there is no indication these are transformer-based large language models (e.g., ChatGPT, GPT-4). They are generic AEE tools, not explicitly LLM-based generative systems integrated into instruction.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on English writing ability, independent learning ability in writing, and compares computer vs. teacher scoring feedback within a writing project, so the primary context is writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that students’ English writing ability and independent learning ability were ‘significantly improved’ and mentions descriptive statistics, implying quantifiable outcome measures of writing performance.""
    }
}"
939,"Investigating English as a Foreign Language Learners' Perceptions, Emotions, and Performance during Online Collaborative Writing",2022,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are EFL learners: 58 male students enrolled in writing courses in the Department of English Language and Translation at Qassim University. The focus is clearly on English as a foreign language.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Blackboard and Blackboard Chatbox for online collaborative writing. These are not large language models or transformer-based generative tools (e.g., ChatGPT, GPT-4). No LLM integration is mentioned.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on collaborative writing, learners’ emotions, and performance in writing courses, so the primary context is writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports learners’ overall performance and compares performance between face-to-face and Blackboard Chatbox instruction, including a significance test (Sig. = 0.287), indicating quantifiable writing outcomes.""
    }
}"
940,Partnering with Ai: Intelligent Writing Assistance and Instructed Language Learning,2022,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses ‘learners’ and ‘instructional language learning’ but does not specify that participants are L2 English learners (ESL/EFL/ELL) or that the focus is specifically on English writing.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The piece is described as a ‘column’ that examines AI-enabled writing tools and reviews findings from research studies. It does not report an experimental or quasi-experimental study conducted by the authors, nor does it clearly focus on a specific LLM-based tool (e.g., ChatGPT, GPT-4). It is a narrative/overview rather than an intervention study.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""Writing assistance and instructional language learning are central themes, but because this is a column reviewing tools and research rather than reporting a specific empirical intervention, the context as a primary writing competence intervention study is not established.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract does not mention any quantifiable writing outcome metrics or experimental results. It focuses on reviewing tools and prior findings and discussing their use, which aligns with a conceptual/review piece rather than an empirical study with measured writing outcomes.""
    }
}"
941,Investigating Connections between Teacher Identity and Pedagogy in a Content-based Classroom,2021,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are L2 English learners in an L2 English legal education (LLM) program, learning to write a legal genre (office memorandum), which fits ESL/EAP-type contexts focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes a classroom-based ethnography examining how a law instructor’s role identities shape pedagogy. There is no mention of large language models, AI, or any technology-mediated intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is a legal research and writing course where the instructor teaches L2 learners to write an office memorandum, clearly focusing on writing competence and pedagogy.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study is qualitative (ethnography) with observations, interviews, and artifacts. It does not report quantifiable writing outcome metrics or experimental evaluation of an intervention.""
    }
}"
942,Application of Artificial Intelligence Powered Digital Writing Assistant in Higher Education: Randomized Controlled Trial,2021,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are described as \""English second postgraduate students\"" and \""non-native postgraduate students in English academic writing,\"" indicating L2 English learners in an English academic writing context.""
    },
    ""c2"": {
        ""status"": ""unclear"",
        ""evidence"": ""The intervention is an \""Artificial Intelligence (AI) powered writing tool\"" delivered in a randomized controlled trial. However, the abstract does not specify that this AI tool is a large language model (e.g., ChatGPT/GPT-based or transformer generative model). Given the 2021 date and lack of detail, it is likely a generic AI writing assistant rather than an LLM, but this cannot be confirmed from the abstract alone.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary outcomes reported are behavioral, emotional, and cognitive engagement, self-efficacy for writing, and emotions. The focus is on learning behavior and attitudinal technology acceptance, not on writing competence or writing-related performance measures. Writing is the context, but not the main outcome variable.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing performance outcomes (e.g., writing quality scores, accuracy, complexity) are reported. All measured outcomes are affective or engagement-related constructs, so the study does not provide experimental measures of writing improvement attributable to the AI tool.""
    }
}"
943,Ensemble Multi-channel Neural Networks for Scientific Language Editing Evaluation,2021,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract discusses scientific papers authored by non-native English speakers in general and the AESW shared task dataset, but there is no indication of actual learner participants in ESL/EFL/ELL instructional contexts. It is a system evaluation study, not an intervention with L2 learners.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study proposes an Ensemble Multi-Channel Neural Networks (EMC-NN) model for sentence-level language editing evaluation. It is not an LLM-based (e.g., ChatGPT, GPT-4) pedagogical intervention; rather, it is a classification model for detecting whether sentences need editing.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on automated scientific writing evaluation (predicting if a sentence needs editing), not on integrating LLMs into writing instruction or learners’ writing processes. It is a tool performance study, not a teaching/learning context targeting writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are model performance metrics (F1-score) on the AESW task, not quantifiable writing outcomes for learners. No experimental or quasi-experimental intervention with learner writing performance is described.""
    }
}"
944,Automated L2 Writing Performance Assessment: a Literature Review,2021,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses ESL/EFL writing instruction contexts in general but, as a literature review, does not specify a concrete participant population of L2 English learners within an empirical study.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a literature review of Automated Writing Evaluation (AWE) systems over two decades, not an experimental or quasi-experimental study integrating LLMs into instruction. It is a secondary review, not a primary intervention study.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""While the focus is on teaching and assessing writing, the paper synthesizes prior work on AWE systems rather than reporting a specific pedagogical intervention or context with primary data.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a literature review, the study does not report original, quantifiable writing outcome metrics from an intervention; it summarizes existing research and suggests future directions.""
    }
}"
945,A Hierarchical Bert-based Transfer Learning Approach for Multi-dimensional Essay Scoring,2021,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions a self-collected dataset of Chinese EFL learners’ argumentation (CELA), indicating L2 English learners are involved. However, the primary focus is on automated scoring performance, not on learner outcomes, and it is unclear whether participants are treated as learners in an instructional context rather than as data sources for model training.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study develops a hierarchical BERT-based model for automated essay scoring (AES). BERT is used as a pre-trained language model for scoring, not as an instructional or intervention tool integrated into writing instruction or writing processes. There is no experimental or quasi-experimental LLM-mediated pedagogical intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on improving automated essay scoring accuracy (QWK scores) across multiple dimensions. This is an assessment/measurement study of AES functionality, not a pedagogical study targeting writing competence or writing-related learning outcomes in an instructional context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are model performance metrics (average quadratic weighted kappa) comparing the proposed AES model to baselines. There are no quantifiable learner writing outcomes or measures of the effectiveness of an LLM-mediated writing intervention.""
    }
}"
946,A Literature Review of Foreign Studies on the Impact of Call on Second Language Acquisition from 2015,2021,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract discusses second language acquisition and foreign studies on CALL in general, but does not specify that the reviewed participants are L2 English learners or that the focus is on English rather than other target languages.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The article is explicitly described as a literature review of empirical studies on computer-assisted language learning (CALL) since 2015. It is not an experimental or quasi-experimental primary study, and it does not specifically focus on LLM-based tools such as ChatGPT or GPT-4.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""The review concerns computer-assisted language teaching and second language acquisition broadly. It does not indicate that the primary focus is on writing competence or writing-related variables; multiple aspects of language teaching may be covered.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""As a literature review, the paper does not itself report original, quantifiable writing outcome metrics from an LLM-mediated intervention. It synthesizes prior CALL studies rather than conducting a new intervention with measured writing outcomes.""
    }
}"
947,Digital Storytelling with Chatbots: Mapping L2 Participation and Perception Patterns,2021,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract states the context is an L2 class at a university in South Korea, implying EFL learners, but it does not explicitly specify that the target language is English. It only refers to “L2” generically.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses a “digital storytelling chatbot system (storybot).” The abstract does not indicate that this chatbot is a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model). It appears to be a scripted or task-specific chatbot, not an LLM-based system.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on participation rates, reading comprehension, and perceptions of storybot interactions. While L2 output is mentioned, the outcomes emphasized are reading comprehension and perception, not writing competence or writing-focused instruction.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports participation analytics (amount read vs. written) and survey-based perceptions. It does not report quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity) to assess effectiveness of a writing intervention; writing is not systematically measured as an outcome.""
    }
}"
948,The Intervention of Internet Technology on Students' English Learning in the Intelligent Era,2021,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Chinese medicine undergraduates learning English as a second language in China (ESL/EFL context). The study explicitly concerns second language learning (SLL) and English writing ability.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is described as an 'Internet learning system' and 'Internet technology' with AI resources and intelligent learning system, but there is no indication that a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model) is used. It appears to be a general AI/Internet-based learning platform, not an LLM-based writing tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""Writing is one of the assessed skills; the abstract mentions an 'English Writing Scale' and reports that English writing ability is lower than middle level, and that performance in listening, reading, writing, and translation improved in the experimental group. Thus, writing competence is a primary outcome among other skills.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable outcomes: performance differences between experimental and control groups (p<0.01) across listening, reading, writing, and translation, as well as correlations and regression analyses involving learning anxiety, motivation, and learning ability. Writing performance is explicitly measured via an English Writing Scale.""
    }
}"
949,Research on the Design of Lexical-chunks Centered Mode of Writing under Artificial Intelligence in College English Course,2021,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study is situated in a college English course with EFL learners (“college English writing teaching model… for EFL, especially for students with a relatively low language proficiency”), indicating L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract mentions “big data technology” and “artificial intelligence” in general but does not specify the use of large language models (e.g., ChatGPT, GPT-4) or any transformer-based generative model. It appears to be a data-driven monitoring/feedback system rather than an LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on a “college English writing teaching model” and how lexical-chunk-centered instruction affects students’ writing input and output, which aligns with writing competence as a primary focus.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract notes that big data technology “effectively monitors the learning process” and that lexical chunk teaching “promotes students’ writing input and triggers output,” but it does not clearly report quantifiable writing outcome metrics or experimental results; the design (experimental vs. descriptive) is not explicit.""
    }
}"
950,The Listening Strategies of Non English Majors in Colleges and Universities Based on Artificial Intelligence,2021,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are non-English majors in colleges and universities studying English listening, which implies L2 English learners in an EFL/ESL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the title mentions 'based on artificial intelligence', the abstract describes a questionnaire study on listening strategies and metacognitive strategies. There is no indication of an experimental or quasi-experimental design integrating large language models (e.g., ChatGPT, GPT-4) into instruction or learning processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on listening strategies and listening level, not on writing competence or writing-related variables. No writing instruction or writing process is mentioned.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported concern listening strategy use and listening performance (e.g., scores for groups on questionnaire topics). There are no quantifiable writing outcome metrics or writing intervention effects reported.""
    }
}"
951,L2 Learner Cognitive Psychological Factors about Artificial Intelligence Writing Corrective Feedback,2021,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 1,952 undergraduate L2 learners in China working on English writing, which fits an EFL/ESL/ELL L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The AI tool is Pigai, described as an AI evaluating system for English writings. Pigai is not a large language model–based generative system like ChatGPT/GPT-4; it is primarily an automated evaluation/correction tool. The study focuses on AI writing corrective feedback, not on an LLM-mediated writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on learner cognitive psychological factors (perception, noticing, uptake, initiative, retention, emotion) regarding AI WCF, not on designing or evaluating a pedagogical writing intervention using LLMs. It examines attitudes and cognitive responses to Pigai feedback rather than a structured instructional intervention in writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes are Likert-scale measures of cognitive psychological factors and correlations among them. There are no reported quantitative writing performance outcomes (e.g., writing scores, quality measures, accuracy gains) to assess the effectiveness of the AI feedback on writing.""
    }
}"
952,Examining the Impact of Grammarly on the Quality of Mobile L2 Writing,2021,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants were Japanese L2 English university students in an EFL context, and the focus is explicitly on English writing quality (grammatical accuracy, lexical richness, etc.).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses Grammarly, described as an intelligent writing assistant with predictive text and real-time corrective feedback. Grammarly is not an LLM-based generative model like ChatGPT/GPT-4; it is an automated writing evaluation tool and does not meet the review’s requirement for transformer-based LLM integration.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study’s primary focus is on L2 writing competence, specifically mobile writing quality, examining grammatical accuracy, lexical richness, writing fluency, and syntactic complexity under Grammarly vs. non-Grammarly conditions.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing outcomes, including grammatical errors, lexical variation, writing fluency, and syntactic complexity, analyzed via descriptive statistics and t-tests to assess the impact of the intervention.""
    }
}"
953,Automated Writing Evaluation (awe) in Higher Education: Indonesian Efl Students' Perceptions about Grammarly Use across Student Cohorts,2021,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Indonesian undergraduate EFL students majoring in English education, clearly an L2 English learner population in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention tool is Grammarly, an Automated Writing Evaluation (AWE) system. Grammarly is not described as an LLM-based, transformer generative model in this study and is treated as a conventional AWE tool, which falls outside the review’s required focus on LLMs such as ChatGPT, GPT-4, etc.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is EFL writing classes and the use of Grammarly to assist students’ writing processes, focusing on composing and revising writing and feedback on errors—clearly writing-related.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates students’ perceptions of Grammarly’s use via questionnaires and interviews. It does not report quantifiable writing outcome metrics (e.g., changes in writing scores, accuracy, complexity) but focuses on perceived usefulness and drawbacks.""
    }
}"
954,Going beyond Computer-assisted Vocabulary Learning: Research Synthesis and Frameworks,2020,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract refers broadly to 'foreign language learners' and 'learning foreign vocabulary' without specifying that participants are L2 English learners in ESL/EFL/ELL contexts or that the target language is English. The focus is on vocabulary learning in general, not clearly on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study presents three computer-assisted vocabulary learning applications (image recommendation, context representation from lifelogging images, and location-based word recommendation) within the AIVAS platform. There is no indication that these tools are based on large language models (e.g., ChatGPT, GPT-4, transformer-based generative models); they appear to be conventional CALL tools.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is vocabulary learning in informal settings, not writing competence or writing-related variables. The applications support image selection, context representation, and associated word recommendation, with no mention of writing instruction or writing processes.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Reported evaluations involve human and data-driven assessments of the vocabulary learning systems, but there is no indication of quantifiable writing outcome metrics or any writing intervention outcomes. The outcomes relate to vocabulary learning, not writing performance.""
    }
}"
955,Future Prediction of L2 Writing Performance: a Machine Learning Approach,2020,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 102 students of English Language Teaching in Turkey, indicating L2 English learners in an EFL/ESL-related context, with outcomes explicitly about L2 writing performance.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study trains a machine learning model to predict L2 writing performance using demographic and psychometric data. It does not involve large language models (e.g., ChatGPT, GPT-4) nor integrate any LLM into writing instruction or writing processes; it is a predictive analytics study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on predicting end-of-term L2 writing performance (Pass/Fail) for early identification of at-risk students, not on a pedagogical writing intervention or instructional use of AI in writing. There is no described integration of the model into teaching or writing activities.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Although L2 writing performance is measured, the study does not report outcomes of an LLM-mediated writing intervention. It evaluates prediction accuracy of a machine learning classifier, not changes in writing performance due to an AI-supported instructional treatment.""
    }
}"
956,Efl Writing Tasks and the Application of the Concept of Situatedness: Evaluating the Theoretical and Practical Aspects of the Saudi Efl Context,2020,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Saudi EFL students at Qassim and Bisha Universities, clearly an EFL/ELL context focused on English writing skills.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is a Situated Learning approach delivered via a virtual online learning environment and ‘artificial worlds’, but there is no indication that large language models (e.g., ChatGPT, GPT-4) are used. The technology appears to be a virtual learning environment, not an LLM-based tool.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly examines how the Situated Learning approach affects EFL student writing tasks and reports improvement in practical English writing skills, indicating a primary focus on writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""An experimental comparison between control and experimental groups is conducted, and results report that the virtual language experience improved participants’ practical English writing skills, implying quantifiable outcome measures, even if not detailed in the abstract.""
    }
}"
957,Detecting Preposition Errors to Target Interlingual Errors in Second Language Writing,2020,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers generally to 'second language learners' and 'second language writing' but does not specify that the target language is English or that participants are ESL/EFL/ELL learners. It may be about multiple languages with diverse prepositions, so the English L2 focus is not confirmed.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on developing classifiers and fine-tuned BERT models for preposition error detection as part of a prospective digital writing assistant. There is no indication of an experimental or quasi-experimental pedagogical intervention using an LLM with learners; it is a computational detection study.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automatic preposition error detection models, not on writing instruction or learner-facing writing processes. The envisioned assistant is not empirically implemented as an instructional intervention in this study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes or measures of writing competence are reported. The paper evaluates model performance on error detection, not changes in learners’ writing quality following an intervention.""
    }
}"
958,Bert-based Contextual Semantic Analysis for English Preposition Error Correction,2020,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Although the abstract mentions ESL learners’ writing as the motivation, the study itself is about developing a preposition error correction model; it does not describe an intervention with actual L2 English learner participants.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is a BERT-based preposition error correction model. BERT is a bidirectional encoder model, not a generative large language model used pedagogically in writing instruction. There is no experimental or quasi-experimental LLM-mediated teaching intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on automatic preposition error correction technology, not on a pedagogical context or writing instruction process. It is a NLP system paper rather than a study of writing competence development.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable learner writing outcomes or instructional effects are reported; the abstract only discusses model design and scoring, not changes in learners’ writing performance.""
    }
}"
959,Research on the Cultivation of Non-english Majors' English Reading Interest: Poa Teaching Mode in the Internet + Era,2020,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are non-English majors engaged in college English reading instruction in China, i.e., L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is the POA (Production-Oriented Approach) teaching model in the context of 'Internet +', but there is no mention of large language models (e.g., ChatGPT, GPT-4) or any transformer-based generative AI being integrated into instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on English reading interest and reading instruction, not on writing competence or writing-related variables, even though reading is said to support later writing development.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract reports that POA can promote students’ reading interest in four aspects, but does not specify quantitative writing outcome metrics or any writing-focused measures; outcomes appear to be attitudinal (interest in reading).""
    }
}"
960,"Exploring the Development of Writing Complexity, Accuracy, and Fluency in Relation to the Motivational Trajectories: a Dynamically-oriented Case Study; 探討與動機軌跡相關的寫作複雜度,正確性和流暢度的發展:一個動態性的個案研究",2020,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participant is described as a 'successful highly motivated EFL learner,' indicating an English-as-a-foreign-language context and thus an L2 English learner.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""In this study, 'LLM' refers to language learning motivation, not large language models. There is no mention of ChatGPT, GPT-4, or any transformer-based generative AI, nor any AI-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on the development of writing complexity, accuracy, and fluency (CAF) in L2 writing, clearly centering on writing competence and related variables.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study quantitatively assesses CAF measures across ten stages of monthly writing assignments, providing quantifiable writing outcome metrics, even though these are not linked to any LLM-based intervention.""
    }
}"
961,Is the Simplest Chatbot Effective in English Writing Learning Assistance?,2020,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “non-native learners” writing English, which suggests L2 English learners, but it does not explicitly specify ESL/EFL/ELL contexts or participant details. Population appears likely relevant but is not fully clear from the abstract alone.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses “the simplest chatbot (such as ELIZA).” ELIZA-style chatbots are rule-based and predate transformer-based large language models. There is no indication that the system is an LLM (e.g., GPT-style, transformer-based generative model). Thus, it does not meet the requirement that the intervention integrate an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on English writing learning assistance, comparing a standard editor with a chatbot-based writing system and examining effects on word usage and self-revision. The primary focus is on writing behavior and writing-related variables, not on automated scoring or non-pedagogical evaluation.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study empirically compares the number of words learners produce with a standard editor versus a chatbot-based system and analyzes writing results (word usage, self-revision). These are quantifiable writing outcome metrics assessing the effectiveness of the intervention.""
    }
}"
962,A Critical Deconstruction of Computer-based Test Application in Turkish State University,2020,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are Turkish EFL university students and their instructors, clearly situated in an English as a foreign language context, with data focused on English proficiency testing (Versant English Test).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study investigates conceptions of the Versant English Test, an automated AI-based test of spoken and written language. It is not an experimental or quasi-experimental pedagogical intervention integrating an LLM into writing instruction or writing processes; it is an assessment tool evaluation, and the abstract does not indicate use of transformer-based generative LLMs.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automated assessment (VET) and its validity, reliability, and washback, not on developing writing competence or writing-related instructional interventions. Writing is only one component of a broader language test, and there is no described writing pedagogy or intervention context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses a qualitative phenomenological design with semi-structured interviews and focus groups to explore attitudes and perceptions. It does not report quantifiable writing outcome metrics or experimental measures of writing performance following an AI/LLM-mediated writing intervention.""
    }
}"
963,A Machine Learning Approach to Persian Text Readability Assessment Using a Crowdsourced Dataset,2020,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on Persian text readability assessment and dataset creation. There is no mention of L2 English learners, ESL/EFL/ELL contexts, or English as the target language; instead, it concerns Persian language readability in general.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is a machine learning model for Persian text readability assessment, not an LLM-based tool (e.g., ChatGPT, GPT-4) integrated into writing instruction or writing processes. It is an NLP/readability system, not an LLM-mediated pedagogical intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on automated text readability assessment for Persian, not on writing competence, writing instruction, or writing-related pedagogical variables. It is a language technology development study rather than a writing intervention study.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No writing outcome metrics for learners are reported. The study evaluates model accuracy in assessing readability, not changes in learners’ writing performance or outcomes following an intervention.""
    }
}"
964,Digital Storytelling with Chatbots: Mapping L2 Participation and Perception Patterns,2020,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""Participants are L2 learners in a university class in South Korea, which strongly suggests EFL learners, but the abstract never explicitly states that the target language is English. It only refers to “L2” and “L2 class.”""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses a “digital storytelling chatbot system (storybot)” in 2020. There is no indication that this is a large language model or transformer-based generative model (e.g., ChatGPT, GPT-4). It is described as a narrative-focused chatbot, not as an LLM-based tool.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on participation rates, perceptions, and reading comprehension in interactions with a storybot. Writing is minimal and not the central instructional focus; the study is framed as increasing L2 output and reading comprehension, not specifically writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The study reports participation analytics and reading comprehension (cohesion between comprehension questions and responses) plus perception survey data. It does not report quantifiable writing outcome metrics or structured evaluation of writing performance attributable to the chatbot intervention.""
    }
}"
965,"Exploring the Development of Writing Complexity, Accuracy, and Fluency in Relation to the Motivational Trajectories: a Dynamically-oriented Case Study",2020,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The participant is described as a 'successful highly motivated EFL learner,' indicating an English-as-a-foreign-language context and thus an L2 English learner.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The term 'LLM' in the abstract refers to 'language learning motivation,' not large language models. There is no mention of ChatGPT, GPT-4, or any LLM-based tool, nor any AI-mediated instructional intervention. The study is a CDST-oriented case study of motivation and CAF development, not an LLM-integrated intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study focuses on writing-related variables—complexity, accuracy, and fluency (CAF)—in monthly writing assignments, aligning with a primary focus on writing competence and its development.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study quantitatively assesses the development of general measures of CAF over ten stages using descriptive and statistical analyses, providing quantifiable writing outcome metrics, even though these are not linked to any LLM-based intervention.""
    }
}"
966,Foreign Language Learners’ Preference of E-leaming Methods: an Empirical Study,2020,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are foreign language learners taking English courses (listening, reading, writing, translating, speaking) at Xinhua Colleges, indicating an EFL/ESL context focused on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study compares four e-learning delivery methods (video conferencing, self-recorded videos, MOOC courses, electronic materials by native speakers). There is no mention of large language models or tools like ChatGPT, GPT-4, etc., nor any AI-based generative intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is on learners’ preference for different e-learning methods across several skills, not specifically on writing competence or writing-related variables. Writing is only one of several course types considered, and no writing-focused pedagogical intervention is described.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes concern preferences and influencing factors (time, place, network quality, emotional attachment, proficiency, interaction). No quantifiable writing performance or writing outcome metrics are reported.""
    }
}"
967,Research on College English Teaching Strategies and Applications Based on Big Data,2019,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions 'college English teaching in China', which likely involves EFL learners, but it does not explicitly specify that participants are L2 English learners or provide details about the learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study focuses on 'big data' as a basis for teaching strategies. There is no mention of large language models (e.g., ChatGPT, GPT-4) or any transformer-based generative AI being integrated into instruction or writing processes.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract addresses general 'college English teaching strategies and applications' in the big data era. It does not indicate that the primary focus is on writing competence or writing-related variables; it appears to concern overall English teaching.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""No quantifiable writing outcome metrics are mentioned. The paper is described as an empirical analysis of teaching and proposing measures, without reference to measured changes in writing performance or related variables.""
    }
}"
968,Chinese Grammatical Error Correction Based on Convolutional Sequence to Sequence Model,2019,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on Chinese grammatical error correction for learners of Chinese as a second language. The target language is Chinese, not English, so it does not match the required L2 English learner population/context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study introduces a convolutional sequence-to-sequence model (a CNN-based neural MT/GEC system), not a large language model such as ChatGPT, GPT-4, or similar transformer-based generative LLM used pedagogically. It is a computational NLP model development paper, not an LLM-mediated instructional intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is automatic grammatical error correction system development and evaluation, not writing instruction or writing processes in an educational setting. There is no pedagogical intervention targeting learners’ writing competence.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are model performance improvements over a baseline neural MT model, not quantifiable writing outcomes for human learners following an LLM-mediated writing intervention.""
    }
}"
969,Application of Artificial Intelligence to the Small Open Online English Abstract Writing Course,2019,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are 79 graduate students learning English abstract writing in a SMOOC context, indicating L2 English academic writing instruction (ESL/EFL/ELL-type context).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses an AI-assisted system called Quick Research Papers (QRP) for writing, grading, feedback, and analytics. The abstract (2019) does not indicate that QRP is a large language model or transformer-based generative model; it appears to be an automated error-detection/analytics tool rather than an LLM like ChatGPT/GPT-4.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is explicitly on improving English abstract writing skills, tracking writing errors, and using AI analytics to guide teaching and consultation—clearly centered on writing competence.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The study reports quantifiable writing-related outcomes: number of words written, total errors (501), and distribution of error types (e.g., noun, spelling, subject-verb agreement), used to assess writing weaknesses.""
    }
}"
970,"5th Eai International Conference on E-learning, E-education, and Online Training, Eleot 2019",2019,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The proceedings volume includes multiple studies, one of which mentions EFL writing and another mentions College English education, but the abstract is a table-of-contents style overview. It is not clear which specific participant populations are involved or whether they are L2 English learners in ESL/EFL/ELL contexts.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract lists various topics (MOOCs, blended learning, AI in wireless sensor networks, etc.). One paper mentions a web-based automatic writing evaluation platform, but there is no indication that any study uses large language models (e.g., ChatGPT, GPT-4) in writing instruction. The AI references appear unrelated to LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""One listed paper is titled “Self-correction’s Effects on EFL Writing on Web-Based Automatic Writing Evaluation Platform,” which suggests a focus on writing competence, but the nature of the intervention and tools is not specified. It may involve automated evaluation rather than an LLM-mediated pedagogical writing intervention.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The EFL writing paper title implies an empirical study of self-correction effects, which likely includes quantitative writing outcomes, but the abstract for the proceedings volume does not provide explicit information on outcome measures or designs for any individual paper.""
    }
}"
971,Detection of Non-standard English Expressions by Language Sense,2019,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract refers to improving the ability of Chinese students’ English writing and mentions second language acquisition, indicating L2 English learners (likely EFL in China).""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study proposes an algorithm (N-LanSen) for detecting non-standard English expressions. There is no indication that this is a large language model (LLM) or transformer-based generative model; it appears to be a detection/classification algorithm, not an LLM-based writing intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on developing and evaluating an algorithm to detect non-standard expressions in essays, not on a pedagogical intervention or integration into writing instruction. It is essentially a detection tool evaluation, not a teaching/learning context.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The only reported outcome is algorithmic performance (high accuracy in detecting non-standard expressions). There are no quantifiable learner writing outcomes or measures of improvement in students’ writing as a result of an intervention.""
    }
}"
972,Native Language Identification in Very Short Utterances Using Bidirectional Long Short-term Memory Network,2019,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""Participants are Urdu speakers whose native language is being identified from very short English L2 utterances, but the study is framed as a speech/native language identification task, not as an ESL/EFL/ELL learning population in an instructional context. There is no indication of an educational or L2 learning setting.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The study uses bidirectional long short-term memory (BLSTM) neural networks for native language identification. BLSTMs are not large language models (LLMs) such as ChatGPT, GPT-4, or similar transformer-based generative models, and there is no writing instruction or LLM-mediated intervention.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The focus is on automatic native language identification from speech using acoustic features (MFCC, GFCC) and BLSTM classifiers. There is no focus on writing competence, writing instruction, or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""Outcomes reported are classification accuracy for native language identification across different feature sets and utterance durations. No writing outcomes or measures of writing performance are reported.""
    }
}"
973,A Framework of Computer-based Learning System Based on Self-regulated Model in English Writing,2019,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""Participants are explicitly described as Thai EFL learners, and the system is for English writing, so the population is L2 English learners in an EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper describes a computer-based learning system using components of linguistics and machine translation, but there is no indication that it uses large language models (e.g., ChatGPT, GPT-4) or any transformer-based generative model. It appears to be a design of a general computer-assisted system, not an LLM-based intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The focus is on a computer-based learning system for English writing, incorporating self-regulated learning phases to guide target sentence writing, which aligns with writing competence and writing-related variables.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract presents only the design phase of the system and its aim to collect learner behavior for future analysis. It does not report any experimental or quasi-experimental outcomes, nor any quantifiable writing performance metrics.""
    }
}"
974,An Associativity-agnostic In-cache Computing Architecture Optimized for Multiplication,2019,exclude,"{
    ""c1"": {
        ""status"": ""fail"",
        ""evidence"": ""The paper is a hardware/architecture study on in-cache computing for multiplication operations. There is no mention of human participants, language learners, ESL/EFL/ELL contexts, or any educational population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention concerns an in-cache computing architecture (BLADE) and its optimization for multiplication in CMOS technology. It does not involve large language models, ChatGPT-like systems, or any LLM-based pedagogical tool.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The context is computer architecture and energy-efficient computation for machine learning workloads, not writing instruction, writing processes, or language education. No writing competence or writing-related variables are addressed.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The outcomes reported are hardware metrics (performance, area, energy, cycle count) for multiplication operations. There are no quantifiable writing outcomes or measures of L2 writing performance.""
    }
}"
975,Automated Writing Evaluation System: Tapping Its Potential for Learner Engagement,2018,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions second language acquisition in general but does not specify that the participants are L2 English learners in ESL/EFL/ELL contexts, nor that the focus is specifically on English.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The title and abstract refer broadly to an automated writing evaluation system and AI technologies but do not indicate the use of large language models (e.g., ChatGPT, GPT-4). It appears to be a conceptual or descriptive piece about AWE/AI rather than an LLM-based experimental or quasi-experimental intervention.""
    },
    ""c3"": {
        ""status"": ""unclear"",
        ""evidence"": ""While the title suggests a focus on writing evaluation and learner engagement, the abstract is too general to confirm that the primary focus is on writing competence or writing-related variables within a pedagogical intervention.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""There is no indication of an experimental or quasi-experimental study design or of any reported quantitative writing outcome measures; the abstract reads as a general discussion of AI and AWE potential.""
    }
}"
976,Application of Sentiment Analysis to Language Learning,2018,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract refers to “second or foreign language learning” and “language learners,” but does not specify that the target language is English or that participants are ESL/EFL/ELL learners. The target language could be any L2.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention is RESOLVE, a context-aware emotion synonym suggestion system using sentiment analysis and machine-learning techniques. There is no indication that it is based on a large language model or transformer-based generative model (e.g., ChatGPT, GPT-4). It appears to be a traditional NLP/sentiment analysis tool rather than an LLM.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The study involves a writing task and aims to improve learners’ use of emotion vocabulary in their writings, indicating a focus on writing-related competence (emotion word use in written production).""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""A pedagogical evaluation was conducted using a writing task, and the abstract reports that participants “achieved substantial progress on emotion word use,” with less proficient participants showing greater improvements. This implies quantifiable outcome measures of writing-related performance.""
    }
}"
977,Supporting Esl Writing by Prompting Crowdsourced Structural Feedback,2017,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The study explicitly targets support for English as a Second Language (ESL) writing and focuses on non-native speakers, indicating an L2 English learner population.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention (StructFeed) relies on crowdsourced annotations from native speakers and compares this to three naïve machine learning methods. There is no indication that a large language model (e.g., transformer-based generative model like ChatGPT/GPT-4) is used; the ML methods appear to be traditional, not LLM-based.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The context is ESL writing support, focusing on paragraph structure (topic sentence, irrelevant sentences) and writing hints, which are directly related to writing competence and revision outcomes.""
    },
    ""c4"": {
        ""status"": ""pass"",
        ""evidence"": ""The abstract reports that people who received feedback via StructFeed showed the highest improvement after revision, implying quantifiable writing outcome measures were used to assess effectiveness.""
    }
}"
978,A Tutorial Proposal On: Advanced Technical Communications for Esl Engineers and Ooi,2017,exclude,"{
    ""c1"": {
        ""status"": ""pass"",
        ""evidence"": ""The course is explicitly designed for English-as-a-Second-Language (ESL) engineers and others of interest, indicating an L2 English learner population in an ESL/EFL context.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract describes an IEEE course on advanced technical writing and presentation skills, with demonstrations of grammatical subtlety, cultural differences, cognitive style, and logical thinking. There is no mention of large language models (e.g., ChatGPT, GPT-4) or any AI-based intervention.""
    },
    ""c3"": {
        ""status"": ""pass"",
        ""evidence"": ""The primary focus is on technical writing and presentation skills for ESL engineers, which is directly related to writing competence and communication skills.""
    },
    ""c4"": {
        ""status"": ""fail"",
        ""evidence"": ""The abstract reports participant satisfaction (97%) but does not mention any quantifiable writing outcome metrics or experimental evaluation of changes in writing performance.""
    }
}"
979,Integrating an Adjusted Conversational Agent into a Mobile-assisted Language Learning Application,2017,exclude,"{
    ""c1"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract mentions a mobile-assisted English language learning application and students learning vocabulary in English, which suggests L2 learners, but it does not explicitly state that participants are ESL/EFL/ELL learners or that English is a second/foreign language for them.""
    },
    ""c2"": {
        ""status"": ""fail"",
        ""evidence"": ""The intervention uses the chatterbot ALICE, a rule-based conversational agent, not a transformer-based large language model such as ChatGPT, GPT-4, or similar. Therefore, it does not meet the requirement of integrating an LLM into instruction.""
    },
    ""c3"": {
        ""status"": ""fail"",
        ""evidence"": ""The primary focus is vocabulary learning, motivation, engagement, and cognitive skills within a general English learning app. Writing is only mentioned as one modality for chatting with the agent, not as the central focus on writing competence or writing-related variables.""
    },
    ""c4"": {
        ""status"": ""unclear"",
        ""evidence"": ""The abstract notes that students can be evaluated by the chatterbot and that the system supports vocabulary practice, but it does not specify any quantifiable writing outcome metrics or structured assessment of writing performance.""
    }
}"
