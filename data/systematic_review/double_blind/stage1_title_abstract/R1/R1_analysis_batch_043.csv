Title,Year,Decision,Notes
Exploring the Potential of Chatgpt in Assessing L2 Writing Accuracy for Research Purposes,2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions '100 L2 essays across five proficiency levels' but does not specify that these are L2 English learners or that the target language is English. The L2 could be any language.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT-4 is used to measure linguistic accuracy and detect errors in L2 essays, not as part of an instructional or quasi-experimental writing intervention. The focus is on tool validation for research purposes, not on integrating LLMs into teaching or learning processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on assessing ChatGPT\u2019s performance in error detection (measurement/assessment function), not on improving learners\u2019 writing competence or implementing a pedagogical writing intervention. This aligns with automated assessment validation rather than instructional use.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics related to learner improvement or intervention effects are reported. Outcomes concern precision, recall, and correlation between ChatGPT and human error coding, not changes in learners\u2019 writing performance.""}}"
Using Ai-based Detectors to Control Ai-assisted Plagiarism in Esl Writing: “the Terminator Versus the Machines”,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The context is ESL composition, implying involvement of L2 English learners in ESL settings. The focus is on essays written in English within ESL contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study investigates RoBERTa-based AI detectors for identifying ChatGPT-generated texts. ChatGPT is used as a source of machine-generated essays, not as an instructional or intervention tool in writing pedagogy. There is no experimental or quasi-experimental design integrating LLMs into writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on controlling AI-assisted plagiarism and evaluating AI-based detectors\u2019 accuracy, not on improving writing competence or writing-related pedagogical outcomes. It is essentially a detection/forensics study rather than a writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy) are reported. Outcomes relate to detection accuracy of classifiers, not to learners\u2019 writing performance following an LLM-mediated intervention.""}}"
"A Triple Challenge: Students' Identification, Interpretation, and Use of Individualized Automated Feedback in Learning to Write English as a Foreign Language.",2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are eighth-grade students learning English as a foreign language, clearly indicating an EFL context and L2 English learners: \u201ceighth-grade students'\u2026writing skills in English as a foreign language.\u201d""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses an \u201cAI-based automated essay assessment tool (EAT)\u201d that provides automatic feedback and logs revisions. There is no indication that this tool is a large language model (e.g., ChatGPT/GPT-style transformer-based generative model); it is framed as an automated essay assessment system, which typically predates LLMs and focuses on scoring/feedback rather than generative language modeling.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on writing competence and related processes: \u201cassessment literacy and writing skills in English as a foreign language,\u201d and the study examines how automated feedback and teacher/peer discussion foster students\u2019 writing skills.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcomes: \u201cthe improvements made on the essay based on the feedback logs\u2026 and the different versions of the essay were examined using frequency analyses,\u201d indicating measurable changes in writing following the intervention.""}}"
From Process to Product: Writing Engagement and Performance of Efl Learners under Computer-generated Feedback Instruction,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 42 English as a foreign language (EFL) learners, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses Pigai, described as a Chinese automated writing evaluation (AWE) system. Pigai is a traditional AWE tool, not specified as an LLM or transformer-based generative model (e.g., ChatGPT, GPT-4). Thus it does not meet the requirement that the intervention integrate an LLM.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on revision processes and writing products, analyzing feedback uptake and text quality (complexity, accuracy, fluency), which are core writing-related variables in L2 writing instruction.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcomes, including text quality measured via complexity, accuracy, and fluency (CAF), and examines the impact of automated feedback on these measures.""}}"
"Artificial Intelligence in Language Instruction: Impact on English Learning Achievement, L2 Motivation, and Self-regulated Learning",2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are English as a Foreign Language (EFL) university students, and outcomes are explicitly about English learning (grammar, vocabulary, reading, writing).""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The abstract only states that the experimental group received \u201cAI-mediated instruction\u201d via an \u201cAI platform\u201d or \u201cAI-powered platforms.\u201d It does not specify that the AI is a large language model (e.g., ChatGPT, GPT-4) or a transformer-based generative model. It could be any AI-driven educational technology, so it cannot be confidently classified as an LLM-based intervention.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""Writing is one of several domains assessed (grammar, vocabulary, reading comprehension, and writing skills), but the primary focus appears to be overall English learning achievement, L2 motivation, and self-regulated learning rather than writing competence specifically. The extent to which writing is a central focus is not clear from the abstract.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Pre- and post-tests were used to evaluate English learning achievement, including writing skills, providing quantifiable outcome measures. Thus, there are experimental measures of writing-related performance, even if writing is only one component.""}}"
Local Similarity and Global Variability Characterize the Semantic Space of Human Languages,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Although the study uses TOEFL essays written by 38,500 speakers from various native languages, the focus is not on these writers as L2 learners in an instructional ESL/EFL/ELL context, but on cross-linguistic semantic variability. The participants are not situated in a pedagogical intervention or learning context targeting English writing development.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Large language models are used as analytic tools to characterize semantic space across languages, not as an instructional intervention or integrated into learners\u2019 writing processes. There is no experimental or quasi-experimental design where LLMs support or mediate writing instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on semantic variability and cross-linguistic meaning organization, not on writing competence or writing-related pedagogical variables. TOEFL essays are used as data to infer semantic structure, not to improve or assess writing through an educational intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study does not report quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity) resulting from an LLM-mediated intervention. Outcomes concern semantic similarity/variability across languages, not changes in learners\u2019 writing performance.""}}"
Bibliometrically and Systematically Analyzing Automated Writing Evaluation for English Learning,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The article is a bibliometric and systematic review of automated writing evaluation (AWE) for English learning, not an empirical study with its own participant sample. It synthesizes 56 peer-reviewed articles rather than reporting original data from a defined group of L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The work is a bibliometric and systematic review of AWE tools in general. It does not report an experimental or quasi-experimental intervention using a specific LLM (e.g., ChatGPT, GPT-4) in writing instruction; instead, it aggregates prior studies on AWE, many of which may not involve LLMs.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the topic is automated writing evaluation in English learning, the paper\u2019s primary focus is mapping the literature (topics, authors, countries) and summarizing general findings, not implementing or evaluating a concrete pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study does not present original quantitative writing outcome measures from an intervention. It synthesizes existing studies and discusses overall effectiveness and variability, which falls under review/overview rather than reporting new experimental outcomes.""}}"
Enhancing Academic Writing Skills and Motivation: Assessing the Efficacy of Chatgpt in Ai-assisted Language Learning for Efl Students,2023,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Chinese English as a Foreign Language (EFL) students. The abstract explicitly states the context is EFL and focuses on English writing skills and motivation, satisfying the L2 English learner requirement.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention is \u2018AI-assisted instruction via ChatGPT\u2019 for the experimental group, compared to traditional instruction. ChatGPT is a large language model, and the design is experimental with random assignment and pre/post testing.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on academic writing skills and writing motivation. The intervention integrates ChatGPT into language learning specifically to impact writing, not for automated scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses a pre-test and post-test design to assess writing skills, with writing samples evaluated using established scoring rubrics. Quantitative analysis reports significant improvements in writing skills and motivation, providing measurable writing outcomes.""}}"
"A Triple Challenge: Students’ Identification, Interpretation, and Use of Individualized Automated Feedback in Learning to Write English as a Foreign Language",2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are eighth-grade students learning English as a foreign language, clearly an EFL context with English as the target language: \u201ceighth-grade students\u2019 \u2026 writing skills in English as a foreign language.\u201d""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses an \u201cAI-based automated essay assessment tool (EAT)\u201d that provides automatic feedback. The abstract frames it as an automated essay assessment system, not as an LLM (e.g., ChatGPT/GPT-4) or transformer-based generative model integrated into instruction. No indication is given that the tool is a large language model; it appears to be a conventional automated essay scoring/feedback system.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on \u201cassessment literacy and writing skills in English as a foreign language\u201d and how automated feedback plus teacher/peer discussion fosters students\u2019 writing skills. This is a pedagogical writing intervention, not merely evaluation of an automated scoring system\u2019s reliability.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study examines \u201cimprovements made on the essay based on the feedback logs \u2026 and the different versions of the essay \u2026 using frequency analyses,\u201d indicating quantifiable writing outcome measures related to revisions and improvements.""}}"
Second Language Learners’ Post-editing Strategies for Machine Translation Errors,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The abstract refers to generic 'second language (L2) learners' and 'L2 writing' but does not specify that the target language is English or that the context is ESL/EFL/ELL. The institutional affiliation (University of Hawaii at Manoa) does not guarantee that the L2 is English in this study.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses Google Translate, described as a neural machine translator. While it is an AI tool, the abstract does not indicate that it is a large language model (LLM) such as ChatGPT/GPT-4 or similar transformer-based generative model used interactively for writing instruction. The focus is on MT output and post-editing, not on an LLM-based writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study clearly focuses on L2 writing: learners use machine translation to address lexical and grammatical problems during L2 writing, and the analysis concerns MT errors, post-editing strategies, and writing competence in the 'AI era.'""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports a quantitative outcome: 'Successfulness of PE was gauged by comparing sentence adequacy scores of the MT output and PEd texts.' This provides measurable writing-related outcomes linked to the intervention.""}}"
Engineering Chatgpt Prompts for Efl Writing Classes,2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers generally to 'EFL education' and 'student writing' but does not specify that an empirical study with EFL learners was conducted, nor provide participant details. It may be a conceptual or practical article rather than a participant-based study.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is discussed as a feedback tool and the article 'will demonstrate effective prompts for writing classes', there is no indication of an experimental or quasi-experimental design or structured intervention being implemented and evaluated. It appears to be a descriptive or pedagogical piece on prompt design.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The focus is on EFL writing classes and feedback on student writing, which is writing-related. However, without evidence of an actual intervention study, it is unclear whether the context meets the review\u2019s requirement for a pedagogical intervention rather than a conceptual discussion.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not mention any quantitative writing outcome measures or assessment of effectiveness. It only states that the article will demonstrate effective prompts, suggesting no empirical evaluation of writing outcomes.""}}"
Exploring the Effects of Grammarly on Efl Students’ Foreign Language Anxiety and Learner Autonomy,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL students in academic writing courses at a Japanese university, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses Grammarly, described as an automated writing evaluation (AWE) tool. Grammarly is not an LLM-based, transformer generative model like ChatGPT or GPT-4; it is an AI-assisted grammar checker, which falls outside the specified LLM-based tools.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is L2 English academic writing, with Grammarly used while editing English writing. The focus is on writing-related variables (foreign language anxiety and learner autonomy in writing).""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports pre- and post-survey measures of foreign language anxiety and learner autonomy, and qualitative perceptions. It does not report quantifiable writing performance outcomes; the main outcomes are affective and autonomy-related, not direct writing competence metrics.""}}"
"2023 Ieee 15th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management, Hnicem 2023",2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The record is a conference proceedings volume containing 263 papers. One listed paper is \u201cutilization of artificial intelligence in academic writing class: L2 learners perspective,\u201d which may involve L2 learners, but no specific information on participants or language (English vs. other) is provided in the abstract of the proceedings.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The proceedings-level abstract does not specify that any paper uses large language models (e.g., ChatGPT, GPT-4). The mentioned study on AI in academic writing is generic (\u201cartificial intelligence\u201d) with no indication that it is LLM-based or that it uses transformer-based generative models in an experimental or quasi-experimental design.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""One paper title suggests a focus on academic writing (\u201cutilization of artificial intelligence in academic writing class: L2 learners perspective\u201d), but the proceedings abstract provides no detail on whether the primary focus is writing competence or pedagogy versus general perceptions or technology use.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""No quantifiable writing outcome metrics or experimental results are reported in the proceedings abstract. It only lists paper titles and broad topics, so it is impossible to confirm that any included study reports measurable writing outcomes from an AI/LLM-mediated intervention.""}}"
Fusion Weighted Features and Bilstm-attention Model for Argument Mining of Efl Writing,2023,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The title mentions EFL writing, suggesting texts may be from EFL learners, but the abstract does not specify participants, learner status, or that the corpus consists of L2 English learners in ESL/EFL/ELL contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study proposes an argument mining model using BERT and BiLSTM-attention for automatic annotation of argumentative essays. This is an NLP system evaluation, not an experimental or quasi-experimental pedagogical intervention integrating an LLM into writing instruction or writing processes for learners.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on argument mining performance and potential support for automated scoring, not on improving learners\u2019 writing competence or writing-related variables through an instructional intervention. It evaluates a computational model, not a teaching/learning context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are model precision (69%) and comparison with existing models. There are no quantifiable learner writing outcomes or measures of writing improvement resulting from an LLM-mediated intervention.""}}"
"Navigating the Impact of Chatgpt/gpt4 on Legal Academic Examinations: Challenges, Opportunities and Recommendations",2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The abstract discusses students and researchers in universities and higher education generally, including non-native English speakers, but it does not specify that the population is L2 English learners in ESL/EFL/ELL contexts, nor does it present empirical data on such a population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The paper is a conceptual/discussion piece about the impact of ChatGPT/GPT-4 on academic writing, plagiarism, and ethics. It does not describe an experimental or quasi-experimental intervention integrating LLMs into writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""While the focus is on academic writing and AI tools, the article addresses challenges, opportunities, and policy/ethical recommendations rather than a pedagogical intervention aimed at improving writing competence with measurable outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics or experimental measures are reported. The article proposes strategies and discusses implications but does not assess the effectiveness of an LLM-mediated writing intervention.""}}"
Teachers’ Reflections on Academic Dishonesty in Efl Students’ Writings in the Era of Artificial Intelligence,2023,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The participants are 67 teachers, not L2 English learners. Although the context involves EFL students\u2019 writings, the data and analysis focus on teachers\u2019 perceptions rather than on L2 learners as the study population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study explores teachers\u2019 perceptions of AI and academic dishonesty; it does not describe an experimental or quasi-experimental intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is academic dishonesty and ethical implications of AI in student writing, not on improving writing competence or writing-related pedagogical interventions using LLMs.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported. The study is based on questionnaires and interviews about perceptions, without experimental measures of writing performance or structured LLM-mediated writing interventions.""}}"
Chatgpt's Capabilities in Spotting and Analyzing Writing Errors Experienced by Efl Learners,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly refers to 'English as a foreign language (EFL) learners' and 'EFL writing education', indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study investigates ChatGPT\u2019s effectiveness in detecting EFL learners\u2019 writing errors compared to human instructors. It evaluates ChatGPT as an error-detection tool, not as part of an experimental or quasi-experimental pedagogical intervention in writing instruction or writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on ChatGPT\u2019s capability to spot and analyze writing errors (i.e., tool performance and reliability), similar to an automated error-detection/assessment study. There is no described instructional intervention or integration into learners\u2019 writing development.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported concern ChatGPT\u2019s error-detection performance (e.g., types of errors identified, F-score, p-value). There are no quantifiable learner writing outcome measures (e.g., improvement in writing quality, accuracy, complexity) following an LLM-mediated intervention.""}}"
Improving Logical Flow in English-as-a-foreign-language Learner Essays by Reordering Sentences,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The corpus ICNALE-AS2R consists of essays written by English-as-a-foreign-language learners from various Asian countries, clearly indicating an EFL L2 English learner population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study proposes and evaluates a computational sentence reordering system trained on learner essays. It is an NLP/AI system development and evaluation paper; there is no indication that an LLM (e.g., ChatGPT, GPT-4) is used, nor that the system is integrated into an instructional intervention with learners.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on developing an automatic sentence reordering system and evaluating its performance on metrics like longest common subsequence ratio and Kendall\u2019s Tau. There is no pedagogical context, classroom implementation, or writing instruction intervention; it is a text-processing task, not a teaching/learning intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are system performance metrics on reordering accuracy, not learner writing outcomes. No experimental or quasi-experimental measures of changes in learners\u2019 writing competence or related variables are presented.""}}"
Second Language Learners' Post-editing Strategies for Machine Translation Errors,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study involves 57 second language (L2) learners using Google Translate in L2 writing. While the target language is not explicitly stated as English, the general L2 context and focus on L2 writing suggest it could include English; however, this is not central to the exclusion decision.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention centers on Google Translate, a neural machine translation (MT) system, not a large language model (LLM) such as ChatGPT, GPT-4, or similar transformer-based generative models used interactively for writing instruction. The study analyzes post-editing of MT output rather than an LLM-mediated writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly L2 writing: learners use MT output during L2 writing and apply post-editing strategies to address lexical and grammatical problems. The focus is on writing competence and strategies in an AI-supported writing process.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable outcomes: sentence adequacy scores comparing MT output and post-edited texts, and examines how proficiency affects successful post-editing. These are measurable writing-related outcomes.""}}"
The Impact of Artificial Intelligence in Foreign Language Learning Using Learning Management Systems: a Systematic Literature Review,2023,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract focuses on English as a foreign language and discusses learners and teachers in EFL contexts using AI via learning management systems. Thus, the population is aligned with L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The article is explicitly described as a systematic literature review, not an experimental or quasi-experimental primary study. It synthesizes prior work on AI tools in LMSs rather than implementing a specific LLM-based intervention itself.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although writing is mentioned among the four skills, the paper\u2019s primary focus is broad foreign language learning (reading, writing, speaking, listening) and the general effects of AI in LMSs, not a targeted writing competence intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a systematic literature review, it does not report original, quantifiable writing outcome metrics from an intervention; instead, it summarizes perceived benefits and general improvements across skills.""}}"
