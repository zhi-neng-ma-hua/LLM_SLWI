Title,Year,Decision,Notes
"Ai-driven Language Learning in Higher Education: an Empirical Study on Self-reflection, Creativity, Anxiety, and Emotional Resilience in Efl Learners",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 205 English as a Foreign Language (EFL) undergraduate learners from various Chinese universities, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers broadly to \u201cAI-powered feedback\u201d (grammar/vocabulary corrections, motivational feedback) but does not specify that the tools are large language model\u2013based (e.g., ChatGPT, GPT-4). They could be traditional NLP/grammar checkers. No explicit mention of LLMs or transformer-based generative models is made.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on self-reflection, creativity, anxiety, and emotional resilience. Writing is mentioned only tangentially (\u201cenjoyment in writing and speaking\u201d), and there is no indication that the study centers on writing competence or writing-related instructional interventions; it is a general AI feedback and affective/psychological outcomes study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported concern self-reflection, creativity, confidence, anxiety reduction, and emotional resilience. There is no mention of quantifiable writing performance metrics (e.g., writing scores, text quality measures) used to assess the effectiveness of the AI intervention on writing competence.""}}"
From Algorithms to Annotations: Rethinking Feedback Practices in Academic Writing through Ai-human Comparison,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study focuses on Malaysian L2 students in an English for Academic Purposes (EAP) setting, clearly indicating L2 English learners in an EFL/ESL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used to generate feedback, the design is comparative/descriptive: it examines how ChatGPT and instructors use epistemic strategies and delivery methods in comments on 200 introductions. There is no experimental or quasi-experimental instructional intervention integrating LLMs into writing instruction or processes; it is an AI\u2013human feedback comparison study.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on characterizing feedback practices (epistemic strategies and delivery methods) of ChatGPT vs. instructors, not on improving or measuring writing competence. It informs pedagogy conceptually but does not constitute a pedagogical writing intervention with outcome evaluation.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports no quantifiable writing outcome metrics (e.g., changes in writing quality, scores, accuracy). It analyzes properties of feedback, not the effects of LLM-mediated feedback on learners\u2019 writing performance.""}}"
The Role of Ai Assisted Writing Feedback in Developing Secondary Students Writing Skills,2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as secondary-level EFL students in Turkey, which fits L2 English learners in an EFL context. The focus is clearly on English writing skills.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to an \u201cAI writing assistant\u201d and \u201cAI-assisted writing feedback\u201d but does not specify whether the tool is an LLM (e.g., ChatGPT, GPT-4) or a non-LLM AI tool (e.g., rule-based or traditional NLP). Without explicit indication that a transformer-based generative model is used, it is not possible to confirm it meets the LLM criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on developing students\u2019 writing skills and writing performance (grammar, vocabulary, coherence) through AI-assisted feedback in a pedagogical context, not on automated scoring or system evaluation alone.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses an experimental design with pre-test and post-test writing assessments and reports quantifiable improvements in overall writing performance and subcomponents (grammar, vocabulary, coherence) between experimental and control groups.""}}"
Chatgpt-generated Versus Human Direct Corrective Feedback on L2 Writing,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are second-year English Pedagogy students at a Chilean university, indicating they are L2 English learners in an EFL/ESL context. The study explicitly concerns L2 essay writing in English.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention compares direct written corrective feedback (WCF) provided by ChatGPT (an LLM) versus a human teacher. Students were randomly assigned to ChatGPT or teacher feedback over four sessions, indicating an experimental design integrating an LLM into writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on L2 essay writing quality, with ChatGPT used to deliver written corrective feedback as part of writing instruction. This directly targets writing competence rather than automated scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcomes: task response, cohesion and coherence, lexical resource, and grammatical range and accuracy. It compares effectiveness of ChatGPT vs. human WCF in improving these writing measures, noting significant enhancement and ChatGPT\u2019s superiority.""}}"
Efl Students’ Writing Engagement and Ai Attitude in Genai-assisted Contexts: a Mixed-methods Study Grounded in Sdt and Tam,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL learners (\u201cEFL learners\u2019 engagement in GenAI-assisted writing\u201d), clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines engagement profiles and attitudes toward GenAI and includes teacher interviews about potential use. It explicitly notes that few teachers have actively integrated such tools into their teaching. There is no described experimental or quasi-experimental LLM-based writing intervention or structured use of a specific LLM (e.g., ChatGPT) as part of instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is GenAI-assisted writing and writing engagement in EFL, which is directly related to writing competence\u2013related variables (engagement in writing).""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are engagement profiles and attitudes; there is no indication of quantifiable writing performance metrics (e.g., writing scores, quality measures) assessing effectiveness of an LLM-mediated writing intervention.""}}"
Examining Language Learners’ Genai-assisted Writing Self-efficacy Profiles and the Relationship with Their Writing Self-regulated Learning Strategies,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are explicitly described as English-as-a-foreign-language (EFL) learners, which fits the target population of L2 English learners in EFL/ESL/ELL contexts.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u2018GenAI-assisted writing\u2019 and GenAI as a scaffolding tool, but does not specify whether the GenAI tools are large language models (e.g., ChatGPT, GPT-4) or other forms of AI. It also does not clearly describe an experimental or quasi-experimental instructional intervention; the focus is on profiling learners\u2019 self-efficacy rather than testing an intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on GenAI-assisted writing self-efficacy profiles and their relationship with self-regulated learning strategies, not on writing competence or writing-related performance variables. The study examines motivational constructs underlying GenAI-assisted writing processes rather than implementing and evaluating a pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, text quality measures) are reported. Outcomes are self-efficacy profiles, SRL strategy use, and antecedents such as years of English learning and perceived proficiency, without measured changes in writing performance following an LLM-mediated intervention.""}}"
"Effects of Three Levels of Ai Integration on Second Language Academic Writing: Evaluating Restricted, Guided, and Free Use of Chatgpt",2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Korean college students in English essay writing courses, explicitly described as L2-English learners. The focus is on English academic writing, fitting ESL/EFL/ELL L2 English contexts.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention manipulates three levels of ChatGPT use (Restricted, Guided, Free) as instructional tools. ChatGPT is a large language model, and the design is quasi-experimental with three comparison groups over a semester.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on academic English essay writing. The study examines how different levels of AI integration affect academic writing outcomes, not on automated scoring or system evaluation alone.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcomes: essay scores and subcomponents (content quality, organization, language use) comparing the three groups, thus providing measurable effects of the LLM-mediated intervention.""}}"
Exploring Second Language Writers’ Engagement with Chatgpt Feedback: Revision Behaviors and Perceptions,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 25 B1-level English as a Foreign Language (EFL) students at a university in T\u00fcrkiye, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is used as a feedback tool, but the design is observational/descriptive (mixed methods) rather than experimental or quasi-experimental. The study explores engagement with feedback and perceptions, not an intervention tested for effectiveness against a control or pre-post design.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on L2 writing, specifically how EFL writers engage with ChatGPT feedback when revising opinion essays, including content, organization, and language use.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although essay drafts and revisions are analyzed, the abstract reports descriptive patterns of revision behavior and perceptions, not quantifiable writing outcome metrics assessing the effectiveness of a ChatGPT-mediated intervention (e.g., pre-post writing scores or comparative gains).""}}"
Empowering Students' Autonomy in Efl Learning: Ai Innovations in Schools of the Global South,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The population focus is on school-based English as a Foreign Language (EFL) learning across the Global South, which aligns with L2 English learners in EFL contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The article is a PRISMA-guided systematic review of AI in EFL learning, not an experimental or quasi-experimental primary study integrating specific LLMs (e.g., ChatGPT, GPT-4) into writing instruction. It synthesizes 22 empirical studies rather than reporting its own LLM-based intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The review addresses AI support for student autonomy across multiple skills (speaking, reading, writing, listening, vocabulary). Writing is only one of several skills and not the primary focus on writing competence or writing-related variables required by the review\u2019s scope.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a systematic review, it does not itself report original, quantifiable writing outcome metrics from an LLM-mediated intervention; instead, it synthesizes diverse AI-related studies with a focus on autonomy, not specific writing outcome measures.""}}"
"Negotiating Understanding, Control, and Authorship: L2 Learners’ Experiences with Ai-assisted Paraphrasing in Academic Writing",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are twelve English-as-a-foreign-language (EFL) students at a Chinese university, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cAI tools\u201d for paraphrasing but does not specify that they are large language models (e.g., ChatGPT, GPT-4). They could be other AI-based paraphrasers or translators not grounded in LLMs. The design is qualitative (interviews) rather than an experimental or quasi-experimental intervention study.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on learners\u2019 experiences and interactions with AI-assisted paraphrasing in academic writing, not on a structured pedagogical writing intervention or systematic integration of LLMs into instruction. It explores use patterns and agency rather than an instructional treatment targeting writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is purely qualitative, based on interviews and thematic analysis. No quantifiable writing outcome metrics or experimental measures of writing performance are reported.""}}"
"Exploring L2 Writing Motivation in Ai-mediated Efl Contexts: the Role of Teacher Affective Support, Ai Literacy, and Self-efficacy through the Lens of Self-determination Theory",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 627 Chinese university students in an AI-mediated EFL writing context, i.e., L2 English learners. The focus is clearly on L2 writing motivation in EFL settings.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is correlational/structural (questionnaires, SPSS, AMOS) and examines AI-mediated contexts, teacher affective support, AI literacy, and self-efficacy. It does not describe an experimental or quasi-experimental LLM-based writing intervention (e.g., ChatGPT use in instruction); AI is a contextual factor, not a specific LLM intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is L2 writing motivation and its predictors (teacher affective support, AI literacy, self-efficacy) within AI-mediated contexts, not on writing competence or writing-related performance variables. It is a motivational study rather than a writing instruction or competence intervention study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are self-reported motivational and psychological constructs measured via questionnaires and modeled structurally. No quantifiable writing performance or competence outcomes (e.g., writing scores, quality measures) are reported to assess effectiveness of an LLM-mediated writing intervention.""}}"
The Psychology of Pedagogical Compromise: Written Corrective Feedback in Chinese Efl Writing through an Ecological Systems Lens,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Chinese university EFL (English as a Foreign Language) students and teachers, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention concerns different types of written corrective feedback (selective, comprehensive, minimal) delivered by teachers. There is no mention of large language models or any LLM-based tool (e.g., ChatGPT, GPT-4) being integrated into the writing instruction or process.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on writing competence, specifically written corrective feedback practices and their impact on student writing accuracy and anxiety in EFL writing.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantitative writing outcomes, including improvements in writing accuracy and satisfaction, with statistical results (F = 15.61, p < .001, d = 1.08) comparing selective, comprehensive, and minimal feedback.""}}"
Threshold-triggered Dual Effects in Ai-assisted Efl Writing: Self-efficacy Modulates Grammar Learning Pathways,2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly refers to EFL (English as a Foreign Language) grammar instruction and EFL learners, indicating L2 English learners in an EFL context. The focus is clearly on English grammar learning.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study examines \u201cAI writing tools\u201d and \u201cAI-assisted EFL writing,\u201d but the abstract does not specify whether these tools are large language model\u2013based (e.g., ChatGPT, GPT-4) or other forms of AI (e.g., rule-based grammar checkers). Without explicit mention of LLMs or transformer-based generative models, it is not possible to confirm that the intervention meets the LLM criterion.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The focus is on \u201cEFL grammar instruction,\u201d \u201cgrammatical competence growth,\u201d and \u201cgrammar learning pathways\u201d within AI-assisted EFL writing. While this is related to writing, it is not clear whether the primary outcome is overall writing competence or broader writing-related performance, as opposed to isolated grammar learning. The title and abstract emphasize grammar rather than writing quality or composition skills.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract reports quantifiable outcomes: a self-efficacy threshold (T=3.278), proportions of learners showing regression (60.32%), and differential grammatical competence growth/erosion. These indicate measured, quantitative learning outcomes under AI-assisted conditions, even though the exact writing metrics are not fully detailed.""}}"
A Student-centered Framework for Understanding Efl Thesis Writing Difficulties in Vietnam,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Vietnamese English as a Foreign Language undergraduate students writing theses in English, clearly fitting an EFL/ELL context focused on English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""AI tools are mentioned only as part of the support systems and in relation to institutional policies and ethical use. There is no indication of an experimental or quasi-experimental design integrating LLMs (e.g., ChatGPT) into writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on understanding thesis writing difficulties and support systems broadly, not on a specific LLM-mediated writing intervention. AI tools are one of several supports and not the central pedagogical intervention under study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses a qualitative design with semi-structured interviews and thematic analysis. It does not report quantifiable writing outcome metrics or experimental measures of the effectiveness of AI/LLM-mediated writing interventions.""}}"
Feedback Literacy and Efl Learner Engagement with Chatgpt Feedback: Predicting Feedback Uptake and Perceived Usefulness,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 51 Chinese university students in EFL writing, clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses ChatGPT, a large language model, to provide feedback on three ChatGPT-supported writing assignments, integrating it into the writing process.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is EFL writing with a focus on engagement with ChatGPT-generated feedback and revision-based tasks, directly tied to writing instruction and feedback use.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are feedback uptake (behavioral adoption) and perceived usefulness, analyzed via regression and mediation. The abstract does not indicate any quantifiable writing performance or quality measures (e.g., scores, rubric-based writing improvement); it focuses on engagement and perceptions rather than writing competence outcomes.""}}"
Exploring Sentence-level Revision Capabilities of Large Language Models in English for Academic Purposes Writing Assistance,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions challenges for non-native English speakers in English for Academic Purposes, but it does not state that the study involves human L2 English learners as participants. It appears to be a system-level evaluation of LLM performance rather than a learner-based study.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study evaluates LLMs\u2019 sentence-level revision (SentRev) capabilities via three experimental setups, but these are NLP/system experiments, not pedagogical interventions integrated into writing instruction or learner writing processes. No teaching or learning intervention with L2 writers is described.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on assessing LLM performance on SentRev and improving it via prompting and academic phrase integration. There is no indication of a classroom or instructional context, nor of writing competence development among learners; it is a technical evaluation of LLM functionality.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are LLM performance metrics on sentence-level revision tasks and benchmark considerations, not quantifiable writing outcomes for L2 learners. No learner writing scores, gains, or writing-related learner variables are measured.""}}"
A Multi-stage Interactive Writing Task for the Assessment of English Language Writing Proficiency,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses an assessment of English language writing proficiency but does not specify that participants are L2 English learners (ESL/EFL/ELL). They could be native or mixed populations; the population type is not explicit.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""A large language model is used to automatically analyze test-taker responses and generate customized follow-up prompts, but this is within a testing/assessment system, not an instructional or pedagogical writing intervention. There is no indication of experimental or quasi-experimental integration of LLMs into teaching or learning processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on assessment design and validity of a high-stakes writing test, not on improving writing competence through instruction. The LLM is used for theme detection and prompt generation to support measurement, aligning with assessment functionality rather than a pedagogical writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported concern test validity, fairness, and the effect of follow-up task type on scores, not the effectiveness of an LLM-mediated writing intervention. There is no structured instructional treatment or quantifiable learning gain in writing ability attributable to LLM-based teaching or feedback.""}}"
Integrating Move Analysis and Sentence Reconstruction in Automated Writing Evaluation for L2 Academic Writers,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cL2 academic writers\u201d and \u201clearners,\u201d implying L2 English users in an academic writing context, but it does not explicitly specify ESL/EFL/ELL participants or any concrete learner sample; the focus is primarily on system development and evaluation.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although GURUS uses transformer-based LLMs and is framed as an AWE system for academic writing, the study centers on system design and performance metrics (classification, reconstruction) rather than an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction with learners as participants.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on automated move classification and sentence reconstruction performance (F1, Brier, BERTscore, human assessment of outputs). While writing instruction is discussed conceptually, the study does not report an implemented instructional intervention or learner use in a writing course; it is essentially a system evaluation, not a pedagogical study of writing competence change.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable learner writing outcome metrics (e.g., pre/post writing scores, improvements in accuracy, complexity, or genre performance) are reported. The quantitative results concern model performance (classification and reconstruction quality), not measured changes in L2 learners\u2019 writing following an LLM-mediated intervention.""}}"
Examining the Consistency of Instructor Versus Large Language Model Ratings on Summary Content: Toward Checklist-based Feedback Provision with Second Language Writers,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Japanese undergraduate students producing learner-generated summaries in an L2 writing instruction context in Japan, indicating L2 English writers in an EFL setting.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines consistency between instructor ratings and LLM-estimated ratings using different prompts. It focuses on LLM-based scoring/checklist ratings, not on an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on rating agreement and prompt design for LLM-generated checklist ratings, akin to automated assessment functionality. There is no described instructional intervention where LLMs are used to teach or support writing; the pedagogical use is only discussed as a potential future application.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study does not report quantifiable outcomes of an LLM-mediated writing intervention (e.g., changes in writing quality due to LLM use). It analyzes agreement between human and LLM ratings on existing summaries, without measuring writing improvement or intervention effects.""}}"
"Evaluating Generative Ai Tools for Improving English Writing Skills: a Preliminary Comparison of Chatgpt-4, Google Gemini, and Microsoft Copilot",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as B+ level English as a Foreign Language (EFL) students at a preparatory school in T\u00fcrkiye, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the study uses LLM-based tools (ChatGPT-4, Google Gemini, Microsoft Copilot), the design focuses on comparing the tools\u2019 performance in supporting brainstorming, outlining, and feedback, rather than an experimental or quasi-experimental pedagogical intervention where learners\u2019 writing development is measured over time. The primary unit of analysis appears to be tool outputs and student perceptions, not an instructional treatment effect on learners.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is opinion essay writing in EFL, with focus on idea generation, essay structuring, and feedback\u2014clearly writing-related variables within a pedagogical context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Rubric-based evaluations are used to compare the tools\u2019 performance (e.g., idea generation, structuring, feedback actionability), but the abstract does not indicate that students\u2019 own writing outcomes (e.g., improvements in essay quality or scores attributable to the intervention) are measured as dependent variables. The focus is on tool comparison and perceptions, not quantifiable learner writing gains from an LLM-mediated intervention.""}}"
