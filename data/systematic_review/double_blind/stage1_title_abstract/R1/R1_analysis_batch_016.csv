Title,Year,Decision,Notes
The Role of Chatgpt in Enhancing Efl Students’ Esp Writing Skills: an Experimental Study of Gender and Major Differences,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as EFL university students learning ESP writing, which clearly indicates L2 English learners in an EFL context with a focus on English writing.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study is an experimental study using ChatGPT as a self-directed learning tool. ChatGPT is a large language model, and it is integrated into the learning process to enhance ESP writing skills.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on ESP writing skills, i.e., writing competence. The intervention uses ChatGPT specifically to enhance writing, not for automated scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports pre- and post-test data on writing skills, analyzed with Wilcoxon signed-rank test and ANOVA, indicating quantifiable writing outcome metrics to assess the effectiveness of the ChatGPT-mediated intervention.""}}"
Perceptions and Effectiveness of Ai-assisted Written Corrective Feedback: a Case Study of Chinese Efl University Students,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Chinese EFL university students in a College English course, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cAI-assisted written corrective feedback (AI-WCF)\u201d and \u201cAI tools,\u201d but does not specify that these are large language model\u2013based systems (e.g., ChatGPT, GPT-4). They could be other AI feedback tools not based on LLMs.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is argumentative writing in a College English course, with AI-assisted written corrective feedback integrated into structured writing tasks. The focus is on writing subskills (unity, support, cohesion/coherence, language use).""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are based on self-assessed progress via questionnaires, i.e., perceived gains in writing subskills. There is no indication of objective, quantifiable writing performance measures (e.g., rated texts, scores) to assess effectiveness of the AI-mediated intervention.""}}"
A Hybrid System for Automated Assessment of Korean L2 Writing: Integrating Linguistic Features with Llm,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The population consists of Korean L2 learners and the focus is on Korean L2 writing assessed on the TOPIK scale. The review requires L2 English learners in ESL/EFL/ELL contexts with data focused on English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The LLM is used to generate an ideal reference answer as part of an automated essay scoring (AES) system. There is no experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or learner writing processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on developing and validating an automated assessment system (AES) for Korean L2 writing, not on writing instruction or intervention. This falls under excluded contexts (LLM functionality as an automated essay scoring system).""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports system performance metrics (scoring accuracy, alignment with human judgments) rather than quantifiable learner writing outcomes resulting from an LLM-mediated instructional intervention.""}}"
Teachers’ Perceptions and Students’ Strategies in Using Ai-mediated Informal Digital Learning for Career Esl Writing,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are university students in an English writing course in an ESL context (\u201ccareer ESL writing instruction\u201d), so they are L2 English learners in an ESL setting.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although students use AI tools including ChatGPT (an LLM), the study is described as a case study exploring teachers\u2019 perceptions and students\u2019 strategies. There is no indication of an experimental or quasi-experimental design testing an LLM-based intervention; instead, it is observational/qualitative.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly writing-focused: \u201ccareer ESL writing instruction,\u201d \u201cEnglish writing course,\u201d and exploration of how AI-mediated informal digital learning tools are used for writing projects and rhetorical accessibility.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports qualitative findings about strategies and perceptions and mentions that students became more aware of how to improve their writing, but it does not report any quantifiable writing outcome metrics or experimental measures of writing improvement.""}}"
Blending Focus on Form and Technology: Teaching Essay Writing with Ai Tools; Biçim Ve Teknolojiye Odaklanmayı Harmanlamak: Yapay Zekâ Araçlarıyla Makale Yazmayı Öğretme,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as 120 undergraduate ESL learners, indicating L2 English learners in an ESL context with a focus on English essay writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The abstract states that the intervention integrates focus-on-form instruction with \u2018AI tools\u2019 but does not specify that these are large language models (e.g., ChatGPT, GPT-4). Given the generic term \u2018AI tools\u2019 and no mention of generative or LLM-based systems, it cannot be assumed they are LLMs rather than other AI-based writing aids.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study\u2019s primary focus is on teaching essay writing and examining effects on accuracy, fluency, and overall writing proficiency, clearly centering on writing competence rather than automated scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The design includes pre- and post-tests comparing control and experimental groups, and reports significant enhancement in essay writing in terms of linguistic accuracy and engagement, indicating quantifiable writing outcome metrics.""}}"
Pre-service Teachers’ Perceptions of the Use of Artificial Intelligence in an English as a Foreign Language Learning Context,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 120 EFL university students (B1\u2013B2 CEFR) in an English as a Foreign Language learning context, which fits the L2 English learner population criterion.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although generative AI tools, specifically ChatGPT, are mentioned, the study focuses on pre-service teachers\u2019 perceptions of integrating these tools, not on an experimental or quasi-experimental LLM-based writing intervention. No structured instructional treatment using ChatGPT is described.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""Writing is mentioned as one of several perceived benefits (students affirmed ChatGPT enhanced their writing abilities), but the primary focus is general EFL learning and perceptions of AI, not a targeted writing competence intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses surveys, narratives, questionnaires, and interviews to explore perceptions. There is no indication of quantifiable writing outcome measures (e.g., pre/post writing scores, rubric-based writing assessment) to evaluate the effectiveness of an LLM-mediated writing intervention.""}}"
Artificial Intelligence in Esl/efl Education: Evidence from Recent Reviews (2024–2025),2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The article is explicitly described as a \u201creview of reviews,\u201d synthesizing 14 systematic reviews, meta-analyses, and meta-syntheses. It does not report on a primary study with a defined participant population of L2 English learners; instead, it aggregates findings from other reviews.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""As a secondary study (\u201creview of reviews\u201d), it does not implement an experimental or quasi-experimental LLM-based intervention itself. It summarizes prior work on AI-enhanced instruction, including generative AI such as ChatGPT, but does not constitute an intervention study.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on synthesizing evidence across multiple skills and dimensions (writing, speaking, learner roles, ethics), not on a specific, primary writing-focused pedagogical intervention. It is a higher-level synthesis rather than a context-specific writing intervention study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The article does not report original, quantifiable writing outcome metrics from a primary intervention. Any effectiveness data are aggregated from other reviews, which falls under excluded publication types (reviews, meta-analyses).""}}"
Genai and Human Assessments of L2 Chinese Writing: Interrater Reliability and Rater Bias,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are learners of Chinese as a second language (L2 Chinese writing). The review targets L2 English learners in ESL/EFL/ELL contexts with a focus on English writing, so the population and target language do not match the inclusion criteria.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT and DeepSeek are used as automated raters to assess L2 Chinese writing. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or writing processes; the focus is on assessment reliability and rater bias.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on writing assessment (interrater reliability, severity, consistency, genre-based bias) rather than on improving writing competence or writing-related learning outcomes. It evaluates LLMs as essay scorers, which the protocol specifies should be excluded.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports psychometric outcomes (agreement, correlation, severity, bias) for rating performance, not quantifiable writing outcome metrics resulting from an LLM-mediated writing intervention. There is no structured instructional intervention whose impact on learners\u2019 writing is measured.""}}"
Examining the Efficacy of Chatgpt and Human-derived Corrective Feedback in Addressing Grammatical Errors in Saudi Efl Students’ Compositions,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 53 Saudi EFL undergraduates at the University of Jeddah. The context is explicitly EFL and the focus is on English grammatical accuracy in students\u2019 compositions.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention compares ChatGPT-based written corrective feedback (experimental group) with human corrective feedback (control group) over eight weeks. ChatGPT is a large language model integrated into the writing instruction process, and the design is experimental with pretest\u2013posttest groups.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on written corrective feedback on students\u2019 compositions and aims to foster linguistic accuracy in writing. The context is clearly writing instruction (EFL compositions) rather than automated scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Pretests and posttests assessed participants\u2019 grammatical competence in writing, and quantitative findings report that the experimental group significantly outperformed the control group in the posttest. These are quantifiable writing-related outcome measures of the LLM-mediated intervention.""}}"
Exploring Efl Teachers' Strategies in Employing Ai Chatbots in Writing Instruction to Enhance Student Engagement,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as EFL students, i.e., L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cAI chatbots\u201d and \u201cadvanced AI language models\u201d but does not specify that they are large language models (e.g., ChatGPT, GPT-4) as opposed to rule-based or simpler AI chatbots. The specific technology and model type are not identified.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is EFL writing instruction, and the intervention is the use of AI chatbots within writing classes. The focus is pedagogical, not automated scoring or system evaluation.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study\u2019s primary quantitative outcome is student engagement (affective, behavioral, cognitive). There is no indication of quantifiable writing performance or writing quality measures; writing outcomes are only mentioned generically as \u2018eventually enhancing student learning outcomes\u2019 without reported metrics.""}}"
Self-assessment Accuracy in the Age of Artificial Intelligence: Differential Effects of Llm-generated Feedback,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are N = 459 upper secondary students who wrote an argumentative essay in English as a foreign language, clearly indicating an EFL (L2 English) population.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses GPT-3.5-turbo-generated feedback as the intervention in a randomized control experiment, integrating an LLM into the writing process (feedback on first drafts during revision).""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the task is argumentative essay writing in EFL and involves revision, the primary outcome of interest is self-assessment accuracy (SAA), not writing competence or writing-related performance variables. The abstract reports effects on SAA and its moderators, not on writing quality or other writing outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The only reported quantitative outcome is self-assessment accuracy (SAA) and its change; there is no mention of quantifiable writing performance metrics (e.g., scores, quality ratings, linguistic measures) used to assess the effectiveness of the LLM-mediated writing intervention on writing itself.""}}"
Evaluating L2 Learners’ Experience with Genai-powered Academic Reading Tool in Higher Education: a Small-scale Exploratory Study,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cL2 learners\u201d and \u201cpostgraduate students\u201d using an academic reading tool, but it does not explicitly state that they are L2 English learners in ESL/EFL/ELL contexts or that English is the target language. The context (academic reading, theoretical frameworks) suggests English-medium study, but this is not clearly specified.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is a GenAI-powered academic reading tool (Fullpicture) using ChatGPT to generate reading reports. The focus is on academic reading support, not on integrating LLMs into writing instruction or writing processes. There is no experimental or quasi-experimental design targeting writing intervention; instead, students evaluate the tool and reflect on their reading experience.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is academic reading comprehension and learners\u2019 experiences with a GenAI reading tool. While the tool may indirectly influence academic writing (e.g., generating perspectives for writing), the study is framed around reading comprehension levels and evaluation of arguments and evidence, not on writing competence or writing-related instructional interventions.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are learners\u2019 reflections and Likert-scale ratings of the tool\u2019s effectiveness for reading-related constructs (e.g., comprehension, evaluation of arguments). There are no quantifiable writing outcome metrics (e.g., writing quality scores, revisions, text features) assessing the effectiveness of an LLM-mediated writing intervention.""}}"
Effects of Deepseek-assisted Writing Instruction on Efl Learners' Writing Performance,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as EFL learners working on English writing skills, which fits the target population of L2 English learners in an EFL context.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study is a prospective quasi-experimental design where DeepSeek, a named LLM, is employed to assist learners\u2019 writing during a defined intervention period, integrating the LLM into writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on English writing competence, examining different dimensions of learners\u2019 English writing skills (micro- and macro-level performance) within an instructional intervention, not on automated scoring or system evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Learners\u2019 writing production from baseline, intervention, and follow-up periods was collected and rated, yielding quantifiable writing performance outcomes (e.g., vocabulary, grammar, mechanics, macro-level performance) to assess the effect of DeepSeek-assisted instruction.""}}"
Ai-driven Scaffolding and Affective Support in Esl Argumentative Writing: a Multimodal Analytics Approach,2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly refers to ESL students and an ESL system for writing argumentative essays, indicating L2 English learners in an ESL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The system uses a Transformer architecture with an emotion recognition model and AI-based scaffolding. However, it is not clear whether this is a large language model used for generative writing support (e.g., ChatGPT-like) or primarily a multimodal emotion-recognition/analytics model without LLM-based text generation. The abstract does not specify LLM-based generative intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on ESL argumentative writing, writing quality, writing patterns, and performance, with AI-driven scaffolding and affective support as part of a dynamic intervention framework. This aligns with writing competence and writing-related variables in a pedagogical context.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract notes that it was \u2018experimentally determined\u2019 that the system managed writing quality and reduced cognitive load, and that statistical modeling examined correlations between multimodal characteristics and writing performance. This implies quantifiable writing outcome metrics were collected.""}}"
Understanding Efl Learners’ Strategies in Aiassisted English Writing: an Activity Theory Perspective; Comprensión De Estrategias De Los Estudiantes De Efl En La Escritura Asistida Por Ia,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as English as a foreign language (EFL) learners, indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers broadly to \u201cAI-assisted writing\u201d and \u201cinteracting with AI,\u201d but does not specify that the AI tools are large language models (e.g., ChatGPT, GPT-4) or transformer-based generative systems. The type of AI is not identified.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on EFL learners\u2019 strategies when using AI to assist with writing tasks, clearly centering on writing processes and practices in an educational context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is qualitative, using screenshots, chat logs, and semi-structured interviews to explore strategies and perceptions. No experimental or quasi-experimental design or quantifiable writing outcome metrics are reported.""}}"
Bridging the Gap: a Systematic Deconstruction Strategy for Esl Student Success in Academic Writing,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly targets ESL students and discusses their challenges in academic writing, clearly situating the population as English L2 learners in an ESL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the paper mentions AI tools and prompt engineering, it does not specify the use of large language models (e.g., ChatGPT, GPT-4) nor describe an experimental or quasi-experimental intervention integrating LLMs into writing instruction. It appears to be a conceptual/strategic paper about prompt design rather than an LLM-based intervention study.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on academic writing and a strategy to help ESL students handle writing prompts, addressing rhetorical and disciplinary requirements in writing tasks. Thus, the primary context is writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not report any empirical, quantifiable writing outcome measures or an experimental evaluation of the proposed strategy. It describes a strategy and provides an illustrative example (using \u201cThe Gift of the Magi\u201d) but no structured intervention outcomes or metrics.""}}"
Students’ Self-determination in Using Machine Translation and Generative Ai Tools for English for Academic Purposes,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EAP students in an English as a Second Language context in Australia and an English as a Foreign Language context in Vietnam, i.e., L2 English learners in ESL/EFL contexts.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study investigates students\u2019 use of machine translation and generative AI tools and their motivations, but there is no indication of an experimental or quasi-experimental design integrating a specific LLM (e.g., ChatGPT) as a structured writing intervention. It is primarily a survey/interview study of existing practices and perceptions.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on self-determination (autonomy, competence, relatedness) and motivational aspects of MT/GAI use in academic writing, not on evaluating a pedagogical writing intervention or systematically designed LLM-mediated writing instruction. Mention of \u2018innovations\u2019 is illustrative rather than an assessed intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are motivational constructs and perceptions (autonomy, competence, relatedness) analyzed via survey and regression. There is no report of quantifiable writing performance or writing quality measures as outcomes of an LLM-mediated intervention.""}}"
The Algorithmic Adjuvant: Synthesizing Human Pedagogy and Artificial Intelligence in the Modern Esl Classroom with Insights from Uzbekistan,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study focuses on ESL classrooms in Uzbekistan, explicitly describing English as a Second Language (ESL) education and learners, which fits the target population of L2 English learners in ESL/EFL contexts.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions AI technologies such as intelligent tutoring systems, automated writing aids, and speech recognition software, but does not specify that these are large language model (LLM)-based tools (e.g., ChatGPT, GPT-4). The nature of the AI tools (LLM vs. other AI) is not clear, and there is no explicit mention of transformer-based generative models.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""Writing is mentioned only indirectly via \u2018automated writing aids\u2019; the broader focus is on ESL instruction, learner engagement, fluency, autonomy, and general AI integration. The primary emphasis appears to be overall ESL teaching rather than a focused intervention on writing competence or writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is based on qualitative case studies and observational evidence, discussing opportunities, challenges, motivation, fluency, and autonomy. It does not report quantifiable writing outcome metrics or experimental measures of writing performance; outcomes are described qualitatively rather than via structured, quantitative writing assessments.""}}"
Probing into Efl Students’ Perceptions about the Impact of Utilizing Ai-powered Tools on Their Academic Writing Practices,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as EFL students enrolled in an \u201cAcademic Writing 2\u201d course at a private university in Oman, indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is among the tools used, the study is framed as an exploration of perceptions of multiple AI-powered tools (Grammarly, Wordtune, ChatGPT, Quillbot) and uses a qualitative approach without an explicit experimental or quasi-experimental design to test an LLM-based writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is academic writing instruction; tools are used for grammar/style suggestions, paraphrasing, summarizing, and brainstorming within an academic writing classroom, focusing on writing practices and performance.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract emphasizes qualitative data (learning journals, observations, focus-group interviews) and students\u2019 perceptions. While it mentions improved writing skills and performance, there is no indication of reported quantifiable writing outcome metrics or experimental measures of effectiveness.""}}"
When Ai Meets Source Use: Exploring Chatgpt's Potential in L2 Summary Writing Assessment,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study analyzes 90 L2 student summary essays in an integrated writing assessment context, indicating participants are L2 writers. Although the target language is not explicitly stated, the context (Elsevier, L2 summary writing, integrated writing assessment) strongly implies L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""ChatGPT is used as an automated rater (GPT_original, GPT_calibrated) to score L2 summary writing and is compared with human raters. There is no indication of an instructional or quasi-experimental pedagogical intervention integrating ChatGPT into learners\u2019 writing processes or instruction; it is a scoring/assessment study.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on ChatGPT\u2019s performance as a rating tool for integrated L2 summary writing (scoring, rater severity, source-use criterion), not on improving learners\u2019 writing competence through an instructional intervention. This aligns with automated essay scoring/assessment research, which is outside the review scope.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports quantitative outcomes in terms of rating behavior (severity, alignment with human raters, gaps in assessing source use), but these are not writing outcome measures from an LLM-mediated instructional intervention. No experimental manipulation of learners\u2019 writing with pre/post or comparative writing performance metrics is described.""}}"
