Title,Year,Decision,Notes
Investigating Connections between Teacher Identity and Pedagogy in a Content-based Classroom,2021,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are L2 English learners in an L2 English legal education (LLM) program, learning to write a legal genre (office memorandum), which fits ESL/EAP-type contexts focused on English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The abstract describes a classroom-based ethnography examining how a law instructor\u2019s role identities shape pedagogy. There is no mention of large language models, AI, or any technology-mediated intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is a legal research and writing course where the instructor teaches L2 learners to write an office memorandum, clearly focusing on writing competence and pedagogy.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is qualitative (ethnography) with observations, interviews, and artifacts. It does not report quantifiable writing outcome metrics or experimental evaluation of an intervention.""}}"
Application of Artificial Intelligence Powered Digital Writing Assistant in Higher Education: Randomized Controlled Trial,2021,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as \""English second postgraduate students\"" and \""non-native postgraduate students in English academic writing,\"" indicating L2 English learners in an English academic writing context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The intervention is an \""Artificial Intelligence (AI) powered writing tool\"" delivered in a randomized controlled trial. However, the abstract does not specify that this AI tool is a large language model (e.g., ChatGPT/GPT-based or transformer generative model). Given the 2021 date and lack of detail, it is likely a generic AI writing assistant rather than an LLM, but this cannot be confirmed from the abstract alone.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary outcomes reported are behavioral, emotional, and cognitive engagement, self-efficacy for writing, and emotions. The focus is on learning behavior and attitudinal technology acceptance, not on writing competence or writing-related performance measures. Writing is the context, but not the main outcome variable.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing performance outcomes (e.g., writing quality scores, accuracy, complexity) are reported. All measured outcomes are affective or engagement-related constructs, so the study does not provide experimental measures of writing improvement attributable to the AI tool.""}}"
Ensemble Multi-channel Neural Networks for Scientific Language Editing Evaluation,2021,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The abstract discusses scientific papers authored by non-native English speakers in general and the AESW shared task dataset, but there is no indication of actual learner participants in ESL/EFL/ELL instructional contexts. It is a system evaluation study, not an intervention with L2 learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study proposes an Ensemble Multi-Channel Neural Networks (EMC-NN) model for sentence-level language editing evaluation. It is not an LLM-based (e.g., ChatGPT, GPT-4) pedagogical intervention; rather, it is a classification model for detecting whether sentences need editing.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on automated scientific writing evaluation (predicting if a sentence needs editing), not on integrating LLMs into writing instruction or learners\u2019 writing processes. It is a tool performance study, not a teaching/learning context targeting writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported are model performance metrics (F1-score) on the AESW task, not quantifiable writing outcomes for learners. No experimental or quasi-experimental intervention with learner writing performance is described.""}}"
Automated L2 Writing Performance Assessment: a Literature Review,2021,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses ESL/EFL writing instruction contexts in general but, as a literature review, does not specify a concrete participant population of L2 English learners within an empirical study.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The article is explicitly described as a literature review of Automated Writing Evaluation (AWE) systems over two decades, not an experimental or quasi-experimental study integrating LLMs into instruction. It is a secondary review, not a primary intervention study.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""While the focus is on teaching and assessing writing, the paper synthesizes prior work on AWE systems rather than reporting a specific pedagogical intervention or context with primary data.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a literature review, the study does not report original, quantifiable writing outcome metrics from an intervention; it summarizes existing research and suggests future directions.""}}"
A Hierarchical Bert-based Transfer Learning Approach for Multi-dimensional Essay Scoring,2021,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions a self-collected dataset of Chinese EFL learners\u2019 argumentation (CELA), indicating L2 English learners are involved. However, the primary focus is on automated scoring performance, not on learner outcomes, and it is unclear whether participants are treated as learners in an instructional context rather than as data sources for model training.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study develops a hierarchical BERT-based model for automated essay scoring (AES). BERT is used as a pre-trained language model for scoring, not as an instructional or intervention tool integrated into writing instruction or writing processes. There is no experimental or quasi-experimental LLM-mediated pedagogical intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on improving automated essay scoring accuracy (QWK scores) across multiple dimensions. This is an assessment/measurement study of AES functionality, not a pedagogical study targeting writing competence or writing-related learning outcomes in an instructional context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported are model performance metrics (average quadratic weighted kappa) comparing the proposed AES model to baselines. There are no quantifiable learner writing outcomes or measures of the effectiveness of an LLM-mediated writing intervention.""}}"
A Literature Review of Foreign Studies on the Impact of Call on Second Language Acquisition from 2015,2021,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract discusses second language acquisition and foreign studies on CALL in general, but does not specify that the reviewed participants are L2 English learners or that the focus is on English rather than other target languages.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The article is explicitly described as a literature review of empirical studies on computer-assisted language learning (CALL) since 2015. It is not an experimental or quasi-experimental primary study, and it does not specifically focus on LLM-based tools such as ChatGPT or GPT-4.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The review concerns computer-assisted language teaching and second language acquisition broadly. It does not indicate that the primary focus is on writing competence or writing-related variables; multiple aspects of language teaching may be covered.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""As a literature review, the paper does not itself report original, quantifiable writing outcome metrics from an LLM-mediated intervention. It synthesizes prior CALL studies rather than conducting a new intervention with measured writing outcomes.""}}"
Digital Storytelling with Chatbots: Mapping L2 Participation and Perception Patterns,2021,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract states the context is an L2 class at a university in South Korea, implying EFL learners, but it does not explicitly specify that the target language is English. It only refers to \u201cL2\u201d generically.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses a \u201cdigital storytelling chatbot system (storybot).\u201d The abstract does not indicate that this chatbot is a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model). It appears to be a scripted or task-specific chatbot, not an LLM-based system.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on participation rates, reading comprehension, and perceptions of storybot interactions. While L2 output is mentioned, the outcomes emphasized are reading comprehension and perception, not writing competence or writing-focused instruction.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports participation analytics (amount read vs. written) and survey-based perceptions. It does not report quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity) to assess effectiveness of a writing intervention; writing is not systematically measured as an outcome.""}}"
The Intervention of Internet Technology on Students' English Learning in the Intelligent Era,2021,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Chinese medicine undergraduates learning English as a second language in China (ESL/EFL context). The study explicitly concerns second language learning (SLL) and English writing ability.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is described as an 'Internet learning system' and 'Internet technology' with AI resources and intelligent learning system, but there is no indication that a large language model (e.g., ChatGPT, GPT-4, transformer-based generative model) is used. It appears to be a general AI/Internet-based learning platform, not an LLM-based writing tool.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""Writing is one of the assessed skills; the abstract mentions an 'English Writing Scale' and reports that English writing ability is lower than middle level, and that performance in listening, reading, writing, and translation improved in the experimental group. Thus, writing competence is a primary outcome among other skills.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable outcomes: performance differences between experimental and control groups (p<0.01) across listening, reading, writing, and translation, as well as correlations and regression analyses involving learning anxiety, motivation, and learning ability. Writing performance is explicitly measured via an English Writing Scale.""}}"
Research on the Design of Lexical-chunks Centered Mode of Writing under Artificial Intelligence in College English Course,2021,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study is situated in a college English course with EFL learners (\u201ccollege English writing teaching model\u2026 for EFL, especially for students with a relatively low language proficiency\u201d), indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The abstract mentions \u201cbig data technology\u201d and \u201cartificial intelligence\u201d in general but does not specify the use of large language models (e.g., ChatGPT, GPT-4) or any transformer-based generative model. It appears to be a data-driven monitoring/feedback system rather than an LLM-mediated writing intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on a \u201ccollege English writing teaching model\u201d and how lexical-chunk-centered instruction affects students\u2019 writing input and output, which aligns with writing competence as a primary focus.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract notes that big data technology \u201ceffectively monitors the learning process\u201d and that lexical chunk teaching \u201cpromotes students\u2019 writing input and triggers output,\u201d but it does not clearly report quantifiable writing outcome metrics or experimental results; the design (experimental vs. descriptive) is not explicit.""}}"
The Listening Strategies of Non English Majors in Colleges and Universities Based on Artificial Intelligence,2021,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are non-English majors in colleges and universities studying English listening, which implies L2 English learners in an EFL/ESL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the title mentions 'based on artificial intelligence', the abstract describes a questionnaire study on listening strategies and metacognitive strategies. There is no indication of an experimental or quasi-experimental design integrating large language models (e.g., ChatGPT, GPT-4) into instruction or learning processes.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on listening strategies and listening level, not on writing competence or writing-related variables. No writing instruction or writing process is mentioned.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported concern listening strategy use and listening performance (e.g., scores for groups on questionnaire topics). There are no quantifiable writing outcome metrics or writing intervention effects reported.""}}"
L2 Learner Cognitive Psychological Factors about Artificial Intelligence Writing Corrective Feedback,2021,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 1,952 undergraduate L2 learners in China working on English writing, which fits an EFL/ESL/ELL L2 English learner population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The AI tool is Pigai, described as an AI evaluating system for English writings. Pigai is not a large language model\u2013based generative system like ChatGPT/GPT-4; it is primarily an automated evaluation/correction tool. The study focuses on AI writing corrective feedback, not on an LLM-mediated writing intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on learner cognitive psychological factors (perception, noticing, uptake, initiative, retention, emotion) regarding AI WCF, not on designing or evaluating a pedagogical writing intervention using LLMs. It examines attitudes and cognitive responses to Pigai feedback rather than a structured instructional intervention in writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are Likert-scale measures of cognitive psychological factors and correlations among them. There are no reported quantitative writing performance outcomes (e.g., writing scores, quality measures, accuracy gains) to assess the effectiveness of the AI feedback on writing.""}}"
Examining the Impact of Grammarly on the Quality of Mobile L2 Writing,2021,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were Japanese L2 English university students in an EFL context, and the focus is explicitly on English writing quality (grammatical accuracy, lexical richness, etc.).""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses Grammarly, described as an intelligent writing assistant with predictive text and real-time corrective feedback. Grammarly is not an LLM-based generative model like ChatGPT/GPT-4; it is an automated writing evaluation tool and does not meet the review\u2019s requirement for transformer-based LLM integration.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study\u2019s primary focus is on L2 writing competence, specifically mobile writing quality, examining grammatical accuracy, lexical richness, writing fluency, and syntactic complexity under Grammarly vs. non-Grammarly conditions.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports quantifiable writing outcomes, including grammatical errors, lexical variation, writing fluency, and syntactic complexity, analyzed via descriptive statistics and t-tests to assess the impact of the intervention.""}}"
Automated Writing Evaluation (awe) in Higher Education: Indonesian Efl Students' Perceptions about Grammarly Use across Student Cohorts,2021,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Indonesian undergraduate EFL students majoring in English education, clearly an L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention tool is Grammarly, an Automated Writing Evaluation (AWE) system. Grammarly is not described as an LLM-based, transformer generative model in this study and is treated as a conventional AWE tool, which falls outside the review\u2019s required focus on LLMs such as ChatGPT, GPT-4, etc.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is EFL writing classes and the use of Grammarly to assist students\u2019 writing processes, focusing on composing and revising writing and feedback on errors\u2014clearly writing-related.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study investigates students\u2019 perceptions of Grammarly\u2019s use via questionnaires and interviews. It does not report quantifiable writing outcome metrics (e.g., changes in writing scores, accuracy, complexity) but focuses on perceived usefulness and drawbacks.""}}"
Going beyond Computer-assisted Vocabulary Learning: Research Synthesis and Frameworks,2020,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The abstract refers broadly to 'foreign language learners' and 'learning foreign vocabulary' without specifying that participants are L2 English learners in ESL/EFL/ELL contexts or that the target language is English. The focus is on vocabulary learning in general, not clearly on English.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study presents three computer-assisted vocabulary learning applications (image recommendation, context representation from lifelogging images, and location-based word recommendation) within the AIVAS platform. There is no indication that these tools are based on large language models (e.g., ChatGPT, GPT-4, transformer-based generative models); they appear to be conventional CALL tools.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is vocabulary learning in informal settings, not writing competence or writing-related variables. The applications support image selection, context representation, and associated word recommendation, with no mention of writing instruction or writing processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Reported evaluations involve human and data-driven assessments of the vocabulary learning systems, but there is no indication of quantifiable writing outcome metrics or any writing intervention outcomes. The outcomes relate to vocabulary learning, not writing performance.""}}"
Future Prediction of L2 Writing Performance: a Machine Learning Approach,2020,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 102 students of English Language Teaching in Turkey, indicating L2 English learners in an EFL/ESL-related context, with outcomes explicitly about L2 writing performance.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study trains a machine learning model to predict L2 writing performance using demographic and psychometric data. It does not involve large language models (e.g., ChatGPT, GPT-4) nor integrate any LLM into writing instruction or writing processes; it is a predictive analytics study.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on predicting end-of-term L2 writing performance (Pass/Fail) for early identification of at-risk students, not on a pedagogical writing intervention or instructional use of AI in writing. There is no described integration of the model into teaching or writing activities.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although L2 writing performance is measured, the study does not report outcomes of an LLM-mediated writing intervention. It evaluates prediction accuracy of a machine learning classifier, not changes in writing performance due to an AI-supported instructional treatment.""}}"
Efl Writing Tasks and the Application of the Concept of Situatedness: Evaluating the Theoretical and Practical Aspects of the Saudi Efl Context,2020,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Saudi EFL students at Qassim and Bisha Universities, clearly an EFL/ELL context focused on English writing skills.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is a Situated Learning approach delivered via a virtual online learning environment and \u2018artificial worlds\u2019, but there is no indication that large language models (e.g., ChatGPT, GPT-4) are used. The technology appears to be a virtual learning environment, not an LLM-based tool.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study explicitly examines how the Situated Learning approach affects EFL student writing tasks and reports improvement in practical English writing skills, indicating a primary focus on writing competence.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""An experimental comparison between control and experimental groups is conducted, and results report that the virtual language experience improved participants\u2019 practical English writing skills, implying quantifiable outcome measures, even if not detailed in the abstract.""}}"
Detecting Preposition Errors to Target Interlingual Errors in Second Language Writing,2020,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers generally to 'second language learners' and 'second language writing' but does not specify that the target language is English or that participants are ESL/EFL/ELL learners. It may be about multiple languages with diverse prepositions, so the English L2 focus is not confirmed.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study focuses on developing classifiers and fine-tuned BERT models for preposition error detection as part of a prospective digital writing assistant. There is no indication of an experimental or quasi-experimental pedagogical intervention using an LLM with learners; it is a computational detection study.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on automatic preposition error detection models, not on writing instruction or learner-facing writing processes. The envisioned assistant is not empirically implemented as an instructional intervention in this study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable learner writing outcomes or measures of writing competence are reported. The paper evaluates model performance on error detection, not changes in learners\u2019 writing quality following an intervention.""}}"
Bert-based Contextual Semantic Analysis for English Preposition Error Correction,2020,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Although the abstract mentions ESL learners\u2019 writing as the motivation, the study itself is about developing a preposition error correction model; it does not describe an intervention with actual L2 English learner participants.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is a BERT-based preposition error correction model. BERT is a bidirectional encoder model, not a generative large language model used pedagogically in writing instruction. There is no experimental or quasi-experimental LLM-mediated teaching intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on automatic preposition error correction technology, not on a pedagogical context or writing instruction process. It is a NLP system paper rather than a study of writing competence development.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable learner writing outcomes or instructional effects are reported; the abstract only discusses model design and scoring, not changes in learners\u2019 writing performance.""}}"
Research on the Cultivation of Non-english Majors' English Reading Interest: Poa Teaching Mode in the Internet + Era,2020,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are non-English majors engaged in college English reading instruction in China, i.e., L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention is the POA (Production-Oriented Approach) teaching model in the context of 'Internet +', but there is no mention of large language models (e.g., ChatGPT, GPT-4) or any transformer-based generative AI being integrated into instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on English reading interest and reading instruction, not on writing competence or writing-related variables, even though reading is said to support later writing development.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The abstract reports that POA can promote students\u2019 reading interest in four aspects, but does not specify quantitative writing outcome metrics or any writing-focused measures; outcomes appear to be attitudinal (interest in reading).""}}"
"Exploring the Development of Writing Complexity, Accuracy, and Fluency in Relation to the Motivational Trajectories: a Dynamically-oriented Case Study; 探討與動機軌跡相關的寫作複雜度,正確性和流暢度的發展:一個動態性的個案研究",2020,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participant is described as a 'successful highly motivated EFL learner,' indicating an English-as-a-foreign-language context and thus an L2 English learner.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""In this study, 'LLM' refers to language learning motivation, not large language models. There is no mention of ChatGPT, GPT-4, or any transformer-based generative AI, nor any AI-mediated instructional intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study focuses on the development of writing complexity, accuracy, and fluency (CAF) in L2 writing, clearly centering on writing competence and related variables.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study quantitatively assesses CAF measures across ten stages of monthly writing assignments, providing quantifiable writing outcome metrics, even though these are not linked to any LLM-based intervention.""}}"
