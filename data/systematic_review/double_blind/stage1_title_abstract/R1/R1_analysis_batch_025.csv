Title,Year,Decision,Notes
Postgraduate Students' Attitude Toward Using Chatgpt in Enhancing Their Master's Thesis: a Mixed Method Study,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as postgraduate EFL learners, indicating they are L2 English learners in an EFL context and the focus is on English thesis writing.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is central, the study is not an experimental or quasi-experimental intervention. It investigates students\u2019 attitudes and self-reported uses of ChatGPT rather than implementing and testing a structured LLM-mediated instructional intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on enhancing the quality of Master\u2019s thesis writing (content, structure, grammar, sentence structure, APA style), which are writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study uses semi-structured interviews and a questionnaire to explore attitudes and perceived benefits. There is no indication of quantifiable writing outcome measures (e.g., pre/post writing scores, rubric-based performance) assessing the effectiveness of ChatGPT on writing quality.""}}"
Enhancing Argumentative Essay Skills: Evaluating the Efficacy of Ai-powered Tools Versus the Traditional Approach among Learners,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly refers to \u201csecond language (L2) learners\u201d and \u201csecond language learners,\u201d indicating an L2 population. While the target language is not named, the context of argumentative essay writing and institutional teaching strongly suggests an ESL/EFL academic writing context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses \u201cAI-powered writing tools like Quill Bot, Jeni AI, and others.\u201d QuillBot is not an LLM-based pedagogical tool in the sense required (it is primarily a paraphrasing/editing tool and not framed here as a transformer-based generative LLM used for instruction). No specific LLMs (e.g., ChatGPT, GPT-4, Gemini) are mentioned, and the tools are not clearly identified as LLM-based writing assistants integrated into instruction, so it does not meet the LLM intervention criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study\u2019s focus is on teaching and learning argumentative essay writing: \u201cmentor students to write argumentative essays,\u201d \u201cteach students the skill of crafting persuasive essays,\u201d and it evaluates different instructional approaches. This aligns with a writing competence intervention context rather than automated scoring or system evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study is described as a quasi-experimental design with experimental and control groups, and it reports that combining traditional methods with AI tools \u201csignificantly improved writing competency and the long-term retention of argumentative writing abilities.\u201d This implies quantitative outcome measures of writing performance over a semester.""}}"
Leveraging Llm-based Chatbots for Interactional Grammar Feedback in L2 Writing: Opportunities and Challenges,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 89 second-year pre-service teachers in South Korea receiving grammar feedback on their English essays, indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The title and abstract describe a \u2018LLM-based chatbot\u2019 and mention ChatGPT as context, but do not explicitly state that the implemented chatbot itself is powered by a large language model (e.g., GPT-4) versus a rule-based or non-LLM system. It is also unclear whether the design is experimental or quasi-experimental rather than descriptive/showcase of practice.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is L2 writing instruction, focusing on interactional grammar feedback on students\u2019 English essays and its role as a feedback provider in L2 writing classrooms, which aligns with writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports that the chatbot \u2018offers several advantages\u2019 and could be a complementary resource, but does not indicate any quantitative writing outcome measures (e.g., changes in writing scores, accuracy, complexity) or an experimental comparison. It appears to be a practice-oriented or evaluative study without reported quantifiable writing outcomes.""}}"
Chinese Efl Learners’ Genai Literacy in Digital Multimodal Composing and Self-regulated Writing: Chain Mediation Effects of Needs Satisfaction and Creative Self-concept,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as 634 Chinese EFL learners, i.e., L2 English learners in an EFL context, with focus on English writing and digital multimodal composing in EFL.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines learners\u2019 GenAI literacy in digital multimodal composing via questionnaires and structural equation modeling. There is no experimental or quasi-experimental intervention where an LLM (e.g., ChatGPT, GPT-4) is integrated into writing instruction or writing processes; GenAI is treated as a literacy construct, not as an implemented pedagogical tool.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on psychological mechanisms (needs satisfaction, creative self-concept) linking GenAI literacy in DMC to self-regulated writing. It does not describe a concrete LLM-mediated writing intervention or instructional context; rather, it is a correlational/mediation study of literacy and SRL, not an implemented writing pedagogy using LLMs.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes are questionnaire-based measures of GenAI literacy, needs satisfaction, creative self-concept, and self-regulated writing. The study does not report quantifiable writing performance outcomes (e.g., text quality, accuracy, complexity) resulting from an LLM-mediated intervention.""}}"
Artificial Intelligence Vs. Instructor Supported Ai: Teaching Second Language Writing Via “write&improve”,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The study investigates \u2018second language writing\u2019 and \u2018English writing success\u2019 and \u2018English writing self-efficacy beliefs,\u2019 indicating participants are L2 English learners in an ESL/EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention uses the Write&Improve system. While it is an AI-based feedback tool, the abstract does not indicate that it is an LLM/transformer-based generative model (e.g., ChatGPT, GPT-4). Write&Improve is typically an automated feedback system, not a large language model\u2013mediated writing assistant as required by the review.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on second language writing, specifically \u2018English writing success\u2019 and related constructs (self-efficacy, achievement emotions, teacher-student interaction) within a writing instruction context.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses an 8-week pretest\u2013posttest control group design and reports a \u2018statistically significant increase\u2019 in English writing success and other variables, indicating quantifiable writing outcome metrics are collected and analyzed.""}}"
"International Conference on Artificial Intelligence and Networks, Icain 2024",2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""This is a conference proceedings volume description listing multiple papers across AI and networks. No specific study with L2 English learners is described in the abstract. One title mentions EFL teachers, but no participant details or focus on L2 English learners\u2019 writing outcomes are provided at the proceedings level.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The abstract summarizes a collection of 50 papers on diverse AI topics. It does not specify any experimental or quasi-experimental integration of large language models (e.g., ChatGPT, GPT-4) into writing instruction. The only writing-related title, \u201cEFL Teachers\u2019 Inquisitive Agency in AI-Enhanced Writing Instruction,\u201d does not indicate LLM use or an intervention design in this proceedings-level abstract.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The proceedings cover broad AI and network topics (cybersecurity, fake news detection, medical imaging, etc.). Writing is only tangentially mentioned in one paper title, and there is no indication that the primary focus of any described study is writing competence or writing-related variables in a pedagogical context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics are reported in this proceedings abstract. It is a general description of a conference volume, not a specific empirical study with measured writing outcomes related to an LLM-mediated intervention.""}}"
"Ai-assisted Academic Writing in a Blended Efl Setting: Practices and Perceived Effectiveness at Fpt University, Hanoi",2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as first-year EFL students at FPT University Hanoi, indicating L2 English learners in an EFL context, with outcomes reported in terms of IELTS writing band scores (English).""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract states that students use AI tools such as ChatGPT, QuillBot, and DeepSeek to support academic writing, but it does not clearly specify whether there is an experimental or quasi-experimental intervention design centered on LLM integration versus a control/comparison condition. It may be observational use within a blended course rather than a structured LLM-mediated intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on academic writing in an EFL blended learning environment, examining how AI tools are used for idea generation, grammar correction, and content refinement, and discussing AI\u2019s pedagogical potential in EFL writing instruction.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""The study reports that writing scores improved by an average of 0.94 IELTS band scores, but the abstract does not clarify whether this gain is causally attributed to a defined LLM-based intervention (e.g., pre/post with structured AI use) or is simply correlational/observational. The design and measurement structure are not sufficiently detailed to confirm it as an experimental or quasi-experimental outcome of LLM-mediated intervention.""}}"
Large Language Model-driven Dynamic Assessment of Grammatical Accuracy in English Language Learner Writing,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions 'learners of English' and 'English Language Learner Writing', suggesting an ELL context, but it does not clearly specify that participants are L2 English learners in ESL/EFL/ELL settings, nor does it describe an actual learner sample.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study develops DynaWrite and tests 21 LLMs (with focus on GPT-4o and neural-chat) for their ability to provide dynamic assessment feedback and identify grammatical errors. The focus is on system performance and model comparison, not on an experimental or quasi-experimental pedagogical intervention integrating LLMs into instruction with learners.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the context is grammatical accuracy in learner writing, the primary focus is on evaluating LLM capabilities (error detection, DA quality, responsiveness, stability) rather than on improving learners\u2019 writing competence through an instructional intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable learner writing outcomes are reported. The metrics concern model performance (error identification accuracy, quality of hints, responsiveness, stability), not changes in learners\u2019 writing performance following an LLM-mediated intervention.""}}"
Prompt Engineering as Mediation: Investigating Ai Chatbot-assisted Writing Process from an Activity Theory Perspective,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as Chinese EFL (English as a Foreign Language) undergraduates, indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to an \u2018AI chatbot\u2019 and \u2018chatbot-supported expository writing tasks\u2019 but does not specify that the chatbot is a large language model (e.g., ChatGPT, GPT-4). It could be any AI chatbot, so the LLM nature of the tool is not confirmed.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on \u2018chatbot-supported expository writing tasks\u2019 and \u2018AI chatbot-assisted writing within activity systems,\u2019 clearly centering on writing processes and outcomes in an instructional context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although the abstract mentions \u2018shaping writing outcomes,\u2019 it presents a qualitative, activity-theory-based investigation using interaction logs, artifacts, and interviews. There is no indication of an experimental or quasi-experimental design with quantifiable writing outcome metrics to assess intervention effectiveness.""}}"
The Role of Artificial Intelligence in Writing Assessment: Learner Perceptions and System Effectiveness,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract mentions 'learners of varying educational levels' but does not specify that they are L2 English learners in ESL/EFL/ELL contexts. Their language background and whether English is an L2 is not stated.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study focuses on AI-driven writing tools such as Grammarly and Turnitin, which are not described as large language model (LLM)-based generative systems. There is no mention of ChatGPT, GPT-4, or other LLMs, nor of an experimental or quasi-experimental LLM-based instructional intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on writing assessment, learner perceptions, and system effectiveness (accuracy, fairness, clarity of feedback), not on a pedagogical writing intervention or instructional integration of LLMs. It evaluates an assessment tool rather than a structured teaching/learning process in writing.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although the abstract claims that regular usage of the AI tool 'significantly enhances writing skills, particularly in grammar,' it does not clearly describe an experimental or quasi-experimental design with quantifiable writing outcome metrics specific to an LLM-mediated intervention. The emphasis is on perceptions and satisfaction ratings rather than measured writing performance changes from an LLM-based intervention.""}}"
The Potential Advantages of Using an Llm-based Chatbot for Automated Writing Evaluation for English Teaching Practitioners,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are Korean high school EFL students, clearly L2 English learners in an EFL context: \u201cnarrative essays written by Korean high school EFL students.\u201d""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study develops an AWE chatbot based on ChatGPT 4.0-turbo used as an automated rater. There is no experimental or quasi-experimental pedagogical intervention integrating the LLM into writing instruction or writing processes; it is a tool validation study.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on automated writing evaluation and score reliability/validity: comparing chatbot scores with human raters using analytic measures and Rasch modeling. It evaluates LLM functionality as an essay scoring system, not as part of a teaching/learning intervention targeting writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics from an intervention are reported. The study analyzes correlations between LLM and human scores on existing essays, without any instructional treatment or pre/post writing performance measures.""}}"
Development and Validation of a Multidimensional Chatgpt Feedback Engagement Scale in Second Language Writing,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to 'second language (L2) writing' and 'students' but does not specify that the target language is English or that participants are ESL/EFL/ELL learners. The L2 could be any language.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study focuses on developing and validating a 'ChatGPT Feedback Engagement Scale.' It examines engagement with ChatGPT feedback but does not describe an experimental or quasi-experimental pedagogical intervention integrating an LLM into writing instruction; rather, it is a measurement development/validation study.""}, ""c3"": {""status"": ""unclear"", ""evidence"": ""The context is L2 writing and ChatGPT feedback engagement, which is writing-related. However, the primary focus is on engagement constructs and scale development, not on writing competence or instructional intervention outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The outcomes reported are psychometric properties of an engagement scale (factor structure, validity, reliability). There is no indication of quantifiable writing performance or writing quality measures used to assess the effectiveness of an LLM-mediated writing intervention.""}}"
Understanding How Ai Chatbots Influence Efl Learners' Oral English Learning Motivation and Outcomes: Evidence from Chinese Learners,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 351 EFL students in China learning spoken English with an AI chatbot, clearly an EFL/ESL context focused on English as L2.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers generically to \u201cAI chatbots\u201d for spoken English learning but does not specify that they are large language model\u2013based (e.g., ChatGPT, GPT-4) or transformer generative models. They could be rule-based or other non-LLM systems.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on spoken/oral English learning, motivation, self-efficacy, and social presence. There is no indication that writing instruction, writing processes, or writing competence are targeted outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes concern oral English learning motivation and learning outcomes in a general sense, analyzed via SEM from questionnaire data. No quantifiable writing outcome metrics or writing performance measures are reported.""}}"
A Qualitative Descriptive Study of Teachers' Beliefs and Their Design Thinking Practices in Integrating an Ai-based Automated Feedback Tool,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The context is Norwegian 9th-grade students learning English as a second language, taught by ESL teachers. The abstract explicitly mentions \u2018English as a second language teachers\u2019 and \u2018L2 writing\u2019, indicating L2 English learners in an ESL/EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The intervention involves an AI-driven automated feedback tool (Essay Assessment Technology, EAT), but it is not identified as an LLM-based tool (e.g., ChatGPT, GPT-4). It is framed as an automated assessment/feedback system, and there is no indication it is a transformer-based generative LLM. Thus it does not meet the LLM requirement.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on teachers\u2019 beliefs, perceptions, and design thinking practices when integrating an AI-based automated feedback tool, not on students\u2019 writing competence or writing-related learning outcomes. It is essentially about technology integration and teacher cognition, not a pedagogical writing intervention outcome study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is explicitly described as a \u2018descriptive qualitative study\u2019 using teacher interviews to explore perceptions and pedagogical decisions. No quantitative or experimental writing outcome measures for students are reported in the abstract.""}}"
Effects of Ai Chatbots on Efl Students' Critical Thinking Skills and Intrinsic Motivation in Argumentative Writing,2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants were 40 Chinese undergraduates in an EFL context (\u201cEFL classroom activities\u201d), indicating they are L2 English learners. The focus is on argumentative writing in English.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The intervention uses an \u201cAI chatbot\u201d called Spark Desk. The abstract does not specify whether Spark Desk is a large language model (LLM)\u2013based chatbot (e.g., transformer-based generative model) or a different type of AI system. Without confirmation that it is LLM-based, it is unclear if this meets the LLM criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is argumentative writing in an EFL classroom. The chatbot is integrated into writing activities, and outcomes include critical thinking skills in argumentative writing and intrinsic motivation related to writing. This aligns with a writing-focused pedagogical intervention rather than automated scoring.""}, ""c4"": {""status"": ""unclear"", ""evidence"": ""Critical thinking skills were assessed using the Illinois Critical Thinking Essay Scoring Rubric applied to students\u2019 argumentative writing, and intrinsic motivation was measured quantitatively. However, the abstract does not clearly state whether direct writing performance metrics (e.g., writing quality scores, language accuracy, coherence) were quantified as outcomes, or only CTS as a construct applied to essays. It is therefore unclear if it reports quantifiable writing outcome metrics as defined in the inclusion criteria.""}}"
To Disclose or Not to Disclose: Exploring the Risk of Being Transparent about Genai Use in Second Language Writing,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly focuses on second language (L2) writers and L2 writing assessment, indicating that the population is L2 learners. While the target language is not named, the context of L2 writing assessment and GenAI in academic settings strongly suggests L2 English, so this criterion is treated as passed.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines the impact of disclosing GenAI use on teachers\u2019 grading. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating a specific LLM (e.g., ChatGPT) into writing instruction or processes; GenAI use is a background condition, not the designed instructional treatment.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on how disclosure of GenAI use affects L2 writing assessment (grades and teacher bias), not on improving writing competence or writing-related skills through LLM-mediated instruction. This aligns more with assessment bias and policy rather than a writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Although quantitative differences in grades under different disclosure conditions are reported, these are not outcomes of an LLM-mediated writing intervention. The study does not evaluate the effectiveness of GenAI/LLM use on writing quality; it evaluates teacher scoring behavior when GenAI use is disclosed.""}}"
Creating an Internationally Equitable Playing Field for Publishing in English-language Scholarly Journals,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The article discusses non-Anglophone authors publishing in English-language scholarly journals, but not as L2 English learners in ESL/EFL/ELL instructional contexts. It focuses on academic publishing inequities rather than language learners in educational settings.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Artificial intelligence is mentioned only as a recommendation to facilitate translation, not as an implemented LLM-based intervention in an experimental or quasi-experimental study. No specific LLM tools or instructional integration are described.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on barriers to publishing and equity in academic journals, not on writing instruction, writing pedagogy, or systematic intervention in writing competence. It is a conceptual/recommendation piece, not a pedagogical writing intervention study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not report any empirical data or quantifiable writing outcomes. It offers recommendations and arguments without experimental measures or structured intervention outcomes.""}}"
Digital Literacy in the Age of Artificial Intelligence: Exploring Student Engagement with Automated Writing Evaluation (awe) Feedback,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract is situated in the context of L2 writing but does not specify the target language (e.g., English) or clearly identify participants as ESL/EFL/ELL learners. It appears more conceptual/theoretical than participant-based.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the title mentions AI and automated writing evaluation (AWE), the abstract describes a review and conceptual discussion of digital literacy and student engagement. There is no indication of an experimental or quasi-experimental design integrating an LLM-based tool (e.g., ChatGPT, GPT-4) into writing instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on theorizing digital literacy and engagement in L2 writing, not on a concrete pedagogical intervention targeting writing competence or writing-related variables using LLMs. It is primarily a conceptual article rather than an intervention study.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics or experimental measures are reported. The article reviews concepts and proposes an integrated model; it does not assess the effectiveness of an LLM-mediated writing intervention.""}}"
Secondary School English Teachers' Application of Artificial Intelligence-guided Chatbot in the Provision of Feedback on Student Writing: an Activity Theory Perspective,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""Participants are 13 secondary school English teachers in China. The abstract does not specify the language background of the students whose writing receives feedback, though the context suggests L2 English learners. However, the study\u2019s participants and data focus are on teachers, not learners, so it is unclear whether learner-level L2 English data are central.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses Kimi, an AI-guided chatbot, to support teacher feedback on student writing. Kimi may be an LLM-based tool, but the abstract does not explicitly identify it as a large language model (e.g., ChatGPT/GPT-4-type transformer). Without confirmation that Kimi is LLM-based, it is unclear whether this meets the LLM intervention criterion.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on how teachers incorporate an AI-guided chatbot into their feedback practices, analyzed through Activity Theory. Outcomes reported concern characteristics of Kimi vs. teacher feedback and components of the activity system, not on changes in learners\u2019 writing competence or writing-related performance variables. Thus, the context is feedback practice, not a pedagogical writing intervention with learner outcomes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not report any quantifiable writing outcome metrics (e.g., writing scores, complexity, accuracy, fluency) for students. Findings relate to amount, length, foci, and types of feedback and to activity system components, but not to measured changes in student writing performance. Therefore, it does not meet the requirement for quantifiable writing outcomes.""}}"
Efl Students' Writing Engagement and Ai Attitude in Genai-assisted Contexts: a Mixed-methods Study Grounded in Sdt and Tam,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are explicitly described as EFL learners in GenAI-assisted writing contexts, which fits the target population of L2 English learners in EFL settings.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the context is \u2018GenAI-assisted writing\u2019, the abstract does not describe any experimental or quasi-experimental instructional intervention integrating a specific LLM into writing instruction. It focuses on profiling engagement and attitudes, and notes that few teachers have actively integrated such tools into their teaching, suggesting no structured LLM-based intervention was implemented.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on writing engagement and attitudes toward GenAI, not on writing competence or writing-related performance variables. The study examines engagement profiles and teacher perceptions rather than pedagogical effects on writing skills.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing scores, quality ratings, accuracy, complexity) are reported. Outcomes are engagement profiles and attitude measures, plus qualitative interview data, without experimental measures of writing performance.""}}"
