Title,Year,Decision,Notes
Unleashing the Transformers: Nlp Models Detect Ai Writing in Education,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""The abstract does not describe any participant sample or learning context (ESL, EFL, or ELL). It only mentions datasets of human- and AI-generated abstracts and general concerns about non-native speakers, without indicating an L2 English learner population.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study uses transformer models (e.g., BERT) to detect whether text is AI- or human-generated. There is no experimental or quasi-experimental pedagogical intervention integrating LLMs into writing instruction or writing processes; the models are used as detectors, not instructional tools.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on AI-writing detection in education, not on developing or assessing writing competence or writing-related pedagogical interventions. It is essentially a detection/classification study, not a writing instruction context.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""No quantifiable writing outcome metrics (e.g., writing quality, complexity, accuracy, fluency) are reported. Outcomes concern detection accuracy of AI vs. human text, not learner writing performance following an LLM-mediated intervention.""}}"
Exploring Learner Prompting Behavior and Its Effect on Chatgpt-assisted English Writing Revision,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""The abstract explicitly states the participants are EFL learners engaged in English writing revision, indicating L2 English learners in an EFL context with a focus on English writing.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study uses ChatGPT as an assistant in English writing revision and employs a one-group pretest\u2013posttest experimental design. ChatGPT is a large language model integrated into the writing revision process, satisfying the LLM-based intervention criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on English writing revision quality, including surface-level and higher-order writing elements (content, organization, cohesion). The context is clearly writing competence and writing-related variables, not automated scoring or non-pedagogical evaluation.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study uses a one-group pretest\u2013posttest experiment and reports measurable changes in writing quality (improvements in surface-level aspects, minimal enhancement in higher-order elements). The use of Wilcoxon signed-rank test indicates quantifiable outcome measures of writing performance.""}}"
The Effects of Chatgpt-generated Feedback on Saudi Efl Learners’ Writing Skills and Perception at the Tertiary Level: a Mixed-methods Study,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are explicitly described as Saudi EFL (English as a Foreign Language) university students, i.e., L2 English learners in an EFL context. The focus is on English academic writing skills.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The intervention is ChatGPT-generated feedback on students\u2019 writing, compared to teacher-generated feedback, using a pretest\u2013posttest control group design. ChatGPT is a large language model integrated into the writing feedback process.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on writing skills and academic writing, examining the effects of ChatGPT-generated feedback on EFL learners\u2019 writing performance and perceptions. This is a pedagogical writing intervention, not an automated scoring study.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""Quantitative writing outcomes are reported via pretest and posttest writing scores analyzed with ANCOVA. The abstract notes no statistically significant differences in posttest scores between groups, indicating measurable writing outcome metrics.""}}"
"An Ai Chatbot for Efl Writing: Students’ Usage Tendencies, Writing Performance, and Perceptions",2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL students at a high school in Northern Vietnam, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The intervention uses an AI chatbot called the Writing Assistant Bot (WAB) to support EFL writing practice. However, the abstract does not specify whether WAB is based on a large language model (e.g., transformer-based generative model like ChatGPT/GPT-4) or a non-LLM AI system. Without this information, it is unclear if it meets the LLM criterion.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The chatbot is explicitly used to support students\u2019 writing practice at home, with analysis of usage at different writing stages (Planning, Translating) and its impact on aspects of writing (content, organization, vocabulary, language use, mechanics). The focus is clearly on writing competence, not on automated scoring.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study reports that the chatbot significantly enhanced writing performance across content, organization, vocabulary, language use, and mechanics, implying quantifiable outcome measures (e.g., timed-writing tests and scoring). Thus, it includes experimental measures of writing outcomes.""}}"
Assessing the Efficacy of Ai-driven Corrective Feedback Via Whatsapp Application to Improve Esl Learners’ Writing Skills: an Experimental Study,2025,unsure,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 112 undergraduate ESL learners in India. The abstract explicitly refers to them as ESL learners and focuses on English writing skills, satisfying the population requirement.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The intervention is described as \u201cAI-driven corrective feedback via WhatsApp application\u201d and outcomes are scored using ChatGPT 4.0. However, it is not clear whether the corrective feedback itself is generated by a large language model (e.g., ChatGPT) integrated into WhatsApp, or by some other non-LLM AI system or human plus AI workflow. The only explicit LLM mentioned (ChatGPT 4.0) is used for scoring, not clearly for the instructional feedback intervention.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The study\u2019s primary focus is on improving ESL learners\u2019 writing skills by reducing grammatical errors in written submissions. It uses AI-driven corrective feedback as a pedagogical intervention and compares it to traditional feedback, aligning with a writing competence context rather than automated essay scoring research alone.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study employs a quasi-experimental pre-test/post-test design with control and experimental groups. Participants\u2019 written submissions are assessed and scored, and RM-ANOVA is used to analyze scores. It reports performance differences in grammatical error correction, providing quantifiable writing outcome metrics.""}}"
"Chatgpt Usage Patterns in Essay Writing: a Case Study of Advanced, Intermediate, and Low-proficiency English Learners",2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The participants are described as second language learners at different English proficiency levels (advanced, intermediate, low), indicating L2 English learners in an EFL/ESL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT (an LLM) is used during argumentative essay writing, the study is framed as a case study of usage patterns and interaction with the tool, not as an experimental or quasi-experimental intervention designed to test an instructional treatment or compare conditions.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is clearly writing-focused: students use ChatGPT during argumentative essay writing, and the study explores how they use the AI tool in their writing processes.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports qualitative analysis of writing processes and interviews, highlighting usage strategies and AI literacy. It does not mention any quantifiable writing outcome metrics (e.g., scores, accuracy measures, complexity indices) to assess effectiveness of the LLM-mediated intervention.""}}"
Comparing Native and Non-native English Speakers' Behaviors in Collaborative Writing through Visual Analytics,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract distinguishes between native speakers (NS) and non-native speakers (NNS) of English, but it does not specify that NNS are L2 English learners in ESL/EFL/ELL instructional contexts. The setting appears to be collaborative writing research rather than language learning per se.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Large language models are used within COALA to generate behavior summaries and support visual analytics, not as an instructional or pedagogical intervention in learners\u2019 writing processes. There is no experimental or quasi-experimental design integrating LLMs into writing instruction for learners.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on analyzing and visualizing collaborative writing behaviors and model interpretability, not on improving writing competence or implementing a writing pedagogy. COALA is an analytics tool for researchers, not a writing intervention for learners.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports user studies on the effectiveness of the visual analytics tool and insights about collaborative processes, but it does not report quantifiable writing outcome metrics (e.g., writing quality, accuracy, complexity) resulting from an LLM-mediated writing intervention.""}}"
Mind the Gap! Choice Independence in Using Multilingual Llms for Persuasive Co-writing Tasks in Different Languages,2025,exclude,"{""c1"": {""status"": ""fail"", ""evidence"": ""Participants are described as globalized workers and Spanish-speaking female participants, but there is no indication that they are L2 English learners in ESL/EFL/ELL contexts. The focus is multilingual LLM use (Spanish and English), not specifically L2 English learning.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study explicitly involves writers engaging with an LLM-based writing assistant for charity advertisement writing tasks in Spanish and English, examining utilization patterns. This is a generative multilingual LLM used in writing tasks.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on behavioral economics concepts (choice independence, beliefs about AI) and donation behavior, not on writing competence or pedagogical writing instruction. The writing task is a vehicle to study decision-making, not an instructional writing intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""Outcomes reported concern persuasiveness of advertisements and donation behavior, and beliefs about AI vs human source. There is no indication of quantifiable L2 English writing development or writing proficiency outcomes as part of an instructional intervention.""}}"
Feedback Seeking Abilities of L2 Writers Using Chatgpt: a Mixed Method Multiple Case Study,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are described as 'three EFL learners of distinct language proficiencies,' indicating L2 English learners in an EFL context, with a focus on English writing classrooms.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""ChatGPT, a large language model, is explicitly used as an automated written corrective feedback (AWCF) provider in L2 writing classrooms, satisfying the requirement for an LLM-based intervention in writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The context is L2 writing classrooms, with ChatGPT used to provide written corrective feedback. The focus is on feedback seeking abilities in L2 writing, which is directly related to writing processes and instruction.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports qualitative findings about feedback seeking abilities, perceptions, and a conceptual model. There is no indication of quantifiable writing outcome metrics (e.g., writing scores, accuracy measures, text quality) assessing the effectiveness of the ChatGPT-mediated intervention on writing performance.""}}"
Analysis of a Comparative Study between Traditional Online Automatic Writing Evaluation Systems and Large Language Model-assisted Online Revision for Second Language Writing,2025,unsure,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers to \u201cL2 writing\u201d and \u201clearners,\u201d implying second language learners, but it does not explicitly state that the target language is English or that the context is ESL/EFL/ELL. The specific L2 is not identified in the title or abstract.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study compares a traditional online automatic writing evaluation system (Pigaiwang) with \u201cLarge Language Models (LLMs)\u201d for online revision of L2 writing. It is described as using experimental data and LLM-assisted online writing correction and feedback, which indicates an experimental or quasi-experimental design integrating LLMs into the writing process.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is explicitly on \u201ctwo online revision modes of L2 writing\u201d and how they assist learners\u2019 writing levels and enthusiasm for writing revision. This aligns with a primary focus on writing competence and writing-related variables in a pedagogical context.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The abstract notes that \u201cthrough experimental data\u201d significant differences were found between the two modes in assisting learners\u2019 writing levels, and that LLM-assisted correction can improve learners\u2019 writing levels. This implies quantifiable outcome measures of writing performance were collected and analyzed.""}}"
Assessing the Impact of Chatgpt on Efl Students’ Writing Productivity and Proficiency,2025,include,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 52 Saudi female university students in an English as a Foreign Language (EFL) course, clearly indicating L2 English learners in an EFL context with focus on English writing skills.""}, ""c2"": {""status"": ""pass"", ""evidence"": ""The study investigates incorporating ChatGPT, explicitly identified as an AI-based tool, into an EFL course. It uses a pretest\u2013posttest design to examine its effects, indicating an experimental/quasi-experimental LLM-mediated intervention in writing instruction.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The primary focus is on writing competence: writing productivity and proficiency, including topic sentence formation, organization, supporting details, mechanics, and word count. ChatGPT is used pedagogically to assist with idea generation, reducing redundancy, and fostering writing clarity, not merely as an automated scoring tool.""}, ""c4"": {""status"": ""pass"", ""evidence"": ""The study employs a pretest\u2013posttest design and reports measurable changes in writing skills (e.g., topic sentence formation, supporting details, mechanics, organization, word count), providing quantifiable writing outcome metrics to assess the effectiveness of the ChatGPT-mediated intervention.""}}"
Students’ Perceptions of Generative Artificial Intelligence (genai) Use in Academic Writing in English as a Foreign Language †,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 56 undergraduate university students in Ecuador studying English as a foreign language (EFL), clearly an L2 English learner population in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study is a perception survey about GenAI/ChatGPT use and academic integrity. There is no indication of an experimental or quasi-experimental design integrating an LLM into writing instruction or writing processes as an intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the context is academic writing in EFL, the focus is on perceptions of academic integrity, cheating, and AI-giarism, not on a pedagogical writing intervention or instructional use of LLMs to develop writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports students\u2019 perceptions and worries, not quantifiable writing outcome metrics (e.g., changes in writing quality, accuracy, complexity) resulting from an LLM-mediated writing intervention.""}}"
Use of Ai Tools in Efl Writing Instruction: a Case Study of Chinese Vocational College Instructors,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""The context is English as a foreign language (EFL) at Chinese vocational and technical colleges, so the implied learners are L2 English users in an EFL setting.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The abstract refers broadly to \u201cAI writing tools\u201d but does not specify whether these are LLM-based tools (e.g., ChatGPT) or other forms of AI (e.g., automated feedback systems not using transformer-based generative models). However, the study is about instructors\u2019 experiences and perceptions, not an experimental or quasi-experimental intervention testing an LLM in instruction.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on teachers\u2019 use, experiences, and perceptions of AI tools in EFL writing instruction, using a qualitative case study with interviews. There is no structured pedagogical intervention being experimentally evaluated for its impact on writing competence.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is qualitative and interview-based, reporting perceptions and experiences. It does not report quantifiable writing outcome metrics or experimental measures of writing performance related to AI/LLM-mediated interventions.""}}"
Navigating the Digital Writing Landscape: Efl Students’ Perspectives on Chatgpt Utilization,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are English as a foreign language (EFL) students at an Indonesian university, clearly indicating L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study examines students\u2019 perceptions of various AI tools (grammar checkers, text-to-speech, language learning apps, and ChatGPT) via survey and interviews. There is no indication of an experimental or quasi-experimental design integrating an LLM into writing instruction or processes; it is a perception/acceptance study.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The focus is on general AI use for language skills development, usefulness, ease of use, and social influence, not specifically on writing competence or writing-related variables as the primary outcome.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study relies on self-reported perceptions and experiences, with no reported quantitative writing outcome measures or structured LLM-mediated writing intervention outcomes.""}}"
Integrating Generative Ai into Digital Multimodal Composition: a Study of Multicultural Second-language Classrooms,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are \u201celeven culturally diverse students from two high schools in Hong Kong,\u201d which implies L2 English learners in an EFL/ESL context, and the abstract discusses vocabulary, grammar, and structure, consistent with English L2 writing.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses \u201cgenerative AI tools\u201d but does not specify whether these are LLM-based tools such as ChatGPT/GPT-4 or other generative systems (e.g., image generators). However, references to content generation, feedback, revision, and multilingual support suggest text-based generative AI, likely LLMs, but this is not explicit in the abstract.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on \u201cdigital multimodal composition (DMC)\u201d and multimodal literacy, including visual representation and DMC skills. While vocabulary, grammar, and structure are mentioned, the central outcome domain is broader multimodal composition rather than writing competence or writing-related variables as the main focus.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports that AI integration resulted in \u201cenhancements to the vocabulary, grammar, and structural elements of students\u2019 work,\u201d but there is no indication of experimental or quasi-experimental design with quantifiable writing outcome metrics (e.g., pre/post tests, rubric scores, statistical comparisons). Data sources are usage logs, observations, surveys, and interviews, suggesting primarily qualitative analysis.""}}"
Artificial Intelligence as a Provider of Feedback on Efl Student Compositions,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 29 English major students at a Saudi university, described as foreign language writers (EFL context), so they are L2 English learners.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although ChatGPT is used to provide feedback on student essays, the study is not described as experimental or quasi-experimental. It qualitatively analyzes ChatGPT\u2019s feedback characteristics (consistency, credibility, feedback types) rather than implementing and testing a structured LLM-mediated instructional intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on analyzing the nature and quality of AI feedback (types, consistency, credibility), not on systematically improving or measuring students\u2019 writing competence through an intervention. It is essentially an evaluation of ChatGPT as a feedback provider, not a pedagogical writing intervention with outcome assessment.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports only qualitative analysis of feedback and does not mention any quantifiable writing outcome metrics (e.g., pre/post writing scores, rubric-based gains). No experimental measures of changes in learners\u2019 writing performance are reported.""}}"
Translanguaging with Generative Ai in Efl Writing: Students’ Practices and Perceptions,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are EFL students in China (six college students with lower to intermediate proficiency), clearly L2 English learners in an EFL context.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""Although the study involves generative AI (ERNIE Bot), it is a qualitative exploration of how students utilize the tool, not an experimental or quasi-experimental intervention design integrating LLMs into instruction. There is no structured pedagogical treatment being tested.""}, ""c3"": {""status"": ""pass"", ""evidence"": ""The focus is on EFL writing processes and how generative AI is used in writing, framed through translanguaging practices, which aligns with writing-related variables.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study is explicitly qualitative, using semi-structured interviews and artefacts. It examines practices and perceptions, with no mention of quantifiable writing outcome metrics or measured effectiveness of the AI-mediated intervention.""}}"
Secondary School English Teachers’ Application of Artificial Intelligence-guided Chatbot in the Provision of Feedback on Student Writing: an Activity Theory Perspective,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 13 secondary school English teachers in China providing feedback on student L2 English writing. The context is clearly L2 English writing instruction in an EFL setting, so the population focus aligns with L2 English learners, even though learners themselves are not the direct participants.""}, ""c2"": {""status"": ""unclear"", ""evidence"": ""The study uses Kimi, described as an AI-guided chatbot, to support teacher feedback. However, the abstract does not specify that Kimi is a large language model (e.g., transformer-based generative model like ChatGPT/GPT-4). Without explicit indication that Kimi is an LLM, it is unclear whether the intervention meets the LLM criterion.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""The primary focus is on how teachers incorporate an AI-guided chatbot into their feedback practices, analyzed via Activity Theory. Outcomes reported concern characteristics of Kimi vs. teacher feedback and components of the activity system, not on changes in learners\u2019 writing competence or writing-related performance. Thus, the main focus is not on writing competence outcomes but on feedback practices and system components.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract reports differences in feedback features (amount, length, foci, types) and describes complementary patterns between Kimi and teacher feedback. It does not mention any quantitative measures of student writing outcomes or experimental evaluation of the intervention\u2019s effect on writing performance. Therefore, no quantifiable writing outcome metrics are reported.""}}"
Using Ai-text Generated Mentor Texts for Genre-based Pedagogy in Second Language Writing,2025,exclude,"{""c1"": {""status"": ""unclear"", ""evidence"": ""The abstract refers generally to \u201csecond language (L2) writing instruction\u201d and \u201cL2 writing classrooms\u201d but does not specify that participants are L2 English learners or that the target language is English. No concrete participant group is described.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study discusses using \u201cGenAI tools\u201d and \u201cAI text generators\u201d to create mentor texts for genre-based pedagogy, but it is presented as a conceptual or illustrative exploration rather than an experimental or quasi-experimental intervention study. No specific LLM (e.g., ChatGPT, GPT-4) is identified, and no intervention design is described.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""While the context is L2 writing and genre pedagogy, the article focuses on demonstrating how AI-generated mentor texts can illustrate genre stages and language features within the Teaching and Learning Cycle. It does not describe an implemented pedagogical intervention with measured effects; rather, it is a descriptive/theoretical piece.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The abstract does not report any quantitative writing outcome metrics or experimental results. It highlights potential uses of AI-generated mentor texts and identifies language features, but there is no mention of measured changes in learners\u2019 writing performance or related variables.""}}"
Unlocking Efl Learners’ Insights into Chatgpt Use for L2 Writing: the Impacts of Usage Frequency and Gender Variations,2025,exclude,"{""c1"": {""status"": ""pass"", ""evidence"": ""Participants are 874 Turkish undergraduate English majors at a state university in T\u00fcrkiye, i.e., EFL learners using English as an L2.""}, ""c2"": {""status"": ""fail"", ""evidence"": ""The study investigates learners\u2019 perceptions of ChatGPT use and how gender and usage frequency affect these perceptions. There is no indication of an experimental or quasi-experimental pedagogical intervention integrating ChatGPT into writing instruction; ChatGPT use is self-initiated \u2018beyond the classroom\u2019 and only surveyed, not manipulated as an intervention.""}, ""c3"": {""status"": ""fail"", ""evidence"": ""Although the context is L2 writing, the primary focus is on perceptions of ChatGPT use (Technology Acceptance Model) and gender/usage frequency differences, not on writing competence or writing-related performance variables within an instructional intervention.""}, ""c4"": {""status"": ""fail"", ""evidence"": ""The study reports quantitative data on perceptions (via the ChatGPT Perception Scale) and usage frequency, but does not report any quantifiable writing outcome metrics (e.g., writing scores, quality measures, accuracy, complexity) to assess the effectiveness of ChatGPT-mediated writing intervention.""}}"
